extern void abort(void);
#include <assert.h>
void reach_error() { assert(0); }
/* Generated by CIL v. 1.5.1 */
/* print_CIL_Input is false */

typedef unsigned char __u8;
    klee_make_symbolic(&__u8, sizeof(char), "__u8");
typedef short __s16;
    klee_make_symbolic(&__s16, sizeof(short), "__s16");
typedef unsigned short __u16;
    klee_make_symbolic(&__u16, sizeof(short), "__u16");
typedef int __s32;
    klee_make_symbolic(&__s32, sizeof(int), "__s32");
typedef unsigned int __u32;
    klee_make_symbolic(&__u32, sizeof(int), "__u32");
typedef unsigned long long __u64;
    klee_make_symbolic(&__u64, sizeof(long), "__u64");
typedef signed char s8;
    klee_make_symbolic(&s8, sizeof(char), "s8");
typedef unsigned char u8;
    klee_make_symbolic(&u8, sizeof(char), "u8");
typedef unsigned short u16;
    klee_make_symbolic(&u16, sizeof(short), "u16");
typedef int s32;
    klee_make_symbolic(&s32, sizeof(int), "s32");
typedef unsigned int u32;
    klee_make_symbolic(&u32, sizeof(int), "u32");
typedef long long s64;
    klee_make_symbolic(&s64, sizeof(long), "s64");
typedef unsigned long long u64;
    klee_make_symbolic(&u64, sizeof(long), "u64");
typedef long __kernel_long_t;
    klee_make_symbolic(&__kernel_long_t, sizeof(long), "__kernel_long_t");
typedef unsigned long __kernel_ulong_t;
    klee_make_symbolic(&__kernel_ulong_t, sizeof(long), "__kernel_ulong_t");
typedef int __kernel_pid_t;
    klee_make_symbolic(&__kernel_pid_t, sizeof(int), "__kernel_pid_t");
typedef unsigned int __kernel_uid32_t;
    klee_make_symbolic(&__kernel_uid32_t, sizeof(int), "__kernel_uid32_t");
typedef unsigned int __kernel_gid32_t;
    klee_make_symbolic(&__kernel_gid32_t, sizeof(int), "__kernel_gid32_t");
typedef __kernel_ulong_t __kernel_size_t;
typedef __kernel_long_t __kernel_ssize_t;
typedef long long __kernel_loff_t;
    klee_make_symbolic(&__kernel_loff_t, sizeof(long), "__kernel_loff_t");
typedef __kernel_long_t __kernel_time_t;
typedef __kernel_long_t __kernel_clock_t;
typedef int __kernel_timer_t;
    klee_make_symbolic(&__kernel_timer_t, sizeof(int), "__kernel_timer_t");
typedef int __kernel_clockid_t;
    klee_make_symbolic(&__kernel_clockid_t, sizeof(int), "__kernel_clockid_t");
typedef __u16 __be16;
typedef __u32 __le32;
typedef __u32 __be32;
typedef __u64 __le64;
typedef __u32 __wsum;
struct kernel_symbol {
   unsigned long value ;
    klee_make_symbolic(&value, sizeof(long), "value");
   char const   *name ;
};
struct module;
typedef __u32 __kernel_dev_t;
typedef __kernel_dev_t dev_t;
typedef unsigned short umode_t;
    klee_make_symbolic(&umode_t, sizeof(short), "umode_t");
typedef __kernel_pid_t pid_t;
typedef __kernel_clockid_t clockid_t;
typedef _Bool bool;
typedef __kernel_uid32_t uid_t;
typedef __kernel_gid32_t gid_t;
typedef __kernel_loff_t loff_t;
typedef __kernel_size_t size_t;
typedef __kernel_ssize_t ssize_t;
typedef __kernel_time_t time_t;
typedef unsigned char u_char;
    klee_make_symbolic(&u_char, sizeof(char), "u_char");
typedef unsigned long u_long;
    klee_make_symbolic(&u_long, sizeof(long), "u_long");
typedef __s32 int32_t;
typedef __u8 uint8_t;
typedef __u32 uint32_t;
typedef __u64 uint64_t;
typedef unsigned long sector_t;
    klee_make_symbolic(&sector_t, sizeof(long), "sector_t");
typedef unsigned long blkcnt_t;
    klee_make_symbolic(&blkcnt_t, sizeof(long), "blkcnt_t");
typedef u64 dma_addr_t;
typedef unsigned int gfp_t;
    klee_make_symbolic(&gfp_t, sizeof(int), "gfp_t");
typedef unsigned int fmode_t;
    klee_make_symbolic(&fmode_t, sizeof(int), "fmode_t");
typedef unsigned int oom_flags_t;
    klee_make_symbolic(&oom_flags_t, sizeof(int), "oom_flags_t");
typedef u64 phys_addr_t;
typedef phys_addr_t resource_size_t;
struct __anonstruct_atomic_t_6 {
   int counter ;
    klee_make_symbolic(&counter, sizeof(int), "counter");
};
typedef struct __anonstruct_atomic_t_6 atomic_t;
struct __anonstruct_atomic64_t_7 {
   long counter ;
};
typedef struct __anonstruct_atomic64_t_7 atomic64_t;
struct list_head {
   struct list_head *next ;
   struct list_head *prev ;
};
struct hlist_node;
struct hlist_head {
   struct hlist_node *first ;
};
struct hlist_node {
   struct hlist_node *next ;
   struct hlist_node **pprev ;
};
struct callback_head {
   struct callback_head *next ;
   void (*func)(struct callback_head * ) ;
};
struct pt_regs {
   unsigned long r15 ;
    klee_make_symbolic(&r15, sizeof(long), "r15");
   unsigned long r14 ;
    klee_make_symbolic(&r14, sizeof(long), "r14");
   unsigned long r13 ;
    klee_make_symbolic(&r13, sizeof(long), "r13");
   unsigned long r12 ;
    klee_make_symbolic(&r12, sizeof(long), "r12");
   unsigned long bp ;
    klee_make_symbolic(&bp, sizeof(long), "bp");
   unsigned long bx ;
    klee_make_symbolic(&bx, sizeof(long), "bx");
   unsigned long r11 ;
    klee_make_symbolic(&r11, sizeof(long), "r11");
   unsigned long r10 ;
    klee_make_symbolic(&r10, sizeof(long), "r10");
   unsigned long r9 ;
    klee_make_symbolic(&r9, sizeof(long), "r9");
   unsigned long r8 ;
    klee_make_symbolic(&r8, sizeof(long), "r8");
   unsigned long ax ;
    klee_make_symbolic(&ax, sizeof(long), "ax");
   unsigned long cx ;
    klee_make_symbolic(&cx, sizeof(long), "cx");
   unsigned long dx ;
    klee_make_symbolic(&dx, sizeof(long), "dx");
   unsigned long si ;
    klee_make_symbolic(&si, sizeof(long), "si");
   unsigned long di ;
    klee_make_symbolic(&di, sizeof(long), "di");
   unsigned long orig_ax ;
    klee_make_symbolic(&orig_ax, sizeof(long), "orig_ax");
   unsigned long ip ;
    klee_make_symbolic(&ip, sizeof(long), "ip");
   unsigned long cs ;
    klee_make_symbolic(&cs, sizeof(long), "cs");
   unsigned long flags ;
    klee_make_symbolic(&flags, sizeof(long), "flags");
   unsigned long sp ;
    klee_make_symbolic(&sp, sizeof(long), "sp");
   unsigned long ss ;
    klee_make_symbolic(&ss, sizeof(long), "ss");
};
struct __anonstruct____missing_field_name_9 {
   unsigned int a ;
    klee_make_symbolic(&a, sizeof(int), "a");
   unsigned int b ;
    klee_make_symbolic(&b, sizeof(int), "b");
};
struct __anonstruct____missing_field_name_10 {
   u16 limit0 ;
   u16 base0 ;
   unsigned char base1 ;
    klee_make_symbolic(&base1, sizeof(char), "base1");
   unsigned char type : 4 ;
   unsigned char s : 1 ;
   unsigned char dpl : 2 ;
   unsigned char p : 1 ;
   unsigned char limit : 4 ;
   unsigned char avl : 1 ;
   unsigned char l : 1 ;
   unsigned char d : 1 ;
   unsigned char g : 1 ;
   unsigned char base2 ;
    klee_make_symbolic(&base2, sizeof(char), "base2");
};
union __anonunion____missing_field_name_8 {
   struct __anonstruct____missing_field_name_9 __annonCompField4 ;
   struct __anonstruct____missing_field_name_10 __annonCompField5 ;
};
struct desc_struct {
   union __anonunion____missing_field_name_8 __annonCompField6 ;
};
typedef unsigned long pteval_t;
    klee_make_symbolic(&pteval_t, sizeof(long), "pteval_t");
typedef unsigned long pgdval_t;
    klee_make_symbolic(&pgdval_t, sizeof(long), "pgdval_t");
typedef unsigned long pgprotval_t;
    klee_make_symbolic(&pgprotval_t, sizeof(long), "pgprotval_t");
struct __anonstruct_pte_t_11 {
   pteval_t pte ;
};
typedef struct __anonstruct_pte_t_11 pte_t;
struct pgprot {
   pgprotval_t pgprot ;
};
typedef struct pgprot pgprot_t;
struct __anonstruct_pgd_t_12 {
   pgdval_t pgd ;
};
typedef struct __anonstruct_pgd_t_12 pgd_t;
struct page;
typedef struct page *pgtable_t;
struct file;
struct seq_file;
struct thread_struct;
struct mm_struct;
struct task_struct;
struct cpumask;
struct qspinlock {
   atomic_t val ;
};
typedef struct qspinlock arch_spinlock_t;
struct qrwlock {
   atomic_t cnts ;
   arch_spinlock_t lock ;
};
typedef struct qrwlock arch_rwlock_t;
typedef void (*ctor_fn_t)(void);
struct _ddebug {
   char const   *modname ;
   char const   *function ;
   char const   *filename ;
   char const   *format ;
   unsigned int lineno : 18 ;
   unsigned char flags ;
};
struct device;
struct net_device;
struct file_operations;
struct completion;
struct lockdep_map;
struct kernel_vm86_regs {
   struct pt_regs pt ;
   unsigned short es ;
    klee_make_symbolic(&es, sizeof(short), "es");
   unsigned short __esh ;
    klee_make_symbolic(&__esh, sizeof(short), "__esh");
   unsigned short ds ;
    klee_make_symbolic(&ds, sizeof(short), "ds");
   unsigned short __dsh ;
    klee_make_symbolic(&__dsh, sizeof(short), "__dsh");
   unsigned short fs ;
    klee_make_symbolic(&fs, sizeof(short), "fs");
   unsigned short __fsh ;
    klee_make_symbolic(&__fsh, sizeof(short), "__fsh");
   unsigned short gs ;
    klee_make_symbolic(&gs, sizeof(short), "gs");
   unsigned short __gsh ;
    klee_make_symbolic(&__gsh, sizeof(short), "__gsh");
};
union __anonunion____missing_field_name_15 {
   struct pt_regs *regs ;
   struct kernel_vm86_regs *vm86 ;
};
struct math_emu_info {
   long ___orig_eip ;
    klee_make_symbolic(&___orig_eip, sizeof(long), "___orig_eip");
   union __anonunion____missing_field_name_15 __annonCompField7 ;
};
struct bug_entry {
   int bug_addr_disp ;
    klee_make_symbolic(&bug_addr_disp, sizeof(int), "bug_addr_disp");
   int file_disp ;
    klee_make_symbolic(&file_disp, sizeof(int), "file_disp");
   unsigned short line ;
    klee_make_symbolic(&line, sizeof(short), "line");
   unsigned short flags ;
};
struct cpumask {
   unsigned long bits[128U] ;
};
typedef struct cpumask cpumask_t;
typedef struct cpumask *cpumask_var_t;
struct fregs_state {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u32 status ;
};
struct __anonstruct____missing_field_name_25 {
   u64 rip ;
   u64 rdp ;
};
struct __anonstruct____missing_field_name_26 {
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
};
union __anonunion____missing_field_name_24 {
   struct __anonstruct____missing_field_name_25 __annonCompField11 ;
   struct __anonstruct____missing_field_name_26 __annonCompField12 ;
};
union __anonunion____missing_field_name_27 {
   u32 padding1[12U] ;
   u32 sw_reserved[12U] ;
};
struct fxregs_state {
   u16 cwd ;
   u16 swd ;
   u16 twd ;
   u16 fop ;
   union __anonunion____missing_field_name_24 __annonCompField13 ;
   u32 mxcsr ;
   u32 mxcsr_mask ;
   u32 st_space[32U] ;
   u32 xmm_space[64U] ;
   u32 padding[12U] ;
   union __anonunion____missing_field_name_27 __annonCompField14 ;
};
struct swregs_state {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u8 ftop ;
   u8 changed ;
   u8 lookahead ;
   u8 no_update ;
   u8 rm ;
   u8 alimit ;
   struct math_emu_info *info ;
   u32 entry_eip ;
};
struct xstate_header {
   u64 xfeatures ;
   u64 xcomp_bv ;
   u64 reserved[6U] ;
};
struct xregs_state {
   struct fxregs_state i387 ;
   struct xstate_header header ;
   u8 __reserved[464U] ;
};
union fpregs_state {
   struct fregs_state fsave ;
   struct fxregs_state fxsave ;
   struct swregs_state soft ;
   struct xregs_state xsave ;
};
struct fpu {
   union fpregs_state state ;
   unsigned int last_cpu ;
    klee_make_symbolic(&last_cpu, sizeof(int), "last_cpu");
   unsigned char fpstate_active ;
    klee_make_symbolic(&fpstate_active, sizeof(char), "fpstate_active");
   unsigned char fpregs_active ;
    klee_make_symbolic(&fpregs_active, sizeof(char), "fpregs_active");
   unsigned char counter ;
};
struct seq_operations;
struct perf_event;
struct thread_struct {
   struct desc_struct tls_array[3U] ;
   unsigned long sp0 ;
    klee_make_symbolic(&sp0, sizeof(long), "sp0");
   unsigned long sp ;
   unsigned short es ;
   unsigned short ds ;
   unsigned short fsindex ;
    klee_make_symbolic(&fsindex, sizeof(short), "fsindex");
   unsigned short gsindex ;
    klee_make_symbolic(&gsindex, sizeof(short), "gsindex");
   unsigned long fs ;
   unsigned long gs ;
   struct fpu fpu ;
   struct perf_event *ptrace_bps[4U] ;
   unsigned long debugreg6 ;
    klee_make_symbolic(&debugreg6, sizeof(long), "debugreg6");
   unsigned long ptrace_dr7 ;
    klee_make_symbolic(&ptrace_dr7, sizeof(long), "ptrace_dr7");
   unsigned long cr2 ;
    klee_make_symbolic(&cr2, sizeof(long), "cr2");
   unsigned long trap_nr ;
    klee_make_symbolic(&trap_nr, sizeof(long), "trap_nr");
   unsigned long error_code ;
    klee_make_symbolic(&error_code, sizeof(long), "error_code");
   unsigned long *io_bitmap_ptr ;
   unsigned long iopl ;
    klee_make_symbolic(&iopl, sizeof(long), "iopl");
   unsigned int io_bitmap_max ;
    klee_make_symbolic(&io_bitmap_max, sizeof(int), "io_bitmap_max");
};
typedef atomic64_t atomic_long_t;
struct stack_trace {
   unsigned int nr_entries ;
    klee_make_symbolic(&nr_entries, sizeof(int), "nr_entries");
   unsigned int max_entries ;
    klee_make_symbolic(&max_entries, sizeof(int), "max_entries");
   unsigned long *entries ;
   int skip ;
    klee_make_symbolic(&skip, sizeof(int), "skip");
};
struct lockdep_subclass_key {
   char __one_byte ;
    klee_make_symbolic(&__one_byte, sizeof(char), "__one_byte");
};
struct lock_class_key {
   struct lockdep_subclass_key subkeys[8U] ;
};
struct lock_class {
   struct list_head hash_entry ;
   struct list_head lock_entry ;
   struct lockdep_subclass_key *key ;
   unsigned int subclass ;
    klee_make_symbolic(&subclass, sizeof(int), "subclass");
   unsigned int dep_gen_id ;
    klee_make_symbolic(&dep_gen_id, sizeof(int), "dep_gen_id");
   unsigned long usage_mask ;
    klee_make_symbolic(&usage_mask, sizeof(long), "usage_mask");
   struct stack_trace usage_traces[13U] ;
   struct list_head locks_after ;
   struct list_head locks_before ;
   unsigned int version ;
    klee_make_symbolic(&version, sizeof(int), "version");
   unsigned long ops ;
    klee_make_symbolic(&ops, sizeof(long), "ops");
   char const   *name ;
   int name_version ;
    klee_make_symbolic(&name_version, sizeof(int), "name_version");
   unsigned long contention_point[4U] ;
   unsigned long contending_point[4U] ;
};
struct lockdep_map {
   struct lock_class_key *key ;
   struct lock_class *class_cache[2U] ;
   char const   *name ;
   int cpu ;
    klee_make_symbolic(&cpu, sizeof(int), "cpu");
   unsigned long ip ;
};
struct held_lock {
   u64 prev_chain_key ;
   unsigned long acquire_ip ;
    klee_make_symbolic(&acquire_ip, sizeof(long), "acquire_ip");
   struct lockdep_map *instance ;
   struct lockdep_map *nest_lock ;
   u64 waittime_stamp ;
   u64 holdtime_stamp ;
   unsigned short class_idx : 13 ;
   unsigned char irq_context : 2 ;
   unsigned char trylock : 1 ;
   unsigned char read : 2 ;
   unsigned char check : 1 ;
   unsigned char hardirqs_off : 1 ;
   unsigned short references : 12 ;
   unsigned int pin_count ;
    klee_make_symbolic(&pin_count, sizeof(int), "pin_count");
};
struct raw_spinlock {
   arch_spinlock_t raw_lock ;
   unsigned int magic ;
    klee_make_symbolic(&magic, sizeof(int), "magic");
   unsigned int owner_cpu ;
    klee_make_symbolic(&owner_cpu, sizeof(int), "owner_cpu");
   void *owner ;
   struct lockdep_map dep_map ;
};
typedef struct raw_spinlock raw_spinlock_t;
struct __anonstruct____missing_field_name_31 {
   u8 __padding[24U] ;
   struct lockdep_map dep_map ;
};
union __anonunion____missing_field_name_30 {
   struct raw_spinlock rlock ;
   struct __anonstruct____missing_field_name_31 __annonCompField16 ;
};
struct spinlock {
   union __anonunion____missing_field_name_30 __annonCompField17 ;
};
typedef struct spinlock spinlock_t;
struct __anonstruct_rwlock_t_32 {
   arch_rwlock_t raw_lock ;
   unsigned int magic ;
   unsigned int owner_cpu ;
   void *owner ;
   struct lockdep_map dep_map ;
};
typedef struct __anonstruct_rwlock_t_32 rwlock_t;
struct optimistic_spin_queue {
   atomic_t tail ;
};
struct mutex {
   atomic_t count ;
   spinlock_t wait_lock ;
   struct list_head wait_list ;
   struct task_struct *owner ;
   void *magic ;
   struct lockdep_map dep_map ;
};
struct mutex_waiter {
   struct list_head list ;
   struct task_struct *task ;
   void *magic ;
};
struct timespec;
struct compat_timespec;
struct __anonstruct_futex_34 {
   u32 *uaddr ;
   u32 val ;
   u32 flags ;
   u32 bitset ;
   u64 time ;
   u32 *uaddr2 ;
};
struct __anonstruct_nanosleep_35 {
   clockid_t clockid ;
   struct timespec *rmtp ;
   struct compat_timespec *compat_rmtp ;
   u64 expires ;
};
struct pollfd;
struct __anonstruct_poll_36 {
   struct pollfd *ufds ;
   int nfds ;
    klee_make_symbolic(&nfds, sizeof(int), "nfds");
   int has_timeout ;
    klee_make_symbolic(&has_timeout, sizeof(int), "has_timeout");
   unsigned long tv_sec ;
    klee_make_symbolic(&tv_sec, sizeof(long), "tv_sec");
   unsigned long tv_nsec ;
    klee_make_symbolic(&tv_nsec, sizeof(long), "tv_nsec");
};
union __anonunion____missing_field_name_33 {
   struct __anonstruct_futex_34 futex ;
   struct __anonstruct_nanosleep_35 nanosleep ;
   struct __anonstruct_poll_36 poll ;
};
struct restart_block {
   long (*fn)(struct restart_block * ) ;
   union __anonunion____missing_field_name_33 __annonCompField18 ;
};
struct seqcount {
   unsigned int sequence ;
    klee_make_symbolic(&sequence, sizeof(int), "sequence");
   struct lockdep_map dep_map ;
};
typedef struct seqcount seqcount_t;
struct __anonstruct_seqlock_t_45 {
   struct seqcount seqcount ;
   spinlock_t lock ;
};
typedef struct __anonstruct_seqlock_t_45 seqlock_t;
struct timespec {
   __kernel_time_t tv_sec ;
   long tv_nsec ;
};
union ktime {
   s64 tv64 ;
};
typedef union ktime ktime_t;
struct timer_list {
   struct hlist_node entry ;
   unsigned long expires ;
    klee_make_symbolic(&expires, sizeof(long), "expires");
   void (*function)(unsigned long  ) ;
   unsigned long data ;
    klee_make_symbolic(&data, sizeof(long), "data");
   u32 flags ;
   int slack ;
    klee_make_symbolic(&slack, sizeof(int), "slack");
   int start_pid ;
    klee_make_symbolic(&start_pid, sizeof(int), "start_pid");
   void *start_site ;
   char start_comm[16U] ;
   struct lockdep_map lockdep_map ;
};
struct hrtimer;
enum hrtimer_restart;
struct __wait_queue_head {
   spinlock_t lock ;
   struct list_head task_list ;
};
typedef struct __wait_queue_head wait_queue_head_t;
struct completion {
   unsigned int done ;
    klee_make_symbolic(&done, sizeof(int), "done");
   wait_queue_head_t wait ;
};
struct notifier_block;
struct rb_node {
   unsigned long __rb_parent_color ;
    klee_make_symbolic(&__rb_parent_color, sizeof(long), "__rb_parent_color");
   struct rb_node *rb_right ;
   struct rb_node *rb_left ;
};
struct rb_root {
   struct rb_node *rb_node ;
};
struct ctl_table;
struct nsproxy;
struct ctl_table_root;
struct ctl_table_header;
struct ctl_dir;
typedef int proc_handler(struct ctl_table * , int  , void * , size_t * , loff_t * );
struct ctl_table_poll {
   atomic_t event ;
   wait_queue_head_t wait ;
};
struct ctl_table {
   char const   *procname ;
   void *data ;
   int maxlen ;
    klee_make_symbolic(&maxlen, sizeof(int), "maxlen");
   umode_t mode ;
   struct ctl_table *child ;
   proc_handler *proc_handler ;
   struct ctl_table_poll *poll ;
   void *extra1 ;
   void *extra2 ;
};
struct ctl_node {
   struct rb_node node ;
   struct ctl_table_header *header ;
};
struct __anonstruct____missing_field_name_47 {
   struct ctl_table *ctl_table ;
   int used ;
    klee_make_symbolic(&used, sizeof(int), "used");
   int count ;
    klee_make_symbolic(&count, sizeof(int), "count");
   int nreg ;
    klee_make_symbolic(&nreg, sizeof(int), "nreg");
};
union __anonunion____missing_field_name_46 {
   struct __anonstruct____missing_field_name_47 __annonCompField19 ;
   struct callback_head rcu ;
};
struct ctl_table_set;
struct ctl_table_header {
   union __anonunion____missing_field_name_46 __annonCompField20 ;
   struct completion *unregistering ;
   struct ctl_table *ctl_table_arg ;
   struct ctl_table_root *root ;
   struct ctl_table_set *set ;
   struct ctl_dir *parent ;
   struct ctl_node *node ;
};
struct ctl_dir {
   struct ctl_table_header header ;
   struct rb_root root ;
};
struct ctl_table_set {
   int (*is_seen)(struct ctl_table_set * ) ;
   struct ctl_dir dir ;
};
struct ctl_table_root {
   struct ctl_table_set default_set ;
   struct ctl_table_set *(*lookup)(struct ctl_table_root * , struct nsproxy * ) ;
   int (*permissions)(struct ctl_table_header * , struct ctl_table * ) ;
};
struct workqueue_struct;
struct work_struct;
struct work_struct {
   atomic_long_t data ;
   struct list_head entry ;
   void (*func)(struct work_struct * ) ;
   struct lockdep_map lockdep_map ;
};
struct delayed_work {
   struct work_struct work ;
   struct timer_list timer ;
   struct workqueue_struct *wq ;
   int cpu ;
};
struct vm_area_struct;
struct __anonstruct_nodemask_t_48 {
   unsigned long bits[16U] ;
};
typedef struct __anonstruct_nodemask_t_48 nodemask_t;
struct rw_semaphore;
struct rw_semaphore {
   long count ;
   struct list_head wait_list ;
   raw_spinlock_t wait_lock ;
   struct optimistic_spin_queue osq ;
   struct task_struct *owner ;
   struct lockdep_map dep_map ;
};
struct notifier_block {
   int (*notifier_call)(struct notifier_block * , unsigned long  , void * ) ;
   struct notifier_block *next ;
   int priority ;
    klee_make_symbolic(&priority, sizeof(int), "priority");
};
struct resource {
   resource_size_t start ;
   resource_size_t end ;
   char const   *name ;
   unsigned long flags ;
   struct resource *parent ;
   struct resource *sibling ;
   struct resource *child ;
};
struct pci_dev;
struct pm_message {
   int event ;
    klee_make_symbolic(&event, sizeof(int), "event");
};
typedef struct pm_message pm_message_t;
struct dev_pm_ops {
   int (*prepare)(struct device * ) ;
   void (*complete)(struct device * ) ;
   int (*suspend)(struct device * ) ;
   int (*resume)(struct device * ) ;
   int (*freeze)(struct device * ) ;
   int (*thaw)(struct device * ) ;
   int (*poweroff)(struct device * ) ;
   int (*restore)(struct device * ) ;
   int (*suspend_late)(struct device * ) ;
   int (*resume_early)(struct device * ) ;
   int (*freeze_late)(struct device * ) ;
   int (*thaw_early)(struct device * ) ;
   int (*poweroff_late)(struct device * ) ;
   int (*restore_early)(struct device * ) ;
   int (*suspend_noirq)(struct device * ) ;
   int (*resume_noirq)(struct device * ) ;
   int (*freeze_noirq)(struct device * ) ;
   int (*thaw_noirq)(struct device * ) ;
   int (*poweroff_noirq)(struct device * ) ;
   int (*restore_noirq)(struct device * ) ;
   int (*runtime_suspend)(struct device * ) ;
   int (*runtime_resume)(struct device * ) ;
   int (*runtime_idle)(struct device * ) ;
};
enum rpm_status {
    RPM_ACTIVE = 0,
    RPM_RESUMING = 1,
    RPM_SUSPENDED = 2,
    RPM_SUSPENDING = 3
} ;
enum rpm_request {
    RPM_REQ_NONE = 0,
    RPM_REQ_IDLE = 1,
    RPM_REQ_SUSPEND = 2,
    RPM_REQ_AUTOSUSPEND = 3,
    RPM_REQ_RESUME = 4
} ;
struct wakeup_source;
struct wake_irq;
struct pm_subsys_data {
   spinlock_t lock ;
   unsigned int refcount ;
    klee_make_symbolic(&refcount, sizeof(int), "refcount");
   struct list_head clock_list ;
};
struct dev_pm_qos;
struct dev_pm_info {
   pm_message_t power_state ;
   unsigned char can_wakeup : 1 ;
   unsigned char async_suspend : 1 ;
   bool is_prepared ;
   bool is_suspended ;
   bool is_noirq_suspended ;
   bool is_late_suspended ;
   bool ignore_children ;
   bool early_init ;
   bool direct_complete ;
   spinlock_t lock ;
   struct list_head entry ;
   struct completion completion ;
   struct wakeup_source *wakeup ;
   bool wakeup_path ;
   bool syscore ;
   struct timer_list suspend_timer ;
   unsigned long timer_expires ;
    klee_make_symbolic(&timer_expires, sizeof(long), "timer_expires");
   struct work_struct work ;
   wait_queue_head_t wait_queue ;
   struct wake_irq *wakeirq ;
   atomic_t usage_count ;
   atomic_t child_count ;
   unsigned char disable_depth : 3 ;
   unsigned char idle_notification : 1 ;
   unsigned char request_pending : 1 ;
   unsigned char deferred_resume : 1 ;
   unsigned char run_wake : 1 ;
   unsigned char runtime_auto : 1 ;
   unsigned char no_callbacks : 1 ;
   unsigned char irq_safe : 1 ;
   unsigned char use_autosuspend : 1 ;
   unsigned char timer_autosuspends : 1 ;
   unsigned char memalloc_noio : 1 ;
   enum rpm_request request ;
   enum rpm_status runtime_status ;
   int runtime_error ;
    klee_make_symbolic(&runtime_error, sizeof(int), "runtime_error");
   int autosuspend_delay ;
    klee_make_symbolic(&autosuspend_delay, sizeof(int), "autosuspend_delay");
   unsigned long last_busy ;
    klee_make_symbolic(&last_busy, sizeof(long), "last_busy");
   unsigned long active_jiffies ;
    klee_make_symbolic(&active_jiffies, sizeof(long), "active_jiffies");
   unsigned long suspended_jiffies ;
    klee_make_symbolic(&suspended_jiffies, sizeof(long), "suspended_jiffies");
   unsigned long accounting_timestamp ;
    klee_make_symbolic(&accounting_timestamp, sizeof(long), "accounting_timestamp");
   struct pm_subsys_data *subsys_data ;
   void (*set_latency_tolerance)(struct device * , s32  ) ;
   struct dev_pm_qos *qos ;
};
struct dev_pm_domain {
   struct dev_pm_ops ops ;
   void (*detach)(struct device * , bool  ) ;
   int (*activate)(struct device * ) ;
   void (*sync)(struct device * ) ;
   void (*dismiss)(struct device * ) ;
};
struct pci_bus;
struct __anonstruct_mm_context_t_113 {
   void *ldt ;
   int size ;
    klee_make_symbolic(&size, sizeof(int), "size");
   unsigned short ia32_compat ;
    klee_make_symbolic(&ia32_compat, sizeof(short), "ia32_compat");
   struct mutex lock ;
   void *vdso ;
   atomic_t perf_rdpmc_allowed ;
};
typedef struct __anonstruct_mm_context_t_113 mm_context_t;
struct bio_vec;
struct llist_node;
struct llist_node {
   struct llist_node *next ;
};
struct kmem_cache;
struct kernel_cap_struct {
   __u32 cap[2U] ;
};
typedef struct kernel_cap_struct kernel_cap_t;
struct inode;
struct dentry;
struct user_namespace;
struct plist_node {
   int prio ;
    klee_make_symbolic(&prio, sizeof(int), "prio");
   struct list_head prio_list ;
   struct list_head node_list ;
};
struct arch_uprobe_task {
   unsigned long saved_scratch_register ;
    klee_make_symbolic(&saved_scratch_register, sizeof(long), "saved_scratch_register");
   unsigned int saved_trap_nr ;
    klee_make_symbolic(&saved_trap_nr, sizeof(int), "saved_trap_nr");
   unsigned int saved_tf ;
    klee_make_symbolic(&saved_tf, sizeof(int), "saved_tf");
};
enum uprobe_task_state {
    UTASK_RUNNING = 0,
    UTASK_SSTEP = 1,
    UTASK_SSTEP_ACK = 2,
    UTASK_SSTEP_TRAPPED = 3
} ;
struct __anonstruct____missing_field_name_146 {
   struct arch_uprobe_task autask ;
   unsigned long vaddr ;
    klee_make_symbolic(&vaddr, sizeof(long), "vaddr");
};
struct __anonstruct____missing_field_name_147 {
   struct callback_head dup_xol_work ;
   unsigned long dup_xol_addr ;
    klee_make_symbolic(&dup_xol_addr, sizeof(long), "dup_xol_addr");
};
union __anonunion____missing_field_name_145 {
   struct __anonstruct____missing_field_name_146 __annonCompField33 ;
   struct __anonstruct____missing_field_name_147 __annonCompField34 ;
};
struct uprobe;
struct return_instance;
struct uprobe_task {
   enum uprobe_task_state state ;
   union __anonunion____missing_field_name_145 __annonCompField35 ;
   struct uprobe *active_uprobe ;
   unsigned long xol_vaddr ;
    klee_make_symbolic(&xol_vaddr, sizeof(long), "xol_vaddr");
   struct return_instance *return_instances ;
   unsigned int depth ;
    klee_make_symbolic(&depth, sizeof(int), "depth");
};
struct xol_area;
struct uprobes_state {
   struct xol_area *xol_area ;
};
struct address_space;
struct mem_cgroup;
typedef void compound_page_dtor(struct page * );
union __anonunion____missing_field_name_148 {
   struct address_space *mapping ;
   void *s_mem ;
};
union __anonunion____missing_field_name_150 {
   unsigned long index ;
    klee_make_symbolic(&index, sizeof(long), "index");
   void *freelist ;
   bool pfmemalloc ;
};
struct __anonstruct____missing_field_name_154 {
   unsigned short inuse ;
    klee_make_symbolic(&inuse, sizeof(short), "inuse");
   unsigned short objects : 15 ;
   unsigned char frozen : 1 ;
};
union __anonunion____missing_field_name_153 {
   atomic_t _mapcount ;
   struct __anonstruct____missing_field_name_154 __annonCompField38 ;
   int units ;
    klee_make_symbolic(&units, sizeof(int), "units");
};
struct __anonstruct____missing_field_name_152 {
   union __anonunion____missing_field_name_153 __annonCompField39 ;
   atomic_t _count ;
};
union __anonunion____missing_field_name_151 {
   unsigned long counters ;
    klee_make_symbolic(&counters, sizeof(long), "counters");
   struct __anonstruct____missing_field_name_152 __annonCompField40 ;
   unsigned int active ;
    klee_make_symbolic(&active, sizeof(int), "active");
};
struct __anonstruct____missing_field_name_149 {
   union __anonunion____missing_field_name_150 __annonCompField37 ;
   union __anonunion____missing_field_name_151 __annonCompField41 ;
};
struct __anonstruct____missing_field_name_156 {
   struct page *next ;
   int pages ;
    klee_make_symbolic(&pages, sizeof(int), "pages");
   int pobjects ;
    klee_make_symbolic(&pobjects, sizeof(int), "pobjects");
};
struct slab;
struct __anonstruct____missing_field_name_157 {
   compound_page_dtor *compound_dtor ;
   unsigned long compound_order ;
    klee_make_symbolic(&compound_order, sizeof(long), "compound_order");
};
union __anonunion____missing_field_name_155 {
   struct list_head lru ;
   struct __anonstruct____missing_field_name_156 __annonCompField43 ;
   struct slab *slab_page ;
   struct callback_head callback_head ;
   struct __anonstruct____missing_field_name_157 __annonCompField44 ;
   pgtable_t pmd_huge_pte ;
};
union __anonunion____missing_field_name_158 {
   unsigned long private ;
    klee_make_symbolic(&private, sizeof(long), "private");
   spinlock_t *ptl ;
   struct kmem_cache *slab_cache ;
   struct page *first_page ;
};
struct page {
   unsigned long flags ;
   union __anonunion____missing_field_name_148 __annonCompField36 ;
   struct __anonstruct____missing_field_name_149 __annonCompField42 ;
   union __anonunion____missing_field_name_155 __annonCompField45 ;
   union __anonunion____missing_field_name_158 __annonCompField46 ;
   struct mem_cgroup *mem_cgroup ;
};
struct page_frag {
   struct page *page ;
   __u32 offset ;
   __u32 size ;
};
struct __anonstruct_shared_159 {
   struct rb_node rb ;
   unsigned long rb_subtree_last ;
    klee_make_symbolic(&rb_subtree_last, sizeof(long), "rb_subtree_last");
};
struct anon_vma;
struct vm_operations_struct;
struct mempolicy;
struct vm_area_struct {
   unsigned long vm_start ;
    klee_make_symbolic(&vm_start, sizeof(long), "vm_start");
   unsigned long vm_end ;
    klee_make_symbolic(&vm_end, sizeof(long), "vm_end");
   struct vm_area_struct *vm_next ;
   struct vm_area_struct *vm_prev ;
   struct rb_node vm_rb ;
   unsigned long rb_subtree_gap ;
    klee_make_symbolic(&rb_subtree_gap, sizeof(long), "rb_subtree_gap");
   struct mm_struct *vm_mm ;
   pgprot_t vm_page_prot ;
   unsigned long vm_flags ;
    klee_make_symbolic(&vm_flags, sizeof(long), "vm_flags");
   struct __anonstruct_shared_159 shared ;
   struct list_head anon_vma_chain ;
   struct anon_vma *anon_vma ;
   struct vm_operations_struct  const  *vm_ops ;
   unsigned long vm_pgoff ;
    klee_make_symbolic(&vm_pgoff, sizeof(long), "vm_pgoff");
   struct file *vm_file ;
   void *vm_private_data ;
   struct mempolicy *vm_policy ;
};
struct core_thread {
   struct task_struct *task ;
   struct core_thread *next ;
};
struct core_state {
   atomic_t nr_threads ;
   struct core_thread dumper ;
   struct completion startup ;
};
struct task_rss_stat {
   int events ;
    klee_make_symbolic(&events, sizeof(int), "events");
   int count[3U] ;
};
struct mm_rss_stat {
   atomic_long_t count[3U] ;
};
struct kioctx_table;
struct linux_binfmt;
struct mmu_notifier_mm;
struct mm_struct {
   struct vm_area_struct *mmap ;
   struct rb_root mm_rb ;
   u32 vmacache_seqnum ;
   unsigned long (*get_unmapped_area)(struct file * , unsigned long  , unsigned long  ,
                                      unsigned long  , unsigned long  ) ;
   unsigned long mmap_base ;
    klee_make_symbolic(&mmap_base, sizeof(long), "mmap_base");
   unsigned long mmap_legacy_base ;
    klee_make_symbolic(&mmap_legacy_base, sizeof(long), "mmap_legacy_base");
   unsigned long task_size ;
    klee_make_symbolic(&task_size, sizeof(long), "task_size");
   unsigned long highest_vm_end ;
    klee_make_symbolic(&highest_vm_end, sizeof(long), "highest_vm_end");
   pgd_t *pgd ;
   atomic_t mm_users ;
   atomic_t mm_count ;
   atomic_long_t nr_ptes ;
   atomic_long_t nr_pmds ;
   int map_count ;
    klee_make_symbolic(&map_count, sizeof(int), "map_count");
   spinlock_t page_table_lock ;
   struct rw_semaphore mmap_sem ;
   struct list_head mmlist ;
   unsigned long hiwater_rss ;
    klee_make_symbolic(&hiwater_rss, sizeof(long), "hiwater_rss");
   unsigned long hiwater_vm ;
    klee_make_symbolic(&hiwater_vm, sizeof(long), "hiwater_vm");
   unsigned long total_vm ;
    klee_make_symbolic(&total_vm, sizeof(long), "total_vm");
   unsigned long locked_vm ;
    klee_make_symbolic(&locked_vm, sizeof(long), "locked_vm");
   unsigned long pinned_vm ;
    klee_make_symbolic(&pinned_vm, sizeof(long), "pinned_vm");
   unsigned long shared_vm ;
    klee_make_symbolic(&shared_vm, sizeof(long), "shared_vm");
   unsigned long exec_vm ;
    klee_make_symbolic(&exec_vm, sizeof(long), "exec_vm");
   unsigned long stack_vm ;
    klee_make_symbolic(&stack_vm, sizeof(long), "stack_vm");
   unsigned long def_flags ;
    klee_make_symbolic(&def_flags, sizeof(long), "def_flags");
   unsigned long start_code ;
    klee_make_symbolic(&start_code, sizeof(long), "start_code");
   unsigned long end_code ;
    klee_make_symbolic(&end_code, sizeof(long), "end_code");
   unsigned long start_data ;
    klee_make_symbolic(&start_data, sizeof(long), "start_data");
   unsigned long end_data ;
    klee_make_symbolic(&end_data, sizeof(long), "end_data");
   unsigned long start_brk ;
    klee_make_symbolic(&start_brk, sizeof(long), "start_brk");
   unsigned long brk ;
    klee_make_symbolic(&brk, sizeof(long), "brk");
   unsigned long start_stack ;
    klee_make_symbolic(&start_stack, sizeof(long), "start_stack");
   unsigned long arg_start ;
    klee_make_symbolic(&arg_start, sizeof(long), "arg_start");
   unsigned long arg_end ;
    klee_make_symbolic(&arg_end, sizeof(long), "arg_end");
   unsigned long env_start ;
    klee_make_symbolic(&env_start, sizeof(long), "env_start");
   unsigned long env_end ;
    klee_make_symbolic(&env_end, sizeof(long), "env_end");
   unsigned long saved_auxv[46U] ;
   struct mm_rss_stat rss_stat ;
   struct linux_binfmt *binfmt ;
   cpumask_var_t cpu_vm_mask_var ;
   mm_context_t context ;
   unsigned long flags ;
   struct core_state *core_state ;
   spinlock_t ioctx_lock ;
   struct kioctx_table *ioctx_table ;
   struct task_struct *owner ;
   struct file *exe_file ;
   struct mmu_notifier_mm *mmu_notifier_mm ;
   struct cpumask cpumask_allocation ;
   unsigned long numa_next_scan ;
    klee_make_symbolic(&numa_next_scan, sizeof(long), "numa_next_scan");
   unsigned long numa_scan_offset ;
    klee_make_symbolic(&numa_scan_offset, sizeof(long), "numa_scan_offset");
   int numa_scan_seq ;
    klee_make_symbolic(&numa_scan_seq, sizeof(int), "numa_scan_seq");
   bool tlb_flush_pending ;
   struct uprobes_state uprobes_state ;
   void *bd_addr ;
};
typedef unsigned long cputime_t;
    klee_make_symbolic(&cputime_t, sizeof(long), "cputime_t");
struct __anonstruct_kuid_t_161 {
   uid_t val ;
};
typedef struct __anonstruct_kuid_t_161 kuid_t;
struct __anonstruct_kgid_t_162 {
   gid_t val ;
};
typedef struct __anonstruct_kgid_t_162 kgid_t;
struct sem_undo_list;
struct sysv_sem {
   struct sem_undo_list *undo_list ;
};
struct user_struct;
struct sysv_shm {
   struct list_head shm_clist ;
};
struct __anonstruct_sigset_t_163 {
   unsigned long sig[1U] ;
};
typedef struct __anonstruct_sigset_t_163 sigset_t;
struct siginfo;
typedef void __signalfn_t(int  );
typedef __signalfn_t *__sighandler_t;
typedef void __restorefn_t(void);
typedef __restorefn_t *__sigrestore_t;
union sigval {
   int sival_int ;
    klee_make_symbolic(&sival_int, sizeof(int), "sival_int");
   void *sival_ptr ;
};
typedef union sigval sigval_t;
struct __anonstruct__kill_165 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
};
struct __anonstruct__timer_166 {
   __kernel_timer_t _tid ;
   int _overrun ;
    klee_make_symbolic(&_overrun, sizeof(int), "_overrun");
   char _pad[0U] ;
   sigval_t _sigval ;
   int _sys_private ;
    klee_make_symbolic(&_sys_private, sizeof(int), "_sys_private");
};
struct __anonstruct__rt_167 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
   sigval_t _sigval ;
};
struct __anonstruct__sigchld_168 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
   int _status ;
    klee_make_symbolic(&_status, sizeof(int), "_status");
   __kernel_clock_t _utime ;
   __kernel_clock_t _stime ;
};
struct __anonstruct__addr_bnd_170 {
   void *_lower ;
   void *_upper ;
};
struct __anonstruct__sigfault_169 {
   void *_addr ;
   short _addr_lsb ;
    klee_make_symbolic(&_addr_lsb, sizeof(short), "_addr_lsb");
   struct __anonstruct__addr_bnd_170 _addr_bnd ;
};
struct __anonstruct__sigpoll_171 {
   long _band ;
    klee_make_symbolic(&_band, sizeof(long), "_band");
   int _fd ;
    klee_make_symbolic(&_fd, sizeof(int), "_fd");
};
struct __anonstruct__sigsys_172 {
   void *_call_addr ;
   int _syscall ;
    klee_make_symbolic(&_syscall, sizeof(int), "_syscall");
   unsigned int _arch ;
    klee_make_symbolic(&_arch, sizeof(int), "_arch");
};
union __anonunion__sifields_164 {
   int _pad[28U] ;
   struct __anonstruct__kill_165 _kill ;
   struct __anonstruct__timer_166 _timer ;
   struct __anonstruct__rt_167 _rt ;
   struct __anonstruct__sigchld_168 _sigchld ;
   struct __anonstruct__sigfault_169 _sigfault ;
   struct __anonstruct__sigpoll_171 _sigpoll ;
   struct __anonstruct__sigsys_172 _sigsys ;
};
struct siginfo {
   int si_signo ;
    klee_make_symbolic(&si_signo, sizeof(int), "si_signo");
   int si_errno ;
    klee_make_symbolic(&si_errno, sizeof(int), "si_errno");
   int si_code ;
    klee_make_symbolic(&si_code, sizeof(int), "si_code");
   union __anonunion__sifields_164 _sifields ;
};
typedef struct siginfo siginfo_t;
struct sigpending {
   struct list_head list ;
   sigset_t signal ;
};
struct sigaction {
   __sighandler_t sa_handler ;
   unsigned long sa_flags ;
    klee_make_symbolic(&sa_flags, sizeof(long), "sa_flags");
   __sigrestore_t sa_restorer ;
   sigset_t sa_mask ;
};
struct k_sigaction {
   struct sigaction sa ;
};
enum pid_type {
    PIDTYPE_PID = 0,
    PIDTYPE_PGID = 1,
    PIDTYPE_SID = 2,
    PIDTYPE_MAX = 3
} ;
struct pid_namespace;
struct upid {
   int nr ;
    klee_make_symbolic(&nr, sizeof(int), "nr");
   struct pid_namespace *ns ;
   struct hlist_node pid_chain ;
};
struct pid {
   atomic_t count ;
   unsigned int level ;
    klee_make_symbolic(&level, sizeof(int), "level");
   struct hlist_head tasks[3U] ;
   struct callback_head rcu ;
   struct upid numbers[1U] ;
};
struct pid_link {
   struct hlist_node node ;
   struct pid *pid ;
};
struct percpu_counter {
   raw_spinlock_t lock ;
   s64 count ;
   struct list_head list ;
   s32 *counters ;
};
struct seccomp_filter;
struct seccomp {
   int mode ;
    klee_make_symbolic(&mode, sizeof(int), "mode");
   struct seccomp_filter *filter ;
};
struct rt_mutex_waiter;
struct rlimit {
   __kernel_ulong_t rlim_cur ;
   __kernel_ulong_t rlim_max ;
};
struct timerqueue_node {
   struct rb_node node ;
   ktime_t expires ;
};
struct timerqueue_head {
   struct rb_root head ;
   struct timerqueue_node *next ;
};
struct hrtimer_clock_base;
struct hrtimer_cpu_base;
enum hrtimer_restart {
    HRTIMER_NORESTART = 0,
    HRTIMER_RESTART = 1
} ;
struct hrtimer {
   struct timerqueue_node node ;
   ktime_t _softexpires ;
   enum hrtimer_restart (*function)(struct hrtimer * ) ;
   struct hrtimer_clock_base *base ;
   unsigned long state ;
    klee_make_symbolic(&state, sizeof(long), "state");
   int start_pid ;
   void *start_site ;
   char start_comm[16U] ;
};
struct hrtimer_clock_base {
   struct hrtimer_cpu_base *cpu_base ;
   int index ;
   clockid_t clockid ;
   struct timerqueue_head active ;
   ktime_t (*get_time)(void) ;
   ktime_t offset ;
};
struct hrtimer_cpu_base {
   raw_spinlock_t lock ;
   seqcount_t seq ;
   struct hrtimer *running ;
   unsigned int cpu ;
   unsigned int active_bases ;
    klee_make_symbolic(&active_bases, sizeof(int), "active_bases");
   unsigned int clock_was_set_seq ;
    klee_make_symbolic(&clock_was_set_seq, sizeof(int), "clock_was_set_seq");
   bool migration_enabled ;
   bool nohz_active ;
   unsigned char in_hrtirq : 1 ;
   unsigned char hres_active : 1 ;
   unsigned char hang_detected : 1 ;
   ktime_t expires_next ;
   struct hrtimer *next_timer ;
   unsigned int nr_events ;
    klee_make_symbolic(&nr_events, sizeof(int), "nr_events");
   unsigned int nr_retries ;
    klee_make_symbolic(&nr_retries, sizeof(int), "nr_retries");
   unsigned int nr_hangs ;
    klee_make_symbolic(&nr_hangs, sizeof(int), "nr_hangs");
   unsigned int max_hang_time ;
    klee_make_symbolic(&max_hang_time, sizeof(int), "max_hang_time");
   struct hrtimer_clock_base clock_base[4U] ;
};
struct task_io_accounting {
   u64 rchar ;
   u64 wchar ;
   u64 syscr ;
   u64 syscw ;
   u64 read_bytes ;
   u64 write_bytes ;
   u64 cancelled_write_bytes ;
};
struct latency_record {
   unsigned long backtrace[12U] ;
   unsigned int count ;
   unsigned long time ;
    klee_make_symbolic(&time, sizeof(long), "time");
   unsigned long max ;
    klee_make_symbolic(&max, sizeof(long), "max");
};
struct assoc_array_ptr;
struct assoc_array {
   struct assoc_array_ptr *root ;
   unsigned long nr_leaves_on_tree ;
    klee_make_symbolic(&nr_leaves_on_tree, sizeof(long), "nr_leaves_on_tree");
};
typedef int32_t key_serial_t;
typedef uint32_t key_perm_t;
struct key;
struct signal_struct;
struct cred;
struct key_type;
struct keyring_index_key {
   struct key_type *type ;
   char const   *description ;
   size_t desc_len ;
};
union __anonunion____missing_field_name_179 {
   struct list_head graveyard_link ;
   struct rb_node serial_node ;
};
struct key_user;
union __anonunion____missing_field_name_180 {
   time_t expiry ;
   time_t revoked_at ;
};
struct __anonstruct____missing_field_name_182 {
   struct key_type *type ;
   char *description ;
};
union __anonunion____missing_field_name_181 {
   struct keyring_index_key index_key ;
   struct __anonstruct____missing_field_name_182 __annonCompField49 ;
};
union __anonunion_type_data_183 {
   struct list_head link ;
   unsigned long x[2U] ;
   void *p[2U] ;
   int reject_error ;
    klee_make_symbolic(&reject_error, sizeof(int), "reject_error");
};
union __anonunion_payload_185 {
   unsigned long value ;
   void *rcudata ;
   void *data ;
   void *data2[2U] ;
};
union __anonunion____missing_field_name_184 {
   union __anonunion_payload_185 payload ;
   struct assoc_array keys ;
};
struct key {
   atomic_t usage ;
   key_serial_t serial ;
   union __anonunion____missing_field_name_179 __annonCompField47 ;
   struct rw_semaphore sem ;
   struct key_user *user ;
   void *security ;
   union __anonunion____missing_field_name_180 __annonCompField48 ;
   time_t last_used_at ;
   kuid_t uid ;
   kgid_t gid ;
   key_perm_t perm ;
   unsigned short quotalen ;
    klee_make_symbolic(&quotalen, sizeof(short), "quotalen");
   unsigned short datalen ;
    klee_make_symbolic(&datalen, sizeof(short), "datalen");
   unsigned long flags ;
   union __anonunion____missing_field_name_181 __annonCompField50 ;
   union __anonunion_type_data_183 type_data ;
   union __anonunion____missing_field_name_184 __annonCompField51 ;
};
struct audit_context;
struct group_info {
   atomic_t usage ;
   int ngroups ;
    klee_make_symbolic(&ngroups, sizeof(int), "ngroups");
   int nblocks ;
    klee_make_symbolic(&nblocks, sizeof(int), "nblocks");
   kgid_t small_block[32U] ;
   kgid_t *blocks[0U] ;
};
struct cred {
   atomic_t usage ;
   atomic_t subscribers ;
   void *put_addr ;
   unsigned int magic ;
   kuid_t uid ;
   kgid_t gid ;
   kuid_t suid ;
   kgid_t sgid ;
   kuid_t euid ;
   kgid_t egid ;
   kuid_t fsuid ;
   kgid_t fsgid ;
   unsigned int securebits ;
    klee_make_symbolic(&securebits, sizeof(int), "securebits");
   kernel_cap_t cap_inheritable ;
   kernel_cap_t cap_permitted ;
   kernel_cap_t cap_effective ;
   kernel_cap_t cap_bset ;
   unsigned char jit_keyring ;
    klee_make_symbolic(&jit_keyring, sizeof(char), "jit_keyring");
   struct key *session_keyring ;
   struct key *process_keyring ;
   struct key *thread_keyring ;
   struct key *request_key_auth ;
   void *security ;
   struct user_struct *user ;
   struct user_namespace *user_ns ;
   struct group_info *group_info ;
   struct callback_head rcu ;
};
union __anonunion____missing_field_name_186 {
   unsigned long bitmap[4U] ;
   struct callback_head callback_head ;
};
struct idr_layer {
   int prefix ;
    klee_make_symbolic(&prefix, sizeof(int), "prefix");
   int layer ;
    klee_make_symbolic(&layer, sizeof(int), "layer");
   struct idr_layer *ary[256U] ;
   int count ;
   union __anonunion____missing_field_name_186 __annonCompField52 ;
};
struct idr {
   struct idr_layer *hint ;
   struct idr_layer *top ;
   int layers ;
    klee_make_symbolic(&layers, sizeof(int), "layers");
   int cur ;
    klee_make_symbolic(&cur, sizeof(int), "cur");
   spinlock_t lock ;
   int id_free_cnt ;
    klee_make_symbolic(&id_free_cnt, sizeof(int), "id_free_cnt");
   struct idr_layer *id_free ;
};
struct ida_bitmap {
   long nr_busy ;
    klee_make_symbolic(&nr_busy, sizeof(long), "nr_busy");
   unsigned long bitmap[15U] ;
};
struct ida {
   struct idr idr ;
   struct ida_bitmap *free_bitmap ;
};
struct percpu_ref;
typedef void percpu_ref_func_t(struct percpu_ref * );
struct percpu_ref {
   atomic_long_t count ;
   unsigned long percpu_count_ptr ;
    klee_make_symbolic(&percpu_count_ptr, sizeof(long), "percpu_count_ptr");
   percpu_ref_func_t *release ;
   percpu_ref_func_t *confirm_switch ;
   bool force_atomic ;
   struct callback_head rcu ;
};
struct cgroup;
struct cgroup_root;
struct cgroup_subsys;
struct cgroup_taskset;
struct kernfs_node;
struct kernfs_ops;
struct kernfs_open_file;
struct cgroup_subsys_state {
   struct cgroup *cgroup ;
   struct cgroup_subsys *ss ;
   struct percpu_ref refcnt ;
   struct cgroup_subsys_state *parent ;
   struct list_head sibling ;
   struct list_head children ;
   int id ;
    klee_make_symbolic(&id, sizeof(int), "id");
   unsigned int flags ;
   u64 serial_nr ;
   struct callback_head callback_head ;
   struct work_struct destroy_work ;
};
struct css_set {
   atomic_t refcount ;
   struct hlist_node hlist ;
   struct list_head tasks ;
   struct list_head mg_tasks ;
   struct list_head cgrp_links ;
   struct cgroup *dfl_cgrp ;
   struct cgroup_subsys_state *subsys[12U] ;
   struct list_head mg_preload_node ;
   struct list_head mg_node ;
   struct cgroup *mg_src_cgrp ;
   struct css_set *mg_dst_cset ;
   struct list_head e_cset_node[12U] ;
   struct callback_head callback_head ;
};
struct cgroup {
   struct cgroup_subsys_state self ;
   unsigned long flags ;
   int id ;
   int populated_cnt ;
    klee_make_symbolic(&populated_cnt, sizeof(int), "populated_cnt");
   struct kernfs_node *kn ;
   struct kernfs_node *procs_kn ;
   struct kernfs_node *populated_kn ;
   unsigned int subtree_control ;
    klee_make_symbolic(&subtree_control, sizeof(int), "subtree_control");
   unsigned int child_subsys_mask ;
    klee_make_symbolic(&child_subsys_mask, sizeof(int), "child_subsys_mask");
   struct cgroup_subsys_state *subsys[12U] ;
   struct cgroup_root *root ;
   struct list_head cset_links ;
   struct list_head e_csets[12U] ;
   struct list_head pidlists ;
   struct mutex pidlist_mutex ;
   wait_queue_head_t offline_waitq ;
   struct work_struct release_agent_work ;
};
struct kernfs_root;
struct cgroup_root {
   struct kernfs_root *kf_root ;
   unsigned int subsys_mask ;
    klee_make_symbolic(&subsys_mask, sizeof(int), "subsys_mask");
   int hierarchy_id ;
    klee_make_symbolic(&hierarchy_id, sizeof(int), "hierarchy_id");
   struct cgroup cgrp ;
   atomic_t nr_cgrps ;
   struct list_head root_list ;
   unsigned int flags ;
   struct idr cgroup_idr ;
   char release_agent_path[4096U] ;
   char name[64U] ;
};
struct cftype {
   char name[64U] ;
   int private ;
   umode_t mode ;
   size_t max_write_len ;
   unsigned int flags ;
   struct cgroup_subsys *ss ;
   struct list_head node ;
   struct kernfs_ops *kf_ops ;
   u64 (*read_u64)(struct cgroup_subsys_state * , struct cftype * ) ;
   s64 (*read_s64)(struct cgroup_subsys_state * , struct cftype * ) ;
   int (*seq_show)(struct seq_file * , void * ) ;
   void *(*seq_start)(struct seq_file * , loff_t * ) ;
   void *(*seq_next)(struct seq_file * , void * , loff_t * ) ;
   void (*seq_stop)(struct seq_file * , void * ) ;
   int (*write_u64)(struct cgroup_subsys_state * , struct cftype * , u64  ) ;
   int (*write_s64)(struct cgroup_subsys_state * , struct cftype * , s64  ) ;
   ssize_t (*write)(struct kernfs_open_file * , char * , size_t  , loff_t  ) ;
   struct lock_class_key lockdep_key ;
};
struct cgroup_subsys {
   struct cgroup_subsys_state *(*css_alloc)(struct cgroup_subsys_state * ) ;
   int (*css_online)(struct cgroup_subsys_state * ) ;
   void (*css_offline)(struct cgroup_subsys_state * ) ;
   void (*css_released)(struct cgroup_subsys_state * ) ;
   void (*css_free)(struct cgroup_subsys_state * ) ;
   void (*css_reset)(struct cgroup_subsys_state * ) ;
   void (*css_e_css_changed)(struct cgroup_subsys_state * ) ;
   int (*can_attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*cancel_attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*fork)(struct task_struct * ) ;
   void (*exit)(struct cgroup_subsys_state * , struct cgroup_subsys_state * , struct task_struct * ) ;
   void (*bind)(struct cgroup_subsys_state * ) ;
   int disabled ;
    klee_make_symbolic(&disabled, sizeof(int), "disabled");
   int early_init ;
    klee_make_symbolic(&early_init, sizeof(int), "early_init");
   bool broken_hierarchy ;
   bool warned_broken_hierarchy ;
   int id ;
   char const   *name ;
   struct cgroup_root *root ;
   struct idr css_idr ;
   struct list_head cfts ;
   struct cftype *dfl_cftypes ;
   struct cftype *legacy_cftypes ;
   unsigned int depends_on ;
    klee_make_symbolic(&depends_on, sizeof(int), "depends_on");
};
struct futex_pi_state;
struct robust_list_head;
struct bio_list;
struct fs_struct;
struct perf_event_context;
struct blk_plug;
struct nameidata;
struct cfs_rq;
struct task_group;
struct sighand_struct {
   atomic_t count ;
   struct k_sigaction action[64U] ;
   spinlock_t siglock ;
   wait_queue_head_t signalfd_wqh ;
};
struct pacct_struct {
   int ac_flag ;
    klee_make_symbolic(&ac_flag, sizeof(int), "ac_flag");
   long ac_exitcode ;
    klee_make_symbolic(&ac_exitcode, sizeof(long), "ac_exitcode");
   unsigned long ac_mem ;
    klee_make_symbolic(&ac_mem, sizeof(long), "ac_mem");
   cputime_t ac_utime ;
   cputime_t ac_stime ;
   unsigned long ac_minflt ;
    klee_make_symbolic(&ac_minflt, sizeof(long), "ac_minflt");
   unsigned long ac_majflt ;
    klee_make_symbolic(&ac_majflt, sizeof(long), "ac_majflt");
};
struct cpu_itimer {
   cputime_t expires ;
   cputime_t incr ;
   u32 error ;
   u32 incr_error ;
};
struct cputime {
   cputime_t utime ;
   cputime_t stime ;
};
struct task_cputime {
   cputime_t utime ;
   cputime_t stime ;
   unsigned long long sum_exec_runtime ;
    klee_make_symbolic(&sum_exec_runtime, sizeof(long), "sum_exec_runtime");
};
struct task_cputime_atomic {
   atomic64_t utime ;
   atomic64_t stime ;
   atomic64_t sum_exec_runtime ;
};
struct thread_group_cputimer {
   struct task_cputime_atomic cputime_atomic ;
   int running ;
    klee_make_symbolic(&running, sizeof(int), "running");
};
struct autogroup;
struct tty_struct;
struct taskstats;
struct tty_audit_buf;
struct signal_struct {
   atomic_t sigcnt ;
   atomic_t live ;
   int nr_threads ;
    klee_make_symbolic(&nr_threads, sizeof(int), "nr_threads");
   struct list_head thread_head ;
   wait_queue_head_t wait_chldexit ;
   struct task_struct *curr_target ;
   struct sigpending shared_pending ;
   int group_exit_code ;
    klee_make_symbolic(&group_exit_code, sizeof(int), "group_exit_code");
   int notify_count ;
    klee_make_symbolic(&notify_count, sizeof(int), "notify_count");
   struct task_struct *group_exit_task ;
   int group_stop_count ;
    klee_make_symbolic(&group_stop_count, sizeof(int), "group_stop_count");
   unsigned int flags ;
   unsigned char is_child_subreaper : 1 ;
   unsigned char has_child_subreaper : 1 ;
   int posix_timer_id ;
    klee_make_symbolic(&posix_timer_id, sizeof(int), "posix_timer_id");
   struct list_head posix_timers ;
   struct hrtimer real_timer ;
   struct pid *leader_pid ;
   ktime_t it_real_incr ;
   struct cpu_itimer it[2U] ;
   struct thread_group_cputimer cputimer ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   struct pid *tty_old_pgrp ;
   int leader ;
    klee_make_symbolic(&leader, sizeof(int), "leader");
   struct tty_struct *tty ;
   struct autogroup *autogroup ;
   seqlock_t stats_lock ;
   cputime_t utime ;
   cputime_t stime ;
   cputime_t cutime ;
   cputime_t cstime ;
   cputime_t gtime ;
   cputime_t cgtime ;
   struct cputime prev_cputime ;
   unsigned long nvcsw ;
    klee_make_symbolic(&nvcsw, sizeof(long), "nvcsw");
   unsigned long nivcsw ;
    klee_make_symbolic(&nivcsw, sizeof(long), "nivcsw");
   unsigned long cnvcsw ;
    klee_make_symbolic(&cnvcsw, sizeof(long), "cnvcsw");
   unsigned long cnivcsw ;
    klee_make_symbolic(&cnivcsw, sizeof(long), "cnivcsw");
   unsigned long min_flt ;
    klee_make_symbolic(&min_flt, sizeof(long), "min_flt");
   unsigned long maj_flt ;
    klee_make_symbolic(&maj_flt, sizeof(long), "maj_flt");
   unsigned long cmin_flt ;
    klee_make_symbolic(&cmin_flt, sizeof(long), "cmin_flt");
   unsigned long cmaj_flt ;
    klee_make_symbolic(&cmaj_flt, sizeof(long), "cmaj_flt");
   unsigned long inblock ;
    klee_make_symbolic(&inblock, sizeof(long), "inblock");
   unsigned long oublock ;
    klee_make_symbolic(&oublock, sizeof(long), "oublock");
   unsigned long cinblock ;
    klee_make_symbolic(&cinblock, sizeof(long), "cinblock");
   unsigned long coublock ;
    klee_make_symbolic(&coublock, sizeof(long), "coublock");
   unsigned long maxrss ;
    klee_make_symbolic(&maxrss, sizeof(long), "maxrss");
   unsigned long cmaxrss ;
    klee_make_symbolic(&cmaxrss, sizeof(long), "cmaxrss");
   struct task_io_accounting ioac ;
   unsigned long long sum_sched_runtime ;
    klee_make_symbolic(&sum_sched_runtime, sizeof(long), "sum_sched_runtime");
   struct rlimit rlim[16U] ;
   struct pacct_struct pacct ;
   struct taskstats *stats ;
   unsigned int audit_tty ;
    klee_make_symbolic(&audit_tty, sizeof(int), "audit_tty");
   unsigned int audit_tty_log_passwd ;
    klee_make_symbolic(&audit_tty_log_passwd, sizeof(int), "audit_tty_log_passwd");
   struct tty_audit_buf *tty_audit_buf ;
   oom_flags_t oom_flags ;
   short oom_score_adj ;
    klee_make_symbolic(&oom_score_adj, sizeof(short), "oom_score_adj");
   short oom_score_adj_min ;
    klee_make_symbolic(&oom_score_adj_min, sizeof(short), "oom_score_adj_min");
   struct mutex cred_guard_mutex ;
};
struct user_struct {
   atomic_t __count ;
   atomic_t processes ;
   atomic_t sigpending ;
   atomic_t inotify_watches ;
   atomic_t inotify_devs ;
   atomic_t fanotify_listeners ;
   atomic_long_t epoll_watches ;
   unsigned long mq_bytes ;
    klee_make_symbolic(&mq_bytes, sizeof(long), "mq_bytes");
   unsigned long locked_shm ;
    klee_make_symbolic(&locked_shm, sizeof(long), "locked_shm");
   struct key *uid_keyring ;
   struct key *session_keyring ;
   struct hlist_node uidhash_node ;
   kuid_t uid ;
   atomic_long_t locked_vm ;
};
struct backing_dev_info;
struct reclaim_state;
struct sched_info {
   unsigned long pcount ;
    klee_make_symbolic(&pcount, sizeof(long), "pcount");
   unsigned long long run_delay ;
    klee_make_symbolic(&run_delay, sizeof(long), "run_delay");
   unsigned long long last_arrival ;
    klee_make_symbolic(&last_arrival, sizeof(long), "last_arrival");
   unsigned long long last_queued ;
    klee_make_symbolic(&last_queued, sizeof(long), "last_queued");
};
struct task_delay_info {
   spinlock_t lock ;
   unsigned int flags ;
   u64 blkio_start ;
   u64 blkio_delay ;
   u64 swapin_delay ;
   u32 blkio_count ;
   u32 swapin_count ;
   u64 freepages_start ;
   u64 freepages_delay ;
   u32 freepages_count ;
};
struct wake_q_node {
   struct wake_q_node *next ;
};
struct io_context;
struct pipe_inode_info;
struct uts_namespace;
struct load_weight {
   unsigned long weight ;
    klee_make_symbolic(&weight, sizeof(long), "weight");
   u32 inv_weight ;
};
struct sched_avg {
   u64 last_runnable_update ;
   s64 decay_count ;
   unsigned long load_avg_contrib ;
    klee_make_symbolic(&load_avg_contrib, sizeof(long), "load_avg_contrib");
   unsigned long utilization_avg_contrib ;
    klee_make_symbolic(&utilization_avg_contrib, sizeof(long), "utilization_avg_contrib");
   u32 runnable_avg_sum ;
   u32 avg_period ;
   u32 running_avg_sum ;
};
struct sched_statistics {
   u64 wait_start ;
   u64 wait_max ;
   u64 wait_count ;
   u64 wait_sum ;
   u64 iowait_count ;
   u64 iowait_sum ;
   u64 sleep_start ;
   u64 sleep_max ;
   s64 sum_sleep_runtime ;
   u64 block_start ;
   u64 block_max ;
   u64 exec_max ;
   u64 slice_max ;
   u64 nr_migrations_cold ;
   u64 nr_failed_migrations_affine ;
   u64 nr_failed_migrations_running ;
   u64 nr_failed_migrations_hot ;
   u64 nr_forced_migrations ;
   u64 nr_wakeups ;
   u64 nr_wakeups_sync ;
   u64 nr_wakeups_migrate ;
   u64 nr_wakeups_local ;
   u64 nr_wakeups_remote ;
   u64 nr_wakeups_affine ;
   u64 nr_wakeups_affine_attempts ;
   u64 nr_wakeups_passive ;
   u64 nr_wakeups_idle ;
};
struct sched_entity {
   struct load_weight load ;
   struct rb_node run_node ;
   struct list_head group_node ;
   unsigned int on_rq ;
    klee_make_symbolic(&on_rq, sizeof(int), "on_rq");
   u64 exec_start ;
   u64 sum_exec_runtime ;
   u64 vruntime ;
   u64 prev_sum_exec_runtime ;
   u64 nr_migrations ;
   struct sched_statistics statistics ;
   int depth ;
   struct sched_entity *parent ;
   struct cfs_rq *cfs_rq ;
   struct cfs_rq *my_q ;
   struct sched_avg avg ;
};
struct rt_rq;
struct sched_rt_entity {
   struct list_head run_list ;
   unsigned long timeout ;
    klee_make_symbolic(&timeout, sizeof(long), "timeout");
   unsigned long watchdog_stamp ;
    klee_make_symbolic(&watchdog_stamp, sizeof(long), "watchdog_stamp");
   unsigned int time_slice ;
    klee_make_symbolic(&time_slice, sizeof(int), "time_slice");
   struct sched_rt_entity *back ;
   struct sched_rt_entity *parent ;
   struct rt_rq *rt_rq ;
   struct rt_rq *my_q ;
};
struct sched_dl_entity {
   struct rb_node rb_node ;
   u64 dl_runtime ;
   u64 dl_deadline ;
   u64 dl_period ;
   u64 dl_bw ;
   s64 runtime ;
   u64 deadline ;
   unsigned int flags ;
   int dl_throttled ;
    klee_make_symbolic(&dl_throttled, sizeof(int), "dl_throttled");
   int dl_new ;
    klee_make_symbolic(&dl_new, sizeof(int), "dl_new");
   int dl_boosted ;
    klee_make_symbolic(&dl_boosted, sizeof(int), "dl_boosted");
   int dl_yielded ;
    klee_make_symbolic(&dl_yielded, sizeof(int), "dl_yielded");
   struct hrtimer dl_timer ;
};
struct memcg_oom_info {
   struct mem_cgroup *memcg ;
   gfp_t gfp_mask ;
   int order ;
    klee_make_symbolic(&order, sizeof(int), "order");
   unsigned char may_oom : 1 ;
};
struct sched_class;
struct files_struct;
struct compat_robust_list_head;
struct numa_group;
struct task_struct {
   long volatile   state ;
   void *stack ;
   atomic_t usage ;
   unsigned int flags ;
   unsigned int ptrace ;
    klee_make_symbolic(&ptrace, sizeof(int), "ptrace");
   struct llist_node wake_entry ;
   int on_cpu ;
    klee_make_symbolic(&on_cpu, sizeof(int), "on_cpu");
   struct task_struct *last_wakee ;
   unsigned long wakee_flips ;
    klee_make_symbolic(&wakee_flips, sizeof(long), "wakee_flips");
   unsigned long wakee_flip_decay_ts ;
    klee_make_symbolic(&wakee_flip_decay_ts, sizeof(long), "wakee_flip_decay_ts");
   int wake_cpu ;
    klee_make_symbolic(&wake_cpu, sizeof(int), "wake_cpu");
   int on_rq ;
   int prio ;
   int static_prio ;
    klee_make_symbolic(&static_prio, sizeof(int), "static_prio");
   int normal_prio ;
    klee_make_symbolic(&normal_prio, sizeof(int), "normal_prio");
   unsigned int rt_priority ;
    klee_make_symbolic(&rt_priority, sizeof(int), "rt_priority");
   struct sched_class  const  *sched_class ;
   struct sched_entity se ;
   struct sched_rt_entity rt ;
   struct task_group *sched_task_group ;
   struct sched_dl_entity dl ;
   struct hlist_head preempt_notifiers ;
   unsigned int policy ;
    klee_make_symbolic(&policy, sizeof(int), "policy");
   int nr_cpus_allowed ;
    klee_make_symbolic(&nr_cpus_allowed, sizeof(int), "nr_cpus_allowed");
   cpumask_t cpus_allowed ;
   unsigned long rcu_tasks_nvcsw ;
    klee_make_symbolic(&rcu_tasks_nvcsw, sizeof(long), "rcu_tasks_nvcsw");
   bool rcu_tasks_holdout ;
   struct list_head rcu_tasks_holdout_list ;
   int rcu_tasks_idle_cpu ;
    klee_make_symbolic(&rcu_tasks_idle_cpu, sizeof(int), "rcu_tasks_idle_cpu");
   struct sched_info sched_info ;
   struct list_head tasks ;
   struct plist_node pushable_tasks ;
   struct rb_node pushable_dl_tasks ;
   struct mm_struct *mm ;
   struct mm_struct *active_mm ;
   u32 vmacache_seqnum ;
   struct vm_area_struct *vmacache[4U] ;
   struct task_rss_stat rss_stat ;
   int exit_state ;
    klee_make_symbolic(&exit_state, sizeof(int), "exit_state");
   int exit_code ;
    klee_make_symbolic(&exit_code, sizeof(int), "exit_code");
   int exit_signal ;
    klee_make_symbolic(&exit_signal, sizeof(int), "exit_signal");
   int pdeath_signal ;
    klee_make_symbolic(&pdeath_signal, sizeof(int), "pdeath_signal");
   unsigned long jobctl ;
    klee_make_symbolic(&jobctl, sizeof(long), "jobctl");
   unsigned int personality ;
    klee_make_symbolic(&personality, sizeof(int), "personality");
   unsigned char in_execve : 1 ;
   unsigned char in_iowait : 1 ;
   unsigned char sched_reset_on_fork : 1 ;
   unsigned char sched_contributes_to_load : 1 ;
   unsigned char sched_migrated : 1 ;
   unsigned char memcg_kmem_skip_account : 1 ;
   unsigned char brk_randomized : 1 ;
   unsigned long atomic_flags ;
    klee_make_symbolic(&atomic_flags, sizeof(long), "atomic_flags");
   struct restart_block restart_block ;
   pid_t pid ;
   pid_t tgid ;
   struct task_struct *real_parent ;
   struct task_struct *parent ;
   struct list_head children ;
   struct list_head sibling ;
   struct task_struct *group_leader ;
   struct list_head ptraced ;
   struct list_head ptrace_entry ;
   struct pid_link pids[3U] ;
   struct list_head thread_group ;
   struct list_head thread_node ;
   struct completion *vfork_done ;
   int *set_child_tid ;
   int *clear_child_tid ;
   cputime_t utime ;
   cputime_t stime ;
   cputime_t utimescaled ;
   cputime_t stimescaled ;
   cputime_t gtime ;
   struct cputime prev_cputime ;
   unsigned long nvcsw ;
   unsigned long nivcsw ;
   u64 start_time ;
   u64 real_start_time ;
   unsigned long min_flt ;
   unsigned long maj_flt ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   struct cred  const  *real_cred ;
   struct cred  const  *cred ;
   char comm[16U] ;
   struct nameidata *nameidata ;
   struct sysv_sem sysvsem ;
   struct sysv_shm sysvshm ;
   unsigned long last_switch_count ;
    klee_make_symbolic(&last_switch_count, sizeof(long), "last_switch_count");
   struct thread_struct thread ;
   struct fs_struct *fs ;
   struct files_struct *files ;
   struct nsproxy *nsproxy ;
   struct signal_struct *signal ;
   struct sighand_struct *sighand ;
   sigset_t blocked ;
   sigset_t real_blocked ;
   sigset_t saved_sigmask ;
   struct sigpending pending ;
   unsigned long sas_ss_sp ;
    klee_make_symbolic(&sas_ss_sp, sizeof(long), "sas_ss_sp");
   size_t sas_ss_size ;
   int (*notifier)(void * ) ;
   void *notifier_data ;
   sigset_t *notifier_mask ;
   struct callback_head *task_works ;
   struct audit_context *audit_context ;
   kuid_t loginuid ;
   unsigned int sessionid ;
    klee_make_symbolic(&sessionid, sizeof(int), "sessionid");
   struct seccomp seccomp ;
   u32 parent_exec_id ;
   u32 self_exec_id ;
   spinlock_t alloc_lock ;
   raw_spinlock_t pi_lock ;
   struct wake_q_node wake_q ;
   struct rb_root pi_waiters ;
   struct rb_node *pi_waiters_leftmost ;
   struct rt_mutex_waiter *pi_blocked_on ;
   struct mutex_waiter *blocked_on ;
   unsigned int irq_events ;
    klee_make_symbolic(&irq_events, sizeof(int), "irq_events");
   unsigned long hardirq_enable_ip ;
    klee_make_symbolic(&hardirq_enable_ip, sizeof(long), "hardirq_enable_ip");
   unsigned long hardirq_disable_ip ;
    klee_make_symbolic(&hardirq_disable_ip, sizeof(long), "hardirq_disable_ip");
   unsigned int hardirq_enable_event ;
    klee_make_symbolic(&hardirq_enable_event, sizeof(int), "hardirq_enable_event");
   unsigned int hardirq_disable_event ;
    klee_make_symbolic(&hardirq_disable_event, sizeof(int), "hardirq_disable_event");
   int hardirqs_enabled ;
    klee_make_symbolic(&hardirqs_enabled, sizeof(int), "hardirqs_enabled");
   int hardirq_context ;
    klee_make_symbolic(&hardirq_context, sizeof(int), "hardirq_context");
   unsigned long softirq_disable_ip ;
    klee_make_symbolic(&softirq_disable_ip, sizeof(long), "softirq_disable_ip");
   unsigned long softirq_enable_ip ;
    klee_make_symbolic(&softirq_enable_ip, sizeof(long), "softirq_enable_ip");
   unsigned int softirq_disable_event ;
    klee_make_symbolic(&softirq_disable_event, sizeof(int), "softirq_disable_event");
   unsigned int softirq_enable_event ;
    klee_make_symbolic(&softirq_enable_event, sizeof(int), "softirq_enable_event");
   int softirqs_enabled ;
    klee_make_symbolic(&softirqs_enabled, sizeof(int), "softirqs_enabled");
   int softirq_context ;
    klee_make_symbolic(&softirq_context, sizeof(int), "softirq_context");
   u64 curr_chain_key ;
   int lockdep_depth ;
    klee_make_symbolic(&lockdep_depth, sizeof(int), "lockdep_depth");
   unsigned int lockdep_recursion ;
    klee_make_symbolic(&lockdep_recursion, sizeof(int), "lockdep_recursion");
   struct held_lock held_locks[48U] ;
   gfp_t lockdep_reclaim_gfp ;
   void *journal_info ;
   struct bio_list *bio_list ;
   struct blk_plug *plug ;
   struct reclaim_state *reclaim_state ;
   struct backing_dev_info *backing_dev_info ;
   struct io_context *io_context ;
   unsigned long ptrace_message ;
    klee_make_symbolic(&ptrace_message, sizeof(long), "ptrace_message");
   siginfo_t *last_siginfo ;
   struct task_io_accounting ioac ;
   u64 acct_rss_mem1 ;
   u64 acct_vm_mem1 ;
   cputime_t acct_timexpd ;
   nodemask_t mems_allowed ;
   seqcount_t mems_allowed_seq ;
   int cpuset_mem_spread_rotor ;
    klee_make_symbolic(&cpuset_mem_spread_rotor, sizeof(int), "cpuset_mem_spread_rotor");
   int cpuset_slab_spread_rotor ;
    klee_make_symbolic(&cpuset_slab_spread_rotor, sizeof(int), "cpuset_slab_spread_rotor");
   struct css_set *cgroups ;
   struct list_head cg_list ;
   struct robust_list_head *robust_list ;
   struct compat_robust_list_head *compat_robust_list ;
   struct list_head pi_state_list ;
   struct futex_pi_state *pi_state_cache ;
   struct perf_event_context *perf_event_ctxp[2U] ;
   struct mutex perf_event_mutex ;
   struct list_head perf_event_list ;
   struct mempolicy *mempolicy ;
   short il_next ;
    klee_make_symbolic(&il_next, sizeof(short), "il_next");
   short pref_node_fork ;
    klee_make_symbolic(&pref_node_fork, sizeof(short), "pref_node_fork");
   int numa_scan_seq ;
   unsigned int numa_scan_period ;
    klee_make_symbolic(&numa_scan_period, sizeof(int), "numa_scan_period");
   unsigned int numa_scan_period_max ;
    klee_make_symbolic(&numa_scan_period_max, sizeof(int), "numa_scan_period_max");
   int numa_preferred_nid ;
    klee_make_symbolic(&numa_preferred_nid, sizeof(int), "numa_preferred_nid");
   unsigned long numa_migrate_retry ;
    klee_make_symbolic(&numa_migrate_retry, sizeof(long), "numa_migrate_retry");
   u64 node_stamp ;
   u64 last_task_numa_placement ;
   u64 last_sum_exec_runtime ;
   struct callback_head numa_work ;
   struct list_head numa_entry ;
   struct numa_group *numa_group ;
   unsigned long *numa_faults ;
   unsigned long total_numa_faults ;
    klee_make_symbolic(&total_numa_faults, sizeof(long), "total_numa_faults");
   unsigned long numa_faults_locality[3U] ;
   unsigned long numa_pages_migrated ;
    klee_make_symbolic(&numa_pages_migrated, sizeof(long), "numa_pages_migrated");
   struct callback_head rcu ;
   struct pipe_inode_info *splice_pipe ;
   struct page_frag task_frag ;
   struct task_delay_info *delays ;
   int make_it_fail ;
    klee_make_symbolic(&make_it_fail, sizeof(int), "make_it_fail");
   int nr_dirtied ;
    klee_make_symbolic(&nr_dirtied, sizeof(int), "nr_dirtied");
   int nr_dirtied_pause ;
    klee_make_symbolic(&nr_dirtied_pause, sizeof(int), "nr_dirtied_pause");
   unsigned long dirty_paused_when ;
    klee_make_symbolic(&dirty_paused_when, sizeof(long), "dirty_paused_when");
   int latency_record_count ;
    klee_make_symbolic(&latency_record_count, sizeof(int), "latency_record_count");
   struct latency_record latency_record[32U] ;
   unsigned long timer_slack_ns ;
    klee_make_symbolic(&timer_slack_ns, sizeof(long), "timer_slack_ns");
   unsigned long default_timer_slack_ns ;
    klee_make_symbolic(&default_timer_slack_ns, sizeof(long), "default_timer_slack_ns");
   unsigned int kasan_depth ;
    klee_make_symbolic(&kasan_depth, sizeof(int), "kasan_depth");
   unsigned long trace ;
    klee_make_symbolic(&trace, sizeof(long), "trace");
   unsigned long trace_recursion ;
    klee_make_symbolic(&trace_recursion, sizeof(long), "trace_recursion");
   struct memcg_oom_info memcg_oom ;
   struct uprobe_task *utask ;
   unsigned int sequential_io ;
    klee_make_symbolic(&sequential_io, sizeof(int), "sequential_io");
   unsigned int sequential_io_avg ;
    klee_make_symbolic(&sequential_io_avg, sizeof(int), "sequential_io_avg");
   unsigned long task_state_change ;
    klee_make_symbolic(&task_state_change, sizeof(long), "task_state_change");
   int pagefault_disabled ;
    klee_make_symbolic(&pagefault_disabled, sizeof(int), "pagefault_disabled");
};
struct efx_tx_queue;
struct efx_filter_spec;
struct efx_channel;
struct ethtool_cmd;
struct ethtool_coalesce;
struct efx_nic;
struct mtd_info;
struct efx_rx_queue;
struct ethtool_pauseparam;
struct ethtool_wolinfo;
struct ptp_clock_info;
struct ethtool_rxnfc;
struct device_attribute;
struct ethtool_ringparam;
struct kstat {
   u64 ino ;
   dev_t dev ;
   umode_t mode ;
   unsigned int nlink ;
    klee_make_symbolic(&nlink, sizeof(int), "nlink");
   kuid_t uid ;
   kgid_t gid ;
   dev_t rdev ;
   loff_t size ;
   struct timespec atime ;
   struct timespec mtime ;
   struct timespec ctime ;
   unsigned long blksize ;
    klee_make_symbolic(&blksize, sizeof(long), "blksize");
   unsigned long long blocks ;
    klee_make_symbolic(&blocks, sizeof(long), "blocks");
};
typedef __u64 Elf64_Addr;
typedef __u16 Elf64_Half;
typedef __u32 Elf64_Word;
typedef __u64 Elf64_Xword;
struct elf64_sym {
   Elf64_Word st_name ;
   unsigned char st_info ;
    klee_make_symbolic(&st_info, sizeof(char), "st_info");
   unsigned char st_other ;
    klee_make_symbolic(&st_other, sizeof(char), "st_other");
   Elf64_Half st_shndx ;
   Elf64_Addr st_value ;
   Elf64_Xword st_size ;
};
typedef struct elf64_sym Elf64_Sym;
struct iattr;
struct super_block;
struct file_system_type;
struct kernfs_open_node;
struct kernfs_iattrs;
struct kernfs_elem_dir {
   unsigned long subdirs ;
    klee_make_symbolic(&subdirs, sizeof(long), "subdirs");
   struct rb_root children ;
   struct kernfs_root *root ;
};
struct kernfs_elem_symlink {
   struct kernfs_node *target_kn ;
};
struct kernfs_elem_attr {
   struct kernfs_ops  const  *ops ;
   struct kernfs_open_node *open ;
   loff_t size ;
   struct kernfs_node *notify_next ;
};
union __anonunion____missing_field_name_209 {
   struct kernfs_elem_dir dir ;
   struct kernfs_elem_symlink symlink ;
   struct kernfs_elem_attr attr ;
};
struct kernfs_node {
   atomic_t count ;
   atomic_t active ;
   struct lockdep_map dep_map ;
   struct kernfs_node *parent ;
   char const   *name ;
   struct rb_node rb ;
   void const   *ns ;
   unsigned int hash ;
    klee_make_symbolic(&hash, sizeof(int), "hash");
   union __anonunion____missing_field_name_209 __annonCompField56 ;
   void *priv ;
   unsigned short flags ;
   umode_t mode ;
   unsigned int ino ;
    klee_make_symbolic(&ino, sizeof(int), "ino");
   struct kernfs_iattrs *iattr ;
};
struct kernfs_syscall_ops {
   int (*remount_fs)(struct kernfs_root * , int * , char * ) ;
   int (*show_options)(struct seq_file * , struct kernfs_root * ) ;
   int (*mkdir)(struct kernfs_node * , char const   * , umode_t  ) ;
   int (*rmdir)(struct kernfs_node * ) ;
   int (*rename)(struct kernfs_node * , struct kernfs_node * , char const   * ) ;
};
struct kernfs_root {
   struct kernfs_node *kn ;
   unsigned int flags ;
   struct ida ino_ida ;
   struct kernfs_syscall_ops *syscall_ops ;
   struct list_head supers ;
   wait_queue_head_t deactivate_waitq ;
};
struct kernfs_open_file {
   struct kernfs_node *kn ;
   struct file *file ;
   void *priv ;
   struct mutex mutex ;
   int event ;
   struct list_head list ;
   char *prealloc_buf ;
   size_t atomic_write_len ;
   bool mmapped ;
   struct vm_operations_struct  const  *vm_ops ;
};
struct kernfs_ops {
   int (*seq_show)(struct seq_file * , void * ) ;
   void *(*seq_start)(struct seq_file * , loff_t * ) ;
   void *(*seq_next)(struct seq_file * , void * , loff_t * ) ;
   void (*seq_stop)(struct seq_file * , void * ) ;
   ssize_t (*read)(struct kernfs_open_file * , char * , size_t  , loff_t  ) ;
   size_t atomic_write_len ;
   bool prealloc ;
   ssize_t (*write)(struct kernfs_open_file * , char * , size_t  , loff_t  ) ;
   int (*mmap)(struct kernfs_open_file * , struct vm_area_struct * ) ;
   struct lock_class_key lockdep_key ;
};
struct sock;
struct kobject;
enum kobj_ns_type {
    KOBJ_NS_TYPE_NONE = 0,
    KOBJ_NS_TYPE_NET = 1,
    KOBJ_NS_TYPES = 2
} ;
struct kobj_ns_type_operations {
   enum kobj_ns_type type ;
   bool (*current_may_mount)(void) ;
   void *(*grab_current_ns)(void) ;
   void const   *(*netlink_ns)(struct sock * ) ;
   void const   *(*initial_ns)(void) ;
   void (*drop_ns)(void * ) ;
};
struct bin_attribute;
struct attribute {
   char const   *name ;
   umode_t mode ;
   bool ignore_lockdep ;
   struct lock_class_key *key ;
   struct lock_class_key skey ;
};
struct attribute_group {
   char const   *name ;
   umode_t (*is_visible)(struct kobject * , struct attribute * , int  ) ;
   struct attribute **attrs ;
   struct bin_attribute **bin_attrs ;
};
struct bin_attribute {
   struct attribute attr ;
   size_t size ;
   void *private ;
   ssize_t (*read)(struct file * , struct kobject * , struct bin_attribute * , char * ,
                   loff_t  , size_t  ) ;
   ssize_t (*write)(struct file * , struct kobject * , struct bin_attribute * , char * ,
                    loff_t  , size_t  ) ;
   int (*mmap)(struct file * , struct kobject * , struct bin_attribute * , struct vm_area_struct * ) ;
};
struct sysfs_ops {
   ssize_t (*show)(struct kobject * , struct attribute * , char * ) ;
   ssize_t (*store)(struct kobject * , struct attribute * , char const   * , size_t  ) ;
};
struct kref {
   atomic_t refcount ;
};
struct kset;
struct kobj_type;
struct kobject {
   char const   *name ;
   struct list_head entry ;
   struct kobject *parent ;
   struct kset *kset ;
   struct kobj_type *ktype ;
   struct kernfs_node *sd ;
   struct kref kref ;
   struct delayed_work release ;
   unsigned char state_initialized : 1 ;
   unsigned char state_in_sysfs : 1 ;
   unsigned char state_add_uevent_sent : 1 ;
   unsigned char state_remove_uevent_sent : 1 ;
   unsigned char uevent_suppress : 1 ;
};
struct kobj_type {
   void (*release)(struct kobject * ) ;
   struct sysfs_ops  const  *sysfs_ops ;
   struct attribute **default_attrs ;
   struct kobj_ns_type_operations  const  *(*child_ns_type)(struct kobject * ) ;
   void const   *(*namespace)(struct kobject * ) ;
};
struct kobj_uevent_env {
   char *argv[3U] ;
   char *envp[32U] ;
   int envp_idx ;
    klee_make_symbolic(&envp_idx, sizeof(int), "envp_idx");
   char buf[2048U] ;
   int buflen ;
    klee_make_symbolic(&buflen, sizeof(int), "buflen");
};
struct kset_uevent_ops {
   int (* const  filter)(struct kset * , struct kobject * ) ;
   char const   *(* const  name)(struct kset * , struct kobject * ) ;
   int (* const  uevent)(struct kset * , struct kobject * , struct kobj_uevent_env * ) ;
};
struct kset {
   struct list_head list ;
   spinlock_t list_lock ;
   struct kobject kobj ;
   struct kset_uevent_ops  const  *uevent_ops ;
};
struct kernel_param;
struct kernel_param_ops {
   unsigned int flags ;
   int (*set)(char const   * , struct kernel_param  const  * ) ;
   int (*get)(char * , struct kernel_param  const  * ) ;
   void (*free)(void * ) ;
};
struct kparam_string;
struct kparam_array;
union __anonunion____missing_field_name_210 {
   void *arg ;
   struct kparam_string  const  *str ;
   struct kparam_array  const  *arr ;
};
struct kernel_param {
   char const   *name ;
   struct module *mod ;
   struct kernel_param_ops  const  *ops ;
   u16 const   perm ;
   s8 level ;
   u8 flags ;
   union __anonunion____missing_field_name_210 __annonCompField57 ;
};
struct kparam_string {
   unsigned int maxlen ;
   char *string ;
};
struct kparam_array {
   unsigned int max ;
   unsigned int elemsize ;
    klee_make_symbolic(&elemsize, sizeof(int), "elemsize");
   unsigned int *num ;
   struct kernel_param_ops  const  *ops ;
   void *elem ;
};
struct latch_tree_node {
   struct rb_node node[2U] ;
};
struct mod_arch_specific {

};
struct module_param_attrs;
struct module_kobject {
   struct kobject kobj ;
   struct module *mod ;
   struct kobject *drivers_dir ;
   struct module_param_attrs *mp ;
   struct completion *kobj_completion ;
};
struct module_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct module_attribute * , struct module_kobject * , char * ) ;
   ssize_t (*store)(struct module_attribute * , struct module_kobject * , char const   * ,
                    size_t  ) ;
   void (*setup)(struct module * , char const   * ) ;
   int (*test)(struct module * ) ;
   void (*free)(struct module * ) ;
};
struct exception_table_entry;
enum module_state {
    MODULE_STATE_LIVE = 0,
    MODULE_STATE_COMING = 1,
    MODULE_STATE_GOING = 2,
    MODULE_STATE_UNFORMED = 3
} ;
struct mod_tree_node {
   struct module *mod ;
   struct latch_tree_node node ;
};
struct module_sect_attrs;
struct module_notes_attrs;
struct tracepoint;
struct trace_event_call;
struct trace_enum_map;
struct module {
   enum module_state state ;
   struct list_head list ;
   char name[56U] ;
   struct module_kobject mkobj ;
   struct module_attribute *modinfo_attrs ;
   char const   *version ;
   char const   *srcversion ;
   struct kobject *holders_dir ;
   struct kernel_symbol  const  *syms ;
   unsigned long const   *crcs ;
   unsigned int num_syms ;
    klee_make_symbolic(&num_syms, sizeof(int), "num_syms");
   struct mutex param_lock ;
   struct kernel_param *kp ;
   unsigned int num_kp ;
    klee_make_symbolic(&num_kp, sizeof(int), "num_kp");
   unsigned int num_gpl_syms ;
    klee_make_symbolic(&num_gpl_syms, sizeof(int), "num_gpl_syms");
   struct kernel_symbol  const  *gpl_syms ;
   unsigned long const   *gpl_crcs ;
   struct kernel_symbol  const  *unused_syms ;
   unsigned long const   *unused_crcs ;
   unsigned int num_unused_syms ;
    klee_make_symbolic(&num_unused_syms, sizeof(int), "num_unused_syms");
   unsigned int num_unused_gpl_syms ;
    klee_make_symbolic(&num_unused_gpl_syms, sizeof(int), "num_unused_gpl_syms");
   struct kernel_symbol  const  *unused_gpl_syms ;
   unsigned long const   *unused_gpl_crcs ;
   bool sig_ok ;
   bool async_probe_requested ;
   struct kernel_symbol  const  *gpl_future_syms ;
   unsigned long const   *gpl_future_crcs ;
   unsigned int num_gpl_future_syms ;
    klee_make_symbolic(&num_gpl_future_syms, sizeof(int), "num_gpl_future_syms");
   unsigned int num_exentries ;
    klee_make_symbolic(&num_exentries, sizeof(int), "num_exentries");
   struct exception_table_entry *extable ;
   int (*init)(void) ;
   void *module_init ;
   void *module_core ;
   unsigned int init_size ;
    klee_make_symbolic(&init_size, sizeof(int), "init_size");
   unsigned int core_size ;
    klee_make_symbolic(&core_size, sizeof(int), "core_size");
   unsigned int init_text_size ;
    klee_make_symbolic(&init_text_size, sizeof(int), "init_text_size");
   unsigned int core_text_size ;
    klee_make_symbolic(&core_text_size, sizeof(int), "core_text_size");
   struct mod_tree_node mtn_core ;
   struct mod_tree_node mtn_init ;
   unsigned int init_ro_size ;
    klee_make_symbolic(&init_ro_size, sizeof(int), "init_ro_size");
   unsigned int core_ro_size ;
    klee_make_symbolic(&core_ro_size, sizeof(int), "core_ro_size");
   struct mod_arch_specific arch ;
   unsigned int taints ;
    klee_make_symbolic(&taints, sizeof(int), "taints");
   unsigned int num_bugs ;
    klee_make_symbolic(&num_bugs, sizeof(int), "num_bugs");
   struct list_head bug_list ;
   struct bug_entry *bug_table ;
   Elf64_Sym *symtab ;
   Elf64_Sym *core_symtab ;
   unsigned int num_symtab ;
    klee_make_symbolic(&num_symtab, sizeof(int), "num_symtab");
   unsigned int core_num_syms ;
    klee_make_symbolic(&core_num_syms, sizeof(int), "core_num_syms");
   char *strtab ;
   char *core_strtab ;
   struct module_sect_attrs *sect_attrs ;
   struct module_notes_attrs *notes_attrs ;
   char *args ;
   void *percpu ;
   unsigned int percpu_size ;
    klee_make_symbolic(&percpu_size, sizeof(int), "percpu_size");
   unsigned int num_tracepoints ;
    klee_make_symbolic(&num_tracepoints, sizeof(int), "num_tracepoints");
   struct tracepoint * const  *tracepoints_ptrs ;
   unsigned int num_trace_bprintk_fmt ;
    klee_make_symbolic(&num_trace_bprintk_fmt, sizeof(int), "num_trace_bprintk_fmt");
   char const   **trace_bprintk_fmt_start ;
   struct trace_event_call **trace_events ;
   unsigned int num_trace_events ;
    klee_make_symbolic(&num_trace_events, sizeof(int), "num_trace_events");
   struct trace_enum_map **trace_enums ;
   unsigned int num_trace_enums ;
    klee_make_symbolic(&num_trace_enums, sizeof(int), "num_trace_enums");
   bool klp_alive ;
   struct list_head source_list ;
   struct list_head target_list ;
   void (*exit)(void) ;
   atomic_t refcnt ;
   ctor_fn_t (**ctors)(void) ;
   unsigned int num_ctors ;
    klee_make_symbolic(&num_ctors, sizeof(int), "num_ctors");
};
typedef unsigned long kernel_ulong_t;
    klee_make_symbolic(&kernel_ulong_t, sizeof(long), "kernel_ulong_t");
struct pci_device_id {
   __u32 vendor ;
   __u32 device ;
   __u32 subvendor ;
   __u32 subdevice ;
   __u32 class ;
   __u32 class_mask ;
   kernel_ulong_t driver_data ;
};
struct acpi_device_id {
   __u8 id[9U] ;
   kernel_ulong_t driver_data ;
};
struct of_device_id {
   char name[32U] ;
   char type[32U] ;
   char compatible[128U] ;
   void const   *data ;
};
struct klist_node;
struct klist_node {
   void *n_klist ;
   struct list_head n_node ;
   struct kref n_ref ;
};
struct path;
struct seq_file {
   char *buf ;
   size_t size ;
   size_t from ;
   size_t count ;
   size_t pad_until ;
   loff_t index ;
   loff_t read_pos ;
   u64 version ;
   struct mutex lock ;
   struct seq_operations  const  *op ;
   int poll_event ;
    klee_make_symbolic(&poll_event, sizeof(int), "poll_event");
   struct user_namespace *user_ns ;
   void *private ;
};
struct seq_operations {
   void *(*start)(struct seq_file * , loff_t * ) ;
   void (*stop)(struct seq_file * , void * ) ;
   void *(*next)(struct seq_file * , void * , loff_t * ) ;
   int (*show)(struct seq_file * , void * ) ;
};
struct pinctrl;
struct pinctrl_state;
struct dev_pin_info {
   struct pinctrl *p ;
   struct pinctrl_state *default_state ;
   struct pinctrl_state *sleep_state ;
   struct pinctrl_state *idle_state ;
};
struct dma_map_ops;
struct dev_archdata {
   struct dma_map_ops *dma_ops ;
   void *iommu ;
};
struct device_private;
struct device_driver;
struct driver_private;
struct class;
struct subsys_private;
struct bus_type;
struct device_node;
struct fwnode_handle;
struct iommu_ops;
struct iommu_group;
struct bus_type {
   char const   *name ;
   char const   *dev_name ;
   struct device *dev_root ;
   struct device_attribute *dev_attrs ;
   struct attribute_group  const  **bus_groups ;
   struct attribute_group  const  **dev_groups ;
   struct attribute_group  const  **drv_groups ;
   int (*match)(struct device * , struct device_driver * ) ;
   int (*uevent)(struct device * , struct kobj_uevent_env * ) ;
   int (*probe)(struct device * ) ;
   int (*remove)(struct device * ) ;
   void (*shutdown)(struct device * ) ;
   int (*online)(struct device * ) ;
   int (*offline)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
   struct iommu_ops  const  *iommu_ops ;
   struct subsys_private *p ;
   struct lock_class_key lock_key ;
};
struct device_type;
enum probe_type {
    PROBE_DEFAULT_STRATEGY = 0,
    PROBE_PREFER_ASYNCHRONOUS = 1,
    PROBE_FORCE_SYNCHRONOUS = 2
} ;
struct device_driver {
   char const   *name ;
   struct bus_type *bus ;
   struct module *owner ;
   char const   *mod_name ;
   bool suppress_bind_attrs ;
   enum probe_type probe_type ;
   struct of_device_id  const  *of_match_table ;
   struct acpi_device_id  const  *acpi_match_table ;
   int (*probe)(struct device * ) ;
   int (*remove)(struct device * ) ;
   void (*shutdown)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct attribute_group  const  **groups ;
   struct dev_pm_ops  const  *pm ;
   struct driver_private *p ;
};
struct class_attribute;
struct class {
   char const   *name ;
   struct module *owner ;
   struct class_attribute *class_attrs ;
   struct attribute_group  const  **dev_groups ;
   struct kobject *dev_kobj ;
   int (*dev_uevent)(struct device * , struct kobj_uevent_env * ) ;
   char *(*devnode)(struct device * , umode_t * ) ;
   void (*class_release)(struct class * ) ;
   void (*dev_release)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct kobj_ns_type_operations  const  *ns_type ;
   void const   *(*namespace)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
   struct subsys_private *p ;
};
struct class_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct class * , struct class_attribute * , char * ) ;
   ssize_t (*store)(struct class * , struct class_attribute * , char const   * , size_t  ) ;
};
struct device_type {
   char const   *name ;
   struct attribute_group  const  **groups ;
   int (*uevent)(struct device * , struct kobj_uevent_env * ) ;
   char *(*devnode)(struct device * , umode_t * , kuid_t * , kgid_t * ) ;
   void (*release)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
};
struct device_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct device * , struct device_attribute * , char * ) ;
   ssize_t (*store)(struct device * , struct device_attribute * , char const   * ,
                    size_t  ) ;
};
struct device_dma_parameters {
   unsigned int max_segment_size ;
    klee_make_symbolic(&max_segment_size, sizeof(int), "max_segment_size");
   unsigned long segment_boundary_mask ;
    klee_make_symbolic(&segment_boundary_mask, sizeof(long), "segment_boundary_mask");
};
struct dma_coherent_mem;
struct cma;
struct device {
   struct device *parent ;
   struct device_private *p ;
   struct kobject kobj ;
   char const   *init_name ;
   struct device_type  const  *type ;
   struct mutex mutex ;
   struct bus_type *bus ;
   struct device_driver *driver ;
   void *platform_data ;
   void *driver_data ;
   struct dev_pm_info power ;
   struct dev_pm_domain *pm_domain ;
   struct dev_pin_info *pins ;
   int numa_node ;
    klee_make_symbolic(&numa_node, sizeof(int), "numa_node");
   u64 *dma_mask ;
   u64 coherent_dma_mask ;
   unsigned long dma_pfn_offset ;
    klee_make_symbolic(&dma_pfn_offset, sizeof(long), "dma_pfn_offset");
   struct device_dma_parameters *dma_parms ;
   struct list_head dma_pools ;
   struct dma_coherent_mem *dma_mem ;
   struct cma *cma_area ;
   struct dev_archdata archdata ;
   struct device_node *of_node ;
   struct fwnode_handle *fwnode ;
   dev_t devt ;
   u32 id ;
   spinlock_t devres_lock ;
   struct list_head devres_head ;
   struct klist_node knode_class ;
   struct class *class ;
   struct attribute_group  const  **groups ;
   void (*release)(struct device * ) ;
   struct iommu_group *iommu_group ;
   bool offline_disabled ;
   bool offline ;
};
struct wakeup_source {
   char const   *name ;
   struct list_head entry ;
   spinlock_t lock ;
   struct wake_irq *wakeirq ;
   struct timer_list timer ;
   unsigned long timer_expires ;
   ktime_t total_time ;
   ktime_t max_time ;
   ktime_t last_time ;
   ktime_t start_prevent_time ;
   ktime_t prevent_sleep_time ;
   unsigned long event_count ;
    klee_make_symbolic(&event_count, sizeof(long), "event_count");
   unsigned long active_count ;
    klee_make_symbolic(&active_count, sizeof(long), "active_count");
   unsigned long relax_count ;
    klee_make_symbolic(&relax_count, sizeof(long), "relax_count");
   unsigned long expire_count ;
    klee_make_symbolic(&expire_count, sizeof(long), "expire_count");
   unsigned long wakeup_count ;
    klee_make_symbolic(&wakeup_count, sizeof(long), "wakeup_count");
   bool active ;
   bool autosleep_enabled ;
};
struct hotplug_slot;
struct pci_slot {
   struct pci_bus *bus ;
   struct list_head list ;
   struct hotplug_slot *hotplug ;
   unsigned char number ;
    klee_make_symbolic(&number, sizeof(char), "number");
   struct kobject kobj ;
};
typedef int pci_power_t;
    klee_make_symbolic(&pci_power_t, sizeof(int), "pci_power_t");
typedef unsigned int pci_channel_state_t;
    klee_make_symbolic(&pci_channel_state_t, sizeof(int), "pci_channel_state_t");
enum pci_channel_state {
    pci_channel_io_normal = 1,
    pci_channel_io_frozen = 2,
    pci_channel_io_perm_failure = 3
} ;
typedef unsigned short pci_dev_flags_t;
    klee_make_symbolic(&pci_dev_flags_t, sizeof(short), "pci_dev_flags_t");
typedef unsigned short pci_bus_flags_t;
    klee_make_symbolic(&pci_bus_flags_t, sizeof(short), "pci_bus_flags_t");
struct pcie_link_state;
struct pci_vpd;
struct pci_sriov;
struct pci_ats;
struct proc_dir_entry;
struct pci_driver;
union __anonunion____missing_field_name_220 {
   struct pci_sriov *sriov ;
   struct pci_dev *physfn ;
};
struct pci_dev {
   struct list_head bus_list ;
   struct pci_bus *bus ;
   struct pci_bus *subordinate ;
   void *sysdata ;
   struct proc_dir_entry *procent ;
   struct pci_slot *slot ;
   unsigned int devfn ;
    klee_make_symbolic(&devfn, sizeof(int), "devfn");
   unsigned short vendor ;
    klee_make_symbolic(&vendor, sizeof(short), "vendor");
   unsigned short device ;
    klee_make_symbolic(&device, sizeof(short), "device");
   unsigned short subsystem_vendor ;
    klee_make_symbolic(&subsystem_vendor, sizeof(short), "subsystem_vendor");
   unsigned short subsystem_device ;
    klee_make_symbolic(&subsystem_device, sizeof(short), "subsystem_device");
   unsigned int class ;
    klee_make_symbolic(&class, sizeof(int), "class");
   u8 revision ;
   u8 hdr_type ;
   u8 pcie_cap ;
   u8 msi_cap ;
   u8 msix_cap ;
   unsigned char pcie_mpss : 3 ;
   u8 rom_base_reg ;
   u8 pin ;
   u16 pcie_flags_reg ;
   u8 dma_alias_devfn ;
   struct pci_driver *driver ;
   u64 dma_mask ;
   struct device_dma_parameters dma_parms ;
   pci_power_t current_state ;
   u8 pm_cap ;
   unsigned char pme_support : 5 ;
   unsigned char pme_interrupt : 1 ;
   unsigned char pme_poll : 1 ;
   unsigned char d1_support : 1 ;
   unsigned char d2_support : 1 ;
   unsigned char no_d1d2 : 1 ;
   unsigned char no_d3cold : 1 ;
   unsigned char d3cold_allowed : 1 ;
   unsigned char mmio_always_on : 1 ;
   unsigned char wakeup_prepared : 1 ;
   unsigned char runtime_d3cold : 1 ;
   unsigned char ignore_hotplug : 1 ;
   unsigned int d3_delay ;
    klee_make_symbolic(&d3_delay, sizeof(int), "d3_delay");
   unsigned int d3cold_delay ;
    klee_make_symbolic(&d3cold_delay, sizeof(int), "d3cold_delay");
   struct pcie_link_state *link_state ;
   pci_channel_state_t error_state ;
   struct device dev ;
   int cfg_size ;
    klee_make_symbolic(&cfg_size, sizeof(int), "cfg_size");
   unsigned int irq ;
    klee_make_symbolic(&irq, sizeof(int), "irq");
   struct resource resource[17U] ;
   bool match_driver ;
   unsigned char transparent : 1 ;
   unsigned char multifunction : 1 ;
   unsigned char is_added : 1 ;
   unsigned char is_busmaster : 1 ;
   unsigned char no_msi : 1 ;
   unsigned char no_64bit_msi : 1 ;
   unsigned char block_cfg_access : 1 ;
   unsigned char broken_parity_status : 1 ;
   unsigned char irq_reroute_variant : 2 ;
   unsigned char msi_enabled : 1 ;
   unsigned char msix_enabled : 1 ;
   unsigned char ari_enabled : 1 ;
   unsigned char is_managed : 1 ;
   unsigned char needs_freset : 1 ;
   unsigned char state_saved : 1 ;
   unsigned char is_physfn : 1 ;
   unsigned char is_virtfn : 1 ;
   unsigned char reset_fn : 1 ;
   unsigned char is_hotplug_bridge : 1 ;
   unsigned char __aer_firmware_first_valid : 1 ;
   unsigned char __aer_firmware_first : 1 ;
   unsigned char broken_intx_masking : 1 ;
   unsigned char io_window_1k : 1 ;
   unsigned char irq_managed : 1 ;
   unsigned char has_secondary_link : 1 ;
   pci_dev_flags_t dev_flags ;
   atomic_t enable_cnt ;
   u32 saved_config_space[16U] ;
   struct hlist_head saved_cap_space ;
   struct bin_attribute *rom_attr ;
   int rom_attr_enabled ;
    klee_make_symbolic(&rom_attr_enabled, sizeof(int), "rom_attr_enabled");
   struct bin_attribute *res_attr[17U] ;
   struct bin_attribute *res_attr_wc[17U] ;
   struct list_head msi_list ;
   struct attribute_group  const  **msi_irq_groups ;
   struct pci_vpd *vpd ;
   union __anonunion____missing_field_name_220 __annonCompField58 ;
   struct pci_ats *ats ;
   phys_addr_t rom ;
   size_t romlen ;
   char *driver_override ;
};
struct pci_ops;
struct msi_controller;
struct pci_bus {
   struct list_head node ;
   struct pci_bus *parent ;
   struct list_head children ;
   struct list_head devices ;
   struct pci_dev *self ;
   struct list_head slots ;
   struct resource *resource[4U] ;
   struct list_head resources ;
   struct resource busn_res ;
   struct pci_ops *ops ;
   struct msi_controller *msi ;
   void *sysdata ;
   struct proc_dir_entry *procdir ;
   unsigned char number ;
   unsigned char primary ;
    klee_make_symbolic(&primary, sizeof(char), "primary");
   unsigned char max_bus_speed ;
    klee_make_symbolic(&max_bus_speed, sizeof(char), "max_bus_speed");
   unsigned char cur_bus_speed ;
    klee_make_symbolic(&cur_bus_speed, sizeof(char), "cur_bus_speed");
   char name[48U] ;
   unsigned short bridge_ctl ;
    klee_make_symbolic(&bridge_ctl, sizeof(short), "bridge_ctl");
   pci_bus_flags_t bus_flags ;
   struct device *bridge ;
   struct device dev ;
   struct bin_attribute *legacy_io ;
   struct bin_attribute *legacy_mem ;
   unsigned char is_added : 1 ;
};
struct pci_ops {
   void *(*map_bus)(struct pci_bus * , unsigned int  , int  ) ;
   int (*read)(struct pci_bus * , unsigned int  , int  , int  , u32 * ) ;
   int (*write)(struct pci_bus * , unsigned int  , int  , int  , u32  ) ;
};
struct pci_dynids {
   spinlock_t lock ;
   struct list_head list ;
};
typedef unsigned int pci_ers_result_t;
    klee_make_symbolic(&pci_ers_result_t, sizeof(int), "pci_ers_result_t");
struct pci_error_handlers {
   pci_ers_result_t (*error_detected)(struct pci_dev * , enum pci_channel_state  ) ;
   pci_ers_result_t (*mmio_enabled)(struct pci_dev * ) ;
   pci_ers_result_t (*link_reset)(struct pci_dev * ) ;
   pci_ers_result_t (*slot_reset)(struct pci_dev * ) ;
   void (*reset_notify)(struct pci_dev * , bool  ) ;
   void (*resume)(struct pci_dev * ) ;
};
struct pci_driver {
   struct list_head node ;
   char const   *name ;
   struct pci_device_id  const  *id_table ;
   int (*probe)(struct pci_dev * , struct pci_device_id  const  * ) ;
   void (*remove)(struct pci_dev * ) ;
   int (*suspend)(struct pci_dev * , pm_message_t  ) ;
   int (*suspend_late)(struct pci_dev * , pm_message_t  ) ;
   int (*resume_early)(struct pci_dev * ) ;
   int (*resume)(struct pci_dev * ) ;
   void (*shutdown)(struct pci_dev * ) ;
   int (*sriov_configure)(struct pci_dev * , int  ) ;
   struct pci_error_handlers  const  *err_handler ;
   struct device_driver driver ;
   struct pci_dynids dynids ;
};
struct shrink_control {
   gfp_t gfp_mask ;
   unsigned long nr_to_scan ;
    klee_make_symbolic(&nr_to_scan, sizeof(long), "nr_to_scan");
   int nid ;
    klee_make_symbolic(&nid, sizeof(int), "nid");
   struct mem_cgroup *memcg ;
};
struct shrinker {
   unsigned long (*count_objects)(struct shrinker * , struct shrink_control * ) ;
   unsigned long (*scan_objects)(struct shrinker * , struct shrink_control * ) ;
   int seeks ;
    klee_make_symbolic(&seeks, sizeof(int), "seeks");
   long batch ;
    klee_make_symbolic(&batch, sizeof(long), "batch");
   unsigned long flags ;
   struct list_head list ;
   atomic_long_t *nr_deferred ;
};
struct file_ra_state;
struct writeback_control;
struct bdi_writeback;
struct vm_fault {
   unsigned int flags ;
   unsigned long pgoff ;
    klee_make_symbolic(&pgoff, sizeof(long), "pgoff");
   void *virtual_address ;
   struct page *cow_page ;
   struct page *page ;
   unsigned long max_pgoff ;
    klee_make_symbolic(&max_pgoff, sizeof(long), "max_pgoff");
   pte_t *pte ;
};
struct vm_operations_struct {
   void (*open)(struct vm_area_struct * ) ;
   void (*close)(struct vm_area_struct * ) ;
   int (*fault)(struct vm_area_struct * , struct vm_fault * ) ;
   void (*map_pages)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*page_mkwrite)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*pfn_mkwrite)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*access)(struct vm_area_struct * , unsigned long  , void * , int  , int  ) ;
   char const   *(*name)(struct vm_area_struct * ) ;
   int (*set_policy)(struct vm_area_struct * , struct mempolicy * ) ;
   struct mempolicy *(*get_policy)(struct vm_area_struct * , unsigned long  ) ;
   struct page *(*find_special_page)(struct vm_area_struct * , unsigned long  ) ;
};
struct kvec;
struct scatterlist {
   unsigned long sg_magic ;
    klee_make_symbolic(&sg_magic, sizeof(long), "sg_magic");
   unsigned long page_link ;
    klee_make_symbolic(&page_link, sizeof(long), "page_link");
   unsigned int offset ;
    klee_make_symbolic(&offset, sizeof(int), "offset");
   unsigned int length ;
    klee_make_symbolic(&length, sizeof(int), "length");
   dma_addr_t dma_address ;
   unsigned int dma_length ;
    klee_make_symbolic(&dma_length, sizeof(int), "dma_length");
};
struct sg_table {
   struct scatterlist *sgl ;
   unsigned int nents ;
    klee_make_symbolic(&nents, sizeof(int), "nents");
   unsigned int orig_nents ;
    klee_make_symbolic(&orig_nents, sizeof(int), "orig_nents");
};
struct msix_entry {
   u32 vector ;
   u16 entry ;
};
struct dma_attrs {
   unsigned long flags[1U] ;
};
enum dma_data_direction {
    DMA_BIDIRECTIONAL = 0,
    DMA_TO_DEVICE = 1,
    DMA_FROM_DEVICE = 2,
    DMA_NONE = 3
} ;
struct dma_map_ops {
   void *(*alloc)(struct device * , size_t  , dma_addr_t * , gfp_t  , struct dma_attrs * ) ;
   void (*free)(struct device * , size_t  , void * , dma_addr_t  , struct dma_attrs * ) ;
   int (*mmap)(struct device * , struct vm_area_struct * , void * , dma_addr_t  ,
               size_t  , struct dma_attrs * ) ;
   int (*get_sgtable)(struct device * , struct sg_table * , void * , dma_addr_t  ,
                      size_t  , struct dma_attrs * ) ;
   dma_addr_t (*map_page)(struct device * , struct page * , unsigned long  , size_t  ,
                          enum dma_data_direction  , struct dma_attrs * ) ;
   void (*unmap_page)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ,
                      struct dma_attrs * ) ;
   int (*map_sg)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ,
                 struct dma_attrs * ) ;
   void (*unmap_sg)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ,
                    struct dma_attrs * ) ;
   void (*sync_single_for_cpu)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ) ;
   void (*sync_single_for_device)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ) ;
   void (*sync_sg_for_cpu)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ) ;
   void (*sync_sg_for_device)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ) ;
   int (*mapping_error)(struct device * , dma_addr_t  ) ;
   int (*dma_supported)(struct device * , u64  ) ;
   int (*set_dma_mask)(struct device * , u64  ) ;
   int is_phys ;
    klee_make_symbolic(&is_phys, sizeof(int), "is_phys");
};
struct iovec {
   void *iov_base ;
   __kernel_size_t iov_len ;
};
struct kvec {
   void *iov_base ;
   size_t iov_len ;
};
union __anonunion____missing_field_name_221 {
   struct iovec  const  *iov ;
   struct kvec  const  *kvec ;
   struct bio_vec  const  *bvec ;
};
struct iov_iter {
   int type ;
    klee_make_symbolic(&type, sizeof(int), "type");
   size_t iov_offset ;
   size_t count ;
   union __anonunion____missing_field_name_221 __annonCompField59 ;
   unsigned long nr_segs ;
    klee_make_symbolic(&nr_segs, sizeof(long), "nr_segs");
};
struct dql {
   unsigned int num_queued ;
    klee_make_symbolic(&num_queued, sizeof(int), "num_queued");
   unsigned int adj_limit ;
    klee_make_symbolic(&adj_limit, sizeof(int), "adj_limit");
   unsigned int last_obj_cnt ;
    klee_make_symbolic(&last_obj_cnt, sizeof(int), "last_obj_cnt");
   unsigned int limit ;
    klee_make_symbolic(&limit, sizeof(int), "limit");
   unsigned int num_completed ;
    klee_make_symbolic(&num_completed, sizeof(int), "num_completed");
   unsigned int prev_ovlimit ;
    klee_make_symbolic(&prev_ovlimit, sizeof(int), "prev_ovlimit");
   unsigned int prev_num_queued ;
    klee_make_symbolic(&prev_num_queued, sizeof(int), "prev_num_queued");
   unsigned int prev_last_obj_cnt ;
    klee_make_symbolic(&prev_last_obj_cnt, sizeof(int), "prev_last_obj_cnt");
   unsigned int lowest_slack ;
    klee_make_symbolic(&lowest_slack, sizeof(int), "lowest_slack");
   unsigned long slack_start_time ;
    klee_make_symbolic(&slack_start_time, sizeof(long), "slack_start_time");
   unsigned int max_limit ;
    klee_make_symbolic(&max_limit, sizeof(int), "max_limit");
   unsigned int min_limit ;
    klee_make_symbolic(&min_limit, sizeof(int), "min_limit");
   unsigned int slack_hold_time ;
    klee_make_symbolic(&slack_hold_time, sizeof(int), "slack_hold_time");
};
typedef unsigned short __kernel_sa_family_t;
    klee_make_symbolic(&__kernel_sa_family_t, sizeof(short), "__kernel_sa_family_t");
typedef __kernel_sa_family_t sa_family_t;
struct sockaddr {
   sa_family_t sa_family ;
   char sa_data[14U] ;
};
struct kiocb;
struct msghdr {
   void *msg_name ;
   int msg_namelen ;
    klee_make_symbolic(&msg_namelen, sizeof(int), "msg_namelen");
   struct iov_iter msg_iter ;
   void *msg_control ;
   __kernel_size_t msg_controllen ;
   unsigned int msg_flags ;
    klee_make_symbolic(&msg_flags, sizeof(int), "msg_flags");
   struct kiocb *msg_iocb ;
};
struct __anonstruct_sync_serial_settings_223 {
   unsigned int clock_rate ;
    klee_make_symbolic(&clock_rate, sizeof(int), "clock_rate");
   unsigned int clock_type ;
    klee_make_symbolic(&clock_type, sizeof(int), "clock_type");
   unsigned short loopback ;
    klee_make_symbolic(&loopback, sizeof(short), "loopback");
};
typedef struct __anonstruct_sync_serial_settings_223 sync_serial_settings;
struct __anonstruct_te1_settings_224 {
   unsigned int clock_rate ;
   unsigned int clock_type ;
   unsigned short loopback ;
   unsigned int slot_map ;
    klee_make_symbolic(&slot_map, sizeof(int), "slot_map");
};
typedef struct __anonstruct_te1_settings_224 te1_settings;
struct __anonstruct_raw_hdlc_proto_225 {
   unsigned short encoding ;
    klee_make_symbolic(&encoding, sizeof(short), "encoding");
   unsigned short parity ;
    klee_make_symbolic(&parity, sizeof(short), "parity");
};
typedef struct __anonstruct_raw_hdlc_proto_225 raw_hdlc_proto;
struct __anonstruct_fr_proto_226 {
   unsigned int t391 ;
    klee_make_symbolic(&t391, sizeof(int), "t391");
   unsigned int t392 ;
    klee_make_symbolic(&t392, sizeof(int), "t392");
   unsigned int n391 ;
    klee_make_symbolic(&n391, sizeof(int), "n391");
   unsigned int n392 ;
    klee_make_symbolic(&n392, sizeof(int), "n392");
   unsigned int n393 ;
    klee_make_symbolic(&n393, sizeof(int), "n393");
   unsigned short lmi ;
    klee_make_symbolic(&lmi, sizeof(short), "lmi");
   unsigned short dce ;
    klee_make_symbolic(&dce, sizeof(short), "dce");
};
typedef struct __anonstruct_fr_proto_226 fr_proto;
struct __anonstruct_fr_proto_pvc_227 {
   unsigned int dlci ;
    klee_make_symbolic(&dlci, sizeof(int), "dlci");
};
typedef struct __anonstruct_fr_proto_pvc_227 fr_proto_pvc;
struct __anonstruct_fr_proto_pvc_info_228 {
   unsigned int dlci ;
   char master[16U] ;
};
typedef struct __anonstruct_fr_proto_pvc_info_228 fr_proto_pvc_info;
struct __anonstruct_cisco_proto_229 {
   unsigned int interval ;
    klee_make_symbolic(&interval, sizeof(int), "interval");
   unsigned int timeout ;
};
typedef struct __anonstruct_cisco_proto_229 cisco_proto;
struct ifmap {
   unsigned long mem_start ;
    klee_make_symbolic(&mem_start, sizeof(long), "mem_start");
   unsigned long mem_end ;
    klee_make_symbolic(&mem_end, sizeof(long), "mem_end");
   unsigned short base_addr ;
    klee_make_symbolic(&base_addr, sizeof(short), "base_addr");
   unsigned char irq ;
   unsigned char dma ;
    klee_make_symbolic(&dma, sizeof(char), "dma");
   unsigned char port ;
    klee_make_symbolic(&port, sizeof(char), "port");
};
union __anonunion_ifs_ifsu_230 {
   raw_hdlc_proto *raw_hdlc ;
   cisco_proto *cisco ;
   fr_proto *fr ;
   fr_proto_pvc *fr_pvc ;
   fr_proto_pvc_info *fr_pvc_info ;
   sync_serial_settings *sync ;
   te1_settings *te1 ;
};
struct if_settings {
   unsigned int type ;
   unsigned int size ;
   union __anonunion_ifs_ifsu_230 ifs_ifsu ;
};
union __anonunion_ifr_ifrn_231 {
   char ifrn_name[16U] ;
};
union __anonunion_ifr_ifru_232 {
   struct sockaddr ifru_addr ;
   struct sockaddr ifru_dstaddr ;
   struct sockaddr ifru_broadaddr ;
   struct sockaddr ifru_netmask ;
   struct sockaddr ifru_hwaddr ;
   short ifru_flags ;
    klee_make_symbolic(&ifru_flags, sizeof(short), "ifru_flags");
   int ifru_ivalue ;
    klee_make_symbolic(&ifru_ivalue, sizeof(int), "ifru_ivalue");
   int ifru_mtu ;
    klee_make_symbolic(&ifru_mtu, sizeof(int), "ifru_mtu");
   struct ifmap ifru_map ;
   char ifru_slave[16U] ;
   char ifru_newname[16U] ;
   void *ifru_data ;
   struct if_settings ifru_settings ;
};
struct ifreq {
   union __anonunion_ifr_ifrn_231 ifr_ifrn ;
   union __anonunion_ifr_ifru_232 ifr_ifru ;
};
struct hlist_bl_node;
struct hlist_bl_head {
   struct hlist_bl_node *first ;
};
struct hlist_bl_node {
   struct hlist_bl_node *next ;
   struct hlist_bl_node **pprev ;
};
struct __anonstruct____missing_field_name_237 {
   spinlock_t lock ;
   int count ;
};
union __anonunion____missing_field_name_236 {
   struct __anonstruct____missing_field_name_237 __annonCompField60 ;
};
struct lockref {
   union __anonunion____missing_field_name_236 __annonCompField61 ;
};
struct vfsmount;
struct __anonstruct____missing_field_name_239 {
   u32 hash ;
   u32 len ;
};
union __anonunion____missing_field_name_238 {
   struct __anonstruct____missing_field_name_239 __annonCompField62 ;
   u64 hash_len ;
};
struct qstr {
   union __anonunion____missing_field_name_238 __annonCompField63 ;
   unsigned char const   *name ;
};
struct dentry_operations;
union __anonunion_d_u_240 {
   struct hlist_node d_alias ;
   struct callback_head d_rcu ;
};
struct dentry {
   unsigned int d_flags ;
    klee_make_symbolic(&d_flags, sizeof(int), "d_flags");
   seqcount_t d_seq ;
   struct hlist_bl_node d_hash ;
   struct dentry *d_parent ;
   struct qstr d_name ;
   struct inode *d_inode ;
   unsigned char d_iname[32U] ;
   struct lockref d_lockref ;
   struct dentry_operations  const  *d_op ;
   struct super_block *d_sb ;
   unsigned long d_time ;
    klee_make_symbolic(&d_time, sizeof(long), "d_time");
   void *d_fsdata ;
   struct list_head d_lru ;
   struct list_head d_child ;
   struct list_head d_subdirs ;
   union __anonunion_d_u_240 d_u ;
};
struct dentry_operations {
   int (*d_revalidate)(struct dentry * , unsigned int  ) ;
   int (*d_weak_revalidate)(struct dentry * , unsigned int  ) ;
   int (*d_hash)(struct dentry  const  * , struct qstr * ) ;
   int (*d_compare)(struct dentry  const  * , struct dentry  const  * , unsigned int  ,
                    char const   * , struct qstr  const  * ) ;
   int (*d_delete)(struct dentry  const  * ) ;
   void (*d_release)(struct dentry * ) ;
   void (*d_prune)(struct dentry * ) ;
   void (*d_iput)(struct dentry * , struct inode * ) ;
   char *(*d_dname)(struct dentry * , char * , int  ) ;
   struct vfsmount *(*d_automount)(struct path * ) ;
   int (*d_manage)(struct dentry * , bool  ) ;
   struct inode *(*d_select_inode)(struct dentry * , unsigned int  ) ;
};
struct path {
   struct vfsmount *mnt ;
   struct dentry *dentry ;
};
struct list_lru_one {
   struct list_head list ;
   long nr_items ;
    klee_make_symbolic(&nr_items, sizeof(long), "nr_items");
};
struct list_lru_memcg {
   struct list_lru_one *lru[0U] ;
};
struct list_lru_node {
   spinlock_t lock ;
   struct list_lru_one lru ;
   struct list_lru_memcg *memcg_lrus ;
};
struct list_lru {
   struct list_lru_node *node ;
   struct list_head list ;
};
struct __anonstruct____missing_field_name_244 {
   struct radix_tree_node *parent ;
   void *private_data ;
};
union __anonunion____missing_field_name_243 {
   struct __anonstruct____missing_field_name_244 __annonCompField64 ;
   struct callback_head callback_head ;
};
struct radix_tree_node {
   unsigned int path ;
    klee_make_symbolic(&path, sizeof(int), "path");
   unsigned int count ;
   union __anonunion____missing_field_name_243 __annonCompField65 ;
   struct list_head private_list ;
   void *slots[64U] ;
   unsigned long tags[3U][1U] ;
};
struct radix_tree_root {
   unsigned int height ;
    klee_make_symbolic(&height, sizeof(int), "height");
   gfp_t gfp_mask ;
   struct radix_tree_node *rnode ;
};
struct fiemap_extent {
   __u64 fe_logical ;
   __u64 fe_physical ;
   __u64 fe_length ;
   __u64 fe_reserved64[2U] ;
   __u32 fe_flags ;
   __u32 fe_reserved[3U] ;
};
enum migrate_mode {
    MIGRATE_ASYNC = 0,
    MIGRATE_SYNC_LIGHT = 1,
    MIGRATE_SYNC = 2
} ;
struct block_device;
struct bio_vec {
   struct page *bv_page ;
   unsigned int bv_len ;
    klee_make_symbolic(&bv_len, sizeof(int), "bv_len");
   unsigned int bv_offset ;
    klee_make_symbolic(&bv_offset, sizeof(int), "bv_offset");
};
struct export_operations;
struct poll_table_struct;
struct kstatfs;
struct swap_info_struct;
struct iattr {
   unsigned int ia_valid ;
    klee_make_symbolic(&ia_valid, sizeof(int), "ia_valid");
   umode_t ia_mode ;
   kuid_t ia_uid ;
   kgid_t ia_gid ;
   loff_t ia_size ;
   struct timespec ia_atime ;
   struct timespec ia_mtime ;
   struct timespec ia_ctime ;
   struct file *ia_file ;
};
struct dquot;
typedef __kernel_uid32_t projid_t;
struct __anonstruct_kprojid_t_248 {
   projid_t val ;
};
typedef struct __anonstruct_kprojid_t_248 kprojid_t;
enum quota_type {
    USRQUOTA = 0,
    GRPQUOTA = 1,
    PRJQUOTA = 2
} ;
typedef long long qsize_t;
    klee_make_symbolic(&qsize_t, sizeof(long), "qsize_t");
union __anonunion____missing_field_name_249 {
   kuid_t uid ;
   kgid_t gid ;
   kprojid_t projid ;
};
struct kqid {
   union __anonunion____missing_field_name_249 __annonCompField67 ;
   enum quota_type type ;
};
struct mem_dqblk {
   qsize_t dqb_bhardlimit ;
   qsize_t dqb_bsoftlimit ;
   qsize_t dqb_curspace ;
   qsize_t dqb_rsvspace ;
   qsize_t dqb_ihardlimit ;
   qsize_t dqb_isoftlimit ;
   qsize_t dqb_curinodes ;
   time_t dqb_btime ;
   time_t dqb_itime ;
};
struct quota_format_type;
struct mem_dqinfo {
   struct quota_format_type *dqi_format ;
   int dqi_fmt_id ;
    klee_make_symbolic(&dqi_fmt_id, sizeof(int), "dqi_fmt_id");
   struct list_head dqi_dirty_list ;
   unsigned long dqi_flags ;
    klee_make_symbolic(&dqi_flags, sizeof(long), "dqi_flags");
   unsigned int dqi_bgrace ;
    klee_make_symbolic(&dqi_bgrace, sizeof(int), "dqi_bgrace");
   unsigned int dqi_igrace ;
    klee_make_symbolic(&dqi_igrace, sizeof(int), "dqi_igrace");
   qsize_t dqi_max_spc_limit ;
   qsize_t dqi_max_ino_limit ;
   void *dqi_priv ;
};
struct dquot {
   struct hlist_node dq_hash ;
   struct list_head dq_inuse ;
   struct list_head dq_free ;
   struct list_head dq_dirty ;
   struct mutex dq_lock ;
   atomic_t dq_count ;
   wait_queue_head_t dq_wait_unused ;
   struct super_block *dq_sb ;
   struct kqid dq_id ;
   loff_t dq_off ;
   unsigned long dq_flags ;
    klee_make_symbolic(&dq_flags, sizeof(long), "dq_flags");
   struct mem_dqblk dq_dqb ;
};
struct quota_format_ops {
   int (*check_quota_file)(struct super_block * , int  ) ;
   int (*read_file_info)(struct super_block * , int  ) ;
   int (*write_file_info)(struct super_block * , int  ) ;
   int (*free_file_info)(struct super_block * , int  ) ;
   int (*read_dqblk)(struct dquot * ) ;
   int (*commit_dqblk)(struct dquot * ) ;
   int (*release_dqblk)(struct dquot * ) ;
};
struct dquot_operations {
   int (*write_dquot)(struct dquot * ) ;
   struct dquot *(*alloc_dquot)(struct super_block * , int  ) ;
   void (*destroy_dquot)(struct dquot * ) ;
   int (*acquire_dquot)(struct dquot * ) ;
   int (*release_dquot)(struct dquot * ) ;
   int (*mark_dirty)(struct dquot * ) ;
   int (*write_info)(struct super_block * , int  ) ;
   qsize_t *(*get_reserved_space)(struct inode * ) ;
   int (*get_projid)(struct inode * , kprojid_t * ) ;
};
struct qc_dqblk {
   int d_fieldmask ;
    klee_make_symbolic(&d_fieldmask, sizeof(int), "d_fieldmask");
   u64 d_spc_hardlimit ;
   u64 d_spc_softlimit ;
   u64 d_ino_hardlimit ;
   u64 d_ino_softlimit ;
   u64 d_space ;
   u64 d_ino_count ;
   s64 d_ino_timer ;
   s64 d_spc_timer ;
   int d_ino_warns ;
    klee_make_symbolic(&d_ino_warns, sizeof(int), "d_ino_warns");
   int d_spc_warns ;
    klee_make_symbolic(&d_spc_warns, sizeof(int), "d_spc_warns");
   u64 d_rt_spc_hardlimit ;
   u64 d_rt_spc_softlimit ;
   u64 d_rt_space ;
   s64 d_rt_spc_timer ;
   int d_rt_spc_warns ;
    klee_make_symbolic(&d_rt_spc_warns, sizeof(int), "d_rt_spc_warns");
};
struct qc_type_state {
   unsigned int flags ;
   unsigned int spc_timelimit ;
    klee_make_symbolic(&spc_timelimit, sizeof(int), "spc_timelimit");
   unsigned int ino_timelimit ;
    klee_make_symbolic(&ino_timelimit, sizeof(int), "ino_timelimit");
   unsigned int rt_spc_timelimit ;
    klee_make_symbolic(&rt_spc_timelimit, sizeof(int), "rt_spc_timelimit");
   unsigned int spc_warnlimit ;
    klee_make_symbolic(&spc_warnlimit, sizeof(int), "spc_warnlimit");
   unsigned int ino_warnlimit ;
    klee_make_symbolic(&ino_warnlimit, sizeof(int), "ino_warnlimit");
   unsigned int rt_spc_warnlimit ;
    klee_make_symbolic(&rt_spc_warnlimit, sizeof(int), "rt_spc_warnlimit");
   unsigned long long ino ;
   blkcnt_t blocks ;
   blkcnt_t nextents ;
};
struct qc_state {
   unsigned int s_incoredqs ;
    klee_make_symbolic(&s_incoredqs, sizeof(int), "s_incoredqs");
   struct qc_type_state s_state[3U] ;
};
struct qc_info {
   int i_fieldmask ;
    klee_make_symbolic(&i_fieldmask, sizeof(int), "i_fieldmask");
   unsigned int i_flags ;
    klee_make_symbolic(&i_flags, sizeof(int), "i_flags");
   unsigned int i_spc_timelimit ;
    klee_make_symbolic(&i_spc_timelimit, sizeof(int), "i_spc_timelimit");
   unsigned int i_ino_timelimit ;
    klee_make_symbolic(&i_ino_timelimit, sizeof(int), "i_ino_timelimit");
   unsigned int i_rt_spc_timelimit ;
    klee_make_symbolic(&i_rt_spc_timelimit, sizeof(int), "i_rt_spc_timelimit");
   unsigned int i_spc_warnlimit ;
    klee_make_symbolic(&i_spc_warnlimit, sizeof(int), "i_spc_warnlimit");
   unsigned int i_ino_warnlimit ;
    klee_make_symbolic(&i_ino_warnlimit, sizeof(int), "i_ino_warnlimit");
   unsigned int i_rt_spc_warnlimit ;
    klee_make_symbolic(&i_rt_spc_warnlimit, sizeof(int), "i_rt_spc_warnlimit");
};
struct quotactl_ops {
   int (*quota_on)(struct super_block * , int  , int  , struct path * ) ;
   int (*quota_off)(struct super_block * , int  ) ;
   int (*quota_enable)(struct super_block * , unsigned int  ) ;
   int (*quota_disable)(struct super_block * , unsigned int  ) ;
   int (*quota_sync)(struct super_block * , int  ) ;
   int (*set_info)(struct super_block * , int  , struct qc_info * ) ;
   int (*get_dqblk)(struct super_block * , struct kqid  , struct qc_dqblk * ) ;
   int (*set_dqblk)(struct super_block * , struct kqid  , struct qc_dqblk * ) ;
   int (*get_state)(struct super_block * , struct qc_state * ) ;
   int (*rm_xquota)(struct super_block * , unsigned int  ) ;
};
struct quota_format_type {
   int qf_fmt_id ;
    klee_make_symbolic(&qf_fmt_id, sizeof(int), "qf_fmt_id");
   struct quota_format_ops  const  *qf_ops ;
   struct module *qf_owner ;
   struct quota_format_type *qf_next ;
};
struct quota_info {
   unsigned int flags ;
   struct mutex dqio_mutex ;
   struct mutex dqonoff_mutex ;
   struct inode *files[3U] ;
   struct mem_dqinfo info[3U] ;
   struct quota_format_ops  const  *ops[3U] ;
};
struct kiocb {
   struct file *ki_filp ;
   loff_t ki_pos ;
   void (*ki_complete)(struct kiocb * , long  , long  ) ;
   void *private ;
   int ki_flags ;
    klee_make_symbolic(&ki_flags, sizeof(int), "ki_flags");
};
struct address_space_operations {
   int (*writepage)(struct page * , struct writeback_control * ) ;
   int (*readpage)(struct file * , struct page * ) ;
   int (*writepages)(struct address_space * , struct writeback_control * ) ;
   int (*set_page_dirty)(struct page * ) ;
   int (*readpages)(struct file * , struct address_space * , struct list_head * ,
                    unsigned int  ) ;
   int (*write_begin)(struct file * , struct address_space * , loff_t  , unsigned int  ,
                      unsigned int  , struct page ** , void ** ) ;
   int (*write_end)(struct file * , struct address_space * , loff_t  , unsigned int  ,
                    unsigned int  , struct page * , void * ) ;
   sector_t (*bmap)(struct address_space * , sector_t  ) ;
   void (*invalidatepage)(struct page * , unsigned int  , unsigned int  ) ;
   int (*releasepage)(struct page * , gfp_t  ) ;
   void (*freepage)(struct page * ) ;
   ssize_t (*direct_IO)(struct kiocb * , struct iov_iter * , loff_t  ) ;
   int (*migratepage)(struct address_space * , struct page * , struct page * , enum migrate_mode  ) ;
   int (*launder_page)(struct page * ) ;
   int (*is_partially_uptodate)(struct page * , unsigned long  , unsigned long  ) ;
   void (*is_dirty_writeback)(struct page * , bool * , bool * ) ;
   int (*error_remove_page)(struct address_space * , struct page * ) ;
   int (*swap_activate)(struct swap_info_struct * , struct file * , sector_t * ) ;
   void (*swap_deactivate)(struct file * ) ;
};
struct address_space {
   struct inode *host ;
   struct radix_tree_root page_tree ;
   spinlock_t tree_lock ;
   atomic_t i_mmap_writable ;
   struct rb_root i_mmap ;
   struct rw_semaphore i_mmap_rwsem ;
   unsigned long nrpages ;
    klee_make_symbolic(&nrpages, sizeof(long), "nrpages");
   unsigned long nrshadows ;
    klee_make_symbolic(&nrshadows, sizeof(long), "nrshadows");
   unsigned long writeback_index ;
    klee_make_symbolic(&writeback_index, sizeof(long), "writeback_index");
   struct address_space_operations  const  *a_ops ;
   unsigned long flags ;
   spinlock_t private_lock ;
   struct list_head private_list ;
   void *private_data ;
};
struct request_queue;
struct hd_struct;
struct gendisk;
struct block_device {
   dev_t bd_dev ;
   int bd_openers ;
    klee_make_symbolic(&bd_openers, sizeof(int), "bd_openers");
   struct inode *bd_inode ;
   struct super_block *bd_super ;
   struct mutex bd_mutex ;
   struct list_head bd_inodes ;
   void *bd_claiming ;
   void *bd_holder ;
   int bd_holders ;
    klee_make_symbolic(&bd_holders, sizeof(int), "bd_holders");
   bool bd_write_holder ;
   struct list_head bd_holder_disks ;
   struct block_device *bd_contains ;
   unsigned int bd_block_size ;
    klee_make_symbolic(&bd_block_size, sizeof(int), "bd_block_size");
   struct hd_struct *bd_part ;
   unsigned int bd_part_count ;
    klee_make_symbolic(&bd_part_count, sizeof(int), "bd_part_count");
   int bd_invalidated ;
    klee_make_symbolic(&bd_invalidated, sizeof(int), "bd_invalidated");
   struct gendisk *bd_disk ;
   struct request_queue *bd_queue ;
   struct list_head bd_list ;
   unsigned long bd_private ;
    klee_make_symbolic(&bd_private, sizeof(long), "bd_private");
   int bd_fsfreeze_count ;
    klee_make_symbolic(&bd_fsfreeze_count, sizeof(int), "bd_fsfreeze_count");
   struct mutex bd_fsfreeze_mutex ;
};
struct posix_acl;
struct inode_operations;
union __anonunion____missing_field_name_252 {
   unsigned int const   i_nlink ;
   unsigned int __i_nlink ;
    klee_make_symbolic(&__i_nlink, sizeof(int), "__i_nlink");
};
union __anonunion____missing_field_name_253 {
   struct hlist_head i_dentry ;
   struct callback_head i_rcu ;
};
struct file_lock_context;
struct cdev;
union __anonunion____missing_field_name_254 {
   struct pipe_inode_info *i_pipe ;
   struct block_device *i_bdev ;
   struct cdev *i_cdev ;
   char *i_link ;
};
struct inode {
   umode_t i_mode ;
   unsigned short i_opflags ;
    klee_make_symbolic(&i_opflags, sizeof(short), "i_opflags");
   kuid_t i_uid ;
   kgid_t i_gid ;
   unsigned int i_flags ;
   struct posix_acl *i_acl ;
   struct posix_acl *i_default_acl ;
   struct inode_operations  const  *i_op ;
   struct super_block *i_sb ;
   struct address_space *i_mapping ;
   void *i_security ;
   unsigned long i_ino ;
    klee_make_symbolic(&i_ino, sizeof(long), "i_ino");
   union __anonunion____missing_field_name_252 __annonCompField68 ;
   dev_t i_rdev ;
   loff_t i_size ;
   struct timespec i_atime ;
   struct timespec i_mtime ;
   struct timespec i_ctime ;
   spinlock_t i_lock ;
   unsigned short i_bytes ;
    klee_make_symbolic(&i_bytes, sizeof(short), "i_bytes");
   unsigned int i_blkbits ;
    klee_make_symbolic(&i_blkbits, sizeof(int), "i_blkbits");
   blkcnt_t i_blocks ;
   unsigned long i_state ;
    klee_make_symbolic(&i_state, sizeof(long), "i_state");
   struct mutex i_mutex ;
   unsigned long dirtied_when ;
    klee_make_symbolic(&dirtied_when, sizeof(long), "dirtied_when");
   unsigned long dirtied_time_when ;
    klee_make_symbolic(&dirtied_time_when, sizeof(long), "dirtied_time_when");
   struct hlist_node i_hash ;
   struct list_head i_wb_list ;
   struct bdi_writeback *i_wb ;
   int i_wb_frn_winner ;
    klee_make_symbolic(&i_wb_frn_winner, sizeof(int), "i_wb_frn_winner");
   u16 i_wb_frn_avg_time ;
   u16 i_wb_frn_history ;
   struct list_head i_lru ;
   struct list_head i_sb_list ;
   union __anonunion____missing_field_name_253 __annonCompField69 ;
   u64 i_version ;
   atomic_t i_count ;
   atomic_t i_dio_count ;
   atomic_t i_writecount ;
   atomic_t i_readcount ;
   struct file_operations  const  *i_fop ;
   struct file_lock_context *i_flctx ;
   struct address_space i_data ;
   struct list_head i_devices ;
   union __anonunion____missing_field_name_254 __annonCompField70 ;
   __u32 i_generation ;
   __u32 i_fsnotify_mask ;
   struct hlist_head i_fsnotify_marks ;
   void *i_private ;
};
struct fown_struct {
   rwlock_t lock ;
   struct pid *pid ;
   enum pid_type pid_type ;
   kuid_t uid ;
   kuid_t euid ;
   int signum ;
    klee_make_symbolic(&signum, sizeof(int), "signum");
};
struct file_ra_state {
   unsigned long start ;
    klee_make_symbolic(&start, sizeof(long), "start");
   unsigned int size ;
   unsigned int async_size ;
    klee_make_symbolic(&async_size, sizeof(int), "async_size");
   unsigned int ra_pages ;
    klee_make_symbolic(&ra_pages, sizeof(int), "ra_pages");
   unsigned int mmap_miss ;
    klee_make_symbolic(&mmap_miss, sizeof(int), "mmap_miss");
   loff_t prev_pos ;
};
union __anonunion_f_u_255 {
   struct llist_node fu_llist ;
   struct callback_head fu_rcuhead ;
};
struct file {
   union __anonunion_f_u_255 f_u ;
   struct path f_path ;
   struct inode *f_inode ;
   struct file_operations  const  *f_op ;
   spinlock_t f_lock ;
   atomic_long_t f_count ;
   unsigned int f_flags ;
    klee_make_symbolic(&f_flags, sizeof(int), "f_flags");
   fmode_t f_mode ;
   struct mutex f_pos_lock ;
   loff_t f_pos ;
   struct fown_struct f_owner ;
   struct cred  const  *f_cred ;
   struct file_ra_state f_ra ;
   u64 f_version ;
   void *f_security ;
   void *private_data ;
   struct list_head f_ep_links ;
   struct list_head f_tfile_llink ;
   struct address_space *f_mapping ;
};
typedef void *fl_owner_t;
struct file_lock;
struct file_lock_operations {
   void (*fl_copy_lock)(struct file_lock * , struct file_lock * ) ;
   void (*fl_release_private)(struct file_lock * ) ;
};
struct lock_manager_operations {
   int (*lm_compare_owner)(struct file_lock * , struct file_lock * ) ;
   unsigned long (*lm_owner_key)(struct file_lock * ) ;
   fl_owner_t (*lm_get_owner)(fl_owner_t  ) ;
   void (*lm_put_owner)(fl_owner_t  ) ;
   void (*lm_notify)(struct file_lock * ) ;
   int (*lm_grant)(struct file_lock * , int  ) ;
   bool (*lm_break)(struct file_lock * ) ;
   int (*lm_change)(struct file_lock * , int  , struct list_head * ) ;
   void (*lm_setup)(struct file_lock * , void ** ) ;
};
struct net;
struct nlm_lockowner;
struct nfs_lock_info {
   u32 state ;
   struct nlm_lockowner *owner ;
   struct list_head list ;
};
struct nfs4_lock_state;
struct nfs4_lock_info {
   struct nfs4_lock_state *owner ;
};
struct fasync_struct;
struct __anonstruct_afs_257 {
   struct list_head link ;
   int state ;
};
union __anonunion_fl_u_256 {
   struct nfs_lock_info nfs_fl ;
   struct nfs4_lock_info nfs4_fl ;
   struct __anonstruct_afs_257 afs ;
};
struct file_lock {
   struct file_lock *fl_next ;
   struct list_head fl_list ;
   struct hlist_node fl_link ;
   struct list_head fl_block ;
   fl_owner_t fl_owner ;
   unsigned int fl_flags ;
    klee_make_symbolic(&fl_flags, sizeof(int), "fl_flags");
   unsigned char fl_type ;
    klee_make_symbolic(&fl_type, sizeof(char), "fl_type");
   unsigned int fl_pid ;
    klee_make_symbolic(&fl_pid, sizeof(int), "fl_pid");
   int fl_link_cpu ;
    klee_make_symbolic(&fl_link_cpu, sizeof(int), "fl_link_cpu");
   struct pid *fl_nspid ;
   wait_queue_head_t fl_wait ;
   struct file *fl_file ;
   loff_t fl_start ;
   loff_t fl_end ;
   struct fasync_struct *fl_fasync ;
   unsigned long fl_break_time ;
    klee_make_symbolic(&fl_break_time, sizeof(long), "fl_break_time");
   unsigned long fl_downgrade_time ;
    klee_make_symbolic(&fl_downgrade_time, sizeof(long), "fl_downgrade_time");
   struct file_lock_operations  const  *fl_ops ;
   struct lock_manager_operations  const  *fl_lmops ;
   union __anonunion_fl_u_256 fl_u ;
};
struct file_lock_context {
   spinlock_t flc_lock ;
   struct list_head flc_flock ;
   struct list_head flc_posix ;
   struct list_head flc_lease ;
};
struct fasync_struct {
   spinlock_t fa_lock ;
   int magic ;
   int fa_fd ;
    klee_make_symbolic(&fa_fd, sizeof(int), "fa_fd");
   struct fasync_struct *fa_next ;
   struct file *fa_file ;
   struct callback_head fa_rcu ;
};
struct sb_writers {
   struct percpu_counter counter[3U] ;
   wait_queue_head_t wait ;
   int frozen ;
    klee_make_symbolic(&frozen, sizeof(int), "frozen");
   wait_queue_head_t wait_unfrozen ;
   struct lockdep_map lock_map[3U] ;
};
struct super_operations;
struct xattr_handler;
struct super_block {
   struct list_head s_list ;
   dev_t s_dev ;
   unsigned char s_blocksize_bits ;
    klee_make_symbolic(&s_blocksize_bits, sizeof(char), "s_blocksize_bits");
   unsigned long s_blocksize ;
    klee_make_symbolic(&s_blocksize, sizeof(long), "s_blocksize");
   loff_t s_maxbytes ;
   struct file_system_type *s_type ;
   struct super_operations  const  *s_op ;
   struct dquot_operations  const  *dq_op ;
   struct quotactl_ops  const  *s_qcop ;
   struct export_operations  const  *s_export_op ;
   unsigned long s_flags ;
    klee_make_symbolic(&s_flags, sizeof(long), "s_flags");
   unsigned long s_iflags ;
    klee_make_symbolic(&s_iflags, sizeof(long), "s_iflags");
   unsigned long s_magic ;
    klee_make_symbolic(&s_magic, sizeof(long), "s_magic");
   struct dentry *s_root ;
   struct rw_semaphore s_umount ;
   int s_count ;
    klee_make_symbolic(&s_count, sizeof(int), "s_count");
   atomic_t s_active ;
   void *s_security ;
   struct xattr_handler  const  **s_xattr ;
   struct list_head s_inodes ;
   struct hlist_bl_head s_anon ;
   struct list_head s_mounts ;
   struct block_device *s_bdev ;
   struct backing_dev_info *s_bdi ;
   struct mtd_info *s_mtd ;
   struct hlist_node s_instances ;
   unsigned int s_quota_types ;
    klee_make_symbolic(&s_quota_types, sizeof(int), "s_quota_types");
   struct quota_info s_dquot ;
   struct sb_writers s_writers ;
   char s_id[32U] ;
   u8 s_uuid[16U] ;
   void *s_fs_info ;
   unsigned int s_max_links ;
    klee_make_symbolic(&s_max_links, sizeof(int), "s_max_links");
   fmode_t s_mode ;
   u32 s_time_gran ;
   struct mutex s_vfs_rename_mutex ;
   char *s_subtype ;
   char *s_options ;
   struct dentry_operations  const  *s_d_op ;
   int cleancache_poolid ;
    klee_make_symbolic(&cleancache_poolid, sizeof(int), "cleancache_poolid");
   struct shrinker s_shrink ;
   atomic_long_t s_remove_count ;
   int s_readonly_remount ;
    klee_make_symbolic(&s_readonly_remount, sizeof(int), "s_readonly_remount");
   struct workqueue_struct *s_dio_done_wq ;
   struct hlist_head s_pins ;
   struct list_lru s_dentry_lru ;
   struct list_lru s_inode_lru ;
   struct callback_head rcu ;
   int s_stack_depth ;
    klee_make_symbolic(&s_stack_depth, sizeof(int), "s_stack_depth");
};
struct fiemap_extent_info {
   unsigned int fi_flags ;
    klee_make_symbolic(&fi_flags, sizeof(int), "fi_flags");
   unsigned int fi_extents_mapped ;
    klee_make_symbolic(&fi_extents_mapped, sizeof(int), "fi_extents_mapped");
   unsigned int fi_extents_max ;
    klee_make_symbolic(&fi_extents_max, sizeof(int), "fi_extents_max");
   struct fiemap_extent *fi_extents_start ;
};
struct dir_context;
struct dir_context {
   int (*actor)(struct dir_context * , char const   * , int  , loff_t  , u64  , unsigned int  ) ;
   loff_t pos ;
};
struct file_operations {
   struct module *owner ;
   loff_t (*llseek)(struct file * , loff_t  , int  ) ;
   ssize_t (*read)(struct file * , char * , size_t  , loff_t * ) ;
   ssize_t (*write)(struct file * , char const   * , size_t  , loff_t * ) ;
   ssize_t (*read_iter)(struct kiocb * , struct iov_iter * ) ;
   ssize_t (*write_iter)(struct kiocb * , struct iov_iter * ) ;
   int (*iterate)(struct file * , struct dir_context * ) ;
   unsigned int (*poll)(struct file * , struct poll_table_struct * ) ;
   long (*unlocked_ioctl)(struct file * , unsigned int  , unsigned long  ) ;
   long (*compat_ioctl)(struct file * , unsigned int  , unsigned long  ) ;
   int (*mmap)(struct file * , struct vm_area_struct * ) ;
   int (*mremap)(struct file * , struct vm_area_struct * ) ;
   int (*open)(struct inode * , struct file * ) ;
   int (*flush)(struct file * , fl_owner_t  ) ;
   int (*release)(struct inode * , struct file * ) ;
   int (*fsync)(struct file * , loff_t  , loff_t  , int  ) ;
   int (*aio_fsync)(struct kiocb * , int  ) ;
   int (*fasync)(int  , struct file * , int  ) ;
   int (*lock)(struct file * , int  , struct file_lock * ) ;
   ssize_t (*sendpage)(struct file * , struct page * , int  , size_t  , loff_t * ,
                       int  ) ;
   unsigned long (*get_unmapped_area)(struct file * , unsigned long  , unsigned long  ,
                                      unsigned long  , unsigned long  ) ;
   int (*check_flags)(int  ) ;
   int (*flock)(struct file * , int  , struct file_lock * ) ;
   ssize_t (*splice_write)(struct pipe_inode_info * , struct file * , loff_t * , size_t  ,
                           unsigned int  ) ;
   ssize_t (*splice_read)(struct file * , loff_t * , struct pipe_inode_info * , size_t  ,
                          unsigned int  ) ;
   int (*setlease)(struct file * , long  , struct file_lock ** , void ** ) ;
   long (*fallocate)(struct file * , int  , loff_t  , loff_t  ) ;
   void (*show_fdinfo)(struct seq_file * , struct file * ) ;
};
struct inode_operations {
   struct dentry *(*lookup)(struct inode * , struct dentry * , unsigned int  ) ;
   char const   *(*follow_link)(struct dentry * , void ** ) ;
   int (*permission)(struct inode * , int  ) ;
   struct posix_acl *(*get_acl)(struct inode * , int  ) ;
   int (*readlink)(struct dentry * , char * , int  ) ;
   void (*put_link)(struct inode * , void * ) ;
   int (*create)(struct inode * , struct dentry * , umode_t  , bool  ) ;
   int (*link)(struct dentry * , struct inode * , struct dentry * ) ;
   int (*unlink)(struct inode * , struct dentry * ) ;
   int (*symlink)(struct inode * , struct dentry * , char const   * ) ;
   int (*mkdir)(struct inode * , struct dentry * , umode_t  ) ;
   int (*rmdir)(struct inode * , struct dentry * ) ;
   int (*mknod)(struct inode * , struct dentry * , umode_t  , dev_t  ) ;
   int (*rename)(struct inode * , struct dentry * , struct inode * , struct dentry * ) ;
   int (*rename2)(struct inode * , struct dentry * , struct inode * , struct dentry * ,
                  unsigned int  ) ;
   int (*setattr)(struct dentry * , struct iattr * ) ;
   int (*getattr)(struct vfsmount * , struct dentry * , struct kstat * ) ;
   int (*setxattr)(struct dentry * , char const   * , void const   * , size_t  , int  ) ;
   ssize_t (*getxattr)(struct dentry * , char const   * , void * , size_t  ) ;
   ssize_t (*listxattr)(struct dentry * , char * , size_t  ) ;
   int (*removexattr)(struct dentry * , char const   * ) ;
   int (*fiemap)(struct inode * , struct fiemap_extent_info * , u64  , u64  ) ;
   int (*update_time)(struct inode * , struct timespec * , int  ) ;
   int (*atomic_open)(struct inode * , struct dentry * , struct file * , unsigned int  ,
                      umode_t  , int * ) ;
   int (*tmpfile)(struct inode * , struct dentry * , umode_t  ) ;
   int (*set_acl)(struct inode * , struct posix_acl * , int  ) ;
};
struct super_operations {
   struct inode *(*alloc_inode)(struct super_block * ) ;
   void (*destroy_inode)(struct inode * ) ;
   void (*dirty_inode)(struct inode * , int  ) ;
   int (*write_inode)(struct inode * , struct writeback_control * ) ;
   int (*drop_inode)(struct inode * ) ;
   void (*evict_inode)(struct inode * ) ;
   void (*put_super)(struct super_block * ) ;
   int (*sync_fs)(struct super_block * , int  ) ;
   int (*freeze_super)(struct super_block * ) ;
   int (*freeze_fs)(struct super_block * ) ;
   int (*thaw_super)(struct super_block * ) ;
   int (*unfreeze_fs)(struct super_block * ) ;
   int (*statfs)(struct dentry * , struct kstatfs * ) ;
   int (*remount_fs)(struct super_block * , int * , char * ) ;
   void (*umount_begin)(struct super_block * ) ;
   int (*show_options)(struct seq_file * , struct dentry * ) ;
   int (*show_devname)(struct seq_file * , struct dentry * ) ;
   int (*show_path)(struct seq_file * , struct dentry * ) ;
   int (*show_stats)(struct seq_file * , struct dentry * ) ;
   ssize_t (*quota_read)(struct super_block * , int  , char * , size_t  , loff_t  ) ;
   ssize_t (*quota_write)(struct super_block * , int  , char const   * , size_t  ,
                          loff_t  ) ;
   struct dquot **(*get_dquots)(struct inode * ) ;
   int (*bdev_try_to_free_page)(struct super_block * , struct page * , gfp_t  ) ;
   long (*nr_cached_objects)(struct super_block * , struct shrink_control * ) ;
   long (*free_cached_objects)(struct super_block * , struct shrink_control * ) ;
};
struct file_system_type {
   char const   *name ;
   int fs_flags ;
    klee_make_symbolic(&fs_flags, sizeof(int), "fs_flags");
   struct dentry *(*mount)(struct file_system_type * , int  , char const   * , void * ) ;
   void (*kill_sb)(struct super_block * ) ;
   struct module *owner ;
   struct file_system_type *next ;
   struct hlist_head fs_supers ;
   struct lock_class_key s_lock_key ;
   struct lock_class_key s_umount_key ;
   struct lock_class_key s_vfs_rename_key ;
   struct lock_class_key s_writers_key[3U] ;
   struct lock_class_key i_lock_key ;
   struct lock_class_key i_mutex_key ;
   struct lock_class_key i_mutex_dir_key ;
};
typedef s32 compat_time_t;
typedef s32 compat_long_t;
typedef u32 compat_uptr_t;
struct compat_timespec {
   compat_time_t tv_sec ;
   s32 tv_nsec ;
};
struct compat_robust_list {
   compat_uptr_t next ;
};
struct compat_robust_list_head {
   struct compat_robust_list list ;
   compat_long_t futex_offset ;
   compat_uptr_t list_op_pending ;
};
enum ldv_25195 {
    SS_FREE = 0,
    SS_UNCONNECTED = 1,
    SS_CONNECTING = 2,
    SS_CONNECTED = 3,
    SS_DISCONNECTING = 4
} ;
typedef enum ldv_25195 socket_state;
struct socket_wq {
   wait_queue_head_t wait ;
   struct fasync_struct *fasync_list ;
   struct callback_head rcu ;
};
struct proto_ops;
struct socket {
   socket_state state ;
   short type ;
   unsigned long flags ;
   struct socket_wq *wq ;
   struct file *file ;
   struct sock *sk ;
   struct proto_ops  const  *ops ;
};
struct proto_ops {
   int family ;
    klee_make_symbolic(&family, sizeof(int), "family");
   struct module *owner ;
   int (*release)(struct socket * ) ;
   int (*bind)(struct socket * , struct sockaddr * , int  ) ;
   int (*connect)(struct socket * , struct sockaddr * , int  , int  ) ;
   int (*socketpair)(struct socket * , struct socket * ) ;
   int (*accept)(struct socket * , struct socket * , int  ) ;
   int (*getname)(struct socket * , struct sockaddr * , int * , int  ) ;
   unsigned int (*poll)(struct file * , struct socket * , struct poll_table_struct * ) ;
   int (*ioctl)(struct socket * , unsigned int  , unsigned long  ) ;
   int (*compat_ioctl)(struct socket * , unsigned int  , unsigned long  ) ;
   int (*listen)(struct socket * , int  ) ;
   int (*shutdown)(struct socket * , int  ) ;
   int (*setsockopt)(struct socket * , int  , int  , char * , unsigned int  ) ;
   int (*getsockopt)(struct socket * , int  , int  , char * , int * ) ;
   int (*compat_setsockopt)(struct socket * , int  , int  , char * , unsigned int  ) ;
   int (*compat_getsockopt)(struct socket * , int  , int  , char * , int * ) ;
   int (*sendmsg)(struct socket * , struct msghdr * , size_t  ) ;
   int (*recvmsg)(struct socket * , struct msghdr * , size_t  , int  ) ;
   int (*mmap)(struct file * , struct socket * , struct vm_area_struct * ) ;
   ssize_t (*sendpage)(struct socket * , struct page * , int  , size_t  , int  ) ;
   ssize_t (*splice_read)(struct socket * , loff_t * , struct pipe_inode_info * ,
                          size_t  , unsigned int  ) ;
   int (*set_peek_off)(struct sock * , int  ) ;
};
struct exception_table_entry {
   int insn ;
    klee_make_symbolic(&insn, sizeof(int), "insn");
   int fixup ;
    klee_make_symbolic(&fixup, sizeof(int), "fixup");
};
struct in6_addr;
struct sk_buff;
typedef u64 netdev_features_t;
union __anonunion_in6_u_272 {
   __u8 u6_addr8[16U] ;
   __be16 u6_addr16[8U] ;
   __be32 u6_addr32[4U] ;
};
struct in6_addr {
   union __anonunion_in6_u_272 in6_u ;
};
struct ethhdr {
   unsigned char h_dest[6U] ;
   unsigned char h_source[6U] ;
   __be16 h_proto ;
};
struct pipe_buf_operations;
struct pipe_buffer {
   struct page *page ;
   unsigned int offset ;
   unsigned int len ;
    klee_make_symbolic(&len, sizeof(int), "len");
   struct pipe_buf_operations  const  *ops ;
   unsigned int flags ;
   unsigned long private ;
};
struct pipe_inode_info {
   struct mutex mutex ;
   wait_queue_head_t wait ;
   unsigned int nrbufs ;
    klee_make_symbolic(&nrbufs, sizeof(int), "nrbufs");
   unsigned int curbuf ;
    klee_make_symbolic(&curbuf, sizeof(int), "curbuf");
   unsigned int buffers ;
    klee_make_symbolic(&buffers, sizeof(int), "buffers");
   unsigned int readers ;
    klee_make_symbolic(&readers, sizeof(int), "readers");
   unsigned int writers ;
    klee_make_symbolic(&writers, sizeof(int), "writers");
   unsigned int files ;
    klee_make_symbolic(&files, sizeof(int), "files");
   unsigned int waiting_writers ;
    klee_make_symbolic(&waiting_writers, sizeof(int), "waiting_writers");
   unsigned int r_counter ;
    klee_make_symbolic(&r_counter, sizeof(int), "r_counter");
   unsigned int w_counter ;
    klee_make_symbolic(&w_counter, sizeof(int), "w_counter");
   struct page *tmp_page ;
   struct fasync_struct *fasync_readers ;
   struct fasync_struct *fasync_writers ;
   struct pipe_buffer *bufs ;
};
struct pipe_buf_operations {
   int can_merge ;
    klee_make_symbolic(&can_merge, sizeof(int), "can_merge");
   int (*confirm)(struct pipe_inode_info * , struct pipe_buffer * ) ;
   void (*release)(struct pipe_inode_info * , struct pipe_buffer * ) ;
   int (*steal)(struct pipe_inode_info * , struct pipe_buffer * ) ;
   void (*get)(struct pipe_inode_info * , struct pipe_buffer * ) ;
};
struct napi_struct;
struct nf_conntrack {
   atomic_t use ;
};
union __anonunion____missing_field_name_277 {
   struct net_device *physoutdev ;
   char neigh_header[8U] ;
};
union __anonunion____missing_field_name_278 {
   __be32 ipv4_daddr ;
   struct in6_addr ipv6_daddr ;
};
struct nf_bridge_info {
   atomic_t use ;
   unsigned char orig_proto ;
    klee_make_symbolic(&orig_proto, sizeof(char), "orig_proto");
   bool pkt_otherhost ;
   __u16 frag_max_size ;
   unsigned int mask ;
    klee_make_symbolic(&mask, sizeof(int), "mask");
   struct net_device *physindev ;
   union __anonunion____missing_field_name_277 __annonCompField74 ;
   union __anonunion____missing_field_name_278 __annonCompField75 ;
};
struct sk_buff_head {
   struct sk_buff *next ;
   struct sk_buff *prev ;
   __u32 qlen ;
   spinlock_t lock ;
};
typedef unsigned int sk_buff_data_t;
    klee_make_symbolic(&sk_buff_data_t, sizeof(int), "sk_buff_data_t");
struct __anonstruct____missing_field_name_281 {
   u32 stamp_us ;
   u32 stamp_jiffies ;
};
union __anonunion____missing_field_name_280 {
   u64 v64 ;
   struct __anonstruct____missing_field_name_281 __annonCompField76 ;
};
struct skb_mstamp {
   union __anonunion____missing_field_name_280 __annonCompField77 ;
};
union __anonunion____missing_field_name_284 {
   ktime_t tstamp ;
   struct skb_mstamp skb_mstamp ;
};
struct __anonstruct____missing_field_name_283 {
   struct sk_buff *next ;
   struct sk_buff *prev ;
   union __anonunion____missing_field_name_284 __annonCompField78 ;
};
union __anonunion____missing_field_name_282 {
   struct __anonstruct____missing_field_name_283 __annonCompField79 ;
   struct rb_node rbnode ;
};
struct sec_path;
struct __anonstruct____missing_field_name_286 {
   __u16 csum_start ;
   __u16 csum_offset ;
};
union __anonunion____missing_field_name_285 {
   __wsum csum ;
   struct __anonstruct____missing_field_name_286 __annonCompField81 ;
};
union __anonunion____missing_field_name_287 {
   unsigned int napi_id ;
    klee_make_symbolic(&napi_id, sizeof(int), "napi_id");
   unsigned int sender_cpu ;
    klee_make_symbolic(&sender_cpu, sizeof(int), "sender_cpu");
};
union __anonunion____missing_field_name_288 {
   __u32 mark ;
   __u32 reserved_tailroom ;
};
union __anonunion____missing_field_name_289 {
   __be16 inner_protocol ;
   __u8 inner_ipproto ;
};
struct sk_buff {
   union __anonunion____missing_field_name_282 __annonCompField80 ;
   struct sock *sk ;
   struct net_device *dev ;
   char cb[48U] ;
   unsigned long _skb_refdst ;
    klee_make_symbolic(&_skb_refdst, sizeof(long), "_skb_refdst");
   void (*destructor)(struct sk_buff * ) ;
   struct sec_path *sp ;
   struct nf_conntrack *nfct ;
   struct nf_bridge_info *nf_bridge ;
   unsigned int len ;
   unsigned int data_len ;
    klee_make_symbolic(&data_len, sizeof(int), "data_len");
   __u16 mac_len ;
   __u16 hdr_len ;
   __u16 queue_mapping ;
   unsigned char cloned : 1 ;
   unsigned char nohdr : 1 ;
   unsigned char fclone : 2 ;
   unsigned char peeked : 1 ;
   unsigned char head_frag : 1 ;
   unsigned char xmit_more : 1 ;
   __u32 headers_start[0U] ;
   __u8 __pkt_type_offset[0U] ;
   unsigned char pkt_type : 3 ;
   unsigned char pfmemalloc : 1 ;
   unsigned char ignore_df : 1 ;
   unsigned char nfctinfo : 3 ;
   unsigned char nf_trace : 1 ;
   unsigned char ip_summed : 2 ;
   unsigned char ooo_okay : 1 ;
   unsigned char l4_hash : 1 ;
   unsigned char sw_hash : 1 ;
   unsigned char wifi_acked_valid : 1 ;
   unsigned char wifi_acked : 1 ;
   unsigned char no_fcs : 1 ;
   unsigned char encapsulation : 1 ;
   unsigned char encap_hdr_csum : 1 ;
   unsigned char csum_valid : 1 ;
   unsigned char csum_complete_sw : 1 ;
   unsigned char csum_level : 2 ;
   unsigned char csum_bad : 1 ;
   unsigned char ndisc_nodetype : 2 ;
   unsigned char ipvs_property : 1 ;
   unsigned char inner_protocol_type : 1 ;
   unsigned char remcsum_offload : 1 ;
   __u16 tc_index ;
   __u16 tc_verd ;
   union __anonunion____missing_field_name_285 __annonCompField82 ;
   __u32 priority ;
   int skb_iif ;
    klee_make_symbolic(&skb_iif, sizeof(int), "skb_iif");
   __u32 hash ;
   __be16 vlan_proto ;
   __u16 vlan_tci ;
   union __anonunion____missing_field_name_287 __annonCompField83 ;
   __u32 secmark ;
   union __anonunion____missing_field_name_288 __annonCompField84 ;
   union __anonunion____missing_field_name_289 __annonCompField85 ;
   __u16 inner_transport_header ;
   __u16 inner_network_header ;
   __u16 inner_mac_header ;
   __be16 protocol ;
   __u16 transport_header ;
   __u16 network_header ;
   __u16 mac_header ;
   __u32 headers_end[0U] ;
   sk_buff_data_t tail ;
   sk_buff_data_t end ;
   unsigned char *head ;
   unsigned char *data ;
   unsigned int truesize ;
    klee_make_symbolic(&truesize, sizeof(int), "truesize");
   atomic_t users ;
};
struct dst_entry;
struct rtable;
struct ethtool_cmd {
   __u32 cmd ;
   __u32 supported ;
   __u32 advertising ;
   __u16 speed ;
   __u8 duplex ;
   __u8 port ;
   __u8 phy_address ;
   __u8 transceiver ;
   __u8 autoneg ;
   __u8 mdio_support ;
   __u32 maxtxpkt ;
   __u32 maxrxpkt ;
   __u16 speed_hi ;
   __u8 eth_tp_mdix ;
   __u8 eth_tp_mdix_ctrl ;
   __u32 lp_advertising ;
   __u32 reserved[2U] ;
};
struct ethtool_drvinfo {
   __u32 cmd ;
   char driver[32U] ;
   char version[32U] ;
   char fw_version[32U] ;
   char bus_info[32U] ;
   char erom_version[32U] ;
   char reserved2[12U] ;
   __u32 n_priv_flags ;
   __u32 n_stats ;
   __u32 testinfo_len ;
   __u32 eedump_len ;
   __u32 regdump_len ;
};
struct ethtool_wolinfo {
   __u32 cmd ;
   __u32 supported ;
   __u32 wolopts ;
   __u8 sopass[6U] ;
};
struct ethtool_tunable {
   __u32 cmd ;
   __u32 id ;
   __u32 type_id ;
   __u32 len ;
   void *data[0U] ;
};
struct ethtool_regs {
   __u32 cmd ;
   __u32 version ;
   __u32 len ;
   __u8 data[0U] ;
};
struct ethtool_eeprom {
   __u32 cmd ;
   __u32 magic ;
   __u32 offset ;
   __u32 len ;
   __u8 data[0U] ;
};
struct ethtool_eee {
   __u32 cmd ;
   __u32 supported ;
   __u32 advertised ;
   __u32 lp_advertised ;
   __u32 eee_active ;
   __u32 eee_enabled ;
   __u32 tx_lpi_enabled ;
   __u32 tx_lpi_timer ;
   __u32 reserved[2U] ;
};
struct ethtool_modinfo {
   __u32 cmd ;
   __u32 type ;
   __u32 eeprom_len ;
   __u32 reserved[8U] ;
};
struct ethtool_coalesce {
   __u32 cmd ;
   __u32 rx_coalesce_usecs ;
   __u32 rx_max_coalesced_frames ;
   __u32 rx_coalesce_usecs_irq ;
   __u32 rx_max_coalesced_frames_irq ;
   __u32 tx_coalesce_usecs ;
   __u32 tx_max_coalesced_frames ;
   __u32 tx_coalesce_usecs_irq ;
   __u32 tx_max_coalesced_frames_irq ;
   __u32 stats_block_coalesce_usecs ;
   __u32 use_adaptive_rx_coalesce ;
   __u32 use_adaptive_tx_coalesce ;
   __u32 pkt_rate_low ;
   __u32 rx_coalesce_usecs_low ;
   __u32 rx_max_coalesced_frames_low ;
   __u32 tx_coalesce_usecs_low ;
   __u32 tx_max_coalesced_frames_low ;
   __u32 pkt_rate_high ;
   __u32 rx_coalesce_usecs_high ;
   __u32 rx_max_coalesced_frames_high ;
   __u32 tx_coalesce_usecs_high ;
   __u32 tx_max_coalesced_frames_high ;
   __u32 rate_sample_interval ;
};
struct ethtool_ringparam {
   __u32 cmd ;
   __u32 rx_max_pending ;
   __u32 rx_mini_max_pending ;
   __u32 rx_jumbo_max_pending ;
   __u32 tx_max_pending ;
   __u32 rx_pending ;
   __u32 rx_mini_pending ;
   __u32 rx_jumbo_pending ;
   __u32 tx_pending ;
};
struct ethtool_channels {
   __u32 cmd ;
   __u32 max_rx ;
   __u32 max_tx ;
   __u32 max_other ;
   __u32 max_combined ;
   __u32 rx_count ;
   __u32 tx_count ;
   __u32 other_count ;
   __u32 combined_count ;
};
struct ethtool_pauseparam {
   __u32 cmd ;
   __u32 autoneg ;
   __u32 rx_pause ;
   __u32 tx_pause ;
};
struct ethtool_test {
   __u32 cmd ;
   __u32 flags ;
   __u32 reserved ;
   __u32 len ;
   __u64 data[0U] ;
};
struct ethtool_stats {
   __u32 cmd ;
   __u32 n_stats ;
   __u64 data[0U] ;
};
struct ethtool_tcpip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be16 psrc ;
   __be16 pdst ;
   __u8 tos ;
};
struct ethtool_ah_espip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be32 spi ;
   __u8 tos ;
};
struct ethtool_usrip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be32 l4_4_bytes ;
   __u8 tos ;
   __u8 ip_ver ;
   __u8 proto ;
};
union ethtool_flow_union {
   struct ethtool_tcpip4_spec tcp_ip4_spec ;
   struct ethtool_tcpip4_spec udp_ip4_spec ;
   struct ethtool_tcpip4_spec sctp_ip4_spec ;
   struct ethtool_ah_espip4_spec ah_ip4_spec ;
   struct ethtool_ah_espip4_spec esp_ip4_spec ;
   struct ethtool_usrip4_spec usr_ip4_spec ;
   struct ethhdr ether_spec ;
   __u8 hdata[52U] ;
};
struct ethtool_flow_ext {
   __u8 padding[2U] ;
   unsigned char h_dest[6U] ;
   __be16 vlan_etype ;
   __be16 vlan_tci ;
   __be32 data[2U] ;
};
struct ethtool_rx_flow_spec {
   __u32 flow_type ;
   union ethtool_flow_union h_u ;
   struct ethtool_flow_ext h_ext ;
   union ethtool_flow_union m_u ;
   struct ethtool_flow_ext m_ext ;
   __u64 ring_cookie ;
   __u32 location ;
};
struct ethtool_rxnfc {
   __u32 cmd ;
   __u32 flow_type ;
   __u64 data ;
   struct ethtool_rx_flow_spec fs ;
   __u32 rule_cnt ;
   __u32 rule_locs[0U] ;
};
struct ethtool_flash {
   __u32 cmd ;
   __u32 region ;
   char data[128U] ;
};
struct ethtool_dump {
   __u32 cmd ;
   __u32 version ;
   __u32 flag ;
   __u32 len ;
   __u8 data[0U] ;
};
struct ethtool_ts_info {
   __u32 cmd ;
   __u32 so_timestamping ;
   __s32 phc_index ;
   __u32 tx_types ;
   __u32 tx_reserved[3U] ;
   __u32 rx_filters ;
   __u32 rx_reserved[3U] ;
};
enum ethtool_phys_id_state {
    ETHTOOL_ID_INACTIVE = 0,
    ETHTOOL_ID_ACTIVE = 1,
    ETHTOOL_ID_ON = 2,
    ETHTOOL_ID_OFF = 3
} ;
struct ethtool_ops {
   int (*get_settings)(struct net_device * , struct ethtool_cmd * ) ;
   int (*set_settings)(struct net_device * , struct ethtool_cmd * ) ;
   void (*get_drvinfo)(struct net_device * , struct ethtool_drvinfo * ) ;
   int (*get_regs_len)(struct net_device * ) ;
   void (*get_regs)(struct net_device * , struct ethtool_regs * , void * ) ;
   void (*get_wol)(struct net_device * , struct ethtool_wolinfo * ) ;
   int (*set_wol)(struct net_device * , struct ethtool_wolinfo * ) ;
   u32 (*get_msglevel)(struct net_device * ) ;
   void (*set_msglevel)(struct net_device * , u32  ) ;
   int (*nway_reset)(struct net_device * ) ;
   u32 (*get_link)(struct net_device * ) ;
   int (*get_eeprom_len)(struct net_device * ) ;
   int (*get_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*set_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_coalesce)(struct net_device * , struct ethtool_coalesce * ) ;
   int (*set_coalesce)(struct net_device * , struct ethtool_coalesce * ) ;
   void (*get_ringparam)(struct net_device * , struct ethtool_ringparam * ) ;
   int (*set_ringparam)(struct net_device * , struct ethtool_ringparam * ) ;
   void (*get_pauseparam)(struct net_device * , struct ethtool_pauseparam * ) ;
   int (*set_pauseparam)(struct net_device * , struct ethtool_pauseparam * ) ;
   void (*self_test)(struct net_device * , struct ethtool_test * , u64 * ) ;
   void (*get_strings)(struct net_device * , u32  , u8 * ) ;
   int (*set_phys_id)(struct net_device * , enum ethtool_phys_id_state  ) ;
   void (*get_ethtool_stats)(struct net_device * , struct ethtool_stats * , u64 * ) ;
   int (*begin)(struct net_device * ) ;
   void (*complete)(struct net_device * ) ;
   u32 (*get_priv_flags)(struct net_device * ) ;
   int (*set_priv_flags)(struct net_device * , u32  ) ;
   int (*get_sset_count)(struct net_device * , int  ) ;
   int (*get_rxnfc)(struct net_device * , struct ethtool_rxnfc * , u32 * ) ;
   int (*set_rxnfc)(struct net_device * , struct ethtool_rxnfc * ) ;
   int (*flash_device)(struct net_device * , struct ethtool_flash * ) ;
   int (*reset)(struct net_device * , u32 * ) ;
   u32 (*get_rxfh_key_size)(struct net_device * ) ;
   u32 (*get_rxfh_indir_size)(struct net_device * ) ;
   int (*get_rxfh)(struct net_device * , u32 * , u8 * , u8 * ) ;
   int (*set_rxfh)(struct net_device * , u32 const   * , u8 const   * , u8 const    ) ;
   void (*get_channels)(struct net_device * , struct ethtool_channels * ) ;
   int (*set_channels)(struct net_device * , struct ethtool_channels * ) ;
   int (*get_dump_flag)(struct net_device * , struct ethtool_dump * ) ;
   int (*get_dump_data)(struct net_device * , struct ethtool_dump * , void * ) ;
   int (*set_dump)(struct net_device * , struct ethtool_dump * ) ;
   int (*get_ts_info)(struct net_device * , struct ethtool_ts_info * ) ;
   int (*get_module_info)(struct net_device * , struct ethtool_modinfo * ) ;
   int (*get_module_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_eee)(struct net_device * , struct ethtool_eee * ) ;
   int (*set_eee)(struct net_device * , struct ethtool_eee * ) ;
   int (*get_tunable)(struct net_device * , struct ethtool_tunable  const  * , void * ) ;
   int (*set_tunable)(struct net_device * , struct ethtool_tunable  const  * , void const   * ) ;
};
struct prot_inuse;
struct netns_core {
   struct ctl_table_header *sysctl_hdr ;
   int sysctl_somaxconn ;
    klee_make_symbolic(&sysctl_somaxconn, sizeof(int), "sysctl_somaxconn");
   struct prot_inuse *inuse ;
};
struct u64_stats_sync {

};
struct ipstats_mib {
   u64 mibs[36U] ;
   struct u64_stats_sync syncp ;
};
struct icmp_mib {
   unsigned long mibs[28U] ;
};
struct icmpmsg_mib {
   atomic_long_t mibs[512U] ;
};
struct icmpv6_mib {
   unsigned long mibs[6U] ;
};
struct icmpv6_mib_device {
   atomic_long_t mibs[6U] ;
};
struct icmpv6msg_mib {
   atomic_long_t mibs[512U] ;
};
struct icmpv6msg_mib_device {
   atomic_long_t mibs[512U] ;
};
struct tcp_mib {
   unsigned long mibs[16U] ;
};
struct udp_mib {
   unsigned long mibs[9U] ;
};
struct linux_mib {
   unsigned long mibs[115U] ;
};
struct linux_xfrm_mib {
   unsigned long mibs[29U] ;
};
struct netns_mib {
   struct tcp_mib *tcp_statistics ;
   struct ipstats_mib *ip_statistics ;
   struct linux_mib *net_statistics ;
   struct udp_mib *udp_statistics ;
   struct udp_mib *udplite_statistics ;
   struct icmp_mib *icmp_statistics ;
   struct icmpmsg_mib *icmpmsg_statistics ;
   struct proc_dir_entry *proc_net_devsnmp6 ;
   struct udp_mib *udp_stats_in6 ;
   struct udp_mib *udplite_stats_in6 ;
   struct ipstats_mib *ipv6_statistics ;
   struct icmpv6_mib *icmpv6_statistics ;
   struct icmpv6msg_mib *icmpv6msg_statistics ;
   struct linux_xfrm_mib *xfrm_statistics ;
};
struct netns_unix {
   int sysctl_max_dgram_qlen ;
    klee_make_symbolic(&sysctl_max_dgram_qlen, sizeof(int), "sysctl_max_dgram_qlen");
   struct ctl_table_header *ctl ;
};
struct netns_packet {
   struct mutex sklist_lock ;
   struct hlist_head sklist ;
};
struct netns_frags {
   struct percpu_counter mem ;
   int timeout ;
   int high_thresh ;
    klee_make_symbolic(&high_thresh, sizeof(int), "high_thresh");
   int low_thresh ;
    klee_make_symbolic(&low_thresh, sizeof(int), "low_thresh");
};
struct ipv4_devconf;
struct fib_rules_ops;
struct fib_table;
struct local_ports {
   seqlock_t lock ;
   int range[2U] ;
   bool warned ;
};
struct ping_group_range {
   seqlock_t lock ;
   kgid_t range[2U] ;
};
struct inet_peer_base;
struct xt_table;
struct netns_ipv4 {
   struct ctl_table_header *forw_hdr ;
   struct ctl_table_header *frags_hdr ;
   struct ctl_table_header *ipv4_hdr ;
   struct ctl_table_header *route_hdr ;
   struct ctl_table_header *xfrm4_hdr ;
   struct ipv4_devconf *devconf_all ;
   struct ipv4_devconf *devconf_dflt ;
   struct fib_rules_ops *rules_ops ;
   bool fib_has_custom_rules ;
   struct fib_table *fib_local ;
   struct fib_table *fib_main ;
   struct fib_table *fib_default ;
   int fib_num_tclassid_users ;
    klee_make_symbolic(&fib_num_tclassid_users, sizeof(int), "fib_num_tclassid_users");
   struct hlist_head *fib_table_hash ;
   bool fib_offload_disabled ;
   struct sock *fibnl ;
   struct sock **icmp_sk ;
   struct sock *mc_autojoin_sk ;
   struct inet_peer_base *peers ;
   struct sock **tcp_sk ;
   struct netns_frags frags ;
   struct xt_table *iptable_filter ;
   struct xt_table *iptable_mangle ;
   struct xt_table *iptable_raw ;
   struct xt_table *arptable_filter ;
   struct xt_table *iptable_security ;
   struct xt_table *nat_table ;
   int sysctl_icmp_echo_ignore_all ;
    klee_make_symbolic(&sysctl_icmp_echo_ignore_all, sizeof(int), "sysctl_icmp_echo_ignore_all");
   int sysctl_icmp_echo_ignore_broadcasts ;
    klee_make_symbolic(&sysctl_icmp_echo_ignore_broadcasts, sizeof(int), "sysctl_icmp_echo_ignore_broadcasts");
   int sysctl_icmp_ignore_bogus_error_responses ;
    klee_make_symbolic(&sysctl_icmp_ignore_bogus_error_responses, sizeof(int), "sysctl_icmp_ignore_bogus_error_responses");
   int sysctl_icmp_ratelimit ;
    klee_make_symbolic(&sysctl_icmp_ratelimit, sizeof(int), "sysctl_icmp_ratelimit");
   int sysctl_icmp_ratemask ;
    klee_make_symbolic(&sysctl_icmp_ratemask, sizeof(int), "sysctl_icmp_ratemask");
   int sysctl_icmp_errors_use_inbound_ifaddr ;
    klee_make_symbolic(&sysctl_icmp_errors_use_inbound_ifaddr, sizeof(int), "sysctl_icmp_errors_use_inbound_ifaddr");
   struct local_ports ip_local_ports ;
   int sysctl_tcp_ecn ;
    klee_make_symbolic(&sysctl_tcp_ecn, sizeof(int), "sysctl_tcp_ecn");
   int sysctl_tcp_ecn_fallback ;
    klee_make_symbolic(&sysctl_tcp_ecn_fallback, sizeof(int), "sysctl_tcp_ecn_fallback");
   int sysctl_ip_no_pmtu_disc ;
    klee_make_symbolic(&sysctl_ip_no_pmtu_disc, sizeof(int), "sysctl_ip_no_pmtu_disc");
   int sysctl_ip_fwd_use_pmtu ;
    klee_make_symbolic(&sysctl_ip_fwd_use_pmtu, sizeof(int), "sysctl_ip_fwd_use_pmtu");
   int sysctl_ip_nonlocal_bind ;
    klee_make_symbolic(&sysctl_ip_nonlocal_bind, sizeof(int), "sysctl_ip_nonlocal_bind");
   int sysctl_fwmark_reflect ;
    klee_make_symbolic(&sysctl_fwmark_reflect, sizeof(int), "sysctl_fwmark_reflect");
   int sysctl_tcp_fwmark_accept ;
    klee_make_symbolic(&sysctl_tcp_fwmark_accept, sizeof(int), "sysctl_tcp_fwmark_accept");
   int sysctl_tcp_mtu_probing ;
    klee_make_symbolic(&sysctl_tcp_mtu_probing, sizeof(int), "sysctl_tcp_mtu_probing");
   int sysctl_tcp_base_mss ;
    klee_make_symbolic(&sysctl_tcp_base_mss, sizeof(int), "sysctl_tcp_base_mss");
   int sysctl_tcp_probe_threshold ;
    klee_make_symbolic(&sysctl_tcp_probe_threshold, sizeof(int), "sysctl_tcp_probe_threshold");
   u32 sysctl_tcp_probe_interval ;
   struct ping_group_range ping_group_range ;
   atomic_t dev_addr_genid ;
   unsigned long *sysctl_local_reserved_ports ;
   struct list_head mr_tables ;
   struct fib_rules_ops *mr_rules_ops ;
   atomic_t rt_genid ;
};
struct neighbour;
struct dst_ops {
   unsigned short family ;
   unsigned int gc_thresh ;
    klee_make_symbolic(&gc_thresh, sizeof(int), "gc_thresh");
   int (*gc)(struct dst_ops * ) ;
   struct dst_entry *(*check)(struct dst_entry * , __u32  ) ;
   unsigned int (*default_advmss)(struct dst_entry  const  * ) ;
   unsigned int (*mtu)(struct dst_entry  const  * ) ;
   u32 *(*cow_metrics)(struct dst_entry * , unsigned long  ) ;
   void (*destroy)(struct dst_entry * ) ;
   void (*ifdown)(struct dst_entry * , struct net_device * , int  ) ;
   struct dst_entry *(*negative_advice)(struct dst_entry * ) ;
   void (*link_failure)(struct sk_buff * ) ;
   void (*update_pmtu)(struct dst_entry * , struct sock * , struct sk_buff * , u32  ) ;
   void (*redirect)(struct dst_entry * , struct sock * , struct sk_buff * ) ;
   int (*local_out)(struct sk_buff * ) ;
   struct neighbour *(*neigh_lookup)(struct dst_entry  const  * , struct sk_buff * ,
                                     void const   * ) ;
   struct kmem_cache *kmem_cachep ;
   struct percpu_counter pcpuc_entries ;
};
struct netns_sysctl_ipv6 {
   struct ctl_table_header *hdr ;
   struct ctl_table_header *route_hdr ;
   struct ctl_table_header *icmp_hdr ;
   struct ctl_table_header *frags_hdr ;
   struct ctl_table_header *xfrm6_hdr ;
   int bindv6only ;
    klee_make_symbolic(&bindv6only, sizeof(int), "bindv6only");
   int flush_delay ;
    klee_make_symbolic(&flush_delay, sizeof(int), "flush_delay");
   int ip6_rt_max_size ;
    klee_make_symbolic(&ip6_rt_max_size, sizeof(int), "ip6_rt_max_size");
   int ip6_rt_gc_min_interval ;
    klee_make_symbolic(&ip6_rt_gc_min_interval, sizeof(int), "ip6_rt_gc_min_interval");
   int ip6_rt_gc_timeout ;
    klee_make_symbolic(&ip6_rt_gc_timeout, sizeof(int), "ip6_rt_gc_timeout");
   int ip6_rt_gc_interval ;
    klee_make_symbolic(&ip6_rt_gc_interval, sizeof(int), "ip6_rt_gc_interval");
   int ip6_rt_gc_elasticity ;
    klee_make_symbolic(&ip6_rt_gc_elasticity, sizeof(int), "ip6_rt_gc_elasticity");
   int ip6_rt_mtu_expires ;
    klee_make_symbolic(&ip6_rt_mtu_expires, sizeof(int), "ip6_rt_mtu_expires");
   int ip6_rt_min_advmss ;
    klee_make_symbolic(&ip6_rt_min_advmss, sizeof(int), "ip6_rt_min_advmss");
   int flowlabel_consistency ;
    klee_make_symbolic(&flowlabel_consistency, sizeof(int), "flowlabel_consistency");
   int auto_flowlabels ;
    klee_make_symbolic(&auto_flowlabels, sizeof(int), "auto_flowlabels");
   int icmpv6_time ;
    klee_make_symbolic(&icmpv6_time, sizeof(int), "icmpv6_time");
   int anycast_src_echo_reply ;
    klee_make_symbolic(&anycast_src_echo_reply, sizeof(int), "anycast_src_echo_reply");
   int fwmark_reflect ;
    klee_make_symbolic(&fwmark_reflect, sizeof(int), "fwmark_reflect");
   int idgen_retries ;
    klee_make_symbolic(&idgen_retries, sizeof(int), "idgen_retries");
   int idgen_delay ;
    klee_make_symbolic(&idgen_delay, sizeof(int), "idgen_delay");
   int flowlabel_state_ranges ;
    klee_make_symbolic(&flowlabel_state_ranges, sizeof(int), "flowlabel_state_ranges");
};
struct ipv6_devconf;
struct rt6_info;
struct rt6_statistics;
struct fib6_table;
struct netns_ipv6 {
   struct netns_sysctl_ipv6 sysctl ;
   struct ipv6_devconf *devconf_all ;
   struct ipv6_devconf *devconf_dflt ;
   struct inet_peer_base *peers ;
   struct netns_frags frags ;
   struct xt_table *ip6table_filter ;
   struct xt_table *ip6table_mangle ;
   struct xt_table *ip6table_raw ;
   struct xt_table *ip6table_security ;
   struct xt_table *ip6table_nat ;
   struct rt6_info *ip6_null_entry ;
   struct rt6_statistics *rt6_stats ;
   struct timer_list ip6_fib_timer ;
   struct hlist_head *fib_table_hash ;
   struct fib6_table *fib6_main_tbl ;
   struct dst_ops ip6_dst_ops ;
   unsigned int ip6_rt_gc_expire ;
    klee_make_symbolic(&ip6_rt_gc_expire, sizeof(int), "ip6_rt_gc_expire");
   unsigned long ip6_rt_last_gc ;
    klee_make_symbolic(&ip6_rt_last_gc, sizeof(long), "ip6_rt_last_gc");
   struct rt6_info *ip6_prohibit_entry ;
   struct rt6_info *ip6_blk_hole_entry ;
   struct fib6_table *fib6_local_tbl ;
   struct fib_rules_ops *fib6_rules_ops ;
   struct sock **icmp_sk ;
   struct sock *ndisc_sk ;
   struct sock *tcp_sk ;
   struct sock *igmp_sk ;
   struct sock *mc_autojoin_sk ;
   struct list_head mr6_tables ;
   struct fib_rules_ops *mr6_rules_ops ;
   atomic_t dev_addr_genid ;
   atomic_t fib6_sernum ;
};
struct netns_nf_frag {
   struct netns_sysctl_ipv6 sysctl ;
   struct netns_frags frags ;
};
struct netns_sysctl_lowpan {
   struct ctl_table_header *frags_hdr ;
};
struct netns_ieee802154_lowpan {
   struct netns_sysctl_lowpan sysctl ;
   struct netns_frags frags ;
};
struct sctp_mib;
struct netns_sctp {
   struct sctp_mib *sctp_statistics ;
   struct proc_dir_entry *proc_net_sctp ;
   struct ctl_table_header *sysctl_header ;
   struct sock *ctl_sock ;
   struct list_head local_addr_list ;
   struct list_head addr_waitq ;
   struct timer_list addr_wq_timer ;
   struct list_head auto_asconf_splist ;
   spinlock_t addr_wq_lock ;
   spinlock_t local_addr_lock ;
   unsigned int rto_initial ;
    klee_make_symbolic(&rto_initial, sizeof(int), "rto_initial");
   unsigned int rto_min ;
    klee_make_symbolic(&rto_min, sizeof(int), "rto_min");
   unsigned int rto_max ;
    klee_make_symbolic(&rto_max, sizeof(int), "rto_max");
   int rto_alpha ;
    klee_make_symbolic(&rto_alpha, sizeof(int), "rto_alpha");
   int rto_beta ;
    klee_make_symbolic(&rto_beta, sizeof(int), "rto_beta");
   int max_burst ;
    klee_make_symbolic(&max_burst, sizeof(int), "max_burst");
   int cookie_preserve_enable ;
    klee_make_symbolic(&cookie_preserve_enable, sizeof(int), "cookie_preserve_enable");
   char *sctp_hmac_alg ;
   unsigned int valid_cookie_life ;
    klee_make_symbolic(&valid_cookie_life, sizeof(int), "valid_cookie_life");
   unsigned int sack_timeout ;
    klee_make_symbolic(&sack_timeout, sizeof(int), "sack_timeout");
   unsigned int hb_interval ;
    klee_make_symbolic(&hb_interval, sizeof(int), "hb_interval");
   int max_retrans_association ;
    klee_make_symbolic(&max_retrans_association, sizeof(int), "max_retrans_association");
   int max_retrans_path ;
    klee_make_symbolic(&max_retrans_path, sizeof(int), "max_retrans_path");
   int max_retrans_init ;
    klee_make_symbolic(&max_retrans_init, sizeof(int), "max_retrans_init");
   int pf_retrans ;
    klee_make_symbolic(&pf_retrans, sizeof(int), "pf_retrans");
   int sndbuf_policy ;
    klee_make_symbolic(&sndbuf_policy, sizeof(int), "sndbuf_policy");
   int rcvbuf_policy ;
    klee_make_symbolic(&rcvbuf_policy, sizeof(int), "rcvbuf_policy");
   int default_auto_asconf ;
    klee_make_symbolic(&default_auto_asconf, sizeof(int), "default_auto_asconf");
   int addip_enable ;
    klee_make_symbolic(&addip_enable, sizeof(int), "addip_enable");
   int addip_noauth ;
    klee_make_symbolic(&addip_noauth, sizeof(int), "addip_noauth");
   int prsctp_enable ;
    klee_make_symbolic(&prsctp_enable, sizeof(int), "prsctp_enable");
   int auth_enable ;
    klee_make_symbolic(&auth_enable, sizeof(int), "auth_enable");
   int scope_policy ;
    klee_make_symbolic(&scope_policy, sizeof(int), "scope_policy");
   int rwnd_upd_shift ;
    klee_make_symbolic(&rwnd_upd_shift, sizeof(int), "rwnd_upd_shift");
   unsigned long max_autoclose ;
    klee_make_symbolic(&max_autoclose, sizeof(long), "max_autoclose");
};
struct netns_dccp {
   struct sock *v4_ctl_sk ;
   struct sock *v6_ctl_sk ;
};
struct nf_logger;
struct netns_nf {
   struct proc_dir_entry *proc_netfilter ;
   struct nf_logger  const  *nf_loggers[13U] ;
   struct ctl_table_header *nf_log_dir_header ;
};
struct ebt_table;
struct netns_xt {
   struct list_head tables[13U] ;
   bool notrack_deprecated_warning ;
   bool clusterip_deprecated_warning ;
   struct ebt_table *broute_table ;
   struct ebt_table *frame_filter ;
   struct ebt_table *frame_nat ;
};
struct hlist_nulls_node;
struct hlist_nulls_head {
   struct hlist_nulls_node *first ;
};
struct hlist_nulls_node {
   struct hlist_nulls_node *next ;
   struct hlist_nulls_node **pprev ;
};
struct nf_proto_net {
   struct ctl_table_header *ctl_table_header ;
   struct ctl_table *ctl_table ;
   struct ctl_table_header *ctl_compat_header ;
   struct ctl_table *ctl_compat_table ;
   unsigned int users ;
    klee_make_symbolic(&users, sizeof(int), "users");
};
struct nf_generic_net {
   struct nf_proto_net pn ;
   unsigned int timeout ;
};
struct nf_tcp_net {
   struct nf_proto_net pn ;
   unsigned int timeouts[14U] ;
   unsigned int tcp_loose ;
    klee_make_symbolic(&tcp_loose, sizeof(int), "tcp_loose");
   unsigned int tcp_be_liberal ;
    klee_make_symbolic(&tcp_be_liberal, sizeof(int), "tcp_be_liberal");
   unsigned int tcp_max_retrans ;
    klee_make_symbolic(&tcp_max_retrans, sizeof(int), "tcp_max_retrans");
};
struct nf_udp_net {
   struct nf_proto_net pn ;
   unsigned int timeouts[2U] ;
};
struct nf_icmp_net {
   struct nf_proto_net pn ;
   unsigned int timeout ;
};
struct nf_ip_net {
   struct nf_generic_net generic ;
   struct nf_tcp_net tcp ;
   struct nf_udp_net udp ;
   struct nf_icmp_net icmp ;
   struct nf_icmp_net icmpv6 ;
   struct ctl_table_header *ctl_table_header ;
   struct ctl_table *ctl_table ;
};
struct ct_pcpu {
   spinlock_t lock ;
   struct hlist_nulls_head unconfirmed ;
   struct hlist_nulls_head dying ;
   struct hlist_nulls_head tmpl ;
};
struct ip_conntrack_stat;
struct nf_ct_event_notifier;
struct nf_exp_event_notifier;
struct netns_ct {
   atomic_t count ;
   unsigned int expect_count ;
    klee_make_symbolic(&expect_count, sizeof(int), "expect_count");
   struct delayed_work ecache_dwork ;
   bool ecache_dwork_pending ;
   struct ctl_table_header *sysctl_header ;
   struct ctl_table_header *acct_sysctl_header ;
   struct ctl_table_header *tstamp_sysctl_header ;
   struct ctl_table_header *event_sysctl_header ;
   struct ctl_table_header *helper_sysctl_header ;
   char *slabname ;
   unsigned int sysctl_log_invalid ;
    klee_make_symbolic(&sysctl_log_invalid, sizeof(int), "sysctl_log_invalid");
   int sysctl_events ;
    klee_make_symbolic(&sysctl_events, sizeof(int), "sysctl_events");
   int sysctl_acct ;
    klee_make_symbolic(&sysctl_acct, sizeof(int), "sysctl_acct");
   int sysctl_auto_assign_helper ;
    klee_make_symbolic(&sysctl_auto_assign_helper, sizeof(int), "sysctl_auto_assign_helper");
   bool auto_assign_helper_warned ;
   int sysctl_tstamp ;
    klee_make_symbolic(&sysctl_tstamp, sizeof(int), "sysctl_tstamp");
   int sysctl_checksum ;
    klee_make_symbolic(&sysctl_checksum, sizeof(int), "sysctl_checksum");
   unsigned int htable_size ;
    klee_make_symbolic(&htable_size, sizeof(int), "htable_size");
   seqcount_t generation ;
   struct kmem_cache *nf_conntrack_cachep ;
   struct hlist_nulls_head *hash ;
   struct hlist_head *expect_hash ;
   struct ct_pcpu *pcpu_lists ;
   struct ip_conntrack_stat *stat ;
   struct nf_ct_event_notifier *nf_conntrack_event_cb ;
   struct nf_exp_event_notifier *nf_expect_event_cb ;
   struct nf_ip_net nf_ct_proto ;
   unsigned int labels_used ;
    klee_make_symbolic(&labels_used, sizeof(int), "labels_used");
   u8 label_words ;
   struct hlist_head *nat_bysource ;
   unsigned int nat_htable_size ;
    klee_make_symbolic(&nat_htable_size, sizeof(int), "nat_htable_size");
};
struct nft_af_info;
struct netns_nftables {
   struct list_head af_info ;
   struct list_head commit_list ;
   struct nft_af_info *ipv4 ;
   struct nft_af_info *ipv6 ;
   struct nft_af_info *inet ;
   struct nft_af_info *arp ;
   struct nft_af_info *bridge ;
   struct nft_af_info *netdev ;
   unsigned int base_seq ;
    klee_make_symbolic(&base_seq, sizeof(int), "base_seq");
   u8 gencursor ;
};
enum irqreturn {
    IRQ_NONE = 0,
    IRQ_HANDLED = 1,
    IRQ_WAKE_THREAD = 2
} ;
typedef enum irqreturn irqreturn_t;
struct tasklet_struct {
   struct tasklet_struct *next ;
   unsigned long state ;
   atomic_t count ;
   void (*func)(unsigned long  ) ;
   unsigned long data ;
};
struct flow_cache_percpu {
   struct hlist_head *hash_table ;
   int hash_count ;
    klee_make_symbolic(&hash_count, sizeof(int), "hash_count");
   u32 hash_rnd ;
   int hash_rnd_recalc ;
    klee_make_symbolic(&hash_rnd_recalc, sizeof(int), "hash_rnd_recalc");
   struct tasklet_struct flush_tasklet ;
};
struct flow_cache {
   u32 hash_shift ;
   struct flow_cache_percpu *percpu ;
   struct notifier_block hotcpu_notifier ;
   int low_watermark ;
    klee_make_symbolic(&low_watermark, sizeof(int), "low_watermark");
   int high_watermark ;
    klee_make_symbolic(&high_watermark, sizeof(int), "high_watermark");
   struct timer_list rnd_timer ;
};
struct xfrm_policy_hash {
   struct hlist_head *table ;
   unsigned int hmask ;
    klee_make_symbolic(&hmask, sizeof(int), "hmask");
   u8 dbits4 ;
   u8 sbits4 ;
   u8 dbits6 ;
   u8 sbits6 ;
};
struct xfrm_policy_hthresh {
   struct work_struct work ;
   seqlock_t lock ;
   u8 lbits4 ;
   u8 rbits4 ;
   u8 lbits6 ;
   u8 rbits6 ;
};
struct netns_xfrm {
   struct list_head state_all ;
   struct hlist_head *state_bydst ;
   struct hlist_head *state_bysrc ;
   struct hlist_head *state_byspi ;
   unsigned int state_hmask ;
    klee_make_symbolic(&state_hmask, sizeof(int), "state_hmask");
   unsigned int state_num ;
    klee_make_symbolic(&state_num, sizeof(int), "state_num");
   struct work_struct state_hash_work ;
   struct hlist_head state_gc_list ;
   struct work_struct state_gc_work ;
   struct list_head policy_all ;
   struct hlist_head *policy_byidx ;
   unsigned int policy_idx_hmask ;
    klee_make_symbolic(&policy_idx_hmask, sizeof(int), "policy_idx_hmask");
   struct hlist_head policy_inexact[3U] ;
   struct xfrm_policy_hash policy_bydst[3U] ;
   unsigned int policy_count[6U] ;
   struct work_struct policy_hash_work ;
   struct xfrm_policy_hthresh policy_hthresh ;
   struct sock *nlsk ;
   struct sock *nlsk_stash ;
   u32 sysctl_aevent_etime ;
   u32 sysctl_aevent_rseqth ;
   int sysctl_larval_drop ;
    klee_make_symbolic(&sysctl_larval_drop, sizeof(int), "sysctl_larval_drop");
   u32 sysctl_acq_expires ;
   struct ctl_table_header *sysctl_hdr ;
   struct dst_ops xfrm4_dst_ops ;
   struct dst_ops xfrm6_dst_ops ;
   spinlock_t xfrm_state_lock ;
   rwlock_t xfrm_policy_lock ;
   struct mutex xfrm_cfg_mutex ;
   struct flow_cache flow_cache_global ;
   atomic_t flow_cache_genid ;
   struct list_head flow_cache_gc_list ;
   spinlock_t flow_cache_gc_lock ;
   struct work_struct flow_cache_gc_work ;
   struct work_struct flow_cache_flush_work ;
   struct mutex flow_flush_sem ;
};
struct mpls_route;
struct netns_mpls {
   size_t platform_labels ;
   struct mpls_route **platform_label ;
   struct ctl_table_header *ctl ;
};
struct proc_ns_operations;
struct ns_common {
   atomic_long_t stashed ;
   struct proc_ns_operations  const  *ops ;
   unsigned int inum ;
    klee_make_symbolic(&inum, sizeof(int), "inum");
};
struct net_generic;
struct netns_ipvs;
struct net {
   atomic_t passive ;
   atomic_t count ;
   spinlock_t rules_mod_lock ;
   atomic64_t cookie_gen ;
   struct list_head list ;
   struct list_head cleanup_list ;
   struct list_head exit_list ;
   struct user_namespace *user_ns ;
   spinlock_t nsid_lock ;
   struct idr netns_ids ;
   struct ns_common ns ;
   struct proc_dir_entry *proc_net ;
   struct proc_dir_entry *proc_net_stat ;
   struct ctl_table_set sysctls ;
   struct sock *rtnl ;
   struct sock *genl_sock ;
   struct list_head dev_base_head ;
   struct hlist_head *dev_name_head ;
   struct hlist_head *dev_index_head ;
   unsigned int dev_base_seq ;
    klee_make_symbolic(&dev_base_seq, sizeof(int), "dev_base_seq");
   int ifindex ;
    klee_make_symbolic(&ifindex, sizeof(int), "ifindex");
   unsigned int dev_unreg_count ;
    klee_make_symbolic(&dev_unreg_count, sizeof(int), "dev_unreg_count");
   struct list_head rules_ops ;
   struct net_device *loopback_dev ;
   struct netns_core core ;
   struct netns_mib mib ;
   struct netns_packet packet ;
   struct netns_unix unx ;
   struct netns_ipv4 ipv4 ;
   struct netns_ipv6 ipv6 ;
   struct netns_ieee802154_lowpan ieee802154_lowpan ;
   struct netns_sctp sctp ;
   struct netns_dccp dccp ;
   struct netns_nf nf ;
   struct netns_xt xt ;
   struct netns_ct ct ;
   struct netns_nftables nft ;
   struct netns_nf_frag nf_frag ;
   struct sock *nfnl ;
   struct sock *nfnl_stash ;
   struct sk_buff_head wext_nlevents ;
   struct net_generic *gen ;
   struct netns_xfrm xfrm ;
   struct netns_ipvs *ipvs ;
   struct netns_mpls mpls ;
   struct sock *diag_nlsk ;
   atomic_t fnhe_genid ;
};
struct __anonstruct_possible_net_t_306 {
   struct net *net ;
};
typedef struct __anonstruct_possible_net_t_306 possible_net_t;
enum fwnode_type {
    FWNODE_INVALID = 0,
    FWNODE_OF = 1,
    FWNODE_ACPI = 2,
    FWNODE_PDATA = 3
} ;
struct fwnode_handle {
   enum fwnode_type type ;
   struct fwnode_handle *secondary ;
};
typedef u32 phandle;
struct property {
   char *name ;
   int length ;
   void *value ;
   struct property *next ;
   unsigned long _flags ;
    klee_make_symbolic(&_flags, sizeof(long), "_flags");
   unsigned int unique_id ;
    klee_make_symbolic(&unique_id, sizeof(int), "unique_id");
   struct bin_attribute attr ;
};
struct device_node {
   char const   *name ;
   char const   *type ;
   phandle phandle ;
   char const   *full_name ;
   struct fwnode_handle fwnode ;
   struct property *properties ;
   struct property *deadprops ;
   struct device_node *parent ;
   struct device_node *child ;
   struct device_node *sibling ;
   struct kobject kobj ;
   unsigned long _flags ;
   void *data ;
};
struct mii_ioctl_data {
   __u16 phy_id ;
   __u16 reg_num ;
   __u16 val_in ;
   __u16 val_out ;
};
enum ldv_28775 {
    PHY_INTERFACE_MODE_NA = 0,
    PHY_INTERFACE_MODE_MII = 1,
    PHY_INTERFACE_MODE_GMII = 2,
    PHY_INTERFACE_MODE_SGMII = 3,
    PHY_INTERFACE_MODE_TBI = 4,
    PHY_INTERFACE_MODE_REVMII = 5,
    PHY_INTERFACE_MODE_RMII = 6,
    PHY_INTERFACE_MODE_RGMII = 7,
    PHY_INTERFACE_MODE_RGMII_ID = 8,
    PHY_INTERFACE_MODE_RGMII_RXID = 9,
    PHY_INTERFACE_MODE_RGMII_TXID = 10,
    PHY_INTERFACE_MODE_RTBI = 11,
    PHY_INTERFACE_MODE_SMII = 12,
    PHY_INTERFACE_MODE_XGMII = 13,
    PHY_INTERFACE_MODE_MOCA = 14,
    PHY_INTERFACE_MODE_QSGMII = 15,
    PHY_INTERFACE_MODE_MAX = 16
} ;
typedef enum ldv_28775 phy_interface_t;
enum ldv_28829 {
    MDIOBUS_ALLOCATED = 1,
    MDIOBUS_REGISTERED = 2,
    MDIOBUS_UNREGISTERED = 3,
    MDIOBUS_RELEASED = 4
} ;
struct phy_device;
struct mii_bus {
   char const   *name ;
   char id[17U] ;
   void *priv ;
   int (*read)(struct mii_bus * , int  , int  ) ;
   int (*write)(struct mii_bus * , int  , int  , u16  ) ;
   int (*reset)(struct mii_bus * ) ;
   struct mutex mdio_lock ;
   struct device *parent ;
   enum ldv_28829 state ;
   struct device dev ;
   struct phy_device *phy_map[32U] ;
   u32 phy_mask ;
   u32 phy_ignore_ta_mask ;
   int *irq ;
};
enum phy_state {
    PHY_DOWN = 0,
    PHY_STARTING = 1,
    PHY_READY = 2,
    PHY_PENDING = 3,
    PHY_UP = 4,
    PHY_AN = 5,
    PHY_RUNNING = 6,
    PHY_NOLINK = 7,
    PHY_FORCING = 8,
    PHY_CHANGELINK = 9,
    PHY_HALTED = 10,
    PHY_RESUMING = 11
} ;
struct phy_c45_device_ids {
   u32 devices_in_package ;
   u32 device_ids[8U] ;
};
struct phy_driver;
struct phy_device {
   struct phy_driver *drv ;
   struct mii_bus *bus ;
   struct device dev ;
   u32 phy_id ;
   struct phy_c45_device_ids c45_ids ;
   bool is_c45 ;
   bool is_internal ;
   bool has_fixups ;
   bool suspended ;
   enum phy_state state ;
   u32 dev_flags ;
   phy_interface_t interface ;
   int addr ;
    klee_make_symbolic(&addr, sizeof(int), "addr");
   int speed ;
    klee_make_symbolic(&speed, sizeof(int), "speed");
   int duplex ;
    klee_make_symbolic(&duplex, sizeof(int), "duplex");
   int pause ;
    klee_make_symbolic(&pause, sizeof(int), "pause");
   int asym_pause ;
    klee_make_symbolic(&asym_pause, sizeof(int), "asym_pause");
   int link ;
    klee_make_symbolic(&link, sizeof(int), "link");
   u32 interrupts ;
   u32 supported ;
   u32 advertising ;
   u32 lp_advertising ;
   int autoneg ;
    klee_make_symbolic(&autoneg, sizeof(int), "autoneg");
   int link_timeout ;
    klee_make_symbolic(&link_timeout, sizeof(int), "link_timeout");
   int irq ;
   void *priv ;
   struct work_struct phy_queue ;
   struct delayed_work state_queue ;
   atomic_t irq_disable ;
   struct mutex lock ;
   struct net_device *attached_dev ;
   void (*adjust_link)(struct net_device * ) ;
};
struct phy_driver {
   u32 phy_id ;
   char *name ;
   unsigned int phy_id_mask ;
    klee_make_symbolic(&phy_id_mask, sizeof(int), "phy_id_mask");
   u32 features ;
   u32 flags ;
   void const   *driver_data ;
   int (*soft_reset)(struct phy_device * ) ;
   int (*config_init)(struct phy_device * ) ;
   int (*probe)(struct phy_device * ) ;
   int (*suspend)(struct phy_device * ) ;
   int (*resume)(struct phy_device * ) ;
   int (*config_aneg)(struct phy_device * ) ;
   int (*aneg_done)(struct phy_device * ) ;
   int (*read_status)(struct phy_device * ) ;
   int (*ack_interrupt)(struct phy_device * ) ;
   int (*config_intr)(struct phy_device * ) ;
   int (*did_interrupt)(struct phy_device * ) ;
   void (*remove)(struct phy_device * ) ;
   int (*match_phy_device)(struct phy_device * ) ;
   int (*ts_info)(struct phy_device * , struct ethtool_ts_info * ) ;
   int (*hwtstamp)(struct phy_device * , struct ifreq * ) ;
   bool (*rxtstamp)(struct phy_device * , struct sk_buff * , int  ) ;
   void (*txtstamp)(struct phy_device * , struct sk_buff * , int  ) ;
   int (*set_wol)(struct phy_device * , struct ethtool_wolinfo * ) ;
   void (*get_wol)(struct phy_device * , struct ethtool_wolinfo * ) ;
   void (*link_change_notify)(struct phy_device * ) ;
   int (*read_mmd_indirect)(struct phy_device * , int  , int  , int  ) ;
   void (*write_mmd_indirect)(struct phy_device * , int  , int  , int  , u32  ) ;
   int (*module_info)(struct phy_device * , struct ethtool_modinfo * ) ;
   int (*module_eeprom)(struct phy_device * , struct ethtool_eeprom * , u8 * ) ;
   struct device_driver driver ;
};
struct fixed_phy_status {
   int link ;
   int speed ;
   int duplex ;
   int pause ;
   int asym_pause ;
};
enum dsa_tag_protocol {
    DSA_TAG_PROTO_NONE = 0,
    DSA_TAG_PROTO_DSA = 1,
    DSA_TAG_PROTO_TRAILER = 2,
    DSA_TAG_PROTO_EDSA = 3,
    DSA_TAG_PROTO_BRCM = 4
} ;
struct dsa_chip_data {
   struct device *host_dev ;
   int sw_addr ;
    klee_make_symbolic(&sw_addr, sizeof(int), "sw_addr");
   int eeprom_len ;
    klee_make_symbolic(&eeprom_len, sizeof(int), "eeprom_len");
   struct device_node *of_node ;
   char *port_names[12U] ;
   struct device_node *port_dn[12U] ;
   s8 *rtable ;
};
struct dsa_platform_data {
   struct device *netdev ;
   struct net_device *of_netdev ;
   int nr_chips ;
    klee_make_symbolic(&nr_chips, sizeof(int), "nr_chips");
   struct dsa_chip_data *chip ;
};
struct packet_type;
struct dsa_switch;
struct dsa_switch_tree {
   struct dsa_platform_data *pd ;
   struct net_device *master_netdev ;
   int (*rcv)(struct sk_buff * , struct net_device * , struct packet_type * , struct net_device * ) ;
   enum dsa_tag_protocol tag_protocol ;
   s8 cpu_switch ;
   s8 cpu_port ;
   int link_poll_needed ;
    klee_make_symbolic(&link_poll_needed, sizeof(int), "link_poll_needed");
   struct work_struct link_poll_work ;
   struct timer_list link_poll_timer ;
   struct dsa_switch *ds[4U] ;
};
struct dsa_switch_driver;
struct dsa_switch {
   struct dsa_switch_tree *dst ;
   int index ;
   enum dsa_tag_protocol tag_protocol ;
   struct dsa_chip_data *pd ;
   struct dsa_switch_driver *drv ;
   struct device *master_dev ;
   char hwmon_name[24U] ;
   struct device *hwmon_dev ;
   u32 dsa_port_mask ;
   u32 phys_port_mask ;
   u32 phys_mii_mask ;
   struct mii_bus *slave_mii_bus ;
   struct net_device *ports[12U] ;
};
struct dsa_switch_driver {
   struct list_head list ;
   enum dsa_tag_protocol tag_protocol ;
   int priv_size ;
    klee_make_symbolic(&priv_size, sizeof(int), "priv_size");
   char *(*probe)(struct device * , int  ) ;
   int (*setup)(struct dsa_switch * ) ;
   int (*set_addr)(struct dsa_switch * , u8 * ) ;
   u32 (*get_phy_flags)(struct dsa_switch * , int  ) ;
   int (*phy_read)(struct dsa_switch * , int  , int  ) ;
   int (*phy_write)(struct dsa_switch * , int  , int  , u16  ) ;
   void (*poll_link)(struct dsa_switch * ) ;
   void (*adjust_link)(struct dsa_switch * , int  , struct phy_device * ) ;
   void (*fixed_link_update)(struct dsa_switch * , int  , struct fixed_phy_status * ) ;
   void (*get_strings)(struct dsa_switch * , int  , uint8_t * ) ;
   void (*get_ethtool_stats)(struct dsa_switch * , int  , uint64_t * ) ;
   int (*get_sset_count)(struct dsa_switch * ) ;
   void (*get_wol)(struct dsa_switch * , int  , struct ethtool_wolinfo * ) ;
   int (*set_wol)(struct dsa_switch * , int  , struct ethtool_wolinfo * ) ;
   int (*suspend)(struct dsa_switch * ) ;
   int (*resume)(struct dsa_switch * ) ;
   int (*port_enable)(struct dsa_switch * , int  , struct phy_device * ) ;
   void (*port_disable)(struct dsa_switch * , int  , struct phy_device * ) ;
   int (*set_eee)(struct dsa_switch * , int  , struct phy_device * , struct ethtool_eee * ) ;
   int (*get_eee)(struct dsa_switch * , int  , struct ethtool_eee * ) ;
   int (*get_temp)(struct dsa_switch * , int * ) ;
   int (*get_temp_limit)(struct dsa_switch * , int * ) ;
   int (*set_temp_limit)(struct dsa_switch * , int  ) ;
   int (*get_temp_alarm)(struct dsa_switch * , bool * ) ;
   int (*get_eeprom_len)(struct dsa_switch * ) ;
   int (*get_eeprom)(struct dsa_switch * , struct ethtool_eeprom * , u8 * ) ;
   int (*set_eeprom)(struct dsa_switch * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_regs_len)(struct dsa_switch * , int  ) ;
   void (*get_regs)(struct dsa_switch * , int  , struct ethtool_regs * , void * ) ;
   int (*port_join_bridge)(struct dsa_switch * , int  , u32  ) ;
   int (*port_leave_bridge)(struct dsa_switch * , int  , u32  ) ;
   int (*port_stp_update)(struct dsa_switch * , int  , u8  ) ;
   int (*fdb_add)(struct dsa_switch * , int  , unsigned char const   * , u16  ) ;
   int (*fdb_del)(struct dsa_switch * , int  , unsigned char const   * , u16  ) ;
   int (*fdb_getnext)(struct dsa_switch * , int  , unsigned char * , bool * ) ;
};
struct ieee_ets {
   __u8 willing ;
   __u8 ets_cap ;
   __u8 cbs ;
   __u8 tc_tx_bw[8U] ;
   __u8 tc_rx_bw[8U] ;
   __u8 tc_tsa[8U] ;
   __u8 prio_tc[8U] ;
   __u8 tc_reco_bw[8U] ;
   __u8 tc_reco_tsa[8U] ;
   __u8 reco_prio_tc[8U] ;
};
struct ieee_maxrate {
   __u64 tc_maxrate[8U] ;
};
struct ieee_qcn {
   __u8 rpg_enable[8U] ;
   __u32 rppp_max_rps[8U] ;
   __u32 rpg_time_reset[8U] ;
   __u32 rpg_byte_reset[8U] ;
   __u32 rpg_threshold[8U] ;
   __u32 rpg_max_rate[8U] ;
   __u32 rpg_ai_rate[8U] ;
   __u32 rpg_hai_rate[8U] ;
   __u32 rpg_gd[8U] ;
   __u32 rpg_min_dec_fac[8U] ;
   __u32 rpg_min_rate[8U] ;
   __u32 cndd_state_machine[8U] ;
};
struct ieee_qcn_stats {
   __u64 rppp_rp_centiseconds[8U] ;
   __u32 rppp_created_rps[8U] ;
};
struct ieee_pfc {
   __u8 pfc_cap ;
   __u8 pfc_en ;
   __u8 mbc ;
   __u16 delay ;
   __u64 requests[8U] ;
   __u64 indications[8U] ;
};
struct cee_pg {
   __u8 willing ;
   __u8 error ;
   __u8 pg_en ;
   __u8 tcs_supported ;
   __u8 pg_bw[8U] ;
   __u8 prio_pg[8U] ;
};
struct cee_pfc {
   __u8 willing ;
   __u8 error ;
   __u8 pfc_en ;
   __u8 tcs_supported ;
};
struct dcb_app {
   __u8 selector ;
   __u8 priority ;
   __u16 protocol ;
};
struct dcb_peer_app_info {
   __u8 willing ;
   __u8 error ;
};
struct dcbnl_rtnl_ops {
   int (*ieee_getets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_setets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_getmaxrate)(struct net_device * , struct ieee_maxrate * ) ;
   int (*ieee_setmaxrate)(struct net_device * , struct ieee_maxrate * ) ;
   int (*ieee_getqcn)(struct net_device * , struct ieee_qcn * ) ;
   int (*ieee_setqcn)(struct net_device * , struct ieee_qcn * ) ;
   int (*ieee_getqcnstats)(struct net_device * , struct ieee_qcn_stats * ) ;
   int (*ieee_getpfc)(struct net_device * , struct ieee_pfc * ) ;
   int (*ieee_setpfc)(struct net_device * , struct ieee_pfc * ) ;
   int (*ieee_getapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_setapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_delapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_peer_getets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_peer_getpfc)(struct net_device * , struct ieee_pfc * ) ;
   u8 (*getstate)(struct net_device * ) ;
   u8 (*setstate)(struct net_device * , u8  ) ;
   void (*getpermhwaddr)(struct net_device * , u8 * ) ;
   void (*setpgtccfgtx)(struct net_device * , int  , u8  , u8  , u8  , u8  ) ;
   void (*setpgbwgcfgtx)(struct net_device * , int  , u8  ) ;
   void (*setpgtccfgrx)(struct net_device * , int  , u8  , u8  , u8  , u8  ) ;
   void (*setpgbwgcfgrx)(struct net_device * , int  , u8  ) ;
   void (*getpgtccfgtx)(struct net_device * , int  , u8 * , u8 * , u8 * , u8 * ) ;
   void (*getpgbwgcfgtx)(struct net_device * , int  , u8 * ) ;
   void (*getpgtccfgrx)(struct net_device * , int  , u8 * , u8 * , u8 * , u8 * ) ;
   void (*getpgbwgcfgrx)(struct net_device * , int  , u8 * ) ;
   void (*setpfccfg)(struct net_device * , int  , u8  ) ;
   void (*getpfccfg)(struct net_device * , int  , u8 * ) ;
   u8 (*setall)(struct net_device * ) ;
   u8 (*getcap)(struct net_device * , int  , u8 * ) ;
   int (*getnumtcs)(struct net_device * , int  , u8 * ) ;
   int (*setnumtcs)(struct net_device * , int  , u8  ) ;
   u8 (*getpfcstate)(struct net_device * ) ;
   void (*setpfcstate)(struct net_device * , u8  ) ;
   void (*getbcncfg)(struct net_device * , int  , u32 * ) ;
   void (*setbcncfg)(struct net_device * , int  , u32  ) ;
   void (*getbcnrp)(struct net_device * , int  , u8 * ) ;
   void (*setbcnrp)(struct net_device * , int  , u8  ) ;
   int (*setapp)(struct net_device * , u8  , u16  , u8  ) ;
   int (*getapp)(struct net_device * , u8  , u16  ) ;
   u8 (*getfeatcfg)(struct net_device * , int  , u8 * ) ;
   u8 (*setfeatcfg)(struct net_device * , int  , u8  ) ;
   u8 (*getdcbx)(struct net_device * ) ;
   u8 (*setdcbx)(struct net_device * , u8  ) ;
   int (*peer_getappinfo)(struct net_device * , struct dcb_peer_app_info * , u16 * ) ;
   int (*peer_getapptable)(struct net_device * , struct dcb_app * ) ;
   int (*cee_peer_getpg)(struct net_device * , struct cee_pg * ) ;
   int (*cee_peer_getpfc)(struct net_device * , struct cee_pfc * ) ;
};
struct taskstats {
   __u16 version ;
   __u32 ac_exitcode ;
   __u8 ac_flag ;
   __u8 ac_nice ;
   __u64 cpu_count ;
   __u64 cpu_delay_total ;
   __u64 blkio_count ;
   __u64 blkio_delay_total ;
   __u64 swapin_count ;
   __u64 swapin_delay_total ;
   __u64 cpu_run_real_total ;
   __u64 cpu_run_virtual_total ;
   char ac_comm[32U] ;
   __u8 ac_sched ;
   __u8 ac_pad[3U] ;
   __u32 ac_uid ;
   __u32 ac_gid ;
   __u32 ac_pid ;
   __u32 ac_ppid ;
   __u32 ac_btime ;
   __u64 ac_etime ;
   __u64 ac_utime ;
   __u64 ac_stime ;
   __u64 ac_minflt ;
   __u64 ac_majflt ;
   __u64 coremem ;
   __u64 virtmem ;
   __u64 hiwater_rss ;
   __u64 hiwater_vm ;
   __u64 read_char ;
   __u64 write_char ;
   __u64 read_syscalls ;
   __u64 write_syscalls ;
   __u64 read_bytes ;
   __u64 write_bytes ;
   __u64 cancelled_write_bytes ;
   __u64 nvcsw ;
   __u64 nivcsw ;
   __u64 ac_utimescaled ;
   __u64 ac_stimescaled ;
   __u64 cpu_scaled_run_real_total ;
   __u64 freepages_count ;
   __u64 freepages_delay_total ;
};
struct netprio_map {
   struct callback_head rcu ;
   u32 priomap_len ;
   u32 priomap[] ;
};
struct xfrm_policy;
struct xfrm_state;
struct request_sock;
struct mnt_namespace;
struct ipc_namespace;
struct nsproxy {
   atomic_t count ;
   struct uts_namespace *uts_ns ;
   struct ipc_namespace *ipc_ns ;
   struct mnt_namespace *mnt_ns ;
   struct pid_namespace *pid_ns_for_children ;
   struct net *net_ns ;
};
struct nlmsghdr {
   __u32 nlmsg_len ;
   __u16 nlmsg_type ;
   __u16 nlmsg_flags ;
   __u32 nlmsg_seq ;
   __u32 nlmsg_pid ;
};
struct nlattr {
   __u16 nla_len ;
   __u16 nla_type ;
};
struct netlink_callback {
   struct sk_buff *skb ;
   struct nlmsghdr  const  *nlh ;
   int (*dump)(struct sk_buff * , struct netlink_callback * ) ;
   int (*done)(struct netlink_callback * ) ;
   void *data ;
   struct module *module ;
   u16 family ;
   u16 min_dump_alloc ;
   unsigned int prev_seq ;
    klee_make_symbolic(&prev_seq, sizeof(int), "prev_seq");
   unsigned int seq ;
    klee_make_symbolic(&seq, sizeof(int), "seq");
   long args[6U] ;
};
struct ndmsg {
   __u8 ndm_family ;
   __u8 ndm_pad1 ;
   __u16 ndm_pad2 ;
   __s32 ndm_ifindex ;
   __u16 ndm_state ;
   __u8 ndm_flags ;
   __u8 ndm_type ;
};
struct rtnl_link_stats64 {
   __u64 rx_packets ;
   __u64 tx_packets ;
   __u64 rx_bytes ;
   __u64 tx_bytes ;
   __u64 rx_errors ;
   __u64 tx_errors ;
   __u64 rx_dropped ;
   __u64 tx_dropped ;
   __u64 multicast ;
   __u64 collisions ;
   __u64 rx_length_errors ;
   __u64 rx_over_errors ;
   __u64 rx_crc_errors ;
   __u64 rx_frame_errors ;
   __u64 rx_fifo_errors ;
   __u64 rx_missed_errors ;
   __u64 tx_aborted_errors ;
   __u64 tx_carrier_errors ;
   __u64 tx_fifo_errors ;
   __u64 tx_heartbeat_errors ;
   __u64 tx_window_errors ;
   __u64 rx_compressed ;
   __u64 tx_compressed ;
};
struct ifla_vf_stats {
   __u64 rx_packets ;
   __u64 tx_packets ;
   __u64 rx_bytes ;
   __u64 tx_bytes ;
   __u64 broadcast ;
   __u64 multicast ;
};
struct ifla_vf_info {
   __u32 vf ;
   __u8 mac[32U] ;
   __u32 vlan ;
   __u32 qos ;
   __u32 spoofchk ;
   __u32 linkstate ;
   __u32 min_tx_rate ;
   __u32 max_tx_rate ;
   __u32 rss_query_en ;
};
struct netpoll_info;
struct wireless_dev;
struct wpan_dev;
struct mpls_dev;
enum netdev_tx {
    __NETDEV_TX_MIN = (-0x7FFFFFFF-1),
    NETDEV_TX_OK = 0,
    NETDEV_TX_BUSY = 16,
    NETDEV_TX_LOCKED = 32
} ;
typedef enum netdev_tx netdev_tx_t;
struct net_device_stats {
   unsigned long rx_packets ;
    klee_make_symbolic(&rx_packets, sizeof(long), "rx_packets");
   unsigned long tx_packets ;
    klee_make_symbolic(&tx_packets, sizeof(long), "tx_packets");
   unsigned long rx_bytes ;
    klee_make_symbolic(&rx_bytes, sizeof(long), "rx_bytes");
   unsigned long tx_bytes ;
    klee_make_symbolic(&tx_bytes, sizeof(long), "tx_bytes");
   unsigned long rx_errors ;
    klee_make_symbolic(&rx_errors, sizeof(long), "rx_errors");
   unsigned long tx_errors ;
    klee_make_symbolic(&tx_errors, sizeof(long), "tx_errors");
   unsigned long rx_dropped ;
    klee_make_symbolic(&rx_dropped, sizeof(long), "rx_dropped");
   unsigned long tx_dropped ;
    klee_make_symbolic(&tx_dropped, sizeof(long), "tx_dropped");
   unsigned long multicast ;
    klee_make_symbolic(&multicast, sizeof(long), "multicast");
   unsigned long collisions ;
    klee_make_symbolic(&collisions, sizeof(long), "collisions");
   unsigned long rx_length_errors ;
    klee_make_symbolic(&rx_length_errors, sizeof(long), "rx_length_errors");
   unsigned long rx_over_errors ;
    klee_make_symbolic(&rx_over_errors, sizeof(long), "rx_over_errors");
   unsigned long rx_crc_errors ;
    klee_make_symbolic(&rx_crc_errors, sizeof(long), "rx_crc_errors");
   unsigned long rx_frame_errors ;
    klee_make_symbolic(&rx_frame_errors, sizeof(long), "rx_frame_errors");
   unsigned long rx_fifo_errors ;
    klee_make_symbolic(&rx_fifo_errors, sizeof(long), "rx_fifo_errors");
   unsigned long rx_missed_errors ;
    klee_make_symbolic(&rx_missed_errors, sizeof(long), "rx_missed_errors");
   unsigned long tx_aborted_errors ;
    klee_make_symbolic(&tx_aborted_errors, sizeof(long), "tx_aborted_errors");
   unsigned long tx_carrier_errors ;
    klee_make_symbolic(&tx_carrier_errors, sizeof(long), "tx_carrier_errors");
   unsigned long tx_fifo_errors ;
    klee_make_symbolic(&tx_fifo_errors, sizeof(long), "tx_fifo_errors");
   unsigned long tx_heartbeat_errors ;
    klee_make_symbolic(&tx_heartbeat_errors, sizeof(long), "tx_heartbeat_errors");
   unsigned long tx_window_errors ;
    klee_make_symbolic(&tx_window_errors, sizeof(long), "tx_window_errors");
   unsigned long rx_compressed ;
    klee_make_symbolic(&rx_compressed, sizeof(long), "rx_compressed");
   unsigned long tx_compressed ;
    klee_make_symbolic(&tx_compressed, sizeof(long), "tx_compressed");
};
struct neigh_parms;
struct netdev_hw_addr_list {
   struct list_head list ;
   int count ;
};
struct hh_cache {
   u16 hh_len ;
   u16 __pad ;
   seqlock_t hh_lock ;
   unsigned long hh_data[16U] ;
};
struct header_ops {
   int (*create)(struct sk_buff * , struct net_device * , unsigned short  , void const   * ,
                 void const   * , unsigned int  ) ;
   int (*parse)(struct sk_buff  const  * , unsigned char * ) ;
   int (*cache)(struct neighbour  const  * , struct hh_cache * , __be16  ) ;
   void (*cache_update)(struct hh_cache * , struct net_device  const  * , unsigned char const   * ) ;
};
struct napi_struct {
   struct list_head poll_list ;
   unsigned long state ;
   int weight ;
   unsigned int gro_count ;
    klee_make_symbolic(&gro_count, sizeof(int), "gro_count");
   int (*poll)(struct napi_struct * , int  ) ;
   spinlock_t poll_lock ;
   int poll_owner ;
    klee_make_symbolic(&poll_owner, sizeof(int), "poll_owner");
   struct net_device *dev ;
   struct sk_buff *gro_list ;
   struct sk_buff *skb ;
   struct hrtimer timer ;
   struct list_head dev_list ;
   struct hlist_node napi_hash_node ;
   unsigned int napi_id ;
};
enum rx_handler_result {
    RX_HANDLER_CONSUMED = 0,
    RX_HANDLER_ANOTHER = 1,
    RX_HANDLER_EXACT = 2,
    RX_HANDLER_PASS = 3
} ;
typedef enum rx_handler_result rx_handler_result_t;
typedef rx_handler_result_t rx_handler_func_t(struct sk_buff ** );
struct Qdisc;
struct netdev_queue {
   struct net_device *dev ;
   struct Qdisc *qdisc ;
   struct Qdisc *qdisc_sleeping ;
   struct kobject kobj ;
   int numa_node ;
   spinlock_t _xmit_lock ;
   int xmit_lock_owner ;
    klee_make_symbolic(&xmit_lock_owner, sizeof(int), "xmit_lock_owner");
   unsigned long trans_start ;
    klee_make_symbolic(&trans_start, sizeof(long), "trans_start");
   unsigned long trans_timeout ;
    klee_make_symbolic(&trans_timeout, sizeof(long), "trans_timeout");
   unsigned long state ;
   struct dql dql ;
   unsigned long tx_maxrate ;
    klee_make_symbolic(&tx_maxrate, sizeof(long), "tx_maxrate");
};
struct rps_map {
   unsigned int len ;
   struct callback_head rcu ;
   u16 cpus[0U] ;
};
struct rps_dev_flow {
   u16 cpu ;
   u16 filter ;
   unsigned int last_qtail ;
    klee_make_symbolic(&last_qtail, sizeof(int), "last_qtail");
};
struct rps_dev_flow_table {
   unsigned int mask ;
   struct callback_head rcu ;
   struct rps_dev_flow flows[0U] ;
};
struct netdev_rx_queue {
   struct rps_map *rps_map ;
   struct rps_dev_flow_table *rps_flow_table ;
   struct kobject kobj ;
   struct net_device *dev ;
};
struct xps_map {
   unsigned int len ;
   unsigned int alloc_len ;
    klee_make_symbolic(&alloc_len, sizeof(int), "alloc_len");
   struct callback_head rcu ;
   u16 queues[0U] ;
};
struct xps_dev_maps {
   struct callback_head rcu ;
   struct xps_map *cpu_map[0U] ;
};
struct netdev_tc_txq {
   u16 count ;
   u16 offset ;
};
struct netdev_fcoe_hbainfo {
   char manufacturer[64U] ;
   char serial_number[64U] ;
   char hardware_version[64U] ;
   char driver_version[64U] ;
   char optionrom_version[64U] ;
   char firmware_version[64U] ;
   char model[256U] ;
   char model_description[256U] ;
};
struct netdev_phys_item_id {
   unsigned char id[32U] ;
   unsigned char id_len ;
    klee_make_symbolic(&id_len, sizeof(char), "id_len");
};
struct net_device_ops {
   int (*ndo_init)(struct net_device * ) ;
   void (*ndo_uninit)(struct net_device * ) ;
   int (*ndo_open)(struct net_device * ) ;
   int (*ndo_stop)(struct net_device * ) ;
   netdev_tx_t (*ndo_start_xmit)(struct sk_buff * , struct net_device * ) ;
   u16 (*ndo_select_queue)(struct net_device * , struct sk_buff * , void * , u16 (*)(struct net_device * ,
                                                                                     struct sk_buff * ) ) ;
   void (*ndo_change_rx_flags)(struct net_device * , int  ) ;
   void (*ndo_set_rx_mode)(struct net_device * ) ;
   int (*ndo_set_mac_address)(struct net_device * , void * ) ;
   int (*ndo_validate_addr)(struct net_device * ) ;
   int (*ndo_do_ioctl)(struct net_device * , struct ifreq * , int  ) ;
   int (*ndo_set_config)(struct net_device * , struct ifmap * ) ;
   int (*ndo_change_mtu)(struct net_device * , int  ) ;
   int (*ndo_neigh_setup)(struct net_device * , struct neigh_parms * ) ;
   void (*ndo_tx_timeout)(struct net_device * ) ;
   struct rtnl_link_stats64 *(*ndo_get_stats64)(struct net_device * , struct rtnl_link_stats64 * ) ;
   struct net_device_stats *(*ndo_get_stats)(struct net_device * ) ;
   int (*ndo_vlan_rx_add_vid)(struct net_device * , __be16  , u16  ) ;
   int (*ndo_vlan_rx_kill_vid)(struct net_device * , __be16  , u16  ) ;
   void (*ndo_poll_controller)(struct net_device * ) ;
   int (*ndo_netpoll_setup)(struct net_device * , struct netpoll_info * ) ;
   void (*ndo_netpoll_cleanup)(struct net_device * ) ;
   int (*ndo_busy_poll)(struct napi_struct * ) ;
   int (*ndo_set_vf_mac)(struct net_device * , int  , u8 * ) ;
   int (*ndo_set_vf_vlan)(struct net_device * , int  , u16  , u8  ) ;
   int (*ndo_set_vf_rate)(struct net_device * , int  , int  , int  ) ;
   int (*ndo_set_vf_spoofchk)(struct net_device * , int  , bool  ) ;
   int (*ndo_get_vf_config)(struct net_device * , int  , struct ifla_vf_info * ) ;
   int (*ndo_set_vf_link_state)(struct net_device * , int  , int  ) ;
   int (*ndo_get_vf_stats)(struct net_device * , int  , struct ifla_vf_stats * ) ;
   int (*ndo_set_vf_port)(struct net_device * , int  , struct nlattr ** ) ;
   int (*ndo_get_vf_port)(struct net_device * , int  , struct sk_buff * ) ;
   int (*ndo_set_vf_rss_query_en)(struct net_device * , int  , bool  ) ;
   int (*ndo_setup_tc)(struct net_device * , u8  ) ;
   int (*ndo_fcoe_enable)(struct net_device * ) ;
   int (*ndo_fcoe_disable)(struct net_device * ) ;
   int (*ndo_fcoe_ddp_setup)(struct net_device * , u16  , struct scatterlist * , unsigned int  ) ;
   int (*ndo_fcoe_ddp_done)(struct net_device * , u16  ) ;
   int (*ndo_fcoe_ddp_target)(struct net_device * , u16  , struct scatterlist * ,
                              unsigned int  ) ;
   int (*ndo_fcoe_get_hbainfo)(struct net_device * , struct netdev_fcoe_hbainfo * ) ;
   int (*ndo_fcoe_get_wwn)(struct net_device * , u64 * , int  ) ;
   int (*ndo_rx_flow_steer)(struct net_device * , struct sk_buff  const  * , u16  ,
                            u32  ) ;
   int (*ndo_add_slave)(struct net_device * , struct net_device * ) ;
   int (*ndo_del_slave)(struct net_device * , struct net_device * ) ;
   netdev_features_t (*ndo_fix_features)(struct net_device * , netdev_features_t  ) ;
   int (*ndo_set_features)(struct net_device * , netdev_features_t  ) ;
   int (*ndo_neigh_construct)(struct neighbour * ) ;
   void (*ndo_neigh_destroy)(struct neighbour * ) ;
   int (*ndo_fdb_add)(struct ndmsg * , struct nlattr ** , struct net_device * , unsigned char const   * ,
                      u16  , u16  ) ;
   int (*ndo_fdb_del)(struct ndmsg * , struct nlattr ** , struct net_device * , unsigned char const   * ,
                      u16  ) ;
   int (*ndo_fdb_dump)(struct sk_buff * , struct netlink_callback * , struct net_device * ,
                       struct net_device * , int  ) ;
   int (*ndo_bridge_setlink)(struct net_device * , struct nlmsghdr * , u16  ) ;
   int (*ndo_bridge_getlink)(struct sk_buff * , u32  , u32  , struct net_device * ,
                             u32  , int  ) ;
   int (*ndo_bridge_dellink)(struct net_device * , struct nlmsghdr * , u16  ) ;
   int (*ndo_change_carrier)(struct net_device * , bool  ) ;
   int (*ndo_get_phys_port_id)(struct net_device * , struct netdev_phys_item_id * ) ;
   int (*ndo_get_phys_port_name)(struct net_device * , char * , size_t  ) ;
   void (*ndo_add_vxlan_port)(struct net_device * , sa_family_t  , __be16  ) ;
   void (*ndo_del_vxlan_port)(struct net_device * , sa_family_t  , __be16  ) ;
   void *(*ndo_dfwd_add_station)(struct net_device * , struct net_device * ) ;
   void (*ndo_dfwd_del_station)(struct net_device * , void * ) ;
   netdev_tx_t (*ndo_dfwd_start_xmit)(struct sk_buff * , struct net_device * , void * ) ;
   int (*ndo_get_lock_subclass)(struct net_device * ) ;
   netdev_features_t (*ndo_features_check)(struct sk_buff * , struct net_device * ,
                                           netdev_features_t  ) ;
   int (*ndo_set_tx_maxrate)(struct net_device * , int  , u32  ) ;
   int (*ndo_get_iflink)(struct net_device  const  * ) ;
};
struct __anonstruct_adj_list_316 {
   struct list_head upper ;
   struct list_head lower ;
};
struct __anonstruct_all_adj_list_317 {
   struct list_head upper ;
   struct list_head lower ;
};
struct iw_handler_def;
struct iw_public_data;
struct switchdev_ops;
struct vlan_info;
struct tipc_bearer;
struct in_device;
struct dn_dev;
struct inet6_dev;
struct tcf_proto;
struct cpu_rmap;
struct pcpu_lstats;
struct pcpu_sw_netstats;
struct pcpu_dstats;
struct pcpu_vstats;
union __anonunion____missing_field_name_318 {
   void *ml_priv ;
   struct pcpu_lstats *lstats ;
   struct pcpu_sw_netstats *tstats ;
   struct pcpu_dstats *dstats ;
   struct pcpu_vstats *vstats ;
};
struct garp_port;
struct mrp_port;
struct rtnl_link_ops;
struct net_device {
   char name[16U] ;
   struct hlist_node name_hlist ;
   char *ifalias ;
   unsigned long mem_end ;
   unsigned long mem_start ;
   unsigned long base_addr ;
   int irq ;
   atomic_t carrier_changes ;
   unsigned long state ;
   struct list_head dev_list ;
   struct list_head napi_list ;
   struct list_head unreg_list ;
   struct list_head close_list ;
   struct list_head ptype_all ;
   struct list_head ptype_specific ;
   struct __anonstruct_adj_list_316 adj_list ;
   struct __anonstruct_all_adj_list_317 all_adj_list ;
   netdev_features_t features ;
   netdev_features_t hw_features ;
   netdev_features_t wanted_features ;
   netdev_features_t vlan_features ;
   netdev_features_t hw_enc_features ;
   netdev_features_t mpls_features ;
   int ifindex ;
   int group ;
    klee_make_symbolic(&group, sizeof(int), "group");
   struct net_device_stats stats ;
   atomic_long_t rx_dropped ;
   atomic_long_t tx_dropped ;
   struct iw_handler_def  const  *wireless_handlers ;
   struct iw_public_data *wireless_data ;
   struct net_device_ops  const  *netdev_ops ;
   struct ethtool_ops  const  *ethtool_ops ;
   struct switchdev_ops  const  *switchdev_ops ;
   struct header_ops  const  *header_ops ;
   unsigned int flags ;
   unsigned int priv_flags ;
    klee_make_symbolic(&priv_flags, sizeof(int), "priv_flags");
   unsigned short gflags ;
    klee_make_symbolic(&gflags, sizeof(short), "gflags");
   unsigned short padded ;
    klee_make_symbolic(&padded, sizeof(short), "padded");
   unsigned char operstate ;
    klee_make_symbolic(&operstate, sizeof(char), "operstate");
   unsigned char link_mode ;
    klee_make_symbolic(&link_mode, sizeof(char), "link_mode");
   unsigned char if_port ;
    klee_make_symbolic(&if_port, sizeof(char), "if_port");
   unsigned char dma ;
   unsigned int mtu ;
    klee_make_symbolic(&mtu, sizeof(int), "mtu");
   unsigned short type ;
   unsigned short hard_header_len ;
    klee_make_symbolic(&hard_header_len, sizeof(short), "hard_header_len");
   unsigned short needed_headroom ;
    klee_make_symbolic(&needed_headroom, sizeof(short), "needed_headroom");
   unsigned short needed_tailroom ;
    klee_make_symbolic(&needed_tailroom, sizeof(short), "needed_tailroom");
   unsigned char perm_addr[32U] ;
   unsigned char addr_assign_type ;
    klee_make_symbolic(&addr_assign_type, sizeof(char), "addr_assign_type");
   unsigned char addr_len ;
    klee_make_symbolic(&addr_len, sizeof(char), "addr_len");
   unsigned short neigh_priv_len ;
    klee_make_symbolic(&neigh_priv_len, sizeof(short), "neigh_priv_len");
   unsigned short dev_id ;
    klee_make_symbolic(&dev_id, sizeof(short), "dev_id");
   unsigned short dev_port ;
    klee_make_symbolic(&dev_port, sizeof(short), "dev_port");
   spinlock_t addr_list_lock ;
   unsigned char name_assign_type ;
    klee_make_symbolic(&name_assign_type, sizeof(char), "name_assign_type");
   bool uc_promisc ;
   struct netdev_hw_addr_list uc ;
   struct netdev_hw_addr_list mc ;
   struct netdev_hw_addr_list dev_addrs ;
   struct kset *queues_kset ;
   unsigned int promiscuity ;
    klee_make_symbolic(&promiscuity, sizeof(int), "promiscuity");
   unsigned int allmulti ;
    klee_make_symbolic(&allmulti, sizeof(int), "allmulti");
   struct vlan_info *vlan_info ;
   struct dsa_switch_tree *dsa_ptr ;
   struct tipc_bearer *tipc_ptr ;
   void *atalk_ptr ;
   struct in_device *ip_ptr ;
   struct dn_dev *dn_ptr ;
   struct inet6_dev *ip6_ptr ;
   void *ax25_ptr ;
   struct wireless_dev *ieee80211_ptr ;
   struct wpan_dev *ieee802154_ptr ;
   struct mpls_dev *mpls_ptr ;
   unsigned long last_rx ;
    klee_make_symbolic(&last_rx, sizeof(long), "last_rx");
   unsigned char *dev_addr ;
   struct netdev_rx_queue *_rx ;
   unsigned int num_rx_queues ;
    klee_make_symbolic(&num_rx_queues, sizeof(int), "num_rx_queues");
   unsigned int real_num_rx_queues ;
    klee_make_symbolic(&real_num_rx_queues, sizeof(int), "real_num_rx_queues");
   unsigned long gro_flush_timeout ;
    klee_make_symbolic(&gro_flush_timeout, sizeof(long), "gro_flush_timeout");
   rx_handler_func_t *rx_handler ;
   void *rx_handler_data ;
   struct tcf_proto *ingress_cl_list ;
   struct netdev_queue *ingress_queue ;
   struct list_head nf_hooks_ingress ;
   unsigned char broadcast[32U] ;
   struct cpu_rmap *rx_cpu_rmap ;
   struct hlist_node index_hlist ;
   struct netdev_queue *_tx ;
   unsigned int num_tx_queues ;
    klee_make_symbolic(&num_tx_queues, sizeof(int), "num_tx_queues");
   unsigned int real_num_tx_queues ;
    klee_make_symbolic(&real_num_tx_queues, sizeof(int), "real_num_tx_queues");
   struct Qdisc *qdisc ;
   unsigned long tx_queue_len ;
    klee_make_symbolic(&tx_queue_len, sizeof(long), "tx_queue_len");
   spinlock_t tx_global_lock ;
   int watchdog_timeo ;
    klee_make_symbolic(&watchdog_timeo, sizeof(int), "watchdog_timeo");
   struct xps_dev_maps *xps_maps ;
   unsigned long trans_start ;
   struct timer_list watchdog_timer ;
   int *pcpu_refcnt ;
   struct list_head todo_list ;
   struct list_head link_watch_list ;
   unsigned char reg_state ;
    klee_make_symbolic(&reg_state, sizeof(char), "reg_state");
   bool dismantle ;
   unsigned short rtnl_link_state ;
    klee_make_symbolic(&rtnl_link_state, sizeof(short), "rtnl_link_state");
   void (*destructor)(struct net_device * ) ;
   struct netpoll_info *npinfo ;
   possible_net_t nd_net ;
   union __anonunion____missing_field_name_318 __annonCompField95 ;
   struct garp_port *garp_port ;
   struct mrp_port *mrp_port ;
   struct device dev ;
   struct attribute_group  const  *sysfs_groups[4U] ;
   struct attribute_group  const  *sysfs_rx_queue_group ;
   struct rtnl_link_ops  const  *rtnl_link_ops ;
   unsigned int gso_max_size ;
    klee_make_symbolic(&gso_max_size, sizeof(int), "gso_max_size");
   u16 gso_max_segs ;
   u16 gso_min_segs ;
   struct dcbnl_rtnl_ops  const  *dcbnl_ops ;
   u8 num_tc ;
   struct netdev_tc_txq tc_to_txq[16U] ;
   u8 prio_tc_map[16U] ;
   unsigned int fcoe_ddp_xid ;
    klee_make_symbolic(&fcoe_ddp_xid, sizeof(int), "fcoe_ddp_xid");
   struct netprio_map *priomap ;
   struct phy_device *phydev ;
   struct lock_class_key *qdisc_tx_busylock ;
};
struct packet_type {
   __be16 type ;
   struct net_device *dev ;
   int (*func)(struct sk_buff * , struct net_device * , struct packet_type * , struct net_device * ) ;
   bool (*id_match)(struct packet_type * , struct sock * ) ;
   void *af_packet_priv ;
   struct list_head list ;
};
struct pcpu_sw_netstats {
   u64 rx_packets ;
   u64 rx_bytes ;
   u64 tx_packets ;
   u64 tx_bytes ;
   struct u64_stats_sync syncp ;
};
struct netdev_notifier_info {
   struct net_device *dev ;
};
struct page_counter {
   atomic_long_t count ;
   unsigned long limit ;
   struct page_counter *parent ;
   unsigned long watermark ;
    klee_make_symbolic(&watermark, sizeof(long), "watermark");
   unsigned long failcnt ;
    klee_make_symbolic(&failcnt, sizeof(long), "failcnt");
};
struct sock_filter {
   __u16 code ;
   __u8 jt ;
   __u8 jf ;
   __u32 k ;
};
struct bpf_insn {
   __u8 code ;
   unsigned char dst_reg : 4 ;
   unsigned char src_reg : 4 ;
   __s16 off ;
   __s32 imm ;
};
enum bpf_prog_type {
    BPF_PROG_TYPE_UNSPEC = 0,
    BPF_PROG_TYPE_SOCKET_FILTER = 1,
    BPF_PROG_TYPE_KPROBE = 2,
    BPF_PROG_TYPE_SCHED_CLS = 3,
    BPF_PROG_TYPE_SCHED_ACT = 4
} ;
struct bpf_prog_aux;
struct sock_fprog_kern {
   u16 len ;
   struct sock_filter *filter ;
};
union __anonunion____missing_field_name_333 {
   struct sock_filter insns[0U] ;
   struct bpf_insn insnsi[0U] ;
};
struct bpf_prog {
   u16 pages ;
   bool jited ;
   bool gpl_compatible ;
   u32 len ;
   enum bpf_prog_type type ;
   struct bpf_prog_aux *aux ;
   struct sock_fprog_kern *orig_prog ;
   unsigned int (*bpf_func)(struct sk_buff  const  * , struct bpf_insn  const  * ) ;
   union __anonunion____missing_field_name_333 __annonCompField100 ;
};
struct sk_filter {
   atomic_t refcnt ;
   struct callback_head rcu ;
   struct bpf_prog *prog ;
};
struct pollfd {
   int fd ;
    klee_make_symbolic(&fd, sizeof(int), "fd");
   short events ;
   short revents ;
    klee_make_symbolic(&revents, sizeof(short), "revents");
};
struct poll_table_struct {
   void (*_qproc)(struct file * , wait_queue_head_t * , struct poll_table_struct * ) ;
   unsigned long _key ;
    klee_make_symbolic(&_key, sizeof(long), "_key");
};
struct nla_policy {
   u16 type ;
   u16 len ;
};
struct rtnl_link_ops {
   struct list_head list ;
   char const   *kind ;
   size_t priv_size ;
   void (*setup)(struct net_device * ) ;
   int maxtype ;
    klee_make_symbolic(&maxtype, sizeof(int), "maxtype");
   struct nla_policy  const  *policy ;
   int (*validate)(struct nlattr ** , struct nlattr ** ) ;
   int (*newlink)(struct net * , struct net_device * , struct nlattr ** , struct nlattr ** ) ;
   int (*changelink)(struct net_device * , struct nlattr ** , struct nlattr ** ) ;
   void (*dellink)(struct net_device * , struct list_head * ) ;
   size_t (*get_size)(struct net_device  const  * ) ;
   int (*fill_info)(struct sk_buff * , struct net_device  const  * ) ;
   size_t (*get_xstats_size)(struct net_device  const  * ) ;
   int (*fill_xstats)(struct sk_buff * , struct net_device  const  * ) ;
   unsigned int (*get_num_tx_queues)(void) ;
   unsigned int (*get_num_rx_queues)(void) ;
   int slave_maxtype ;
    klee_make_symbolic(&slave_maxtype, sizeof(int), "slave_maxtype");
   struct nla_policy  const  *slave_policy ;
   int (*slave_validate)(struct nlattr ** , struct nlattr ** ) ;
   int (*slave_changelink)(struct net_device * , struct net_device * , struct nlattr ** ,
                           struct nlattr ** ) ;
   size_t (*get_slave_size)(struct net_device  const  * , struct net_device  const  * ) ;
   int (*fill_slave_info)(struct sk_buff * , struct net_device  const  * , struct net_device  const  * ) ;
   struct net *(*get_link_net)(struct net_device  const  * ) ;
};
struct neigh_table;
struct neigh_parms {
   possible_net_t net ;
   struct net_device *dev ;
   struct list_head list ;
   int (*neigh_setup)(struct neighbour * ) ;
   void (*neigh_cleanup)(struct neighbour * ) ;
   struct neigh_table *tbl ;
   void *sysctl_table ;
   int dead ;
    klee_make_symbolic(&dead, sizeof(int), "dead");
   atomic_t refcnt ;
   struct callback_head callback_head ;
   int reachable_time ;
    klee_make_symbolic(&reachable_time, sizeof(int), "reachable_time");
   int data[13U] ;
   unsigned long data_state[1U] ;
};
struct neigh_statistics {
   unsigned long allocs ;
    klee_make_symbolic(&allocs, sizeof(long), "allocs");
   unsigned long destroys ;
    klee_make_symbolic(&destroys, sizeof(long), "destroys");
   unsigned long hash_grows ;
    klee_make_symbolic(&hash_grows, sizeof(long), "hash_grows");
   unsigned long res_failed ;
    klee_make_symbolic(&res_failed, sizeof(long), "res_failed");
   unsigned long lookups ;
    klee_make_symbolic(&lookups, sizeof(long), "lookups");
   unsigned long hits ;
    klee_make_symbolic(&hits, sizeof(long), "hits");
   unsigned long rcv_probes_mcast ;
    klee_make_symbolic(&rcv_probes_mcast, sizeof(long), "rcv_probes_mcast");
   unsigned long rcv_probes_ucast ;
    klee_make_symbolic(&rcv_probes_ucast, sizeof(long), "rcv_probes_ucast");
   unsigned long periodic_gc_runs ;
    klee_make_symbolic(&periodic_gc_runs, sizeof(long), "periodic_gc_runs");
   unsigned long forced_gc_runs ;
    klee_make_symbolic(&forced_gc_runs, sizeof(long), "forced_gc_runs");
   unsigned long unres_discards ;
    klee_make_symbolic(&unres_discards, sizeof(long), "unres_discards");
};
struct neigh_ops;
struct neighbour {
   struct neighbour *next ;
   struct neigh_table *tbl ;
   struct neigh_parms *parms ;
   unsigned long confirmed ;
    klee_make_symbolic(&confirmed, sizeof(long), "confirmed");
   unsigned long updated ;
    klee_make_symbolic(&updated, sizeof(long), "updated");
   rwlock_t lock ;
   atomic_t refcnt ;
   struct sk_buff_head arp_queue ;
   unsigned int arp_queue_len_bytes ;
    klee_make_symbolic(&arp_queue_len_bytes, sizeof(int), "arp_queue_len_bytes");
   struct timer_list timer ;
   unsigned long used ;
   atomic_t probes ;
   __u8 flags ;
   __u8 nud_state ;
   __u8 type ;
   __u8 dead ;
   seqlock_t ha_lock ;
   unsigned char ha[32U] ;
   struct hh_cache hh ;
   int (*output)(struct neighbour * , struct sk_buff * ) ;
   struct neigh_ops  const  *ops ;
   struct callback_head rcu ;
   struct net_device *dev ;
   u8 primary_key[0U] ;
};
struct neigh_ops {
   int family ;
   void (*solicit)(struct neighbour * , struct sk_buff * ) ;
   void (*error_report)(struct neighbour * , struct sk_buff * ) ;
   int (*output)(struct neighbour * , struct sk_buff * ) ;
   int (*connected_output)(struct neighbour * , struct sk_buff * ) ;
};
struct pneigh_entry {
   struct pneigh_entry *next ;
   possible_net_t net ;
   struct net_device *dev ;
   u8 flags ;
   u8 key[0U] ;
};
struct neigh_hash_table {
   struct neighbour **hash_buckets ;
   unsigned int hash_shift ;
    klee_make_symbolic(&hash_shift, sizeof(int), "hash_shift");
   __u32 hash_rnd[4U] ;
   struct callback_head rcu ;
};
struct neigh_table {
   int family ;
   int entry_size ;
    klee_make_symbolic(&entry_size, sizeof(int), "entry_size");
   int key_len ;
    klee_make_symbolic(&key_len, sizeof(int), "key_len");
   __be16 protocol ;
   __u32 (*hash)(void const   * , struct net_device  const  * , __u32 * ) ;
   bool (*key_eq)(struct neighbour  const  * , void const   * ) ;
   int (*constructor)(struct neighbour * ) ;
   int (*pconstructor)(struct pneigh_entry * ) ;
   void (*pdestructor)(struct pneigh_entry * ) ;
   void (*proxy_redo)(struct sk_buff * ) ;
   char *id ;
   struct neigh_parms parms ;
   struct list_head parms_list ;
   int gc_interval ;
    klee_make_symbolic(&gc_interval, sizeof(int), "gc_interval");
   int gc_thresh1 ;
    klee_make_symbolic(&gc_thresh1, sizeof(int), "gc_thresh1");
   int gc_thresh2 ;
    klee_make_symbolic(&gc_thresh2, sizeof(int), "gc_thresh2");
   int gc_thresh3 ;
    klee_make_symbolic(&gc_thresh3, sizeof(int), "gc_thresh3");
   unsigned long last_flush ;
    klee_make_symbolic(&last_flush, sizeof(long), "last_flush");
   struct delayed_work gc_work ;
   struct timer_list proxy_timer ;
   struct sk_buff_head proxy_queue ;
   atomic_t entries ;
   rwlock_t lock ;
   unsigned long last_rand ;
    klee_make_symbolic(&last_rand, sizeof(long), "last_rand");
   struct neigh_statistics *stats ;
   struct neigh_hash_table *nht ;
   struct pneigh_entry **phash_buckets ;
};
struct dn_route;
union __anonunion____missing_field_name_344 {
   struct dst_entry *next ;
   struct rtable *rt_next ;
   struct rt6_info *rt6_next ;
   struct dn_route *dn_next ;
};
struct dst_entry {
   struct callback_head callback_head ;
   struct dst_entry *child ;
   struct net_device *dev ;
   struct dst_ops *ops ;
   unsigned long _metrics ;
    klee_make_symbolic(&_metrics, sizeof(long), "_metrics");
   unsigned long expires ;
   struct dst_entry *path ;
   struct dst_entry *from ;
   struct xfrm_state *xfrm ;
   int (*input)(struct sk_buff * ) ;
   int (*output)(struct sock * , struct sk_buff * ) ;
   unsigned short flags ;
   unsigned short pending_confirm ;
    klee_make_symbolic(&pending_confirm, sizeof(short), "pending_confirm");
   short error ;
    klee_make_symbolic(&error, sizeof(short), "error");
   short obsolete ;
    klee_make_symbolic(&obsolete, sizeof(short), "obsolete");
   unsigned short header_len ;
    klee_make_symbolic(&header_len, sizeof(short), "header_len");
   unsigned short trailer_len ;
    klee_make_symbolic(&trailer_len, sizeof(short), "trailer_len");
   __u32 tclassid ;
   long __pad_to_align_refcnt[2U] ;
   atomic_t __refcnt ;
   int __use ;
    klee_make_symbolic(&__use, sizeof(int), "__use");
   unsigned long lastuse ;
    klee_make_symbolic(&lastuse, sizeof(long), "lastuse");
   union __anonunion____missing_field_name_344 __annonCompField101 ;
};
struct hwtstamp_config {
   int flags ;
   int tx_type ;
    klee_make_symbolic(&tx_type, sizeof(int), "tx_type");
   int rx_filter ;
    klee_make_symbolic(&rx_filter, sizeof(int), "rx_filter");
};
struct __anonstruct_socket_lock_t_345 {
   spinlock_t slock ;
   int owned ;
    klee_make_symbolic(&owned, sizeof(int), "owned");
   wait_queue_head_t wq ;
   struct lockdep_map dep_map ;
};
typedef struct __anonstruct_socket_lock_t_345 socket_lock_t;
struct proto;
typedef __u32 __portpair;
typedef __u64 __addrpair;
struct __anonstruct____missing_field_name_347 {
   __be32 skc_daddr ;
   __be32 skc_rcv_saddr ;
};
union __anonunion____missing_field_name_346 {
   __addrpair skc_addrpair ;
   struct __anonstruct____missing_field_name_347 __annonCompField102 ;
};
union __anonunion____missing_field_name_348 {
   unsigned int skc_hash ;
    klee_make_symbolic(&skc_hash, sizeof(int), "skc_hash");
   __u16 skc_u16hashes[2U] ;
};
struct __anonstruct____missing_field_name_350 {
   __be16 skc_dport ;
   __u16 skc_num ;
};
union __anonunion____missing_field_name_349 {
   __portpair skc_portpair ;
   struct __anonstruct____missing_field_name_350 __annonCompField105 ;
};
union __anonunion____missing_field_name_351 {
   struct hlist_node skc_bind_node ;
   struct hlist_nulls_node skc_portaddr_node ;
};
union __anonunion____missing_field_name_352 {
   struct hlist_node skc_node ;
   struct hlist_nulls_node skc_nulls_node ;
};
struct sock_common {
   union __anonunion____missing_field_name_346 __annonCompField103 ;
   union __anonunion____missing_field_name_348 __annonCompField104 ;
   union __anonunion____missing_field_name_349 __annonCompField106 ;
   unsigned short skc_family ;
    klee_make_symbolic(&skc_family, sizeof(short), "skc_family");
   unsigned char volatile   skc_state ;
   unsigned char skc_reuse : 4 ;
   unsigned char skc_reuseport : 1 ;
   unsigned char skc_ipv6only : 1 ;
   unsigned char skc_net_refcnt : 1 ;
   int skc_bound_dev_if ;
    klee_make_symbolic(&skc_bound_dev_if, sizeof(int), "skc_bound_dev_if");
   union __anonunion____missing_field_name_351 __annonCompField107 ;
   struct proto *skc_prot ;
   possible_net_t skc_net ;
   struct in6_addr skc_v6_daddr ;
   struct in6_addr skc_v6_rcv_saddr ;
   atomic64_t skc_cookie ;
   int skc_dontcopy_begin[0U] ;
   union __anonunion____missing_field_name_352 __annonCompField108 ;
   int skc_tx_queue_mapping ;
    klee_make_symbolic(&skc_tx_queue_mapping, sizeof(int), "skc_tx_queue_mapping");
   atomic_t skc_refcnt ;
   int skc_dontcopy_end[0U] ;
};
struct cg_proto;
struct __anonstruct_sk_backlog_353 {
   atomic_t rmem_alloc ;
   int len ;
   struct sk_buff *head ;
   struct sk_buff *tail ;
};
struct sock {
   struct sock_common __sk_common ;
   socket_lock_t sk_lock ;
   struct sk_buff_head sk_receive_queue ;
   struct __anonstruct_sk_backlog_353 sk_backlog ;
   int sk_forward_alloc ;
    klee_make_symbolic(&sk_forward_alloc, sizeof(int), "sk_forward_alloc");
   __u32 sk_rxhash ;
   u16 sk_incoming_cpu ;
   __u32 sk_txhash ;
   unsigned int sk_napi_id ;
    klee_make_symbolic(&sk_napi_id, sizeof(int), "sk_napi_id");
   unsigned int sk_ll_usec ;
    klee_make_symbolic(&sk_ll_usec, sizeof(int), "sk_ll_usec");
   atomic_t sk_drops ;
   int sk_rcvbuf ;
    klee_make_symbolic(&sk_rcvbuf, sizeof(int), "sk_rcvbuf");
   struct sk_filter *sk_filter ;
   struct socket_wq *sk_wq ;
   struct xfrm_policy *sk_policy[2U] ;
   unsigned long sk_flags ;
    klee_make_symbolic(&sk_flags, sizeof(long), "sk_flags");
   struct dst_entry *sk_rx_dst ;
   struct dst_entry *sk_dst_cache ;
   spinlock_t sk_dst_lock ;
   atomic_t sk_wmem_alloc ;
   atomic_t sk_omem_alloc ;
   int sk_sndbuf ;
    klee_make_symbolic(&sk_sndbuf, sizeof(int), "sk_sndbuf");
   struct sk_buff_head sk_write_queue ;
   unsigned char sk_shutdown : 2 ;
   unsigned char sk_no_check_tx : 1 ;
   unsigned char sk_no_check_rx : 1 ;
   unsigned char sk_userlocks : 4 ;
   unsigned char sk_protocol ;
    klee_make_symbolic(&sk_protocol, sizeof(char), "sk_protocol");
   unsigned short sk_type ;
    klee_make_symbolic(&sk_type, sizeof(short), "sk_type");
   int sk_wmem_queued ;
    klee_make_symbolic(&sk_wmem_queued, sizeof(int), "sk_wmem_queued");
   gfp_t sk_allocation ;
   u32 sk_pacing_rate ;
   u32 sk_max_pacing_rate ;
   netdev_features_t sk_route_caps ;
   netdev_features_t sk_route_nocaps ;
   int sk_gso_type ;
    klee_make_symbolic(&sk_gso_type, sizeof(int), "sk_gso_type");
   unsigned int sk_gso_max_size ;
    klee_make_symbolic(&sk_gso_max_size, sizeof(int), "sk_gso_max_size");
   u16 sk_gso_max_segs ;
   int sk_rcvlowat ;
    klee_make_symbolic(&sk_rcvlowat, sizeof(int), "sk_rcvlowat");
   unsigned long sk_lingertime ;
    klee_make_symbolic(&sk_lingertime, sizeof(long), "sk_lingertime");
   struct sk_buff_head sk_error_queue ;
   struct proto *sk_prot_creator ;
   rwlock_t sk_callback_lock ;
   int sk_err ;
    klee_make_symbolic(&sk_err, sizeof(int), "sk_err");
   int sk_err_soft ;
    klee_make_symbolic(&sk_err_soft, sizeof(int), "sk_err_soft");
   u32 sk_ack_backlog ;
   u32 sk_max_ack_backlog ;
   __u32 sk_priority ;
   __u32 sk_cgrp_prioidx ;
   struct pid *sk_peer_pid ;
   struct cred  const  *sk_peer_cred ;
   long sk_rcvtimeo ;
    klee_make_symbolic(&sk_rcvtimeo, sizeof(long), "sk_rcvtimeo");
   long sk_sndtimeo ;
    klee_make_symbolic(&sk_sndtimeo, sizeof(long), "sk_sndtimeo");
   struct timer_list sk_timer ;
   ktime_t sk_stamp ;
   u16 sk_tsflags ;
   u32 sk_tskey ;
   struct socket *sk_socket ;
   void *sk_user_data ;
   struct page_frag sk_frag ;
   struct sk_buff *sk_send_head ;
   __s32 sk_peek_off ;
   int sk_write_pending ;
    klee_make_symbolic(&sk_write_pending, sizeof(int), "sk_write_pending");
   void *sk_security ;
   __u32 sk_mark ;
   u32 sk_classid ;
   struct cg_proto *sk_cgrp ;
   void (*sk_state_change)(struct sock * ) ;
   void (*sk_data_ready)(struct sock * ) ;
   void (*sk_write_space)(struct sock * ) ;
   void (*sk_error_report)(struct sock * ) ;
   int (*sk_backlog_rcv)(struct sock * , struct sk_buff * ) ;
   void (*sk_destruct)(struct sock * ) ;
};
struct request_sock_ops;
struct timewait_sock_ops;
struct inet_hashinfo;
struct raw_hashinfo;
struct udp_table;
union __anonunion_h_356 {
   struct inet_hashinfo *hashinfo ;
   struct udp_table *udp_table ;
   struct raw_hashinfo *raw_hash ;
};
struct proto {
   void (*close)(struct sock * , long  ) ;
   int (*connect)(struct sock * , struct sockaddr * , int  ) ;
   int (*disconnect)(struct sock * , int  ) ;
   struct sock *(*accept)(struct sock * , int  , int * ) ;
   int (*ioctl)(struct sock * , int  , unsigned long  ) ;
   int (*init)(struct sock * ) ;
   void (*destroy)(struct sock * ) ;
   void (*shutdown)(struct sock * , int  ) ;
   int (*setsockopt)(struct sock * , int  , int  , char * , unsigned int  ) ;
   int (*getsockopt)(struct sock * , int  , int  , char * , int * ) ;
   int (*compat_setsockopt)(struct sock * , int  , int  , char * , unsigned int  ) ;
   int (*compat_getsockopt)(struct sock * , int  , int  , char * , int * ) ;
   int (*compat_ioctl)(struct sock * , unsigned int  , unsigned long  ) ;
   int (*sendmsg)(struct sock * , struct msghdr * , size_t  ) ;
   int (*recvmsg)(struct sock * , struct msghdr * , size_t  , int  , int  , int * ) ;
   int (*sendpage)(struct sock * , struct page * , int  , size_t  , int  ) ;
   int (*bind)(struct sock * , struct sockaddr * , int  ) ;
   int (*backlog_rcv)(struct sock * , struct sk_buff * ) ;
   void (*release_cb)(struct sock * ) ;
   void (*hash)(struct sock * ) ;
   void (*unhash)(struct sock * ) ;
   void (*rehash)(struct sock * ) ;
   int (*get_port)(struct sock * , unsigned short  ) ;
   void (*clear_sk)(struct sock * , int  ) ;
   unsigned int inuse_idx ;
    klee_make_symbolic(&inuse_idx, sizeof(int), "inuse_idx");
   bool (*stream_memory_free)(struct sock  const  * ) ;
   void (*enter_memory_pressure)(struct sock * ) ;
   atomic_long_t *memory_allocated ;
   struct percpu_counter *sockets_allocated ;
   int *memory_pressure ;
   long *sysctl_mem ;
   int *sysctl_wmem ;
   int *sysctl_rmem ;
   int max_header ;
    klee_make_symbolic(&max_header, sizeof(int), "max_header");
   bool no_autobind ;
   struct kmem_cache *slab ;
   unsigned int obj_size ;
    klee_make_symbolic(&obj_size, sizeof(int), "obj_size");
   int slab_flags ;
    klee_make_symbolic(&slab_flags, sizeof(int), "slab_flags");
   struct percpu_counter *orphan_count ;
   struct request_sock_ops *rsk_prot ;
   struct timewait_sock_ops *twsk_prot ;
   union __anonunion_h_356 h ;
   struct module *owner ;
   char name[32U] ;
   struct list_head node ;
   int (*init_cgroup)(struct mem_cgroup * , struct cgroup_subsys * ) ;
   void (*destroy_cgroup)(struct mem_cgroup * ) ;
   struct cg_proto *(*proto_cgroup)(struct mem_cgroup * ) ;
};
struct cg_proto {
   struct page_counter memory_allocated ;
   struct percpu_counter sockets_allocated ;
   int memory_pressure ;
    klee_make_symbolic(&memory_pressure, sizeof(int), "memory_pressure");
   long sysctl_mem[3U] ;
   unsigned long flags ;
   struct mem_cgroup *memcg ;
};
struct request_sock_ops {
   int family ;
   int obj_size ;
   struct kmem_cache *slab ;
   char *slab_name ;
   int (*rtx_syn_ack)(struct sock * , struct request_sock * ) ;
   void (*send_ack)(struct sock * , struct sk_buff * , struct request_sock * ) ;
   void (*send_reset)(struct sock * , struct sk_buff * ) ;
   void (*destructor)(struct request_sock * ) ;
   void (*syn_ack_timeout)(struct request_sock  const  * ) ;
};
struct request_sock {
   struct sock_common __req_common ;
   struct request_sock *dl_next ;
   struct sock *rsk_listener ;
   u16 mss ;
   u8 num_retrans ;
   unsigned char cookie_ts : 1 ;
   unsigned char num_timeout : 7 ;
   u32 window_clamp ;
   u32 rcv_wnd ;
   u32 ts_recent ;
   struct timer_list rsk_timer ;
   struct request_sock_ops  const  *rsk_ops ;
   struct sock *sk ;
   u32 *saved_syn ;
   u32 secid ;
   u32 peer_secid ;
};
struct timewait_sock_ops {
   struct kmem_cache *twsk_slab ;
   char *twsk_slab_name ;
   unsigned int twsk_obj_size ;
    klee_make_symbolic(&twsk_obj_size, sizeof(int), "twsk_obj_size");
   int (*twsk_unique)(struct sock * , struct sock * , void * ) ;
   void (*twsk_destructor)(struct sock * ) ;
};
struct mdio_if_info {
   int prtad ;
    klee_make_symbolic(&prtad, sizeof(int), "prtad");
   u32 mmds ;
   unsigned int mode_support ;
    klee_make_symbolic(&mode_support, sizeof(int), "mode_support");
   struct net_device *dev ;
   int (*mdio_read)(struct net_device * , int  , int  , u16  ) ;
   int (*mdio_write)(struct net_device * , int  , int  , u16  , u16  ) ;
};
struct otp_info {
   __u32 start ;
   __u32 length ;
   __u32 locked ;
};
struct nand_oobfree {
   __u32 offset ;
   __u32 length ;
};
struct mtd_ecc_stats {
   __u32 corrected ;
   __u32 failed ;
   __u32 badblocks ;
   __u32 bbtblocks ;
};
struct erase_info {
   struct mtd_info *mtd ;
   uint64_t addr ;
   uint64_t len ;
   uint64_t fail_addr ;
   u_long time ;
   u_long retries ;
    klee_make_symbolic(&retries, sizeof(long), "retries");
   unsigned int dev ;
    klee_make_symbolic(&dev, sizeof(int), "dev");
   unsigned int cell ;
    klee_make_symbolic(&cell, sizeof(int), "cell");
   void (*callback)(struct erase_info * ) ;
   u_long priv ;
    klee_make_symbolic(&priv, sizeof(long), "priv");
   u_char state ;
   struct erase_info *next ;
};
struct mtd_erase_region_info {
   uint64_t offset ;
   uint32_t erasesize ;
   uint32_t numblocks ;
   unsigned long *lockmap ;
};
struct mtd_oob_ops {
   unsigned int mode ;
   size_t len ;
   size_t retlen ;
   size_t ooblen ;
   size_t oobretlen ;
   uint32_t ooboffs ;
   uint8_t *datbuf ;
   uint8_t *oobbuf ;
};
struct nand_ecclayout {
   __u32 eccbytes ;
   __u32 eccpos[640U] ;
   __u32 oobavail ;
   struct nand_oobfree oobfree[32U] ;
};
struct mtd_info {
   u_char type ;
   uint32_t flags ;
   uint64_t size ;
   uint32_t erasesize ;
   uint32_t writesize ;
   uint32_t writebufsize ;
   uint32_t oobsize ;
   uint32_t oobavail ;
   unsigned int erasesize_shift ;
    klee_make_symbolic(&erasesize_shift, sizeof(int), "erasesize_shift");
   unsigned int writesize_shift ;
    klee_make_symbolic(&writesize_shift, sizeof(int), "writesize_shift");
   unsigned int erasesize_mask ;
    klee_make_symbolic(&erasesize_mask, sizeof(int), "erasesize_mask");
   unsigned int writesize_mask ;
    klee_make_symbolic(&writesize_mask, sizeof(int), "writesize_mask");
   unsigned int bitflip_threshold ;
    klee_make_symbolic(&bitflip_threshold, sizeof(int), "bitflip_threshold");
   char const   *name ;
   int index ;
   struct nand_ecclayout *ecclayout ;
   unsigned int ecc_step_size ;
    klee_make_symbolic(&ecc_step_size, sizeof(int), "ecc_step_size");
   unsigned int ecc_strength ;
    klee_make_symbolic(&ecc_strength, sizeof(int), "ecc_strength");
   int numeraseregions ;
    klee_make_symbolic(&numeraseregions, sizeof(int), "numeraseregions");
   struct mtd_erase_region_info *eraseregions ;
   int (*_erase)(struct mtd_info * , struct erase_info * ) ;
   int (*_point)(struct mtd_info * , loff_t  , size_t  , size_t * , void ** , resource_size_t * ) ;
   int (*_unpoint)(struct mtd_info * , loff_t  , size_t  ) ;
   unsigned long (*_get_unmapped_area)(struct mtd_info * , unsigned long  , unsigned long  ,
                                       unsigned long  ) ;
   int (*_read)(struct mtd_info * , loff_t  , size_t  , size_t * , u_char * ) ;
   int (*_write)(struct mtd_info * , loff_t  , size_t  , size_t * , u_char const   * ) ;
   int (*_panic_write)(struct mtd_info * , loff_t  , size_t  , size_t * , u_char const   * ) ;
   int (*_read_oob)(struct mtd_info * , loff_t  , struct mtd_oob_ops * ) ;
   int (*_write_oob)(struct mtd_info * , loff_t  , struct mtd_oob_ops * ) ;
   int (*_get_fact_prot_info)(struct mtd_info * , size_t  , size_t * , struct otp_info * ) ;
   int (*_read_fact_prot_reg)(struct mtd_info * , loff_t  , size_t  , size_t * , u_char * ) ;
   int (*_get_user_prot_info)(struct mtd_info * , size_t  , size_t * , struct otp_info * ) ;
   int (*_read_user_prot_reg)(struct mtd_info * , loff_t  , size_t  , size_t * , u_char * ) ;
   int (*_write_user_prot_reg)(struct mtd_info * , loff_t  , size_t  , size_t * ,
                               u_char * ) ;
   int (*_lock_user_prot_reg)(struct mtd_info * , loff_t  , size_t  ) ;
   int (*_writev)(struct mtd_info * , struct kvec  const  * , unsigned long  , loff_t  ,
                  size_t * ) ;
   void (*_sync)(struct mtd_info * ) ;
   int (*_lock)(struct mtd_info * , loff_t  , uint64_t  ) ;
   int (*_unlock)(struct mtd_info * , loff_t  , uint64_t  ) ;
   int (*_is_locked)(struct mtd_info * , loff_t  , uint64_t  ) ;
   int (*_block_isreserved)(struct mtd_info * , loff_t  ) ;
   int (*_block_isbad)(struct mtd_info * , loff_t  ) ;
   int (*_block_markbad)(struct mtd_info * , loff_t  ) ;
   int (*_suspend)(struct mtd_info * ) ;
   void (*_resume)(struct mtd_info * ) ;
   void (*_reboot)(struct mtd_info * ) ;
   int (*_get_device)(struct mtd_info * ) ;
   void (*_put_device)(struct mtd_info * ) ;
   struct backing_dev_info *backing_dev_info ;
   struct notifier_block reboot_notifier ;
   struct mtd_ecc_stats ecc_stats ;
   int subpage_sft ;
    klee_make_symbolic(&subpage_sft, sizeof(int), "subpage_sft");
   void *priv ;
   struct module *owner ;
   struct device dev ;
   int usecount ;
    klee_make_symbolic(&usecount, sizeof(int), "usecount");
};
struct ipv6_stable_secret {
   bool initialized ;
   struct in6_addr secret ;
};
struct ipv6_devconf {
   __s32 forwarding ;
   __s32 hop_limit ;
   __s32 mtu6 ;
   __s32 accept_ra ;
   __s32 accept_redirects ;
   __s32 autoconf ;
   __s32 dad_transmits ;
   __s32 rtr_solicits ;
   __s32 rtr_solicit_interval ;
   __s32 rtr_solicit_delay ;
   __s32 force_mld_version ;
   __s32 mldv1_unsolicited_report_interval ;
   __s32 mldv2_unsolicited_report_interval ;
   __s32 use_tempaddr ;
   __s32 temp_valid_lft ;
   __s32 temp_prefered_lft ;
   __s32 regen_max_retry ;
   __s32 max_desync_factor ;
   __s32 max_addresses ;
   __s32 accept_ra_defrtr ;
   __s32 accept_ra_pinfo ;
   __s32 accept_ra_rtr_pref ;
   __s32 rtr_probe_interval ;
   __s32 accept_ra_rt_info_max_plen ;
   __s32 proxy_ndp ;
   __s32 accept_source_route ;
   __s32 accept_ra_from_local ;
   __s32 optimistic_dad ;
   __s32 use_optimistic ;
   __s32 mc_forwarding ;
   __s32 disable_ipv6 ;
   __s32 accept_dad ;
   __s32 force_tllao ;
   __s32 ndisc_notify ;
   __s32 suppress_frag_ndisc ;
   __s32 accept_ra_mtu ;
   struct ipv6_stable_secret stable_secret ;
   void *sysctl ;
};
struct ip6_sf_list {
   struct ip6_sf_list *sf_next ;
   struct in6_addr sf_addr ;
   unsigned long sf_count[2U] ;
   unsigned char sf_gsresp ;
    klee_make_symbolic(&sf_gsresp, sizeof(char), "sf_gsresp");
   unsigned char sf_oldin ;
    klee_make_symbolic(&sf_oldin, sizeof(char), "sf_oldin");
   unsigned char sf_crcount ;
    klee_make_symbolic(&sf_crcount, sizeof(char), "sf_crcount");
};
struct ifmcaddr6 {
   struct in6_addr mca_addr ;
   struct inet6_dev *idev ;
   struct ifmcaddr6 *next ;
   struct ip6_sf_list *mca_sources ;
   struct ip6_sf_list *mca_tomb ;
   unsigned int mca_sfmode ;
    klee_make_symbolic(&mca_sfmode, sizeof(int), "mca_sfmode");
   unsigned char mca_crcount ;
    klee_make_symbolic(&mca_crcount, sizeof(char), "mca_crcount");
   unsigned long mca_sfcount[2U] ;
   struct timer_list mca_timer ;
   unsigned int mca_flags ;
    klee_make_symbolic(&mca_flags, sizeof(int), "mca_flags");
   int mca_users ;
    klee_make_symbolic(&mca_users, sizeof(int), "mca_users");
   atomic_t mca_refcnt ;
   spinlock_t mca_lock ;
   unsigned long mca_cstamp ;
    klee_make_symbolic(&mca_cstamp, sizeof(long), "mca_cstamp");
   unsigned long mca_tstamp ;
    klee_make_symbolic(&mca_tstamp, sizeof(long), "mca_tstamp");
};
struct ifacaddr6 {
   struct in6_addr aca_addr ;
   struct inet6_dev *aca_idev ;
   struct rt6_info *aca_rt ;
   struct ifacaddr6 *aca_next ;
   int aca_users ;
    klee_make_symbolic(&aca_users, sizeof(int), "aca_users");
   atomic_t aca_refcnt ;
   unsigned long aca_cstamp ;
    klee_make_symbolic(&aca_cstamp, sizeof(long), "aca_cstamp");
   unsigned long aca_tstamp ;
    klee_make_symbolic(&aca_tstamp, sizeof(long), "aca_tstamp");
};
struct ipv6_devstat {
   struct proc_dir_entry *proc_dir_entry ;
   struct ipstats_mib *ipv6 ;
   struct icmpv6_mib_device *icmpv6dev ;
   struct icmpv6msg_mib_device *icmpv6msgdev ;
};
struct inet6_dev {
   struct net_device *dev ;
   struct list_head addr_list ;
   struct ifmcaddr6 *mc_list ;
   struct ifmcaddr6 *mc_tomb ;
   spinlock_t mc_lock ;
   unsigned char mc_qrv ;
    klee_make_symbolic(&mc_qrv, sizeof(char), "mc_qrv");
   unsigned char mc_gq_running ;
    klee_make_symbolic(&mc_gq_running, sizeof(char), "mc_gq_running");
   unsigned char mc_ifc_count ;
    klee_make_symbolic(&mc_ifc_count, sizeof(char), "mc_ifc_count");
   unsigned char mc_dad_count ;
    klee_make_symbolic(&mc_dad_count, sizeof(char), "mc_dad_count");
   unsigned long mc_v1_seen ;
    klee_make_symbolic(&mc_v1_seen, sizeof(long), "mc_v1_seen");
   unsigned long mc_qi ;
    klee_make_symbolic(&mc_qi, sizeof(long), "mc_qi");
   unsigned long mc_qri ;
    klee_make_symbolic(&mc_qri, sizeof(long), "mc_qri");
   unsigned long mc_maxdelay ;
    klee_make_symbolic(&mc_maxdelay, sizeof(long), "mc_maxdelay");
   struct timer_list mc_gq_timer ;
   struct timer_list mc_ifc_timer ;
   struct timer_list mc_dad_timer ;
   struct ifacaddr6 *ac_list ;
   rwlock_t lock ;
   atomic_t refcnt ;
   __u32 if_flags ;
   int dead ;
   u8 rndid[8U] ;
   struct timer_list regen_timer ;
   struct list_head tempaddr_list ;
   struct in6_addr token ;
   struct neigh_parms *nd_parms ;
   struct ipv6_devconf cnf ;
   struct ipv6_devstat stats ;
   struct timer_list rs_timer ;
   __u8 rs_probes ;
   __u8 addr_gen_mode ;
   unsigned long tstamp ;
    klee_make_symbolic(&tstamp, sizeof(long), "tstamp");
   struct callback_head rcu ;
};
union __anonunion____missing_field_name_377 {
   __be32 a4 ;
   __be32 a6[4U] ;
   struct in6_addr in6 ;
};
struct inetpeer_addr_base {
   union __anonunion____missing_field_name_377 __annonCompField110 ;
};
struct inetpeer_addr {
   struct inetpeer_addr_base addr ;
   __u16 family ;
};
union __anonunion____missing_field_name_378 {
   struct list_head gc_list ;
   struct callback_head gc_rcu ;
};
struct __anonstruct____missing_field_name_380 {
   atomic_t rid ;
};
union __anonunion____missing_field_name_379 {
   struct __anonstruct____missing_field_name_380 __annonCompField112 ;
   struct callback_head rcu ;
   struct inet_peer *gc_next ;
};
struct inet_peer {
   struct inet_peer *avl_left ;
   struct inet_peer *avl_right ;
   struct inetpeer_addr daddr ;
   __u32 avl_height ;
   u32 metrics[16U] ;
   u32 rate_tokens ;
   unsigned long rate_last ;
    klee_make_symbolic(&rate_last, sizeof(long), "rate_last");
   union __anonunion____missing_field_name_378 __annonCompField111 ;
   union __anonunion____missing_field_name_379 __annonCompField113 ;
   __u32 dtime ;
   atomic_t refcnt ;
};
struct inet_peer_base {
   struct inet_peer *root ;
   seqlock_t lock ;
   int total ;
    klee_make_symbolic(&total, sizeof(int), "total");
};
struct uncached_list;
struct rtable {
   struct dst_entry dst ;
   int rt_genid ;
    klee_make_symbolic(&rt_genid, sizeof(int), "rt_genid");
   unsigned int rt_flags ;
    klee_make_symbolic(&rt_flags, sizeof(int), "rt_flags");
   __u16 rt_type ;
   __u8 rt_is_input ;
   __u8 rt_uses_gateway ;
   int rt_iif ;
    klee_make_symbolic(&rt_iif, sizeof(int), "rt_iif");
   __be32 rt_gateway ;
   u32 rt_pmtu ;
   struct list_head rt_uncached ;
   struct uncached_list *rt_uncached_list ;
};
enum efx_loopback_mode {
    LOOPBACK_NONE = 0,
    LOOPBACK_DATA = 1,
    LOOPBACK_GMAC = 2,
    LOOPBACK_XGMII = 3,
    LOOPBACK_XGXS = 4,
    LOOPBACK_XAUI = 5,
    LOOPBACK_GMII = 6,
    LOOPBACK_SGMII = 7,
    LOOPBACK_XGBR = 8,
    LOOPBACK_XFI = 9,
    LOOPBACK_XAUI_FAR = 10,
    LOOPBACK_GMII_FAR = 11,
    LOOPBACK_SGMII_FAR = 12,
    LOOPBACK_XFI_FAR = 13,
    LOOPBACK_GPHY = 14,
    LOOPBACK_PHYXS = 15,
    LOOPBACK_PCS = 16,
    LOOPBACK_PMAPMD = 17,
    LOOPBACK_XPORT = 18,
    LOOPBACK_XGMII_WS = 19,
    LOOPBACK_XAUI_WS = 20,
    LOOPBACK_XAUI_WS_FAR = 21,
    LOOPBACK_XAUI_WS_NEAR = 22,
    LOOPBACK_GMII_WS = 23,
    LOOPBACK_XFI_WS = 24,
    LOOPBACK_XFI_WS_FAR = 25,
    LOOPBACK_PHYXS_WS = 26,
    LOOPBACK_MAX = 27
} ;
enum reset_type {
    RESET_TYPE_INVISIBLE = 0,
    RESET_TYPE_RECOVER_OR_ALL = 1,
    RESET_TYPE_ALL = 2,
    RESET_TYPE_WORLD = 3,
    RESET_TYPE_RECOVER_OR_DISABLE = 4,
    RESET_TYPE_DATAPATH = 5,
    RESET_TYPE_MC_BIST = 6,
    RESET_TYPE_DISABLE = 7,
    RESET_TYPE_MAX_METHOD = 8,
    RESET_TYPE_TX_WATCHDOG = 9,
    RESET_TYPE_INT_ERROR = 10,
    RESET_TYPE_RX_RECOVERY = 11,
    RESET_TYPE_DMA_ERROR = 12,
    RESET_TYPE_TX_SKIP = 13,
    RESET_TYPE_MC_FAILURE = 14,
    RESET_TYPE_MCDI_TIMEOUT = 15,
    RESET_TYPE_MAX = 16
} ;
union efx_dword {
   __le32 u32[1U] ;
};
typedef union efx_dword efx_dword_t;
union efx_qword {
   __le64 u64[1U] ;
   __le32 u32[2U] ;
   efx_dword_t dword[2U] ;
};
typedef union efx_qword efx_qword_t;
union efx_oword {
   __le64 u64[2U] ;
   efx_qword_t qword[2U] ;
   __le32 u32[4U] ;
   efx_dword_t dword[4U] ;
};
typedef union efx_oword efx_oword_t;
enum efx_filter_priority {
    EFX_FILTER_PRI_HINT = 0,
    EFX_FILTER_PRI_AUTO = 1,
    EFX_FILTER_PRI_MANUAL = 2,
    EFX_FILTER_PRI_REQUIRED = 3
} ;
struct efx_filter_spec {
   unsigned short match_flags : 12 ;
   unsigned char priority : 2 ;
   unsigned char flags : 6 ;
   unsigned short dmaq_id : 12 ;
   u32 rss_context ;
   __be16 outer_vid ;
   __be16 inner_vid ;
   u8 loc_mac[6U] ;
   u8 rem_mac[6U] ;
   __be16 ether_type ;
   u8 ip_proto ;
   __be32 loc_host[4U] ;
   __be32 rem_host[4U] ;
   __be16 loc_port ;
   __be16 rem_port ;
};
struct efx_ptp_data;
struct efx_self_tests;
struct efx_buffer {
   void *addr ;
   dma_addr_t dma_addr ;
   unsigned int len ;
};
struct efx_special_buffer {
   struct efx_buffer buf ;
   unsigned int index ;
   unsigned int entries ;
    klee_make_symbolic(&entries, sizeof(int), "entries");
};
union __anonunion____missing_field_name_382 {
   struct sk_buff  const  *skb ;
   void *heap_buf ;
};
union __anonunion____missing_field_name_383 {
   efx_qword_t option ;
   dma_addr_t dma_addr ;
};
struct efx_tx_buffer {
   union __anonunion____missing_field_name_382 __annonCompField115 ;
   union __anonunion____missing_field_name_383 __annonCompField116 ;
   unsigned short flags ;
   unsigned short len ;
   unsigned short unmap_len ;
    klee_make_symbolic(&unmap_len, sizeof(short), "unmap_len");
   unsigned short dma_offset ;
    klee_make_symbolic(&dma_offset, sizeof(short), "dma_offset");
};
struct efx_tx_queue {
   struct efx_nic *efx ;
   unsigned int queue ;
    klee_make_symbolic(&queue, sizeof(int), "queue");
   struct efx_channel *channel ;
   struct netdev_queue *core_txq ;
   struct efx_tx_buffer *buffer ;
   struct efx_buffer *tsoh_page ;
   struct efx_special_buffer txd ;
   unsigned int ptr_mask ;
    klee_make_symbolic(&ptr_mask, sizeof(int), "ptr_mask");
   void *piobuf ;
   unsigned int piobuf_offset ;
    klee_make_symbolic(&piobuf_offset, sizeof(int), "piobuf_offset");
   bool initialised ;
   unsigned int read_count ;
    klee_make_symbolic(&read_count, sizeof(int), "read_count");
   unsigned int old_write_count ;
    klee_make_symbolic(&old_write_count, sizeof(int), "old_write_count");
   unsigned int merge_events ;
    klee_make_symbolic(&merge_events, sizeof(int), "merge_events");
   unsigned int insert_count ;
    klee_make_symbolic(&insert_count, sizeof(int), "insert_count");
   unsigned int write_count ;
    klee_make_symbolic(&write_count, sizeof(int), "write_count");
   unsigned int old_read_count ;
    klee_make_symbolic(&old_read_count, sizeof(int), "old_read_count");
   unsigned int tso_bursts ;
    klee_make_symbolic(&tso_bursts, sizeof(int), "tso_bursts");
   unsigned int tso_long_headers ;
    klee_make_symbolic(&tso_long_headers, sizeof(int), "tso_long_headers");
   unsigned int tso_packets ;
    klee_make_symbolic(&tso_packets, sizeof(int), "tso_packets");
   unsigned int pushes ;
    klee_make_symbolic(&pushes, sizeof(int), "pushes");
   unsigned int pio_packets ;
    klee_make_symbolic(&pio_packets, sizeof(int), "pio_packets");
   unsigned long tx_packets ;
   unsigned int empty_read_count ;
    klee_make_symbolic(&empty_read_count, sizeof(int), "empty_read_count");
   atomic_t flush_outstanding ;
};
struct efx_rx_buffer {
   dma_addr_t dma_addr ;
   struct page *page ;
   u16 page_offset ;
   u16 len ;
   u16 flags ;
};
struct efx_rx_queue {
   struct efx_nic *efx ;
   int core_index ;
    klee_make_symbolic(&core_index, sizeof(int), "core_index");
   struct efx_rx_buffer *buffer ;
   struct efx_special_buffer rxd ;
   unsigned int ptr_mask ;
   bool refill_enabled ;
   bool flush_pending ;
   unsigned int added_count ;
    klee_make_symbolic(&added_count, sizeof(int), "added_count");
   unsigned int notified_count ;
    klee_make_symbolic(&notified_count, sizeof(int), "notified_count");
   unsigned int removed_count ;
    klee_make_symbolic(&removed_count, sizeof(int), "removed_count");
   unsigned int scatter_n ;
    klee_make_symbolic(&scatter_n, sizeof(int), "scatter_n");
   unsigned int scatter_len ;
    klee_make_symbolic(&scatter_len, sizeof(int), "scatter_len");
   struct page **page_ring ;
   unsigned int page_add ;
    klee_make_symbolic(&page_add, sizeof(int), "page_add");
   unsigned int page_remove ;
    klee_make_symbolic(&page_remove, sizeof(int), "page_remove");
   unsigned int page_recycle_count ;
    klee_make_symbolic(&page_recycle_count, sizeof(int), "page_recycle_count");
   unsigned int page_recycle_failed ;
    klee_make_symbolic(&page_recycle_failed, sizeof(int), "page_recycle_failed");
   unsigned int page_recycle_full ;
    klee_make_symbolic(&page_recycle_full, sizeof(int), "page_recycle_full");
   unsigned int page_ptr_mask ;
    klee_make_symbolic(&page_ptr_mask, sizeof(int), "page_ptr_mask");
   unsigned int max_fill ;
    klee_make_symbolic(&max_fill, sizeof(int), "max_fill");
   unsigned int fast_fill_trigger ;
    klee_make_symbolic(&fast_fill_trigger, sizeof(int), "fast_fill_trigger");
   unsigned int min_fill ;
    klee_make_symbolic(&min_fill, sizeof(int), "min_fill");
   unsigned int min_overfill ;
    klee_make_symbolic(&min_overfill, sizeof(int), "min_overfill");
   unsigned int recycle_count ;
    klee_make_symbolic(&recycle_count, sizeof(int), "recycle_count");
   struct timer_list slow_fill ;
   unsigned int slow_fill_count ;
    klee_make_symbolic(&slow_fill_count, sizeof(int), "slow_fill_count");
   unsigned long rx_packets ;
};
enum efx_sync_events_state {
    SYNC_EVENTS_DISABLED = 0,
    SYNC_EVENTS_QUIESCENT = 1,
    SYNC_EVENTS_REQUESTED = 2,
    SYNC_EVENTS_VALID = 3
} ;
struct efx_channel_type;
struct efx_channel {
   struct efx_nic *efx ;
   int channel ;
    klee_make_symbolic(&channel, sizeof(int), "channel");
   struct efx_channel_type  const  *type ;
   bool eventq_init ;
   bool enabled ;
   int irq ;
   unsigned int irq_moderation ;
    klee_make_symbolic(&irq_moderation, sizeof(int), "irq_moderation");
   struct net_device *napi_dev ;
   struct napi_struct napi_str ;
   unsigned int state ;
   spinlock_t state_lock ;
   struct efx_special_buffer eventq ;
   unsigned int eventq_mask ;
    klee_make_symbolic(&eventq_mask, sizeof(int), "eventq_mask");
   unsigned int eventq_read_ptr ;
    klee_make_symbolic(&eventq_read_ptr, sizeof(int), "eventq_read_ptr");
   int event_test_cpu ;
    klee_make_symbolic(&event_test_cpu, sizeof(int), "event_test_cpu");
   unsigned int irq_count ;
    klee_make_symbolic(&irq_count, sizeof(int), "irq_count");
   unsigned int irq_mod_score ;
    klee_make_symbolic(&irq_mod_score, sizeof(int), "irq_mod_score");
   unsigned int rfs_filters_added ;
    klee_make_symbolic(&rfs_filters_added, sizeof(int), "rfs_filters_added");
   unsigned int n_rx_tobe_disc ;
    klee_make_symbolic(&n_rx_tobe_disc, sizeof(int), "n_rx_tobe_disc");
   unsigned int n_rx_ip_hdr_chksum_err ;
    klee_make_symbolic(&n_rx_ip_hdr_chksum_err, sizeof(int), "n_rx_ip_hdr_chksum_err");
   unsigned int n_rx_tcp_udp_chksum_err ;
    klee_make_symbolic(&n_rx_tcp_udp_chksum_err, sizeof(int), "n_rx_tcp_udp_chksum_err");
   unsigned int n_rx_mcast_mismatch ;
    klee_make_symbolic(&n_rx_mcast_mismatch, sizeof(int), "n_rx_mcast_mismatch");
   unsigned int n_rx_frm_trunc ;
    klee_make_symbolic(&n_rx_frm_trunc, sizeof(int), "n_rx_frm_trunc");
   unsigned int n_rx_overlength ;
    klee_make_symbolic(&n_rx_overlength, sizeof(int), "n_rx_overlength");
   unsigned int n_skbuff_leaks ;
    klee_make_symbolic(&n_skbuff_leaks, sizeof(int), "n_skbuff_leaks");
   unsigned int n_rx_nodesc_trunc ;
    klee_make_symbolic(&n_rx_nodesc_trunc, sizeof(int), "n_rx_nodesc_trunc");
   unsigned int n_rx_merge_events ;
    klee_make_symbolic(&n_rx_merge_events, sizeof(int), "n_rx_merge_events");
   unsigned int n_rx_merge_packets ;
    klee_make_symbolic(&n_rx_merge_packets, sizeof(int), "n_rx_merge_packets");
   unsigned int rx_pkt_n_frags ;
    klee_make_symbolic(&rx_pkt_n_frags, sizeof(int), "rx_pkt_n_frags");
   unsigned int rx_pkt_index ;
    klee_make_symbolic(&rx_pkt_index, sizeof(int), "rx_pkt_index");
   struct efx_rx_queue rx_queue ;
   struct efx_tx_queue tx_queue[4U] ;
   enum efx_sync_events_state sync_events_state ;
   u32 sync_timestamp_major ;
   u32 sync_timestamp_minor ;
};
struct efx_msi_context {
   struct efx_nic *efx ;
   unsigned int index ;
   char name[22U] ;
};
struct efx_channel_type {
   void (*handle_no_channel)(struct efx_nic * ) ;
   int (*pre_probe)(struct efx_channel * ) ;
   void (*post_remove)(struct efx_channel * ) ;
   void (*get_name)(struct efx_channel * , char * , size_t  ) ;
   struct efx_channel *(*copy)(struct efx_channel  const  * ) ;
   bool (*receive_skb)(struct efx_channel * , struct sk_buff * ) ;
   bool keep_eventq ;
};
enum efx_led_mode {
    EFX_LED_OFF = 0,
    EFX_LED_ON = 1,
    EFX_LED_DEFAULT = 2
} ;
enum efx_int_mode {
    EFX_INT_MODE_MSIX = 0,
    EFX_INT_MODE_MSI = 1,
    EFX_INT_MODE_LEGACY = 2,
    EFX_INT_MODE_MAX = 3
} ;
enum nic_state {
    STATE_UNINIT = 0,
    STATE_READY = 1,
    STATE_DISABLED = 2,
    STATE_RECOVERY = 3
} ;
struct efx_link_state {
   bool up ;
   bool fd ;
   u8 fc ;
   unsigned int speed ;
};
struct efx_phy_operations {
   int (*probe)(struct efx_nic * ) ;
   int (*init)(struct efx_nic * ) ;
   void (*fini)(struct efx_nic * ) ;
   void (*remove)(struct efx_nic * ) ;
   int (*reconfigure)(struct efx_nic * ) ;
   bool (*poll)(struct efx_nic * ) ;
   void (*get_settings)(struct efx_nic * , struct ethtool_cmd * ) ;
   int (*set_settings)(struct efx_nic * , struct ethtool_cmd * ) ;
   void (*set_npage_adv)(struct efx_nic * , u32  ) ;
   int (*test_alive)(struct efx_nic * ) ;
   char const   *(*test_name)(struct efx_nic * , unsigned int  ) ;
   int (*run_tests)(struct efx_nic * , int * , unsigned int  ) ;
   int (*get_module_eeprom)(struct efx_nic * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_module_info)(struct efx_nic * , struct ethtool_modinfo * ) ;
};
enum efx_phy_mode {
    PHY_MODE_NORMAL = 0,
    PHY_MODE_TX_DISABLED = 1,
    PHY_MODE_LOW_POWER = 2,
    PHY_MODE_OFF = 4,
    PHY_MODE_SPECIAL = 8
} ;
union efx_multicast_hash {
   u8 byte[32U] ;
   efx_oword_t oword[2U] ;
};
struct efx_nic_type;
struct efx_mcdi_data;
struct efx_nic {
   char name[16U] ;
   struct list_head node ;
   struct efx_nic *primary ;
   struct list_head secondary_list ;
   struct pci_dev *pci_dev ;
   unsigned int port_num ;
    klee_make_symbolic(&port_num, sizeof(int), "port_num");
   struct efx_nic_type  const  *type ;
   int legacy_irq ;
    klee_make_symbolic(&legacy_irq, sizeof(int), "legacy_irq");
   bool eeh_disabled_legacy_irq ;
   struct workqueue_struct *workqueue ;
   char workqueue_name[16U] ;
   struct work_struct reset_work ;
   resource_size_t membase_phys ;
   void *membase ;
   enum efx_int_mode interrupt_mode ;
   unsigned int timer_quantum_ns ;
    klee_make_symbolic(&timer_quantum_ns, sizeof(int), "timer_quantum_ns");
   bool irq_rx_adaptive ;
   unsigned int irq_rx_moderation ;
    klee_make_symbolic(&irq_rx_moderation, sizeof(int), "irq_rx_moderation");
   u32 msg_enable ;
   enum nic_state state ;
   unsigned long reset_pending ;
    klee_make_symbolic(&reset_pending, sizeof(long), "reset_pending");
   struct efx_channel *channel[32U] ;
   struct efx_msi_context msi_context[32U] ;
   struct efx_channel_type  const  *extra_channel_type[2U] ;
   unsigned int rxq_entries ;
    klee_make_symbolic(&rxq_entries, sizeof(int), "rxq_entries");
   unsigned int txq_entries ;
    klee_make_symbolic(&txq_entries, sizeof(int), "txq_entries");
   unsigned int txq_stop_thresh ;
    klee_make_symbolic(&txq_stop_thresh, sizeof(int), "txq_stop_thresh");
   unsigned int txq_wake_thresh ;
    klee_make_symbolic(&txq_wake_thresh, sizeof(int), "txq_wake_thresh");
   unsigned int tx_dc_base ;
    klee_make_symbolic(&tx_dc_base, sizeof(int), "tx_dc_base");
   unsigned int rx_dc_base ;
    klee_make_symbolic(&rx_dc_base, sizeof(int), "rx_dc_base");
   unsigned int sram_lim_qw ;
    klee_make_symbolic(&sram_lim_qw, sizeof(int), "sram_lim_qw");
   unsigned int next_buffer_table ;
    klee_make_symbolic(&next_buffer_table, sizeof(int), "next_buffer_table");
   unsigned int max_channels ;
    klee_make_symbolic(&max_channels, sizeof(int), "max_channels");
   unsigned int n_channels ;
    klee_make_symbolic(&n_channels, sizeof(int), "n_channels");
   unsigned int n_rx_channels ;
    klee_make_symbolic(&n_rx_channels, sizeof(int), "n_rx_channels");
   unsigned int rss_spread ;
    klee_make_symbolic(&rss_spread, sizeof(int), "rss_spread");
   unsigned int tx_channel_offset ;
    klee_make_symbolic(&tx_channel_offset, sizeof(int), "tx_channel_offset");
   unsigned int n_tx_channels ;
    klee_make_symbolic(&n_tx_channels, sizeof(int), "n_tx_channels");
   unsigned int rx_ip_align ;
    klee_make_symbolic(&rx_ip_align, sizeof(int), "rx_ip_align");
   unsigned int rx_dma_len ;
    klee_make_symbolic(&rx_dma_len, sizeof(int), "rx_dma_len");
   unsigned int rx_buffer_order ;
    klee_make_symbolic(&rx_buffer_order, sizeof(int), "rx_buffer_order");
   unsigned int rx_buffer_truesize ;
    klee_make_symbolic(&rx_buffer_truesize, sizeof(int), "rx_buffer_truesize");
   unsigned int rx_page_buf_step ;
    klee_make_symbolic(&rx_page_buf_step, sizeof(int), "rx_page_buf_step");
   unsigned int rx_bufs_per_page ;
    klee_make_symbolic(&rx_bufs_per_page, sizeof(int), "rx_bufs_per_page");
   unsigned int rx_pages_per_batch ;
    klee_make_symbolic(&rx_pages_per_batch, sizeof(int), "rx_pages_per_batch");
   unsigned int rx_prefix_size ;
    klee_make_symbolic(&rx_prefix_size, sizeof(int), "rx_prefix_size");
   int rx_packet_hash_offset ;
    klee_make_symbolic(&rx_packet_hash_offset, sizeof(int), "rx_packet_hash_offset");
   int rx_packet_len_offset ;
    klee_make_symbolic(&rx_packet_len_offset, sizeof(int), "rx_packet_len_offset");
   int rx_packet_ts_offset ;
    klee_make_symbolic(&rx_packet_ts_offset, sizeof(int), "rx_packet_ts_offset");
   u8 rx_hash_key[40U] ;
   u32 rx_indir_table[128U] ;
   bool rx_scatter ;
   unsigned int int_error_count ;
    klee_make_symbolic(&int_error_count, sizeof(int), "int_error_count");
   unsigned long int_error_expire ;
    klee_make_symbolic(&int_error_expire, sizeof(long), "int_error_expire");
   bool irq_soft_enabled ;
   struct efx_buffer irq_status ;
   unsigned int irq_zero_count ;
    klee_make_symbolic(&irq_zero_count, sizeof(int), "irq_zero_count");
   unsigned int irq_level ;
    klee_make_symbolic(&irq_level, sizeof(int), "irq_level");
   struct delayed_work selftest_work ;
   struct list_head mtd_list ;
   void *nic_data ;
   struct efx_mcdi_data *mcdi ;
   struct mutex mac_lock ;
   struct work_struct mac_work ;
   bool port_enabled ;
   bool mc_bist_for_other_fn ;
   bool port_initialized ;
   struct net_device *net_dev ;
   struct efx_buffer stats_buffer ;
   u64 rx_nodesc_drops_total ;
   u64 rx_nodesc_drops_while_down ;
   bool rx_nodesc_drops_prev_state ;
   unsigned int phy_type ;
    klee_make_symbolic(&phy_type, sizeof(int), "phy_type");
   struct efx_phy_operations  const  *phy_op ;
   void *phy_data ;
   struct mdio_if_info mdio ;
   unsigned int mdio_bus ;
    klee_make_symbolic(&mdio_bus, sizeof(int), "mdio_bus");
   enum efx_phy_mode phy_mode ;
   u32 link_advertising ;
   struct efx_link_state link_state ;
   unsigned int n_link_state_changes ;
    klee_make_symbolic(&n_link_state_changes, sizeof(int), "n_link_state_changes");
   bool unicast_filter ;
   union efx_multicast_hash multicast_hash ;
   u8 wanted_fc ;
   unsigned int fc_disable ;
    klee_make_symbolic(&fc_disable, sizeof(int), "fc_disable");
   atomic_t rx_reset ;
   enum efx_loopback_mode loopback_mode ;
   u64 loopback_modes ;
   void *loopback_selftest ;
   struct rw_semaphore filter_sem ;
   spinlock_t filter_lock ;
   void *filter_state ;
   u32 *rps_flow_id ;
   unsigned int rps_expire_index ;
    klee_make_symbolic(&rps_expire_index, sizeof(int), "rps_expire_index");
   atomic_t active_queues ;
   atomic_t rxq_flush_pending ;
   atomic_t rxq_flush_outstanding ;
   wait_queue_head_t flush_wq ;
   unsigned int vf_count ;
    klee_make_symbolic(&vf_count, sizeof(int), "vf_count");
   unsigned int vf_init_count ;
    klee_make_symbolic(&vf_init_count, sizeof(int), "vf_init_count");
   unsigned int vi_scale ;
    klee_make_symbolic(&vi_scale, sizeof(int), "vi_scale");
   struct efx_ptp_data *ptp_data ;
   char *vpd_sn ;
   struct delayed_work monitor_work ;
   spinlock_t biu_lock ;
   int last_irq_cpu ;
    klee_make_symbolic(&last_irq_cpu, sizeof(int), "last_irq_cpu");
   spinlock_t stats_lock ;
   atomic_t n_rx_noskb_drops ;
};
struct efx_mtd_partition {
   struct list_head node ;
   struct mtd_info mtd ;
   char const   *dev_type_name ;
   char const   *type_name ;
   char name[36U] ;
};
struct efx_nic_type {
   bool is_vf ;
   unsigned int mem_bar ;
    klee_make_symbolic(&mem_bar, sizeof(int), "mem_bar");
   unsigned int (*mem_map_size)(struct efx_nic * ) ;
   int (*probe)(struct efx_nic * ) ;
   void (*remove)(struct efx_nic * ) ;
   int (*init)(struct efx_nic * ) ;
   int (*dimension_resources)(struct efx_nic * ) ;
   void (*fini)(struct efx_nic * ) ;
   void (*monitor)(struct efx_nic * ) ;
   enum reset_type (*map_reset_reason)(enum reset_type  ) ;
   int (*map_reset_flags)(u32 * ) ;
   int (*reset)(struct efx_nic * , enum reset_type  ) ;
   int (*probe_port)(struct efx_nic * ) ;
   void (*remove_port)(struct efx_nic * ) ;
   bool (*handle_global_event)(struct efx_channel * , efx_qword_t * ) ;
   int (*fini_dmaq)(struct efx_nic * ) ;
   void (*prepare_flush)(struct efx_nic * ) ;
   void (*finish_flush)(struct efx_nic * ) ;
   void (*prepare_flr)(struct efx_nic * ) ;
   void (*finish_flr)(struct efx_nic * ) ;
   size_t (*describe_stats)(struct efx_nic * , u8 * ) ;
   size_t (*update_stats)(struct efx_nic * , u64 * , struct rtnl_link_stats64 * ) ;
   void (*start_stats)(struct efx_nic * ) ;
   void (*pull_stats)(struct efx_nic * ) ;
   void (*stop_stats)(struct efx_nic * ) ;
   void (*set_id_led)(struct efx_nic * , enum efx_led_mode  ) ;
   void (*push_irq_moderation)(struct efx_channel * ) ;
   int (*reconfigure_port)(struct efx_nic * ) ;
   void (*prepare_enable_fc_tx)(struct efx_nic * ) ;
   int (*reconfigure_mac)(struct efx_nic * ) ;
   bool (*check_mac_fault)(struct efx_nic * ) ;
   void (*get_wol)(struct efx_nic * , struct ethtool_wolinfo * ) ;
   int (*set_wol)(struct efx_nic * , u32  ) ;
   void (*resume_wol)(struct efx_nic * ) ;
   int (*test_chip)(struct efx_nic * , struct efx_self_tests * ) ;
   int (*test_nvram)(struct efx_nic * ) ;
   void (*mcdi_request)(struct efx_nic * , efx_dword_t const   * , size_t  , efx_dword_t const   * ,
                        size_t  ) ;
   bool (*mcdi_poll_response)(struct efx_nic * ) ;
   void (*mcdi_read_response)(struct efx_nic * , efx_dword_t * , size_t  , size_t  ) ;
   int (*mcdi_poll_reboot)(struct efx_nic * ) ;
   void (*irq_enable_master)(struct efx_nic * ) ;
   void (*irq_test_generate)(struct efx_nic * ) ;
   void (*irq_disable_non_ev)(struct efx_nic * ) ;
   irqreturn_t (*irq_handle_msi)(int  , void * ) ;
   irqreturn_t (*irq_handle_legacy)(int  , void * ) ;
   int (*tx_probe)(struct efx_tx_queue * ) ;
   void (*tx_init)(struct efx_tx_queue * ) ;
   void (*tx_remove)(struct efx_tx_queue * ) ;
   void (*tx_write)(struct efx_tx_queue * ) ;
   int (*rx_push_rss_config)(struct efx_nic * , bool  , u32 const   * ) ;
   int (*rx_probe)(struct efx_rx_queue * ) ;
   void (*rx_init)(struct efx_rx_queue * ) ;
   void (*rx_remove)(struct efx_rx_queue * ) ;
   void (*rx_write)(struct efx_rx_queue * ) ;
   void (*rx_defer_refill)(struct efx_rx_queue * ) ;
   int (*ev_probe)(struct efx_channel * ) ;
   int (*ev_init)(struct efx_channel * ) ;
   void (*ev_fini)(struct efx_channel * ) ;
   void (*ev_remove)(struct efx_channel * ) ;
   int (*ev_process)(struct efx_channel * , int  ) ;
   void (*ev_read_ack)(struct efx_channel * ) ;
   void (*ev_test_generate)(struct efx_channel * ) ;
   int (*filter_table_probe)(struct efx_nic * ) ;
   void (*filter_table_restore)(struct efx_nic * ) ;
   void (*filter_table_remove)(struct efx_nic * ) ;
   void (*filter_update_rx_scatter)(struct efx_nic * ) ;
   s32 (*filter_insert)(struct efx_nic * , struct efx_filter_spec * , bool  ) ;
   int (*filter_remove_safe)(struct efx_nic * , enum efx_filter_priority  , u32  ) ;
   int (*filter_get_safe)(struct efx_nic * , enum efx_filter_priority  , u32  , struct efx_filter_spec * ) ;
   int (*filter_clear_rx)(struct efx_nic * , enum efx_filter_priority  ) ;
   u32 (*filter_count_rx_used)(struct efx_nic * , enum efx_filter_priority  ) ;
   u32 (*filter_get_rx_id_limit)(struct efx_nic * ) ;
   s32 (*filter_get_rx_ids)(struct efx_nic * , enum efx_filter_priority  , u32 * ,
                            u32  ) ;
   s32 (*filter_rfs_insert)(struct efx_nic * , struct efx_filter_spec * ) ;
   bool (*filter_rfs_expire_one)(struct efx_nic * , u32  , unsigned int  ) ;
   int (*mtd_probe)(struct efx_nic * ) ;
   void (*mtd_rename)(struct efx_mtd_partition * ) ;
   int (*mtd_read)(struct mtd_info * , loff_t  , size_t  , size_t * , u8 * ) ;
   int (*mtd_erase)(struct mtd_info * , loff_t  , size_t  ) ;
   int (*mtd_write)(struct mtd_info * , loff_t  , size_t  , size_t * , u8 const   * ) ;
   int (*mtd_sync)(struct mtd_info * ) ;
   void (*ptp_write_host_time)(struct efx_nic * , u32  ) ;
   int (*ptp_set_ts_sync_events)(struct efx_nic * , bool  , bool  ) ;
   int (*ptp_set_ts_config)(struct efx_nic * , struct hwtstamp_config * ) ;
   int (*sriov_configure)(struct efx_nic * , int  ) ;
   int (*sriov_init)(struct efx_nic * ) ;
   void (*sriov_fini)(struct efx_nic * ) ;
   bool (*sriov_wanted)(struct efx_nic * ) ;
   void (*sriov_reset)(struct efx_nic * ) ;
   void (*sriov_flr)(struct efx_nic * , unsigned int  ) ;
   int (*sriov_set_vf_mac)(struct efx_nic * , int  , u8 * ) ;
   int (*sriov_set_vf_vlan)(struct efx_nic * , int  , u16  , u8  ) ;
   int (*sriov_set_vf_spoofchk)(struct efx_nic * , int  , bool  ) ;
   int (*sriov_get_vf_config)(struct efx_nic * , int  , struct ifla_vf_info * ) ;
   int (*sriov_set_vf_link_state)(struct efx_nic * , int  , int  ) ;
   int (*sriov_get_phys_port_id)(struct efx_nic * , struct netdev_phys_item_id * ) ;
   int (*vswitching_probe)(struct efx_nic * ) ;
   int (*vswitching_restore)(struct efx_nic * ) ;
   void (*vswitching_remove)(struct efx_nic * ) ;
   int (*get_mac_address)(struct efx_nic * , unsigned char * ) ;
   int (*set_mac_address)(struct efx_nic * ) ;
   int revision ;
    klee_make_symbolic(&revision, sizeof(int), "revision");
   unsigned int txd_ptr_tbl_base ;
    klee_make_symbolic(&txd_ptr_tbl_base, sizeof(int), "txd_ptr_tbl_base");
   unsigned int rxd_ptr_tbl_base ;
    klee_make_symbolic(&rxd_ptr_tbl_base, sizeof(int), "rxd_ptr_tbl_base");
   unsigned int buf_tbl_base ;
    klee_make_symbolic(&buf_tbl_base, sizeof(int), "buf_tbl_base");
   unsigned int evq_ptr_tbl_base ;
    klee_make_symbolic(&evq_ptr_tbl_base, sizeof(int), "evq_ptr_tbl_base");
   unsigned int evq_rptr_tbl_base ;
    klee_make_symbolic(&evq_rptr_tbl_base, sizeof(int), "evq_rptr_tbl_base");
   u64 max_dma_mask ;
   unsigned int rx_prefix_size ;
   unsigned int rx_hash_offset ;
    klee_make_symbolic(&rx_hash_offset, sizeof(int), "rx_hash_offset");
   unsigned int rx_ts_offset ;
    klee_make_symbolic(&rx_ts_offset, sizeof(int), "rx_ts_offset");
   unsigned int rx_buffer_padding ;
    klee_make_symbolic(&rx_buffer_padding, sizeof(int), "rx_buffer_padding");
   bool can_rx_scatter ;
   bool always_rx_scatter ;
   unsigned int max_interrupt_mode ;
    klee_make_symbolic(&max_interrupt_mode, sizeof(int), "max_interrupt_mode");
   unsigned int timer_period_max ;
    klee_make_symbolic(&timer_period_max, sizeof(int), "timer_period_max");
   netdev_features_t offload_features ;
   int mcdi_max_ver ;
    klee_make_symbolic(&mcdi_max_ver, sizeof(int), "mcdi_max_ver");
   unsigned int max_rx_ip_filters ;
    klee_make_symbolic(&max_rx_ip_filters, sizeof(int), "max_rx_ip_filters");
   u32 hwtstamp_filters ;
};
enum efx_mcdi_state {
    MCDI_STATE_QUIESCENT = 0,
    MCDI_STATE_RUNNING_SYNC = 1,
    MCDI_STATE_RUNNING_ASYNC = 2,
    MCDI_STATE_COMPLETED = 3
} ;
enum efx_mcdi_mode {
    MCDI_MODE_POLL = 0,
    MCDI_MODE_EVENTS = 1,
    MCDI_MODE_FAIL = 2
} ;
struct efx_mcdi_iface {
   struct efx_nic *efx ;
   enum efx_mcdi_state state ;
   enum efx_mcdi_mode mode ;
   wait_queue_head_t wq ;
   spinlock_t iface_lock ;
   bool new_epoch ;
   unsigned int credits ;
    klee_make_symbolic(&credits, sizeof(int), "credits");
   unsigned int seqno ;
    klee_make_symbolic(&seqno, sizeof(int), "seqno");
   int resprc ;
    klee_make_symbolic(&resprc, sizeof(int), "resprc");
   size_t resp_hdr_len ;
   size_t resp_data_len ;
   spinlock_t async_lock ;
   struct list_head async_list ;
   struct timer_list async_timer ;
   char *logging_buffer ;
   bool logging_enabled ;
};
struct efx_mcdi_mon_attribute;
struct efx_mcdi_mon {
   struct efx_buffer dma_buf ;
   struct mutex update_lock ;
   unsigned long last_update ;
    klee_make_symbolic(&last_update, sizeof(long), "last_update");
   struct device *device ;
   struct efx_mcdi_mon_attribute *attrs ;
   struct attribute_group group ;
   struct attribute_group  const  *groups[2U] ;
   unsigned int n_attrs ;
    klee_make_symbolic(&n_attrs, sizeof(int), "n_attrs");
};
struct efx_mcdi_data {
   struct efx_mcdi_iface iface ;
   struct efx_mcdi_mon hwmon ;
   u32 fn_flags ;
};
struct efx_loopback_self_tests {
   int tx_sent[4U] ;
   int tx_done[4U] ;
   int rx_good ;
    klee_make_symbolic(&rx_good, sizeof(int), "rx_good");
   int rx_bad ;
    klee_make_symbolic(&rx_bad, sizeof(int), "rx_bad");
};
struct efx_self_tests {
   int phy_alive ;
    klee_make_symbolic(&phy_alive, sizeof(int), "phy_alive");
   int nvram ;
    klee_make_symbolic(&nvram, sizeof(int), "nvram");
   int interrupt ;
    klee_make_symbolic(&interrupt, sizeof(int), "interrupt");
   int eventq_dma[32U] ;
   int eventq_int[32U] ;
   int memory ;
    klee_make_symbolic(&memory, sizeof(int), "memory");
   int registers ;
    klee_make_symbolic(&registers, sizeof(int), "registers");
   int phy_ext[20U] ;
   struct efx_loopback_self_tests loopback[18U] ;
};
typedef bool ldv_func_ret_type;
typedef bool ldv_func_ret_type___0;
typedef bool ldv_func_ret_type___1;
typedef bool ldv_func_ret_type___2;
typedef int ldv_func_ret_type___3;
    klee_make_symbolic(&ldv_func_ret_type___3, sizeof(int), "ldv_func_ret_type___3");
typedef int ldv_func_ret_type___4;
    klee_make_symbolic(&ldv_func_ret_type___4, sizeof(int), "ldv_func_ret_type___4");
typedef int ldv_func_ret_type___5;
    klee_make_symbolic(&ldv_func_ret_type___5, sizeof(int), "ldv_func_ret_type___5");
typedef bool ldv_func_ret_type___6;
typedef bool ldv_func_ret_type___7;
typedef int ldv_func_ret_type___8;
    klee_make_symbolic(&ldv_func_ret_type___8, sizeof(int), "ldv_func_ret_type___8");
typedef bool ldv_func_ret_type___9;
typedef int ldv_func_ret_type___10;
    klee_make_symbolic(&ldv_func_ret_type___10, sizeof(int), "ldv_func_ret_type___10");
typedef __u16 __le16;
enum hrtimer_restart;
struct __anonstruct_near_229 {
   u16 index ;
   u16 dist ;
};
struct cpu_rmap {
   struct kref refcount ;
   u16 size ;
   u16 used ;
   void **obj ;
   struct __anonstruct_near_229 near[0U] ;
};
struct efx_hw_stat_desc {
   char const   *name ;
   u16 dma_width ;
   u16 offset ;
};
struct efx_nic_reg {
   unsigned int offset : 24 ;
   unsigned char min_revision : 3 ;
   unsigned char max_revision : 3 ;
};
struct efx_nic_reg_table {
   unsigned int offset : 24 ;
   unsigned char min_revision : 3 ;
   unsigned char max_revision : 3 ;
   unsigned char step : 6 ;
   unsigned int rows : 21 ;
};
enum hrtimer_restart;
struct __wait_queue;
typedef struct __wait_queue wait_queue_t;
struct __wait_queue {
   unsigned int flags ;
   void *private ;
   int (*func)(wait_queue_t * , unsigned int  , int  , void * ) ;
   struct list_head task_list ;
};
struct rt_mutex {
   raw_spinlock_t wait_lock ;
   struct rb_root waiters ;
   struct rb_node *waiters_leftmost ;
   struct task_struct *owner ;
   int save_state ;
    klee_make_symbolic(&save_state, sizeof(int), "save_state");
   char const   *name ;
   char const   *file ;
   int line ;
   void *magic ;
};
struct netdev_hw_addr {
   struct list_head list ;
   unsigned char addr[32U] ;
   unsigned char type ;
   bool global_use ;
   int sync_cnt ;
    klee_make_symbolic(&sync_cnt, sizeof(int), "sync_cnt");
   int refcount ;
   int synced ;
    klee_make_symbolic(&synced, sizeof(int), "synced");
   struct callback_head callback_head ;
};
struct i2c_msg {
   __u16 addr ;
   __u16 flags ;
   __u16 len ;
   __u8 *buf ;
};
union i2c_smbus_data {
   __u8 byte ;
   __u16 word ;
   __u8 block[34U] ;
};
struct i2c_algorithm;
struct i2c_adapter;
struct i2c_client;
enum i2c_slave_event;
enum i2c_slave_event;
struct i2c_client {
   unsigned short flags ;
   unsigned short addr ;
   char name[20U] ;
   struct i2c_adapter *adapter ;
   struct device dev ;
   int irq ;
   struct list_head detected ;
   int (*slave_cb)(struct i2c_client * , enum i2c_slave_event  , u8 * ) ;
};
enum i2c_slave_event {
    I2C_SLAVE_READ_REQUESTED = 0,
    I2C_SLAVE_WRITE_REQUESTED = 1,
    I2C_SLAVE_READ_PROCESSED = 2,
    I2C_SLAVE_WRITE_RECEIVED = 3,
    I2C_SLAVE_STOP = 4
} ;
struct i2c_algorithm {
   int (*master_xfer)(struct i2c_adapter * , struct i2c_msg * , int  ) ;
   int (*smbus_xfer)(struct i2c_adapter * , u16  , unsigned short  , char  , u8  ,
                     int  , union i2c_smbus_data * ) ;
   u32 (*functionality)(struct i2c_adapter * ) ;
   int (*reg_slave)(struct i2c_client * ) ;
   int (*unreg_slave)(struct i2c_client * ) ;
};
struct i2c_bus_recovery_info {
   int (*recover_bus)(struct i2c_adapter * ) ;
   int (*get_scl)(struct i2c_adapter * ) ;
   void (*set_scl)(struct i2c_adapter * , int  ) ;
   int (*get_sda)(struct i2c_adapter * ) ;
   void (*prepare_recovery)(struct i2c_adapter * ) ;
   void (*unprepare_recovery)(struct i2c_adapter * ) ;
   int scl_gpio ;
    klee_make_symbolic(&scl_gpio, sizeof(int), "scl_gpio");
   int sda_gpio ;
    klee_make_symbolic(&sda_gpio, sizeof(int), "sda_gpio");
};
struct i2c_adapter_quirks {
   u64 flags ;
   int max_num_msgs ;
    klee_make_symbolic(&max_num_msgs, sizeof(int), "max_num_msgs");
   u16 max_write_len ;
   u16 max_read_len ;
   u16 max_comb_1st_msg_len ;
   u16 max_comb_2nd_msg_len ;
};
struct i2c_adapter {
   struct module *owner ;
   unsigned int class ;
   struct i2c_algorithm  const  *algo ;
   void *algo_data ;
   struct rt_mutex bus_lock ;
   int timeout ;
   int retries ;
   struct device dev ;
   int nr ;
   char name[48U] ;
   struct completion dev_released ;
   struct mutex userspace_clients_lock ;
   struct list_head userspace_clients ;
   struct i2c_bus_recovery_info *bus_recovery_info ;
   struct i2c_adapter_quirks  const  *quirks ;
};
struct i2c_algo_bit_data {
   void *data ;
   void (*setsda)(void * , int  ) ;
   void (*setscl)(void * , int  ) ;
   int (*getsda)(void * ) ;
   int (*getscl)(void * ) ;
   int (*pre_xfer)(struct i2c_adapter * ) ;
   void (*post_xfer)(struct i2c_adapter * ) ;
   int udelay ;
    klee_make_symbolic(&udelay, sizeof(int), "udelay");
   int timeout ;
};
struct falcon_board_type {
   u8 id ;
   int (*init)(struct efx_nic * ) ;
   void (*init_phy)(struct efx_nic * ) ;
   void (*fini)(struct efx_nic * ) ;
   void (*set_id_led)(struct efx_nic * , enum efx_led_mode  ) ;
   int (*monitor)(struct efx_nic * ) ;
};
struct falcon_board {
   struct falcon_board_type  const  *type ;
   int major ;
    klee_make_symbolic(&major, sizeof(int), "major");
   int minor ;
    klee_make_symbolic(&minor, sizeof(int), "minor");
   struct i2c_adapter i2c_adap ;
   struct i2c_algo_bit_data i2c_data ;
   struct i2c_client *hwmon_client ;
   struct i2c_client *ioexp_client ;
};
struct falcon_spi_device {
   int device_id ;
    klee_make_symbolic(&device_id, sizeof(int), "device_id");
   unsigned int size ;
   unsigned int addr_len ;
   unsigned char munge_address : 1 ;
   u8 erase_command ;
   unsigned int erase_size ;
    klee_make_symbolic(&erase_size, sizeof(int), "erase_size");
   unsigned int block_size ;
    klee_make_symbolic(&block_size, sizeof(int), "block_size");
};
struct falcon_nic_data {
   struct pci_dev *pci_dev2 ;
   struct falcon_board board ;
   u64 stats[49U] ;
   unsigned int stats_disable_count ;
    klee_make_symbolic(&stats_disable_count, sizeof(int), "stats_disable_count");
   bool stats_pending ;
   struct timer_list stats_timer ;
   struct falcon_spi_device spi_flash ;
   struct falcon_spi_device spi_eeprom ;
   struct mutex spi_lock ;
   struct mutex mdio_lock ;
   bool xmac_poll_required ;
};
struct siena_vf;
struct siena_nic_data {
   struct efx_nic *efx ;
   int wol_filter_id ;
    klee_make_symbolic(&wol_filter_id, sizeof(int), "wol_filter_id");
   u64 stats[59U] ;
   struct siena_vf *vf ;
   struct efx_channel *vfdi_channel ;
   unsigned int vf_buftbl_base ;
    klee_make_symbolic(&vf_buftbl_base, sizeof(int), "vf_buftbl_base");
   struct efx_buffer vfdi_status ;
   struct list_head local_addr_list ;
   struct list_head local_page_list ;
   struct mutex local_lock ;
   struct work_struct peer_work ;
};
struct efx_farch_register_test {
   unsigned int address ;
    klee_make_symbolic(&address, sizeof(int), "address");
   efx_oword_t mask ;
};
enum efx_farch_filter_table_id {
    EFX_FARCH_FILTER_TABLE_RX_IP = 0,
    EFX_FARCH_FILTER_TABLE_RX_MAC = 1,
    EFX_FARCH_FILTER_TABLE_RX_DEF = 2,
    EFX_FARCH_FILTER_TABLE_TX_MAC = 3,
    EFX_FARCH_FILTER_TABLE_COUNT = 4
} ;
struct efx_farch_filter_spec {
   unsigned char type : 4 ;
   unsigned char priority : 4 ;
   u8 flags ;
   u16 dmaq_id ;
   u32 data[3U] ;
};
struct efx_farch_filter_table {
   enum efx_farch_filter_table_id id ;
   u32 offset ;
   unsigned int size ;
   unsigned int step ;
    klee_make_symbolic(&step, sizeof(int), "step");
   unsigned int used ;
   unsigned long *used_bitmap ;
   struct efx_farch_filter_spec *spec ;
   unsigned int search_limit[10U] ;
};
struct efx_farch_filter_state {
   struct efx_farch_filter_table table[4U] ;
};
struct __anonstruct_mm_segment_t_29 {
   unsigned long seg ;
    klee_make_symbolic(&seg, sizeof(long), "seg");
};
typedef struct __anonstruct_mm_segment_t_29 mm_segment_t;
struct thread_info {
   struct task_struct *task ;
   __u32 flags ;
   __u32 status ;
   __u32 cpu ;
   int saved_preempt_count ;
    klee_make_symbolic(&saved_preempt_count, sizeof(int), "saved_preempt_count");
   mm_segment_t addr_limit ;
   void *sysenter_return ;
   unsigned char sig_on_uaccess_error : 1 ;
   unsigned char uaccess_err : 1 ;
};
enum hrtimer_restart;
enum i2c_slave_event;
enum i2c_slave_event;
struct falcon_nvconfig_board_v2 {
   __le16 nports ;
   u8 port0_phy_addr ;
   u8 port0_phy_type ;
   u8 port1_phy_addr ;
   u8 port1_phy_type ;
   __le16 asic_sub_revision ;
   __le16 board_revision ;
};
struct falcon_nvconfig_board_v3 {
   __le32 spi_device_type[2U] ;
};
struct falcon_nvconfig {
   efx_oword_t ee_vpd_cfg_reg ;
   u8 mac_address[2U][8U] ;
   efx_oword_t pcie_sd_ctl0123_reg ;
   efx_oword_t pcie_sd_ctl45_reg ;
   efx_oword_t pcie_pcs_ctl_stat_reg ;
   efx_oword_t hw_init_reg ;
   efx_oword_t nic_stat_reg ;
   efx_oword_t glb_ctl_reg ;
   efx_oword_t srm_cfg_reg ;
   efx_oword_t spare_reg ;
   __le16 board_magic_num ;
   __le16 board_struct_ver ;
   __le16 board_checksum ;
   struct falcon_nvconfig_board_v2 board_v2 ;
   efx_oword_t ee_base_page_reg ;
   struct falcon_nvconfig_board_v3 board_v3 ;
};
struct falcon_mtd_partition {
   struct efx_mtd_partition common ;
   struct falcon_spi_device  const  *spi ;
   size_t offset ;
};
typedef int ldv_func_ret_type___11;
    klee_make_symbolic(&ldv_func_ret_type___11, sizeof(int), "ldv_func_ret_type___11");
typedef int ldv_func_ret_type___12;
    klee_make_symbolic(&ldv_func_ret_type___12, sizeof(int), "ldv_func_ret_type___12");
typedef int ldv_func_ret_type___13;
    klee_make_symbolic(&ldv_func_ret_type___13, sizeof(int), "ldv_func_ret_type___13");
typedef __u16 uint16_t;
enum hrtimer_restart;
struct efx_mcdi_mtd_partition {
   struct efx_mtd_partition common ;
   bool updating ;
   u16 nvram_type ;
   u16 fw_subtype ;
};
struct siena_nvram_type_info {
   int port ;
   char const   *name ;
};
enum hrtimer_restart;
enum efx_filter_match_flags {
    EFX_FILTER_MATCH_REM_HOST = 1,
    EFX_FILTER_MATCH_LOC_HOST = 2,
    EFX_FILTER_MATCH_REM_MAC = 4,
    EFX_FILTER_MATCH_REM_PORT = 8,
    EFX_FILTER_MATCH_LOC_MAC = 16,
    EFX_FILTER_MATCH_LOC_PORT = 32,
    EFX_FILTER_MATCH_ETHER_TYPE = 64,
    EFX_FILTER_MATCH_INNER_VID = 128,
    EFX_FILTER_MATCH_OUTER_VID = 256,
    EFX_FILTER_MATCH_IP_PROTO = 512,
    EFX_FILTER_MATCH_LOC_MAC_IG = 1024
} ;
enum efx_filter_flags {
    EFX_FILTER_FLAG_RX_RSS = 1,
    EFX_FILTER_FLAG_RX_SCATTER = 2,
    EFX_FILTER_FLAG_RX_OVER_AUTO = 4,
    EFX_FILTER_FLAG_RX = 8,
    EFX_FILTER_FLAG_TX = 16
} ;
typedef void efx_mcdi_async_completer(struct efx_nic * , unsigned long  , int  , efx_dword_t * ,
                                      size_t  );
struct ef10_vf;
struct efx_ef10_nic_data {
   struct efx_buffer mcdi_buf ;
   u16 warm_boot_count ;
   unsigned int vi_base ;
    klee_make_symbolic(&vi_base, sizeof(int), "vi_base");
   unsigned int n_allocated_vis ;
    klee_make_symbolic(&n_allocated_vis, sizeof(int), "n_allocated_vis");
   bool must_realloc_vis ;
   bool must_restore_filters ;
   unsigned int n_piobufs ;
    klee_make_symbolic(&n_piobufs, sizeof(int), "n_piobufs");
   void *wc_membase ;
   void *pio_write_base ;
   unsigned int pio_write_vi_base ;
    klee_make_symbolic(&pio_write_vi_base, sizeof(int), "pio_write_vi_base");
   unsigned int piobuf_handle[16U] ;
   bool must_restore_piobufs ;
   u32 rx_rss_context ;
   bool rx_rss_context_exclusive ;
   u64 stats[73U] ;
   bool workaround_35388 ;
   bool must_check_datapath_caps ;
   u32 datapath_caps ;
   unsigned int rx_dpcpu_fw_id ;
    klee_make_symbolic(&rx_dpcpu_fw_id, sizeof(int), "rx_dpcpu_fw_id");
   unsigned int tx_dpcpu_fw_id ;
    klee_make_symbolic(&tx_dpcpu_fw_id, sizeof(int), "tx_dpcpu_fw_id");
   unsigned int vport_id ;
    klee_make_symbolic(&vport_id, sizeof(int), "vport_id");
   bool must_probe_vswitching ;
   unsigned int pf_index ;
    klee_make_symbolic(&pf_index, sizeof(int), "pf_index");
   u8 port_id[6U] ;
   unsigned int vf_index ;
    klee_make_symbolic(&vf_index, sizeof(int), "vf_index");
   struct ef10_vf *vf ;
   u8 vport_mac[6U] ;
};
struct ef10_vf {
   struct efx_nic *efx ;
   struct pci_dev *pci_dev ;
   unsigned int vport_id ;
   unsigned int vport_assigned ;
    klee_make_symbolic(&vport_assigned, sizeof(int), "vport_assigned");
   u8 mac[6U] ;
   u16 vlan ;
};
struct __anonstruct_entry_373 {
   unsigned long spec ;
    klee_make_symbolic(&spec, sizeof(long), "spec");
   u64 handle ;
};
struct __anonstruct_dev_uc_list_374 {
   u8 addr[6U] ;
   u16 id ;
};
struct __anonstruct_dev_mc_list_375 {
   u8 addr[6U] ;
   u16 id ;
};
struct efx_ef10_filter_table {
   enum efx_filter_match_flags rx_match_flags[61U] ;
   unsigned int rx_match_count ;
    klee_make_symbolic(&rx_match_count, sizeof(int), "rx_match_count");
   struct __anonstruct_entry_373 *entry ;
   wait_queue_head_t waitq ;
   struct __anonstruct_dev_uc_list_374 dev_uc_list[32U] ;
   struct __anonstruct_dev_mc_list_375 dev_mc_list[256U] ;
   int dev_uc_count ;
    klee_make_symbolic(&dev_uc_count, sizeof(int), "dev_uc_count");
   int dev_mc_count ;
    klee_make_symbolic(&dev_mc_count, sizeof(int), "dev_mc_count");
};
struct __anonstruct_531 {
   unsigned long spec ;
   u64 handle ;
};
struct __anonstruct_533 {
   unsigned long spec ;
   u64 handle ;
};
struct efx_ef10_nvram_type_info {
   u16 type ;
   u16 type_mask ;
   u8 port ;
   char const   *name ;
};
typedef __u16 __sum16;
typedef int pao_T__;
    klee_make_symbolic(&pao_T__, sizeof(int), "pao_T__");
typedef int pao_T_____0;
    klee_make_symbolic(&pao_T_____0, sizeof(int), "pao_T_____0");
enum hrtimer_restart;
struct skb_frag_struct;
typedef struct skb_frag_struct skb_frag_t;
struct __anonstruct_page_218 {
   struct page *p ;
};
struct skb_frag_struct {
   struct __anonstruct_page_218 page ;
   __u32 page_offset ;
   __u32 size ;
};
struct skb_shared_hwtstamps {
   ktime_t hwtstamp ;
};
struct skb_shared_info {
   unsigned char nr_frags ;
    klee_make_symbolic(&nr_frags, sizeof(char), "nr_frags");
   __u8 tx_flags ;
   unsigned short gso_size ;
    klee_make_symbolic(&gso_size, sizeof(short), "gso_size");
   unsigned short gso_segs ;
    klee_make_symbolic(&gso_segs, sizeof(short), "gso_segs");
   unsigned short gso_type ;
    klee_make_symbolic(&gso_type, sizeof(short), "gso_type");
   struct sk_buff *frag_list ;
   struct skb_shared_hwtstamps hwtstamps ;
   u32 tskey ;
   __be32 ip6_frag_id ;
   atomic_t dataref ;
   void *destructor_arg ;
   skb_frag_t frags[17U] ;
};
enum skb_free_reason {
    SKB_REASON_CONSUMED = 0,
    SKB_REASON_DROPPED = 1
} ;
struct tcphdr {
   __be16 source ;
   __be16 dest ;
   __be32 seq ;
   __be32 ack_seq ;
   unsigned char res1 : 4 ;
   unsigned char doff : 4 ;
   unsigned char fin : 1 ;
   unsigned char syn : 1 ;
   unsigned char rst : 1 ;
   unsigned char psh : 1 ;
   unsigned char ack : 1 ;
   unsigned char urg : 1 ;
   unsigned char ece : 1 ;
   unsigned char cwr : 1 ;
   __be16 window ;
   __sum16 check ;
   __be16 urg_ptr ;
};
struct iphdr {
   unsigned char ihl : 4 ;
   unsigned char version : 4 ;
   __u8 tos ;
   __be16 tot_len ;
   __be16 id ;
   __be16 frag_off ;
   __u8 ttl ;
   __u8 protocol ;
   __sum16 check ;
   __be32 saddr ;
   __be32 daddr ;
};
struct ipv6hdr {
   unsigned char priority : 4 ;
   unsigned char version : 4 ;
   __u8 flow_lbl[3U] ;
   __be16 payload_len ;
   __u8 nexthdr ;
   __u8 hop_limit ;
   struct in6_addr saddr ;
   struct in6_addr daddr ;
};
struct vlan_ethhdr {
   unsigned char h_dest[6U] ;
   unsigned char h_source[6U] ;
   __be16 h_vlan_proto ;
   __be16 h_vlan_TCI ;
   __be16 h_vlan_encapsulated_proto ;
};
struct efx_short_copy_buffer {
   int used ;
   u8 buf[64U] ;
};
struct tso_state {
   unsigned int out_len ;
    klee_make_symbolic(&out_len, sizeof(int), "out_len");
   unsigned int seqnum ;
    klee_make_symbolic(&seqnum, sizeof(int), "seqnum");
   u16 ipv4_id ;
   unsigned int packet_space ;
    klee_make_symbolic(&packet_space, sizeof(int), "packet_space");
   dma_addr_t dma_addr ;
   unsigned int in_len ;
    klee_make_symbolic(&in_len, sizeof(int), "in_len");
   unsigned int unmap_len ;
   dma_addr_t unmap_addr ;
   unsigned short dma_flags ;
    klee_make_symbolic(&dma_flags, sizeof(short), "dma_flags");
   __be16 protocol ;
   unsigned int ip_off ;
    klee_make_symbolic(&ip_off, sizeof(int), "ip_off");
   unsigned int tcp_off ;
    klee_make_symbolic(&tcp_off, sizeof(int), "tcp_off");
   unsigned int header_len ;
   unsigned int ip_base_len ;
    klee_make_symbolic(&ip_base_len, sizeof(int), "ip_base_len");
   dma_addr_t header_dma_addr ;
   unsigned int header_unmap_len ;
    klee_make_symbolic(&header_unmap_len, sizeof(int), "header_unmap_len");
};
enum hrtimer_restart;
enum pkt_hash_types {
    PKT_HASH_TYPE_NONE = 0,
    PKT_HASH_TYPE_L2 = 1,
    PKT_HASH_TYPE_L3 = 2,
    PKT_HASH_TYPE_L4 = 3
} ;
struct of_phandle_args {
   struct device_node *np ;
   int args_count ;
    klee_make_symbolic(&args_count, sizeof(int), "args_count");
   uint32_t args[16U] ;
};
enum gro_result {
    GRO_MERGED = 0,
    GRO_MERGED_FREE = 1,
    GRO_HELD = 2,
    GRO_NORMAL = 3,
    GRO_DROP = 4
} ;
typedef enum gro_result gro_result_t;
struct iommu_domain;
struct iommu_domain_geometry {
   dma_addr_t aperture_start ;
   dma_addr_t aperture_end ;
   bool force_aperture ;
};
struct iommu_domain {
   unsigned int type ;
   struct iommu_ops  const  *ops ;
   int (*handler)(struct iommu_domain * , struct device * , unsigned long  , int  ,
                  void * ) ;
   void *handler_token ;
   struct iommu_domain_geometry geometry ;
};
enum iommu_cap {
    IOMMU_CAP_CACHE_COHERENCY = 0,
    IOMMU_CAP_INTR_REMAP = 1,
    IOMMU_CAP_NOEXEC = 2
} ;
enum iommu_attr {
    DOMAIN_ATTR_GEOMETRY = 0,
    DOMAIN_ATTR_PAGING = 1,
    DOMAIN_ATTR_WINDOWS = 2,
    DOMAIN_ATTR_FSL_PAMU_STASH = 3,
    DOMAIN_ATTR_FSL_PAMU_ENABLE = 4,
    DOMAIN_ATTR_FSL_PAMUV1 = 5,
    DOMAIN_ATTR_NESTING = 6,
    DOMAIN_ATTR_MAX = 7
} ;
struct iommu_ops {
   bool (*capable)(enum iommu_cap  ) ;
   struct iommu_domain *(*domain_alloc)(unsigned int  ) ;
   void (*domain_free)(struct iommu_domain * ) ;
   int (*attach_dev)(struct iommu_domain * , struct device * ) ;
   void (*detach_dev)(struct iommu_domain * , struct device * ) ;
   int (*map)(struct iommu_domain * , unsigned long  , phys_addr_t  , size_t  , int  ) ;
   size_t (*unmap)(struct iommu_domain * , unsigned long  , size_t  ) ;
   size_t (*map_sg)(struct iommu_domain * , unsigned long  , struct scatterlist * ,
                    unsigned int  , int  ) ;
   phys_addr_t (*iova_to_phys)(struct iommu_domain * , dma_addr_t  ) ;
   int (*add_device)(struct device * ) ;
   void (*remove_device)(struct device * ) ;
   int (*device_group)(struct device * , unsigned int * ) ;
   int (*domain_get_attr)(struct iommu_domain * , enum iommu_attr  , void * ) ;
   int (*domain_set_attr)(struct iommu_domain * , enum iommu_attr  , void * ) ;
   void (*get_dm_regions)(struct device * , struct list_head * ) ;
   void (*put_dm_regions)(struct device * , struct list_head * ) ;
   int (*domain_window_enable)(struct iommu_domain * , u32  , phys_addr_t  , u64  ,
                               int  ) ;
   void (*domain_window_disable)(struct iommu_domain * , u32  ) ;
   int (*domain_set_windows)(struct iommu_domain * , u32  ) ;
   u32 (*domain_get_windows)(struct iommu_domain * ) ;
   int (*of_xlate)(struct device * , struct of_phandle_args * ) ;
   unsigned long pgsize_bitmap ;
    klee_make_symbolic(&pgsize_bitmap, sizeof(long), "pgsize_bitmap");
   void *priv ;
};
struct vlan_hdr {
   __be16 h_vlan_TCI ;
   __be16 h_vlan_encapsulated_proto ;
};
struct efx_rx_page_state {
   dma_addr_t dma_addr ;
   unsigned int __pad[0U] ;
};
enum hrtimer_restart;
struct udphdr {
   __be16 source ;
   __be16 dest ;
   __be16 len ;
   __sum16 check ;
};
struct efx_loopback_payload {
   struct ethhdr header ;
   struct iphdr ip ;
   struct udphdr udp ;
   __be16 iteration ;
   char msg[64U] ;
};
struct efx_loopback_state {
   bool flush ;
   int packet_count ;
    klee_make_symbolic(&packet_count, sizeof(int), "packet_count");
   struct sk_buff **skbs ;
   bool offload_csum ;
   atomic_t rx_good ;
   atomic_t rx_bad ;
   struct efx_loopback_payload payload ;
};
typedef bool ldv_func_ret_type___14;
enum hrtimer_restart;
enum ldv_36661 {
    EFX_ETHTOOL_STAT_SOURCE_nic = 0,
    EFX_ETHTOOL_STAT_SOURCE_channel = 1,
    EFX_ETHTOOL_STAT_SOURCE_tx_queue = 2
} ;
struct efx_sw_stat_desc {
   char const   *name ;
   enum ldv_36661 source ;
   unsigned int offset ;
   u64 (*get_stat)(void * ) ;
};
enum hrtimer_restart;
enum i2c_slave_event;
enum i2c_slave_event;
struct qt202x_phy_data {
   enum efx_phy_mode phy_mode ;
   bool bug17190_in_bad_state ;
   unsigned long bug17190_timer ;
    klee_make_symbolic(&bug17190_timer, sizeof(long), "bug17190_timer");
   u32 firmware_ver ;
};
enum hrtimer_restart;
enum hrtimer_restart;
enum i2c_slave_event;
enum i2c_slave_event;
struct tenxpress_phy_data {
   enum efx_loopback_mode loopback_mode ;
   enum efx_phy_mode phy_mode ;
   int bad_lp_tries ;
    klee_make_symbolic(&bad_lp_tries, sizeof(int), "bad_lp_tries");
};
enum hrtimer_restart;
enum i2c_slave_event;
enum i2c_slave_event;
struct txc43128_data {
   unsigned long bug10934_timer ;
    klee_make_symbolic(&bug10934_timer, sizeof(long), "bug10934_timer");
   enum efx_phy_mode phy_mode ;
   enum efx_loopback_mode loopback_mode ;
};
enum hrtimer_restart;
struct i2c_board_info;
enum i2c_slave_event;
enum i2c_slave_event;
struct i2c_board_info {
   char type[20U] ;
   unsigned short flags ;
   unsigned short addr ;
   void *platform_data ;
   struct dev_archdata *archdata ;
   struct device_node *of_node ;
   struct fwnode_handle *fwnode ;
   int irq ;
};
enum hrtimer_restart;
struct efx_mcdi_async_param {
   struct list_head list ;
   unsigned int cmd ;
    klee_make_symbolic(&cmd, sizeof(int), "cmd");
   size_t inlen ;
   size_t outlen ;
   bool quiet ;
   efx_mcdi_async_completer *complete ;
   unsigned long cookie ;
    klee_make_symbolic(&cookie, sizeof(long), "cookie");
};
enum hrtimer_restart;
struct efx_mcdi_phy_data {
   u32 flags ;
   u32 type ;
   u32 supported_cap ;
   u32 channel ;
   u32 port ;
   u32 stats_mask ;
   u8 name[20U] ;
   u32 media ;
   u32 mmd_mask ;
   u8 revision[20U] ;
   u32 forced_cap ;
};
enum efx_stats_action {
    EFX_STATS_ENABLE = 0,
    EFX_STATS_DISABLE = 1,
    EFX_STATS_PULL = 2
} ;
enum hrtimer_restart;
enum efx_hwmon_type {
    EFX_HWMON_UNKNOWN = 0,
    EFX_HWMON_TEMP = 1,
    EFX_HWMON_COOL = 2,
    EFX_HWMON_IN = 3,
    EFX_HWMON_CURR = 4,
    EFX_HWMON_POWER = 5,
    EFX_HWMON_TYPES_COUNT = 6
} ;
struct __anonstruct_efx_mcdi_sensor_type_373 {
   char const   *label ;
   enum efx_hwmon_type hwmon_type ;
   int port ;
};
struct efx_mcdi_mon_attribute {
   struct device_attribute dev_attr ;
   unsigned int index ;
   unsigned int type ;
   enum efx_hwmon_type hwmon_type ;
   unsigned int limit_value ;
    klee_make_symbolic(&limit_value, sizeof(int), "limit_value");
   char name[12U] ;
};
typedef long long __s64;
    klee_make_symbolic(&__s64, sizeof(long), "__s64");
enum hrtimer_restart;
struct cdev {
   struct kobject kobj ;
   struct module *owner ;
   struct file_operations  const  *ops ;
   struct list_head list ;
   dev_t dev ;
   unsigned int count ;
};
struct pps_event_time {
   struct timespec ts_real ;
};
struct ptp_clock_time {
   __s64 sec ;
   __u32 nsec ;
   __u32 reserved ;
};
struct ptp_extts_request {
   unsigned int index ;
   unsigned int flags ;
   unsigned int rsv[2U] ;
};
struct ptp_perout_request {
   struct ptp_clock_time start ;
   struct ptp_clock_time period ;
   unsigned int index ;
   unsigned int flags ;
   unsigned int rsv[4U] ;
};
enum ptp_pin_function {
    PTP_PF_NONE = 0,
    PTP_PF_EXTTS = 1,
    PTP_PF_PEROUT = 2,
    PTP_PF_PHYSYNC = 3
} ;
struct ptp_pin_desc {
   char name[64U] ;
   unsigned int index ;
   unsigned int func ;
    klee_make_symbolic(&func, sizeof(int), "func");
   unsigned int chan ;
    klee_make_symbolic(&chan, sizeof(int), "chan");
   unsigned int rsv[5U] ;
};
enum ldv_33302 {
    PTP_CLK_REQ_EXTTS = 0,
    PTP_CLK_REQ_PEROUT = 1,
    PTP_CLK_REQ_PPS = 2
} ;
union __anonunion____missing_field_name_361 {
   struct ptp_extts_request extts ;
   struct ptp_perout_request perout ;
};
struct ptp_clock_request {
   enum ldv_33302 type ;
   union __anonunion____missing_field_name_361 __annonCompField109 ;
};
struct ptp_clock_info {
   struct module *owner ;
   char name[16U] ;
   s32 max_adj ;
   int n_alarm ;
    klee_make_symbolic(&n_alarm, sizeof(int), "n_alarm");
   int n_ext_ts ;
    klee_make_symbolic(&n_ext_ts, sizeof(int), "n_ext_ts");
   int n_per_out ;
    klee_make_symbolic(&n_per_out, sizeof(int), "n_per_out");
   int n_pins ;
    klee_make_symbolic(&n_pins, sizeof(int), "n_pins");
   int pps ;
    klee_make_symbolic(&pps, sizeof(int), "pps");
   struct ptp_pin_desc *pin_config ;
   int (*adjfreq)(struct ptp_clock_info * , s32  ) ;
   int (*adjtime)(struct ptp_clock_info * , s64  ) ;
   int (*gettime64)(struct ptp_clock_info * , struct timespec * ) ;
   int (*settime64)(struct ptp_clock_info * , struct timespec  const  * ) ;
   int (*enable)(struct ptp_clock_info * , struct ptp_clock_request * , int  ) ;
   int (*verify)(struct ptp_clock_info * , unsigned int  , enum ptp_pin_function  ,
                 unsigned int  ) ;
};
struct ptp_clock;
union __anonunion____missing_field_name_362 {
   u64 timestamp ;
   struct pps_event_time pps_times ;
};
struct ptp_clock_event {
   int type ;
   int index ;
   union __anonunion____missing_field_name_362 __annonCompField110 ;
};
enum ptp_packet_state {
    PTP_PACKET_STATE_UNMATCHED = 0,
    PTP_PACKET_STATE_MATCHED = 1,
    PTP_PACKET_STATE_TIMED_OUT = 2,
    PTP_PACKET_STATE_MATCH_UNWANTED = 3
} ;
struct efx_ptp_match {
   u32 words[2U] ;
   unsigned long expiry ;
    klee_make_symbolic(&expiry, sizeof(long), "expiry");
   enum ptp_packet_state state ;
};
struct efx_ptp_event_rx {
   struct list_head link ;
   u32 seq0 ;
   u32 seq1 ;
   ktime_t hwtimestamp ;
   unsigned long expiry ;
};
struct efx_ptp_timeset {
   u32 host_start ;
   u32 major ;
   u32 minor ;
   u32 host_end ;
   u32 wait ;
   u32 window ;
};
struct __anonstruct_ts_corrections_386 {
   s32 tx ;
   s32 rx ;
   s32 pps_out ;
   s32 pps_in ;
};
struct efx_ptp_data {
   struct efx_nic *efx ;
   struct efx_channel *channel ;
   bool rx_ts_inline ;
   struct sk_buff_head rxq ;
   struct sk_buff_head txq ;
   struct list_head evt_list ;
   struct list_head evt_free_list ;
   spinlock_t evt_lock ;
   struct efx_ptp_event_rx rx_evts[8U] ;
   struct workqueue_struct *workwq ;
   struct work_struct work ;
   bool reset_required ;
   u32 rxfilter_event ;
   u32 rxfilter_general ;
   bool rxfilter_installed ;
   struct hwtstamp_config config ;
   bool enabled ;
   unsigned int mode ;
   unsigned int time_format ;
    klee_make_symbolic(&time_format, sizeof(int), "time_format");
   void (*ns_to_nic_time)(s64  , u32 * , u32 * ) ;
   ktime_t (*nic_to_kernel_time)(u32  , u32  , s32  ) ;
   unsigned int min_synchronisation_ns ;
    klee_make_symbolic(&min_synchronisation_ns, sizeof(int), "min_synchronisation_ns");
   struct __anonstruct_ts_corrections_386 ts_corrections ;
   efx_qword_t evt_frags[3U] ;
   int evt_frag_idx ;
    klee_make_symbolic(&evt_frag_idx, sizeof(int), "evt_frag_idx");
   int evt_code ;
    klee_make_symbolic(&evt_code, sizeof(int), "evt_code");
   struct efx_buffer start ;
   struct pps_event_time host_time_pps ;
   s64 current_adjfreq ;
   struct ptp_clock *phc_clock ;
   struct ptp_clock_info phc_clock_info ;
   struct work_struct pps_work ;
   struct workqueue_struct *pps_workwq ;
   bool nic_ts_enabled ;
   efx_dword_t txbuf[63U] ;
   unsigned int good_syncs ;
    klee_make_symbolic(&good_syncs, sizeof(int), "good_syncs");
   unsigned int fast_syncs ;
    klee_make_symbolic(&fast_syncs, sizeof(int), "fast_syncs");
   unsigned int bad_syncs ;
    klee_make_symbolic(&bad_syncs, sizeof(int), "bad_syncs");
   unsigned int sync_timeouts ;
    klee_make_symbolic(&sync_timeouts, sizeof(int), "sync_timeouts");
   unsigned int no_time_syncs ;
    klee_make_symbolic(&no_time_syncs, sizeof(int), "no_time_syncs");
   unsigned int invalid_sync_windows ;
    klee_make_symbolic(&invalid_sync_windows, sizeof(int), "invalid_sync_windows");
   unsigned int undersize_sync_windows ;
    klee_make_symbolic(&undersize_sync_windows, sizeof(int), "undersize_sync_windows");
   unsigned int oversize_sync_windows ;
    klee_make_symbolic(&oversize_sync_windows, sizeof(int), "oversize_sync_windows");
   unsigned int rx_no_timestamp ;
    klee_make_symbolic(&rx_no_timestamp, sizeof(int), "rx_no_timestamp");
   struct efx_ptp_timeset timeset[12U] ;
};
typedef bool ldv_func_ret_type___15;
enum hrtimer_restart;
struct mtd_partition;
struct mtd_part_parser_data;
enum hrtimer_restart;
enum hrtimer_restart;
struct acpi_device;
struct pci_sysdata {
   int domain ;
    klee_make_symbolic(&domain, sizeof(int), "domain");
   int node ;
    klee_make_symbolic(&node, sizeof(int), "node");
   struct acpi_device *companion ;
   void *iommu ;
};
struct vfdi_status;
struct vfdi_endpoint {
   u8 mac_addr[6U] ;
   __be16 tci ;
};
struct __anonstruct_init_evq_385 {
   u32 index ;
   u32 buf_count ;
   u64 addr[] ;
};
struct __anonstruct_init_rxq_386 {
   u32 index ;
   u32 buf_count ;
   u32 evq ;
   u32 label ;
   u32 flags ;
   u32 reserved ;
   u64 addr[] ;
};
struct __anonstruct_init_txq_387 {
   u32 index ;
   u32 buf_count ;
   u32 evq ;
   u32 label ;
   u32 flags ;
   u32 reserved ;
   u64 addr[] ;
};
struct __anonstruct_mac_filter_388 {
   u32 rxq ;
   u32 flags ;
};
struct __anonstruct_set_status_page_389 {
   u64 dma_addr ;
   u64 peer_page_count ;
   u64 peer_page_addr[] ;
};
union __anonunion_u_384 {
   struct __anonstruct_init_evq_385 init_evq ;
   struct __anonstruct_init_rxq_386 init_rxq ;
   struct __anonstruct_init_txq_387 init_txq ;
   struct __anonstruct_mac_filter_388 mac_filter ;
   struct __anonstruct_set_status_page_389 set_status_page ;
};
struct vfdi_req {
   u32 op ;
   u32 reserved1 ;
   s32 rc ;
   u32 reserved2 ;
   union __anonunion_u_384 u ;
};
struct vfdi_status {
   u32 generation_start ;
   u32 generation_end ;
   u32 version ;
   u32 length ;
   u8 vi_scale ;
   u8 max_tx_channels ;
   u8 rss_rxq_count ;
   u8 reserved1 ;
   u16 peer_count ;
   u16 reserved2 ;
   struct vfdi_endpoint local ;
    klee_make_symbolic(&local, sizeof(int), "local");
   struct vfdi_endpoint peers[256U] ;
   u32 timer_quantum_ns ;
};
enum efx_vf_tx_filter_mode {
    VF_TX_FILTER_OFF = 0,
    VF_TX_FILTER_AUTO = 1,
    VF_TX_FILTER_ON = 2
} ;
struct siena_vf {
   struct efx_nic *efx ;
   unsigned int pci_rid ;
    klee_make_symbolic(&pci_rid, sizeof(int), "pci_rid");
   char pci_name[13U] ;
   unsigned int index ;
   struct work_struct req ;
   u64 req_addr ;
   int req_type ;
    klee_make_symbolic(&req_type, sizeof(int), "req_type");
   unsigned int req_seqno ;
    klee_make_symbolic(&req_seqno, sizeof(int), "req_seqno");
   unsigned int msg_seqno ;
    klee_make_symbolic(&msg_seqno, sizeof(int), "msg_seqno");
   bool busy ;
   struct efx_buffer buf ;
   unsigned int buftbl_base ;
    klee_make_symbolic(&buftbl_base, sizeof(int), "buftbl_base");
   bool rx_filtering ;
   enum efx_filter_flags rx_filter_flags ;
   unsigned int rx_filter_qid ;
    klee_make_symbolic(&rx_filter_qid, sizeof(int), "rx_filter_qid");
   int rx_filter_id ;
    klee_make_symbolic(&rx_filter_id, sizeof(int), "rx_filter_id");
   enum efx_vf_tx_filter_mode tx_filter_mode ;
   int tx_filter_id ;
    klee_make_symbolic(&tx_filter_id, sizeof(int), "tx_filter_id");
   struct vfdi_endpoint addr ;
   u64 status_addr ;
   struct mutex status_lock ;
   u64 *peer_page_addrs ;
   unsigned int peer_page_count ;
    klee_make_symbolic(&peer_page_count, sizeof(int), "peer_page_count");
   u64 evq0_addrs[16U] ;
   unsigned int evq0_count ;
    klee_make_symbolic(&evq0_count, sizeof(int), "evq0_count");
   wait_queue_head_t flush_waitq ;
   struct mutex txq_lock ;
   unsigned long txq_mask[1U] ;
   unsigned int txq_count ;
    klee_make_symbolic(&txq_count, sizeof(int), "txq_count");
   unsigned long rxq_mask[1U] ;
   unsigned int rxq_count ;
    klee_make_symbolic(&rxq_count, sizeof(int), "rxq_count");
   unsigned long rxq_retry_mask[1U] ;
   atomic_t rxq_retry_count ;
   struct work_struct reset_work ;
};
struct efx_memcpy_req {
   unsigned int from_rid ;
    klee_make_symbolic(&from_rid, sizeof(int), "from_rid");
   void *from_buf ;
   u64 from_addr ;
   unsigned int to_rid ;
    klee_make_symbolic(&to_rid, sizeof(int), "to_rid");
   u64 to_addr ;
   unsigned int length ;
};
struct efx_local_addr {
   struct list_head link ;
   u8 addr[6U] ;
};
struct efx_endpoint_page {
   struct list_head link ;
   void *ptr ;
   dma_addr_t addr ;
};
typedef int (*efx_vfdi_op_t)(struct siena_vf * );
typedef bool ldv_func_ret_type___16;
enum hrtimer_restart;
__inline static long ldv__builtin_expect(long exp , long c ) ;
extern struct module __this_module ;
__inline static void set_bit(long nr , unsigned long volatile   *addr ) 
{ 


  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; bts %1,%0": "+m" (*((long volatile   *)addr)): "Ir" (nr): "memory");
  return;
}
}
__inline static void clear_bit(long nr , unsigned long volatile   *addr ) 
{ 


  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; btr %1,%0": "+m" (*((long volatile   *)addr)): "Ir" (nr));
  return;
}
}
__inline static void __clear_bit(long nr , unsigned long volatile   *addr ) 
{ 


  {
  __asm__  volatile   ("btr %1,%0": "+m" (*((long volatile   *)addr)): "Ir" (nr));
  return;
}
}
__inline static int test_and_set_bit(long nr , unsigned long volatile   *addr ) 
{ 
  char c ;
    klee_make_symbolic(&c, sizeof(char), "c");

  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; bts %2, %0; setc %1": "+m" (*addr),
                       "=qm" (c): "Ir" (nr): "memory");
  return ((int )((signed char )c) != 0);
}
}
__inline static int constant_test_bit(long nr , unsigned long const volatile   *addr ) 
{ 


  {
  return ((int )((unsigned long )*(addr + (unsigned long )(nr >> 6)) >> ((int )nr & 63)) & 1);
}
}
__inline static int variable_test_bit(long nr , unsigned long const volatile   *addr ) 
{ 
  int oldbit ;
    klee_make_symbolic(&oldbit, sizeof(int), "oldbit");

  {
  __asm__  volatile   ("bt %2,%1\n\tsbb %0,%0": "=r" (oldbit): "m" (*((unsigned long *)addr)),
                       "Ir" (nr));
  return (oldbit);
}
}
__inline static int fls(int x ) 
{ 
  int r ;
    klee_make_symbolic(&r, sizeof(int), "r");

  {
  __asm__  ("bsrl %1,%0": "=r" (r): "rm" (x), "0" (-1));
  return (r + 1);
}
}
__inline static int fls64(__u64 x ) 
{ 
  int bitpos ;
    klee_make_symbolic(&bitpos, sizeof(int), "bitpos");

  {
  bitpos = -1;
  __asm__  ("bsrq %1,%q0": "+r" (bitpos): "rm" (x));
  return (bitpos + 1);
}
}
extern unsigned long find_next_bit(unsigned long const   * , unsigned long  , unsigned long  ) ;
__inline static unsigned int fls_long(unsigned long l ) 
{ 
  int tmp___0 ;
    klee_make_symbolic(&tmp___0, sizeof(int), "tmp___0");

  {
  tmp___0 = fls64((__u64 )l);
  return ((unsigned int )tmp___0);
}
}
__inline static unsigned long __roundup_pow_of_two(unsigned long n ) 
{ 
  unsigned int tmp ;

  {
  tmp = fls_long(n - 1UL);
  return (1UL << (int )tmp);
}
}
extern int printk(char const   *  , ...) ;
extern void dump_stack(void) ;
extern void __dynamic_netdev_dbg(struct _ddebug * , struct net_device  const  * ,
                                 char const   *  , ...) ;
extern int sprintf(char * , char const   *  , ...) ;
extern int snprintf(char * , size_t  , char const   *  , ...) ;
extern int scnprintf(char * , size_t  , char const   *  , ...) ;
extern void __bad_percpu_size(void) ;
extern void __bad_size_call_parameter(void) ;
extern unsigned long __per_cpu_offset[8192U] ;
__inline static void INIT_LIST_HEAD(struct list_head *list ) 
{ 


  {
  list->next = list;
  list->prev = list;
  return;
}
}
extern void __list_add(struct list_head * , struct list_head * , struct list_head * ) ;
__inline static void list_add_tail(struct list_head *new , struct list_head *head ) 
{ 


  {
  __list_add(new, head->prev, head);
  return;
}
}
extern void list_del(struct list_head * ) ;
__inline static int __get_order(unsigned long size ) 
{ 
  int order ;

  {
  size = size - 1UL;
  size = size >> 12;
  order = fls64((__u64 )size);
  return (order);
}
}
extern void *memset(void * , int  , size_t  ) ;
extern char *strcpy(char * , char const   * ) ;
extern int strcmp(char const   * , char const   * ) ;
extern size_t strlcpy(char * , char const   * , size_t  ) ;
extern void __bitmap_or(unsigned long * , unsigned long const   * , unsigned long const   * ,
                        unsigned int  ) ;
__inline static void bitmap_or(unsigned long *dst , unsigned long const   *src1 ,
                               unsigned long const   *src2 , unsigned int nbits ) 
{ 


  {
  __bitmap_or(dst, src1, src2, nbits);
  return;
}
}
extern void warn_slowpath_null(char const   * , int const    ) ;
extern int nr_cpu_ids ;
    klee_make_symbolic(&nr_cpu_ids, sizeof(int), "nr_cpu_ids");
extern struct cpumask  const  * const  cpu_online_mask ;
__inline static unsigned int cpumask_check(unsigned int cpu ) 
{ 
  bool __warned ;
  int __ret_warn_once ;
    klee_make_symbolic(&__ret_warn_once, sizeof(int), "__ret_warn_once");
  int __ret_warn_on ;
    klee_make_symbolic(&__ret_warn_on, sizeof(int), "__ret_warn_on");
  long tmp ;
  long tmp___0 ;
  long tmp___1 ;
    klee_make_symbolic(&tmp___1, sizeof(long), "tmp___1");

  {
  __ret_warn_once = (unsigned int )nr_cpu_ids <= cpu;
  tmp___1 = ldv__builtin_expect(__ret_warn_once != 0, 0L);
  if (tmp___1 != 0L) {
    __ret_warn_on = ! __warned;
    tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp != 0L) {
      warn_slowpath_null("include/linux/cpumask.h", 117);
    } else {

    }
    tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___0 != 0L) {
      __warned = 1;
    } else {

    }
  } else {

  }
  ldv__builtin_expect(__ret_warn_once != 0, 0L);
  return (cpu);
}
}
__inline static unsigned int cpumask_next(int n , struct cpumask  const  *srcp ) 
{ 
  unsigned long tmp ;

  {
  if (n != -1) {
    cpumask_check((unsigned int )n);
  } else {

  }
  tmp = find_next_bit((unsigned long const   *)(& srcp->bits), (unsigned long )nr_cpu_ids,
                      (unsigned long )(n + 1));
  return ((unsigned int )tmp);
}
}
__inline static int cpumask_test_cpu(int cpu , struct cpumask  const  *cpumask ) 
{ 
  unsigned int tmp ;
  int tmp___0 ;

  {
  tmp = cpumask_check((unsigned int )cpu);
  tmp___0 = variable_test_bit((long )tmp, (unsigned long const volatile   *)(& cpumask->bits));
  return (tmp___0);
}
}
__inline static void cpumask_or(struct cpumask *dstp , struct cpumask  const  *src1p ,
                                struct cpumask  const  *src2p ) 
{ 


  {
  bitmap_or((unsigned long *)(& dstp->bits), (unsigned long const   *)(& src1p->bits),
            (unsigned long const   *)(& src2p->bits), (unsigned int )nr_cpu_ids);
  return;
}
}
extern bool zalloc_cpumask_var(cpumask_var_t ** , gfp_t  ) ;
extern void free_cpumask_var(cpumask_var_t  ) ;
__inline static int atomic_read(atomic_t const   *v ) 
{ 
  int __var ;
    klee_make_symbolic(&__var, sizeof(int), "__var");

  {
  __var = 0;
  return ((int )*((int const volatile   *)(& v->counter)));
}
}
__inline static void atomic_inc(atomic_t *v ) 
{ 


  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; incl %0": "+m" (v->counter));
  return;
}
}
extern void lockdep_init_map(struct lockdep_map * , char const   * , struct lock_class_key * ,
                             int  ) ;
extern void __mutex_init(struct mutex * , char const   * , struct lock_class_key * ) ;
__inline static int mutex_is_locked(struct mutex *lock ) 
{ 
  int tmp ;
    klee_make_symbolic(&tmp, sizeof(int), "tmp");

  {
  tmp = atomic_read((atomic_t const   *)(& lock->count));
  return (tmp != 1);
}
}
__inline static int ldv_mutex_is_locked_18(struct mutex *lock ) ;
extern int mutex_trylock(struct mutex * ) ;
int ldv_mutex_trylock_13(struct mutex *ldv_func_arg1 ) ;
int ldv_mutex_trylock_34(struct mutex *ldv_func_arg1 ) ;
extern void mutex_unlock(struct mutex * ) ;
void ldv_mutex_unlock_11(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_14(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_15(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_20(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_22(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_24(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_25(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_27(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_29(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_33(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_35(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_37(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_39(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_41(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_42(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_46(struct mutex *ldv_func_arg1 ) ;
extern void *malloc(size_t  ) ;
extern void *calloc(size_t  , size_t  ) ;
extern int __VERIFIER_nondet_int(void) ;
extern unsigned long __VERIFIER_nondet_ulong(void) ;
extern void abort(void);
void assume_abort_if_not(int cond) {
  if(!cond) {abort();}
}
__inline static bool IS_ERR(void const *ptr ) ;

void *ldv_malloc(size_t size ) 
{ 
  void *p ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp___0 = __VERIFIER_nondet_int();
  if (tmp___0 != 0) {
    return ((void *)0);
  } else {
    tmp = malloc(size);
    p = tmp;
    assume_abort_if_not((unsigned long )p != (unsigned long )((void *)0));
    assume_abort_if_not(IS_ERR(p) == 0);
    return (p);
  }
}
}
void *ldv_zalloc(size_t size ) 
{ 
  void *p ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp___0 = __VERIFIER_nondet_int();
  if (tmp___0 != 0) {
    return ((void *)0);
  } else {
    tmp = calloc(1UL, size);
    p = tmp;
    assume_abort_if_not((unsigned long )p != (unsigned long )((void *)0));
    assume_abort_if_not(IS_ERR(p) == 0);
    return (p);
  }
}
}
void *ldv_init_zalloc(size_t size ) 
{ 
  void *p ;
  void *tmp ;

  {
  tmp = calloc(1UL, size);
  p = tmp;
  assume_abort_if_not((unsigned long )p != (unsigned long )((void *)0));
  return (p);
}
}
void *ldv_memset(void *s , int c , size_t n ) 
{ 
  void *tmp ;

  {
  tmp = memset(s, c, n);
  return (tmp);
}
}
int ldv_undef_int(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  return (tmp);
}
}
unsigned long ldv_undef_ulong(void) 
{ 
  unsigned long tmp ;

  {
  tmp = __VERIFIER_nondet_ulong();
  return (tmp);
}
}
__inline static void ldv_stop(void) 
{ 


  {
  LDV_STOP: ;
  goto LDV_STOP;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) 
{ 


  {
  return (exp);
}
}
extern void mutex_lock(struct mutex * ) ;
void ldv_mutex_lock_10(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_12(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_16(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_19(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_21(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_23(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_26(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_28(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_32(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_36(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_38(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_40(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_45(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_i_mutex_of_inode(struct mutex *lock ) ;
void ldv_mutex_unlock_i_mutex_of_inode(struct mutex *lock ) ;
void ldv_mutex_lock_lock(struct mutex *lock ) ;
void ldv_mutex_unlock_lock(struct mutex *lock ) ;
void ldv_mutex_lock_mac_lock_of_efx_nic(struct mutex *lock ) ;
int ldv_mutex_trylock_mac_lock_of_efx_nic(struct mutex *lock ) ;
int ldv_mutex_is_locked_mac_lock_of_efx_nic(struct mutex *lock ) ;
void ldv_mutex_unlock_mac_lock_of_efx_nic(struct mutex *lock ) ;
void ldv_mutex_lock_mutex_of_device(struct mutex *lock ) ;
int ldv_mutex_trylock_mutex_of_device(struct mutex *lock ) ;
void ldv_mutex_unlock_mutex_of_device(struct mutex *lock ) ;
extern void __local_bh_disable_ip(unsigned long  , unsigned int  ) ;
__inline static void local_bh_disable(void) 
{ 


  {
  __local_bh_disable_ip(0UL, 512U);
  return;
}
}
extern void __local_bh_enable_ip(unsigned long  , unsigned int  ) ;
__inline static void local_bh_enable(void) 
{ 


  {
  __local_bh_enable_ip(0UL, 512U);
  return;
}
}
extern void __raw_spin_lock_init(raw_spinlock_t * , char const   * , struct lock_class_key * ) ;
extern void _raw_spin_lock(raw_spinlock_t * ) ;
extern void _raw_spin_lock_bh(raw_spinlock_t * ) ;
extern void _raw_spin_unlock(raw_spinlock_t * ) ;
extern void _raw_spin_unlock_bh(raw_spinlock_t * ) ;
__inline static raw_spinlock_t *spinlock_check(spinlock_t *lock ) 
{ 


  {
  return (& lock->__annonCompField17.rlock);
}
}
__inline static void spin_lock(spinlock_t *lock ) 
{ 


  {
  _raw_spin_lock(& lock->__annonCompField17.rlock);
  return;
}
}
__inline static void spin_lock_bh(spinlock_t *lock ) 
{ 


  {
  _raw_spin_lock_bh(& lock->__annonCompField17.rlock);
  return;
}
}
__inline static void spin_unlock(spinlock_t *lock ) 
{ 


  {
  _raw_spin_unlock(& lock->__annonCompField17.rlock);
  return;
}
}
__inline static void spin_unlock_bh(spinlock_t *lock ) 
{ 


  {
  _raw_spin_unlock_bh(& lock->__annonCompField17.rlock);
  return;
}
}
extern unsigned long volatile   jiffies ;
extern unsigned long __msecs_to_jiffies(unsigned int const    ) ;
__inline static unsigned long msecs_to_jiffies(unsigned int const   m ) 
{ 
  unsigned long tmp___0 ;

  {
  tmp___0 = __msecs_to_jiffies(m);
  return (tmp___0);
}
}
extern void init_timer_key(struct timer_list * , unsigned int  , char const   * ,
                           struct lock_class_key * ) ;
extern int mod_timer(struct timer_list * , unsigned long  ) ;
int ldv_mod_timer_17(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
extern void __init_waitqueue_head(wait_queue_head_t * , char const   * , struct lock_class_key * ) ;
extern void delayed_work_timer_fn(unsigned long  ) ;
extern void __init_work(struct work_struct * , int  ) ;
extern struct workqueue_struct *__alloc_workqueue_key(char const   * , unsigned int  ,
                                                      int  , struct lock_class_key * ,
                                                      char const   *  , ...) ;
extern void destroy_workqueue(struct workqueue_struct * ) ;
void ldv_destroy_workqueue_43(struct workqueue_struct *ldv_func_arg1 ) ;
void ldv_destroy_workqueue_48(struct workqueue_struct *ldv_func_arg1 ) ;
void ldv_destroy_workqueue_50(struct workqueue_struct *ldv_func_arg1 ) ;
extern bool queue_work_on(int  , struct workqueue_struct * , struct work_struct * ) ;
bool ldv_queue_work_on_5(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                         struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_7(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                         struct work_struct *ldv_func_arg3 ) ;
extern bool queue_delayed_work_on(int  , struct workqueue_struct * , struct delayed_work * ,
                                  unsigned long  ) ;
bool ldv_queue_delayed_work_on_6(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                 struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_9(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                 struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
extern void flush_workqueue(struct workqueue_struct * ) ;
void ldv_flush_workqueue_8(struct workqueue_struct *ldv_func_arg1 ) ;
extern bool cancel_work_sync(struct work_struct * ) ;
bool ldv_cancel_work_sync_31(struct work_struct *ldv_func_arg1 ) ;
bool ldv_cancel_work_sync_44(struct work_struct *ldv_func_arg1 ) ;
extern bool cancel_delayed_work_sync(struct delayed_work * ) ;
bool ldv_cancel_delayed_work_sync_30(struct delayed_work *ldv_func_arg1 ) ;
__inline static bool queue_work(struct workqueue_struct *wq , struct work_struct *work ) 
{ 
  bool tmp ;

  {
  tmp = ldv_queue_work_on_5(8192, wq, work);
  return (tmp);
}
}
__inline static bool queue_delayed_work(struct workqueue_struct *wq , struct delayed_work *dwork ,
                                        unsigned long delay ) 
{ 
  bool tmp ;

  {
  tmp = ldv_queue_delayed_work_on_6(8192, wq, dwork, delay);
  return (tmp);
}
}
extern void __init_rwsem(struct rw_semaphore * , char const   * , struct lock_class_key * ) ;
extern void down_read(struct rw_semaphore * ) ;
extern void down_write(struct rw_semaphore * ) ;
extern void up_read(struct rw_semaphore * ) ;
extern void up_write(struct rw_semaphore * ) ;
extern void *ioremap_nocache(resource_size_t  , unsigned long  ) ;
extern void iounmap(void volatile   * ) ;
extern cpumask_var_t cpu_sibling_map ;
extern int cpu_number ;
    klee_make_symbolic(&cpu_number, sizeof(int), "cpu_number");
extern void kfree(void const   * ) ;
extern void *__kmalloc(size_t  , gfp_t  ) ;
void *ldv_malloc(size_t size ) ;
__inline static void *kmalloc(size_t size , gfp_t flags ) 
{ 
  void *tmp___2 ;

  {
  tmp___2 = __kmalloc(size, flags);
  return (tmp___2);
}
}
__inline static void *kmalloc_array(size_t n , size_t size , gfp_t flags ) 
{ 
  void *tmp ;

  {
  if (size != 0UL && 0xffffffffffffffffUL / size < n) {
    return ((void *)0);
  } else {

  }
  tmp = __kmalloc(n * size, flags);
  return (tmp);
}
}
void *ldv_calloc(size_t nmemb , size_t size ) ;
__inline static void *kcalloc(size_t n , size_t size , gfp_t flags ) 
{ 
  void *tmp ;

  {
  tmp = kmalloc_array(n, size, flags | 32768U);
  return (tmp);
}
}
void *ldv_zalloc(size_t size ) ;
__inline static void *kzalloc(size_t size , gfp_t flags ) 
{ 
  void *tmp ;

  {
  tmp = kmalloc(size, flags | 32768U);
  return (tmp);
}
}
struct work_struct *ldv_work_struct_9_2  ;
int ldv_timer_11_0  ;
    klee_make_symbolic(&ldv_timer_11_0, sizeof(int), "ldv_timer_11_0");
struct efx_tx_queue *falcon_b0_nic_type_group4  ;
int ldv_state_variable_20  ;
    klee_make_symbolic(&ldv_state_variable_20, sizeof(int), "ldv_state_variable_20");
struct work_struct *ldv_work_struct_3_1  ;
struct timer_list *ldv_timer_list_10_2  ;
int ldv_work_1_1  ;
    klee_make_symbolic(&ldv_work_1_1, sizeof(int), "ldv_work_1_1");
struct efx_filter_spec *efx_hunt_a0_vf_nic_type_group4  ;
struct efx_channel *efx_ptp_channel_type_group0  ;
int ldv_work_9_3  ;
    klee_make_symbolic(&ldv_work_9_3, sizeof(int), "ldv_work_9_3");
struct efx_filter_spec *siena_a0_nic_type_group5  ;
int ldv_state_variable_14  ;
    klee_make_symbolic(&ldv_state_variable_14, sizeof(int), "ldv_state_variable_14");
int ldv_state_variable_37  ;
    klee_make_symbolic(&ldv_state_variable_37, sizeof(int), "ldv_state_variable_37");
int ldv_state_variable_17  ;
    klee_make_symbolic(&ldv_state_variable_17, sizeof(int), "ldv_state_variable_17");
struct ethtool_cmd *falcon_qt202x_phy_ops_group0  ;
int ldv_work_7_2  ;
    klee_make_symbolic(&ldv_work_7_2, sizeof(int), "ldv_work_7_2");
int ldv_state_variable_19  ;
    klee_make_symbolic(&ldv_state_variable_19, sizeof(int), "ldv_state_variable_19");
struct work_struct *ldv_work_struct_4_3  ;
int ldv_state_variable_27  ;
    klee_make_symbolic(&ldv_state_variable_27, sizeof(int), "ldv_state_variable_27");
int ldv_state_variable_9  ;
    klee_make_symbolic(&ldv_state_variable_9, sizeof(int), "ldv_state_variable_9");
struct work_struct *ldv_work_struct_7_1  ;
struct work_struct *ldv_work_struct_2_2  ;
struct timer_list *ldv_timer_list_11_1  ;
int ldv_work_3_3  ;
    klee_make_symbolic(&ldv_work_3_3, sizeof(int), "ldv_work_3_3");
struct work_struct *ldv_work_struct_4_0  ;
int ldv_state_variable_7  ;
    klee_make_symbolic(&ldv_state_variable_7, sizeof(int), "ldv_state_variable_7");
int ldv_timer_12_3  ;
    klee_make_symbolic(&ldv_timer_12_3, sizeof(int), "ldv_timer_12_3");
struct ethtool_coalesce *efx_ethtool_ops_group3  ;
int ldv_work_1_3  ;
    klee_make_symbolic(&ldv_work_1_3, sizeof(int), "ldv_work_1_3");
struct work_struct *ldv_work_struct_2_1  ;
int ldv_work_4_0  ;
    klee_make_symbolic(&ldv_work_4_0, sizeof(int), "ldv_work_4_0");
struct work_struct *ldv_work_struct_3_2  ;
struct device *dev_attr_phy_flash_cfg_group1  ;
struct net_device *efx_ethtool_ops_group4  ;
struct work_struct *ldv_work_struct_7_2  ;
int ldv_state_variable_26  ;
    klee_make_symbolic(&ldv_state_variable_26, sizeof(int), "ldv_state_variable_26");
int ldv_state_variable_28  ;
    klee_make_symbolic(&ldv_state_variable_28, sizeof(int), "ldv_state_variable_28");
struct net_device *efx_netdev_ops_group1  ;
struct work_struct *ldv_work_struct_7_0  ;
int ldv_timer_10_2  ;
    klee_make_symbolic(&ldv_timer_10_2, sizeof(int), "ldv_timer_10_2");
int LDV_IN_INTERRUPT  =    1;
struct work_struct *ldv_work_struct_6_0  ;
int ldv_work_8_3  ;
    klee_make_symbolic(&ldv_work_8_3, sizeof(int), "ldv_work_8_3");
struct efx_nic *falcon_qt202x_phy_ops_group1  ;
struct efx_nic *siena_a0_nic_type_group1  ;
int ldv_work_5_2  ;
    klee_make_symbolic(&ldv_work_5_2, sizeof(int), "ldv_work_5_2");
int ldv_work_7_1  ;
    klee_make_symbolic(&ldv_work_7_1, sizeof(int), "ldv_work_7_1");
int ldv_state_variable_31  ;
    klee_make_symbolic(&ldv_state_variable_31, sizeof(int), "ldv_state_variable_31");
int ldv_work_6_2  ;
    klee_make_symbolic(&ldv_work_6_2, sizeof(int), "ldv_work_6_2");
struct mtd_info *falcon_b0_nic_type_group3  ;
struct efx_channel *efx_hunt_a0_nic_type_group2  ;
int ldv_work_2_1  ;
    klee_make_symbolic(&ldv_work_2_1, sizeof(int), "ldv_work_2_1");
struct efx_nic *falcon_b0_nic_type_group1  ;
struct ethtool_cmd *efx_ethtool_ops_group1  ;
int ldv_timer_13_3  ;
    klee_make_symbolic(&ldv_timer_13_3, sizeof(int), "ldv_timer_13_3");
int ldv_state_variable_8  ;
    klee_make_symbolic(&ldv_state_variable_8, sizeof(int), "ldv_state_variable_8");
struct efx_rx_queue *efx_hunt_a0_nic_type_group0  ;
struct ethtool_pauseparam *efx_ethtool_ops_group2  ;
int ldv_state_variable_15  ;
    klee_make_symbolic(&ldv_state_variable_15, sizeof(int), "ldv_state_variable_15");
struct work_struct *ldv_work_struct_1_3  ;
int ldv_work_8_0  ;
    klee_make_symbolic(&ldv_work_8_0, sizeof(int), "ldv_work_8_0");
struct efx_nic *falcon_a1_nic_type_group1  ;
struct efx_tx_queue *efx_hunt_a0_vf_nic_type_group3  ;
struct ethtool_cmd *falcon_txc_phy_ops_group0  ;
int ldv_state_variable_21  ;
    klee_make_symbolic(&ldv_state_variable_21, sizeof(int), "ldv_state_variable_21");
int ldv_state_variable_33  ;
    klee_make_symbolic(&ldv_state_variable_33, sizeof(int), "ldv_state_variable_33");
struct timer_list *ldv_timer_list_12_0  ;
struct timer_list *ldv_timer_list_11_2  ;
struct work_struct *ldv_work_struct_8_0  ;
struct ethtool_cmd *falcon_sfx7101_phy_ops_group0  ;
int ldv_timer_12_2  ;
    klee_make_symbolic(&ldv_timer_12_2, sizeof(int), "ldv_timer_12_2");
struct ethtool_cmd *efx_mcdi_phy_ops_group0  ;
int ldv_work_3_0  ;
    klee_make_symbolic(&ldv_work_3_0, sizeof(int), "ldv_work_3_0");
struct timer_list *ldv_timer_list_11_0  ;
struct efx_nic *efx_hunt_a0_vf_nic_type_group1  ;
int ldv_work_5_3  ;
    klee_make_symbolic(&ldv_work_5_3, sizeof(int), "ldv_work_5_3");
struct efx_channel *falcon_a1_nic_type_group2  ;
int ldv_timer_10_0  ;
    klee_make_symbolic(&ldv_timer_10_0, sizeof(int), "ldv_timer_10_0");
int ldv_work_6_1  ;
    klee_make_symbolic(&ldv_work_6_1, sizeof(int), "ldv_work_6_1");
int ldv_timer_12_1  ;
    klee_make_symbolic(&ldv_timer_12_1, sizeof(int), "ldv_timer_12_1");
struct work_struct *ldv_work_struct_1_0  ;
int ldv_state_variable_10  ;
    klee_make_symbolic(&ldv_state_variable_10, sizeof(int), "ldv_state_variable_10");
int ldv_work_7_0  ;
    klee_make_symbolic(&ldv_work_7_0, sizeof(int), "ldv_work_7_0");
int ldv_timer_11_3  ;
    klee_make_symbolic(&ldv_timer_11_3, sizeof(int), "ldv_timer_11_3");
int ldv_work_4_1  ;
    klee_make_symbolic(&ldv_work_4_1, sizeof(int), "ldv_work_4_1");
int ldv_timer_13_2  ;
    klee_make_symbolic(&ldv_timer_13_2, sizeof(int), "ldv_timer_13_2");
struct work_struct *ldv_work_struct_7_3  ;
int ldv_state_variable_2  ;
    klee_make_symbolic(&ldv_state_variable_2, sizeof(int), "ldv_state_variable_2");
int ldv_state_variable_25  ;
    klee_make_symbolic(&ldv_state_variable_25, sizeof(int), "ldv_state_variable_25");
int ldv_timer_10_1  ;
    klee_make_symbolic(&ldv_timer_10_1, sizeof(int), "ldv_timer_10_1");
int ldv_work_2_0  ;
    klee_make_symbolic(&ldv_work_2_0, sizeof(int), "ldv_work_2_0");
struct mtd_info *efx_hunt_a0_nic_type_group3  ;
struct timer_list *ldv_timer_list_13_0  ;
int ldv_work_4_2  ;
    klee_make_symbolic(&ldv_work_4_2, sizeof(int), "ldv_work_4_2");
int ldv_state_variable_11  ;
    klee_make_symbolic(&ldv_state_variable_11, sizeof(int), "ldv_state_variable_11");
int ldv_work_1_2  ;
    klee_make_symbolic(&ldv_work_1_2, sizeof(int), "ldv_work_1_2");
struct efx_tx_queue *siena_a0_nic_type_group4  ;
int ldv_state_variable_18  ;
    klee_make_symbolic(&ldv_state_variable_18, sizeof(int), "ldv_state_variable_18");
struct work_struct *ldv_work_struct_5_0  ;
struct timer_list *ldv_timer_list_10_3  ;
struct efx_nic *efx_dummy_phy_operations_group0  ;
struct efx_nic *falcon_txc_phy_ops_group1  ;
struct efx_rx_queue *falcon_b0_nic_type_group0  ;
struct work_struct *ldv_work_struct_9_1  ;
int ldv_work_2_2  ;
    klee_make_symbolic(&ldv_work_2_2, sizeof(int), "ldv_work_2_2");
int ldv_state_variable_32  ;
    klee_make_symbolic(&ldv_state_variable_32, sizeof(int), "ldv_state_variable_32");
struct device *dev_attr_mcdi_logging_group1  ;
struct efx_nic *falcon_sfx7101_phy_ops_group1  ;
struct efx_filter_spec *falcon_a1_nic_type_group5  ;
int pci_counter  ;
    klee_make_symbolic(&pci_counter, sizeof(int), "pci_counter");
int ldv_state_variable_30  ;
    klee_make_symbolic(&ldv_state_variable_30, sizeof(int), "ldv_state_variable_30");
int ldv_work_8_1  ;
    klee_make_symbolic(&ldv_work_8_1, sizeof(int), "ldv_work_8_1");
int ldv_state_variable_0  ;
    klee_make_symbolic(&ldv_state_variable_0, sizeof(int), "ldv_state_variable_0");
struct efx_rx_queue *falcon_a1_nic_type_group0  ;
int ldv_state_variable_12  ;
    klee_make_symbolic(&ldv_state_variable_12, sizeof(int), "ldv_state_variable_12");
struct efx_tx_queue *efx_hunt_a0_nic_type_group4  ;
struct mtd_info *siena_a0_nic_type_group3  ;
struct timer_list *ldv_timer_list_12_1  ;
int ldv_state_variable_22  ;
    klee_make_symbolic(&ldv_state_variable_22, sizeof(int), "ldv_state_variable_22");
int ldv_state_variable_29  ;
    klee_make_symbolic(&ldv_state_variable_29, sizeof(int), "ldv_state_variable_29");
struct work_struct *ldv_work_struct_8_1  ;
struct work_struct *ldv_work_struct_2_0  ;
struct ethtool_wolinfo *efx_ethtool_ops_group6  ;
int ldv_work_6_0  ;
    klee_make_symbolic(&ldv_work_6_0, sizeof(int), "ldv_work_6_0");
int ldv_work_9_0  ;
    klee_make_symbolic(&ldv_work_9_0, sizeof(int), "ldv_work_9_0");
struct work_struct *ldv_work_struct_6_1  ;
int ref_cnt  ;
    klee_make_symbolic(&ref_cnt, sizeof(int), "ref_cnt");
struct efx_nic *efx_mcdi_phy_ops_group1  ;
struct work_struct *ldv_work_struct_8_3  ;
struct work_struct *ldv_work_struct_3_3  ;
int ldv_state_variable_23  ;
    klee_make_symbolic(&ldv_state_variable_23, sizeof(int), "ldv_state_variable_23");
struct timer_list *ldv_timer_list_10_0  ;
struct work_struct *ldv_work_struct_1_1  ;
int ldv_timer_11_2  ;
    klee_make_symbolic(&ldv_timer_11_2, sizeof(int), "ldv_timer_11_2");
int ldv_state_variable_6  ;
    klee_make_symbolic(&ldv_state_variable_6, sizeof(int), "ldv_state_variable_6");
int ldv_work_5_0  ;
    klee_make_symbolic(&ldv_work_5_0, sizeof(int), "ldv_work_5_0");
struct work_struct *ldv_work_struct_4_2  ;
struct timer_list *ldv_timer_list_13_3  ;
struct efx_filter_spec *falcon_b0_nic_type_group5  ;
int ldv_state_variable_38  ;
    klee_make_symbolic(&ldv_state_variable_38, sizeof(int), "ldv_state_variable_38");
int ldv_state_variable_39  ;
    klee_make_symbolic(&ldv_state_variable_39, sizeof(int), "ldv_state_variable_39");
struct work_struct *ldv_work_struct_5_1  ;
struct timer_list *ldv_timer_list_10_1  ;
int ldv_state_variable_3  ;
    klee_make_symbolic(&ldv_state_variable_3, sizeof(int), "ldv_state_variable_3");
struct efx_channel *efx_default_channel_type_group0  ;
int ldv_work_1_0  ;
    klee_make_symbolic(&ldv_work_1_0, sizeof(int), "ldv_work_1_0");
struct pci_dev *efx_pci_driver_group1  ;
int ldv_state_variable_4  ;
    klee_make_symbolic(&ldv_state_variable_4, sizeof(int), "ldv_state_variable_4");
struct work_struct *ldv_work_struct_9_0  ;
struct work_struct *ldv_work_struct_9_3  ;
int ldv_state_variable_36  ;
    klee_make_symbolic(&ldv_state_variable_36, sizeof(int), "ldv_state_variable_36");
int ldv_work_9_2  ;
    klee_make_symbolic(&ldv_work_9_2, sizeof(int), "ldv_work_9_2");
struct ptp_clock_info *efx_phc_clock_info_group0  ;
struct efx_tx_queue *falcon_a1_nic_type_group4  ;
struct work_struct *ldv_work_struct_6_3  ;
struct work_struct *ldv_work_struct_5_2  ;
int ldv_work_9_1  ;
    klee_make_symbolic(&ldv_work_9_1, sizeof(int), "ldv_work_9_1");
struct ethtool_rxnfc *efx_ethtool_ops_group5  ;
int ldv_state_variable_5  ;
    klee_make_symbolic(&ldv_state_variable_5, sizeof(int), "ldv_state_variable_5");
struct work_struct *ldv_work_struct_5_3  ;
int ldv_timer_11_1  ;
    klee_make_symbolic(&ldv_timer_11_1, sizeof(int), "ldv_timer_11_1");
int ldv_timer_12_0  ;
    klee_make_symbolic(&ldv_timer_12_0, sizeof(int), "ldv_timer_12_0");
int ldv_state_variable_13  ;
    klee_make_symbolic(&ldv_state_variable_13, sizeof(int), "ldv_state_variable_13");
int ldv_work_3_2  ;
    klee_make_symbolic(&ldv_work_3_2, sizeof(int), "ldv_work_3_2");
struct device_attribute *dev_attr_phy_flash_cfg_group0  ;
struct work_struct *ldv_work_struct_2_3  ;
int ldv_work_7_3  ;
    klee_make_symbolic(&ldv_work_7_3, sizeof(int), "ldv_work_7_3");
struct timer_list *ldv_timer_list_12_3  ;
int ldv_state_variable_24  ;
    klee_make_symbolic(&ldv_state_variable_24, sizeof(int), "ldv_state_variable_24");
struct timer_list *ldv_timer_list_13_1  ;
int ldv_timer_13_0  ;
    klee_make_symbolic(&ldv_timer_13_0, sizeof(int), "ldv_timer_13_0");
struct efx_filter_spec *efx_hunt_a0_nic_type_group5  ;
struct efx_rx_queue *efx_hunt_a0_vf_nic_type_group0  ;
int ldv_state_variable_1  ;
    klee_make_symbolic(&ldv_state_variable_1, sizeof(int), "ldv_state_variable_1");
struct device_attribute *dev_attr_mcdi_logging_group0  ;
struct mtd_info *falcon_a1_nic_type_group3  ;
struct work_struct *ldv_work_struct_6_2  ;
struct device *efx_pm_ops_group1  ;
struct work_struct *ldv_work_struct_8_2  ;
struct efx_channel *siena_a0_nic_type_group2  ;
int ldv_work_4_3  ;
    klee_make_symbolic(&ldv_work_4_3, sizeof(int), "ldv_work_4_3");
int ldv_work_3_1  ;
    klee_make_symbolic(&ldv_work_3_1, sizeof(int), "ldv_work_3_1");
int ldv_state_variable_16  ;
    klee_make_symbolic(&ldv_state_variable_16, sizeof(int), "ldv_state_variable_16");
int ldv_work_5_1  ;
    klee_make_symbolic(&ldv_work_5_1, sizeof(int), "ldv_work_5_1");
int ldv_work_6_3  ;
    klee_make_symbolic(&ldv_work_6_3, sizeof(int), "ldv_work_6_3");
struct timer_list *ldv_timer_list_12_2  ;
struct ethtool_ringparam *efx_ethtool_ops_group0  ;
struct work_struct *ldv_work_struct_3_0  ;
struct pci_dev *efx_err_handlers_group0  ;
struct work_struct *ldv_work_struct_1_2  ;
struct efx_channel *efx_siena_sriov_channel_type_group0  ;
struct efx_channel *falcon_b0_nic_type_group2  ;
struct timer_list *ldv_timer_list_11_3  ;
struct efx_channel *efx_hunt_a0_vf_nic_type_group2  ;
struct efx_nic *efx_hunt_a0_nic_type_group1  ;
int ldv_work_8_2  ;
    klee_make_symbolic(&ldv_work_8_2, sizeof(int), "ldv_work_8_2");
struct timer_list *ldv_timer_list_13_2  ;
struct efx_rx_queue *siena_a0_nic_type_group0  ;
struct work_struct *ldv_work_struct_4_1  ;
int ldv_state_variable_34  ;
    klee_make_symbolic(&ldv_state_variable_34, sizeof(int), "ldv_state_variable_34");
int ldv_timer_10_3  ;
    klee_make_symbolic(&ldv_timer_10_3, sizeof(int), "ldv_timer_10_3");
int ldv_work_2_3  ;
    klee_make_symbolic(&ldv_work_2_3, sizeof(int), "ldv_work_2_3");
int ldv_timer_13_1  ;
    klee_make_symbolic(&ldv_timer_13_1, sizeof(int), "ldv_timer_13_1");
int ldv_state_variable_35  ;
    klee_make_symbolic(&ldv_state_variable_35, sizeof(int), "ldv_state_variable_35");
void ldv_initialize_ethtool_ops_22(void) ;
void ldv_initialize_efx_nic_type_29(void) ;
void timer_init_12(void) ;
void ldv_initialize_efx_phy_operations_17(void) ;
void ldv_net_device_ops_38(void) ;
void work_init_9(void) ;
void work_init_5(void) ;
void call_and_disable_all_4(int state ) ;
void activate_work_1(struct work_struct *work , int state ) ;
void ldv_initialize_ptp_clock_info_16(void) ;
int reg_timer_10(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) ;
void call_and_disable_work_3(struct work_struct *work ) ;
void ldv_initialize_efx_channel_type_14(void) ;
void disable_work_7(struct work_struct *work ) ;
void disable_work_3(struct work_struct *work ) ;
void work_init_1(void) ;
void disable_suitable_timer_11(struct timer_list *timer ) ;
void invoke_work_4(void) ;
void ldv_initialize_efx_phy_operations_21(void) ;
void ldv_timer_10(int state , struct timer_list *timer ) ;
void work_init_8(void) ;
void activate_work_2(struct work_struct *work , int state ) ;
void choose_timer_11(void) ;
void activate_suitable_timer_10(struct timer_list *timer , unsigned long data ) ;
void timer_init_11(void) ;
void ldv_initialize_pci_error_handlers_32(void) ;
void disable_work_4(struct work_struct *work ) ;
void work_init_4(void) ;
void invoke_work_1(void) ;
int reg_timer_11(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) ;
void activate_suitable_timer_11(struct timer_list *timer , unsigned long data ) ;
void call_and_disable_all_3(int state ) ;
void ldv_initialize_efx_nic_type_28(void) ;
void call_and_disable_work_4(struct work_struct *work ) ;
void ldv_initialize_efx_phy_operations_19(void) ;
void work_init_3(void) ;
void call_and_disable_all_7(int state ) ;
void call_and_disable_work_1(struct work_struct *work ) ;
void call_and_disable_all_2(int state ) ;
void activate_work_3(struct work_struct *work , int state ) ;
void activate_pending_timer_10(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void ldv_initialize_efx_phy_operations_34(void) ;
void ldv_pci_driver_31(void) ;
void work_init_7(void) ;
void ldv_initialize_efx_channel_type_39(void) ;
void ldv_initialize_efx_nic_type_27(void) ;
void disable_work_1(struct work_struct *work ) ;
void ldv_initialize_device_attribute_35(void) ;
void ldv_initialize_efx_phy_operations_20(void) ;
void timer_init_13(void) ;
void ldv_initialize_device_attribute_18(void) ;
void ldv_dev_pm_ops_33(void) ;
void ldv_initialize_efx_nic_type_24(void) ;
void invoke_work_2(void) ;
void ldv_initialize_efx_nic_type_23(void) ;
void activate_work_4(struct work_struct *work , int state ) ;
void disable_suitable_timer_10(struct timer_list *timer ) ;
void work_init_2(void) ;
void call_and_disable_all_1(int state ) ;
void ldv_timer_11(int state , struct timer_list *timer ) ;
void work_init_6(void) ;
void activate_work_7(struct work_struct *work , int state ) ;
void ldv_initialize_efx_channel_type_15(void) ;
void timer_init_10(void) ;
void disable_work_2(struct work_struct *work ) ;
void invoke_work_3(void) ;
void activate_pending_timer_11(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void choose_timer_10(void) ;
void call_and_disable_work_2(struct work_struct *work ) ;
__inline static char const   *kobject_name(struct kobject  const  *kobj ) 
{ 


  {
  return ((char const   *)kobj->name);
}
}
extern int device_create_file(struct device * , struct device_attribute  const  * ) ;
extern void device_remove_file(struct device * , struct device_attribute  const  * ) ;
__inline static char const   *dev_name(struct device  const  *dev ) 
{ 
  char const   *tmp ;

  {
  if ((unsigned long )dev->init_name != (unsigned long )((char const   */* const  */)0)) {
    return ((char const   *)dev->init_name);
  } else {

  }
  tmp = kobject_name(& dev->kobj);
  return (tmp);
}
}
__inline static void *dev_get_drvdata(struct device  const  *dev ) 
{ 


  {
  return ((void *)dev->driver_data);
}
}
__inline static void dev_set_drvdata(struct device *dev , void *data ) 
{ 


  {
  dev->driver_data = data;
  return;
}
}
extern int pci_enable_device(struct pci_dev * ) ;
extern void pci_disable_device(struct pci_dev * ) ;
extern void pci_set_master(struct pci_dev * ) ;
extern int pci_save_state(struct pci_dev * ) ;
extern void pci_restore_state(struct pci_dev * ) ;
extern int pci_set_power_state(struct pci_dev * , pci_power_t  ) ;
extern ssize_t pci_read_vpd(struct pci_dev * , loff_t  , size_t  , void * ) ;
extern int pci_request_region(struct pci_dev * , int  , char const   * ) ;
extern void pci_release_region(struct pci_dev * , int  ) ;
extern int __pci_register_driver(struct pci_driver * , struct module * , char const   * ) ;
int ldv___pci_register_driver_47(struct pci_driver *ldv_func_arg1 , struct module *ldv_func_arg2 ,
                                 char const   *ldv_func_arg3 ) ;
extern void pci_unregister_driver(struct pci_driver * ) ;
void ldv_pci_unregister_driver_49(struct pci_driver *ldv_func_arg1 ) ;
extern void pci_disable_msi(struct pci_dev * ) ;
extern void pci_disable_msix(struct pci_dev * ) ;
extern int pci_enable_msi_range(struct pci_dev * , int  , int  ) ;
__inline static int pci_enable_msi_exact(struct pci_dev *dev , int nvec ) 
{ 
  int rc ;
    klee_make_symbolic(&rc, sizeof(int), "rc");
  int tmp ;

  {
  tmp = pci_enable_msi_range(dev, nvec, nvec);
  rc = tmp;
  if (rc < 0) {
    return (rc);
  } else {

  }
  return (0);
}
}
extern int pci_enable_msix_range(struct pci_dev * , struct msix_entry * , int  , int  ) ;
extern int dma_supported(struct device * , u64  ) ;
extern int dma_set_mask(struct device * , u64  ) ;
__inline static int dma_set_coherent_mask(struct device *dev , u64 mask ) 
{ 
  int tmp ;

  {
  tmp = dma_supported(dev, mask);
  if (tmp == 0) {
    return (-5);
  } else {

  }
  dev->coherent_dma_mask = mask;
  return (0);
}
}
__inline static int dma_set_mask_and_coherent(struct device *dev , u64 mask ) 
{ 
  int rc ;
  int tmp ;

  {
  tmp = dma_set_mask(dev, mask);
  rc = tmp;
  if (rc == 0) {
    dma_set_coherent_mask(dev, mask);
  } else {

  }
  return (rc);
}
}
__inline static void *pci_get_drvdata(struct pci_dev *pdev ) 
{ 
  void *tmp ;

  {
  tmp = dev_get_drvdata((struct device  const  *)(& pdev->dev));
  return (tmp);
}
}
__inline static void pci_set_drvdata(struct pci_dev *pdev , void *data ) 
{ 


  {
  dev_set_drvdata(& pdev->dev, data);
  return;
}
}
__inline static char const   *pci_name(struct pci_dev  const  *pdev ) 
{ 
  char const   *tmp ;

  {
  tmp = dev_name(& pdev->dev);
  return (tmp);
}
}
extern int pci_vfs_assigned(struct pci_dev * ) ;
__inline static u16 pci_vpd_lrdt_size(u8 const   *lrdt ) 
{ 


  {
  return ((int )((u16 )*(lrdt + 1UL)) + ((int )((u16 )*(lrdt + 2UL)) << 8U));
}
}
__inline static u8 pci_vpd_info_field_size(u8 const   *info_field ) 
{ 


  {
  return ((u8 )*(info_field + 2UL));
}
}
extern int pci_vpd_find_tag(u8 const   * , unsigned int  , unsigned int  , u8  ) ;
extern int pci_vpd_find_info_keyword(u8 const   * , unsigned int  , unsigned int  ,
                                     char const   * ) ;
extern void msleep(unsigned int  ) ;
extern void usleep_range(unsigned long  , unsigned long  ) ;
__inline static u32 ethtool_rxfh_indir_default(u32 index , u32 n_rx_rings ) 
{ 


  {
  return (index % n_rx_rings);
}
}
extern void synchronize_irq(unsigned int  ) ;
extern void enable_irq(unsigned int  ) ;
__inline static struct mii_ioctl_data *if_mii(struct ifreq *rq ) 
{ 


  {
  return ((struct mii_ioctl_data *)(& rq->ifr_ifru));
}
}
extern void __napi_schedule(struct napi_struct * ) ;
__inline static bool napi_disable_pending(struct napi_struct *n ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& n->state));
  return (tmp != 0);
}
}
__inline static bool napi_schedule_prep(struct napi_struct *n ) 
{ 
  bool tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
  tmp = napi_disable_pending(n);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    tmp___1 = test_and_set_bit(0L, (unsigned long volatile   *)(& n->state));
    if (tmp___1 == 0) {
      tmp___2 = 1;
    } else {
      tmp___2 = 0;
    }
  } else {
    tmp___2 = 0;
  }
  return ((bool )tmp___2);
}
}
__inline static void napi_schedule(struct napi_struct *n ) 
{ 
  bool tmp ;

  {
  tmp = napi_schedule_prep(n);
  if ((int )tmp) {
    __napi_schedule(n);
  } else {

  }
  return;
}
}
__inline static void napi_complete(struct napi_struct *n ) 
{ 


  {
  return;
}
}
extern void napi_hash_add(struct napi_struct * ) ;
extern void napi_hash_del(struct napi_struct * ) ;
extern void napi_disable(struct napi_struct * ) ;
__inline static void napi_enable(struct napi_struct *n ) 
{ 
  int tmp ;
  long tmp___0 ;

  {
  tmp = constant_test_bit(0L, (unsigned long const volatile   *)(& n->state));
  tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/netdevice.h"),
                         "i" (507), "i" (12UL));
    ldv_43838: ;
    goto ldv_43838;
  } else {

  }
  __asm__  volatile   ("": : : "memory");
  clear_bit(0L, (unsigned long volatile   *)(& n->state));
  return;
}
}
__inline static struct netdev_queue *netdev_get_tx_queue(struct net_device  const  *dev ,
                                                         unsigned int index ) 
{ 


  {
  return ((struct netdev_queue *)dev->_tx + (unsigned long )index);
}
}
__inline static void *netdev_priv(struct net_device  const  *dev ) 
{ 


  {
  return ((void *)dev + 3008U);
}
}
extern void netif_napi_add(struct net_device * , struct napi_struct * , int (*)(struct napi_struct * ,
                                                                                int  ) ,
                           int  ) ;
extern void netif_napi_del(struct napi_struct * ) ;
extern int register_netdevice_notifier(struct notifier_block * ) ;
extern int unregister_netdevice_notifier(struct notifier_block * ) ;
__inline static struct net_device *netdev_notifier_info_to_dev(struct netdev_notifier_info  const  *info ) 
{ 


  {
  return ((struct net_device *)info->dev);
}
}
extern int dev_alloc_name(struct net_device * , char const   * ) ;
extern int dev_close(struct net_device * ) ;
extern int register_netdevice(struct net_device * ) ;
extern void unregister_netdevice_queue(struct net_device * , struct list_head * ) ;
__inline static void unregister_netdevice(struct net_device *dev ) 
{ 


  {
  unregister_netdevice_queue(dev, (struct list_head *)0);
  return;
}
}
extern void free_netdev(struct net_device * ) ;
extern void netif_schedule_queue(struct netdev_queue * ) ;
extern void netif_tx_wake_queue(struct netdev_queue * ) ;
__inline static void netif_tx_wake_all_queues(struct net_device *dev ) 
{ 
  unsigned int i ;
    klee_make_symbolic(&i, sizeof(int), "i");
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  i = 0U;
  goto ldv_44917;
  ldv_44916: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  netif_tx_wake_queue(txq);
  i = i + 1U;
  ldv_44917: ;
  if (dev->num_tx_queues > i) {
    goto ldv_44916;
  } else {

  }

  return;
}
}
__inline static void netif_tx_stop_queue(struct netdev_queue *dev_queue ) 
{ 


  {
  set_bit(0L, (unsigned long volatile   *)(& dev_queue->state));
  return;
}
}
__inline static bool netif_running(struct net_device  const  *dev ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(0L, (unsigned long const volatile   *)(& dev->state));
  return (tmp != 0);
}
}
extern int netif_set_real_num_tx_queues(struct net_device * , unsigned int  ) ;
extern int netif_set_real_num_rx_queues(struct net_device * , unsigned int  ) ;
__inline static bool netif_carrier_ok(struct net_device  const  *dev ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(2L, (unsigned long const volatile   *)(& dev->state));
  return (tmp == 0);
}
}
extern void netif_carrier_on(struct net_device * ) ;
extern void netif_carrier_off(struct net_device * ) ;
__inline static bool netif_device_present(struct net_device *dev ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& dev->state));
  return (tmp != 0);
}
}
extern void netif_device_detach(struct net_device * ) ;
extern void netif_device_attach(struct net_device * ) ;
__inline static void __netif_tx_lock(struct netdev_queue *txq , int cpu ) 
{ 


  {
  spin_lock(& txq->_xmit_lock);
  txq->xmit_lock_owner = cpu;
  return;
}
}
__inline static void __netif_tx_unlock(struct netdev_queue *txq ) 
{ 


  {
  txq->xmit_lock_owner = -1;
  spin_unlock(& txq->_xmit_lock);
  return;
}
}
__inline static void netif_tx_lock(struct net_device *dev ) 
{ 
  unsigned int i ;
  int cpu ;
  int pscr_ret__ ;
    klee_make_symbolic(&pscr_ret__, sizeof(int), "pscr_ret__");
  void const   *__vpp_verify ;
  int pfo_ret__ ;
    klee_make_symbolic(&pfo_ret__, sizeof(int), "pfo_ret__");
  int pfo_ret_____0 ;
    klee_make_symbolic(&pfo_ret_____0, sizeof(int), "pfo_ret_____0");
  int pfo_ret_____1 ;
    klee_make_symbolic(&pfo_ret_____1, sizeof(int), "pfo_ret_____1");
  int pfo_ret_____2 ;
    klee_make_symbolic(&pfo_ret_____2, sizeof(int), "pfo_ret_____2");
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  spin_lock(& dev->tx_global_lock);
  __vpp_verify = (void const   *)0;
  switch (4UL) {
  case 1UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
  goto ldv_45415;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_45415;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_45415;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_45415;
  default: 
  __bad_percpu_size();
  }
  ldv_45415: 
  pscr_ret__ = pfo_ret__;
  goto ldv_45421;
  case 2UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45425;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45425;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45425;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45425;
  default: 
  __bad_percpu_size();
  }
  ldv_45425: 
  pscr_ret__ = pfo_ret_____0;
  goto ldv_45421;
  case 4UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45434;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45434;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45434;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45434;
  default: 
  __bad_percpu_size();
  }
  ldv_45434: 
  pscr_ret__ = pfo_ret_____1;
  goto ldv_45421;
  case 8UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45443;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45443;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45443;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45443;
  default: 
  __bad_percpu_size();
  }
  ldv_45443: 
  pscr_ret__ = pfo_ret_____2;
  goto ldv_45421;
  default: 
  __bad_size_call_parameter();
  goto ldv_45421;
  }
  ldv_45421: 
  cpu = pscr_ret__;
  i = 0U;
  goto ldv_45453;
  ldv_45452: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  __netif_tx_lock(txq, cpu);
  set_bit(2L, (unsigned long volatile   *)(& txq->state));
  __netif_tx_unlock(txq);
  i = i + 1U;
  ldv_45453: ;
  if (dev->num_tx_queues > i) {
    goto ldv_45452;
  } else {

  }

  return;
}
}
__inline static void netif_tx_lock_bh(struct net_device *dev ) 
{ 


  {
  local_bh_disable();
  netif_tx_lock(dev);
  return;
}
}
__inline static void netif_tx_unlock(struct net_device *dev ) 
{ 
  unsigned int i ;
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  i = 0U;
  goto ldv_45464;
  ldv_45463: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  clear_bit(2L, (unsigned long volatile   *)(& txq->state));
  netif_schedule_queue(txq);
  i = i + 1U;
  ldv_45464: ;
  if (dev->num_tx_queues > i) {
    goto ldv_45463;
  } else {

  }
  spin_unlock(& dev->tx_global_lock);
  return;
}
}
__inline static void netif_tx_unlock_bh(struct net_device *dev ) 
{ 


  {
  netif_tx_unlock(dev);
  local_bh_enable();
  return;
}
}
__inline static void netif_tx_disable(struct net_device *dev ) 
{ 
  unsigned int i ;
  int cpu ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  local_bh_disable();
  __vpp_verify = (void const   *)0;
  switch (4UL) {
  case 1UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
  goto ldv_45479;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_45479;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_45479;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_45479;
  default: 
  __bad_percpu_size();
  }
  ldv_45479: 
  pscr_ret__ = pfo_ret__;
  goto ldv_45485;
  case 2UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45489;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45489;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45489;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45489;
  default: 
  __bad_percpu_size();
  }
  ldv_45489: 
  pscr_ret__ = pfo_ret_____0;
  goto ldv_45485;
  case 4UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45498;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45498;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45498;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45498;
  default: 
  __bad_percpu_size();
  }
  ldv_45498: 
  pscr_ret__ = pfo_ret_____1;
  goto ldv_45485;
  case 8UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45507;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45507;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45507;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45507;
  default: 
  __bad_percpu_size();
  }
  ldv_45507: 
  pscr_ret__ = pfo_ret_____2;
  goto ldv_45485;
  default: 
  __bad_size_call_parameter();
  goto ldv_45485;
  }
  ldv_45485: 
  cpu = pscr_ret__;
  i = 0U;
  goto ldv_45517;
  ldv_45516: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  __netif_tx_lock(txq, cpu);
  netif_tx_stop_queue(txq);
  __netif_tx_unlock(txq);
  i = i + 1U;
  ldv_45517: ;
  if (dev->num_tx_queues > i) {
    goto ldv_45516;
  } else {

  }
  local_bh_enable();
  return;
}
}
__inline static void netif_addr_lock_bh(struct net_device *dev ) 
{ 


  {
  spin_lock_bh(& dev->addr_list_lock);
  return;
}
}
__inline static void netif_addr_unlock_bh(struct net_device *dev ) 
{ 


  {
  spin_unlock_bh(& dev->addr_list_lock);
  return;
}
}
extern void unregister_netdev(struct net_device * ) ;
extern void netdev_rss_key_fill(void * , size_t  ) ;
extern void netdev_printk(char const   * , struct net_device  const  * , char const   * 
                          , ...) ;
extern void netdev_err(struct net_device  const  * , char const   *  , ...) ;
extern void netdev_warn(struct net_device  const  * , char const   *  , ...) ;
extern void netdev_info(struct net_device  const  * , char const   *  , ...) ;
extern int eth_validate_addr(struct net_device * ) ;
extern struct net_device *alloc_etherdev_mqs(int  , unsigned int  , unsigned int  ) ;
__inline static bool is_zero_ether_addr(u8 const   *addr ) 
{ 


  {
  return (((unsigned int )*((u32 const   *)addr) | (unsigned int )*((u16 const   *)addr + 4U)) == 0U);
}
}
__inline static bool is_multicast_ether_addr(u8 const   *addr ) 
{ 
  u32 a ;

  {
  a = *((u32 const   *)addr);
  return ((a & 1U) != 0U);
}
}
__inline static bool is_valid_ether_addr(u8 const   *addr ) 
{ 
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
  tmp = is_multicast_ether_addr(addr);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    tmp___1 = is_zero_ether_addr(addr);
    if (tmp___1) {
      tmp___2 = 0;
    } else {
      tmp___2 = 1;
    }
    if (tmp___2) {
      tmp___3 = 1;
    } else {
      tmp___3 = 0;
    }
  } else {
    tmp___3 = 0;
  }
  return ((bool )tmp___3);
}
}
__inline static void ether_addr_copy(u8 *dst , u8 const   *src ) 
{ 


  {
  *((u32 *)dst) = *((u32 const   *)src);
  *((u16 *)dst + 4U) = *((u16 const   *)src + 4U);
  return;
}
}
extern void rtnl_lock(void) ;
extern void rtnl_unlock(void) ;
extern int rtnl_is_locked(void) ;
extern int pci_enable_pcie_error_reporting(struct pci_dev * ) ;
extern int pci_disable_pcie_error_reporting(struct pci_dev * ) ;
extern int pci_cleanup_aer_uncorrect_error_status(struct pci_dev * ) ;
extern int mdio_mii_ioctl(struct mdio_if_info  const  * , struct mii_ioctl_data * ,
                          int  ) ;
__inline static void efx_channel_init_lock(struct efx_channel *channel ) 
{ 
  struct lock_class_key __key ;

  {
  spinlock_check(& channel->state_lock);
  __raw_spin_lock_init(& channel->state_lock.__annonCompField17.rlock, "&(&channel->state_lock)->rlock",
                       & __key);
  return;
}
}
__inline static bool efx_channel_lock_napi(struct efx_channel *channel ) 
{ 
  bool rc ;
  int __ret_warn_on ;
  long tmp ;

  {
  rc = 1;
  spin_lock_bh(& channel->state_lock);
  if ((channel->state & 7U) != 0U) {
    __ret_warn_on = (int )channel->state & 1;
    tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp != 0L) {
      warn_slowpath_null("/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/net/ethernet/sfc/net_driver.h",
                         493);
    } else {

    }
    ldv__builtin_expect(__ret_warn_on != 0, 0L);
    channel->state = channel->state | 8U;
    rc = 0;
  } else {
    channel->state = 1U;
  }
  spin_unlock_bh(& channel->state_lock);
  return (rc);
}
}
__inline static void efx_channel_unlock_napi(struct efx_channel *channel ) 
{ 
  int __ret_warn_on ;
  long tmp ;

  {
  spin_lock_bh(& channel->state_lock);
  __ret_warn_on = (channel->state & 10U) != 0U;
  tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/net/ethernet/sfc/net_driver.h",
                       508);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  channel->state = channel->state & 4U;
  spin_unlock_bh(& channel->state_lock);
  return;
}
}
__inline static bool efx_channel_lock_poll(struct efx_channel *channel ) 
{ 
  bool rc ;

  {
  rc = 1;
  spin_lock_bh(& channel->state_lock);
  if ((channel->state & 7U) != 0U) {
    channel->state = channel->state | 16U;
    rc = 0;
  } else {
    channel->state = channel->state | 2U;
  }
  spin_unlock_bh(& channel->state_lock);
  return (rc);
}
}
__inline static void efx_channel_unlock_poll(struct efx_channel *channel ) 
{ 
  int __ret_warn_on ;
  long tmp ;

  {
  spin_lock_bh(& channel->state_lock);
  __ret_warn_on = (int )channel->state & 1;
  tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/net/ethernet/sfc/net_driver.h",
                       535);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  channel->state = channel->state & 4U;
  spin_unlock_bh(& channel->state_lock);
  return;
}
}
__inline static void efx_channel_enable(struct efx_channel *channel ) 
{ 


  {
  spin_lock_bh(& channel->state_lock);
  channel->state = 0U;
  spin_unlock_bh(& channel->state_lock);
  return;
}
}
__inline static bool efx_channel_disable(struct efx_channel *channel ) 
{ 
  bool rc ;

  {
  rc = 1;
  spin_lock_bh(& channel->state_lock);
  if ((channel->state & 3U) != 0U) {
    rc = 0;
  } else {

  }
  channel->state = channel->state | 4U;
  spin_unlock_bh(& channel->state_lock);
  return (rc);
}
}
char const   * const  efx_loopback_mode_names[27U] ;
unsigned int const   efx_loopback_mode_max ;
char const   * const  efx_reset_type_names[16U] ;
unsigned int const   efx_reset_type_max ;
__inline static int efx_dev_registered(struct efx_nic *efx ) 
{ 


  {
  return ((unsigned int )(efx->net_dev)->reg_state == 1U);
}
}
__inline static struct efx_channel *efx_get_channel(struct efx_nic *efx , unsigned int index ) 
{ 


  {
  return (efx->channel[index]);
}
}
__inline static bool efx_channel_has_tx_queues(struct efx_channel *channel ) 
{ 


  {
  return ((unsigned int )channel->channel - (channel->efx)->tx_channel_offset < (channel->efx)->n_tx_channels);
}
}
__inline static bool efx_tx_queue_used(struct efx_tx_queue *tx_queue ) 
{ 


  {
  return ((bool )((unsigned int )((tx_queue->efx)->net_dev)->num_tc > 1U || (tx_queue->queue & 2U) == 0U));
}
}
__inline static bool efx_channel_has_rx_queue(struct efx_channel *channel ) 
{ 


  {
  return (channel->rx_queue.core_index >= 0);
}
}
__inline static struct efx_rx_queue *efx_channel_get_rx_queue(struct efx_channel *channel ) 
{ 


  {
  return (& channel->rx_queue);
}
}
int efx_net_open(struct net_device *net_dev ) ;
int efx_net_stop(struct net_device *net_dev ) ;
int efx_probe_tx_queue(struct efx_tx_queue *tx_queue ) ;
void efx_remove_tx_queue(struct efx_tx_queue *tx_queue ) ;
void efx_init_tx_queue(struct efx_tx_queue *tx_queue ) ;
void efx_init_tx_queue_core_txq(struct efx_tx_queue *tx_queue ) ;
void efx_fini_tx_queue(struct efx_tx_queue *tx_queue ) ;
netdev_tx_t efx_hard_start_xmit(struct sk_buff *skb , struct net_device *net_dev ) ;
int efx_setup_tc(struct net_device *net_dev , u8 num_tc ) ;
unsigned int efx_tx_max_skb_descs(struct efx_nic *efx ) ;
void efx_set_default_rx_indir_table(struct efx_nic *efx ) ;
void efx_rx_config_page_split(struct efx_nic *efx ) ;
int efx_probe_rx_queue(struct efx_rx_queue *rx_queue ) ;
void efx_remove_rx_queue(struct efx_rx_queue *rx_queue ) ;
void efx_init_rx_queue(struct efx_rx_queue *rx_queue ) ;
void efx_fini_rx_queue(struct efx_rx_queue *rx_queue ) ;
void efx_fast_push_rx_descriptors(struct efx_rx_queue *rx_queue , bool atomic ) ;
void efx_rx_slow_fill(unsigned long context ) ;
void __efx_rx_packet(struct efx_channel *channel ) ;
__inline static void efx_rx_flush_packet(struct efx_channel *channel ) 
{ 


  {
  if (channel->rx_pkt_n_frags != 0U) {
    __efx_rx_packet(channel);
  } else {

  }
  return;
}
}
void efx_schedule_slow_fill(struct efx_rx_queue *rx_queue ) ;
void efx_mac_reconfigure(struct efx_nic *efx ) ;
int efx_filter_rfs(struct net_device *net_dev , struct sk_buff  const  *skb , u16 rxq_index ,
                   u32 flow_id ) ;
bool __efx_filter_rfs_expire(struct efx_nic *efx , unsigned int quota ) ;
__inline static void efx_filter_rfs_expire(struct efx_channel *channel ) 
{ 
  bool tmp ;

  {
  if (channel->rfs_filters_added > 59U) {
    tmp = __efx_filter_rfs_expire(channel->efx, 100U);
    if ((int )tmp) {
      channel->rfs_filters_added = channel->rfs_filters_added - 60U;
    } else {

    }
  } else {

  }
  return;
}
}
int efx_channel_dummy_op_int(struct efx_channel *channel ) ;
void efx_channel_dummy_op_void(struct efx_channel *channel ) ;
int efx_realloc_channels(struct efx_nic *efx , u32 rxq_entries , u32 txq_entries ) ;
int efx_reconfigure_port(struct efx_nic *efx ) ;
int __efx_reconfigure_port(struct efx_nic *efx ) ;
struct ethtool_ops  const  efx_ethtool_ops ;
int efx_reset(struct efx_nic *efx , enum reset_type method ) ;
void efx_reset_down(struct efx_nic *efx , enum reset_type method ) ;
int efx_reset_up(struct efx_nic *efx , enum reset_type method , bool ok ) ;
int efx_try_recovery(struct efx_nic *efx ) ;
void efx_schedule_reset(struct efx_nic *efx , enum reset_type type ) ;
int efx_init_irq_moderation(struct efx_nic *efx , unsigned int tx_usecs , unsigned int rx_usecs ,
                            bool rx_adaptive , bool rx_may_override_tx ) ;
void efx_get_irq_moderation(struct efx_nic *efx , unsigned int *tx_usecs , unsigned int *rx_usecs ,
                            bool *rx_adaptive ) ;
void efx_stop_eventq(struct efx_channel *channel ) ;
void efx_start_eventq(struct efx_channel *channel ) ;
int efx_port_dummy_op_int(struct efx_nic *efx ) ;
void efx_port_dummy_op_void(struct efx_nic *efx ) ;
void efx_update_sw_stats(struct efx_nic *efx , u64 *stats ) ;
__inline static int efx_mtd_probe(struct efx_nic *efx ) 
{ 
  int tmp ;

  {
  tmp = (*((efx->type)->mtd_probe))(efx);
  return (tmp);
}
}
void efx_mtd_rename(struct efx_nic *efx ) ;
void efx_mtd_remove(struct efx_nic *efx ) ;
__inline static unsigned int efx_vf_size(struct efx_nic *efx ) 
{ 


  {
  return ((unsigned int )(1 << (int )efx->vi_scale));
}
}
__inline static void efx_schedule_channel(struct efx_channel *channel ) 
{ 
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;

  {
  if (0) {
    if (((channel->efx)->msg_enable & 512U) != 0U) {
      __vpp_verify = (void const   *)0;
      switch (4UL) {
      case 1UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
      goto ldv_55423;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_55423;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_55423;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_55423;
      default: 
      __bad_percpu_size();
      }
      ldv_55423: 
      pscr_ret__ = pfo_ret__;
      goto ldv_55429;
      case 2UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_55433;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_55433;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_55433;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_55433;
      default: 
      __bad_percpu_size();
      }
      ldv_55433: 
      pscr_ret__ = pfo_ret_____0;
      goto ldv_55429;
      case 4UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_55442;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_55442;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_55442;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_55442;
      default: 
      __bad_percpu_size();
      }
      ldv_55442: 
      pscr_ret__ = pfo_ret_____1;
      goto ldv_55429;
      case 8UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_55451;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_55451;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_55451;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_55451;
      default: 
      __bad_percpu_size();
      }
      ldv_55451: 
      pscr_ret__ = pfo_ret_____2;
      goto ldv_55429;
      default: 
      __bad_size_call_parameter();
      goto ldv_55429;
      }
      ldv_55429: 
      netdev_printk("\017", (struct net_device  const  *)(channel->efx)->net_dev,
                    "channel %d scheduling NAPI poll on CPU%d\n", channel->channel,
                    pscr_ret__);
    } else {

    }
  } else {

  }
  napi_schedule(& channel->napi_str);
  return;
}
}
void efx_link_status_changed(struct efx_nic *efx ) ;
void efx_link_set_advertising(struct efx_nic *efx , u32 advertising ) ;
void efx_link_set_wanted_fc(struct efx_nic *efx , u8 wanted_fc ) ;
__inline static void efx_device_detach_sync(struct efx_nic *efx ) 
{ 
  struct net_device *dev ;

  {
  dev = efx->net_dev;
  netif_tx_lock_bh(dev);
  netif_device_detach(dev);
  netif_tx_unlock_bh(dev);
  return;
}
}
__inline static struct efx_mcdi_iface *efx_mcdi(struct efx_nic *efx ) 
{ 


  {
  return (& (efx->mcdi)->iface);
}
}
int efx_mcdi_poll_reboot(struct efx_nic *efx ) ;
void efx_mcdi_mode_poll(struct efx_nic *efx ) ;
void efx_mcdi_mode_event(struct efx_nic *efx ) ;
void efx_mcdi_flush_async(struct efx_nic *efx ) ;
__inline static int efx_nic_rev(struct efx_nic *efx ) 
{ 


  {
  return ((int )(efx->type)->revision);
}
}
int efx_init_sriov(void) ;
void efx_fini_sriov(void) ;
int efx_ptp_set_ts_config(struct efx_nic *efx , struct ifreq *ifr ) ;
int efx_ptp_get_ts_config(struct efx_nic *efx , struct ifreq *ifr ) ;
void efx_ptp_start_datapath(struct efx_nic *efx ) ;
void efx_ptp_stop_datapath(struct efx_nic *efx ) ;
struct efx_nic_type  const  falcon_a1_nic_type ;
struct efx_nic_type  const  falcon_b0_nic_type ;
struct efx_nic_type  const  siena_a0_nic_type ;
struct efx_nic_type  const  efx_hunt_a0_nic_type ;
struct efx_nic_type  const  efx_hunt_a0_vf_nic_type ;
__inline static int efx_nic_probe_eventq(struct efx_channel *channel ) 
{ 
  int tmp ;

  {
  tmp = (*(((channel->efx)->type)->ev_probe))(channel);
  return (tmp);
}
}
__inline static int efx_nic_init_eventq(struct efx_channel *channel ) 
{ 
  int tmp ;

  {
  tmp = (*(((channel->efx)->type)->ev_init))(channel);
  return (tmp);
}
}
__inline static void efx_nic_fini_eventq(struct efx_channel *channel ) 
{ 


  {
  (*(((channel->efx)->type)->ev_fini))(channel);
  return;
}
}
__inline static void efx_nic_remove_eventq(struct efx_channel *channel ) 
{ 


  {
  (*(((channel->efx)->type)->ev_remove))(channel);
  return;
}
}
__inline static int efx_nic_process_eventq(struct efx_channel *channel , int quota ) 
{ 
  int tmp ;

  {
  tmp = (*(((channel->efx)->type)->ev_process))(channel, quota);
  return (tmp);
}
}
__inline static void efx_nic_eventq_read_ack(struct efx_channel *channel ) 
{ 


  {
  (*(((channel->efx)->type)->ev_read_ack))(channel);
  return;
}
}
int efx_nic_init_interrupt(struct efx_nic *efx ) ;
void efx_nic_fini_interrupt(struct efx_nic *efx ) ;
void efx_selftest_async_start(struct efx_nic *efx ) ;
void efx_selftest_async_cancel(struct efx_nic *efx ) ;
void efx_selftest_async_work(struct work_struct *data ) ;
int efx_sriov_set_vf_mac(struct net_device *net_dev , int vf_i , u8 *mac ) ;
int efx_sriov_set_vf_vlan(struct net_device *net_dev , int vf_i , u16 vlan , u8 qos ) ;
int efx_sriov_set_vf_spoofchk(struct net_device *net_dev , int vf_i , bool spoofchk ) ;
int efx_sriov_get_vf_config(struct net_device *net_dev , int vf_i , struct ifla_vf_info *ivi ) ;
int efx_sriov_set_vf_link_state(struct net_device *net_dev , int vf_i , int link_state ) ;
int efx_sriov_get_phys_port_id(struct net_device *net_dev , struct netdev_phys_item_id *ppid ) ;
unsigned int const   efx_loopback_mode_max  =    27U;
char const   * const  efx_loopback_mode_names[27U]  = 
  {      "NONE",      "DATAPATH",      "GMAC",      "XGMII", 
        "XGXS",      "XAUI",      "GMII",      "SGMII", 
        "XGBR",      "XFI",      "XAUI_FAR",      "GMII_FAR", 
        "SGMII_FAR",      "XFI_FAR",      "GPHY",      "PHYXS", 
        "PCS",      "PMA/PMD",      "XPORT",      "XGMII_WS", 
        "XAUI_WS",      "XAUI_WS_FAR",      "XAUI_WS_NEAR",      "GMII_WS", 
        "XFI_WS",      "XFI_WS_FAR",      "PHYXS_WS"};
unsigned int const   efx_reset_type_max  =    16U;
char const   * const  efx_reset_type_names[16U]  = 
  {      "INVISIBLE",      "RECOVER_OR_ALL",      "ALL",      "WORLD", 
        "RECOVER_OR_DISABLE",      "DATAPATH",      "MC_BIST",      "DISABLE", 
        0,      "TX_WATCHDOG",      "INT_ERROR",      "RX_RECOVERY", 
        "DMA_ERROR",      "TX_SKIP",      "MC_FAILURE",      "MCDI_TIMEOUT (FLR)"};
static struct workqueue_struct *reset_workqueue  ;
static bool separate_tx_channels  ;
static int napi_weight  =    64;
static unsigned int efx_monitor_interval  =    250U;
static unsigned int rx_irq_mod_usec  =    60U;
static unsigned int tx_irq_mod_usec  =    150U;
static unsigned int interrupt_mode  ;
    klee_make_symbolic(&interrupt_mode, sizeof(int), "interrupt_mode");
static unsigned int rss_cpus  ;
    klee_make_symbolic(&rss_cpus, sizeof(int), "rss_cpus");
static bool phy_flash_cfg  ;
static unsigned int irq_adapt_low_thresh  =    8000U;
static unsigned int irq_adapt_high_thresh  =    16000U;
static unsigned int debug  =    8439U;
static int efx_soft_enable_interrupts(struct efx_nic *efx ) ;
static void efx_soft_disable_interrupts(struct efx_nic *efx ) ;
static void efx_remove_channel(struct efx_channel *channel ) ;
static void efx_remove_channels(struct efx_nic *efx ) ;
static struct efx_channel_type  const  efx_default_channel_type ;
static void efx_remove_port(struct efx_nic *efx ) ;
static void efx_init_napi_channel(struct efx_channel *channel ) ;
static void efx_fini_napi(struct efx_nic *efx ) ;
static void efx_fini_napi_channel(struct efx_channel *channel ) ;
static void efx_fini_struct(struct efx_nic *efx ) ;
static void efx_start_all(struct efx_nic *efx ) ;
static void efx_stop_all(struct efx_nic *efx ) ;
static int efx_check_disabled(struct efx_nic *efx ) 
{ 


  {
  if ((unsigned int )efx->state == 2U || (unsigned int )efx->state == 3U) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "device is disabled due to earlier errors\n");
    } else {

    }
    return (-5);
  } else {

  }
  return (0);
}
}
static int efx_process_channel(struct efx_channel *channel , int budget ) 
{ 
  int spent ;
    klee_make_symbolic(&spent, sizeof(int), "spent");
  long tmp ;
  struct efx_rx_queue *rx_queue ;
  struct efx_rx_queue *tmp___0 ;
  bool tmp___1 ;

  {
  tmp = ldv__builtin_expect((long )(! channel->enabled), 0L);
  if (tmp != 0L) {
    return (0);
  } else {

  }
  spent = efx_nic_process_eventq(channel, budget);
  if (spent != 0) {
    tmp___1 = efx_channel_has_rx_queue(channel);
    if ((int )tmp___1) {
      tmp___0 = efx_channel_get_rx_queue(channel);
      rx_queue = tmp___0;
      efx_rx_flush_packet(channel);
      efx_fast_push_rx_descriptors(rx_queue, 1);
    } else {

    }
  } else {

  }
  return (spent);
}
}
static int efx_poll(struct napi_struct *napi , int budget ) 
{ 
  struct efx_channel *channel ;
  struct napi_struct  const  *__mptr ;
  struct efx_nic *efx ;
  int spent ;
  bool tmp ;
  int tmp___0 ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  long tmp___1 ;
  long tmp___2 ;
    klee_make_symbolic(&tmp___2, sizeof(long), "tmp___2");
  bool tmp___3 ;
  long tmp___4 ;
    klee_make_symbolic(&tmp___4, sizeof(long), "tmp___4");

  {
  __mptr = (struct napi_struct  const  *)napi;
  channel = (struct efx_channel *)__mptr + 0xffffffffffffffd0UL;
  efx = channel->efx;
  tmp = efx_channel_lock_napi(channel);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (budget);
  } else {

  }
  if (0) {
    if ((efx->msg_enable & 512U) != 0U) {
      __vpp_verify = (void const   *)0;
      switch (4UL) {
      case 1UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
      goto ldv_56627;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_56627;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_56627;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_56627;
      default: 
      __bad_percpu_size();
      }
      ldv_56627: 
      pscr_ret__ = pfo_ret__;
      goto ldv_56633;
      case 2UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_56637;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_56637;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_56637;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_56637;
      default: 
      __bad_percpu_size();
      }
      ldv_56637: 
      pscr_ret__ = pfo_ret_____0;
      goto ldv_56633;
      case 4UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_56646;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_56646;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_56646;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_56646;
      default: 
      __bad_percpu_size();
      }
      ldv_56646: 
      pscr_ret__ = pfo_ret_____1;
      goto ldv_56633;
      case 8UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_56655;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_56655;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_56655;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_56655;
      default: 
      __bad_percpu_size();
      }
      ldv_56655: 
      pscr_ret__ = pfo_ret_____2;
      goto ldv_56633;
      default: 
      __bad_size_call_parameter();
      goto ldv_56633;
      }
      ldv_56633: 
      netdev_printk("\017", (struct net_device  const  *)efx->net_dev, "channel %d NAPI poll executing on CPU %d\n",
                    channel->channel, pscr_ret__);
    } else {

    }
  } else {

  }
  spent = efx_process_channel(channel, budget);
  if (spent < budget) {
    tmp___3 = efx_channel_has_rx_queue(channel);
    if ((int )tmp___3 && (int )efx->irq_rx_adaptive) {
      channel->irq_count = channel->irq_count + 1U;
      tmp___4 = ldv__builtin_expect(channel->irq_count == 1000U, 0L);
      if (tmp___4 != 0L) {
        tmp___2 = ldv__builtin_expect(channel->irq_mod_score < irq_adapt_low_thresh,
                                   0L);
        if (tmp___2 != 0L) {
          if (channel->irq_moderation > 1U) {
            channel->irq_moderation = channel->irq_moderation - 1U;
            (*((efx->type)->push_irq_moderation))(channel);
          } else {

          }
        } else {
          tmp___1 = ldv__builtin_expect(channel->irq_mod_score > irq_adapt_high_thresh,
                                     0L);
          if (tmp___1 != 0L) {
            if (channel->irq_moderation < efx->irq_rx_moderation) {
              channel->irq_moderation = channel->irq_moderation + 1U;
              (*((efx->type)->push_irq_moderation))(channel);
            } else {

            }
          } else {

          }
        }
        channel->irq_count = 0U;
        channel->irq_mod_score = 0U;
      } else {

      }
    } else {

    }
    efx_filter_rfs_expire(channel);
    napi_complete(napi);
    efx_nic_eventq_read_ack(channel);
  } else {

  }
  efx_channel_unlock_napi(channel);
  return (spent);
}
}
static int efx_probe_eventq(struct efx_channel *channel ) 
{ 
  struct efx_nic *efx ;
  unsigned long entries ;
  struct _ddebug descriptor ;
  long tmp ;
  unsigned long _max1 ;
    klee_make_symbolic(&_max1, sizeof(long), "_max1");
  unsigned long _max2 ;
    klee_make_symbolic(&_max2, sizeof(long), "_max2");
  int tmp___0 ;

  {
  efx = channel->efx;
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_probe_eventq";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "chan %d create event queue\n";
    descriptor.lineno = 334U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "chan %d create event queue\n", channel->channel);
    } else {

    }
  } else {

  }
  entries = __roundup_pow_of_two((unsigned long )((efx->rxq_entries + efx->txq_entries) + 128U));
  _max1 = entries;
  _max2 = 512UL;
  channel->eventq_mask = (unsigned int )(_max1 > _max2 ? _max1 : _max2) - 1U;
  tmp___0 = efx_nic_probe_eventq(channel);
  return (tmp___0);
}
}
static int efx_init_eventq(struct efx_channel *channel ) 
{ 
  struct efx_nic *efx ;
  int rc ;
  struct _ddebug descriptor ;
  long tmp ;

  {
  efx = channel->efx;
  if ((int )efx->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_init_eventq";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "chan %d init event queue\n";
    descriptor.lineno = 354U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "chan %d init event queue\n", channel->channel);
    } else {

    }
  } else {

  }
  rc = efx_nic_init_eventq(channel);
  if (rc == 0) {
    (*((efx->type)->push_irq_moderation))(channel);
    channel->eventq_read_ptr = 0U;
    channel->eventq_init = 1;
  } else {

  }
  return (rc);
}
}
void efx_start_eventq(struct efx_channel *channel ) 
{ 
  struct _ddebug descriptor ;
  long tmp ;

  {
  if (((channel->efx)->msg_enable & 32U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_start_eventq";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "chan %d start event queue\n";
    descriptor.lineno = 369U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)(channel->efx)->net_dev,
                           "chan %d start event queue\n", channel->channel);
    } else {

    }
  } else {

  }
  channel->enabled = 1;
  __asm__  volatile   ("": : : "memory");
  efx_channel_enable(channel);
  napi_enable(& channel->napi_str);
  efx_nic_eventq_read_ack(channel);
  return;
}
}
void efx_stop_eventq(struct efx_channel *channel ) 
{ 
  bool tmp ;
  int tmp___0 ;

  {
  if (! channel->enabled) {
    return;
  } else {

  }
  napi_disable(& channel->napi_str);
  goto ldv_56690;
  ldv_56689: 
  usleep_range(1000UL, 20000UL);
  ldv_56690: 
  tmp = efx_channel_disable(channel);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    goto ldv_56689;
  } else {

  }
  channel->enabled = 0;
  return;
}
}
static void efx_fini_eventq(struct efx_channel *channel ) 
{ 
  struct _ddebug descriptor ;
  long tmp ;

  {
  if (! channel->eventq_init) {
    return;
  } else {

  }
  if ((int )(channel->efx)->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_fini_eventq";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "chan %d fini event queue\n";
    descriptor.lineno = 398U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)(channel->efx)->net_dev,
                           "chan %d fini event queue\n", channel->channel);
    } else {

    }
  } else {

  }
  efx_nic_fini_eventq(channel);
  channel->eventq_init = 0;
  return;
}
}
static void efx_remove_eventq(struct efx_channel *channel ) 
{ 
  struct _ddebug descriptor ;
  long tmp ;

  {
  if ((int )(channel->efx)->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_remove_eventq";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "chan %d remove event queue\n";
    descriptor.lineno = 407U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)(channel->efx)->net_dev,
                           "chan %d remove event queue\n", channel->channel);
    } else {

    }
  } else {

  }
  efx_nic_remove_eventq(channel);
  return;
}
}
static struct efx_channel *efx_alloc_channel(struct efx_nic *efx , int i , struct efx_channel *old_channel ) 
{ 
  struct efx_channel *channel ;
  struct efx_rx_queue *rx_queue ;
  struct efx_tx_queue *tx_queue ;
  int j ;
    klee_make_symbolic(&j, sizeof(int), "j");
  void *tmp ;

  {
  tmp = kzalloc(2176UL, 208U);
  channel = (struct efx_channel *)tmp;
  if ((unsigned long )channel == (unsigned long )((struct efx_channel *)0)) {
    return ((struct efx_channel *)0);
  } else {

  }
  channel->efx = efx;
  channel->channel = i;
  channel->type = & efx_default_channel_type;
  j = 0;
  goto ldv_56712;
  ldv_56711: 
  tx_queue = (struct efx_tx_queue *)(& channel->tx_queue) + (unsigned long )j;
  tx_queue->efx = efx;
  tx_queue->queue = (unsigned int )(i * 4 + j);
  tx_queue->channel = channel;
  j = j + 1;
  ldv_56712: ;
  if (j <= 3) {
    goto ldv_56711;
  } else {

  }
  rx_queue = & channel->rx_queue;
  rx_queue->efx = efx;
  reg_timer_10(& rx_queue->slow_fill, & efx_rx_slow_fill, (unsigned long )rx_queue);
  return (channel);
}
}
static struct efx_channel *efx_copy_channel(struct efx_channel  const  *old_channel ) 
{ 
  struct efx_channel *channel ;
  struct efx_rx_queue *rx_queue ;
  struct efx_tx_queue *tx_queue ;
  int j ;
  void *tmp ;

  {
  tmp = kmalloc(2176UL, 208U);
  channel = (struct efx_channel *)tmp;
  if ((unsigned long )channel == (unsigned long )((struct efx_channel *)0)) {
    return ((struct efx_channel *)0);
  } else {

  }
  *channel = *old_channel;
  channel->napi_dev = (struct net_device *)0;
  memset((void *)(& channel->eventq), 0, 32UL);
  j = 0;
  goto ldv_56722;
  ldv_56721: 
  tx_queue = (struct efx_tx_queue *)(& channel->tx_queue) + (unsigned long )j;
  if ((unsigned long )tx_queue->channel != (unsigned long )((struct efx_channel *)0)) {
    tx_queue->channel = channel;
  } else {

  }
  tx_queue->buffer = (struct efx_tx_buffer *)0;
  memset((void *)(& tx_queue->txd), 0, 32UL);
  j = j + 1;
  ldv_56722: ;
  if (j <= 3) {
    goto ldv_56721;
  } else {

  }
  rx_queue = & channel->rx_queue;
  rx_queue->buffer = (struct efx_rx_buffer *)0;
  memset((void *)(& rx_queue->rxd), 0, 32UL);
  reg_timer_10(& rx_queue->slow_fill, & efx_rx_slow_fill, (unsigned long )rx_queue);
  return (channel);
}
}
static int efx_probe_channel(struct efx_channel *channel ) 
{ 
  struct efx_tx_queue *tx_queue ;
  struct efx_rx_queue *rx_queue ;
  int rc ;
  struct _ddebug descriptor ;
  long tmp ;
  bool tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  bool tmp___3 ;
  int tmp___4 ;

  {
  if (((channel->efx)->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_probe_channel";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "creating channel %d\n";
    descriptor.lineno = 494U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)(channel->efx)->net_dev,
                           "creating channel %d\n", channel->channel);
    } else {

    }
  } else {

  }
  rc = (*((channel->type)->pre_probe))(channel);
  if (rc != 0) {
    goto fail;
  } else {

  }
  rc = efx_probe_eventq(channel);
  if (rc != 0) {
    goto fail;
  } else {

  }
  tmp___1 = efx_channel_has_tx_queues(channel);
  if (tmp___1) {
    tmp___2 = 0;
  } else {
    tmp___2 = 1;
  }
  if (tmp___2) {

  } else {
    tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
    goto ldv_56734;
    ldv_56733: 
    rc = efx_probe_tx_queue(tx_queue);
    if (rc != 0) {
      goto fail;
    } else {

    }
    tx_queue = tx_queue + 1;
    ldv_56734: ;
    if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
      tmp___0 = efx_tx_queue_used(tx_queue);
      if ((int )tmp___0) {
        goto ldv_56733;
      } else {
        goto ldv_56735;
      }
    } else {

    }
    ldv_56735: ;
  }
  tmp___3 = efx_channel_has_rx_queue(channel);
  if (tmp___3) {
    tmp___4 = 0;
  } else {
    tmp___4 = 1;
  }
  if (tmp___4) {

  } else {
    rx_queue = & channel->rx_queue;
    goto ldv_56737;
    ldv_56736: 
    rc = efx_probe_rx_queue(rx_queue);
    if (rc != 0) {
      goto fail;
    } else {

    }
    rx_queue = (struct efx_rx_queue *)0;
    ldv_56737: ;
    if ((unsigned long )rx_queue != (unsigned long )((struct efx_rx_queue *)0)) {
      goto ldv_56736;
    } else {

    }

  }
  return (0);
  fail: 
  efx_remove_channel(channel);
  return (rc);
}
}
static void efx_get_channel_name(struct efx_channel *channel , char *buf , size_t len ) 
{ 
  struct efx_nic *efx ;
  char const   *type ;
  int number ;

  {
  efx = channel->efx;
  number = channel->channel;
  if (efx->tx_channel_offset == 0U) {
    type = "";
  } else
  if ((unsigned int )channel->channel < efx->tx_channel_offset) {
    type = "-rx";
  } else {
    type = "-tx";
    number = (int )((unsigned int )number - efx->tx_channel_offset);
  }
  snprintf(buf, len, "%s%s-%d", (char *)(& efx->name), type, number);
  return;
}
}
static void efx_set_channel_names(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;

  {
  channel = efx->channel[0];
  goto ldv_56752;
  ldv_56751: 
  (*((channel->type)->get_name))(channel, (char *)(& efx->msi_context[channel->channel].name),
                                 22UL);
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56752: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56751;
  } else {

  }

  return;
}
}
static int efx_probe_channels(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;
  int rc ;

  {
  efx->next_buffer_table = 0U;
  channel = efx->channel[efx->n_channels - 1U];
  goto ldv_56761;
  ldv_56760: 
  rc = efx_probe_channel(channel);
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to create channel %d\n",
                 channel->channel);
    } else {

    }
    goto fail;
  } else {

  }
  channel = channel->channel != 0 ? efx->channel[channel->channel + -1] : (struct efx_channel *)0;
  ldv_56761: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56760;
  } else {

  }
  efx_set_channel_names(efx);
  return (0);
  fail: 
  efx_remove_channels(efx);
  return (rc);
}
}
static void efx_start_datapath(struct efx_nic *efx ) 
{ 
  bool old_rx_scatter ;
  struct efx_tx_queue *tx_queue ;
  struct efx_rx_queue *rx_queue ;
  struct efx_channel *channel ;
  size_t rx_buf_len ;
  int tmp ;
  struct _ddebug descriptor ;
  long tmp___0 ;
  struct _ddebug descriptor___0 ;
  long tmp___1 ;
  unsigned int tmp___2 ;
  bool tmp___3 ;
  bool tmp___4 ;
  int tmp___5 ;
    klee_make_symbolic(&tmp___5, sizeof(int), "tmp___5");
  bool tmp___6 ;
  int tmp___7 ;
    klee_make_symbolic(&tmp___7, sizeof(int), "tmp___7");
  int __ret_warn_on ;
  long tmp___8 ;
    klee_make_symbolic(&tmp___8, sizeof(long), "tmp___8");
  bool tmp___9 ;

  {
  old_rx_scatter = efx->rx_scatter;
  efx->rx_dma_len = ((efx->rx_prefix_size + (((efx->net_dev)->mtu + 29U) & 4294967288U)) + (unsigned int )(efx->type)->rx_buffer_padding) + 16U;
  rx_buf_len = ((unsigned long )efx->rx_ip_align + (unsigned long )efx->rx_dma_len) + 64UL;
  if (rx_buf_len <= 4096UL) {
    efx->rx_scatter = (efx->type)->always_rx_scatter;
    efx->rx_buffer_order = 0U;
  } else
  if ((int )(efx->type)->can_rx_scatter) {
    efx->rx_scatter = 1;
    efx->rx_dma_len = 1792U;
    efx->rx_buffer_order = 0U;
  } else {
    efx->rx_scatter = 0;
    tmp = __get_order(rx_buf_len);
    efx->rx_buffer_order = (unsigned int )tmp;
  }
  efx_rx_config_page_split(efx);
  if (efx->rx_buffer_order != 0U) {
    if ((int )efx->msg_enable & 1) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_start_datapath";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
      descriptor.format = "RX buf len=%u; page order=%u batch=%u\n";
      descriptor.lineno = 626U;
      descriptor.flags = 0U;
      tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp___0 != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "RX buf len=%u; page order=%u batch=%u\n", efx->rx_dma_len,
                             efx->rx_buffer_order, efx->rx_pages_per_batch);
      } else {

      }
    } else {

    }
  } else
  if ((int )efx->msg_enable & 1) {
    descriptor___0.modname = "sfc";
    descriptor___0.function = "efx_start_datapath";
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor___0.format = "RX buf len=%u step=%u bpp=%u; page batch=%u\n";
    descriptor___0.lineno = 631U;
    descriptor___0.flags = 0U;
    tmp___1 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
    if (tmp___1 != 0L) {
      __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                           "RX buf len=%u step=%u bpp=%u; page batch=%u\n", efx->rx_dma_len,
                           efx->rx_page_buf_step, efx->rx_bufs_per_page, efx->rx_pages_per_batch);
    } else {

    }
  } else {

  }
  if ((int )efx->rx_scatter != (int )old_rx_scatter) {
    (*((efx->type)->filter_update_rx_scatter))(efx);
  } else {

  }
  tmp___2 = efx_tx_max_skb_descs(efx);
  efx->txq_stop_thresh = efx->txq_entries - tmp___2;
  efx->txq_wake_thresh = efx->txq_stop_thresh / 2U;
  channel = efx->channel[0];
  goto ldv_56783;
  ldv_56782: 
  tmp___4 = efx_channel_has_tx_queues(channel);
  if (tmp___4) {
    tmp___5 = 0;
  } else {
    tmp___5 = 1;
  }
  if (tmp___5) {

  } else {
    tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
    goto ldv_56775;
    ldv_56774: 
    efx_init_tx_queue(tx_queue);
    atomic_inc(& efx->active_queues);
    tx_queue = tx_queue + 1;
    ldv_56775: ;
    if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
      tmp___3 = efx_tx_queue_used(tx_queue);
      if ((int )tmp___3) {
        goto ldv_56774;
      } else {
        goto ldv_56776;
      }
    } else {

    }
    ldv_56776: ;
  }
  tmp___6 = efx_channel_has_rx_queue(channel);
  if (tmp___6) {
    tmp___7 = 0;
  } else {
    tmp___7 = 1;
  }
  if (tmp___7) {

  } else {
    rx_queue = & channel->rx_queue;
    goto ldv_56778;
    ldv_56777: 
    efx_init_rx_queue(rx_queue);
    atomic_inc(& efx->active_queues);
    efx_stop_eventq(channel);
    efx_fast_push_rx_descriptors(rx_queue, 0);
    efx_start_eventq(channel);
    rx_queue = (struct efx_rx_queue *)0;
    ldv_56778: ;
    if ((unsigned long )rx_queue != (unsigned long )((struct efx_rx_queue *)0)) {
      goto ldv_56777;
    } else {

    }

  }
  __ret_warn_on = channel->rx_pkt_n_frags != 0U;
  tmp___8 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___8 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c",
                       662);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56783: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56782;
  } else {

  }
  efx_ptp_start_datapath(efx);
  tmp___9 = netif_device_present(efx->net_dev);
  if ((int )tmp___9) {
    netif_tx_wake_all_queues(efx->net_dev);
  } else {

  }
  return;
}
}
static void efx_stop_datapath(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;
  struct efx_tx_queue *tx_queue ;
  struct efx_rx_queue *rx_queue ;
  int rc ;
  int tmp ;
  long tmp___0 ;
  long tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  bool tmp___4 ;
  struct _ddebug descriptor ;
  long tmp___5 ;
  int tmp___6 ;
    klee_make_symbolic(&tmp___6, sizeof(int), "tmp___6");
  bool tmp___7 ;
  int tmp___8 ;
  bool tmp___9 ;
  int tmp___10 ;
    klee_make_symbolic(&tmp___10, sizeof(int), "tmp___10");

  {
  if (((unsigned int )efx->state == 1U || (unsigned int )efx->state == 3U) || (unsigned int )efx->state == 2U) {
    tmp = rtnl_is_locked();
    tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
    if (tmp___0 != 0L) {
      printk("\vRTNL: assertion failed at %s (%d)\n", (char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c",
             678);
      dump_stack();
    } else {

    }
  } else {

  }
  tmp___1 = ldv__builtin_expect((long )efx->port_enabled, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c"),
                         "i" (679), "i" (12UL));
    ldv_56792: ;
    goto ldv_56792;
  } else {

  }
  efx_ptp_stop_datapath(efx);
  channel = efx->channel[0];
  goto ldv_56797;
  ldv_56796: 
  tmp___2 = efx_channel_has_rx_queue(channel);
  if (tmp___2) {
    tmp___3 = 0;
  } else {
    tmp___3 = 1;
  }
  if (tmp___3) {

  } else {
    rx_queue = & channel->rx_queue;
    goto ldv_56794;
    ldv_56793: 
    rx_queue->refill_enabled = 0;
    rx_queue = (struct efx_rx_queue *)0;
    ldv_56794: ;
    if ((unsigned long )rx_queue != (unsigned long )((struct efx_rx_queue *)0)) {
      goto ldv_56793;
    } else {

    }

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56797: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56796;
  } else {

  }
  channel = efx->channel[0];
  goto ldv_56800;
  ldv_56799: 
  tmp___4 = efx_channel_has_rx_queue(channel);
  if ((int )tmp___4) {
    efx_stop_eventq(channel);
    efx_start_eventq(channel);
  } else {

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56800: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56799;
  } else {

  }
  rc = (*((efx->type)->fini_dmaq))(efx);
  if (rc != 0) {
    tmp___6 = efx_nic_rev(efx);
    if (tmp___6 <= 2) {
      if ((int )efx->msg_enable & 1) {
        netdev_err((struct net_device  const  *)efx->net_dev, "Resetting to recover from flush failure\n");
      } else {

      }
      efx_schedule_reset(efx, 2);
    } else {
      goto _L;
    }
  } else
  _L: /* CIL Label */ 
  if (rc != 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to flush queues\n");
    } else {

    }
  } else
  if ((int )efx->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_stop_datapath";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "successfully flushed all queues\n";
    descriptor.lineno = 716U;
    descriptor.flags = 0U;
    tmp___5 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___5 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "successfully flushed all queues\n");
    } else {

    }
  } else {

  }
  channel = efx->channel[0];
  goto ldv_56811;
  ldv_56810: 
  tmp___7 = efx_channel_has_rx_queue(channel);
  if (tmp___7) {
    tmp___8 = 0;
  } else {
    tmp___8 = 1;
  }
  if (tmp___8) {

  } else {
    rx_queue = & channel->rx_queue;
    goto ldv_56805;
    ldv_56804: 
    efx_fini_rx_queue(rx_queue);
    rx_queue = (struct efx_rx_queue *)0;
    ldv_56805: ;
    if ((unsigned long )rx_queue != (unsigned long )((struct efx_rx_queue *)0)) {
      goto ldv_56804;
    } else {

    }

  }
  tmp___9 = efx_channel_has_tx_queues(channel);
  if (tmp___9) {
    tmp___10 = 0;
  } else {
    tmp___10 = 1;
  }
  if (tmp___10) {

  } else {
    tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
    goto ldv_56808;
    ldv_56807: 
    efx_fini_tx_queue(tx_queue);
    tx_queue = tx_queue + 1;
    ldv_56808: ;
    if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
      goto ldv_56807;
    } else {

    }

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56811: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56810;
  } else {

  }

  return;
}
}
static void efx_remove_channel(struct efx_channel *channel ) 
{ 
  struct efx_tx_queue *tx_queue ;
  struct efx_rx_queue *rx_queue ;
  struct _ddebug descriptor ;
  long tmp ;
  bool tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;

  {
  if ((int )(channel->efx)->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_remove_channel";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "destroy chan %d\n";
    descriptor.lineno = 733U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)(channel->efx)->net_dev,
                           "destroy chan %d\n", channel->channel);
    } else {

    }
  } else {

  }
  tmp___0 = efx_channel_has_rx_queue(channel);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {

  } else {
    rx_queue = & channel->rx_queue;
    goto ldv_56821;
    ldv_56820: 
    efx_remove_rx_queue(rx_queue);
    rx_queue = (struct efx_rx_queue *)0;
    ldv_56821: ;
    if ((unsigned long )rx_queue != (unsigned long )((struct efx_rx_queue *)0)) {
      goto ldv_56820;
    } else {

    }

  }
  tmp___2 = efx_channel_has_tx_queues(channel);
  if (tmp___2) {
    tmp___3 = 0;
  } else {
    tmp___3 = 1;
  }
  if (tmp___3) {

  } else {
    tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
    goto ldv_56824;
    ldv_56823: 
    efx_remove_tx_queue(tx_queue);
    tx_queue = tx_queue + 1;
    ldv_56824: ;
    if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
      goto ldv_56823;
    } else {

    }

  }
  efx_remove_eventq(channel);
  (*((channel->type)->post_remove))(channel);
  return;
}
}
static void efx_remove_channels(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;

  {
  channel = efx->channel[0];
  goto ldv_56831;
  ldv_56830: 
  efx_remove_channel(channel);
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56831: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56830;
  } else {

  }

  return;
}
}
int efx_realloc_channels(struct efx_nic *efx , u32 rxq_entries , u32 txq_entries ) 
{ 
  struct efx_channel *other_channel[32U] ;
  struct efx_channel *channel ;
  u32 old_rxq_entries ;
  u32 old_txq_entries ;
  unsigned int i ;
  unsigned int next_buffer_table ;
  int rc ;
  int rc2 ;
    klee_make_symbolic(&rc2, sizeof(int), "rc2");
  struct efx_rx_queue *rx_queue ;
  struct efx_tx_queue *tx_queue ;
  unsigned int _max1 ;
  unsigned int _max2 ;
  unsigned int _max1___0 ;
    klee_make_symbolic(&_max1___0, sizeof(int), "_max1___0");
  unsigned int _max2___0 ;
    klee_make_symbolic(&_max2___0, sizeof(int), "_max2___0");
  bool tmp ;
  int tmp___0 ;
  unsigned int _max1___1 ;
    klee_make_symbolic(&_max1___1, sizeof(int), "_max1___1");
  unsigned int _max2___1 ;
    klee_make_symbolic(&_max2___1, sizeof(int), "_max2___1");
  bool tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;

  {
  next_buffer_table = 0U;
  rc = efx_check_disabled(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  channel = efx->channel[0];
  goto ldv_56865;
  ldv_56864: ;
  if ((unsigned long )(channel->type)->copy != (unsigned long )((struct efx_channel *(*/* const  */)(struct efx_channel  const  * ))0)) {
    goto ldv_56848;
  } else {

  }
  _max1 = next_buffer_table;
  _max2 = channel->eventq.index + channel->eventq.entries;
  next_buffer_table = _max1 > _max2 ? _max1 : _max2;
  tmp = efx_channel_has_rx_queue(channel);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {

  } else {
    rx_queue = & channel->rx_queue;
    goto ldv_56856;
    ldv_56855: 
    _max1___0 = next_buffer_table;
    _max2___0 = rx_queue->rxd.index + rx_queue->rxd.entries;
    next_buffer_table = _max1___0 > _max2___0 ? _max1___0 : _max2___0;
    rx_queue = (struct efx_rx_queue *)0;
    ldv_56856: ;
    if ((unsigned long )rx_queue != (unsigned long )((struct efx_rx_queue *)0)) {
      goto ldv_56855;
    } else {

    }

  }
  tmp___2 = efx_channel_has_tx_queues(channel);
  if (tmp___2) {
    tmp___3 = 0;
  } else {
    tmp___3 = 1;
  }
  if (tmp___3) {

  } else {
    tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
    goto ldv_56862;
    ldv_56861: 
    _max1___1 = next_buffer_table;
    _max2___1 = tx_queue->txd.index + tx_queue->txd.entries;
    next_buffer_table = _max1___1 > _max2___1 ? _max1___1 : _max2___1;
    tx_queue = tx_queue + 1;
    ldv_56862: ;
    if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
      tmp___1 = efx_tx_queue_used(tx_queue);
      if ((int )tmp___1) {
        goto ldv_56861;
      } else {
        goto ldv_56863;
      }
    } else {

    }
    ldv_56863: ;
  }
  ldv_56848: 
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56865: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56864;
  } else {

  }
  efx_device_detach_sync(efx);
  efx_stop_all(efx);
  efx_soft_disable_interrupts(efx);
  memset((void *)(& other_channel), 0, 256UL);
  i = 0U;
  goto ldv_56869;
  ldv_56868: 
  channel = efx->channel[i];
  if ((unsigned long )(channel->type)->copy != (unsigned long )((struct efx_channel *(*/* const  */)(struct efx_channel  const  * ))0)) {
    channel = (*((channel->type)->copy))((struct efx_channel  const  *)channel);
  } else {

  }
  if ((unsigned long )channel == (unsigned long )((struct efx_channel *)0)) {
    rc = -12;
    goto out;
  } else {

  }
  other_channel[i] = channel;
  i = i + 1U;
  ldv_56869: ;
  if (efx->n_channels > i) {
    goto ldv_56868;
  } else {

  }
  old_rxq_entries = efx->rxq_entries;
  old_txq_entries = efx->txq_entries;
  efx->rxq_entries = rxq_entries;
  efx->txq_entries = txq_entries;
  i = 0U;
  goto ldv_56872;
  ldv_56871: 
  channel = efx->channel[i];
  efx->channel[i] = other_channel[i];
  other_channel[i] = channel;
  i = i + 1U;
  ldv_56872: ;
  if (efx->n_channels > i) {
    goto ldv_56871;
  } else {

  }
  efx->next_buffer_table = next_buffer_table;
  i = 0U;
  goto ldv_56877;
  ldv_56876: 
  channel = efx->channel[i];
  if ((unsigned long )(channel->type)->copy == (unsigned long )((struct efx_channel *(*/* const  */)(struct efx_channel  const  * ))0)) {
    goto ldv_56874;
  } else {

  }
  rc = efx_probe_channel(channel);
  if (rc != 0) {
    goto rollback;
  } else {

  }
  efx_init_napi_channel(efx->channel[i]);
  ldv_56874: 
  i = i + 1U;
  ldv_56877: ;
  if (efx->n_channels > i) {
    goto ldv_56876;
  } else {

  }

  out: 
  i = 0U;
  goto ldv_56880;
  ldv_56879: 
  channel = other_channel[i];
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0) && (unsigned long )(channel->type)->copy != (unsigned long )((struct efx_channel *(*/* const  */)(struct efx_channel  const  * ))0)) {
    efx_fini_napi_channel(channel);
    efx_remove_channel(channel);
    kfree((void const   *)channel);
  } else {

  }
  i = i + 1U;
  ldv_56880: ;
  if (efx->n_channels > i) {
    goto ldv_56879;
  } else {

  }
  rc2 = efx_soft_enable_interrupts(efx);
  if (rc2 != 0) {
    rc = rc != 0 ? rc : rc2;
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "unable to restart interrupts on channel reallocation\n");
    } else {

    }
    efx_schedule_reset(efx, 7);
  } else {
    efx_start_all(efx);
    netif_device_attach(efx->net_dev);
  }
  return (rc);
  rollback: 
  efx->rxq_entries = old_rxq_entries;
  efx->txq_entries = old_txq_entries;
  i = 0U;
  goto ldv_56883;
  ldv_56882: 
  channel = efx->channel[i];
  efx->channel[i] = other_channel[i];
  other_channel[i] = channel;
  i = i + 1U;
  ldv_56883: ;
  if (efx->n_channels > i) {
    goto ldv_56882;
  } else {

  }

  goto out;
}
}
void efx_schedule_slow_fill(struct efx_rx_queue *rx_queue ) 
{ 
  unsigned long tmp ;

  {
  tmp = msecs_to_jiffies(100U);
  ldv_mod_timer_17(& rx_queue->slow_fill, tmp + (unsigned long )jiffies);
  return;
}
}
static struct efx_channel_type  const  efx_default_channel_type  =    {0, & efx_channel_dummy_op_int, & efx_channel_dummy_op_void, & efx_get_channel_name,
    & efx_copy_channel, 0, 0};
int efx_channel_dummy_op_int(struct efx_channel *channel ) 
{ 


  {
  return (0);
}
}
void efx_channel_dummy_op_void(struct efx_channel *channel ) 
{ 


  {
  return;
}
}
void efx_link_status_changed(struct efx_nic *efx ) 
{ 
  struct efx_link_state *link_state ;
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;

  {
  link_state = & efx->link_state;
  tmp = netif_running((struct net_device  const  *)efx->net_dev);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return;
  } else {

  }
  tmp___1 = netif_carrier_ok((struct net_device  const  *)efx->net_dev);
  if ((int )link_state->up != (int )tmp___1) {
    efx->n_link_state_changes = efx->n_link_state_changes + 1U;
    if ((int )link_state->up) {
      netif_carrier_on(efx->net_dev);
    } else {
      netif_carrier_off(efx->net_dev);
    }
  } else {

  }
  if ((int )link_state->up) {
    if ((efx->msg_enable & 4U) != 0U) {
      netdev_info((struct net_device  const  *)efx->net_dev, "link up at %uMbps %s-duplex (MTU %d)\n",
                  link_state->speed, (int )link_state->fd ? (char *)"full" : (char *)"half",
                  (efx->net_dev)->mtu);
    } else {

    }
  } else
  if ((efx->msg_enable & 4U) != 0U) {
    netdev_info((struct net_device  const  *)efx->net_dev, "link down\n");
  } else {

  }
  return;
}
}
void efx_link_set_advertising(struct efx_nic *efx , u32 advertising ) 
{ 


  {
  efx->link_advertising = advertising;
  if (advertising != 0U) {
    if ((advertising & 8192U) != 0U) {
      efx->wanted_fc = (u8 )((unsigned int )efx->wanted_fc | 3U);
    } else {
      efx->wanted_fc = (unsigned int )efx->wanted_fc & 252U;
    }
    if ((advertising & 16384U) != 0U) {
      efx->wanted_fc = (u8 )((unsigned int )efx->wanted_fc ^ 1U);
    } else {

    }
  } else {

  }
  return;
}
}
void efx_link_set_wanted_fc(struct efx_nic *efx , u8 wanted_fc ) 
{ 


  {
  efx->wanted_fc = wanted_fc;
  if (efx->link_advertising != 0U) {
    if (((int )wanted_fc & 2) != 0) {
      efx->link_advertising = efx->link_advertising | 24576U;
    } else {
      efx->link_advertising = efx->link_advertising & 4294942719U;
    }
    if ((int )wanted_fc & 1) {
      efx->link_advertising = efx->link_advertising ^ 16384U;
    } else {

    }
  } else {

  }
  return;
}
}
static void efx_fini_port(struct efx_nic *efx ) ;
void efx_mac_reconfigure(struct efx_nic *efx ) 
{ 


  {
  down_read(& efx->filter_sem);
  (*((efx->type)->reconfigure_mac))(efx);
  up_read(& efx->filter_sem);
  return;
}
}
int __efx_reconfigure_port(struct efx_nic *efx ) 
{ 
  enum efx_phy_mode phy_mode ;
  int rc ;
  int __ret_warn_on ;
  int tmp ;
  long tmp___0 ;

  {
  tmp = ldv_mutex_is_locked_18(& efx->mac_lock);
  __ret_warn_on = tmp == 0;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c",
                       975);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  phy_mode = efx->phy_mode;
  if ((66600958 >> (int )efx->loopback_mode) & 1) {
    efx->phy_mode = (enum efx_phy_mode )((unsigned int )efx->phy_mode | 1U);
  } else {
    efx->phy_mode = (enum efx_phy_mode )((unsigned int )efx->phy_mode & 4294967294U);
  }
  rc = (*((efx->type)->reconfigure_port))(efx);
  if (rc != 0) {
    efx->phy_mode = phy_mode;
  } else {

  }
  return (rc);
}
}
int efx_reconfigure_port(struct efx_nic *efx ) 
{ 
  int rc ;
  int tmp ;
  long tmp___0 ;

  {
  if (((unsigned int )efx->state == 1U || (unsigned int )efx->state == 3U) || (unsigned int )efx->state == 2U) {
    tmp = rtnl_is_locked();
    tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
    if (tmp___0 != 0L) {
      printk("\vRTNL: assertion failed at %s (%d)\n", (char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c",
             998);
      dump_stack();
    } else {

    }
  } else {

  }
  ldv_mutex_lock_19(& efx->mac_lock);
  rc = __efx_reconfigure_port(efx);
  ldv_mutex_unlock_20(& efx->mac_lock);
  return (rc);
}
}
static void efx_mac_work(struct work_struct *data ) 
{ 
  struct efx_nic *efx ;
  struct work_struct  const  *__mptr ;

  {
  __mptr = (struct work_struct  const  *)data;
  efx = (struct efx_nic *)__mptr + 0xfffffffffffff498UL;
  ldv_mutex_lock_21(& efx->mac_lock);
  if ((int )efx->port_enabled) {
    efx_mac_reconfigure(efx);
  } else {

  }
  ldv_mutex_unlock_22(& efx->mac_lock);
  return;
}
}
static int efx_probe_port(struct efx_nic *efx ) 
{ 
  int rc ;
  struct _ddebug descriptor ;
  long tmp ;

  {
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_probe_port";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "create port\n";
    descriptor.lineno = 1024U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "create port\n");
    } else {

    }
  } else {

  }
  if ((int )phy_flash_cfg) {
    efx->phy_mode = 8;
  } else {

  }
  rc = (*((efx->type)->probe_port))(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  ether_addr_copy((efx->net_dev)->dev_addr, (u8 const   *)(& (efx->net_dev)->perm_addr));
  return (0);
}
}
static int efx_init_port(struct efx_nic *efx ) 
{ 
  int rc ;
  struct _ddebug descriptor ;
  long tmp ;

  {
  if ((int )efx->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_init_port";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "init port\n";
    descriptor.lineno = 1044U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "init port\n");
    } else {

    }
  } else {

  }
  ldv_mutex_lock_23(& efx->mac_lock);
  rc = (*((efx->phy_op)->init))(efx);
  if (rc != 0) {
    goto fail1;
  } else {

  }
  efx->port_initialized = 1;
  efx_mac_reconfigure(efx);
  rc = (*((efx->phy_op)->reconfigure))(efx);
  if (rc != 0 && rc != -1) {
    goto fail2;
  } else {

  }
  ldv_mutex_unlock_24(& efx->mac_lock);
  return (0);
  fail2: 
  (*((efx->phy_op)->fini))(efx);
  fail1: 
  ldv_mutex_unlock_25(& efx->mac_lock);
  return (rc);
}
}
static void efx_start_port(struct efx_nic *efx ) 
{ 
  struct _ddebug descriptor ;
  long tmp ;
  long tmp___0 ;

  {
  if ((efx->msg_enable & 32U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_start_port";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "start port\n";
    descriptor.lineno = 1075U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "start port\n");
    } else {

    }
  } else {

  }
  tmp___0 = ldv__builtin_expect((long )efx->port_enabled, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c"),
                         "i" (1076), "i" (12UL));
    ldv_56948: ;
    goto ldv_56948;
  } else {

  }
  ldv_mutex_lock_26(& efx->mac_lock);
  efx->port_enabled = 1;
  efx_mac_reconfigure(efx);
  ldv_mutex_unlock_27(& efx->mac_lock);
  return;
}
}
static void efx_stop_port(struct efx_nic *efx ) 
{ 
  struct _ddebug descriptor ;
  long tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  if ((efx->msg_enable & 16U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_stop_port";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "stop port\n";
    descriptor.lineno = 1094U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "stop port\n");
    } else {

    }
  } else {

  }
  if (((unsigned int )efx->state == 1U || (unsigned int )efx->state == 3U) || (unsigned int )efx->state == 2U) {
    tmp___0 = rtnl_is_locked();
    tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
    if (tmp___1 != 0L) {
      printk("\vRTNL: assertion failed at %s (%d)\n", (char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c",
             1096);
      dump_stack();
    } else {

    }
  } else {

  }
  ldv_mutex_lock_28(& efx->mac_lock);
  efx->port_enabled = 0;
  ldv_mutex_unlock_29(& efx->mac_lock);
  netif_addr_lock_bh(efx->net_dev);
  netif_addr_unlock_bh(efx->net_dev);
  ldv_cancel_delayed_work_sync_30(& efx->monitor_work);
  efx_selftest_async_cancel(efx);
  ldv_cancel_work_sync_31(& efx->mac_work);
  return;
}
}
static void efx_fini_port(struct efx_nic *efx ) 
{ 
  struct _ddebug descriptor ;
  long tmp ;

  {
  if ((int )efx->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_fini_port";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "shut down port\n";
    descriptor.lineno = 1113U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "shut down port\n");
    } else {

    }
  } else {

  }
  if (! efx->port_initialized) {
    return;
  } else {

  }
  (*((efx->phy_op)->fini))(efx);
  efx->port_initialized = 0;
  efx->link_state.up = 0;
  efx_link_status_changed(efx);
  return;
}
}
static void efx_remove_port(struct efx_nic *efx ) 
{ 
  struct _ddebug descriptor ;
  long tmp ;

  {
  if ((int )efx->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_remove_port";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "destroying port\n";
    descriptor.lineno = 1127U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "destroying port\n");
    } else {

    }
  } else {

  }
  (*((efx->type)->remove_port))(efx);
  return;
}
}
static struct list_head efx_primary_list  =    {& efx_primary_list, & efx_primary_list};
static struct list_head efx_unassociated_list  =    {& efx_unassociated_list, & efx_unassociated_list};
static bool efx_same_controller(struct efx_nic *left , struct efx_nic *right ) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  if (((unsigned long )left->type == (unsigned long )right->type && (unsigned long )left->vpd_sn != (unsigned long )((char *)0)) && (unsigned long )right->vpd_sn != (unsigned long )((char *)0)) {
    tmp = strcmp((char const   *)left->vpd_sn, (char const   *)right->vpd_sn);
    if (tmp == 0) {
      tmp___0 = 1;
    } else {
      tmp___0 = 0;
    }
  } else {
    tmp___0 = 0;
  }
  return ((bool )tmp___0);
}
}
static void efx_associate(struct efx_nic *efx ) 
{ 
  struct efx_nic *other ;
  struct efx_nic *next ;
  struct _ddebug descriptor ;
  long tmp ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct _ddebug descriptor___0 ;
  char const   *tmp___0 ;
  long tmp___1 ;
  bool tmp___2 ;
  struct list_head  const  *__mptr___1 ;
  struct list_head  const  *__mptr___2 ;
  struct _ddebug descriptor___1 ;
  char const   *tmp___3 ;
  long tmp___4 ;
  bool tmp___5 ;
  struct list_head  const  *__mptr___3 ;
  struct _ddebug descriptor___2 ;
  long tmp___6 ;

  {
  if ((unsigned long )efx->primary == (unsigned long )efx) {
    if ((efx->msg_enable & 2U) != 0U) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_associate";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
      descriptor.format = "adding to primary list\n";
      descriptor.lineno = 1155U;
      descriptor.flags = 0U;
      tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "adding to primary list\n");
      } else {

      }
    } else {

    }
    list_add_tail(& efx->node, & efx_primary_list);
    __mptr = (struct list_head  const  *)efx_unassociated_list.next;
    other = (struct efx_nic *)__mptr + 0xfffffffffffffff0UL;
    __mptr___0 = (struct list_head  const  *)other->node.next;
    next = (struct efx_nic *)__mptr___0 + 0xfffffffffffffff0UL;
    goto ldv_56985;
    ldv_56984: 
    tmp___2 = efx_same_controller(efx, other);
    if ((int )tmp___2) {
      list_del(& other->node);
      if ((other->msg_enable & 2U) != 0U) {
        descriptor___0.modname = "sfc";
        descriptor___0.function = "efx_associate";
        descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
        descriptor___0.format = "moving to secondary list of %s %s\n";
        descriptor___0.lineno = 1165U;
        descriptor___0.flags = 0U;
        tmp___1 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
        if (tmp___1 != 0L) {
          tmp___0 = pci_name((struct pci_dev  const  *)efx->pci_dev);
          __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)other->net_dev,
                               "moving to secondary list of %s %s\n", tmp___0, (char *)(& (efx->net_dev)->name));
        } else {

        }
      } else {

      }
      list_add_tail(& other->node, & efx->secondary_list);
      other->primary = efx;
    } else {

    }
    other = next;
    __mptr___1 = (struct list_head  const  *)next->node.next;
    next = (struct efx_nic *)__mptr___1 + 0xfffffffffffffff0UL;
    ldv_56985: ;
    if ((unsigned long )(& other->node) != (unsigned long )(& efx_unassociated_list)) {
      goto ldv_56984;
    } else {

    }

  } else {
    __mptr___2 = (struct list_head  const  *)efx_primary_list.next;
    other = (struct efx_nic *)__mptr___2 + 0xfffffffffffffff0UL;
    goto ldv_56993;
    ldv_56992: 
    tmp___5 = efx_same_controller(efx, other);
    if ((int )tmp___5) {
      if ((efx->msg_enable & 2U) != 0U) {
        descriptor___1.modname = "sfc";
        descriptor___1.function = "efx_associate";
        descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
        descriptor___1.format = "adding to secondary list of %s %s\n";
        descriptor___1.lineno = 1179U;
        descriptor___1.flags = 0U;
        tmp___4 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
        if (tmp___4 != 0L) {
          tmp___3 = pci_name((struct pci_dev  const  *)other->pci_dev);
          __dynamic_netdev_dbg(& descriptor___1, (struct net_device  const  *)efx->net_dev,
                               "adding to secondary list of %s %s\n", tmp___3, (char *)(& (other->net_dev)->name));
        } else {

        }
      } else {

      }
      list_add_tail(& efx->node, & other->secondary_list);
      efx->primary = other;
      return;
    } else {

    }
    __mptr___3 = (struct list_head  const  *)other->node.next;
    other = (struct efx_nic *)__mptr___3 + 0xfffffffffffffff0UL;
    ldv_56993: ;
    if ((unsigned long )(& other->node) != (unsigned long )(& efx_primary_list)) {
      goto ldv_56992;
    } else {

    }

    if ((efx->msg_enable & 2U) != 0U) {
      descriptor___2.modname = "sfc";
      descriptor___2.function = "efx_associate";
      descriptor___2.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
      descriptor___2.format = "adding to unassociated list\n";
      descriptor___2.lineno = 1188U;
      descriptor___2.flags = 0U;
      tmp___6 = ldv__builtin_expect((long )descriptor___2.flags & 1L, 0L);
      if (tmp___6 != 0L) {
        __dynamic_netdev_dbg(& descriptor___2, (struct net_device  const  *)efx->net_dev,
                             "adding to unassociated list\n");
      } else {

      }
    } else {

    }
    list_add_tail(& efx->node, & efx_unassociated_list);
  }
  return;
}
}
static void efx_dissociate(struct efx_nic *efx ) 
{ 
  struct efx_nic *other ;
  struct efx_nic *next ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct _ddebug descriptor ;
  long tmp ;
  struct list_head  const  *__mptr___1 ;

  {
  list_del(& efx->node);
  efx->primary = (struct efx_nic *)0;
  __mptr = (struct list_head  const  *)efx->secondary_list.next;
  other = (struct efx_nic *)__mptr + 0xfffffffffffffff0UL;
  __mptr___0 = (struct list_head  const  *)other->node.next;
  next = (struct efx_nic *)__mptr___0 + 0xfffffffffffffff0UL;
  goto ldv_57010;
  ldv_57009: 
  list_del(& other->node);
  if ((other->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_dissociate";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "moving to unassociated list\n";
    descriptor.lineno = 1203U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)other->net_dev,
                           "moving to unassociated list\n");
    } else {

    }
  } else {

  }
  list_add_tail(& other->node, & efx_unassociated_list);
  other->primary = (struct efx_nic *)0;
  other = next;
  __mptr___1 = (struct list_head  const  *)next->node.next;
  next = (struct efx_nic *)__mptr___1 + 0xfffffffffffffff0UL;
  ldv_57010: ;
  if ((unsigned long )(& other->node) != (unsigned long )(& efx->secondary_list)) {
    goto ldv_57009;
  } else {

  }

  return;
}
}
static int efx_init_io(struct efx_nic *efx ) 
{ 
  struct pci_dev *pci_dev ;
  dma_addr_t dma_mask ;
  unsigned int mem_map_size ;
    klee_make_symbolic(&mem_map_size, sizeof(int), "mem_map_size");
  unsigned int tmp ;
  int rc ;
  int bar ;
    klee_make_symbolic(&bar, sizeof(int), "bar");
  struct _ddebug descriptor ;
  long tmp___0 ;
  int tmp___1 ;
  struct _ddebug descriptor___0 ;
  long tmp___2 ;
  struct _ddebug descriptor___1 ;
  long tmp___3 ;

  {
  pci_dev = efx->pci_dev;
  dma_mask = (efx->type)->max_dma_mask;
  tmp = (*((efx->type)->mem_map_size))(efx);
  mem_map_size = tmp;
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_init_io";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "initialising I/O\n";
    descriptor.lineno = 1217U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "initialising I/O\n");
    } else {

    }
  } else {

  }
  bar = (int )(efx->type)->mem_bar;
  rc = pci_enable_device(pci_dev);
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to enable PCI device\n");
    } else {

    }
    goto fail1;
  } else {

  }
  pci_set_master(pci_dev);
  goto ldv_57025;
  ldv_57024: 
  tmp___1 = dma_supported(& pci_dev->dev, dma_mask);
  if (tmp___1 != 0) {
    rc = dma_set_mask_and_coherent(& pci_dev->dev, dma_mask);
    if (rc == 0) {
      goto ldv_57023;
    } else {

    }
  } else {

  }
  dma_mask = dma_mask >> 1;
  ldv_57025: ;
  if (dma_mask > 2147483647ULL) {
    goto ldv_57024;
  } else {

  }
  ldv_57023: ;
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "could not find a suitable DMA mask\n");
    } else {

    }
    goto fail2;
  } else {

  }
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor___0.modname = "sfc";
    descriptor___0.function = "efx_init_io";
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor___0.format = "using DMA mask %llx\n";
    descriptor___0.lineno = 1249U;
    descriptor___0.flags = 0U;
    tmp___2 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
    if (tmp___2 != 0L) {
      __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                           "using DMA mask %llx\n", dma_mask);
    } else {

    }
  } else {

  }
  efx->membase_phys = (efx->pci_dev)->resource[bar].start;
  rc = pci_request_region(pci_dev, bar, "sfc");
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "request for memory BAR failed\n");
    } else {

    }
    rc = -5;
    goto fail3;
  } else {

  }
  efx->membase = ioremap_nocache(efx->membase_phys, (unsigned long )mem_map_size);
  if ((unsigned long )efx->membase == (unsigned long )((void *)0)) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "could not map memory BAR at %llx+%x\n",
                 efx->membase_phys, mem_map_size);
    } else {

    }
    rc = -12;
    goto fail4;
  } else {

  }
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor___1.modname = "sfc";
    descriptor___1.function = "efx_init_io";
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor___1.format = "memory BAR at %llx+%x (virtual %p)\n";
    descriptor___1.lineno = 1270U;
    descriptor___1.flags = 0U;
    tmp___3 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
    if (tmp___3 != 0L) {
      __dynamic_netdev_dbg(& descriptor___1, (struct net_device  const  *)efx->net_dev,
                           "memory BAR at %llx+%x (virtual %p)\n", efx->membase_phys,
                           mem_map_size, efx->membase);
    } else {

    }
  } else {

  }
  return (0);
  fail4: 
  pci_release_region(efx->pci_dev, bar);
  fail3: 
  efx->membase_phys = 0ULL;
  fail2: 
  pci_disable_device(efx->pci_dev);
  fail1: ;
  return (rc);
}
}
static void efx_fini_io(struct efx_nic *efx ) 
{ 
  int bar ;
  struct _ddebug descriptor ;
  long tmp ;
  int tmp___0 ;

  {
  if ((int )efx->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_fini_io";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "shutting down I/O\n";
    descriptor.lineno = 1288U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "shutting down I/O\n");
    } else {

    }
  } else {

  }
  if ((unsigned long )efx->membase != (unsigned long )((void *)0)) {
    iounmap((void volatile   *)efx->membase);
    efx->membase = (void *)0;
  } else {

  }
  if (efx->membase_phys != 0ULL) {
    bar = (int )(efx->type)->mem_bar;
    pci_release_region(efx->pci_dev, bar);
    efx->membase_phys = 0ULL;
  } else {

  }
  tmp___0 = pci_vfs_assigned(efx->pci_dev);
  if (tmp___0 == 0) {
    pci_disable_device(efx->pci_dev);
  } else {

  }
  return;
}
}
void efx_set_default_rx_indir_table(struct efx_nic *efx ) 
{ 
  size_t i ;

  {
  i = 0UL;
  goto ldv_57044;
  ldv_57043: 
  efx->rx_indir_table[i] = ethtool_rxfh_indir_default((u32 )i, efx->rss_spread);
  i = i + 1UL;
  ldv_57044: ;
  if (i <= 127UL) {
    goto ldv_57043;
  } else {

  }

  return;
}
}
static unsigned int efx_wanted_parallelism(struct efx_nic *efx ) 
{ 
  cpumask_var_t thread_mask ;
  unsigned int count ;
  int cpu ;
  bool tmp ;
  int tmp___0 ;
  long tmp___1 ;
  void const   *__vpp_verify ;
  unsigned long __ptr ;
    klee_make_symbolic(&__ptr, sizeof(long), "__ptr");
  int tmp___2 ;
  unsigned int tmp___3 ;
    klee_make_symbolic(&tmp___3, sizeof(int), "tmp___3");
  unsigned int tmp___4 ;
  bool tmp___5 ;
  unsigned int tmp___6 ;
  unsigned int tmp___7 ;

  {
  if (rss_cpus != 0U) {
    count = rss_cpus;
  } else {
    tmp = zalloc_cpumask_var(& thread_mask, 208U);
    if (tmp) {
      tmp___0 = 0;
    } else {
      tmp___0 = 1;
    }
    tmp___1 = ldv__builtin_expect((long )tmp___0, 0L);
    if (tmp___1 != 0L) {
      if ((efx->msg_enable & 2U) != 0U) {
        netdev_warn((struct net_device  const  *)efx->net_dev, "RSS disabled due to allocation failure\n");
      } else {

      }
      return (1U);
    } else {

    }
    count = 0U;
    cpu = -1;
    goto ldv_57057;
    ldv_57056: 
    tmp___2 = cpumask_test_cpu(cpu, (struct cpumask  const  *)thread_mask);
    if (tmp___2 == 0) {
      count = count + 1U;
      __vpp_verify = (void const   *)0;
      __asm__  ("": "=r" (__ptr): "0" (& cpu_sibling_map));
      cpumask_or(thread_mask, (struct cpumask  const  *)thread_mask, (struct cpumask  const  *)*((cpumask_var_t **)(__per_cpu_offset[cpu] + __ptr)));
    } else {

    }
    ldv_57057: 
    tmp___3 = cpumask_next(cpu, cpu_online_mask);
    cpu = (int )tmp___3;
    if (cpu < nr_cpu_ids) {
      goto ldv_57056;
    } else {

    }
    free_cpumask_var(thread_mask);
  }
  if ((unsigned long )(efx->type)->sriov_wanted != (unsigned long )((bool (*/* const  */)(struct efx_nic * ))0)) {
    tmp___5 = (*((efx->type)->sriov_wanted))(efx);
    if ((int )tmp___5) {
      tmp___6 = efx_vf_size(efx);
      if (tmp___6 > 1U) {
        tmp___7 = efx_vf_size(efx);
        if (tmp___7 < count) {
          if ((efx->msg_enable & 2U) != 0U) {
            tmp___4 = efx_vf_size(efx);
            netdev_warn((struct net_device  const  *)efx->net_dev, "Reducing number of RSS channels from %u to %u for VF support. Increase vf-msix-limit to use more channels on the PF.\n",
                        count, tmp___4);
          } else {

          }
          count = efx_vf_size(efx);
        } else {

        }
      } else {

      }
    } else {

    }
  } else {

  }
  return (count);
}
}
static int efx_probe_interrupts(struct efx_nic *efx ) 
{ 
  unsigned int extra_channels ;
    klee_make_symbolic(&extra_channels, sizeof(int), "extra_channels");
  unsigned int i ;
  unsigned int j ;
  int rc ;
  struct msix_entry xentries[32U] ;
  unsigned int n_channels ;
  unsigned int _min1 ;
    klee_make_symbolic(&_min1, sizeof(int), "_min1");
  unsigned int _min2 ;
    klee_make_symbolic(&_min2, sizeof(int), "_min2");
  unsigned int _max1 ;
  unsigned int _max2 ;
  unsigned int _max1___0 ;
  unsigned int _max2___0 ;
  struct efx_channel *tmp ;
  struct efx_channel *tmp___0 ;
  struct efx_channel *tmp___1 ;
  unsigned int tmp___4 ;
  bool tmp___5 ;
  int tmp___6 ;

  {
  extra_channels = 0U;
  i = 0U;
  goto ldv_57067;
  ldv_57066: ;
  if ((unsigned long )efx->extra_channel_type[i] != (unsigned long )((struct efx_channel_type  const  *)0)) {
    extra_channels = extra_channels + 1U;
  } else {

  }
  i = i + 1U;
  ldv_57067: ;
  if (i <= 1U) {
    goto ldv_57066;
  } else {

  }

  if ((unsigned int )efx->interrupt_mode == 0U) {
    n_channels = efx_wanted_parallelism(efx);
    if ((int )separate_tx_channels) {
      n_channels = n_channels * 2U;
    } else {

    }
    n_channels = n_channels + extra_channels;
    _min1 = n_channels;
    _min2 = efx->max_channels;
    n_channels = _min1 < _min2 ? _min1 : _min2;
    i = 0U;
    goto ldv_57075;
    ldv_57074: 
    xentries[i].entry = (u16 )i;
    i = i + 1U;
    ldv_57075: ;
    if (i < n_channels) {
      goto ldv_57074;
    } else {

    }
    rc = pci_enable_msix_range(efx->pci_dev, (struct msix_entry *)(& xentries), 1,
                               (int )n_channels);
    if (rc < 0) {
      efx->interrupt_mode = 1;
      if ((int )efx->msg_enable & 1) {
        netdev_err((struct net_device  const  *)efx->net_dev, "could not enable MSI-X\n");
      } else {

      }
    } else
    if ((unsigned int )rc < n_channels) {
      if ((int )efx->msg_enable & 1) {
        netdev_err((struct net_device  const  *)efx->net_dev, "WARNING: Insufficient MSI-X vectors available (%d < %u).\n",
                   rc, n_channels);
      } else {

      }
      if ((int )efx->msg_enable & 1) {
        netdev_err((struct net_device  const  *)efx->net_dev, "WARNING: Performance may be reduced.\n");
      } else {

      }
      n_channels = (unsigned int )rc;
    } else {

    }
    if (rc > 0) {
      efx->n_channels = n_channels;
      if (n_channels > extra_channels) {
        n_channels = n_channels - extra_channels;
      } else {

      }
      if ((int )separate_tx_channels) {
        _max1 = n_channels / 2U;
        _max2 = 1U;
        efx->n_tx_channels = _max1 > _max2 ? _max1 : _max2;
        _max1___0 = n_channels - efx->n_tx_channels;
        _max2___0 = 1U;
        efx->n_rx_channels = _max1___0 > _max2___0 ? _max1___0 : _max2___0;
      } else {
        efx->n_tx_channels = n_channels;
        efx->n_rx_channels = n_channels;
      }
      i = 0U;
      goto ldv_57084;
      ldv_57083: 
      tmp = efx_get_channel(efx, i);
      tmp->irq = (int )xentries[i].vector;
      i = i + 1U;
      ldv_57084: ;
      if (efx->n_channels > i) {
        goto ldv_57083;
      } else {

      }

    } else {

    }
  } else {

  }
  if ((unsigned int )efx->interrupt_mode == 1U) {
    efx->n_channels = 1U;
    efx->n_rx_channels = 1U;
    efx->n_tx_channels = 1U;
    rc = pci_enable_msi_exact(efx->pci_dev, 1);
    if (rc == 0) {
      tmp___0 = efx_get_channel(efx, 0U);
      tmp___0->irq = (int )(efx->pci_dev)->irq;
    } else {
      if ((int )efx->msg_enable & 1) {
        netdev_err((struct net_device  const  *)efx->net_dev, "could not enable MSI\n");
      } else {

      }
      efx->interrupt_mode = 2;
    }
  } else {

  }
  if ((unsigned int )efx->interrupt_mode == 2U) {
    efx->n_channels = (unsigned int )((int )separate_tx_channels + 1);
    efx->n_rx_channels = 1U;
    efx->n_tx_channels = 1U;
    efx->legacy_irq = (int )(efx->pci_dev)->irq;
  } else {

  }
  j = efx->n_channels;
  i = 0U;
  goto ldv_57088;
  ldv_57087: ;
  if ((unsigned long )efx->extra_channel_type[i] == (unsigned long )((struct efx_channel_type  const  *)0)) {
    goto ldv_57086;
  } else {

  }
  if ((unsigned int )efx->interrupt_mode != 0U || efx->n_channels <= extra_channels) {
    (*((efx->extra_channel_type[i])->handle_no_channel))(efx);
  } else {
    j = j - 1U;
    tmp___1 = efx_get_channel(efx, j);
    tmp___1->type = efx->extra_channel_type[i];
  }
  ldv_57086: 
  i = i + 1U;
  ldv_57088: ;
  if (i <= 1U) {
    goto ldv_57087;
  } else {

  }

  if ((unsigned long )(efx->type)->sriov_wanted != (unsigned long )((bool (*/* const  */)(struct efx_nic * ))0)) {
    if (efx->n_rx_channels > 1U) {
      efx->rss_spread = efx->n_rx_channels;
    } else {
      tmp___5 = (*((efx->type)->sriov_wanted))(efx);
      if (tmp___5) {
        tmp___6 = 0;
      } else {
        tmp___6 = 1;
      }
      if (tmp___6) {
        efx->rss_spread = efx->n_rx_channels;
      } else {
        tmp___4 = efx_vf_size(efx);
        efx->rss_spread = tmp___4;
      }
    }
    return (0);
  } else {

  }
  efx->rss_spread = efx->n_rx_channels;
  return (0);
}
}
static int efx_soft_enable_interrupts(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;
  struct efx_channel *end_channel ;
  int rc ;
  long tmp ;

  {
  tmp = ldv__builtin_expect((unsigned int )efx->state == 2U, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c"),
                         "i" (1479), "i" (12UL));
    ldv_57096: ;
    goto ldv_57096;
  } else {

  }
  efx->irq_soft_enabled = 1;
  __asm__  volatile   ("": : : "memory");
  channel = efx->channel[0];
  goto ldv_57099;
  ldv_57098: ;
  if (! ((_Bool )(channel->type)->keep_eventq)) {
    rc = efx_init_eventq(channel);
    if (rc != 0) {
      goto fail;
    } else {

    }
  } else {

  }
  efx_start_eventq(channel);
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57099: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57098;
  } else {

  }
  efx_mcdi_mode_event(efx);
  return (0);
  fail: 
  end_channel = channel;
  channel = efx->channel[0];
  goto ldv_57103;
  ldv_57102: ;
  if ((unsigned long )channel == (unsigned long )end_channel) {
    goto ldv_57101;
  } else {

  }
  efx_stop_eventq(channel);
  if (! ((_Bool )(channel->type)->keep_eventq)) {
    efx_fini_eventq(channel);
  } else {

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57103: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57102;
  } else {

  }
  ldv_57101: ;
  return (rc);
}
}
static void efx_soft_disable_interrupts(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;

  {
  if ((unsigned int )efx->state == 2U) {
    return;
  } else {

  }
  efx_mcdi_mode_poll(efx);
  efx->irq_soft_enabled = 0;
  __asm__  volatile   ("": : : "memory");
  if (efx->legacy_irq != 0) {
    synchronize_irq((unsigned int )efx->legacy_irq);
  } else {

  }
  channel = efx->channel[0];
  goto ldv_57109;
  ldv_57108: ;
  if (channel->irq != 0) {
    synchronize_irq((unsigned int )channel->irq);
  } else {

  }
  efx_stop_eventq(channel);
  if (! ((_Bool )(channel->type)->keep_eventq)) {
    efx_fini_eventq(channel);
  } else {

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57109: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57108;
  } else {

  }
  efx_mcdi_flush_async(efx);
  return;
}
}
static int efx_enable_interrupts(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;
  struct efx_channel *end_channel ;
  int rc ;
  long tmp ;

  {
  tmp = ldv__builtin_expect((unsigned int )efx->state == 2U, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c"),
                         "i" (1542), "i" (12UL));
    ldv_57117: ;
    goto ldv_57117;
  } else {

  }
  if ((int )efx->eeh_disabled_legacy_irq) {
    enable_irq((unsigned int )efx->legacy_irq);
    efx->eeh_disabled_legacy_irq = 0;
  } else {

  }
  (*((efx->type)->irq_enable_master))(efx);
  channel = efx->channel[0];
  goto ldv_57120;
  ldv_57119: ;
  if ((int )(channel->type)->keep_eventq) {
    rc = efx_init_eventq(channel);
    if (rc != 0) {
      goto fail;
    } else {

    }
  } else {

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57120: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57119;
  } else {

  }
  rc = efx_soft_enable_interrupts(efx);
  if (rc != 0) {
    goto fail;
  } else {

  }
  return (0);
  fail: 
  end_channel = channel;
  channel = efx->channel[0];
  goto ldv_57124;
  ldv_57123: ;
  if ((unsigned long )channel == (unsigned long )end_channel) {
    goto ldv_57122;
  } else {

  }
  if ((int )(channel->type)->keep_eventq) {
    efx_fini_eventq(channel);
  } else {

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57124: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57123;
  } else {

  }
  ldv_57122: 
  (*((efx->type)->irq_disable_non_ev))(efx);
  return (rc);
}
}
static void efx_disable_interrupts(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;

  {
  efx_soft_disable_interrupts(efx);
  channel = efx->channel[0];
  goto ldv_57130;
  ldv_57129: ;
  if ((int )(channel->type)->keep_eventq) {
    efx_fini_eventq(channel);
  } else {

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57130: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57129;
  } else {

  }
  (*((efx->type)->irq_disable_non_ev))(efx);
  return;
}
}
static void efx_remove_interrupts(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;

  {
  channel = efx->channel[0];
  goto ldv_57137;
  ldv_57136: 
  channel->irq = 0;
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57137: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57136;
  } else {

  }
  pci_disable_msi(efx->pci_dev);
  pci_disable_msix(efx->pci_dev);
  efx->legacy_irq = 0;
  return;
}
}
static void efx_set_channels(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;
  struct efx_tx_queue *tx_queue ;
  bool tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  efx->tx_channel_offset = (int )separate_tx_channels ? efx->n_channels - efx->n_tx_channels : 0U;
  channel = efx->channel[0];
  goto ldv_57148;
  ldv_57147: ;
  if ((unsigned int )channel->channel < efx->n_rx_channels) {
    channel->rx_queue.core_index = channel->channel;
  } else {
    channel->rx_queue.core_index = -1;
  }
  tmp___0 = efx_channel_has_tx_queues(channel);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {

  } else {
    tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
    goto ldv_57145;
    ldv_57144: 
    tx_queue->queue = tx_queue->queue - efx->tx_channel_offset * 4U;
    tx_queue = tx_queue + 1;
    ldv_57145: ;
    if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
      tmp = efx_tx_queue_used(tx_queue);
      if ((int )tmp) {
        goto ldv_57144;
      } else {
        goto ldv_57146;
      }
    } else {

    }
    ldv_57146: ;
  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57148: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57147;
  } else {

  }

  return;
}
}
static int efx_probe_nic(struct efx_nic *efx ) 
{ 
  int rc ;
  struct _ddebug descriptor ;
  long tmp ;

  {
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_probe_nic";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "creating NIC\n";
    descriptor.lineno = 1635U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "creating NIC\n");
    } else {

    }
  } else {

  }
  rc = (*((efx->type)->probe))(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = efx_probe_interrupts(efx);
  if (rc != 0) {
    goto fail1;
  } else {

  }
  efx_set_channels(efx);
  rc = (*((efx->type)->dimension_resources))(efx);
  if (rc != 0) {
    goto fail2;
  } else {

  }
  if (efx->n_channels > 1U) {
    netdev_rss_key_fill((void *)(& efx->rx_hash_key), 40UL);
  } else {

  }
  efx_set_default_rx_indir_table(efx);
  netif_set_real_num_tx_queues(efx->net_dev, efx->n_tx_channels);
  netif_set_real_num_rx_queues(efx->net_dev, efx->n_rx_channels);
  efx_init_irq_moderation(efx, tx_irq_mod_usec, rx_irq_mod_usec, 1, 1);
  return (0);
  fail2: 
  efx_remove_interrupts(efx);
  fail1: 
  (*((efx->type)->remove))(efx);
  return (rc);
}
}
static void efx_remove_nic(struct efx_nic *efx ) 
{ 
  struct _ddebug descriptor ;
  long tmp ;

  {
  if ((int )efx->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_remove_nic";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "destroying NIC\n";
    descriptor.lineno = 1677U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "destroying NIC\n");
    } else {

    }
  } else {

  }
  efx_remove_interrupts(efx);
  (*((efx->type)->remove))(efx);
  return;
}
}
static int efx_probe_filters(struct efx_nic *efx ) 
{ 
  int rc ;
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  void *tmp ;

  {
  spinlock_check(& efx->filter_lock);
  __raw_spin_lock_init(& efx->filter_lock.__annonCompField17.rlock, "&(&efx->filter_lock)->rlock",
                       & __key);
  __init_rwsem(& efx->filter_sem, "&efx->filter_sem", & __key___0);
  down_write(& efx->filter_sem);
  rc = (*((efx->type)->filter_table_probe))(efx);
  if (rc != 0) {
    goto out_unlock;
  } else {

  }
  if (((unsigned long long )(efx->type)->offload_features & 4294967296ULL) != 0ULL) {
    tmp = kcalloc((size_t )(efx->type)->max_rx_ip_filters, 4UL, 208U);
    efx->rps_flow_id = (u32 *)tmp;
    if ((unsigned long )efx->rps_flow_id == (unsigned long )((u32 *)0U)) {
      (*((efx->type)->filter_table_remove))(efx);
      rc = -12;
      goto out_unlock;
    } else {

    }
  } else {

  }
  out_unlock: 
  up_write(& efx->filter_sem);
  return (rc);
}
}
static void efx_remove_filters(struct efx_nic *efx ) 
{ 


  {
  kfree((void const   *)efx->rps_flow_id);
  down_write(& efx->filter_sem);
  (*((efx->type)->filter_table_remove))(efx);
  up_write(& efx->filter_sem);
  return;
}
}
static void efx_restore_filters(struct efx_nic *efx ) 
{ 


  {
  down_read(& efx->filter_sem);
  (*((efx->type)->filter_table_restore))(efx);
  up_read(& efx->filter_sem);
  return;
}
}
static int efx_probe_all(struct efx_nic *efx ) 
{ 
  int rc ;
  int __ret_warn_on ;
  unsigned int tmp ;
  long tmp___0 ;
  long tmp___1 ;
  unsigned int tmp___2 ;

  {
  rc = efx_probe_nic(efx);
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to create NIC\n");
    } else {

    }
    goto fail1;
  } else {

  }
  rc = efx_probe_port(efx);
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to create port\n");
    } else {

    }
    goto fail2;
  } else {

  }
  tmp = efx_tx_max_skb_descs(efx);
  __ret_warn_on = tmp * 2U > 1024U;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c",
                       1751);
  } else {

  }
  tmp___1 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___1 != 0L) {
    rc = -22;
    goto fail3;
  } else {

  }
  tmp___2 = 1024U;
  efx->txq_entries = tmp___2;
  efx->rxq_entries = tmp___2;
  rc = (*((efx->type)->vswitching_probe))(efx);
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_warn((struct net_device  const  *)efx->net_dev, "failed to setup vswitching rc=%d; VFs may not function\n",
                  rc);
    } else {

    }
  } else {

  }
  rc = efx_probe_filters(efx);
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to create filter tables\n");
    } else {

    }
    goto fail4;
  } else {

  }
  rc = efx_probe_channels(efx);
  if (rc != 0) {
    goto fail5;
  } else {

  }
  return (0);
  fail5: 
  efx_remove_filters(efx);
  fail4: 
  (*((efx->type)->vswitching_remove))(efx);
  fail3: 
  efx_remove_port(efx);
  fail2: 
  efx_remove_nic(efx);
  fail1: ;
  return (rc);
}
}
static void efx_start_all(struct efx_nic *efx ) 
{ 
  int tmp ;
  long tmp___0 ;
  long tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  bool tmp___4 ;
  int tmp___5 ;

  {
  if (((unsigned int )efx->state == 1U || (unsigned int )efx->state == 3U) || (unsigned int )efx->state == 2U) {
    tmp = rtnl_is_locked();
    tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
    if (tmp___0 != 0L) {
      printk("\vRTNL: assertion failed at %s (%d)\n", (char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c",
             1801);
      dump_stack();
    } else {

    }
  } else {

  }
  tmp___1 = ldv__builtin_expect((unsigned int )efx->state == 2U, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c"),
                         "i" (1802), "i" (12UL));
    ldv_57190: ;
    goto ldv_57190;
  } else {

  }
  if ((int )efx->port_enabled) {
    return;
  } else {
    tmp___2 = netif_running((struct net_device  const  *)efx->net_dev);
    if (tmp___2) {
      tmp___3 = 0;
    } else {
      tmp___3 = 1;
    }
    if (tmp___3) {
      return;
    } else
    if (efx->reset_pending != 0UL) {
      return;
    } else {

    }
  }
  efx_start_port(efx);
  efx_start_datapath(efx);
  if ((unsigned long )(efx->type)->monitor != (unsigned long )((void (*/* const  */)(struct efx_nic * ))0)) {
    queue_delayed_work(efx->workqueue, & efx->monitor_work, (unsigned long )efx_monitor_interval);
  } else {

  }
  tmp___5 = efx_nic_rev(efx);
  if (tmp___5 > 2) {
    ldv_mutex_lock_32(& efx->mac_lock);
    tmp___4 = (*((efx->phy_op)->poll))(efx);
    if ((int )tmp___4) {
      efx_link_status_changed(efx);
    } else {

    }
    ldv_mutex_unlock_33(& efx->mac_lock);
  } else {

  }
  (*((efx->type)->start_stats))(efx);
  (*((efx->type)->pull_stats))(efx);
  spin_lock_bh(& efx->stats_lock);
  (*((efx->type)->update_stats))(efx, (u64 *)0ULL, (struct rtnl_link_stats64 *)0);
  spin_unlock_bh(& efx->stats_lock);
  return;
}
}
static void efx_stop_all(struct efx_nic *efx ) 
{ 
  int tmp ;
  long tmp___0 ;
  int __ret_warn_on ;
  bool tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  long tmp___4 ;

  {
  if (((unsigned int )efx->state == 1U || (unsigned int )efx->state == 3U) || (unsigned int )efx->state == 2U) {
    tmp = rtnl_is_locked();
    tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
    if (tmp___0 != 0L) {
      printk("\vRTNL: assertion failed at %s (%d)\n", (char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c",
             1842);
      dump_stack();
    } else {

    }
  } else {

  }
  if (! efx->port_enabled) {
    return;
  } else {

  }
  (*((efx->type)->pull_stats))(efx);
  spin_lock_bh(& efx->stats_lock);
  (*((efx->type)->update_stats))(efx, (u64 *)0ULL, (struct rtnl_link_stats64 *)0);
  spin_unlock_bh(& efx->stats_lock);
  (*((efx->type)->stop_stats))(efx);
  efx_stop_port(efx);
  tmp___1 = netif_running((struct net_device  const  *)efx->net_dev);
  if ((int )tmp___1) {
    tmp___2 = netif_device_present(efx->net_dev);
    if ((int )tmp___2) {
      tmp___3 = 1;
    } else {
      tmp___3 = 0;
    }
  } else {
    tmp___3 = 0;
  }
  __ret_warn_on = tmp___3;
  tmp___4 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___4 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c",
                       1863);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  netif_tx_disable(efx->net_dev);
  efx_stop_datapath(efx);
  return;
}
}
static void efx_remove_all(struct efx_nic *efx ) 
{ 


  {
  efx_remove_channels(efx);
  efx_remove_filters(efx);
  (*((efx->type)->vswitching_remove))(efx);
  efx_remove_port(efx);
  efx_remove_nic(efx);
  return;
}
}
static unsigned int irq_mod_ticks(unsigned int usecs , unsigned int quantum_ns ) 
{ 


  {
  if (usecs == 0U) {
    return (0U);
  } else {

  }
  if (usecs * 1000U < quantum_ns) {
    return (1U);
  } else {

  }
  return ((usecs * 1000U) / quantum_ns);
}
}
int efx_init_irq_moderation(struct efx_nic *efx , unsigned int tx_usecs , unsigned int rx_usecs ,
                            bool rx_adaptive , bool rx_may_override_tx ) 
{ 
  struct efx_channel *channel ;
  unsigned int irq_mod_max ;
    klee_make_symbolic(&irq_mod_max, sizeof(int), "irq_mod_max");
  unsigned int tx_ticks ;
    klee_make_symbolic(&tx_ticks, sizeof(int), "tx_ticks");
  unsigned int rx_ticks ;
    klee_make_symbolic(&rx_ticks, sizeof(int), "rx_ticks");
  int tmp ;
  long tmp___0 ;
  bool tmp___1 ;
  bool tmp___2 ;

  {
  irq_mod_max = ((unsigned int )(efx->type)->timer_period_max * efx->timer_quantum_ns + 999U) / 1000U;
  if (((unsigned int )efx->state == 1U || (unsigned int )efx->state == 3U) || (unsigned int )efx->state == 2U) {
    tmp = rtnl_is_locked();
    tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
    if (tmp___0 != 0L) {
      printk("\vRTNL: assertion failed at %s (%d)\n", (char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c",
             1907);
      dump_stack();
    } else {

    }
  } else {

  }
  if (tx_usecs > irq_mod_max || rx_usecs > irq_mod_max) {
    return (-22);
  } else {

  }
  tx_ticks = irq_mod_ticks(tx_usecs, efx->timer_quantum_ns);
  rx_ticks = irq_mod_ticks(rx_usecs, efx->timer_quantum_ns);
  if ((tx_ticks != rx_ticks && efx->tx_channel_offset == 0U) && ! rx_may_override_tx) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Channels are shared. RX and TX IRQ moderation must be equal\n");
    } else {

    }
    return (-22);
  } else {

  }
  efx->irq_rx_adaptive = rx_adaptive;
  efx->irq_rx_moderation = rx_ticks;
  channel = efx->channel[0];
  goto ldv_57215;
  ldv_57214: 
  tmp___2 = efx_channel_has_rx_queue(channel);
  if ((int )tmp___2) {
    channel->irq_moderation = rx_ticks;
  } else {
    tmp___1 = efx_channel_has_tx_queues(channel);
    if ((int )tmp___1) {
      channel->irq_moderation = tx_ticks;
    } else {

    }
  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57215: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57214;
  } else {

  }

  return (0);
}
}
void efx_get_irq_moderation(struct efx_nic *efx , unsigned int *tx_usecs , unsigned int *rx_usecs ,
                            bool *rx_adaptive ) 
{ 


  {
  *rx_adaptive = efx->irq_rx_adaptive;
  *rx_usecs = (efx->irq_rx_moderation * efx->timer_quantum_ns + 999U) / 1000U;
  if (efx->tx_channel_offset == 0U) {
    *tx_usecs = *rx_usecs;
  } else {
    *tx_usecs = ((efx->channel[efx->tx_channel_offset])->irq_moderation * efx->timer_quantum_ns + 999U) / 1000U;
  }
  return;
}
}
static void efx_monitor(struct work_struct *data ) 
{ 
  struct efx_nic *efx ;
  struct work_struct  const  *__mptr ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  long tmp ;
  int tmp___0 ;

  {
  __mptr = (struct work_struct  const  *)data;
  efx = (struct efx_nic *)__mptr + 0xfffffffffffff1c0UL;
  if (0) {
    if ((efx->msg_enable & 8U) != 0U) {
      __vpp_verify = (void const   *)0;
      switch (4UL) {
      case 1UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
      goto ldv_57234;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_57234;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_57234;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_57234;
      default: 
      __bad_percpu_size();
      }
      ldv_57234: 
      pscr_ret__ = pfo_ret__;
      goto ldv_57240;
      case 2UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57244;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57244;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57244;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57244;
      default: 
      __bad_percpu_size();
      }
      ldv_57244: 
      pscr_ret__ = pfo_ret_____0;
      goto ldv_57240;
      case 4UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57253;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57253;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57253;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57253;
      default: 
      __bad_percpu_size();
      }
      ldv_57253: 
      pscr_ret__ = pfo_ret_____1;
      goto ldv_57240;
      case 8UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57262;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57262;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57262;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57262;
      default: 
      __bad_percpu_size();
      }
      ldv_57262: 
      pscr_ret__ = pfo_ret_____2;
      goto ldv_57240;
      default: 
      __bad_size_call_parameter();
      goto ldv_57240;
      }
      ldv_57240: 
      netdev_printk("\017", (struct net_device  const  *)efx->net_dev, "hardware monitor executing on CPU %d\n",
                    pscr_ret__);
    } else {

    }
  } else {

  }
  tmp = ldv__builtin_expect((unsigned long )(efx->type)->monitor == (unsigned long )((void (*/* const  */)(struct efx_nic * ))0),
                         0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c"),
                         "i" (1974), "i" (12UL));
    ldv_57271: ;
    goto ldv_57271;
  } else {

  }
  tmp___0 = ldv_mutex_trylock_34(& efx->mac_lock);
  if (tmp___0 != 0) {
    if ((int )efx->port_enabled) {
      (*((efx->type)->monitor))(efx);
    } else {

    }
    ldv_mutex_unlock_35(& efx->mac_lock);
  } else {

  }
  queue_delayed_work(efx->workqueue, & efx->monitor_work, (unsigned long )efx_monitor_interval);
  return;
}
}
static int efx_ioctl(struct net_device *net_dev , struct ifreq *ifr , int cmd ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct mii_ioctl_data *data ;
  struct mii_ioctl_data *tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  tmp___0 = if_mii(ifr);
  data = tmp___0;
  if (cmd == 35248) {
    tmp___1 = efx_ptp_set_ts_config(efx, ifr);
    return (tmp___1);
  } else {

  }
  if (cmd == 35249) {
    tmp___2 = efx_ptp_get_ts_config(efx, ifr);
    return (tmp___2);
  } else {

  }
  if ((cmd == 35144 || cmd == 35145) && ((int )data->phy_id & 64512) == 1024) {
    data->phy_id = (__u16 )((unsigned int )data->phy_id ^ 33792U);
  } else {

  }
  tmp___3 = mdio_mii_ioctl((struct mdio_if_info  const  *)(& efx->mdio), data, cmd);
  return (tmp___3);
}
}
static void efx_init_napi_channel(struct efx_channel *channel ) 
{ 
  struct efx_nic *efx ;

  {
  efx = channel->efx;
  channel->napi_dev = efx->net_dev;
  netif_napi_add(channel->napi_dev, & channel->napi_str, & efx_poll, napi_weight);
  napi_hash_add(& channel->napi_str);
  efx_channel_init_lock(channel);
  return;
}
}
static void efx_init_napi(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;

  {
  channel = efx->channel[0];
  goto ldv_57288;
  ldv_57287: 
  efx_init_napi_channel(channel);
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57288: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57287;
  } else {

  }

  return;
}
}
static void efx_fini_napi_channel(struct efx_channel *channel ) 
{ 


  {
  if ((unsigned long )channel->napi_dev != (unsigned long )((struct net_device *)0)) {
    netif_napi_del(& channel->napi_str);
    napi_hash_del(& channel->napi_str);
  } else {

  }
  channel->napi_dev = (struct net_device *)0;
  return;
}
}
static void efx_fini_napi(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;

  {
  channel = efx->channel[0];
  goto ldv_57298;
  ldv_57297: 
  efx_fini_napi_channel(channel);
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57298: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57297;
  } else {

  }

  return;
}
}
static void efx_netpoll(struct net_device *net_dev ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct efx_channel *channel ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  channel = efx->channel[0];
  goto ldv_57306;
  ldv_57305: 
  efx_schedule_channel(channel);
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57306: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57305;
  } else {

  }

  return;
}
}
static int efx_busy_poll(struct napi_struct *napi ) 
{ 
  struct efx_channel *channel ;
  struct napi_struct  const  *__mptr ;
  struct efx_nic *efx ;
  int budget ;
    klee_make_symbolic(&budget, sizeof(int), "budget");
  int old_rx_packets ;
    klee_make_symbolic(&old_rx_packets, sizeof(int), "old_rx_packets");
  int rx_packets ;
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;

  {
  __mptr = (struct napi_struct  const  *)napi;
  channel = (struct efx_channel *)__mptr + 0xffffffffffffffd0UL;
  efx = channel->efx;
  budget = 4;
  tmp = netif_running((struct net_device  const  *)efx->net_dev);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (-1);
  } else {

  }
  tmp___1 = efx_channel_lock_poll(channel);
  if (tmp___1) {
    tmp___2 = 0;
  } else {
    tmp___2 = 1;
  }
  if (tmp___2) {
    return (-2);
  } else {

  }
  old_rx_packets = (int )channel->rx_queue.rx_packets;
  efx_process_channel(channel, budget);
  rx_packets = (int )((unsigned int )channel->rx_queue.rx_packets - (unsigned int )old_rx_packets);
  efx_channel_unlock_poll(channel);
  return (rx_packets);
}
}
int efx_net_open(struct net_device *net_dev ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int rc ;
  struct _ddebug descriptor ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  long tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((efx->msg_enable & 32U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_net_open";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "opening device on CPU %d\n";
    descriptor.lineno = 2125U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __vpp_verify = (void const   *)0;
      switch (4UL) {
      case 1UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
      goto ldv_57330;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_57330;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_57330;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_57330;
      default: 
      __bad_percpu_size();
      }
      ldv_57330: 
      pscr_ret__ = pfo_ret__;
      goto ldv_57336;
      case 2UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57340;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57340;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57340;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57340;
      default: 
      __bad_percpu_size();
      }
      ldv_57340: 
      pscr_ret__ = pfo_ret_____0;
      goto ldv_57336;
      case 4UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57349;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57349;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57349;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57349;
      default: 
      __bad_percpu_size();
      }
      ldv_57349: 
      pscr_ret__ = pfo_ret_____1;
      goto ldv_57336;
      case 8UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57358;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57358;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57358;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57358;
      default: 
      __bad_percpu_size();
      }
      ldv_57358: 
      pscr_ret__ = pfo_ret_____2;
      goto ldv_57336;
      default: 
      __bad_size_call_parameter();
      goto ldv_57336;
      }
      ldv_57336: 
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "opening device on CPU %d\n", pscr_ret__);
    } else {

    }
  } else {

  }
  rc = efx_check_disabled(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (((unsigned int )efx->phy_mode & 8U) != 0U) {
    return (-16);
  } else {

  }
  tmp___1 = efx_mcdi_poll_reboot(efx);
  if (tmp___1 != 0) {
    tmp___2 = efx_reset(efx, 2);
    if (tmp___2 != 0) {
      return (-5);
    } else {

    }
  } else {

  }
  efx_link_status_changed(efx);
  efx_start_all(efx);
  efx_selftest_async_start(efx);
  return (0);
}
}
int efx_net_stop(struct net_device *net_dev ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct _ddebug descriptor ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  long tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((efx->msg_enable & 16U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_net_stop";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "closing on CPU %d\n";
    descriptor.lineno = 2153U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __vpp_verify = (void const   *)0;
      switch (4UL) {
      case 1UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
      goto ldv_57377;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_57377;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_57377;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_57377;
      default: 
      __bad_percpu_size();
      }
      ldv_57377: 
      pscr_ret__ = pfo_ret__;
      goto ldv_57383;
      case 2UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57387;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57387;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57387;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57387;
      default: 
      __bad_percpu_size();
      }
      ldv_57387: 
      pscr_ret__ = pfo_ret_____0;
      goto ldv_57383;
      case 4UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57396;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57396;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57396;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57396;
      default: 
      __bad_percpu_size();
      }
      ldv_57396: 
      pscr_ret__ = pfo_ret_____1;
      goto ldv_57383;
      case 8UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57405;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57405;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57405;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57405;
      default: 
      __bad_percpu_size();
      }
      ldv_57405: 
      pscr_ret__ = pfo_ret_____2;
      goto ldv_57383;
      default: 
      __bad_size_call_parameter();
      goto ldv_57383;
      }
      ldv_57383: 
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "closing on CPU %d\n", pscr_ret__);
    } else {

    }
  } else {

  }
  efx_stop_all(efx);
  return (0);
}
}
static struct rtnl_link_stats64 *efx_net_stats(struct net_device *net_dev , struct rtnl_link_stats64 *stats ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  spin_lock_bh(& efx->stats_lock);
  (*((efx->type)->update_stats))(efx, (u64 *)0ULL, stats);
  spin_unlock_bh(& efx->stats_lock);
  return (stats);
}
}
static void efx_watchdog(struct net_device *net_dev ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((efx->msg_enable & 128U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "TX stuck with port_enabled=%d: resetting channels\n",
               (int )efx->port_enabled);
  } else {

  }
  efx_schedule_reset(efx, 9);
  return;
}
}
static int efx_change_mtu(struct net_device *net_dev , int new_mtu ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int rc ;
  struct _ddebug descriptor ;
  long tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  rc = efx_check_disabled(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (new_mtu > 9216) {
    return (-22);
  } else {

  }
  if ((int )efx->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_change_mtu";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "changing MTU to %d\n";
    descriptor.lineno = 2199U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "changing MTU to %d\n", new_mtu);
    } else {

    }
  } else {

  }
  efx_device_detach_sync(efx);
  efx_stop_all(efx);
  ldv_mutex_lock_36(& efx->mac_lock);
  net_dev->mtu = (unsigned int )new_mtu;
  efx_mac_reconfigure(efx);
  ldv_mutex_unlock_37(& efx->mac_lock);
  efx_start_all(efx);
  netif_device_attach(efx->net_dev);
  return (0);
}
}
static int efx_set_mac_address(struct net_device *net_dev , void *data ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct sockaddr *addr ;
  u8 *new_addr ;
  u8 old_addr[6U] ;
  int rc ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  addr = (struct sockaddr *)data;
  new_addr = (u8 *)(& addr->sa_data);
  tmp___0 = is_valid_ether_addr((u8 const   *)new_addr);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "invalid ethernet MAC address requested: %pM\n",
                 new_addr);
    } else {

    }
    return (-99);
  } else {

  }
  ether_addr_copy((u8 *)(& old_addr), (u8 const   *)net_dev->dev_addr);
  ether_addr_copy(net_dev->dev_addr, (u8 const   *)new_addr);
  if ((unsigned long )(efx->type)->set_mac_address != (unsigned long )((int (*/* const  */)(struct efx_nic * ))0)) {
    rc = (*((efx->type)->set_mac_address))(efx);
    if (rc != 0) {
      ether_addr_copy(net_dev->dev_addr, (u8 const   *)(& old_addr));
      return (rc);
    } else {

    }
  } else {

  }
  ldv_mutex_lock_38(& efx->mac_lock);
  efx_mac_reconfigure(efx);
  ldv_mutex_unlock_39(& efx->mac_lock);
  return (0);
}
}
static void efx_set_rx_mode(struct net_device *net_dev ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((int )efx->port_enabled) {
    queue_work(efx->workqueue, & efx->mac_work);
  } else {

  }
  return;
}
}
static int efx_set_features(struct net_device *net_dev , netdev_features_t data ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if (((net_dev->features & ~ data) & 4294967296ULL) != 0ULL) {
    tmp___0 = (*((efx->type)->filter_clear_rx))(efx, 2);
    return (tmp___0);
  } else {

  }
  return (0);
}
}
static struct net_device_ops  const  efx_netdev_ops  = 
     {0, 0, & efx_net_open, & efx_net_stop, & efx_hard_start_xmit, 0, 0, & efx_set_rx_mode,
    & efx_set_mac_address, & eth_validate_addr, & efx_ioctl, 0, & efx_change_mtu,
    0, & efx_watchdog, & efx_net_stats, 0, 0, 0, & efx_netpoll, 0, 0, & efx_busy_poll,
    & efx_sriov_set_vf_mac, & efx_sriov_set_vf_vlan, 0, & efx_sriov_set_vf_spoofchk,
    & efx_sriov_get_vf_config, & efx_sriov_set_vf_link_state, 0, 0, 0, 0, & efx_setup_tc,
    0, 0, 0, 0, 0, 0, 0, & efx_filter_rfs, 0, 0, 0, & efx_set_features, 0, 0, 0, 0,
    0, 0, 0, 0, 0, & efx_sriov_get_phys_port_id, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static void efx_update_name(struct efx_nic *efx ) 
{ 


  {
  strcpy((char *)(& efx->name), (char const   *)(& (efx->net_dev)->name));
  efx_mtd_rename(efx);
  efx_set_channel_names(efx);
  return;
}
}
static int efx_netdev_event(struct notifier_block *this , unsigned long event , void *ptr ) 
{ 
  struct net_device *net_dev ;
  struct net_device *tmp ;
  void *tmp___0 ;

  {
  tmp = netdev_notifier_info_to_dev((struct netdev_notifier_info  const  *)ptr);
  net_dev = tmp;
  if ((unsigned long )net_dev->netdev_ops == (unsigned long )(& efx_netdev_ops) && event == 10UL) {
    tmp___0 = netdev_priv((struct net_device  const  *)net_dev);
    efx_update_name((struct efx_nic *)tmp___0);
  } else {

  }
  return (0);
}
}
static struct notifier_block efx_netdev_notifier  =    {& efx_netdev_event, 0, 0};
static ssize_t show_phy_type(struct device *dev , struct device_attribute *attr ,
                             char *buf ) 
{ 
  struct efx_nic *efx ;
  struct device  const  *__mptr ;
  void *tmp ;
  int tmp___0 ;

  {
  __mptr = (struct device  const  *)dev;
  tmp = pci_get_drvdata((struct pci_dev *)__mptr + 0xffffffffffffff68UL);
  efx = (struct efx_nic *)tmp;
  tmp___0 = sprintf(buf, "%d\n", efx->phy_type);
  return ((ssize_t )tmp___0);
}
}
static struct device_attribute dev_attr_phy_type  =    {{"phy_type", 292U, (_Bool)0, 0, {{{(char)0}, {(char)0}, {(char)0}, {(char)0},
                                      {(char)0}, {(char)0}, {(char)0}, {(char)0}}}},
    & show_phy_type, (ssize_t (*)(struct device * , struct device_attribute * , char const   * ,
                                  size_t  ))0};
static ssize_t show_mcdi_log(struct device *dev , struct device_attribute *attr ,
                             char *buf ) 
{ 
  struct efx_nic *efx ;
  struct device  const  *__mptr ;
  void *tmp ;
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp___0 ;
  int tmp___1 ;

  {
  __mptr = (struct device  const  *)dev;
  tmp = pci_get_drvdata((struct pci_dev *)__mptr + 0xffffffffffffff68UL);
  efx = (struct efx_nic *)tmp;
  tmp___0 = efx_mcdi(efx);
  mcdi = tmp___0;
  tmp___1 = scnprintf(buf, 4096UL, "%d\n", (int )mcdi->logging_enabled);
  return ((ssize_t )tmp___1);
}
}
static ssize_t set_mcdi_log(struct device *dev , struct device_attribute *attr , char const   *buf ,
                            size_t count ) 
{ 
  struct efx_nic *efx ;
  struct device  const  *__mptr ;
  void *tmp ;
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp___0 ;
  bool enable ;

  {
  __mptr = (struct device  const  *)dev;
  tmp = pci_get_drvdata((struct pci_dev *)__mptr + 0xffffffffffffff68UL);
  efx = (struct efx_nic *)tmp;
  tmp___0 = efx_mcdi(efx);
  mcdi = tmp___0;
  enable = (bool )(count != 0UL && (int )((signed char )*buf) != 48);
  mcdi->logging_enabled = enable;
  return ((ssize_t )count);
}
}
static struct device_attribute dev_attr_mcdi_logging  =    {{"mcdi_logging", 420U, (_Bool)0, 0, {{{(char)0}, {(char)0}, {(char)0}, {(char)0},
                                          {(char)0}, {(char)0}, {(char)0}, {(char)0}}}},
    & show_mcdi_log, & set_mcdi_log};
static int efx_register_netdev(struct efx_nic *efx ) 
{ 
  struct net_device *net_dev ;
  struct efx_channel *channel ;
  int rc ;
  int tmp ;
  struct efx_tx_queue *tx_queue ;
  bool tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;

  {
  net_dev = efx->net_dev;
  net_dev->watchdog_timeo = 1250;
  net_dev->irq = (int )(efx->pci_dev)->irq;
  net_dev->netdev_ops = & efx_netdev_ops;
  tmp = efx_nic_rev(efx);
  if (tmp > 3) {
    net_dev->priv_flags = net_dev->priv_flags | 131072U;
  } else {

  }
  net_dev->ethtool_ops = & efx_ethtool_ops;
  net_dev->gso_max_segs = 100U;
  rtnl_lock();
  efx->state = 1;
  __asm__  volatile   ("mfence": : : "memory");
  if (efx->reset_pending != 0UL) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "aborting probe due to scheduled reset\n");
    } else {

    }
    rc = -5;
    goto fail_locked;
  } else {

  }
  rc = dev_alloc_name(net_dev, (char const   *)(& net_dev->name));
  if (rc < 0) {
    goto fail_locked;
  } else {

  }
  efx_update_name(efx);
  netif_carrier_off(net_dev);
  rc = register_netdevice(net_dev);
  if (rc != 0) {
    goto fail_locked;
  } else {

  }
  channel = efx->channel[0];
  goto ldv_57525;
  ldv_57524: 
  tmp___1 = efx_channel_has_tx_queues(channel);
  if (tmp___1) {
    tmp___2 = 0;
  } else {
    tmp___2 = 1;
  }
  if (tmp___2) {

  } else {
    tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
    goto ldv_57522;
    ldv_57521: 
    efx_init_tx_queue_core_txq(tx_queue);
    tx_queue = tx_queue + 1;
    ldv_57522: ;
    if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
      tmp___0 = efx_tx_queue_used(tx_queue);
      if ((int )tmp___0) {
        goto ldv_57521;
      } else {
        goto ldv_57523;
      }
    } else {

    }
    ldv_57523: ;
  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57525: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57524;
  } else {

  }
  efx_associate(efx);
  rtnl_unlock();
  rc = device_create_file(& (efx->pci_dev)->dev, (struct device_attribute  const  *)(& dev_attr_phy_type));
  if (rc != 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to init net dev attributes\n");
    } else {

    }
    goto fail_registered;
  } else {

  }
  rc = device_create_file(& (efx->pci_dev)->dev, (struct device_attribute  const  *)(& dev_attr_mcdi_logging));
  if (rc != 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to init net dev attributes\n");
    } else {

    }
    goto fail_attr_mcdi_logging;
  } else {

  }
  return (0);
  fail_attr_mcdi_logging: 
  device_remove_file(& (efx->pci_dev)->dev, (struct device_attribute  const  *)(& dev_attr_phy_type));
  fail_registered: 
  rtnl_lock();
  efx_dissociate(efx);
  unregister_netdevice(net_dev);
  fail_locked: 
  efx->state = 0;
  rtnl_unlock();
  if ((int )efx->msg_enable & 1) {
    netdev_err((struct net_device  const  *)efx->net_dev, "could not register net dev\n");
  } else {

  }
  return (rc);
}
}
static void efx_unregister_netdev(struct efx_nic *efx ) 
{ 
  void *tmp ;
  long tmp___0 ;
  char const   *tmp___1 ;
  int tmp___2 ;

  {
  if ((unsigned long )efx->net_dev == (unsigned long )((struct net_device *)0)) {
    return;
  } else {

  }
  tmp = netdev_priv((struct net_device  const  *)efx->net_dev);
  tmp___0 = ldv__builtin_expect((unsigned long )tmp != (unsigned long )((void *)efx),
                             0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c"),
                         "i" (2442), "i" (12UL));
    ldv_57532: ;
    goto ldv_57532;
  } else {

  }
  tmp___2 = efx_dev_registered(efx);
  if (tmp___2 != 0) {
    tmp___1 = pci_name((struct pci_dev  const  *)efx->pci_dev);
    strlcpy((char *)(& efx->name), tmp___1, 16UL);
    device_remove_file(& (efx->pci_dev)->dev, (struct device_attribute  const  *)(& dev_attr_mcdi_logging));
    device_remove_file(& (efx->pci_dev)->dev, (struct device_attribute  const  *)(& dev_attr_phy_type));
    unregister_netdev(efx->net_dev);
  } else {

  }
  return;
}
}
void efx_reset_down(struct efx_nic *efx , enum reset_type method ) 
{ 
  int tmp ;
  long tmp___0 ;

  {
  if (((unsigned int )efx->state == 1U || (unsigned int )efx->state == 3U) || (unsigned int )efx->state == 2U) {
    tmp = rtnl_is_locked();
    tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
    if (tmp___0 != 0L) {
      printk("\vRTNL: assertion failed at %s (%d)\n", (char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c",
             2464);
      dump_stack();
    } else {

    }
  } else {

  }
  if ((unsigned int )method == 15U) {
    (*((efx->type)->prepare_flr))(efx);
  } else {

  }
  efx_stop_all(efx);
  efx_disable_interrupts(efx);
  ldv_mutex_lock_40(& efx->mac_lock);
  if (((int )efx->port_initialized && (unsigned int )method != 0U) && (unsigned int )method != 5U) {
    (*((efx->phy_op)->fini))(efx);
  } else {

  }
  (*((efx->type)->fini))(efx);
  return;
}
}
int efx_reset_up(struct efx_nic *efx , enum reset_type method , bool ok ) 
{ 
  int rc ;
  int tmp ;
  long tmp___0 ;

  {
  if (((unsigned int )efx->state == 1U || (unsigned int )efx->state == 3U) || (unsigned int )efx->state == 2U) {
    tmp = rtnl_is_locked();
    tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
    if (tmp___0 != 0L) {
      printk("\vRTNL: assertion failed at %s (%d)\n", (char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c",
             2488);
      dump_stack();
    } else {

    }
  } else {

  }
  if ((unsigned int )method == 15U) {
    (*((efx->type)->finish_flr))(efx);
  } else {

  }
  rc = (*((efx->type)->init))(efx);
  if (rc != 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to initialise NIC\n");
    } else {

    }
    goto fail;
  } else {

  }
  if (! ok) {
    goto fail;
  } else {

  }
  if (((int )efx->port_initialized && (unsigned int )method != 0U) && (unsigned int )method != 5U) {
    rc = (*((efx->phy_op)->init))(efx);
    if (rc != 0) {
      goto fail;
    } else {

    }
    rc = (*((efx->phy_op)->reconfigure))(efx);
    if (rc != 0 && rc != -1) {
      if ((int )efx->msg_enable & 1) {
        netdev_err((struct net_device  const  *)efx->net_dev, "could not restore PHY settings\n");
      } else {

      }
    } else {

    }
  } else {

  }
  rc = efx_enable_interrupts(efx);
  if (rc != 0) {
    goto fail;
  } else {

  }
  rc = (*((efx->type)->vswitching_restore))(efx);
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_warn((struct net_device  const  *)efx->net_dev, "failed to restore vswitching rc=%d; VFs may not function\n",
                  rc);
    } else {

    }
  } else {

  }
  down_read(& efx->filter_sem);
  efx_restore_filters(efx);
  up_read(& efx->filter_sem);
  if ((unsigned long )(efx->type)->sriov_reset != (unsigned long )((void (*/* const  */)(struct efx_nic * ))0)) {
    (*((efx->type)->sriov_reset))(efx);
  } else {

  }
  ldv_mutex_unlock_41(& efx->mac_lock);
  efx_start_all(efx);
  return (0);
  fail: 
  efx->port_initialized = 0;
  ldv_mutex_unlock_42(& efx->mac_lock);
  return (rc);
}
}
int efx_reset(struct efx_nic *efx , enum reset_type method ) 
{ 
  int rc ;
  int rc2 ;
  bool disabled ;
  struct _ddebug descriptor ;
  long tmp ;

  {
  if ((int )efx->msg_enable & 1) {
    netdev_info((struct net_device  const  *)efx->net_dev, "resetting (%s)\n", (unsigned int )method < (unsigned int )efx_reset_type_max ? efx_reset_type_names[(unsigned int )method] : (char const   */* const  */)"(invalid)");
  } else {

  }
  efx_device_detach_sync(efx);
  efx_reset_down(efx, method);
  rc = (*((efx->type)->reset))(efx, method);
  if (rc != 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to reset hardware\n");
    } else {

    }
    goto out;
  } else {

  }
  if ((unsigned int )method <= 7U) {
    efx->reset_pending = efx->reset_pending & (unsigned long )(- (1 << (int )((unsigned int )method + 1U)));
  } else {
    __clear_bit((long )method, (unsigned long volatile   *)(& efx->reset_pending));
  }
  pci_set_master(efx->pci_dev);
  out: 
  disabled = (bool )((rc != 0 || (unsigned int )method == 7U) || (unsigned int )method == 4U);
  rc2 = efx_reset_up(efx, method, (int )((bool )(! ((int )disabled != 0))));
  if (rc2 != 0) {
    disabled = 1;
    if (rc == 0) {
      rc = rc2;
    } else {

    }
  } else {

  }
  if ((int )disabled) {
    dev_close(efx->net_dev);
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "has been disabled\n");
    } else {

    }
    efx->state = 2;
  } else {
    if ((int )efx->msg_enable & 1) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_reset";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
      descriptor.format = "reset complete\n";
      descriptor.lineno = 2599U;
      descriptor.flags = 0U;
      tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "reset complete\n");
      } else {

      }
    } else {

    }
    netif_device_attach(efx->net_dev);
  }
  return (rc);
}
}
int efx_try_recovery(struct efx_nic *efx ) 
{ 


  {
  return (0);
}
}
static void efx_wait_for_bist_end(struct efx_nic *efx ) 
{ 
  int i ;
  int tmp ;

  {
  i = 0;
  goto ldv_57563;
  ldv_57562: 
  tmp = efx_mcdi_poll_reboot(efx);
  if (tmp != 0) {
    goto out;
  } else {

  }
  msleep(100U);
  i = i + 1;
  ldv_57563: ;
  if (i <= 99) {
    goto ldv_57562;
  } else {

  }

  if ((int )efx->msg_enable & 1) {
    netdev_err((struct net_device  const  *)efx->net_dev, "Warning: No MC reboot after BIST mode\n");
  } else {

  }
  out: 
  efx->mc_bist_for_other_fn = 0;
  return;
}
}
static void efx_reset_work(struct work_struct *data ) 
{ 
  struct efx_nic *efx ;
  struct work_struct  const  *__mptr ;
  unsigned long pending ;
    klee_make_symbolic(&pending, sizeof(long), "pending");
  enum reset_type method ;
  unsigned long __var ;
  int tmp ;
  int tmp___0 ;

  {
  __mptr = (struct work_struct  const  *)data;
  efx = (struct efx_nic *)__mptr + 0xffffffffffffff90UL;
  __var = 0UL;
  pending = *((unsigned long volatile   *)(& efx->reset_pending));
  tmp = fls((int )pending);
  method = (enum reset_type )(tmp + -1);
  if ((unsigned int )method == 6U) {
    efx_wait_for_bist_end(efx);
  } else {

  }
  if ((unsigned int )method == 4U || (unsigned int )method == 1U) {
    tmp___0 = efx_try_recovery(efx);
    if (tmp___0 != 0) {
      return;
    } else {

    }
  } else {

  }
  if (pending == 0UL) {
    return;
  } else {

  }
  rtnl_lock();
  if ((unsigned int )efx->state == 1U) {
    efx_reset(efx, method);
  } else {

  }
  rtnl_unlock();
  return;
}
}
void efx_schedule_reset(struct efx_nic *efx , enum reset_type type ) 
{ 
  enum reset_type method ;
  struct _ddebug descriptor ;
  long tmp ;
  struct _ddebug descriptor___0 ;
  long tmp___0 ;
  struct _ddebug descriptor___1 ;
  long tmp___1 ;
  enum nic_state __var ;

  {
  if ((unsigned int )efx->state == 3U) {
    if ((int )efx->msg_enable & 1) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_schedule_reset";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
      descriptor.format = "recovering: skip scheduling %s reset\n";
      descriptor.lineno = 2689U;
      descriptor.flags = 0U;
      tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "recovering: skip scheduling %s reset\n", (unsigned int )type < (unsigned int )efx_reset_type_max ? efx_reset_type_names[(unsigned int )type] : (char const   */* const  */)"(invalid)");
      } else {

      }
    } else {

    }
    return;
  } else {

  }
  switch ((unsigned int )type) {
  case 0U: ;
  case 2U: ;
  case 1U: ;
  case 3U: ;
  case 7U: ;
  case 4U: ;
  case 5U: ;
  case 6U: ;
  case 15U: 
  method = type;
  if ((int )efx->msg_enable & 1) {
    descriptor___0.modname = "sfc";
    descriptor___0.function = "efx_schedule_reset";
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor___0.format = "scheduling %s reset\n";
    descriptor___0.lineno = 2705U;
    descriptor___0.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                           "scheduling %s reset\n", (unsigned int )method < (unsigned int )efx_reset_type_max ? efx_reset_type_names[(unsigned int )method] : (char const   */* const  */)"(invalid)");
    } else {

    }
  } else {

  }
  goto ldv_57592;
  default: 
  method = (*((efx->type)->map_reset_reason))(type);
  if ((int )efx->msg_enable & 1) {
    descriptor___1.modname = "sfc";
    descriptor___1.function = "efx_schedule_reset";
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor___1.format = "scheduling %s reset for %s\n";
    descriptor___1.lineno = 2711U;
    descriptor___1.flags = 0U;
    tmp___1 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
    if (tmp___1 != 0L) {
      __dynamic_netdev_dbg(& descriptor___1, (struct net_device  const  *)efx->net_dev,
                           "scheduling %s reset for %s\n", (unsigned int )method < (unsigned int )efx_reset_type_max ? efx_reset_type_names[(unsigned int )method] : (char const   */* const  */)"(invalid)",
                           (unsigned int )type < (unsigned int )efx_reset_type_max ? efx_reset_type_names[(unsigned int )type] : (char const   */* const  */)"(invalid)");
    } else {

    }
  } else {

  }
  goto ldv_57592;
  }
  ldv_57592: 
  set_bit((long )method, (unsigned long volatile   *)(& efx->reset_pending));
  __asm__  volatile   ("mfence": : : "memory");
  __var = 0;
  if ((unsigned int )*((enum nic_state  volatile  *)(& efx->state)) != 1U) {
    return;
  } else {

  }
  efx_mcdi_mode_poll(efx);
  queue_work(reset_workqueue, & efx->reset_work);
  return;
}
}
static struct pci_device_id  const  efx_pci_table[8U]  = 
  {      {6436U, 1795U, 4294967295U, 4294967295U, 0U, 0U, (unsigned long )(& falcon_a1_nic_type)}, 
        {6436U,
      1808U, 4294967295U, 4294967295U, 0U, 0U, (unsigned long )(& falcon_b0_nic_type)}, 
        {6436U,
      2051U, 4294967295U, 4294967295U, 0U, 0U, (unsigned long )(& siena_a0_nic_type)}, 
        {6436U,
      2067U, 4294967295U, 4294967295U, 0U, 0U, (unsigned long )(& siena_a0_nic_type)}, 
        {6436U,
      2307U, 4294967295U, 4294967295U, 0U, 0U, (unsigned long )(& efx_hunt_a0_nic_type)}, 
        {6436U,
      6403U, 4294967295U, 4294967295U, 0U, 0U, (unsigned long )(& efx_hunt_a0_vf_nic_type)}, 
        {6436U,
      2339U, 4294967295U, 4294967295U, 0U, 0U, (unsigned long )(& efx_hunt_a0_nic_type)}, 
        {0U,
      0U, 0U, 0U, 0U, 0U, 0UL}};
int efx_port_dummy_op_int(struct efx_nic *efx ) 
{ 


  {
  return (0);
}
}
void efx_port_dummy_op_void(struct efx_nic *efx ) 
{ 


  {
  return;
}
}
static bool efx_port_dummy_op_poll(struct efx_nic *efx ) 
{ 


  {
  return (0);
}
}
static struct efx_phy_operations  const  efx_dummy_phy_operations  = 
     {0, & efx_port_dummy_op_int, & efx_port_dummy_op_void, 0, & efx_port_dummy_op_int,
    & efx_port_dummy_op_poll, 0, 0, 0, 0, 0, 0, 0, 0};
static int efx_init_struct(struct efx_nic *efx , struct pci_dev *pci_dev , struct net_device *net_dev ) 
{ 
  int i ;
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  atomic_long_t __constr_expr_0 ;
  struct lock_class_key __key___1 ;
  atomic_long_t __constr_expr_1 ;
  struct lock_class_key __key___2 ;
  struct lock_class_key __key___3 ;
  atomic_long_t __constr_expr_2 ;
  struct lock_class_key __key___4 ;
  char const   *tmp ;
  struct lock_class_key __key___5 ;
  struct lock_class_key __key___6 ;
  struct lock_class_key __key___7 ;
  atomic_long_t __constr_expr_3 ;
  struct lock_class_key __key___8 ;
  unsigned int _max1 ;
  unsigned int _max2 ;
  char const   *tmp___0 ;
  struct lock_class_key __key___9 ;
  char const   *__lock_name ;
  struct workqueue_struct *tmp___1 ;

  {
  INIT_LIST_HEAD(& efx->node);
  INIT_LIST_HEAD(& efx->secondary_list);
  spinlock_check(& efx->biu_lock);
  __raw_spin_lock_init(& efx->biu_lock.__annonCompField17.rlock, "&(&efx->biu_lock)->rlock",
                       & __key);
  INIT_LIST_HEAD(& efx->mtd_list);
  __init_work(& efx->reset_work, 0);
  __constr_expr_0.counter = 137438953408L;
  efx->reset_work.data = __constr_expr_0;
  lockdep_init_map(& efx->reset_work.lockdep_map, "(&efx->reset_work)", & __key___0,
                   0);
  INIT_LIST_HEAD(& efx->reset_work.entry);
  efx->reset_work.func = & efx_reset_work;
  __init_work(& efx->monitor_work.work, 0);
  __constr_expr_1.counter = 137438953408L;
  efx->monitor_work.work.data = __constr_expr_1;
  lockdep_init_map(& efx->monitor_work.work.lockdep_map, "(&(&efx->monitor_work)->work)",
                   & __key___1, 0);
  INIT_LIST_HEAD(& efx->monitor_work.work.entry);
  efx->monitor_work.work.func = & efx_monitor;
  init_timer_key(& efx->monitor_work.timer, 2097152U, "(&(&efx->monitor_work)->timer)",
                 & __key___2);
  efx->monitor_work.timer.function = & delayed_work_timer_fn;
  efx->monitor_work.timer.data = (unsigned long )(& efx->monitor_work);
  __init_work(& efx->selftest_work.work, 0);
  __constr_expr_2.counter = 137438953408L;
  efx->selftest_work.work.data = __constr_expr_2;
  lockdep_init_map(& efx->selftest_work.work.lockdep_map, "(&(&efx->selftest_work)->work)",
                   & __key___3, 0);
  INIT_LIST_HEAD(& efx->selftest_work.work.entry);
  efx->selftest_work.work.func = & efx_selftest_async_work;
  init_timer_key(& efx->selftest_work.timer, 2097152U, "(&(&efx->selftest_work)->timer)",
                 & __key___4);
  efx->selftest_work.timer.function = & delayed_work_timer_fn;
  efx->selftest_work.timer.data = (unsigned long )(& efx->selftest_work);
  efx->pci_dev = pci_dev;
  efx->msg_enable = debug;
  efx->state = 0;
  tmp = pci_name((struct pci_dev  const  *)pci_dev);
  strlcpy((char *)(& efx->name), tmp, 16UL);
  efx->net_dev = net_dev;
  efx->rx_prefix_size = (efx->type)->rx_prefix_size;
  efx->rx_ip_align = 0U;
  efx->rx_packet_hash_offset = (int )((unsigned int )(efx->type)->rx_hash_offset - (unsigned int )(efx->type)->rx_prefix_size);
  efx->rx_packet_ts_offset = (int )((unsigned int )(efx->type)->rx_ts_offset - (unsigned int )(efx->type)->rx_prefix_size);
  spinlock_check(& efx->stats_lock);
  __raw_spin_lock_init(& efx->stats_lock.__annonCompField17.rlock, "&(&efx->stats_lock)->rlock",
                       & __key___5);
  __mutex_init(& efx->mac_lock, "&efx->mac_lock", & __key___6);
  efx->phy_op = & efx_dummy_phy_operations;
  efx->mdio.dev = net_dev;
  __init_work(& efx->mac_work, 0);
  __constr_expr_3.counter = 137438953408L;
  efx->mac_work.data = __constr_expr_3;
  lockdep_init_map(& efx->mac_work.lockdep_map, "(&efx->mac_work)", & __key___7, 0);
  INIT_LIST_HEAD(& efx->mac_work.entry);
  efx->mac_work.func = & efx_mac_work;
  __init_waitqueue_head(& efx->flush_wq, "&efx->flush_wq", & __key___8);
  i = 0;
  goto ldv_57630;
  ldv_57629: 
  efx->channel[i] = efx_alloc_channel(efx, i, (struct efx_channel *)0);
  if ((unsigned long )efx->channel[i] == (unsigned long )((struct efx_channel *)0)) {
    goto fail;
  } else {

  }
  efx->msi_context[i].efx = efx;
  efx->msi_context[i].index = (unsigned int )i;
  i = i + 1;
  ldv_57630: ;
  if ((unsigned int )i <= 31U) {
    goto ldv_57629;
  } else {

  }
  _max1 = (efx->type)->max_interrupt_mode;
  _max2 = interrupt_mode;
  efx->interrupt_mode = (enum efx_int_mode )(_max1 > (unsigned int )((unsigned int const   )_max2) ? _max1 : (unsigned int const   )_max2);
  tmp___0 = pci_name((struct pci_dev  const  *)pci_dev);
  snprintf((char *)(& efx->workqueue_name), 16UL, "sfc%s", tmp___0);
  __lock_name = "\"%s\"efx->workqueue_name";
  tmp___1 = __alloc_workqueue_key("%s", 131082U, 1, & __key___9, __lock_name, (char *)(& efx->workqueue_name));
  efx->workqueue = tmp___1;
  if ((unsigned long )efx->workqueue == (unsigned long )((struct workqueue_struct *)0)) {
    goto fail;
  } else {

  }
  return (0);
  fail: 
  efx_fini_struct(efx);
  return (-12);
}
}
static void efx_fini_struct(struct efx_nic *efx ) 
{ 
  int i ;

  {
  i = 0;
  goto ldv_57643;
  ldv_57642: 
  kfree((void const   *)efx->channel[i]);
  i = i + 1;
  ldv_57643: ;
  if ((unsigned int )i <= 31U) {
    goto ldv_57642;
  } else {

  }
  kfree((void const   *)efx->vpd_sn);
  if ((unsigned long )efx->workqueue != (unsigned long )((struct workqueue_struct *)0)) {
    ldv_destroy_workqueue_43(efx->workqueue);
    efx->workqueue = (struct workqueue_struct *)0;
  } else {

  }
  return;
}
}
void efx_update_sw_stats(struct efx_nic *efx , u64 *stats ) 
{ 
  u64 n_rx_nodesc_trunc ;
  struct efx_channel *channel ;
  int tmp ;

  {
  n_rx_nodesc_trunc = 0ULL;
  channel = efx->channel[0];
  goto ldv_57652;
  ldv_57651: 
  n_rx_nodesc_trunc = (u64 )channel->n_rx_nodesc_trunc + n_rx_nodesc_trunc;
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57652: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57651;
  } else {

  }
  *(stats + 1UL) = n_rx_nodesc_trunc;
  tmp = atomic_read((atomic_t const   *)(& efx->n_rx_noskb_drops));
  *stats = (u64 )tmp;
  return;
}
}
static void efx_pci_remove_main(struct efx_nic *efx ) 
{ 
  long tmp ;

  {
  tmp = ldv__builtin_expect((unsigned int )efx->state == 1U, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c"),
                         "i" (2895), "i" (12UL));
    ldv_57657: ;
    goto ldv_57657;
  } else {

  }
  ldv_cancel_work_sync_44(& efx->reset_work);
  efx_disable_interrupts(efx);
  efx_nic_fini_interrupt(efx);
  efx_fini_port(efx);
  (*((efx->type)->fini))(efx);
  efx_fini_napi(efx);
  efx_remove_all(efx);
  return;
}
}
static void efx_pci_remove(struct pci_dev *pci_dev ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct _ddebug descriptor ;
  long tmp___0 ;

  {
  tmp = pci_get_drvdata(pci_dev);
  efx = (struct efx_nic *)tmp;
  if ((unsigned long )efx == (unsigned long )((struct efx_nic *)0)) {
    return;
  } else {

  }
  rtnl_lock();
  efx_dissociate(efx);
  dev_close(efx->net_dev);
  efx_disable_interrupts(efx);
  efx->state = 0;
  rtnl_unlock();
  if ((unsigned long )(efx->type)->sriov_fini != (unsigned long )((void (*/* const  */)(struct efx_nic * ))0)) {
    (*((efx->type)->sriov_fini))(efx);
  } else {

  }
  efx_unregister_netdev(efx);
  efx_mtd_remove(efx);
  efx_pci_remove_main(efx);
  efx_fini_io(efx);
  if ((int )efx->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_pci_remove";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "shutdown successful\n";
    descriptor.lineno = 2936U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "shutdown successful\n");
    } else {

    }
  } else {

  }
  efx_fini_struct(efx);
  free_netdev(efx->net_dev);
  pci_disable_pcie_error_reporting(pci_dev);
  return;
}
}
static void efx_probe_vpd_strings(struct efx_nic *efx ) 
{ 
  struct pci_dev *dev ;
  char vpd_data[512U] ;
  ssize_t vpd_size ;
  int ro_start ;
    klee_make_symbolic(&ro_start, sizeof(int), "ro_start");
  int ro_size ;
    klee_make_symbolic(&ro_size, sizeof(int), "ro_size");
  int i ;
  int j ;
  u16 tmp ;
  u8 tmp___0 ;
  u8 tmp___1 ;
  void *tmp___2 ;

  {
  dev = efx->pci_dev;
  vpd_size = pci_read_vpd(dev, 0LL, 512UL, (void *)(& vpd_data));
  if (vpd_size <= 0L) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Unable to read VPD\n");
    } else {

    }
    return;
  } else {

  }
  ro_start = pci_vpd_find_tag((u8 const   *)(& vpd_data), 0U, (unsigned int )vpd_size,
                              144);
  if (ro_start < 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "VPD Read-only not found\n");
    } else {

    }
    return;
  } else {

  }
  tmp = pci_vpd_lrdt_size((u8 const   *)(& vpd_data) + (unsigned long )ro_start);
  ro_size = (int )tmp;
  j = ro_size;
  i = ro_start + 3;
  if ((ssize_t )(i + j) > vpd_size) {
    j = (int )((unsigned int )vpd_size - (unsigned int )i);
  } else {

  }
  i = pci_vpd_find_info_keyword((u8 const   *)(& vpd_data), (unsigned int )i, (unsigned int )j,
                                "PN");
  if (i < 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Part number not found\n");
    } else {

    }
    return;
  } else {

  }
  tmp___0 = pci_vpd_info_field_size((u8 const   *)(& vpd_data) + (unsigned long )i);
  j = (int )tmp___0;
  i = i + 3;
  if ((ssize_t )(i + j) > vpd_size) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Incomplete part number\n");
    } else {

    }
    return;
  } else {

  }
  if ((int )efx->msg_enable & 1) {
    netdev_info((struct net_device  const  *)efx->net_dev, "Part Number : %.*s\n",
                j, (char *)(& vpd_data) + (unsigned long )i);
  } else {

  }
  i = ro_start + 3;
  j = ro_size;
  i = pci_vpd_find_info_keyword((u8 const   *)(& vpd_data), (unsigned int )i, (unsigned int )j,
                                "SN");
  if (i < 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Serial number not found\n");
    } else {

    }
    return;
  } else {

  }
  tmp___1 = pci_vpd_info_field_size((u8 const   *)(& vpd_data) + (unsigned long )i);
  j = (int )tmp___1;
  i = i + 3;
  if ((ssize_t )(i + j) > vpd_size) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Incomplete serial number\n");
    } else {

    }
    return;
  } else {

  }
  tmp___2 = kmalloc((size_t )(j + 1), 208U);
  efx->vpd_sn = (char *)tmp___2;
  if ((unsigned long )efx->vpd_sn == (unsigned long )((char *)0)) {
    return;
  } else {

  }
  snprintf(efx->vpd_sn, (size_t )(j + 1), "%s", (char *)(& vpd_data) + (unsigned long )i);
  return;
}
}
static int efx_pci_probe_main(struct efx_nic *efx ) 
{ 
  int rc ;

  {
  rc = efx_probe_all(efx);
  if (rc != 0) {
    goto fail1;
  } else {

  }
  efx_init_napi(efx);
  rc = (*((efx->type)->init))(efx);
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to initialise NIC\n");
    } else {

    }
    goto fail3;
  } else {

  }
  rc = efx_init_port(efx);
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to initialise port\n");
    } else {

    }
    goto fail4;
  } else {

  }
  rc = efx_nic_init_interrupt(efx);
  if (rc != 0) {
    goto fail5;
  } else {

  }
  rc = efx_enable_interrupts(efx);
  if (rc != 0) {
    goto fail6;
  } else {

  }
  return (0);
  fail6: 
  efx_nic_fini_interrupt(efx);
  fail5: 
  efx_fini_port(efx);
  fail4: 
  (*((efx->type)->fini))(efx);
  fail3: 
  efx_fini_napi(efx);
  efx_remove_all(efx);
  fail1: ;
  return (rc);
}
}
static int efx_pci_probe(struct pci_dev *pci_dev , struct pci_device_id  const  *entry ) 
{ 
  struct net_device *net_dev ;
  struct efx_nic *efx ;
  int rc ;
  void *tmp ;
  struct _ddebug descriptor ;
  long tmp___0 ;
  int __ret_warn_on ;
  long tmp___1 ;
  struct _ddebug descriptor___0 ;
  long tmp___2 ;

  {
  net_dev = alloc_etherdev_mqs(4032, 64U, 32U);
  if ((unsigned long )net_dev == (unsigned long )((struct net_device *)0)) {
    return (-12);
  } else {

  }
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  efx->type = (struct efx_nic_type  const  *)entry->driver_data;
  net_dev->features = (net_dev->features | (unsigned long long )(efx->type)->offload_features) | 17179934753ULL;
  if (((unsigned long long )(efx->type)->offload_features & 24ULL) != 0ULL) {
    net_dev->features = net_dev->features | 1048576ULL;
  } else {

  }
  net_dev->vlan_features = net_dev->vlan_features | 17181507643ULL;
  net_dev->hw_features = net_dev->features & 0xffffffffffffffdfULL;
  pci_set_drvdata(pci_dev, (void *)efx);
  net_dev->dev.parent = & pci_dev->dev;
  rc = efx_init_struct(efx, pci_dev, net_dev);
  if (rc != 0) {
    goto fail1;
  } else {

  }
  if ((efx->msg_enable & 2U) != 0U) {
    netdev_info((struct net_device  const  *)efx->net_dev, "Solarflare NIC detected\n");
  } else {

  }
  if (! ((_Bool )(efx->type)->is_vf)) {
    efx_probe_vpd_strings(efx);
  } else {

  }
  rc = efx_init_io(efx);
  if (rc != 0) {
    goto fail2;
  } else {

  }
  rc = efx_pci_probe_main(efx);
  if (rc != 0) {
    goto fail3;
  } else {

  }
  rc = efx_register_netdev(efx);
  if (rc != 0) {
    goto fail4;
  } else {

  }
  if ((unsigned long )(efx->type)->sriov_init != (unsigned long )((int (*/* const  */)(struct efx_nic * ))0)) {
    rc = (*((efx->type)->sriov_init))(efx);
    if (rc != 0) {
      if ((efx->msg_enable & 2U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "SR-IOV can\'t be enabled rc %d\n",
                   rc);
      } else {

      }
    } else {

    }
  } else {

  }
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_pci_probe";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor.format = "initialisation successful\n";
    descriptor.lineno = 3133U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "initialisation successful\n");
    } else {

    }
  } else {

  }
  rtnl_lock();
  rc = efx_mtd_probe(efx);
  rtnl_unlock();
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_warn((struct net_device  const  *)efx->net_dev, "failed to create MTDs (%d)\n",
                  rc);
    } else {

    }
  } else {

  }
  rc = pci_enable_pcie_error_reporting(pci_dev);
  if (rc != 0 && rc != -22) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_warn((struct net_device  const  *)efx->net_dev, "pci_enable_pcie_error_reporting failed (%d)\n",
                  rc);
    } else {

    }
  } else {

  }
  return (0);
  fail4: 
  efx_pci_remove_main(efx);
  fail3: 
  efx_fini_io(efx);
  fail2: 
  efx_fini_struct(efx);
  fail1: 
  __ret_warn_on = rc > 0;
  tmp___1 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___1 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c",
                       3157);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if ((int )efx->msg_enable & 1) {
    descriptor___0.modname = "sfc";
    descriptor___0.function = "efx_pci_probe";
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
    descriptor___0.format = "initialisation failed. rc=%d\n";
    descriptor___0.lineno = 3158U;
    descriptor___0.flags = 0U;
    tmp___2 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
    if (tmp___2 != 0L) {
      __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                           "initialisation failed. rc=%d\n", rc);
    } else {

    }
  } else {

  }
  free_netdev(net_dev);
  return (rc);
}
}
static int efx_pci_sriov_configure(struct pci_dev *dev , int num_vfs ) 
{ 
  int rc ;
  struct efx_nic *efx ;
  void *tmp ;

  {
  tmp = pci_get_drvdata(dev);
  efx = (struct efx_nic *)tmp;
  if ((unsigned long )(efx->type)->sriov_configure != (unsigned long )((int (*/* const  */)(struct efx_nic * ,
                                                                                            int  ))0)) {
    rc = (*((efx->type)->sriov_configure))(efx, num_vfs);
    if (rc != 0) {
      return (rc);
    } else {
      return (num_vfs);
    }
  } else {
    return (-95);
  }
}
}
static int efx_pm_freeze(struct device *dev ) 
{ 
  struct efx_nic *efx ;
  struct device  const  *__mptr ;
  void *tmp ;

  {
  __mptr = (struct device  const  *)dev;
  tmp = pci_get_drvdata((struct pci_dev *)__mptr + 0xffffffffffffff68UL);
  efx = (struct efx_nic *)tmp;
  rtnl_lock();
  if ((unsigned int )efx->state != 2U) {
    efx->state = 0;
    efx_device_detach_sync(efx);
    efx_stop_all(efx);
    efx_disable_interrupts(efx);
  } else {

  }
  rtnl_unlock();
  return (0);
}
}
static int efx_pm_thaw(struct device *dev ) 
{ 
  int rc ;
  struct efx_nic *efx ;
  struct device  const  *__mptr ;
  void *tmp ;

  {
  __mptr = (struct device  const  *)dev;
  tmp = pci_get_drvdata((struct pci_dev *)__mptr + 0xffffffffffffff68UL);
  efx = (struct efx_nic *)tmp;
  rtnl_lock();
  if ((unsigned int )efx->state != 2U) {
    rc = efx_enable_interrupts(efx);
    if (rc != 0) {
      goto fail;
    } else {

    }
    ldv_mutex_lock_45(& efx->mac_lock);
    (*((efx->phy_op)->reconfigure))(efx);
    ldv_mutex_unlock_46(& efx->mac_lock);
    efx_start_all(efx);
    netif_device_attach(efx->net_dev);
    efx->state = 1;
    (*((efx->type)->resume_wol))(efx);
  } else {

  }
  rtnl_unlock();
  queue_work(reset_workqueue, & efx->reset_work);
  return (0);
  fail: 
  rtnl_unlock();
  return (rc);
}
}
static int efx_pm_poweroff(struct device *dev ) 
{ 
  struct pci_dev *pci_dev ;
  struct device  const  *__mptr ;
  struct efx_nic *efx ;
  void *tmp ;
  int tmp___0 ;

  {
  __mptr = (struct device  const  *)dev;
  pci_dev = (struct pci_dev *)__mptr + 0xffffffffffffff68UL;
  tmp = pci_get_drvdata(pci_dev);
  efx = (struct efx_nic *)tmp;
  (*((efx->type)->fini))(efx);
  efx->reset_pending = 0UL;
  pci_save_state(pci_dev);
  tmp___0 = pci_set_power_state(pci_dev, 3);
  return (tmp___0);
}
}
static int efx_pm_resume(struct device *dev ) 
{ 
  struct pci_dev *pci_dev ;
  struct device  const  *__mptr ;
  struct efx_nic *efx ;
  void *tmp ;
  int rc ;

  {
  __mptr = (struct device  const  *)dev;
  pci_dev = (struct pci_dev *)__mptr + 0xffffffffffffff68UL;
  tmp = pci_get_drvdata(pci_dev);
  efx = (struct efx_nic *)tmp;
  rc = pci_set_power_state(pci_dev, 0);
  if (rc != 0) {
    return (rc);
  } else {

  }
  pci_restore_state(pci_dev);
  rc = pci_enable_device(pci_dev);
  if (rc != 0) {
    return (rc);
  } else {

  }
  pci_set_master(efx->pci_dev);
  rc = (*((efx->type)->reset))(efx, 2);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = (*((efx->type)->init))(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = efx_pm_thaw(dev);
  return (rc);
}
}
static int efx_pm_suspend(struct device *dev ) 
{ 
  int rc ;

  {
  efx_pm_freeze(dev);
  rc = efx_pm_poweroff(dev);
  if (rc != 0) {
    efx_pm_resume(dev);
  } else {

  }
  return (rc);
}
}
static struct dev_pm_ops  const  efx_pm_ops  = 
     {0, 0, & efx_pm_suspend, & efx_pm_resume, & efx_pm_freeze, & efx_pm_thaw, & efx_pm_poweroff,
    & efx_pm_resume, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static pci_ers_result_t efx_io_error_detected(struct pci_dev *pdev , enum pci_channel_state state ) 
{ 
  pci_ers_result_t status ;
  struct efx_nic *efx ;
  void *tmp ;

  {
  status = 5U;
  tmp = pci_get_drvdata(pdev);
  efx = (struct efx_nic *)tmp;
  if ((unsigned int )state == 3U) {
    return (4U);
  } else {

  }
  rtnl_lock();
  if ((unsigned int )efx->state != 2U) {
    efx->state = 3;
    efx->reset_pending = 0UL;
    efx_device_detach_sync(efx);
    efx_stop_all(efx);
    efx_disable_interrupts(efx);
    status = 3U;
  } else {
    status = 5U;
  }
  rtnl_unlock();
  pci_disable_device(pdev);
  return (status);
}
}
static pci_ers_result_t efx_io_slot_reset(struct pci_dev *pdev ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  pci_ers_result_t status ;
  int rc ;
  int tmp___0 ;

  {
  tmp = pci_get_drvdata(pdev);
  efx = (struct efx_nic *)tmp;
  status = 5U;
  tmp___0 = pci_enable_device(pdev);
  if (tmp___0 != 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Cannot re-enable PCI device after reset.\n");
    } else {

    }
    status = 4U;
  } else {

  }
  rc = pci_cleanup_aer_uncorrect_error_status(pdev);
  if (rc != 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "pci_cleanup_aer_uncorrect_error_status failed (%d)\n",
                 rc);
    } else {

    }
  } else {

  }
  return (status);
}
}
static void efx_io_resume(struct pci_dev *pdev ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int rc ;
  struct _ddebug descriptor ;
  long tmp___0 ;

  {
  tmp = pci_get_drvdata(pdev);
  efx = (struct efx_nic *)tmp;
  rtnl_lock();
  if ((unsigned int )efx->state == 2U) {
    goto out;
  } else {

  }
  rc = efx_reset(efx, 2);
  if (rc != 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "efx_reset failed after PCI error (%d)\n",
                 rc);
    } else {

    }
  } else {
    efx->state = 1;
    if ((efx->msg_enable & 8192U) != 0U) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_io_resume";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/efx.c";
      descriptor.format = "Done resetting and resuming IO after PCI error.\n";
      descriptor.lineno = 3379U;
      descriptor.flags = 0U;
      tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp___0 != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "Done resetting and resuming IO after PCI error.\n");
      } else {

      }
    } else {

    }
  }
  out: 
  rtnl_unlock();
  return;
}
}
static struct pci_error_handlers efx_err_handlers  =    {& efx_io_error_detected, 0, 0, & efx_io_slot_reset, 0, & efx_io_resume};
static struct pci_driver efx_pci_driver  = 
     {{0, 0}, "sfc", (struct pci_device_id  const  *)(& efx_pci_table), & efx_pci_probe,
    & efx_pci_remove, 0, 0, 0, 0, 0, & efx_pci_sriov_configure, (struct pci_error_handlers  const  *)(& efx_err_handlers),
    {0, 0, 0, 0, (_Bool)0, 0, 0, 0, 0, 0, 0, 0, 0, 0, & efx_pm_ops, 0}, {{{{{{0}},
                                                                            0U, 0U,
                                                                            0, {0,
                                                                                {0,
                                                                                 0},
                                                                                0,
                                                                                0,
                                                                                0UL}}}},
                                                                         {0, 0}}};
static int efx_init_module(void) 
{ 
  int rc ;
  struct lock_class_key __key ;
  char const   *__lock_name ;
  struct workqueue_struct *tmp ;

  {
  printk("\016Solarflare NET driver v4.0\n");
  rc = register_netdevice_notifier(& efx_netdev_notifier);
  if (rc != 0) {
    goto err_notifier;
  } else {

  }
  rc = efx_init_sriov();
  if (rc != 0) {
    goto err_sriov;
  } else {

  }
  __lock_name = "\"%s\"\"sfc_reset\"";
  tmp = __alloc_workqueue_key("%s", 131082U, 1, & __key, __lock_name, (char *)"sfc_reset");
  reset_workqueue = tmp;
  if ((unsigned long )reset_workqueue == (unsigned long )((struct workqueue_struct *)0)) {
    rc = -12;
    goto err_reset;
  } else {

  }
  rc = ldv___pci_register_driver_47(& efx_pci_driver, & __this_module, "sfc");
  if (rc < 0) {
    goto err_pci;
  } else {

  }
  return (0);
  err_pci: 
  ldv_destroy_workqueue_48(reset_workqueue);
  err_reset: 
  efx_fini_sriov();
  err_sriov: 
  unregister_netdevice_notifier(& efx_netdev_notifier);
  err_notifier: ;
  return (rc);
}
}
static void efx_exit_module(void) 
{ 


  {
  printk("\016Solarflare NET driver unloading\n");
  ldv_pci_unregister_driver_49(& efx_pci_driver);
  ldv_destroy_workqueue_50(reset_workqueue);
  efx_fini_sriov();
  unregister_netdevice_notifier(& efx_netdev_notifier);
  return;
}
}
struct pci_device_id  const  __mod_pci__efx_pci_table_device_table[8U]  ;
int ldv_retval_20  ;
    klee_make_symbolic(&ldv_retval_20, sizeof(int), "ldv_retval_20");
extern int ldv_suspend_32(void) ;
extern int ldv_thaw_noirq_33(void) ;
extern int ldv_suspend_noirq_33(void) ;
int ldv_retval_18  ;
    klee_make_symbolic(&ldv_retval_18, sizeof(int), "ldv_retval_18");
extern int ldv_freeze_late_33(void) ;
int ldv_retval_2  ;
    klee_make_symbolic(&ldv_retval_2, sizeof(int), "ldv_retval_2");
extern int ldv_prepare_33(void) ;
int ldv_retval_5  ;
    klee_make_symbolic(&ldv_retval_5, sizeof(int), "ldv_retval_5");
int ldv_retval_0  ;
    klee_make_symbolic(&ldv_retval_0, sizeof(int), "ldv_retval_0");
int ldv_retval_23  ;
    klee_make_symbolic(&ldv_retval_23, sizeof(int), "ldv_retval_23");
int ldv_retval_11  ;
    klee_make_symbolic(&ldv_retval_11, sizeof(int), "ldv_retval_11");
int ldv_retval_1  ;
    klee_make_symbolic(&ldv_retval_1, sizeof(int), "ldv_retval_1");
int ldv_retval_22  ;
    klee_make_symbolic(&ldv_retval_22, sizeof(int), "ldv_retval_22");
int ldv_retval_15  ;
    klee_make_symbolic(&ldv_retval_15, sizeof(int), "ldv_retval_15");
extern int ldv_resume_early_33(void) ;
int ldv_retval_16  ;
    klee_make_symbolic(&ldv_retval_16, sizeof(int), "ldv_retval_16");
extern int ldv_resume_noirq_33(void) ;
extern int ldv_release_32(void) ;
void ldv_check_final_state(void) ;
extern int ldv_ndo_init_38(void) ;
int ldv_retval_8  ;
    klee_make_symbolic(&ldv_retval_8, sizeof(int), "ldv_retval_8");
extern int ldv_thaw_early_33(void) ;
int ldv_retval_7  ;
    klee_make_symbolic(&ldv_retval_7, sizeof(int), "ldv_retval_7");
extern int ldv_restore_noirq_33(void) ;
extern int ldv_poweroff_noirq_33(void) ;
int ldv_retval_19  ;
    klee_make_symbolic(&ldv_retval_19, sizeof(int), "ldv_retval_19");
int ldv_retval_14  ;
    klee_make_symbolic(&ldv_retval_14, sizeof(int), "ldv_retval_14");
int ldv_retval_17  ;
    klee_make_symbolic(&ldv_retval_17, sizeof(int), "ldv_retval_17");
int ldv_retval_12  ;
    klee_make_symbolic(&ldv_retval_12, sizeof(int), "ldv_retval_12");
extern int ldv_shutdown_31(void) ;
extern int ldv_restore_early_33(void) ;
extern int ldv_ndo_uninit_38(void) ;
extern int ldv_complete_33(void) ;
extern void ldv_initialize(void) ;
int ldv_retval_6  ;
    klee_make_symbolic(&ldv_retval_6, sizeof(int), "ldv_retval_6");
extern int ldv_suspend_late_33(void) ;
int ldv_retval_21  ;
    klee_make_symbolic(&ldv_retval_21, sizeof(int), "ldv_retval_21");
extern int ldv_poweroff_late_33(void) ;
int ldv_retval_13  ;
    klee_make_symbolic(&ldv_retval_13, sizeof(int), "ldv_retval_13");
extern int ldv_setup_34(void) ;
int ldv_retval_10  ;
    klee_make_symbolic(&ldv_retval_10, sizeof(int), "ldv_retval_10");
int ldv_retval_9  ;
    klee_make_symbolic(&ldv_retval_9, sizeof(int), "ldv_retval_9");
extern int ldv_release_34(void) ;
int ldv_retval_4  ;
    klee_make_symbolic(&ldv_retval_4, sizeof(int), "ldv_retval_4");
extern int ldv_probe_32(void) ;
extern int ldv_freeze_noirq_33(void) ;
int ldv_retval_3  ;
    klee_make_symbolic(&ldv_retval_3, sizeof(int), "ldv_retval_3");
void ldv_net_device_ops_38(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(3008UL);
  efx_netdev_ops_group1 = (struct net_device *)tmp;
  return;
}
}
void call_and_disable_all_4(int state ) 
{ 


  {
  if (ldv_work_4_0 == state) {
    call_and_disable_work_4(ldv_work_struct_4_0);
  } else {

  }
  if (ldv_work_4_1 == state) {
    call_and_disable_work_4(ldv_work_struct_4_1);
  } else {

  }
  if (ldv_work_4_2 == state) {
    call_and_disable_work_4(ldv_work_struct_4_2);
  } else {

  }
  if (ldv_work_4_3 == state) {
    call_and_disable_work_4(ldv_work_struct_4_3);
  } else {

  }
  return;
}
}
void activate_work_1(struct work_struct *work , int state ) 
{ 


  {
  if (ldv_work_1_0 == 0) {
    ldv_work_struct_1_0 = work;
    ldv_work_1_0 = state;
    return;
  } else {

  }
  if (ldv_work_1_1 == 0) {
    ldv_work_struct_1_1 = work;
    ldv_work_1_1 = state;
    return;
  } else {

  }
  if (ldv_work_1_2 == 0) {
    ldv_work_struct_1_2 = work;
    ldv_work_1_2 = state;
    return;
  } else {

  }
  if (ldv_work_1_3 == 0) {
    ldv_work_struct_1_3 = work;
    ldv_work_1_3 = state;
    return;
  } else {

  }
  return;
}
}
int reg_timer_10(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) 
{ 


  {
  if ((unsigned long )function == (unsigned long )(& efx_rx_slow_fill)) {
    activate_suitable_timer_10(timer, data);
  } else {

  }
  return (0);
}
}
void call_and_disable_work_3(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_3_0 == 2 || ldv_work_3_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_0) {
    efx_selftest_async_work(work);
    ldv_work_3_0 = 1;
    return;
  } else {

  }
  if ((ldv_work_3_1 == 2 || ldv_work_3_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_1) {
    efx_selftest_async_work(work);
    ldv_work_3_1 = 1;
    return;
  } else {

  }
  if ((ldv_work_3_2 == 2 || ldv_work_3_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_2) {
    efx_selftest_async_work(work);
    ldv_work_3_2 = 1;
    return;
  } else {

  }
  if ((ldv_work_3_3 == 2 || ldv_work_3_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_3) {
    efx_selftest_async_work(work);
    ldv_work_3_3 = 1;
    return;
  } else {

  }
  return;
}
}
void disable_work_3(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_3_0 == 3 || ldv_work_3_0 == 2) && (unsigned long )ldv_work_struct_3_0 == (unsigned long )work) {
    ldv_work_3_0 = 1;
  } else {

  }
  if ((ldv_work_3_1 == 3 || ldv_work_3_1 == 2) && (unsigned long )ldv_work_struct_3_1 == (unsigned long )work) {
    ldv_work_3_1 = 1;
  } else {

  }
  if ((ldv_work_3_2 == 3 || ldv_work_3_2 == 2) && (unsigned long )ldv_work_struct_3_2 == (unsigned long )work) {
    ldv_work_3_2 = 1;
  } else {

  }
  if ((ldv_work_3_3 == 3 || ldv_work_3_3 == 2) && (unsigned long )ldv_work_struct_3_3 == (unsigned long )work) {
    ldv_work_3_3 = 1;
  } else {

  }
  return;
}
}
void work_init_1(void) 
{ 


  {
  ldv_work_1_0 = 0;
  ldv_work_1_1 = 0;
  ldv_work_1_2 = 0;
  ldv_work_1_3 = 0;
  return;
}
}
void disable_suitable_timer_11(struct timer_list *timer ) 
{ 


  {
  if (ldv_timer_11_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_11_0) {
    ldv_timer_11_0 = 0;
    return;
  } else {

  }
  if (ldv_timer_11_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_11_1) {
    ldv_timer_11_1 = 0;
    return;
  } else {

  }
  if (ldv_timer_11_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_11_2) {
    ldv_timer_11_2 = 0;
    return;
  } else {

  }
  if (ldv_timer_11_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_11_3) {
    ldv_timer_11_3 = 0;
    return;
  } else {

  }
  return;
}
}
void invoke_work_4(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_work_4_0 == 2 || ldv_work_4_0 == 3) {
    ldv_work_4_0 = 4;
    efx_mac_work(ldv_work_struct_4_0);
    ldv_work_4_0 = 1;
  } else {

  }
  goto ldv_57916;
  case 1: ;
  if (ldv_work_4_1 == 2 || ldv_work_4_1 == 3) {
    ldv_work_4_1 = 4;
    efx_mac_work(ldv_work_struct_4_0);
    ldv_work_4_1 = 1;
  } else {

  }
  goto ldv_57916;
  case 2: ;
  if (ldv_work_4_2 == 2 || ldv_work_4_2 == 3) {
    ldv_work_4_2 = 4;
    efx_mac_work(ldv_work_struct_4_0);
    ldv_work_4_2 = 1;
  } else {

  }
  goto ldv_57916;
  case 3: ;
  if (ldv_work_4_3 == 2 || ldv_work_4_3 == 3) {
    ldv_work_4_3 = 4;
    efx_mac_work(ldv_work_struct_4_0);
    ldv_work_4_3 = 1;
  } else {

  }
  goto ldv_57916;
  default: 
  ldv_stop();
  }
  ldv_57916: ;
  return;
}
}
void ldv_timer_10(int state , struct timer_list *timer ) 
{ 


  {
  LDV_IN_INTERRUPT = 2;
  efx_rx_slow_fill(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void activate_work_2(struct work_struct *work , int state ) 
{ 


  {
  if (ldv_work_2_0 == 0) {
    ldv_work_struct_2_0 = work;
    ldv_work_2_0 = state;
    return;
  } else {

  }
  if (ldv_work_2_1 == 0) {
    ldv_work_struct_2_1 = work;
    ldv_work_2_1 = state;
    return;
  } else {

  }
  if (ldv_work_2_2 == 0) {
    ldv_work_struct_2_2 = work;
    ldv_work_2_2 = state;
    return;
  } else {

  }
  if (ldv_work_2_3 == 0) {
    ldv_work_struct_2_3 = work;
    ldv_work_2_3 = state;
    return;
  } else {

  }
  return;
}
}
void choose_timer_11(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_11_0 == 1) {
    ldv_timer_11_0 = 2;
    ldv_timer_11(ldv_timer_11_0, ldv_timer_list_11_0);
  } else {

  }
  goto ldv_57933;
  case 1: ;
  if (ldv_timer_11_1 == 1) {
    ldv_timer_11_1 = 2;
    ldv_timer_11(ldv_timer_11_1, ldv_timer_list_11_1);
  } else {

  }
  goto ldv_57933;
  case 2: ;
  if (ldv_timer_11_2 == 1) {
    ldv_timer_11_2 = 2;
    ldv_timer_11(ldv_timer_11_2, ldv_timer_list_11_2);
  } else {

  }
  goto ldv_57933;
  case 3: ;
  if (ldv_timer_11_3 == 1) {
    ldv_timer_11_3 = 2;
    ldv_timer_11(ldv_timer_11_3, ldv_timer_list_11_3);
  } else {

  }
  goto ldv_57933;
  default: 
  ldv_stop();
  }
  ldv_57933: ;
  return;
}
}
void activate_suitable_timer_10(struct timer_list *timer , unsigned long data ) 
{ 


  {
  if (ldv_timer_10_0 == 0 || ldv_timer_10_0 == 2) {
    ldv_timer_list_10_0 = timer;
    ldv_timer_list_10_0->data = data;
    ldv_timer_10_0 = 1;
    return;
  } else {

  }
  if (ldv_timer_10_1 == 0 || ldv_timer_10_1 == 2) {
    ldv_timer_list_10_1 = timer;
    ldv_timer_list_10_1->data = data;
    ldv_timer_10_1 = 1;
    return;
  } else {

  }
  if (ldv_timer_10_2 == 0 || ldv_timer_10_2 == 2) {
    ldv_timer_list_10_2 = timer;
    ldv_timer_list_10_2->data = data;
    ldv_timer_10_2 = 1;
    return;
  } else {

  }
  if (ldv_timer_10_3 == 0 || ldv_timer_10_3 == 2) {
    ldv_timer_list_10_3 = timer;
    ldv_timer_list_10_3->data = data;
    ldv_timer_10_3 = 1;
    return;
  } else {

  }
  return;
}
}
void timer_init_11(void) 
{ 


  {
  ldv_timer_11_0 = 0;
  ldv_timer_11_1 = 0;
  ldv_timer_11_2 = 0;
  ldv_timer_11_3 = 0;
  return;
}
}
void ldv_initialize_pci_error_handlers_32(void) 
{ 

  {
  efx_err_handlers_group0 = ldv_malloc(sizeof(struct pci_dev));
  return;
}
}
void disable_work_4(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_4_0 == 3 || ldv_work_4_0 == 2) && (unsigned long )ldv_work_struct_4_0 == (unsigned long )work) {
    ldv_work_4_0 = 1;
  } else {

  }
  if ((ldv_work_4_1 == 3 || ldv_work_4_1 == 2) && (unsigned long )ldv_work_struct_4_1 == (unsigned long )work) {
    ldv_work_4_1 = 1;
  } else {

  }
  if ((ldv_work_4_2 == 3 || ldv_work_4_2 == 2) && (unsigned long )ldv_work_struct_4_2 == (unsigned long )work) {
    ldv_work_4_2 = 1;
  } else {

  }
  if ((ldv_work_4_3 == 3 || ldv_work_4_3 == 2) && (unsigned long )ldv_work_struct_4_3 == (unsigned long )work) {
    ldv_work_4_3 = 1;
  } else {

  }
  return;
}
}
void work_init_4(void) 
{ 


  {
  ldv_work_4_0 = 0;
  ldv_work_4_1 = 0;
  ldv_work_4_2 = 0;
  ldv_work_4_3 = 0;
  return;
}
}
void invoke_work_1(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_work_1_0 == 2 || ldv_work_1_0 == 3) {
    ldv_work_1_0 = 4;
    efx_reset_work(ldv_work_struct_1_0);
    ldv_work_1_0 = 1;
  } else {

  }
  goto ldv_57960;
  case 1: ;
  if (ldv_work_1_1 == 2 || ldv_work_1_1 == 3) {
    ldv_work_1_1 = 4;
    efx_reset_work(ldv_work_struct_1_0);
    ldv_work_1_1 = 1;
  } else {

  }
  goto ldv_57960;
  case 2: ;
  if (ldv_work_1_2 == 2 || ldv_work_1_2 == 3) {
    ldv_work_1_2 = 4;
    efx_reset_work(ldv_work_struct_1_0);
    ldv_work_1_2 = 1;
  } else {

  }
  goto ldv_57960;
  case 3: ;
  if (ldv_work_1_3 == 2 || ldv_work_1_3 == 3) {
    ldv_work_1_3 = 4;
    efx_reset_work(ldv_work_struct_1_0);
    ldv_work_1_3 = 1;
  } else {

  }
  goto ldv_57960;
  default: 
  ldv_stop();
  }
  ldv_57960: ;
  return;
}
}
int reg_timer_11(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) 
{ 


  {
  if ((unsigned long )function == (unsigned long )(& efx_rx_slow_fill)) {
    activate_suitable_timer_11(timer, data);
  } else {

  }
  return (0);
}
}
void activate_suitable_timer_11(struct timer_list *timer , unsigned long data ) 
{ 


  {
  if (ldv_timer_11_0 == 0 || ldv_timer_11_0 == 2) {
    ldv_timer_list_11_0 = timer;
    ldv_timer_list_11_0->data = data;
    ldv_timer_11_0 = 1;
    return;
  } else {

  }
  if (ldv_timer_11_1 == 0 || ldv_timer_11_1 == 2) {
    ldv_timer_list_11_1 = timer;
    ldv_timer_list_11_1->data = data;
    ldv_timer_11_1 = 1;
    return;
  } else {

  }
  if (ldv_timer_11_2 == 0 || ldv_timer_11_2 == 2) {
    ldv_timer_list_11_2 = timer;
    ldv_timer_list_11_2->data = data;
    ldv_timer_11_2 = 1;
    return;
  } else {

  }
  if (ldv_timer_11_3 == 0 || ldv_timer_11_3 == 2) {
    ldv_timer_list_11_3 = timer;
    ldv_timer_list_11_3->data = data;
    ldv_timer_11_3 = 1;
    return;
  } else {

  }
  return;
}
}
void call_and_disable_all_3(int state ) 
{ 


  {
  if (ldv_work_3_0 == state) {
    call_and_disable_work_3(ldv_work_struct_3_0);
  } else {

  }
  if (ldv_work_3_1 == state) {
    call_and_disable_work_3(ldv_work_struct_3_1);
  } else {

  }
  if (ldv_work_3_2 == state) {
    call_and_disable_work_3(ldv_work_struct_3_2);
  } else {

  }
  if (ldv_work_3_3 == state) {
    call_and_disable_work_3(ldv_work_struct_3_3);
  } else {

  }
  return;
}
}
void call_and_disable_work_4(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_4_0 == 2 || ldv_work_4_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_0) {
    efx_mac_work(work);
    ldv_work_4_0 = 1;
    return;
  } else {

  }
  if ((ldv_work_4_1 == 2 || ldv_work_4_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_1) {
    efx_mac_work(work);
    ldv_work_4_1 = 1;
    return;
  } else {

  }
  if ((ldv_work_4_2 == 2 || ldv_work_4_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_2) {
    efx_mac_work(work);
    ldv_work_4_2 = 1;
    return;
  } else {

  }
  if ((ldv_work_4_3 == 2 || ldv_work_4_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_3) {
    efx_mac_work(work);
    ldv_work_4_3 = 1;
    return;
  } else {

  }
  return;
}
}
void work_init_3(void) 
{ 


  {
  ldv_work_3_0 = 0;
  ldv_work_3_1 = 0;
  ldv_work_3_2 = 0;
  ldv_work_3_3 = 0;
  return;
}
}
void call_and_disable_work_1(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_1_0 == 2 || ldv_work_1_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_1_0) {
    efx_reset_work(work);
    ldv_work_1_0 = 1;
    return;
  } else {

  }
  if ((ldv_work_1_1 == 2 || ldv_work_1_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_1_1) {
    efx_reset_work(work);
    ldv_work_1_1 = 1;
    return;
  } else {

  }
  if ((ldv_work_1_2 == 2 || ldv_work_1_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_1_2) {
    efx_reset_work(work);
    ldv_work_1_2 = 1;
    return;
  } else {

  }
  if ((ldv_work_1_3 == 2 || ldv_work_1_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_1_3) {
    efx_reset_work(work);
    ldv_work_1_3 = 1;
    return;
  } else {

  }
  return;
}
}
void call_and_disable_all_2(int state ) 
{ 


  {
  if (ldv_work_2_0 == state) {
    call_and_disable_work_2(ldv_work_struct_2_0);
  } else {

  }
  if (ldv_work_2_1 == state) {
    call_and_disable_work_2(ldv_work_struct_2_1);
  } else {

  }
  if (ldv_work_2_2 == state) {
    call_and_disable_work_2(ldv_work_struct_2_2);
  } else {

  }
  if (ldv_work_2_3 == state) {
    call_and_disable_work_2(ldv_work_struct_2_3);
  } else {

  }
  return;
}
}
void activate_work_3(struct work_struct *work , int state ) 
{ 


  {
  if (ldv_work_3_0 == 0) {
    ldv_work_struct_3_0 = work;
    ldv_work_3_0 = state;
    return;
  } else {

  }
  if (ldv_work_3_1 == 0) {
    ldv_work_struct_3_1 = work;
    ldv_work_3_1 = state;
    return;
  } else {

  }
  if (ldv_work_3_2 == 0) {
    ldv_work_struct_3_2 = work;
    ldv_work_3_2 = state;
    return;
  } else {

  }
  if (ldv_work_3_3 == 0) {
    ldv_work_struct_3_3 = work;
    ldv_work_3_3 = state;
    return;
  } else {

  }
  return;
}
}
void activate_pending_timer_10(struct timer_list *timer , unsigned long data , int pending_flag ) 
{ 


  {
  if ((unsigned long )ldv_timer_list_10_0 == (unsigned long )timer) {
    if (ldv_timer_10_0 == 2 || pending_flag != 0) {
      ldv_timer_list_10_0 = timer;
      ldv_timer_list_10_0->data = data;
      ldv_timer_10_0 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_10_1 == (unsigned long )timer) {
    if (ldv_timer_10_1 == 2 || pending_flag != 0) {
      ldv_timer_list_10_1 = timer;
      ldv_timer_list_10_1->data = data;
      ldv_timer_10_1 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_10_2 == (unsigned long )timer) {
    if (ldv_timer_10_2 == 2 || pending_flag != 0) {
      ldv_timer_list_10_2 = timer;
      ldv_timer_list_10_2->data = data;
      ldv_timer_10_2 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_10_3 == (unsigned long )timer) {
    if (ldv_timer_10_3 == 2 || pending_flag != 0) {
      ldv_timer_list_10_3 = timer;
      ldv_timer_list_10_3->data = data;
      ldv_timer_10_3 = 1;
    } else {

    }
    return;
  } else {

  }
  activate_suitable_timer_10(timer, data);
  return;
}
}
void ldv_initialize_efx_phy_operations_34(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(4032UL);
  efx_dummy_phy_operations_group0 = (struct efx_nic *)tmp;
  return;
}
}
void ldv_pci_driver_31(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(2976UL);
  efx_pci_driver_group1 = (struct pci_dev *)tmp;
  return;
}
}
void ldv_initialize_efx_channel_type_39(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(2176UL);
  efx_default_channel_type_group0 = (struct efx_channel *)tmp;
  return;
}
}
void disable_work_1(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_1_0 == 3 || ldv_work_1_0 == 2) && (unsigned long )ldv_work_struct_1_0 == (unsigned long )work) {
    ldv_work_1_0 = 1;
  } else {

  }
  if ((ldv_work_1_1 == 3 || ldv_work_1_1 == 2) && (unsigned long )ldv_work_struct_1_1 == (unsigned long )work) {
    ldv_work_1_1 = 1;
  } else {

  }
  if ((ldv_work_1_2 == 3 || ldv_work_1_2 == 2) && (unsigned long )ldv_work_struct_1_2 == (unsigned long )work) {
    ldv_work_1_2 = 1;
  } else {

  }
  if ((ldv_work_1_3 == 3 || ldv_work_1_3 == 2) && (unsigned long )ldv_work_struct_1_3 == (unsigned long )work) {
    ldv_work_1_3 = 1;
  } else {

  }
  return;
}
}
void ldv_initialize_device_attribute_35(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
  tmp = ldv_init_zalloc(48UL);
  dev_attr_mcdi_logging_group0 = (struct device_attribute *)tmp;
  tmp___0 = ldv_init_zalloc(1416UL);
  dev_attr_mcdi_logging_group1 = (struct device *)tmp___0;
  return;
}
}
void ldv_dev_pm_ops_33(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(1416UL);
  efx_pm_ops_group1 = (struct device *)tmp;
  return;
}
}
void invoke_work_2(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_work_2_0 == 2 || ldv_work_2_0 == 3) {
    ldv_work_2_0 = 4;
    efx_monitor(ldv_work_struct_2_0);
    ldv_work_2_0 = 1;
  } else {

  }
  goto ldv_58027;
  case 1: ;
  if (ldv_work_2_1 == 2 || ldv_work_2_1 == 3) {
    ldv_work_2_1 = 4;
    efx_monitor(ldv_work_struct_2_0);
    ldv_work_2_1 = 1;
  } else {

  }
  goto ldv_58027;
  case 2: ;
  if (ldv_work_2_2 == 2 || ldv_work_2_2 == 3) {
    ldv_work_2_2 = 4;
    efx_monitor(ldv_work_struct_2_0);
    ldv_work_2_2 = 1;
  } else {

  }
  goto ldv_58027;
  case 3: ;
  if (ldv_work_2_3 == 2 || ldv_work_2_3 == 3) {
    ldv_work_2_3 = 4;
    efx_monitor(ldv_work_struct_2_0);
    ldv_work_2_3 = 1;
  } else {

  }
  goto ldv_58027;
  default: 
  ldv_stop();
  }
  ldv_58027: ;
  return;
}
}
void activate_work_4(struct work_struct *work , int state ) 
{ 


  {
  if (ldv_work_4_0 == 0) {
    ldv_work_struct_4_0 = work;
    ldv_work_4_0 = state;
    return;
  } else {

  }
  if (ldv_work_4_1 == 0) {
    ldv_work_struct_4_1 = work;
    ldv_work_4_1 = state;
    return;
  } else {

  }
  if (ldv_work_4_2 == 0) {
    ldv_work_struct_4_2 = work;
    ldv_work_4_2 = state;
    return;
  } else {

  }
  if (ldv_work_4_3 == 0) {
    ldv_work_struct_4_3 = work;
    ldv_work_4_3 = state;
    return;
  } else {

  }
  return;
}
}
void disable_suitable_timer_10(struct timer_list *timer ) 
{ 


  {
  if (ldv_timer_10_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_10_0) {
    ldv_timer_10_0 = 0;
    return;
  } else {

  }
  if (ldv_timer_10_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_10_1) {
    ldv_timer_10_1 = 0;
    return;
  } else {

  }
  if (ldv_timer_10_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_10_2) {
    ldv_timer_10_2 = 0;
    return;
  } else {

  }
  if (ldv_timer_10_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_10_3) {
    ldv_timer_10_3 = 0;
    return;
  } else {

  }
  return;
}
}
void work_init_2(void) 
{ 


  {
  ldv_work_2_0 = 0;
  ldv_work_2_1 = 0;
  ldv_work_2_2 = 0;
  ldv_work_2_3 = 0;
  return;
}
}
void call_and_disable_all_1(int state ) 
{ 


  {
  if (ldv_work_1_0 == state) {
    call_and_disable_work_1(ldv_work_struct_1_0);
  } else {

  }
  if (ldv_work_1_1 == state) {
    call_and_disable_work_1(ldv_work_struct_1_1);
  } else {

  }
  if (ldv_work_1_2 == state) {
    call_and_disable_work_1(ldv_work_struct_1_2);
  } else {

  }
  if (ldv_work_1_3 == state) {
    call_and_disable_work_1(ldv_work_struct_1_3);
  } else {

  }
  return;
}
}
void ldv_timer_11(int state , struct timer_list *timer ) 
{ 


  {
  LDV_IN_INTERRUPT = 2;
  efx_rx_slow_fill(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void timer_init_10(void) 
{ 


  {
  ldv_timer_10_0 = 0;
  ldv_timer_10_1 = 0;
  ldv_timer_10_2 = 0;
  ldv_timer_10_3 = 0;
  return;
}
}
void disable_work_2(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_2_0 == 3 || ldv_work_2_0 == 2) && (unsigned long )ldv_work_struct_2_0 == (unsigned long )work) {
    ldv_work_2_0 = 1;
  } else {

  }
  if ((ldv_work_2_1 == 3 || ldv_work_2_1 == 2) && (unsigned long )ldv_work_struct_2_1 == (unsigned long )work) {
    ldv_work_2_1 = 1;
  } else {

  }
  if ((ldv_work_2_2 == 3 || ldv_work_2_2 == 2) && (unsigned long )ldv_work_struct_2_2 == (unsigned long )work) {
    ldv_work_2_2 = 1;
  } else {

  }
  if ((ldv_work_2_3 == 3 || ldv_work_2_3 == 2) && (unsigned long )ldv_work_struct_2_3 == (unsigned long )work) {
    ldv_work_2_3 = 1;
  } else {

  }
  return;
}
}
void invoke_work_3(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_work_3_0 == 2 || ldv_work_3_0 == 3) {
    ldv_work_3_0 = 4;
    efx_selftest_async_work(ldv_work_struct_3_0);
    ldv_work_3_0 = 1;
  } else {

  }
  goto ldv_58061;
  case 1: ;
  if (ldv_work_3_1 == 2 || ldv_work_3_1 == 3) {
    ldv_work_3_1 = 4;
    efx_selftest_async_work(ldv_work_struct_3_0);
    ldv_work_3_1 = 1;
  } else {

  }
  goto ldv_58061;
  case 2: ;
  if (ldv_work_3_2 == 2 || ldv_work_3_2 == 3) {
    ldv_work_3_2 = 4;
    efx_selftest_async_work(ldv_work_struct_3_0);
    ldv_work_3_2 = 1;
  } else {

  }
  goto ldv_58061;
  case 3: ;
  if (ldv_work_3_3 == 2 || ldv_work_3_3 == 3) {
    ldv_work_3_3 = 4;
    efx_selftest_async_work(ldv_work_struct_3_0);
    ldv_work_3_3 = 1;
  } else {

  }
  goto ldv_58061;
  default: 
  ldv_stop();
  }
  ldv_58061: ;
  return;
}
}
void activate_pending_timer_11(struct timer_list *timer , unsigned long data , int pending_flag ) 
{ 


  {
  if ((unsigned long )ldv_timer_list_11_0 == (unsigned long )timer) {
    if (ldv_timer_11_0 == 2 || pending_flag != 0) {
      ldv_timer_list_11_0 = timer;
      ldv_timer_list_11_0->data = data;
      ldv_timer_11_0 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_11_1 == (unsigned long )timer) {
    if (ldv_timer_11_1 == 2 || pending_flag != 0) {
      ldv_timer_list_11_1 = timer;
      ldv_timer_list_11_1->data = data;
      ldv_timer_11_1 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_11_2 == (unsigned long )timer) {
    if (ldv_timer_11_2 == 2 || pending_flag != 0) {
      ldv_timer_list_11_2 = timer;
      ldv_timer_list_11_2->data = data;
      ldv_timer_11_2 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_11_3 == (unsigned long )timer) {
    if (ldv_timer_11_3 == 2 || pending_flag != 0) {
      ldv_timer_list_11_3 = timer;
      ldv_timer_list_11_3->data = data;
      ldv_timer_11_3 = 1;
    } else {

    }
    return;
  } else {

  }
  activate_suitable_timer_11(timer, data);
  return;
}
}
void choose_timer_10(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_10_0 == 1) {
    ldv_timer_10_0 = 2;
    ldv_timer_10(ldv_timer_10_0, ldv_timer_list_10_0);
  } else {

  }
  goto ldv_58077;
  case 1: ;
  if (ldv_timer_10_1 == 1) {
    ldv_timer_10_1 = 2;
    ldv_timer_10(ldv_timer_10_1, ldv_timer_list_10_1);
  } else {

  }
  goto ldv_58077;
  case 2: ;
  if (ldv_timer_10_2 == 1) {
    ldv_timer_10_2 = 2;
    ldv_timer_10(ldv_timer_10_2, ldv_timer_list_10_2);
  } else {

  }
  goto ldv_58077;
  case 3: ;
  if (ldv_timer_10_3 == 1) {
    ldv_timer_10_3 = 2;
    ldv_timer_10(ldv_timer_10_3, ldv_timer_list_10_3);
  } else {

  }
  goto ldv_58077;
  default: 
  ldv_stop();
  }
  ldv_58077: ;
  return;
}
}
void call_and_disable_work_2(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_2_0 == 2 || ldv_work_2_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_2_0) {
    efx_monitor(work);
    ldv_work_2_0 = 1;
    return;
  } else {

  }
  if ((ldv_work_2_1 == 2 || ldv_work_2_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_2_1) {
    efx_monitor(work);
    ldv_work_2_1 = 1;
    return;
  } else {

  }
  if ((ldv_work_2_2 == 2 || ldv_work_2_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_2_2) {
    efx_monitor(work);
    ldv_work_2_2 = 1;
    return;
  } else {

  }
  if ((ldv_work_2_3 == 2 || ldv_work_2_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_2_3) {
    efx_monitor(work);
    ldv_work_2_3 = 1;
    return;
  } else {

  }
  return;
}
}
void ldv_main_exported_19(void) ;
void ldv_main_exported_28(void) ;
void ldv_main_exported_30(void) ;
void ldv_main_exported_29(void) ;
void ldv_main_exported_17(void) ;
void ldv_main_exported_27(void) ;
void ldv_main_exported_20(void) ;
void ldv_main_exported_14(void) ;
void ldv_main_exported_25(void) ;
void ldv_main_exported_24(void) ;
void ldv_main_exported_26(void) ;
void ldv_main_exported_23(void) ;
void ldv_main_exported_21(void) ;
void ldv_main_exported_22(void) ;
void ldv_main_exported_18(void) ;
void ldv_main_exported_16(void) ;
void ldv_main_exported_15(void) ;
int main(void) 
{ 
  enum pci_channel_state ldvarg0 ;
  int ldvarg178 ;
    klee_make_symbolic(&ldvarg178, sizeof(int), "ldvarg178");
  struct pci_device_id *ldvarg179 ;
  void *tmp ;
  size_t ldvarg181 ;
  char *ldvarg180 ;
  void *tmp___0 ;
  char *ldvarg182 ;
  void *tmp___1 ;
  struct efx_channel *ldvarg310 ;
  void *tmp___2 ;
  char *ldvarg312 ;
  void *tmp___3 ;
  size_t ldvarg311 ;
  char *ldvarg314 ;
  void *tmp___4 ;
  struct device *ldvarg313 ;
  void *tmp___5 ;
  struct device_attribute *ldvarg315 ;
  void *tmp___6 ;
  struct ifreq *ldvarg343 ;
  void *tmp___7 ;
  int ldvarg337 ;
    klee_make_symbolic(&ldvarg337, sizeof(int), "ldvarg337");
  struct ifla_vf_info *ldvarg339 ;
  void *tmp___8 ;
  u16 ldvarg326 ;
  struct netdev_phys_item_id *ldvarg341 ;
  void *tmp___9 ;
  u16 ldvarg331 ;
  struct sk_buff *ldvarg334 ;
  void *tmp___10 ;
  u8 *ldvarg321 ;
  void *tmp___11 ;
  void *ldvarg324 ;
  void *tmp___12 ;
  int ldvarg336 ;
    klee_make_symbolic(&ldvarg336, sizeof(int), "ldvarg336");
  int ldvarg322 ;
    klee_make_symbolic(&ldvarg322, sizeof(int), "ldvarg322");
  int ldvarg340 ;
    klee_make_symbolic(&ldvarg340, sizeof(int), "ldvarg340");
  u8 ldvarg323 ;
  netdev_features_t ldvarg329 ;
  struct napi_struct *ldvarg333 ;
  void *tmp___13 ;
  struct sk_buff *ldvarg327 ;
  void *tmp___14 ;
  int ldvarg332 ;
    klee_make_symbolic(&ldvarg332, sizeof(int), "ldvarg332");
  int ldvarg338 ;
    klee_make_symbolic(&ldvarg338, sizeof(int), "ldvarg338");
  u32 ldvarg325 ;
  struct rtnl_link_stats64 *ldvarg320 ;
  void *tmp___15 ;
  int ldvarg328 ;
    klee_make_symbolic(&ldvarg328, sizeof(int), "ldvarg328");
  u8 ldvarg330 ;
  int ldvarg342 ;
    klee_make_symbolic(&ldvarg342, sizeof(int), "ldvarg342");
  bool ldvarg335 ;
  unsigned long ldvarg346 ;
    klee_make_symbolic(&ldvarg346, sizeof(long), "ldvarg346");
  struct notifier_block *ldvarg344 ;
  void *tmp___16 ;
  void *ldvarg345 ;
  void *tmp___17 ;
  int tmp___18 ;
  int tmp___19 ;
  int tmp___20 ;
  int tmp___21 ;
  int tmp___22 ;
  int tmp___23 ;
  int tmp___24 ;
  int tmp___25 ;
  int tmp___26 ;
  int tmp___27 ;
  int tmp___28 ;

  {
  tmp = ldv_init_zalloc(32UL);
  ldvarg179 = (struct pci_device_id *)tmp;
  tmp___0 = ldv_init_zalloc(1UL);
  ldvarg180 = (char *)tmp___0;
  tmp___1 = ldv_init_zalloc(1UL);
  ldvarg182 = (char *)tmp___1;
  tmp___2 = ldv_init_zalloc(2176UL);
  ldvarg310 = (struct efx_channel *)tmp___2;
  tmp___3 = ldv_init_zalloc(1UL);
  ldvarg312 = (char *)tmp___3;
  tmp___4 = ldv_init_zalloc(1UL);
  ldvarg314 = (char *)tmp___4;
  tmp___5 = ldv_init_zalloc(1416UL);
  ldvarg313 = (struct device *)tmp___5;
  tmp___6 = ldv_init_zalloc(48UL);
  ldvarg315 = (struct device_attribute *)tmp___6;
  tmp___7 = ldv_init_zalloc(40UL);
  ldvarg343 = (struct ifreq *)tmp___7;
  tmp___8 = ldv_init_zalloc(64UL);
  ldvarg339 = (struct ifla_vf_info *)tmp___8;
  tmp___9 = ldv_init_zalloc(33UL);
  ldvarg341 = (struct netdev_phys_item_id *)tmp___9;
  tmp___10 = ldv_init_zalloc(232UL);
  ldvarg334 = (struct sk_buff *)tmp___10;
  tmp___11 = ldv_init_zalloc(1UL);
  ldvarg321 = (u8 *)tmp___11;
  tmp___12 = ldv_init_zalloc(1UL);
  ldvarg324 = tmp___12;
  tmp___13 = ldv_init_zalloc(280UL);
  ldvarg333 = (struct napi_struct *)tmp___13;
  tmp___14 = ldv_init_zalloc(232UL);
  ldvarg327 = (struct sk_buff *)tmp___14;
  tmp___15 = ldv_init_zalloc(184UL);
  ldvarg320 = (struct rtnl_link_stats64 *)tmp___15;
  tmp___16 = ldv_init_zalloc(24UL);
  ldvarg344 = (struct notifier_block *)tmp___16;
  tmp___17 = ldv_init_zalloc(1UL);
  ldvarg345 = tmp___17;
  ldv_initialize();
  ldv_memset((void *)(& ldvarg0), 0, 4UL);
  ldv_memset((void *)(& ldvarg178), 0, 4UL);
  ldv_memset((void *)(& ldvarg181), 0, 8UL);
  ldv_memset((void *)(& ldvarg311), 0, 8UL);
  ldv_memset((void *)(& ldvarg337), 0, 4UL);
  ldv_memset((void *)(& ldvarg326), 0, 2UL);
  ldv_memset((void *)(& ldvarg331), 0, 2UL);
  ldv_memset((void *)(& ldvarg336), 0, 4UL);
  ldv_memset((void *)(& ldvarg322), 0, 4UL);
  ldv_memset((void *)(& ldvarg340), 0, 4UL);
  ldv_memset((void *)(& ldvarg323), 0, 1UL);
  ldv_memset((void *)(& ldvarg329), 0, 8UL);
  ldv_memset((void *)(& ldvarg332), 0, 4UL);
  ldv_memset((void *)(& ldvarg338), 0, 4UL);
  ldv_memset((void *)(& ldvarg325), 0, 4UL);
  ldv_memset((void *)(& ldvarg328), 0, 4UL);
  ldv_memset((void *)(& ldvarg330), 0, 1UL);
  ldv_memset((void *)(& ldvarg342), 0, 4UL);
  ldv_memset((void *)(& ldvarg335), 0, 1UL);
  ldv_memset((void *)(& ldvarg346), 0, 8UL);
  ldv_state_variable_33 = 0;
  ldv_state_variable_32 = 0;
  ldv_state_variable_21 = 0;
  work_init_7();
  ldv_state_variable_7 = 1;
  ldv_state_variable_26 = 0;
  ldv_state_variable_17 = 0;
  work_init_2();
  ldv_state_variable_2 = 1;
  work_init_1();
  ldv_state_variable_1 = 1;
  ldv_state_variable_18 = 0;
  ldv_state_variable_30 = 0;
  ldv_state_variable_16 = 0;
  ldv_state_variable_27 = 0;
  ldv_state_variable_25 = 0;
  ldv_state_variable_28 = 0;
  ldv_state_variable_20 = 0;
  ldv_state_variable_14 = 0;
  ldv_state_variable_24 = 0;
  timer_init_10();
  ldv_state_variable_10 = 1;
  ldv_state_variable_31 = 0;
  ldv_state_variable_35 = 0;
  timer_init_11();
  ldv_state_variable_11 = 1;
  ldv_state_variable_22 = 0;
  ref_cnt = 0;
  ldv_state_variable_0 = 1;
  timer_init_13();
  ldv_state_variable_13 = 1;
  ldv_state_variable_23 = 0;
  ldv_state_variable_29 = 0;
  work_init_6();
  ldv_state_variable_6 = 1;
  ldv_state_variable_39 = 0;
  ldv_state_variable_36 = 0;
  work_init_3();
  ldv_state_variable_3 = 1;
  work_init_9();
  ldv_state_variable_9 = 1;
  timer_init_12();
  ldv_state_variable_12 = 1;
  ldv_state_variable_15 = 0;
  ldv_state_variable_38 = 0;
  work_init_8();
  ldv_state_variable_8 = 1;
  work_init_4();
  ldv_state_variable_4 = 1;
  ldv_state_variable_34 = 0;
  ldv_state_variable_37 = 0;
  ldv_state_variable_19 = 0;
  work_init_5();
  ldv_state_variable_5 = 1;
  ldv_58315: 
  tmp___18 = __VERIFIER_nondet_int();
  switch (tmp___18) {
  case 0: ;
  if (ldv_state_variable_33 != 0) {
    tmp___19 = __VERIFIER_nondet_int();
    switch (tmp___19) {
    case 0: ;
    if (ldv_state_variable_33 == 14) {
      ldv_retval_18 = efx_pm_thaw(efx_pm_ops_group1);
      if (ldv_retval_18 == 0) {
        ldv_state_variable_33 = 15;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 1: ;
    if (ldv_state_variable_33 == 2) {
      ldv_retval_17 = efx_pm_suspend(efx_pm_ops_group1);
      if (ldv_retval_17 == 0) {
        ldv_state_variable_33 = 3;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 2: ;
    if (ldv_state_variable_33 == 2) {
      ldv_retval_16 = efx_pm_poweroff(efx_pm_ops_group1);
      if (ldv_retval_16 == 0) {
        ldv_state_variable_33 = 4;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 3: ;
    if (ldv_state_variable_33 == 2) {
      ldv_retval_15 = efx_pm_freeze(efx_pm_ops_group1);
      if (ldv_retval_15 == 0) {
        ldv_state_variable_33 = 5;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 4: ;
    if (ldv_state_variable_33 == 12) {
      ldv_retval_14 = efx_pm_resume(efx_pm_ops_group1);
      if (ldv_retval_14 == 0) {
        ldv_state_variable_33 = 15;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 5: ;
    if (ldv_state_variable_33 == 13) {
      ldv_retval_13 = efx_pm_resume(efx_pm_ops_group1);
      if (ldv_retval_13 == 0) {
        ldv_state_variable_33 = 15;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 6: ;
    if (ldv_state_variable_33 == 3) {
      ldv_retval_12 = ldv_suspend_late_33();
      if (ldv_retval_12 == 0) {
        ldv_state_variable_33 = 6;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 7: ;
    if (ldv_state_variable_33 == 9) {
      ldv_retval_11 = ldv_restore_early_33();
      if (ldv_retval_11 == 0) {
        ldv_state_variable_33 = 13;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 8: ;
    if (ldv_state_variable_33 == 6) {
      ldv_retval_10 = ldv_resume_early_33();
      if (ldv_retval_10 == 0) {
        ldv_state_variable_33 = 12;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 9: ;
    if (ldv_state_variable_33 == 11) {
      ldv_retval_9 = ldv_thaw_early_33();
      if (ldv_retval_9 == 0) {
        ldv_state_variable_33 = 14;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 10: ;
    if (ldv_state_variable_33 == 7) {
      ldv_retval_8 = ldv_resume_noirq_33();
      if (ldv_retval_8 == 0) {
        ldv_state_variable_33 = 12;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 11: ;
    if (ldv_state_variable_33 == 5) {
      ldv_retval_7 = ldv_freeze_noirq_33();
      if (ldv_retval_7 == 0) {
        ldv_state_variable_33 = 10;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 12: ;
    if (ldv_state_variable_33 == 1) {
      ldv_retval_6 = ldv_prepare_33();
      if (ldv_retval_6 == 0) {
        ldv_state_variable_33 = 2;
        ref_cnt = ref_cnt + 1;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 13: ;
    if (ldv_state_variable_33 == 5) {
      ldv_retval_5 = ldv_freeze_late_33();
      if (ldv_retval_5 == 0) {
        ldv_state_variable_33 = 11;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 14: ;
    if (ldv_state_variable_33 == 10) {
      ldv_retval_4 = ldv_thaw_noirq_33();
      if (ldv_retval_4 == 0) {
        ldv_state_variable_33 = 14;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 15: ;
    if (ldv_state_variable_33 == 4) {
      ldv_retval_3 = ldv_poweroff_noirq_33();
      if (ldv_retval_3 == 0) {
        ldv_state_variable_33 = 8;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 16: ;
    if (ldv_state_variable_33 == 4) {
      ldv_retval_2 = ldv_poweroff_late_33();
      if (ldv_retval_2 == 0) {
        ldv_state_variable_33 = 9;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 17: ;
    if (ldv_state_variable_33 == 8) {
      ldv_retval_1 = ldv_restore_noirq_33();
      if (ldv_retval_1 == 0) {
        ldv_state_variable_33 = 13;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 18: ;
    if (ldv_state_variable_33 == 3) {
      ldv_retval_0 = ldv_suspend_noirq_33();
      if (ldv_retval_0 == 0) {
        ldv_state_variable_33 = 7;
      } else {

      }
    } else {

    }
    goto ldv_58185;
    case 19: ;
    if (ldv_state_variable_33 == 15) {
      ldv_complete_33();
      ldv_state_variable_33 = 1;
      ref_cnt = ref_cnt - 1;
    } else {

    }
    goto ldv_58185;
    default: 
    ldv_stop();
    }
    ldv_58185: ;
  } else {

  }
  goto ldv_58206;
  case 1: ;
  if (ldv_state_variable_32 != 0) {
    tmp___20 = __VERIFIER_nondet_int();
    switch (tmp___20) {
    case 0: ;
    if (ldv_state_variable_32 == 3) {
      efx_io_resume(efx_err_handlers_group0);
      ldv_state_variable_32 = 2;
    } else {

    }
    goto ldv_58209;
    case 1: ;
    if (ldv_state_variable_32 == 3) {
      efx_io_slot_reset(efx_err_handlers_group0);
      ldv_state_variable_32 = 3;
    } else {

    }
    if (ldv_state_variable_32 == 2) {
      efx_io_slot_reset(efx_err_handlers_group0);
      ldv_state_variable_32 = 2;
    } else {

    }
    if (ldv_state_variable_32 == 1) {
      efx_io_slot_reset(efx_err_handlers_group0);
      ldv_state_variable_32 = 1;
    } else {

    }
    goto ldv_58209;
    case 2: ;
    if (ldv_state_variable_32 == 3) {
      efx_io_error_detected(efx_err_handlers_group0, ldvarg0);
      ldv_state_variable_32 = 3;
    } else {

    }
    if (ldv_state_variable_32 == 2) {
      efx_io_error_detected(efx_err_handlers_group0, ldvarg0);
      ldv_state_variable_32 = 2;
    } else {

    }
    if (ldv_state_variable_32 == 1) {
      efx_io_error_detected(efx_err_handlers_group0, ldvarg0);
      ldv_state_variable_32 = 1;
    } else {

    }
    goto ldv_58209;
    case 3: ;
    if (ldv_state_variable_32 == 2) {
      ldv_suspend_32();
      ldv_state_variable_32 = 3;
    } else {

    }
    goto ldv_58209;
    case 4: ;
    if (ldv_state_variable_32 == 3) {
      ldv_release_32();
      ldv_state_variable_32 = 1;
      ref_cnt = ref_cnt - 1;
    } else {

    }
    if (ldv_state_variable_32 == 2) {
      ldv_release_32();
      ldv_state_variable_32 = 1;
      ref_cnt = ref_cnt - 1;
    } else {

    }
    goto ldv_58209;
    case 5: ;
    if (ldv_state_variable_32 == 1) {
      ldv_probe_32();
      ldv_state_variable_32 = 2;
      ref_cnt = ref_cnt + 1;
    } else {

    }
    goto ldv_58209;
    default: 
    ldv_stop();
    }
    ldv_58209: ;
  } else {

  }
  goto ldv_58206;
  case 2: ;
  if (ldv_state_variable_21 != 0) {
    ldv_main_exported_21();
  } else {

  }
  goto ldv_58206;
  case 3: ;
  goto ldv_58206;
  case 4: ;
  if (ldv_state_variable_26 != 0) {
    ldv_main_exported_26();
  } else {

  }
  goto ldv_58206;
  case 5: ;
  if (ldv_state_variable_17 != 0) {
    ldv_main_exported_17();
  } else {

  }
  goto ldv_58206;
  case 6: ;
  if (ldv_state_variable_2 != 0) {
    invoke_work_2();
  } else {

  }
  goto ldv_58206;
  case 7: ;
  if (ldv_state_variable_1 != 0) {
    invoke_work_1();
  } else {

  }
  goto ldv_58206;
  case 8: ;
  if (ldv_state_variable_18 != 0) {
    ldv_main_exported_18();
  } else {

  }
  goto ldv_58206;
  case 9: ;
  if (ldv_state_variable_30 != 0) {
    ldv_main_exported_30();
  } else {

  }
  goto ldv_58206;
  case 10: ;
  if (ldv_state_variable_16 != 0) {
    ldv_main_exported_16();
  } else {

  }
  goto ldv_58206;
  case 11: ;
  if (ldv_state_variable_27 != 0) {
    ldv_main_exported_27();
  } else {

  }
  goto ldv_58206;
  case 12: ;
  if (ldv_state_variable_25 != 0) {
    ldv_main_exported_25();
  } else {

  }
  goto ldv_58206;
  case 13: ;
  if (ldv_state_variable_28 != 0) {
    ldv_main_exported_28();
  } else {

  }
  goto ldv_58206;
  case 14: ;
  if (ldv_state_variable_20 != 0) {
    ldv_main_exported_20();
  } else {

  }
  goto ldv_58206;
  case 15: ;
  if (ldv_state_variable_14 != 0) {
    ldv_main_exported_14();
  } else {

  }
  goto ldv_58206;
  case 16: ;
  if (ldv_state_variable_24 != 0) {
    ldv_main_exported_24();
  } else {

  }
  goto ldv_58206;
  case 17: ;
  if (ldv_state_variable_10 != 0) {
    choose_timer_10();
  } else {

  }
  goto ldv_58206;
  case 18: ;
  if (ldv_state_variable_31 != 0) {
    tmp___21 = __VERIFIER_nondet_int();
    switch (tmp___21) {
    case 0: ;
    if (ldv_state_variable_31 == 1) {
      ldv_retval_19 = efx_pci_probe(efx_pci_driver_group1, (struct pci_device_id  const  *)ldvarg179);
      if (ldv_retval_19 == 0) {
        ldv_state_variable_31 = 2;
        ref_cnt = ref_cnt + 1;
      } else {

      }
    } else {

    }
    goto ldv_58234;
    case 1: ;
    if (ldv_state_variable_31 == 2) {
      efx_pci_sriov_configure(efx_pci_driver_group1, ldvarg178);
      ldv_state_variable_31 = 2;
    } else {

    }
    if (ldv_state_variable_31 == 1) {
      efx_pci_sriov_configure(efx_pci_driver_group1, ldvarg178);
      ldv_state_variable_31 = 1;
    } else {

    }
    goto ldv_58234;
    case 2: ;
    if (ldv_state_variable_31 == 2) {
      efx_pci_remove(efx_pci_driver_group1);
      ldv_state_variable_31 = 1;
    } else {

    }
    goto ldv_58234;
    case 3: ;
    if (ldv_state_variable_31 == 2) {
      ldv_shutdown_31();
      ldv_state_variable_31 = 2;
    } else {

    }
    goto ldv_58234;
    default: 
    ldv_stop();
    }
    ldv_58234: ;
  } else {

  }
  goto ldv_58206;
  case 19: ;
  if (ldv_state_variable_35 != 0) {
    tmp___22 = __VERIFIER_nondet_int();
    switch (tmp___22) {
    case 0: ;
    if (ldv_state_variable_35 == 1) {
      set_mcdi_log(dev_attr_mcdi_logging_group1, dev_attr_mcdi_logging_group0, (char const   *)ldvarg182,
                   ldvarg181);
      ldv_state_variable_35 = 1;
    } else {

    }
    goto ldv_58241;
    case 1: ;
    if (ldv_state_variable_35 == 1) {
      show_mcdi_log(dev_attr_mcdi_logging_group1, dev_attr_mcdi_logging_group0, ldvarg180);
      ldv_state_variable_35 = 1;
    } else {

    }
    goto ldv_58241;
    default: 
    ldv_stop();
    }
    ldv_58241: ;
  } else {

  }
  goto ldv_58206;
  case 20: ;
  if (ldv_state_variable_11 != 0) {
    choose_timer_11();
  } else {

  }
  goto ldv_58206;
  case 21: ;
  if (ldv_state_variable_22 != 0) {
    ldv_main_exported_22();
  } else {

  }
  goto ldv_58206;
  case 22: ;
  if (ldv_state_variable_0 != 0) {
    tmp___23 = __VERIFIER_nondet_int();
    switch (tmp___23) {
    case 0: ;
    if (ldv_state_variable_0 == 2 && ref_cnt == 0) {
      efx_exit_module();
      ldv_state_variable_0 = 3;
      goto ldv_final;
    } else {

    }
    goto ldv_58249;
    case 1: ;
    if (ldv_state_variable_0 == 1) {
      ldv_retval_20 = efx_init_module();
      if (ldv_retval_20 != 0) {
        ldv_state_variable_0 = 3;
        goto ldv_final;
      } else {

      }
      if (ldv_retval_20 == 0) {
        ldv_state_variable_0 = 2;
        ldv_state_variable_19 = 1;
        ldv_initialize_efx_phy_operations_19();
        ldv_state_variable_24 = 1;
        ldv_initialize_efx_nic_type_24();
        ldv_state_variable_37 = 1;
        ldv_state_variable_34 = 1;
        ldv_initialize_efx_phy_operations_34();
        ldv_state_variable_38 = 1;
        ldv_net_device_ops_38();
        ldv_state_variable_20 = 1;
        ldv_initialize_efx_phy_operations_20();
        ldv_state_variable_15 = 1;
        ldv_initialize_efx_channel_type_15();
        ldv_state_variable_14 = 1;
        ldv_initialize_efx_channel_type_14();
        ldv_state_variable_36 = 1;
        ldv_state_variable_28 = 1;
        ldv_initialize_efx_nic_type_28();
        ldv_state_variable_39 = 1;
        ldv_initialize_efx_channel_type_39();
        ldv_state_variable_27 = 1;
        ldv_initialize_efx_nic_type_27();
        ldv_state_variable_25 = 1;
        ldv_state_variable_29 = 1;
        ldv_initialize_efx_nic_type_29();
        ldv_state_variable_16 = 1;
        ldv_initialize_ptp_clock_info_16();
        ldv_state_variable_23 = 1;
        ldv_initialize_efx_nic_type_23();
        ldv_state_variable_30 = 1;
        ldv_state_variable_18 = 1;
        ldv_initialize_device_attribute_18();
        ldv_state_variable_22 = 1;
        ldv_initialize_ethtool_ops_22();
        ldv_state_variable_17 = 1;
        ldv_initialize_efx_phy_operations_17();
        ldv_state_variable_26 = 1;
        ldv_state_variable_21 = 1;
        ldv_initialize_efx_phy_operations_21();
        ldv_state_variable_32 = 1;
        ldv_initialize_pci_error_handlers_32();
        ldv_state_variable_33 = 1;
        ldv_dev_pm_ops_33();
        ldv_state_variable_35 = 1;
        ldv_initialize_device_attribute_35();
      } else {

      }
    } else {

    }
    goto ldv_58249;
    default: 
    ldv_stop();
    }
    ldv_58249: ;
  } else {

  }
  goto ldv_58206;
  case 23: ;
  goto ldv_58206;
  case 24: ;
  if (ldv_state_variable_23 != 0) {
    ldv_main_exported_23();
  } else {

  }
  goto ldv_58206;
  case 25: ;
  if (ldv_state_variable_29 != 0) {
    ldv_main_exported_29();
  } else {

  }
  goto ldv_58206;
  case 26: ;
  goto ldv_58206;
  case 27: ;
  if (ldv_state_variable_39 != 0) {
    tmp___24 = __VERIFIER_nondet_int();
    switch (tmp___24) {
    case 0: ;
    if (ldv_state_variable_39 == 1) {
      efx_get_channel_name(efx_default_channel_type_group0, ldvarg312, ldvarg311);
      ldv_state_variable_39 = 1;
    } else {

    }
    goto ldv_58258;
    case 1: ;
    if (ldv_state_variable_39 == 1) {
      efx_channel_dummy_op_void(efx_default_channel_type_group0);
      ldv_state_variable_39 = 1;
    } else {

    }
    goto ldv_58258;
    case 2: ;
    if (ldv_state_variable_39 == 1) {
      efx_copy_channel((struct efx_channel  const  *)ldvarg310);
      ldv_state_variable_39 = 1;
    } else {

    }
    goto ldv_58258;
    case 3: ;
    if (ldv_state_variable_39 == 1) {
      efx_channel_dummy_op_int(efx_default_channel_type_group0);
      ldv_state_variable_39 = 1;
    } else {

    }
    goto ldv_58258;
    default: 
    ldv_stop();
    }
    ldv_58258: ;
  } else {

  }
  goto ldv_58206;
  case 28: ;
  if (ldv_state_variable_36 != 0) {
    tmp___25 = __VERIFIER_nondet_int();
    switch (tmp___25) {
    case 0: ;
    if (ldv_state_variable_36 == 1) {
      show_phy_type(ldvarg313, ldvarg315, ldvarg314);
      ldv_state_variable_36 = 1;
    } else {

    }
    goto ldv_58265;
    default: 
    ldv_stop();
    }
    ldv_58265: ;
  } else {

  }
  goto ldv_58206;
  case 29: ;
  if (ldv_state_variable_3 != 0) {
    invoke_work_3();
  } else {

  }
  goto ldv_58206;
  case 30: ;
  goto ldv_58206;
  case 31: ;
  goto ldv_58206;
  case 32: ;
  if (ldv_state_variable_15 != 0) {
    ldv_main_exported_15();
  } else {

  }
  goto ldv_58206;
  case 33: ;
  if (ldv_state_variable_38 != 0) {
    tmp___26 = __VERIFIER_nondet_int();
    switch (tmp___26) {
    case 0: ;
    if (ldv_state_variable_38 == 3) {
      efx_ioctl(efx_netdev_ops_group1, ldvarg343, ldvarg342);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_ioctl(efx_netdev_ops_group1, ldvarg343, ldvarg342);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_ioctl(efx_netdev_ops_group1, ldvarg343, ldvarg342);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 1: ;
    if (ldv_state_variable_38 == 3) {
      efx_sriov_get_phys_port_id(efx_netdev_ops_group1, ldvarg341);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_sriov_get_phys_port_id(efx_netdev_ops_group1, ldvarg341);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_sriov_get_phys_port_id(efx_netdev_ops_group1, ldvarg341);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 2: ;
    if (ldv_state_variable_38 == 3) {
      efx_sriov_get_vf_config(efx_netdev_ops_group1, ldvarg340, ldvarg339);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_sriov_get_vf_config(efx_netdev_ops_group1, ldvarg340, ldvarg339);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_sriov_get_vf_config(efx_netdev_ops_group1, ldvarg340, ldvarg339);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 3: ;
    if (ldv_state_variable_38 == 3) {
      efx_sriov_set_vf_link_state(efx_netdev_ops_group1, ldvarg338, ldvarg337);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_sriov_set_vf_link_state(efx_netdev_ops_group1, ldvarg338, ldvarg337);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_sriov_set_vf_link_state(efx_netdev_ops_group1, ldvarg338, ldvarg337);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 4: ;
    if (ldv_state_variable_38 == 2) {
      ldv_retval_22 = efx_net_open(efx_netdev_ops_group1);
      if (ldv_retval_22 == 0) {
        ldv_state_variable_38 = 3;
      } else {

      }
    } else {

    }
    goto ldv_58273;
    case 5: ;
    if (ldv_state_variable_38 == 3) {
      efx_sriov_set_vf_spoofchk(efx_netdev_ops_group1, ldvarg336, (int )ldvarg335);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_sriov_set_vf_spoofchk(efx_netdev_ops_group1, ldvarg336, (int )ldvarg335);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_sriov_set_vf_spoofchk(efx_netdev_ops_group1, ldvarg336, (int )ldvarg335);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 6: ;
    if (ldv_state_variable_38 == 3) {
      efx_hard_start_xmit(ldvarg334, efx_netdev_ops_group1);
      ldv_state_variable_38 = 3;
    } else {

    }
    goto ldv_58273;
    case 7: ;
    if (ldv_state_variable_38 == 3) {
      efx_net_stop(efx_netdev_ops_group1);
      ldv_state_variable_38 = 2;
    } else {

    }
    goto ldv_58273;
    case 8: ;
    if (ldv_state_variable_38 == 3) {
      efx_set_rx_mode(efx_netdev_ops_group1);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_set_rx_mode(efx_netdev_ops_group1);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_set_rx_mode(efx_netdev_ops_group1);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 9: ;
    if (ldv_state_variable_38 == 3) {
      eth_validate_addr(efx_netdev_ops_group1);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      eth_validate_addr(efx_netdev_ops_group1);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      eth_validate_addr(efx_netdev_ops_group1);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 10: ;
    if (ldv_state_variable_38 == 3) {
      efx_busy_poll(ldvarg333);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_busy_poll(ldvarg333);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_busy_poll(ldvarg333);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 11: ;
    if (ldv_state_variable_38 == 3) {
      efx_sriov_set_vf_vlan(efx_netdev_ops_group1, ldvarg332, (int )ldvarg331, (int )ldvarg330);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_sriov_set_vf_vlan(efx_netdev_ops_group1, ldvarg332, (int )ldvarg331, (int )ldvarg330);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_sriov_set_vf_vlan(efx_netdev_ops_group1, ldvarg332, (int )ldvarg331, (int )ldvarg330);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 12: ;
    if (ldv_state_variable_38 == 3) {
      efx_netpoll(efx_netdev_ops_group1);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_netpoll(efx_netdev_ops_group1);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_netpoll(efx_netdev_ops_group1);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 13: ;
    if (ldv_state_variable_38 == 3) {
      efx_set_features(efx_netdev_ops_group1, ldvarg329);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_set_features(efx_netdev_ops_group1, ldvarg329);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_set_features(efx_netdev_ops_group1, ldvarg329);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 14: ;
    if (ldv_state_variable_38 == 3) {
      efx_change_mtu(efx_netdev_ops_group1, ldvarg328);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_change_mtu(efx_netdev_ops_group1, ldvarg328);
      ldv_state_variable_38 = 2;
    } else {

    }
    goto ldv_58273;
    case 15: ;
    if (ldv_state_variable_38 == 3) {
      efx_filter_rfs(efx_netdev_ops_group1, (struct sk_buff  const  *)ldvarg327, (int )ldvarg326,
                     ldvarg325);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_filter_rfs(efx_netdev_ops_group1, (struct sk_buff  const  *)ldvarg327, (int )ldvarg326,
                     ldvarg325);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_filter_rfs(efx_netdev_ops_group1, (struct sk_buff  const  *)ldvarg327, (int )ldvarg326,
                     ldvarg325);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 16: ;
    if (ldv_state_variable_38 == 3) {
      efx_set_mac_address(efx_netdev_ops_group1, ldvarg324);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_set_mac_address(efx_netdev_ops_group1, ldvarg324);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_set_mac_address(efx_netdev_ops_group1, ldvarg324);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 17: ;
    if (ldv_state_variable_38 == 3) {
      efx_setup_tc(efx_netdev_ops_group1, (int )ldvarg323);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_setup_tc(efx_netdev_ops_group1, (int )ldvarg323);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_setup_tc(efx_netdev_ops_group1, (int )ldvarg323);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 18: ;
    if (ldv_state_variable_38 == 3) {
      efx_sriov_set_vf_mac(efx_netdev_ops_group1, ldvarg322, ldvarg321);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_sriov_set_vf_mac(efx_netdev_ops_group1, ldvarg322, ldvarg321);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_sriov_set_vf_mac(efx_netdev_ops_group1, ldvarg322, ldvarg321);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 19: ;
    if (ldv_state_variable_38 == 3) {
      efx_net_stats(efx_netdev_ops_group1, ldvarg320);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_net_stats(efx_netdev_ops_group1, ldvarg320);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_net_stats(efx_netdev_ops_group1, ldvarg320);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 20: ;
    if (ldv_state_variable_38 == 3) {
      efx_watchdog(efx_netdev_ops_group1);
      ldv_state_variable_38 = 3;
    } else {

    }
    if (ldv_state_variable_38 == 2) {
      efx_watchdog(efx_netdev_ops_group1);
      ldv_state_variable_38 = 2;
    } else {

    }
    if (ldv_state_variable_38 == 1) {
      efx_watchdog(efx_netdev_ops_group1);
      ldv_state_variable_38 = 1;
    } else {

    }
    goto ldv_58273;
    case 21: ;
    if (ldv_state_variable_38 == 2) {
      ldv_ndo_uninit_38();
      ldv_state_variable_38 = 1;
      ref_cnt = ref_cnt - 1;
    } else {

    }
    goto ldv_58273;
    case 22: ;
    if (ldv_state_variable_38 == 1) {
      ldv_retval_21 = ldv_ndo_init_38();
      if (ldv_retval_21 == 0) {
        ldv_state_variable_38 = 2;
        ref_cnt = ref_cnt + 1;
      } else {

      }
    } else {

    }
    goto ldv_58273;
    default: 
    ldv_stop();
    }
    ldv_58273: ;
  } else {

  }
  goto ldv_58206;
  case 34: ;
  goto ldv_58206;
  case 35: ;
  if (ldv_state_variable_4 != 0) {
    invoke_work_4();
  } else {

  }
  goto ldv_58206;
  case 36: ;
  if (ldv_state_variable_34 != 0) {
    tmp___27 = __VERIFIER_nondet_int();
    switch (tmp___27) {
    case 0: ;
    if (ldv_state_variable_34 == 3) {
      efx_port_dummy_op_void(efx_dummy_phy_operations_group0);
      ldv_state_variable_34 = 3;
    } else {

    }
    if (ldv_state_variable_34 == 2) {
      efx_port_dummy_op_void(efx_dummy_phy_operations_group0);
      ldv_state_variable_34 = 2;
    } else {

    }
    if (ldv_state_variable_34 == 1) {
      efx_port_dummy_op_void(efx_dummy_phy_operations_group0);
      ldv_state_variable_34 = 1;
    } else {

    }
    goto ldv_58301;
    case 1: ;
    if (ldv_state_variable_34 == 3) {
      efx_port_dummy_op_int(efx_dummy_phy_operations_group0);
      ldv_state_variable_34 = 3;
    } else {

    }
    if (ldv_state_variable_34 == 2) {
      efx_port_dummy_op_int(efx_dummy_phy_operations_group0);
      ldv_state_variable_34 = 2;
    } else {

    }
    if (ldv_state_variable_34 == 1) {
      efx_port_dummy_op_int(efx_dummy_phy_operations_group0);
      ldv_state_variable_34 = 1;
    } else {

    }
    goto ldv_58301;
    case 2: ;
    if (ldv_state_variable_34 == 3) {
      efx_port_dummy_op_poll(efx_dummy_phy_operations_group0);
      ldv_state_variable_34 = 3;
    } else {

    }
    if (ldv_state_variable_34 == 2) {
      efx_port_dummy_op_poll(efx_dummy_phy_operations_group0);
      ldv_state_variable_34 = 2;
    } else {

    }
    if (ldv_state_variable_34 == 1) {
      efx_port_dummy_op_poll(efx_dummy_phy_operations_group0);
      ldv_state_variable_34 = 1;
    } else {

    }
    goto ldv_58301;
    case 3: ;
    if (ldv_state_variable_34 == 2) {
      ldv_retval_23 = efx_port_dummy_op_int(efx_dummy_phy_operations_group0);
      if (ldv_retval_23 == 0) {
        ldv_state_variable_34 = 3;
      } else {

      }
    } else {

    }
    goto ldv_58301;
    case 4: ;
    if (ldv_state_variable_34 == 3) {
      ldv_release_34();
      ldv_state_variable_34 = 1;
      ref_cnt = ref_cnt - 1;
    } else {

    }
    if (ldv_state_variable_34 == 2) {
      ldv_release_34();
      ldv_state_variable_34 = 1;
      ref_cnt = ref_cnt - 1;
    } else {

    }
    goto ldv_58301;
    case 5: ;
    if (ldv_state_variable_34 == 1) {
      ldv_setup_34();
      ldv_state_variable_34 = 2;
      ref_cnt = ref_cnt + 1;
    } else {

    }
    goto ldv_58301;
    default: 
    ldv_stop();
    }
    ldv_58301: ;
  } else {

  }
  goto ldv_58206;
  case 37: ;
  if (ldv_state_variable_37 != 0) {
    tmp___28 = __VERIFIER_nondet_int();
    switch (tmp___28) {
    case 0: ;
    if (ldv_state_variable_37 == 1) {
      efx_netdev_event(ldvarg344, ldvarg346, ldvarg345);
      ldv_state_variable_37 = 1;
    } else {

    }
    goto ldv_58310;
    default: 
    ldv_stop();
    }
    ldv_58310: ;
  } else {

  }
  goto ldv_58206;
  case 38: ;
  if (ldv_state_variable_19 != 0) {
    ldv_main_exported_19();
  } else {

  }
  goto ldv_58206;
  case 39: ;
  goto ldv_58206;
  default: 
  ldv_stop();
  }
  ldv_58206: ;
  goto ldv_58315;
  ldv_final: 
  ldv_check_final_state();
  return 0;
}
}
bool ldv_queue_work_on_5(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                         struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_6(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                 struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_7(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                         struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_8(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_9(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                 struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_10(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_11(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_12(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_13(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_14(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_15(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_16(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mod_timer_17(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_10(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
__inline static int ldv_mutex_is_locked_18(struct mutex *lock ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_is_locked(lock);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_is_locked_mac_lock_of_efx_nic(lock);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_19(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_20(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_21(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_22(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_23(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_24(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_25(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_26(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_27(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_28(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_29(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
bool ldv_cancel_delayed_work_sync_30(struct delayed_work *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___6 ldv_func_res ;
  bool tmp ;

  {
  tmp = cancel_delayed_work_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_work_7(& ldv_func_arg1->work);
  return (ldv_func_res);
}
}
bool ldv_cancel_work_sync_31(struct work_struct *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___7 ldv_func_res ;
  bool tmp ;

  {
  tmp = cancel_work_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_work_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_32(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_33(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_34(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___8 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mac_lock_of_efx_nic(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_35(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_36(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_37(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_38(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_39(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_40(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_41(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_42(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_destroy_workqueue_43(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  destroy_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_cancel_work_sync_44(struct work_struct *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___9 ldv_func_res ;
  bool tmp ;

  {
  tmp = cancel_work_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_work_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_45(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_46(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
int ldv___pci_register_driver_47(struct pci_driver *ldv_func_arg1 , struct module *ldv_func_arg2 ,
                                 char const   *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___10 ldv_func_res ;
  int tmp ;

  {
  tmp = __pci_register_driver(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  ldv_state_variable_31 = 1;
  ldv_pci_driver_31();
  return (ldv_func_res);
}
}
void ldv_destroy_workqueue_48(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  destroy_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
void ldv_pci_unregister_driver_49(struct pci_driver *ldv_func_arg1 ) 
{ 


  {
  pci_unregister_driver(ldv_func_arg1);
  ldv_state_variable_31 = 0;
  return;
}
}
void ldv_destroy_workqueue_50(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  destroy_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
extern unsigned long find_first_bit(unsigned long const   * , unsigned long  ) ;
__inline static __u64 __le64_to_cpup(__le64 const   *p ) 
{ 


  {
  return ((__u64 )*p);
}
}
__inline static __u32 __le32_to_cpup(__le32 const   *p ) 
{ 


  {
  return ((__u32 )*p);
}
}
__inline static __u16 __le16_to_cpup(__le16 const   *p ) 
{ 


  {
  return ((__u16 )*p);
}
}
int ldv_mutex_trylock_109(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_107(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_110(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_111(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_106(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_108(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_112(struct mutex *ldv_func_arg1 ) ;
extern unsigned long _raw_spin_lock_irqsave(raw_spinlock_t * ) ;
extern void _raw_spin_unlock_irqrestore(raw_spinlock_t * , unsigned long  ) ;
__inline static void spin_unlock_irqrestore(spinlock_t *lock , unsigned long flags ) 
{ 


  {
  _raw_spin_unlock_irqrestore(& lock->__annonCompField17.rlock, flags);
  return;
}
}
bool ldv_queue_work_on_101(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_103(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_102(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_105(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_104(struct workqueue_struct *ldv_func_arg1 ) ;
__inline static unsigned int __readl(void const volatile   *addr ) 
{ 
  unsigned int ret ;
    klee_make_symbolic(&ret, sizeof(int), "ret");

  {
  __asm__  volatile   ("movl %1,%0": "=r" (ret): "m" (*((unsigned int volatile   *)addr)));
  return (ret);
}
}
__inline static unsigned long readq(void const volatile   *addr ) 
{ 
  unsigned long ret ;

  {
  __asm__  volatile   ("movq %1,%0": "=r" (ret): "m" (*((unsigned long volatile   *)addr)): "memory");
  return (ret);
}
}
extern int request_threaded_irq(unsigned int  , irqreturn_t (*)(int  , void * ) ,
                                irqreturn_t (*)(int  , void * ) , unsigned long  ,
                                char const   * , void * ) ;
__inline static int request_irq(unsigned int irq , irqreturn_t (*handler)(int  , void * ) ,
                                unsigned long flags , char const   *name , void *dev ) 
{ 
  int tmp ;

  {
  tmp = request_threaded_irq(irq, handler, (irqreturn_t (*)(int  , void * ))0, flags,
                             name, dev);
  return (tmp);
}
}
extern void free_irq(unsigned int  , void * ) ;
extern void *dma_alloc_attrs(struct device * , size_t  , dma_addr_t * , gfp_t  , struct dma_attrs * ) ;
extern void dma_free_attrs(struct device * , size_t  , void * , dma_addr_t  , struct dma_attrs * ) ;
__inline static void *dma_zalloc_coherent(struct device *dev , size_t size , dma_addr_t *dma_handle ,
                                          gfp_t flag ) 
{ 
  void *ret ;
  void *tmp ;

  {
  tmp = dma_alloc_attrs(dev, size, dma_handle, flag | 32768U, (struct dma_attrs *)0);
  ret = tmp;
  return (ret);
}
}
extern struct cpu_rmap *alloc_cpu_rmap(unsigned int  , gfp_t  ) ;
__inline static struct cpu_rmap *alloc_irq_cpu_rmap(unsigned int size ) 
{ 
  struct cpu_rmap *tmp ;

  {
  tmp = alloc_cpu_rmap(size, 208U);
  return (tmp);
}
}
extern void free_irq_cpu_rmap(struct cpu_rmap * ) ;
extern int irq_cpu_rmap_add(struct cpu_rmap * , int  ) ;
__inline static efx_qword_t *efx_event(struct efx_channel *channel , unsigned int index ) 
{ 


  {
  return ((efx_qword_t *)channel->eventq.buf.addr + (unsigned long )(channel->eventq_mask & index));
}
}
__inline static int efx_event_present(efx_qword_t *event ) 
{ 


  {
  return (event->dword[0].u32[0] != 4294967295U && event->dword[1].u32[0] != 4294967295U);
}
}
void efx_nic_event_test_start(struct efx_channel *channel ) ;
bool efx_nic_event_present(struct efx_channel *channel ) ;
void efx_nic_irq_test_start(struct efx_nic *efx ) ;
int efx_nic_alloc_buffer(struct efx_nic *efx , struct efx_buffer *buffer , unsigned int len ,
                         gfp_t gfp_flags ) ;
void efx_nic_free_buffer(struct efx_nic *efx , struct efx_buffer *buffer ) ;
size_t efx_nic_get_regs_len(struct efx_nic *efx ) ;
void efx_nic_get_regs(struct efx_nic *efx , void *buf ) ;
size_t efx_nic_describe_stats(struct efx_hw_stat_desc  const  *desc , size_t count ,
                              unsigned long const   *mask , u8 *names ) ;
void efx_nic_update_stats(struct efx_hw_stat_desc  const  *desc , size_t count , unsigned long const   *mask ,
                          u64 *stats , void const   *dma_buf , bool accumulate ) ;
void efx_nic_fix_nodesc_drop_stat(struct efx_nic *efx , u64 *rx_nodesc_drops ) ;
__inline static __le32 _efx_readd(struct efx_nic *efx , unsigned int reg ) 
{ 
  unsigned int tmp ;

  {
  tmp = __readl((void const volatile   *)efx->membase + (unsigned long )reg);
  return (tmp);
}
}
__inline static void efx_reado(struct efx_nic *efx , efx_oword_t *value , unsigned int reg ) 
{ 
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
  tmp = spinlock_check(& efx->biu_lock);
  flags = _raw_spin_lock_irqsave(tmp);
  value->u32[0] = _efx_readd(efx, reg);
  value->u32[1] = _efx_readd(efx, reg + 4U);
  value->u32[2] = _efx_readd(efx, reg + 8U);
  value->u32[3] = _efx_readd(efx, reg + 12U);
  spin_unlock_irqrestore(& efx->biu_lock, flags);
  return;
}
}
__inline static void efx_sram_readq(struct efx_nic *efx , void *membase , efx_qword_t *value ,
                                    unsigned int index ) 
{ 
  unsigned int addr ;
  unsigned long flags ;
  raw_spinlock_t *tmp ;
  unsigned long tmp___0 ;

  {
  addr = index * 8U;
  tmp = spinlock_check(& efx->biu_lock);
  flags = _raw_spin_lock_irqsave(tmp);
  tmp___0 = readq((void const volatile   *)membase + (unsigned long )addr);
  value->u64[0] = (unsigned long long )tmp___0;
  spin_unlock_irqrestore(& efx->biu_lock, flags);
  return;
}
}
__inline static void efx_readd(struct efx_nic *efx , efx_dword_t *value , unsigned int reg ) 
{ 


  {
  value->u32[0] = _efx_readd(efx, reg);
  return;
}
}
__inline static void efx_reado_table(struct efx_nic *efx , efx_oword_t *value , unsigned int reg ,
                                     unsigned int index ) 
{ 


  {
  efx_reado(efx, value, index * 16U + reg);
  return;
}
}
int efx_nic_alloc_buffer(struct efx_nic *efx , struct efx_buffer *buffer , unsigned int len ,
                         gfp_t gfp_flags ) 
{ 


  {
  buffer->addr = dma_zalloc_coherent(& (efx->pci_dev)->dev, (size_t )len, & buffer->dma_addr,
                                     gfp_flags);
  if ((unsigned long )buffer->addr == (unsigned long )((void *)0)) {
    return (-12);
  } else {

  }
  buffer->len = len;
  return (0);
}
}
void efx_nic_free_buffer(struct efx_nic *efx , struct efx_buffer *buffer ) 
{ 


  {
  if ((unsigned long )buffer->addr != (unsigned long )((void *)0)) {
    dma_free_attrs(& (efx->pci_dev)->dev, (size_t )buffer->len, buffer->addr, buffer->dma_addr,
                   (struct dma_attrs *)0);
    buffer->addr = (void *)0;
  } else {

  }
  return;
}
}
bool efx_nic_event_present(struct efx_channel *channel ) 
{ 
  efx_qword_t *tmp ;
  int tmp___0 ;

  {
  tmp = efx_event(channel, channel->eventq_read_ptr);
  tmp___0 = efx_event_present(tmp);
  return (tmp___0 != 0);
}
}
void efx_nic_event_test_start(struct efx_channel *channel ) 
{ 


  {
  channel->event_test_cpu = -1;
  __asm__  volatile   ("": : : "memory");
  (*(((channel->efx)->type)->ev_test_generate))(channel);
  return;
}
}
void efx_nic_irq_test_start(struct efx_nic *efx ) 
{ 


  {
  efx->last_irq_cpu = -1;
  __asm__  volatile   ("": : : "memory");
  (*((efx->type)->irq_test_generate))(efx);
  return;
}
}
int efx_nic_init_interrupt(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;
  unsigned int n_irqs ;
    klee_make_symbolic(&n_irqs, sizeof(int), "n_irqs");
  int rc ;
  unsigned int tmp ;

  {
  if ((unsigned int )efx->interrupt_mode > 1U) {
    rc = request_irq((unsigned int )efx->legacy_irq, (efx->type)->irq_handle_legacy,
                     128UL, (char const   *)(& efx->name), (void *)efx);
    if (rc != 0) {
      if ((int )efx->msg_enable & 1) {
        netdev_err((struct net_device  const  *)efx->net_dev, "failed to hook legacy IRQ %d\n",
                   (efx->pci_dev)->irq);
      } else {

      }
      goto fail1;
    } else {

    }
    return (0);
  } else {

  }
  if ((unsigned int )efx->interrupt_mode == 0U) {
    (efx->net_dev)->rx_cpu_rmap = alloc_irq_cpu_rmap(efx->n_rx_channels);
    if ((unsigned long )(efx->net_dev)->rx_cpu_rmap == (unsigned long )((struct cpu_rmap *)0)) {
      rc = -12;
      goto fail1;
    } else {

    }
  } else {

  }
  n_irqs = 0U;
  channel = efx->channel[0];
  goto ldv_56391;
  ldv_56390: 
  rc = request_irq((unsigned int )channel->irq, (efx->type)->irq_handle_msi, 256UL,
                   (char const   *)(& efx->msi_context[channel->channel].name), (void *)(& efx->msi_context) + (unsigned long )channel->channel);
  if (rc != 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to hook IRQ %d\n",
                 channel->irq);
    } else {

    }
    goto fail2;
  } else {

  }
  n_irqs = n_irqs + 1U;
  if ((unsigned int )efx->interrupt_mode == 0U && (unsigned int )channel->channel < efx->n_rx_channels) {
    rc = irq_cpu_rmap_add((efx->net_dev)->rx_cpu_rmap, channel->irq);
    if (rc != 0) {
      goto fail2;
    } else {

    }
  } else {

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56391: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56390;
  } else {

  }

  return (0);
  fail2: 
  free_irq_cpu_rmap((efx->net_dev)->rx_cpu_rmap);
  (efx->net_dev)->rx_cpu_rmap = (struct cpu_rmap *)0;
  channel = efx->channel[0];
  goto ldv_56395;
  ldv_56394: 
  tmp = n_irqs;
  n_irqs = n_irqs - 1U;
  if (tmp == 0U) {
    goto ldv_56393;
  } else {

  }
  free_irq((unsigned int )channel->irq, (void *)(& efx->msi_context) + (unsigned long )channel->channel);
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56395: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56394;
  } else {

  }
  ldv_56393: ;
  fail1: ;
  return (rc);
}
}
void efx_nic_fini_interrupt(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;

  {
  free_irq_cpu_rmap((efx->net_dev)->rx_cpu_rmap);
  (efx->net_dev)->rx_cpu_rmap = (struct cpu_rmap *)0;
  if ((unsigned int )efx->interrupt_mode <= 1U) {
    channel = efx->channel[0];
    goto ldv_56401;
    ldv_56400: 
    free_irq((unsigned int )channel->irq, (void *)(& efx->msi_context) + (unsigned long )channel->channel);
    channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
    ldv_56401: ;
    if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
      goto ldv_56400;
    } else {

    }

  } else {
    free_irq((unsigned int )efx->legacy_irq, (void *)efx);
  }
  return;
}
}
static struct efx_nic_reg  const  efx_nic_regs[86U]  = 
  {      {0U, 1U, 3U}, 
        {16U, 1U, 3U}, 
        {32U, 2U, 3U}, 
        {48U, 1U, 3U}, 
        {64U, 2U, 3U}, 
        {192U, 1U, 3U}, 
        {256U, 3U, 3U}, 
        {256U, 1U, 2U}, 
        {272U, 1U, 2U}, 
        {288U, 1U, 2U}, 
        {304U, 1U, 2U}, 
        {320U, 1U, 2U}, 
        {512U, 1U, 2U}, 
        {528U, 1U, 2U}, 
        {544U, 1U, 2U}, 
        {592U, 2U, 3U}, 
        {608U, 1U, 3U}, 
        {624U, 1U, 3U}, 
        {768U, 1U, 3U}, 
        {784U, 1U, 3U}, 
        {800U, 1U, 2U}, 
        {816U, 1U, 2U}, 
        {832U, 1U, 2U}, 
        {1104U, 1U, 3U}, 
        {1120U, 1U, 3U}, 
        {1136U, 1U, 3U}, 
        {1536U, 1U, 3U}, 
        {1552U, 1U, 3U}, 
        {1568U, 1U, 3U}, 
        {1584U, 1U, 3U}, 
        {1632U, 1U, 3U}, 
        {1648U, 1U, 3U}, 
        {2048U, 1U, 3U}, 
        {2064U, 2U, 3U}, 
        {2112U, 1U, 3U}, 
        {2128U, 1U, 3U}, 
        {2144U, 2U, 3U}, 
        {2192U, 1U, 1U}, 
        {2256U, 3U, 3U}, 
        {2272U, 3U, 3U}, 
        {2288U, 3U, 3U}, 
        {2592U, 1U, 3U}, 
        {2608U, 1U, 1U}, 
        {2640U, 1U, 3U}, 
        {2688U, 1U, 3U}, 
        {2704U, 2U, 3U}, 
        {2784U, 2U, 2U}, 
        {2800U, 2U, 3U}, 
        {3072U, 1U, 2U}, 
        {3088U, 1U, 2U}, 
        {3104U, 1U, 2U}, 
        {3120U, 1U, 2U}, 
        {3136U, 1U, 2U}, 
        {3168U, 1U, 2U}, 
        {3200U, 1U, 2U}, 
        {3216U, 2U, 2U}, 
        {3232U, 1U, 2U}, 
        {3248U, 1U, 2U}, 
        {3584U, 1U, 2U}, 
        {3600U, 1U, 2U}, 
        {3648U, 1U, 2U}, 
        {3840U, 1U, 2U}, 
        {3856U, 1U, 2U}, 
        {3872U, 1U, 2U}, 
        {3888U, 1U, 2U}, 
        {3904U, 1U, 2U}, 
        {3920U, 1U, 2U}, 
        {3936U, 1U, 2U}, 
        {3952U, 1U, 2U}, 
        {4352U, 2U, 2U}, 
        {4608U, 1U, 2U}, 
        {4624U, 1U, 2U}, 
        {4640U, 1U, 2U}, 
        {4656U, 1U, 2U}, 
        {4672U, 1U, 2U}, 
        {4688U, 1U, 2U}, 
        {4720U, 1U, 2U}, 
        {4752U, 1U, 2U}, 
        {4816U, 1U, 2U}, 
        {4832U, 1U, 2U}, 
        {4864U, 1U, 2U}, 
        {4880U, 1U, 2U}, 
        {4896U, 1U, 2U}, 
        {0U, 4U, 4U}, 
        {512U, 4U, 4U}, 
        {516U, 4U, 4U}};
static struct efx_nic_reg_table  const  efx_nic_reg_tables[23U]  = 
  {      {2816U, 2U, 2U, 16U, 16U}, 
        {4096U, 2U, 2U, 16U, 16U}, 
        {71680U, 1U, 1U, 16U, 4U}, 
        {15990784U, 2U, 2U, 16U, 4096U}, 
        {15990784U, 3U, 3U, 16U, 1024U}, 
        {71936U, 1U, 1U, 16U, 8U}, 
        {16056320U, 2U, 2U, 16U, 4096U}, 
        {16056320U, 3U, 3U, 16U, 1024U}, 
        {72192U, 1U, 1U, 16U, 4U}, 
        {16121856U, 2U, 2U, 16U, 4096U}, 
        {16121856U, 3U, 3U, 16U, 1024U}, 
        {98304U, 1U, 1U, 8U, 1024U}, 
        {8388608U, 2U, 3U, 8U, 1024U}, 
        {15728656U, 3U, 3U, 32U, 512U}, 
        {16187392U, 2U, 2U, 16U, 4096U}, 
        {16187392U, 3U, 3U, 16U, 1024U}, 
        {16252928U, 2U, 2U, 16U, 4096U}, 
        {16252928U, 3U, 3U, 16U, 1024U}, 
        {16449536U, 2U, 3U, 16U, 128U}, 
        {16646144U, 3U, 3U, 16U, 512U}, 
        {16711680U, 3U, 3U, 4U, 512U}, 
        {15728640U, 2U, 3U, 32U, 8192U}, 
        {16U, 4U, 4U, 4U, 8U}};
size_t efx_nic_get_regs_len(struct efx_nic *efx ) 
{ 
  struct efx_nic_reg  const  *reg ;
  struct efx_nic_reg_table  const  *table ;
  size_t len ;
  size_t __min1 ;
  size_t __min2 ;

  {
  len = 0UL;
  reg = (struct efx_nic_reg  const  *)(& efx_nic_regs);
  goto ldv_56424;
  ldv_56423: ;
  if ((int )(efx->type)->revision >= (int )reg->min_revision && (int )(efx->type)->revision <= (int )reg->max_revision) {
    len = len + 16UL;
  } else {

  }
  reg = reg + 1;
  ldv_56424: ;
  if ((unsigned long )reg < (unsigned long )((struct efx_nic_reg  const  *)(& efx_nic_regs) + 86UL)) {
    goto ldv_56423;
  } else {

  }
  table = (struct efx_nic_reg_table  const  *)(& efx_nic_reg_tables);
  goto ldv_56432;
  ldv_56431: ;
  if ((int )(efx->type)->revision >= (int )table->min_revision && (int )(efx->type)->revision <= (int )table->max_revision) {
    __min1 = (size_t )table->step;
    __min2 = 16UL;
    len = (size_t )table->rows * (__min1 < __min2 ? __min1 : __min2) + len;
  } else {

  }
  table = table + 1;
  ldv_56432: ;
  if ((unsigned long )table < (unsigned long )((struct efx_nic_reg_table  const  *)(& efx_nic_reg_tables) + 23UL)) {
    goto ldv_56431;
  } else {

  }

  return (len);
}
}
void efx_nic_get_regs(struct efx_nic *efx , void *buf ) 
{ 
  struct efx_nic_reg  const  *reg ;
  struct efx_nic_reg_table  const  *table ;
  size_t size ;
  size_t i ;
  size_t __min1 ;
  size_t __min2 ;
  int __ret_warn_on ;
  long tmp ;

  {
  reg = (struct efx_nic_reg  const  *)(& efx_nic_regs);
  goto ldv_56443;
  ldv_56442: ;
  if ((int )(efx->type)->revision >= (int )reg->min_revision && (int )(efx->type)->revision <= (int )reg->max_revision) {
    efx_reado(efx, (efx_oword_t *)buf, (unsigned int )reg->offset);
    buf = buf + 16UL;
  } else {

  }
  reg = reg + 1;
  ldv_56443: ;
  if ((unsigned long )reg < (unsigned long )((struct efx_nic_reg  const  *)(& efx_nic_regs) + 86UL)) {
    goto ldv_56442;
  } else {

  }
  table = (struct efx_nic_reg_table  const  *)(& efx_nic_reg_tables);
  goto ldv_56465;
  ldv_56464: ;
  if ((int )(efx->type)->revision < (int )table->min_revision || (int )(efx->type)->revision > (int )table->max_revision) {
    goto ldv_56449;
  } else {

  }
  __min1 = (size_t )table->step;
  __min2 = 16UL;
  size = __min1 < __min2 ? __min1 : __min2;
  i = 0UL;
  goto ldv_56462;
  ldv_56461: ;
  switch ((int )table->step) {
  case 4: 
  efx_readd(efx, (efx_dword_t *)buf, (unsigned int )table->offset + (unsigned int )i * 4U);
  goto ldv_56454;
  case 8: 
  efx_sram_readq(efx, efx->membase + (unsigned long )table->offset, (efx_qword_t *)buf,
                 (unsigned int )i);
  goto ldv_56454;
  case 16: 
  efx_reado_table(efx, (efx_oword_t *)buf, (unsigned int )table->offset, (unsigned int )i);
  goto ldv_56454;
  case 32: 
  efx_reado_table(efx, (efx_oword_t *)buf, (unsigned int )table->offset, (unsigned int )i * 2U);
  goto ldv_56454;
  default: 
  __ret_warn_on = 1;
  tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/nic.c",
                       437);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  return;
  }
  ldv_56454: 
  buf = buf + size;
  i = i + 1UL;
  ldv_56462: ;
  if ((size_t )table->rows > i) {
    goto ldv_56461;
  } else {

  }

  ldv_56449: 
  table = table + 1;
  ldv_56465: ;
  if ((unsigned long )table < (unsigned long )((struct efx_nic_reg_table  const  *)(& efx_nic_reg_tables) + 23UL)) {
    goto ldv_56464;
  } else {

  }

  return;
}
}
size_t efx_nic_describe_stats(struct efx_hw_stat_desc  const  *desc , size_t count ,
                              unsigned long const   *mask , u8 *names ) 
{ 
  size_t visible ;
  size_t index ;

  {
  visible = 0UL;
  index = find_first_bit(mask, count);
  goto ldv_56476;
  ldv_56475: ;
  if ((unsigned long )(desc + index)->name != (unsigned long )((char const   */* const  */)0)) {
    if ((unsigned long )names != (unsigned long )((u8 *)0U)) {
      strlcpy((char *)names, (desc + index)->name, 32UL);
      names = names + 32UL;
    } else {

    }
    visible = visible + 1UL;
  } else {

  }
  index = find_next_bit(mask, count, index + 1UL);
  ldv_56476: ;
  if (index < count) {
    goto ldv_56475;
  } else {

  }

  return (visible);
}
}
void efx_nic_update_stats(struct efx_hw_stat_desc  const  *desc , size_t count , unsigned long const   *mask ,
                          u64 *stats , void const   *dma_buf , bool accumulate ) 
{ 
  size_t index ;
  void const   *addr ;
  u64 val ;
  __u16 tmp ;
  __u32 tmp___0 ;
  int __ret_warn_on ;
  long tmp___1 ;

  {
  index = find_first_bit(mask, count);
  goto ldv_56497;
  ldv_56496: ;
  if ((unsigned int )((unsigned short )(desc + index)->dma_width) != 0U) {
    addr = dma_buf + (unsigned long )(desc + index)->offset;
    switch ((int )(desc + index)->dma_width) {
    case 16: 
    tmp = __le16_to_cpup((__le16 const   *)addr);
    val = (u64 )tmp;
    goto ldv_56490;
    case 32: 
    tmp___0 = __le32_to_cpup((__le32 const   *)addr);
    val = (u64 )tmp___0;
    goto ldv_56490;
    case 64: 
    val = __le64_to_cpup((__le64 const   *)addr);
    goto ldv_56490;
    default: 
    __ret_warn_on = 1;
    tmp___1 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___1 != 0L) {
      warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/nic.c",
                         512);
    } else {

    }
    ldv__builtin_expect(__ret_warn_on != 0, 0L);
    val = 0ULL;
    goto ldv_56490;
    }
    ldv_56490: ;
    if ((int )accumulate) {
      *(stats + index) = *(stats + index) + val;
    } else {
      *(stats + index) = val;
    }
  } else {

  }
  index = find_next_bit(mask, count, index + 1UL);
  ldv_56497: ;
  if (index < count) {
    goto ldv_56496;
  } else {

  }

  return;
}
}
void efx_nic_fix_nodesc_drop_stat(struct efx_nic *efx , u64 *rx_nodesc_drops ) 
{ 


  {
  if (((efx->net_dev)->flags & 1U) == 0U || ! efx->rx_nodesc_drops_prev_state) {
    efx->rx_nodesc_drops_while_down = efx->rx_nodesc_drops_while_down + (*rx_nodesc_drops - efx->rx_nodesc_drops_total);
  } else {

  }
  efx->rx_nodesc_drops_total = *rx_nodesc_drops;
  efx->rx_nodesc_drops_prev_state = ((int )(efx->net_dev)->flags & 1) != 0;
  *rx_nodesc_drops = *rx_nodesc_drops - efx->rx_nodesc_drops_while_down;
  return;
}
}
bool ldv_queue_work_on_101(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_102(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_103(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_104(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_105(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_106(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_107(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_108(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_109(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_110(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_111(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_112(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
__inline static void __set_bit(long nr , unsigned long volatile   *addr ) 
{ 


  {
  __asm__  volatile   ("bts %1,%0": "+m" (*((long volatile   *)addr)): "Ir" (nr): "memory");
  return;
}
}
__inline static unsigned long __ffs(unsigned long word ) 
{ 


  {
  __asm__  ("rep; bsf %1,%0": "=r" (word): "rm" (word));
  return (word);
}
}
__inline static __u32 __arch_swab32(__u32 val ) 
{ 


  {
  __asm__  ("bswapl %0": "=r" (val): "0" (val));
  return (val);
}
}
__inline static __u16 __fswab16(__u16 val ) 
{ 


  {
  return ((__u16 )((int )((short )((int )val << 8)) | (int )((short )((int )val >> 8))));
}
}
__inline static __u32 __fswab32(__u32 val ) 
{ 
  __u32 tmp ;

  {
  tmp = __arch_swab32(val);
  return (tmp);
}
}
__inline static void __set_bit_le(int nr , void *addr ) 
{ 


  {
  __set_bit((long )nr, (unsigned long volatile   *)addr);
  return;
}
}
__inline static void __clear_bit_le(int nr , void *addr ) 
{ 


  {
  __clear_bit((long )nr, (unsigned long volatile   *)addr);
  return;
}
}
extern void __might_sleep(char const   * , int  , int  ) ;
extern unsigned long __phys_addr(unsigned long  ) ;
extern int memcmp(void const   * , void const   * , size_t  ) ;
extern void __cmpxchg_wrong_size(void) ;
__inline static void atomic_set(atomic_t *v , int i ) 
{ 


  {
  v->counter = i;
  return;
}
}
__inline static void atomic_dec(atomic_t *v ) 
{ 


  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; decl %0": "+m" (v->counter));
  return;
}
}
__inline static int atomic_cmpxchg(atomic_t *v , int old , int new ) 
{ 
  int __ret ;
    klee_make_symbolic(&__ret, sizeof(int), "__ret");
  int __old ;
    klee_make_symbolic(&__old, sizeof(int), "__old");
  int __new ;
    klee_make_symbolic(&__new, sizeof(int), "__new");
  u8 volatile   *__ptr ;
  u16 volatile   *__ptr___0 ;
  u32 volatile   *__ptr___1 ;
  u64 volatile   *__ptr___2 ;

  {
  __old = old;
  __new = new;
  switch (4UL) {
  case 1UL: 
  __ptr = (u8 volatile   *)(& v->counter);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgb %2,%1": "=a" (__ret),
                       "+m" (*__ptr): "q" (__new), "0" (__old): "memory");
  goto ldv_5616;
  case 2UL: 
  __ptr___0 = (u16 volatile   *)(& v->counter);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgw %2,%1": "=a" (__ret),
                       "+m" (*__ptr___0): "r" (__new), "0" (__old): "memory");
  goto ldv_5616;
  case 4UL: 
  __ptr___1 = (u32 volatile   *)(& v->counter);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgl %2,%1": "=a" (__ret),
                       "+m" (*__ptr___1): "r" (__new), "0" (__old): "memory");
  goto ldv_5616;
  case 8UL: 
  __ptr___2 = (u64 volatile   *)(& v->counter);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgq %2,%1": "=a" (__ret),
                       "+m" (*__ptr___2): "r" (__new), "0" (__old): "memory");
  goto ldv_5616;
  default: 
  __cmpxchg_wrong_size();
  }
  ldv_5616: ;
  return (__ret);
}
}
int ldv_mutex_trylock_137(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_135(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_138(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_139(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_134(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_136(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_140(struct mutex *ldv_func_arg1 ) ;
extern void __wake_up(wait_queue_head_t * , unsigned int  , int  , void * ) ;
extern long prepare_to_wait_event(wait_queue_head_t * , wait_queue_t * , int  ) ;
extern void finish_wait(wait_queue_head_t * , wait_queue_t * ) ;
bool ldv_queue_work_on_129(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_131(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_130(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_133(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_132(struct workqueue_struct *ldv_func_arg1 ) ;
__inline static void __writel(unsigned int val , void volatile   *addr ) 
{ 


  {
  __asm__  volatile   ("movl %0,%1": : "r" (val), "m" (*((unsigned int volatile   *)addr)));
  return;
}
}
__inline static void writeq(unsigned long val , void volatile   *addr ) 
{ 


  {
  __asm__  volatile   ("movq %0,%1": : "r" (val), "m" (*((unsigned long volatile   *)addr)): "memory");
  return;
}
}
__inline static phys_addr_t virt_to_phys(void volatile   *address ) 
{ 
  unsigned long tmp ;

  {
  tmp = __phys_addr((unsigned long )address);
  return ((phys_addr_t )tmp);
}
}
extern long schedule_timeout(long  ) ;
extern void disable_irq_nosync(unsigned int  ) ;
extern void pci_clear_master(struct pci_dev * ) ;
extern u32 crc32_le(u32  , unsigned char const   * , size_t  ) ;
extern bool rps_may_expire_flow(struct net_device * , u16  , u32  , u16  ) ;
__inline static void netif_tx_lock___0(struct net_device *dev ) 
{ 
  unsigned int i ;
  int cpu ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  spin_lock(& dev->tx_global_lock);
  __vpp_verify = (void const   *)0;
  switch (4UL) {
  case 1UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
  goto ldv_45308;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_45308;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_45308;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_45308;
  default: 
  __bad_percpu_size();
  }
  ldv_45308: 
  pscr_ret__ = pfo_ret__;
  goto ldv_45314;
  case 2UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45318;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45318;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45318;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45318;
  default: 
  __bad_percpu_size();
  }
  ldv_45318: 
  pscr_ret__ = pfo_ret_____0;
  goto ldv_45314;
  case 4UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45327;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45327;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45327;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45327;
  default: 
  __bad_percpu_size();
  }
  ldv_45327: 
  pscr_ret__ = pfo_ret_____1;
  goto ldv_45314;
  case 8UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45336;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45336;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45336;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45336;
  default: 
  __bad_percpu_size();
  }
  ldv_45336: 
  pscr_ret__ = pfo_ret_____2;
  goto ldv_45314;
  default: 
  __bad_size_call_parameter();
  goto ldv_45314;
  }
  ldv_45314: 
  cpu = pscr_ret__;
  i = 0U;
  goto ldv_45346;
  ldv_45345: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  __netif_tx_lock(txq, cpu);
  set_bit(2L, (unsigned long volatile   *)(& txq->state));
  __netif_tx_unlock(txq);
  i = i + 1U;
  ldv_45346: ;
  if (dev->num_tx_queues > i) {
    goto ldv_45345;
  } else {

  }

  return;
}
}
__inline static void netif_tx_unlock___0(struct net_device *dev ) 
{ 
  unsigned int i ;
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  i = 0U;
  goto ldv_45357;
  ldv_45356: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  clear_bit(2L, (unsigned long volatile   *)(& txq->state));
  netif_schedule_queue(txq);
  i = i + 1U;
  ldv_45357: ;
  if (dev->num_tx_queues > i) {
    goto ldv_45356;
  } else {

  }
  spin_unlock(& dev->tx_global_lock);
  return;
}
}
extern void *vzalloc(unsigned long  ) ;
extern void vfree(void const   * ) ;
__inline static struct efx_tx_queue *efx_get_tx_queue(struct efx_nic *efx , unsigned int index ,
                                                      unsigned int type ) 
{ 


  {
  return ((struct efx_tx_queue *)(& (efx->channel[efx->tx_channel_offset + index])->tx_queue) + (unsigned long )type);
}
}
__inline static struct efx_tx_queue *efx_channel_get_tx_queue(struct efx_channel *channel ,
                                                              unsigned int type ) 
{ 


  {
  return ((struct efx_tx_queue *)(& channel->tx_queue) + (unsigned long )type);
}
}
__inline static struct efx_channel *efx_rx_queue_channel(struct efx_rx_queue *rx_queue ) 
{ 
  struct efx_rx_queue  const  *__mptr ;

  {
  __mptr = (struct efx_rx_queue  const  *)rx_queue;
  return ((struct efx_channel *)__mptr + 0xfffffffffffffe00UL);
}
}
__inline static int efx_rx_queue_index(struct efx_rx_queue *rx_queue ) 
{ 
  struct efx_channel *tmp ;

  {
  tmp = efx_rx_queue_channel(rx_queue);
  return (tmp->channel);
}
}
__inline static struct efx_rx_buffer *efx_rx_buffer(struct efx_rx_queue *rx_queue ,
                                                    unsigned int index ) 
{ 


  {
  return (rx_queue->buffer + (unsigned long )index);
}
}
void efx_xmit_done(struct efx_tx_queue *tx_queue , unsigned int index ) ;
void efx_rx_packet(struct efx_rx_queue *rx_queue , unsigned int index , unsigned int n_frags ,
                   unsigned int len , u16 flags ) ;
__inline static void efx_schedule_channel___0(struct efx_channel *channel ) 
{ 
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;

  {
  if (0) {
    if (((channel->efx)->msg_enable & 512U) != 0U) {
      __vpp_verify = (void const   *)0;
      switch (4UL) {
      case 1UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
      goto ldv_55280;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_55280;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_55280;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_55280;
      default: 
      __bad_percpu_size();
      }
      ldv_55280: 
      pscr_ret__ = pfo_ret__;
      goto ldv_55286;
      case 2UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_55290;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_55290;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_55290;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_55290;
      default: 
      __bad_percpu_size();
      }
      ldv_55290: 
      pscr_ret__ = pfo_ret_____0;
      goto ldv_55286;
      case 4UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_55299;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_55299;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_55299;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_55299;
      default: 
      __bad_percpu_size();
      }
      ldv_55299: 
      pscr_ret__ = pfo_ret_____1;
      goto ldv_55286;
      case 8UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_55308;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_55308;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_55308;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_55308;
      default: 
      __bad_percpu_size();
      }
      ldv_55308: 
      pscr_ret__ = pfo_ret_____2;
      goto ldv_55286;
      default: 
      __bad_size_call_parameter();
      goto ldv_55286;
      }
      ldv_55286: 
      netdev_printk("\017", (struct net_device  const  *)(channel->efx)->net_dev,
                    "channel %d scheduling NAPI poll on CPU%d\n", channel->channel,
                    pscr_ret__);
    } else {

    }
  } else {

  }
  napi_schedule(& channel->napi_str);
  return;
}
}
__inline static void efx_schedule_channel_irq(struct efx_channel *channel ) 
{ 
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;

  {
  __vpp_verify = (void const   *)0;
  switch (4UL) {
  case 1UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
  goto ldv_55325;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_55325;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_55325;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_55325;
  default: 
  __bad_percpu_size();
  }
  ldv_55325: 
  pscr_ret__ = pfo_ret__;
  goto ldv_55331;
  case 2UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_55335;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_55335;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_55335;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_55335;
  default: 
  __bad_percpu_size();
  }
  ldv_55335: 
  pscr_ret__ = pfo_ret_____0;
  goto ldv_55331;
  case 4UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_55344;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_55344;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_55344;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_55344;
  default: 
  __bad_percpu_size();
  }
  ldv_55344: 
  pscr_ret__ = pfo_ret_____1;
  goto ldv_55331;
  case 8UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_55353;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_55353;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_55353;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_55353;
  default: 
  __bad_percpu_size();
  }
  ldv_55353: 
  pscr_ret__ = pfo_ret_____2;
  goto ldv_55331;
  default: 
  __bad_size_call_parameter();
  goto ldv_55331;
  }
  ldv_55331: 
  channel->event_test_cpu = pscr_ret__;
  efx_schedule_channel___0(channel);
  return;
}
}
void efx_mcdi_process_event(struct efx_channel *channel , efx_qword_t *event ) ;
int efx_mcdi_flush_rxqs(struct efx_nic *efx ) ;
u32 efx_farch_fpga_ver(struct efx_nic *efx ) ;
__inline static bool efx_nic_is_dual_func(struct efx_nic *efx ) 
{ 
  int tmp ;

  {
  tmp = efx_nic_rev(efx);
  return (tmp <= 1);
}
}
__inline static efx_qword_t *efx_tx_desc(struct efx_tx_queue *tx_queue , unsigned int index ) 
{ 


  {
  return ((efx_qword_t *)tx_queue->txd.buf.addr + (unsigned long )index);
}
}
__inline static bool __efx_nic_tx_is_empty(struct efx_tx_queue *tx_queue , unsigned int write_count ) 
{ 
  unsigned int empty_read_count ;
  unsigned int __var ;

  {
  __var = 0U;
  empty_read_count = *((unsigned int volatile   *)(& tx_queue->empty_read_count));
  if (empty_read_count == 0U) {
    return (0);
  } else {

  }
  return (((empty_read_count ^ write_count) & 2147483647U) == 0U);
}
}
__inline static bool efx_nic_may_push_tx_desc(struct efx_tx_queue *tx_queue , unsigned int write_count ) 
{ 
  bool was_empty ;
  bool tmp ;

  {
  tmp = __efx_nic_tx_is_empty(tx_queue, write_count);
  was_empty = tmp;
  tx_queue->empty_read_count = 0U;
  return ((bool )((int )was_empty && tx_queue->write_count - write_count == 1U));
}
}
__inline static efx_qword_t *efx_rx_desc(struct efx_rx_queue *rx_queue , unsigned int index ) 
{ 


  {
  return ((efx_qword_t *)rx_queue->rxd.buf.addr + (unsigned long )index);
}
}
int efx_farch_tx_probe(struct efx_tx_queue *tx_queue ) ;
void efx_farch_tx_init(struct efx_tx_queue *tx_queue ) ;
void efx_farch_tx_fini(struct efx_tx_queue *tx_queue ) ;
void efx_farch_tx_remove(struct efx_tx_queue *tx_queue ) ;
void efx_farch_tx_write(struct efx_tx_queue *tx_queue ) ;
int efx_farch_rx_probe(struct efx_rx_queue *rx_queue ) ;
void efx_farch_rx_init(struct efx_rx_queue *rx_queue ) ;
void efx_farch_rx_fini(struct efx_rx_queue *rx_queue ) ;
void efx_farch_rx_remove(struct efx_rx_queue *rx_queue ) ;
void efx_farch_rx_write(struct efx_rx_queue *rx_queue ) ;
void efx_farch_rx_defer_refill(struct efx_rx_queue *rx_queue ) ;
int efx_farch_ev_probe(struct efx_channel *channel ) ;
int efx_farch_ev_init(struct efx_channel *channel ) ;
void efx_farch_ev_fini(struct efx_channel *channel ) ;
void efx_farch_ev_remove(struct efx_channel *channel ) ;
int efx_farch_ev_process(struct efx_channel *channel , int budget ) ;
void efx_farch_ev_read_ack(struct efx_channel *channel ) ;
void efx_farch_ev_test_generate(struct efx_channel *channel ) ;
int efx_farch_filter_table_probe(struct efx_nic *efx ) ;
void efx_farch_filter_table_restore(struct efx_nic *efx ) ;
void efx_farch_filter_table_remove(struct efx_nic *efx ) ;
void efx_farch_filter_update_rx_scatter(struct efx_nic *efx ) ;
s32 efx_farch_filter_insert(struct efx_nic *efx , struct efx_filter_spec *gen_spec ,
                            bool replace_equal ) ;
int efx_farch_filter_remove_safe(struct efx_nic *efx , enum efx_filter_priority priority ,
                                 u32 filter_id ) ;
int efx_farch_filter_get_safe(struct efx_nic *efx , enum efx_filter_priority priority ,
                              u32 filter_id , struct efx_filter_spec *spec_buf ) ;
int efx_farch_filter_clear_rx(struct efx_nic *efx , enum efx_filter_priority priority ) ;
u32 efx_farch_filter_count_rx_used(struct efx_nic *efx , enum efx_filter_priority priority ) ;
u32 efx_farch_filter_get_rx_id_limit(struct efx_nic *efx ) ;
s32 efx_farch_filter_get_rx_ids(struct efx_nic *efx , enum efx_filter_priority priority ,
                                u32 *buf , u32 size ) ;
s32 efx_farch_filter_rfs_insert(struct efx_nic *efx , struct efx_filter_spec *gen_spec ) ;
bool efx_farch_filter_rfs_expire_one(struct efx_nic *efx , u32 flow_id , unsigned int index ) ;
void efx_farch_filter_sync_rx_mode(struct efx_nic *efx ) ;
void efx_farch_irq_enable_master(struct efx_nic *efx ) ;
void efx_farch_irq_test_generate(struct efx_nic *efx ) ;
void efx_farch_irq_disable_master(struct efx_nic *efx ) ;
irqreturn_t efx_farch_msi_interrupt(int irq , void *dev_id ) ;
irqreturn_t efx_farch_legacy_interrupt(int irq , void *dev_id ) ;
irqreturn_t efx_farch_fatal_interrupt(struct efx_nic *efx ) ;
int efx_farch_fini_dmaq(struct efx_nic *efx ) ;
void efx_farch_finish_flr(struct efx_nic *efx ) ;
void efx_farch_dimension_resources(struct efx_nic *efx , unsigned int sram_lim_qw ) ;
void efx_farch_init_common(struct efx_nic *efx ) ;
void efx_farch_rx_push_indir_table(struct efx_nic *efx ) ;
int efx_farch_test_registers(struct efx_nic *efx , struct efx_farch_register_test  const  *regs ,
                             size_t n_regs ) ;
void efx_farch_generate_event(struct efx_nic *efx , unsigned int evq , efx_qword_t *event ) ;
__inline static bool efx_siena_sriov_enabled(struct efx_nic *efx ) 
{ 


  {
  return (efx->vf_init_count != 0U);
}
}
void efx_siena_sriov_tx_flush_done(struct efx_nic *efx , efx_qword_t *event ) ;
void efx_siena_sriov_rx_flush_done(struct efx_nic *efx , efx_qword_t *event ) ;
void efx_siena_sriov_event(struct efx_channel *channel , efx_qword_t *event ) ;
void efx_siena_sriov_desc_fetch_err(struct efx_nic *efx , unsigned int dmaq ) ;
__inline static void _efx_writeq(struct efx_nic *efx , __le64 value , unsigned int reg ) 
{ 


  {
  writeq((unsigned long )value, (void volatile   *)efx->membase + (unsigned long )reg);
  return;
}
}
__inline static void _efx_writed(struct efx_nic *efx , __le32 value , unsigned int reg ) 
{ 


  {
  __writel(value, (void volatile   *)efx->membase + (unsigned long )reg);
  return;
}
}
__inline static void efx_writeo(struct efx_nic *efx , efx_oword_t const   *value ,
                                unsigned int reg ) 
{ 
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
  tmp = spinlock_check(& efx->biu_lock);
  flags = _raw_spin_lock_irqsave(tmp);
  _efx_writeq(efx, value->u64[0], reg);
  _efx_writeq(efx, value->u64[1], reg + 8U);
  __asm__  volatile   ("": : : "memory");
  spin_unlock_irqrestore(& efx->biu_lock, flags);
  return;
}
}
__inline static void efx_sram_writeq(struct efx_nic *efx , void *membase , efx_qword_t const   *value ,
                                     unsigned int index ) 
{ 
  unsigned int addr ;
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
  addr = index * 8U;
  tmp = spinlock_check(& efx->biu_lock);
  flags = _raw_spin_lock_irqsave(tmp);
  writeq((unsigned long )value->u64[0], (void volatile   *)membase + (unsigned long )addr);
  __asm__  volatile   ("": : : "memory");
  spin_unlock_irqrestore(& efx->biu_lock, flags);
  return;
}
}
__inline static void efx_writed(struct efx_nic *efx , efx_dword_t const   *value ,
                                unsigned int reg ) 
{ 


  {
  _efx_writed(efx, value->u32[0], reg);
  return;
}
}
__inline static void efx_writeo_table(struct efx_nic *efx , efx_oword_t const   *value ,
                                      unsigned int reg , unsigned int index ) 
{ 


  {
  efx_writeo(efx, value, index * 16U + reg);
  return;
}
}
__inline static void _efx_writeo_page(struct efx_nic *efx , efx_oword_t *value , unsigned int reg ,
                                      unsigned int page ) 
{ 


  {
  reg = page * 8192U + reg;
  _efx_writeq(efx, value->u64[0], reg);
  _efx_writeq(efx, value->u64[1], reg + 8U);
  return;
}
}
__inline static void _efx_writed_page(struct efx_nic *efx , efx_dword_t const   *value ,
                                      unsigned int reg , unsigned int page ) 
{ 


  {
  efx_writed(efx, value, page * 8192U + reg);
  return;
}
}
static void efx_farch_magic_event(struct efx_channel *channel , u32 magic ) ;
__inline static void efx_write_buf_tbl(struct efx_nic *efx , efx_qword_t *value ,
                                       unsigned int index ) 
{ 


  {
  efx_sram_writeq(efx, efx->membase + (unsigned long )(efx->type)->buf_tbl_base, (efx_qword_t const   *)value,
                  index);
  return;
}
}
static bool efx_masked_compare_oword(efx_oword_t const   *a , efx_oword_t const   *b ,
                                     efx_oword_t const   *mask ) 
{ 


  {
  return ((bool )(((a->u64[0] ^ b->u64[0]) & mask->u64[0]) != 0ULL || ((a->u64[1] ^ b->u64[1]) & mask->u64[1]) != 0ULL));
}
}
int efx_farch_test_registers(struct efx_nic *efx , struct efx_farch_register_test  const  *regs ,
                             size_t n_regs ) 
{ 
  unsigned int address ;
  unsigned int i ;
  unsigned int j ;
  efx_oword_t mask ;
  efx_oword_t imask ;
  efx_oword_t original ;
  efx_oword_t reg ;
  efx_oword_t buf ;
  bool tmp ;
  bool tmp___0 ;

  {
  address = 0U;
  i = 0U;
  goto ldv_56471;
  ldv_56470: 
  address = (regs + (unsigned long )i)->address;
  imask = (regs + (unsigned long )i)->mask;
  mask = imask;
  imask.u64[0] = ~ imask.u64[0];
  imask.u64[1] = ~ imask.u64[1];
  efx_reado(efx, & original, address);
  j = 0U;
  goto ldv_56468;
  ldv_56467: ;
  if ((((((j <= 31U ? (j != 0U ? mask.u32[0] >> (int )j : mask.u32[0] << (int )(- j)) : 0U) | (j <= 63U && j > 31U ? (j > 32U ? mask.u32[1] >> (int )(j - 32U) : mask.u32[1] << (int )(32U - j)) : 0U)) | (j <= 95U && j > 63U ? (j > 64U ? mask.u32[2] >> (int )(j - 64U) : mask.u32[2] << (int )(64U - j)) : 0U)) | (j <= 127U && j > 95U ? (j > 96U ? mask.u32[3] >> (int )(j - 96U) : mask.u32[3] << (int )(96U - j)) : 0U)) & 1U) == 0U) {
    goto ldv_56465;
  } else {

  }
  reg.u64[0] = original.u64[0] & mask.u64[0];
  reg.u64[1] = original.u64[1] & mask.u64[1];
  reg.u32[0] = (reg.u32[0] & (j <= 31U ? (j != 0U ? ~ (1U << (int )j) : ~ (1U >> (int )(- j))) : 4294967295U)) | (j <= 31U ? (j != 0U ? 1U << (int )j : 1U >> (int )(- j)) : 0U);
  reg.u32[1] = (reg.u32[1] & (j <= 63U && j > 31U ? (j > 32U ? ~ (1U << (int )(j - 32U)) : ~ (1U >> (int )(32U - j))) : 4294967295U)) | (j <= 63U && j > 31U ? (j > 32U ? 1U << (int )(j - 32U) : 1U >> (int )(32U - j)) : 0U);
  reg.u32[2] = (reg.u32[2] & (j <= 95U && j > 63U ? (j > 64U ? ~ (1U << (int )(j - 64U)) : ~ (1U >> (int )(64U - j))) : 4294967295U)) | (j <= 95U && j > 63U ? (j > 64U ? 1U << (int )(j - 64U) : 1U >> (int )(64U - j)) : 0U);
  reg.u32[3] = (reg.u32[3] & (j <= 127U && j > 95U ? (j > 96U ? ~ (1U << (int )(j - 96U)) : ~ (1U >> (int )(96U - j))) : 4294967295U)) | (j <= 127U && j > 95U ? (j > 96U ? 1U << (int )(j - 96U) : 1U >> (int )(96U - j)) : 0U);
  efx_writeo(efx, (efx_oword_t const   *)(& reg), address);
  efx_reado(efx, & buf, address);
  tmp = efx_masked_compare_oword((efx_oword_t const   *)(& reg), (efx_oword_t const   *)(& buf),
                                 (efx_oword_t const   *)(& mask));
  if ((int )tmp) {
    goto fail;
  } else {

  }
  reg.u64[0] = original.u64[0] | mask.u64[0];
  reg.u64[1] = original.u64[1] | mask.u64[1];
  reg.u32[0] = reg.u32[0] & (j <= 31U ? (j != 0U ? ~ (1U << (int )j) : ~ (1U >> (int )(- j))) : 4294967295U);
  reg.u32[1] = reg.u32[1] & (j <= 63U && j > 31U ? (j > 32U ? ~ (1U << (int )(j - 32U)) : ~ (1U >> (int )(32U - j))) : 4294967295U);
  reg.u32[2] = reg.u32[2] & (j <= 95U && j > 63U ? (j > 64U ? ~ (1U << (int )(j - 64U)) : ~ (1U >> (int )(64U - j))) : 4294967295U);
  reg.u32[3] = reg.u32[3] & (j <= 127U && j > 95U ? (j > 96U ? ~ (1U << (int )(j - 96U)) : ~ (1U >> (int )(96U - j))) : 4294967295U);
  efx_writeo(efx, (efx_oword_t const   *)(& reg), address);
  efx_reado(efx, & buf, address);
  tmp___0 = efx_masked_compare_oword((efx_oword_t const   *)(& reg), (efx_oword_t const   *)(& buf),
                                     (efx_oword_t const   *)(& mask));
  if ((int )tmp___0) {
    goto fail;
  } else {

  }
  ldv_56465: 
  j = j + 1U;
  ldv_56468: ;
  if (j <= 127U) {
    goto ldv_56467;
  } else {

  }
  efx_writeo(efx, (efx_oword_t const   *)(& original), address);
  i = i + 1U;
  ldv_56471: ;
  if ((size_t )i < n_regs) {
    goto ldv_56470;
  } else {

  }

  return (0);
  fail: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "wrote %08x:%08x:%08x:%08x read %08x:%08x:%08x:%08x at address 0x%x mask %08x:%08x:%08x:%08x\n",
               reg.u32[3], reg.u32[2], reg.u32[1], reg.u32[0], buf.u32[3], buf.u32[2],
               buf.u32[1], buf.u32[0], address, mask.u32[3], mask.u32[2], mask.u32[1],
               mask.u32[0]);
  } else {

  }
  return (-5);
}
}
static void efx_init_special_buffer(struct efx_nic *efx , struct efx_special_buffer *buffer ) 
{ 
  efx_qword_t buf_desc ;
  unsigned int index ;
  dma_addr_t dma_addr ;
  int i ;
  struct _ddebug descriptor ;
  long tmp ;

  {
  i = 0;
  goto ldv_56484;
  ldv_56483: 
  index = buffer->index + (unsigned int )i;
  dma_addr = buffer->buf.dma_addr + (dma_addr_t )(i * 4096);
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_init_special_buffer";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c";
    descriptor.format = "mapping special buffer %d at %llx\n";
    descriptor.lineno = 187U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "mapping special buffer %d at %llx\n", index, dma_addr);
    } else {

    }
  } else {

  }
  buf_desc.u64[0] = (dma_addr >> 12) << 14;
  efx_write_buf_tbl(efx, & buf_desc, index);
  i = i + 1;
  ldv_56484: ;
  if ((unsigned int )i < buffer->entries) {
    goto ldv_56483;
  } else {

  }

  return;
}
}
static void efx_fini_special_buffer(struct efx_nic *efx , struct efx_special_buffer *buffer ) 
{ 
  efx_oword_t buf_tbl_upd ;
  unsigned int start ;
  unsigned int end ;
    klee_make_symbolic(&end, sizeof(int), "end");
  struct _ddebug descriptor ;
  long tmp ;

  {
  start = buffer->index;
  end = (buffer->index + buffer->entries) - 1U;
  if (buffer->entries == 0U) {
    return;
  } else {

  }
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_fini_special_buffer";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c";
    descriptor.format = "unmapping special buffers %d-%d\n";
    descriptor.lineno = 208U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "unmapping special buffers %d-%d\n", buffer->index, (buffer->index + buffer->entries) - 1U);
    } else {

    }
  } else {

  }
  buf_tbl_upd.u64[0] = (((unsigned long long )end << 32) | (unsigned long long )start) | 4611686018427387904ULL;
  buf_tbl_upd.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& buf_tbl_upd), 1616U);
  return;
}
}
static int efx_alloc_special_buffer(struct efx_nic *efx , struct efx_special_buffer *buffer ,
                                    unsigned int len ) 
{ 
  struct siena_nic_data *nic_data ;
  int tmp ;
  long tmp___0 ;
  bool tmp___1 ;
  long tmp___2 ;
  struct _ddebug descriptor ;
  phys_addr_t tmp___3 ;
  long tmp___4 ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  len = (len + 4095U) & 4294963200U;
  tmp = efx_nic_alloc_buffer(efx, & buffer->buf, len, 208U);
  if (tmp != 0) {
    return (-12);
  } else {

  }
  buffer->entries = len / 4096U;
  tmp___0 = ldv__builtin_expect((buffer->buf.dma_addr & 4095ULL) != 0ULL, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c"),
                         "i" (239), "i" (12UL));
    ldv_56501: ;
    goto ldv_56501;
  } else {

  }
  buffer->index = efx->next_buffer_table;
  efx->next_buffer_table = efx->next_buffer_table + buffer->entries;
  tmp___1 = efx_siena_sriov_enabled(efx);
  tmp___2 = ldv__builtin_expect((long )((int )tmp___1 && nic_data->vf_buftbl_base < efx->next_buffer_table),
                             0L);
  if (tmp___2 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c"),
                         "i" (246), "i" (12UL));
    ldv_56502: ;
    goto ldv_56502;
  } else {

  }
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_alloc_special_buffer";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c";
    descriptor.format = "allocating special buffers %d-%d at %llx+%x (virt %p phys %llx)\n";
    descriptor.lineno = 254U;
    descriptor.flags = 0U;
    tmp___4 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___4 != 0L) {
      tmp___3 = virt_to_phys((void volatile   *)buffer->buf.addr);
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "allocating special buffers %d-%d at %llx+%x (virt %p phys %llx)\n",
                           buffer->index, (buffer->index + buffer->entries) - 1U,
                           buffer->buf.dma_addr, len, buffer->buf.addr, tmp___3);
    } else {

    }
  } else {

  }
  return (0);
}
}
static void efx_free_special_buffer(struct efx_nic *efx , struct efx_special_buffer *buffer ) 
{ 
  struct _ddebug descriptor ;
  phys_addr_t tmp ;
  long tmp___0 ;

  {
  if ((unsigned long )buffer->buf.addr == (unsigned long )((void *)0)) {
    return;
  } else {

  }
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_free_special_buffer";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c";
    descriptor.format = "deallocating special buffers %d-%d at %llx+%x (virt %p phys %llx)\n";
    descriptor.lineno = 270U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      tmp = virt_to_phys((void volatile   *)buffer->buf.addr);
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "deallocating special buffers %d-%d at %llx+%x (virt %p phys %llx)\n",
                           buffer->index, (buffer->index + buffer->entries) - 1U,
                           buffer->buf.dma_addr, buffer->buf.len, buffer->buf.addr,
                           tmp);
    } else {

    }
  } else {

  }
  efx_nic_free_buffer(efx, & buffer->buf);
  buffer->entries = 0U;
  return;
}
}
__inline static void efx_farch_notify_tx_desc(struct efx_tx_queue *tx_queue ) 
{ 
  unsigned int write_ptr ;
    klee_make_symbolic(&write_ptr, sizeof(int), "write_ptr");
  efx_dword_t reg ;

  {
  write_ptr = tx_queue->write_count & tx_queue->ptr_mask;
  reg.u32[0] = write_ptr;
  _efx_writed_page(tx_queue->efx, (efx_dword_t const   *)(& reg), 2588U, tx_queue->queue);
  return;
}
}
__inline static void efx_farch_push_tx_desc(struct efx_tx_queue *tx_queue , efx_qword_t const   *txd ) 
{ 
  unsigned int write_ptr ;
  efx_oword_t reg ;

  {
  write_ptr = tx_queue->write_count & tx_queue->ptr_mask;
  reg.u64[0] = 0ULL;
  reg.u64[1] = ((unsigned long long )write_ptr << 32) | 2147483648ULL;
  reg.qword[0] = *txd;
  _efx_writeo_page(tx_queue->efx, & reg, 2576U, tx_queue->queue);
  return;
}
}
void efx_farch_tx_write(struct efx_tx_queue *tx_queue ) 
{ 
  struct efx_tx_buffer *buffer ;
  efx_qword_t *txd ;
  unsigned int write_ptr ;
  unsigned int old_write_count ;
  long tmp ;
  bool tmp___0 ;

  {
  old_write_count = tx_queue->write_count;
  tmp = ldv__builtin_expect(tx_queue->write_count == tx_queue->insert_count, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c"),
                         "i" (324), "i" (12UL));
    ldv_56547: ;
    goto ldv_56547;
  } else {

  }
  ldv_56548: 
  write_ptr = tx_queue->write_count & tx_queue->ptr_mask;
  buffer = tx_queue->buffer + (unsigned long )write_ptr;
  txd = efx_tx_desc(tx_queue, write_ptr);
  tx_queue->write_count = tx_queue->write_count + 1U;
  txd->u64[0] = ((((unsigned long long )buffer->flags & 1ULL) << 62) | ((unsigned long long )buffer->len << 48)) | buffer->__annonCompField116.dma_addr;
  if (tx_queue->write_count != tx_queue->insert_count) {
    goto ldv_56548;
  } else {

  }
  __asm__  volatile   ("sfence": : : "memory");
  tmp___0 = efx_nic_may_push_tx_desc(tx_queue, old_write_count);
  if ((int )tmp___0) {
    txd = efx_tx_desc(tx_queue, tx_queue->ptr_mask & old_write_count);
    efx_farch_push_tx_desc(tx_queue, (efx_qword_t const   *)txd);
    tx_queue->pushes = tx_queue->pushes + 1U;
  } else {
    efx_farch_notify_tx_desc(tx_queue);
  }
  return;
}
}
int efx_farch_tx_probe(struct efx_tx_queue *tx_queue ) 
{ 
  struct efx_nic *efx ;
  unsigned int entries ;
  int tmp ;

  {
  efx = tx_queue->efx;
  entries = tx_queue->ptr_mask + 1U;
  tmp = efx_alloc_special_buffer(efx, & tx_queue->txd, entries * 8U);
  return (tmp);
}
}
void efx_farch_tx_init(struct efx_tx_queue *tx_queue ) 
{ 
  struct efx_nic *efx ;
  efx_oword_t reg ;
  unsigned long tmp ;
  int csum ;
    klee_make_symbolic(&csum, sizeof(int), "csum");
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
  efx = tx_queue->efx;
  efx_init_special_buffer(efx, & tx_queue->txd);
  tmp = __ffs((unsigned long )tx_queue->txd.entries);
  reg.u64[0] = ((((unsigned long long )tx_queue->txd.index << 36) | ((unsigned long long )(tx_queue->channel)->channel << 24)) | ((unsigned long long )tx_queue->queue << 5)) | ((unsigned long long )tmp << 3);
  reg.u64[1] = 150994944ULL;
  tmp___0 = efx_nic_rev(efx);
  if (tmp___0 > 1) {
    csum = (int )tx_queue->queue & 1;
    reg.u64[0] = reg.u64[0];
    reg.u64[1] = (reg.u64[1] & 0xfffffffffbffffffULL) | (csum == 0 ? 67108864ULL : 0ULL);
    reg.u64[0] = reg.u64[0];
    reg.u64[1] = (reg.u64[1] & 0xfffffffffdffffffULL) | (csum == 0 ? 33554432ULL : 0ULL);
  } else {

  }
  efx_writeo_table(efx, (efx_oword_t const   *)(& reg), (efx->type)->txd_ptr_tbl_base,
                   tx_queue->queue);
  tmp___1 = efx_nic_rev(efx);
  if (tmp___1 <= 1) {
    efx_reado(efx, & reg, 2608U);
    if ((int )tx_queue->queue & 1) {
      __clear_bit_le((int )tx_queue->queue, (void *)(& reg));
    } else {
      __set_bit_le((int )tx_queue->queue, (void *)(& reg));
    }
    efx_writeo(efx, (efx_oword_t const   *)(& reg), 2608U);
  } else {

  }
  tmp___2 = efx_nic_rev(efx);
  if (tmp___2 > 1) {
    reg.u64[0] = (tx_queue->queue & 2U) != 0U ? 0ULL : 21ULL;
    reg.u64[1] = 0ULL;
    efx_writeo_table(efx, (efx_oword_t const   *)(& reg), 16252928U, tx_queue->queue);
  } else {

  }
  return;
}
}
static void efx_farch_flush_tx_queue(struct efx_tx_queue *tx_queue ) 
{ 
  struct efx_nic *efx ;
  efx_oword_t tx_flush_descq ;
  int __ret_warn_on ;
  int tmp ;
  long tmp___0 ;

  {
  efx = tx_queue->efx;
  tmp = atomic_read((atomic_t const   *)(& tx_queue->flush_outstanding));
  __ret_warn_on = tmp != 0;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c",
                       428);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  atomic_set(& tx_queue->flush_outstanding, 1);
  tx_flush_descq.u64[0] = (unsigned long long )tx_queue->queue | 4096ULL;
  tx_flush_descq.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& tx_flush_descq), 2560U);
  return;
}
}
void efx_farch_tx_fini(struct efx_tx_queue *tx_queue ) 
{ 
  struct efx_nic *efx ;
  efx_oword_t tx_desc_ptr ;

  {
  efx = tx_queue->efx;
  tx_desc_ptr.u64[0] = 0ULL;
  tx_desc_ptr.u64[1] = 0ULL;
  efx_writeo_table(efx, (efx_oword_t const   *)(& tx_desc_ptr), (efx->type)->txd_ptr_tbl_base,
                   tx_queue->queue);
  efx_fini_special_buffer(efx, & tx_queue->txd);
  return;
}
}
void efx_farch_tx_remove(struct efx_tx_queue *tx_queue ) 
{ 


  {
  efx_free_special_buffer(tx_queue->efx, & tx_queue->txd);
  return;
}
}
__inline static void efx_farch_build_rx_desc(struct efx_rx_queue *rx_queue , unsigned int index ) 
{ 
  struct efx_rx_buffer *rx_buf ;
  efx_qword_t *rxd ;

  {
  rxd = efx_rx_desc(rx_queue, index);
  rx_buf = efx_rx_buffer(rx_queue, index);
  rxd->u64[0] = ((unsigned long long )((unsigned int )rx_buf->len - (unsigned int )((rx_queue->efx)->type)->rx_buffer_padding) << 48) | rx_buf->dma_addr;
  return;
}
}
void efx_farch_rx_write(struct efx_rx_queue *rx_queue ) 
{ 
  struct efx_nic *efx ;
  efx_dword_t reg ;
  unsigned int write_ptr ;
  int tmp ;

  {
  efx = rx_queue->efx;
  goto ldv_56589;
  ldv_56588: 
  efx_farch_build_rx_desc(rx_queue, rx_queue->notified_count & rx_queue->ptr_mask);
  rx_queue->notified_count = rx_queue->notified_count + 1U;
  ldv_56589: ;
  if (rx_queue->notified_count != rx_queue->added_count) {
    goto ldv_56588;
  } else {

  }
  __asm__  volatile   ("sfence": : : "memory");
  write_ptr = rx_queue->added_count & rx_queue->ptr_mask;
  reg.u32[0] = write_ptr;
  tmp = efx_rx_queue_index(rx_queue);
  _efx_writed_page(efx, (efx_dword_t const   *)(& reg), 2108U, (unsigned int )tmp);
  return;
}
}
int efx_farch_rx_probe(struct efx_rx_queue *rx_queue ) 
{ 
  struct efx_nic *efx ;
  unsigned int entries ;
  int tmp ;

  {
  efx = rx_queue->efx;
  entries = rx_queue->ptr_mask + 1U;
  tmp = efx_alloc_special_buffer(efx, & rx_queue->rxd, entries * 8U);
  return (tmp);
}
}
void efx_farch_rx_init(struct efx_rx_queue *rx_queue ) 
{ 
  efx_oword_t rx_desc_ptr ;
  struct efx_nic *efx ;
  bool is_b0 ;
  int tmp ;
  bool iscsi_digest_en ;
  bool jumbo_en ;
  struct _ddebug descriptor ;
  int tmp___0 ;
  long tmp___1 ;
  struct efx_channel *tmp___2 ;
  int tmp___3 ;
  unsigned long tmp___4 ;
  int tmp___5 ;

  {
  efx = rx_queue->efx;
  tmp = efx_nic_rev(efx);
  is_b0 = tmp > 1;
  iscsi_digest_en = is_b0;
  jumbo_en = (bool )(! is_b0 || (int )efx->rx_scatter);
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_farch_rx_init";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c";
    descriptor.format = "RX queue %d ring in special buffers %d-%d\n";
    descriptor.lineno = 531U;
    descriptor.flags = 0U;
    tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___1 != 0L) {
      tmp___0 = efx_rx_queue_index(rx_queue);
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "RX queue %d ring in special buffers %d-%d\n", tmp___0,
                           rx_queue->rxd.index, (rx_queue->rxd.index + rx_queue->rxd.entries) - 1U);
    } else {

    }
  } else {

  }
  rx_queue->scatter_n = 0U;
  efx_init_special_buffer(efx, & rx_queue->rxd);
  tmp___2 = efx_rx_queue_channel(rx_queue);
  tmp___3 = efx_rx_queue_index(rx_queue);
  tmp___4 = __ffs((unsigned long )rx_queue->rxd.entries);
  rx_desc_ptr.u64[0] = ((((((unsigned long long )rx_queue->rxd.index << 36) | ((unsigned long long )tmp___2->channel << 24)) | ((unsigned long long )tmp___3 << 5)) | ((unsigned long long )tmp___4 << 3)) | ((unsigned long long )jumbo_en << 1)) | 1ULL;
  rx_desc_ptr.u64[1] = ((unsigned long long )iscsi_digest_en << 24) | ((unsigned long long )iscsi_digest_en << 23);
  tmp___5 = efx_rx_queue_index(rx_queue);
  efx_writeo_table(efx, (efx_oword_t const   *)(& rx_desc_ptr), (efx->type)->rxd_ptr_tbl_base,
                   (unsigned int )tmp___5);
  return;
}
}
static void efx_farch_flush_rx_queue(struct efx_rx_queue *rx_queue ) 
{ 
  struct efx_nic *efx ;
  efx_oword_t rx_flush_descq ;
  int tmp ;

  {
  efx = rx_queue->efx;
  tmp = efx_rx_queue_index(rx_queue);
  rx_flush_descq.u64[0] = (unsigned long long )tmp | 16777216ULL;
  rx_flush_descq.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& rx_flush_descq), 2080U);
  return;
}
}
void efx_farch_rx_fini(struct efx_rx_queue *rx_queue ) 
{ 
  efx_oword_t rx_desc_ptr ;
  struct efx_nic *efx ;
  int tmp ;

  {
  efx = rx_queue->efx;
  rx_desc_ptr.u64[0] = 0ULL;
  rx_desc_ptr.u64[1] = 0ULL;
  tmp = efx_rx_queue_index(rx_queue);
  efx_writeo_table(efx, (efx_oword_t const   *)(& rx_desc_ptr), (efx->type)->rxd_ptr_tbl_base,
                   (unsigned int )tmp);
  efx_fini_special_buffer(efx, & rx_queue->rxd);
  return;
}
}
void efx_farch_rx_remove(struct efx_rx_queue *rx_queue ) 
{ 


  {
  efx_free_special_buffer(rx_queue->efx, & rx_queue->rxd);
  return;
}
}
static bool efx_farch_flush_wake(struct efx_nic *efx ) 
{ 
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
  __asm__  volatile   ("mfence": : : "memory");
  tmp = atomic_read((atomic_t const   *)(& efx->active_queues));
  if (tmp == 0) {
    tmp___2 = 1;
  } else {
    tmp___0 = atomic_read((atomic_t const   *)(& efx->rxq_flush_outstanding));
    if (tmp___0 <= 3) {
      tmp___1 = atomic_read((atomic_t const   *)(& efx->rxq_flush_pending));
      if (tmp___1 > 0) {
        tmp___2 = 1;
      } else {
        tmp___2 = 0;
      }
    } else {
      tmp___2 = 0;
    }
  }
  return ((bool )tmp___2);
}
}
static bool efx_check_tx_flush_complete(struct efx_nic *efx ) 
{ 
  bool i ;
  efx_oword_t txd_ptr_tbl ;
  struct efx_channel *channel ;
  struct efx_tx_queue *tx_queue ;
  struct _ddebug descriptor ;
  long tmp ;
  struct _ddebug descriptor___0 ;
  long tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;
  bool tmp___3 ;
  int tmp___4 ;

  {
  i = 1;
  channel = efx->channel[0];
  goto ldv_56652;
  ldv_56651: 
  tmp___3 = efx_channel_has_tx_queues(channel);
  if (tmp___3) {
    tmp___4 = 0;
  } else {
    tmp___4 = 1;
  }
  if (tmp___4) {

  } else {
    tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
    goto ldv_56649;
    ldv_56648: 
    efx_reado_table(efx, & txd_ptr_tbl, 16056320U, tx_queue->queue);
    if ((int )txd_ptr_tbl.u64[0] & 1 || (int )(txd_ptr_tbl.u64[1] >> 24) & 1) {
      if ((efx->msg_enable & 8192U) != 0U) {
        descriptor.modname = "sfc";
        descriptor.function = "efx_check_tx_flush_complete";
        descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c";
        descriptor.format = "flush did not complete on TXQ %d\n";
        descriptor.lineno = 625U;
        descriptor.flags = 0U;
        tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
        if (tmp != 0L) {
          __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                               "flush did not complete on TXQ %d\n", tx_queue->queue);
        } else {

        }
      } else {

      }
      i = 0;
    } else {
      tmp___1 = atomic_cmpxchg(& tx_queue->flush_outstanding, 1, 0);
      if (tmp___1 != 0) {
        if ((efx->msg_enable & 8192U) != 0U) {
          descriptor___0.modname = "sfc";
          descriptor___0.function = "efx_check_tx_flush_complete";
          descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c";
          descriptor___0.format = "flush complete on TXQ %d, so drain the queue\n";
          descriptor___0.lineno = 634U;
          descriptor___0.flags = 0U;
          tmp___0 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
          if (tmp___0 != 0L) {
            __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                                 "flush complete on TXQ %d, so drain the queue\n",
                                 tx_queue->queue);
          } else {

          }
        } else {

        }
        efx_farch_magic_event(channel, tx_queue->queue | 66560U);
      } else {

      }
    }
    tx_queue = tx_queue + 1;
    ldv_56649: ;
    if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
      tmp___2 = efx_tx_queue_used(tx_queue);
      if ((int )tmp___2) {
        goto ldv_56648;
      } else {
        goto ldv_56650;
      }
    } else {

    }
    ldv_56650: ;
  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56652: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56651;
  } else {

  }

  return (i);
}
}
static int efx_farch_do_flush(struct efx_nic *efx ) 
{ 
  unsigned int timeout ;
  unsigned long tmp ;
  struct efx_channel *channel ;
  struct efx_rx_queue *rx_queue ;
  struct efx_tx_queue *tx_queue ;
  int rc ;
  bool tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  bool tmp___3 ;
  int tmp___4 ;
  bool tmp___5 ;
  int tmp___6 ;
  bool tmp___7 ;
  int tmp___8 ;
  long __ret ;
  wait_queue_t __wait ;
  long __ret___0 ;
    klee_make_symbolic(&__ret___0, sizeof(long), "__ret___0");
  long __int ;
    klee_make_symbolic(&__int, sizeof(long), "__int");
  long tmp___9 ;
    klee_make_symbolic(&tmp___9, sizeof(long), "tmp___9");
  bool __cond ;
  bool tmp___10 ;
  bool __cond___0 ;
  bool tmp___11 ;
  int tmp___12 ;
    klee_make_symbolic(&tmp___12, sizeof(int), "tmp___12");
  int tmp___13 ;
    klee_make_symbolic(&tmp___13, sizeof(int), "tmp___13");
  int tmp___14 ;
  int tmp___15 ;
  int tmp___16 ;
    klee_make_symbolic(&tmp___16, sizeof(int), "tmp___16");
  bool tmp___17 ;
  int tmp___18 ;

  {
  tmp = msecs_to_jiffies(5000U);
  timeout = (unsigned int )tmp;
  rc = 0;
  channel = efx->channel[0];
  goto ldv_56669;
  ldv_56668: 
  tmp___1 = efx_channel_has_tx_queues(channel);
  if (tmp___1) {
    tmp___2 = 0;
  } else {
    tmp___2 = 1;
  }
  if (tmp___2) {

  } else {
    tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
    goto ldv_56663;
    ldv_56662: 
    efx_farch_flush_tx_queue(tx_queue);
    tx_queue = tx_queue + 1;
    ldv_56663: ;
    if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
      tmp___0 = efx_tx_queue_used(tx_queue);
      if ((int )tmp___0) {
        goto ldv_56662;
      } else {
        goto ldv_56664;
      }
    } else {

    }
    ldv_56664: ;
  }
  tmp___3 = efx_channel_has_rx_queue(channel);
  if (tmp___3) {
    tmp___4 = 0;
  } else {
    tmp___4 = 1;
  }
  if (tmp___4) {

  } else {
    rx_queue = & channel->rx_queue;
    goto ldv_56666;
    ldv_56665: 
    rx_queue->flush_pending = 1;
    atomic_inc(& efx->rxq_flush_pending);
    rx_queue = (struct efx_rx_queue *)0;
    ldv_56666: ;
    if ((unsigned long )rx_queue != (unsigned long )((struct efx_rx_queue *)0)) {
      goto ldv_56665;
    } else {

    }

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56669: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56668;
  } else {

  }

  goto ldv_56692;
  ldv_56691: 
  tmp___5 = efx_siena_sriov_enabled(efx);
  if ((int )tmp___5) {
    rc = efx_mcdi_flush_rxqs(efx);
    if (rc == 0) {
      goto wait;
    } else {

    }
  } else {

  }
  channel = efx->channel[0];
  goto ldv_56676;
  ldv_56675: 
  tmp___7 = efx_channel_has_rx_queue(channel);
  if (tmp___7) {
    tmp___8 = 0;
  } else {
    tmp___8 = 1;
  }
  if (tmp___8) {

  } else {
    rx_queue = & channel->rx_queue;
    goto ldv_56674;
    ldv_56673: 
    tmp___6 = atomic_read((atomic_t const   *)(& efx->rxq_flush_outstanding));
    if (tmp___6 > 3) {
      goto ldv_56672;
    } else {

    }
    if ((int )rx_queue->flush_pending) {
      rx_queue->flush_pending = 0;
      atomic_dec(& efx->rxq_flush_pending);
      atomic_inc(& efx->rxq_flush_outstanding);
      efx_farch_flush_rx_queue(rx_queue);
    } else {

    }
    rx_queue = (struct efx_rx_queue *)0;
    ldv_56674: ;
    if ((unsigned long )rx_queue != (unsigned long )((struct efx_rx_queue *)0)) {
      goto ldv_56673;
    } else {

    }
    ldv_56672: ;
  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56676: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56675;
  } else {

  }

  wait: 
  __ret = (long )timeout;
  __might_sleep("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c",
                703, 0);
  tmp___11 = efx_farch_flush_wake(efx);
  __cond___0 = tmp___11;
  if ((int )__cond___0 && __ret == 0L) {
    __ret = 1L;
  } else {

  }
  if (((int )__cond___0 || __ret == 0L) == 0) {
    __ret___0 = (long )timeout;
    INIT_LIST_HEAD(& __wait.task_list);
    __wait.flags = 0U;
    ldv_56688: 
    tmp___9 = prepare_to_wait_event(& efx->flush_wq, & __wait, 2);
    __int = tmp___9;
    tmp___10 = efx_farch_flush_wake(efx);
    __cond = tmp___10;
    if ((int )__cond && __ret___0 == 0L) {
      __ret___0 = 1L;
    } else {

    }
    if (((int )__cond || __ret___0 == 0L) != 0) {
      goto ldv_56687;
    } else {

    }
    __ret___0 = schedule_timeout(__ret___0);
    goto ldv_56688;
    ldv_56687: 
    finish_wait(& efx->flush_wq, & __wait);
    __ret = __ret___0;
  } else {

  }
  timeout = (unsigned int )__ret;
  ldv_56692: ;
  if (timeout != 0U) {
    tmp___12 = atomic_read((atomic_t const   *)(& efx->active_queues));
    if (tmp___12 > 0) {
      goto ldv_56691;
    } else {
      goto ldv_56693;
    }
  } else {

  }
  ldv_56693: 
  tmp___16 = atomic_read((atomic_t const   *)(& efx->active_queues));
  if (tmp___16 != 0) {
    tmp___17 = efx_check_tx_flush_complete(efx);
    if (tmp___17) {
      tmp___18 = 0;
    } else {
      tmp___18 = 1;
    }
    if (tmp___18) {
      if ((efx->msg_enable & 8192U) != 0U) {
        tmp___13 = atomic_read((atomic_t const   *)(& efx->rxq_flush_pending));
        tmp___14 = atomic_read((atomic_t const   *)(& efx->rxq_flush_outstanding));
        tmp___15 = atomic_read((atomic_t const   *)(& efx->active_queues));
        netdev_err((struct net_device  const  *)efx->net_dev, "failed to flush %d queues (rx %d+%d)\n",
                   tmp___15, tmp___14, tmp___13);
      } else {

      }
      rc = -110;
      atomic_set(& efx->active_queues, 0);
      atomic_set(& efx->rxq_flush_pending, 0);
      atomic_set(& efx->rxq_flush_outstanding, 0);
    } else {

    }
  } else {

  }
  return (rc);
}
}
int efx_farch_fini_dmaq(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;
  struct efx_tx_queue *tx_queue ;
  struct efx_rx_queue *rx_queue ;
  int rc ;
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;

  {
  rc = 0;
  if ((unsigned int )efx->state != 3U) {
    if ((unsigned int )*((unsigned char *)efx->pci_dev + 2529UL) != 0U) {
      (*((efx->type)->prepare_flush))(efx);
      rc = efx_farch_do_flush(efx);
      (*((efx->type)->finish_flush))(efx);
    } else {

    }
    channel = efx->channel[0];
    goto ldv_56708;
    ldv_56707: 
    tmp = efx_channel_has_rx_queue(channel);
    if (tmp) {
      tmp___0 = 0;
    } else {
      tmp___0 = 1;
    }
    if (tmp___0) {

    } else {
      rx_queue = & channel->rx_queue;
      goto ldv_56702;
      ldv_56701: 
      efx_farch_rx_fini(rx_queue);
      rx_queue = (struct efx_rx_queue *)0;
      ldv_56702: ;
      if ((unsigned long )rx_queue != (unsigned long )((struct efx_rx_queue *)0)) {
        goto ldv_56701;
      } else {

      }

    }
    tmp___2 = efx_channel_has_tx_queues(channel);
    if (tmp___2) {
      tmp___3 = 0;
    } else {
      tmp___3 = 1;
    }
    if (tmp___3) {

    } else {
      tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
      goto ldv_56705;
      ldv_56704: 
      efx_farch_tx_fini(tx_queue);
      tx_queue = tx_queue + 1;
      ldv_56705: ;
      if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
        tmp___1 = efx_tx_queue_used(tx_queue);
        if ((int )tmp___1) {
          goto ldv_56704;
        } else {
          goto ldv_56706;
        }
      } else {

      }
      ldv_56706: ;
    }
    channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
    ldv_56708: ;
    if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
      goto ldv_56707;
    } else {

    }

  } else {

  }
  return (rc);
}
}
void efx_farch_finish_flr(struct efx_nic *efx ) 
{ 


  {
  atomic_set(& efx->rxq_flush_pending, 0);
  atomic_set(& efx->rxq_flush_outstanding, 0);
  atomic_set(& efx->active_queues, 0);
  return;
}
}
void efx_farch_ev_read_ack(struct efx_channel *channel ) 
{ 
  efx_dword_t reg ;
  struct efx_nic *efx ;

  {
  efx = channel->efx;
  reg.u32[0] = channel->eventq_read_ptr & channel->eventq_mask;
  efx_writed(efx, (efx_dword_t const   *)(& reg), (unsigned int )(efx->type)->evq_rptr_tbl_base + (unsigned int )(channel->channel * 16));
  return;
}
}
void efx_farch_generate_event(struct efx_nic *efx , unsigned int evq , efx_qword_t *event ) 
{ 
  efx_oword_t drv_ev_reg ;

  {
  drv_ev_reg.u32[0] = event->u32[0];
  drv_ev_reg.u32[1] = event->u32[1];
  drv_ev_reg.u32[2] = 0U;
  drv_ev_reg.u32[3] = 0U;
  drv_ev_reg.u64[0] = drv_ev_reg.u64[0];
  drv_ev_reg.u64[1] = (drv_ev_reg.u64[1] & 0xfffffffffffff000ULL) | (unsigned long long )evq;
  efx_writeo(efx, (efx_oword_t const   *)(& drv_ev_reg), 1088U);
  return;
}
}
static void efx_farch_magic_event(struct efx_channel *channel , u32 magic ) 
{ 
  efx_qword_t event ;

  {
  event.u64[0] = (unsigned long long )magic | 8070450532247928832ULL;
  efx_farch_generate_event(channel->efx, (unsigned int )channel->channel, & event);
  return;
}
}
static int efx_farch_handle_tx_event(struct efx_channel *channel , efx_qword_t *event ) 
{ 
  unsigned int tx_ev_desc_ptr ;
    klee_make_symbolic(&tx_ev_desc_ptr, sizeof(int), "tx_ev_desc_ptr");
  unsigned int tx_ev_q_label ;
    klee_make_symbolic(&tx_ev_q_label, sizeof(int), "tx_ev_q_label");
  struct efx_tx_queue *tx_queue ;
  struct efx_nic *efx ;
  int tx_packets ;
  unsigned long __var ;
  long tmp ;
  long tmp___0 ;

  {
  efx = channel->efx;
  tx_packets = 0;
  __var = 0UL;
  tmp = ldv__builtin_expect((unsigned long )*((unsigned long volatile   *)(& efx->reset_pending)) != 0UL,
                         0L);
  if (tmp != 0L) {
    return (0);
  } else {

  }
  tmp___0 = ldv__builtin_expect((long )((int )(event->u64[0] >> 12)) & 1L, 1L);
  if (tmp___0 != 0L) {
    tx_ev_desc_ptr = (unsigned int )event->u64[0] & 4095U;
    tx_ev_q_label = (unsigned int )(event->u64[0] >> 32) & 31U;
    tx_queue = efx_channel_get_tx_queue(channel, tx_ev_q_label & 3U);
    tx_packets = (int )((tx_ev_desc_ptr - tx_queue->read_count) & tx_queue->ptr_mask);
    efx_xmit_done(tx_queue, tx_ev_desc_ptr);
  } else
  if ((int )(event->u64[0] >> 15) & 1) {
    tx_ev_q_label = (unsigned int )(event->u64[0] >> 32) & 31U;
    tx_queue = efx_channel_get_tx_queue(channel, tx_ev_q_label & 3U);
    netif_tx_lock___0(efx->net_dev);
    efx_farch_notify_tx_desc(tx_queue);
    netif_tx_unlock___0(efx->net_dev);
  } else
  if ((int )(event->u64[0] >> 38) & 1) {
    efx_schedule_reset(efx, 12);
  } else
  if ((efx->msg_enable & 128U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "channel %d unexpected TX event %08x:%08x\n",
               channel->channel, event->u32[1], event->u32[0]);
  } else {

  }
  return (tx_packets);
}
}
static u16 efx_farch_handle_rx_not_ok(struct efx_rx_queue *rx_queue , efx_qword_t const   *event ) 
{ 
  struct efx_channel *channel ;
  struct efx_channel *tmp ;
  struct efx_nic *efx ;
  bool rx_ev_buf_owner_id_err ;
  bool rx_ev_ip_hdr_chksum_err ;
  bool rx_ev_tcp_udp_chksum_err ;
  bool rx_ev_eth_crc_err ;
  bool rx_ev_frm_trunc ;
  bool rx_ev_drib_nib ;
  bool rx_ev_tobe_disc ;
  bool rx_ev_other_err ;
  bool rx_ev_pause_frm ;
  bool rx_ev_hdr_type ;
  bool rx_ev_mcast_pkt ;
  unsigned int rx_ev_pkt_type ;
    klee_make_symbolic(&rx_ev_pkt_type, sizeof(int), "rx_ev_pkt_type");
  int tmp___0 ;

  {
  tmp = efx_rx_queue_channel(rx_queue);
  channel = tmp;
  efx = rx_queue->efx;
  rx_ev_hdr_type = ((event->u64[0] >> 42) & 3ULL) != 0ULL;
  rx_ev_mcast_pkt = ((event->u64[0] >> 39) & 1ULL) != 0ULL;
  rx_ev_tobe_disc = ((event->u64[0] >> 47) & 1ULL) != 0ULL;
  rx_ev_pkt_type = (unsigned int )(event->u64[0] >> 44) & 7U;
  rx_ev_buf_owner_id_err = ((event->u64[0] >> 54) & 1ULL) != 0ULL;
  rx_ev_ip_hdr_chksum_err = ((event->u64[0] >> 52) & 1ULL) != 0ULL;
  rx_ev_tcp_udp_chksum_err = ((event->u64[0] >> 51) & 1ULL) != 0ULL;
  rx_ev_eth_crc_err = ((event->u64[0] >> 50) & 1ULL) != 0ULL;
  rx_ev_frm_trunc = ((event->u64[0] >> 49) & 1ULL) != 0ULL;
  tmp___0 = efx_nic_rev(efx);
  rx_ev_drib_nib = tmp___0 <= 1 && ((event->u64[0] >> 49) & 1ULL) != 0ULL;
  rx_ev_pause_frm = ((event->u64[0] >> 55) & 1ULL) != 0ULL;
  rx_ev_other_err = ((((((int )rx_ev_drib_nib | (int )rx_ev_tcp_udp_chksum_err) | (int )rx_ev_buf_owner_id_err) | (int )rx_ev_eth_crc_err) | (int )rx_ev_frm_trunc) | (int )rx_ev_ip_hdr_chksum_err) != 0;
  if ((int )rx_ev_frm_trunc) {
    channel->n_rx_frm_trunc = channel->n_rx_frm_trunc + 1U;
  } else
  if ((int )rx_ev_tobe_disc) {
    channel->n_rx_tobe_disc = channel->n_rx_tobe_disc + 1U;
  } else
  if ((unsigned long )efx->loopback_selftest == (unsigned long )((void *)0)) {
    if ((int )rx_ev_ip_hdr_chksum_err) {
      channel->n_rx_ip_hdr_chksum_err = channel->n_rx_ip_hdr_chksum_err + 1U;
    } else
    if ((int )rx_ev_tcp_udp_chksum_err) {
      channel->n_rx_tcp_udp_chksum_err = channel->n_rx_tcp_udp_chksum_err + 1U;
    } else {

    }
  } else {

  }
  return ((((((int )rx_ev_eth_crc_err | (int )rx_ev_frm_trunc) | (int )rx_ev_drib_nib) | (int )rx_ev_tobe_disc) | (int )rx_ev_pause_frm) != 0 ? 4U : 0U);
}
}
static bool efx_farch_handle_rx_bad_index(struct efx_rx_queue *rx_queue , unsigned int index ) 
{ 
  struct efx_channel *channel ;
  struct efx_channel *tmp ;
  struct efx_nic *efx ;
  unsigned int expected ;
    klee_make_symbolic(&expected, sizeof(int), "expected");
  unsigned int dropped ;
    klee_make_symbolic(&dropped, sizeof(int), "dropped");
  int tmp___0 ;

  {
  tmp = efx_rx_queue_channel(rx_queue);
  channel = tmp;
  efx = rx_queue->efx;
  if (rx_queue->scatter_n != 0U && (((rx_queue->removed_count + rx_queue->scatter_n) - 1U) & rx_queue->ptr_mask) == index) {
    channel->n_rx_nodesc_trunc = channel->n_rx_nodesc_trunc + 1U;
    return (1);
  } else {

  }
  expected = rx_queue->removed_count & rx_queue->ptr_mask;
  dropped = (index - expected) & rx_queue->ptr_mask;
  if ((efx->msg_enable & 64U) != 0U) {
    netdev_info((struct net_device  const  *)efx->net_dev, "dropped %d events (index=%d expected=%d)\n",
                dropped, index, expected);
  } else {

  }
  tmp___0 = efx_nic_rev(efx);
  efx_schedule_reset(efx, tmp___0 <= 1 ? 11 : 7);
  return (0);
}
}
static void efx_farch_handle_rx_event(struct efx_channel *channel , efx_qword_t const   *event ) 
{ 
  unsigned int rx_ev_desc_ptr ;
    klee_make_symbolic(&rx_ev_desc_ptr, sizeof(int), "rx_ev_desc_ptr");
  unsigned int rx_ev_byte_cnt ;
    klee_make_symbolic(&rx_ev_byte_cnt, sizeof(int), "rx_ev_byte_cnt");
  unsigned int rx_ev_hdr_type ;
    klee_make_symbolic(&rx_ev_hdr_type, sizeof(int), "rx_ev_hdr_type");
  unsigned int rx_ev_mcast_pkt ;
    klee_make_symbolic(&rx_ev_mcast_pkt, sizeof(int), "rx_ev_mcast_pkt");
  unsigned int expected_ptr ;
    klee_make_symbolic(&expected_ptr, sizeof(int), "expected_ptr");
  bool rx_ev_pkt_ok ;
  bool rx_ev_sop ;
  bool rx_ev_cont ;
  u16 flags ;
  struct efx_rx_queue *rx_queue ;
  struct efx_nic *efx ;
  unsigned long __var ;
  long tmp ;
  int __ret_warn_on ;
  long tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  long tmp___3 ;
  long tmp___4 ;
  long tmp___5 ;
  unsigned int rx_ev_mcast_hash_match ;
    klee_make_symbolic(&rx_ev_mcast_hash_match, sizeof(int), "rx_ev_mcast_hash_match");
  long tmp___6 ;

  {
  efx = channel->efx;
  __var = 0UL;
  tmp = ldv__builtin_expect((unsigned long )*((unsigned long volatile   *)(& efx->reset_pending)) != 0UL,
                         0L);
  if (tmp != 0L) {
    return;
  } else {

  }
  rx_ev_cont = ((event->u64[0] >> 31) & 1ULL) != 0ULL;
  rx_ev_sop = ((event->u64[0] >> 15) & 1ULL) != 0ULL;
  __ret_warn_on = ((event->u64[0] >> 32) & 31ULL) != (unsigned long long )channel->channel;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c",
                       1001);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  rx_queue = efx_channel_get_rx_queue(channel);
  rx_ev_desc_ptr = (unsigned int )event->u64[0] & 4095U;
  expected_ptr = (rx_queue->removed_count + rx_queue->scatter_n) & rx_queue->ptr_mask;
  tmp___3 = ldv__builtin_expect(rx_ev_desc_ptr != expected_ptr, 0L);
  if (tmp___3 != 0L) {
    goto _L;
  } else {
    tmp___4 = ldv__builtin_expect((int )rx_ev_sop != (rx_queue->scatter_n == 0U), 0L);
    if (tmp___4 != 0L) {
      _L: /* CIL Label */ 
      if (rx_ev_desc_ptr != expected_ptr) {
        tmp___1 = efx_farch_handle_rx_bad_index(rx_queue, rx_ev_desc_ptr);
        if (tmp___1) {
          tmp___2 = 0;
        } else {
          tmp___2 = 1;
        }
        if (tmp___2) {
          return;
        } else {

        }
      } else {

      }
      if (rx_queue->scatter_n != 0U) {
        efx_rx_packet(rx_queue, rx_queue->removed_count & rx_queue->ptr_mask, rx_queue->scatter_n,
                      0U, 4);
        rx_queue->removed_count = rx_queue->removed_count + rx_queue->scatter_n;
        rx_queue->scatter_n = 0U;
      } else {

      }
      if (rx_ev_desc_ptr != expected_ptr) {
        return;
      } else {

      }
      if (! rx_ev_sop) {
        efx_rx_packet(rx_queue, rx_queue->removed_count & rx_queue->ptr_mask, 1U,
                      0U, 4);
        rx_queue->removed_count = rx_queue->removed_count + 1U;
        return;
      } else {

      }
    } else {

    }
  }
  rx_queue->scatter_n = rx_queue->scatter_n + 1U;
  if ((int )rx_ev_cont) {
    return;
  } else {

  }
  rx_ev_byte_cnt = (unsigned int )(event->u64[0] >> 16) & 16383U;
  rx_ev_pkt_ok = ((event->u64[0] >> 56) & 1ULL) != 0ULL;
  rx_ev_hdr_type = (unsigned int )(event->u64[0] >> 42) & 3U;
  tmp___5 = ldv__builtin_expect((long )rx_ev_pkt_ok, 1L);
  if (tmp___5 != 0L) {
    flags = 0U;
    switch (rx_ev_hdr_type) {
    case 0U: 
    flags = (u16 )((unsigned int )flags | 64U);
    case 1U: 
    flags = (u16 )((unsigned int )flags | 2U);
    case 2U: ;
    case 3U: ;
    goto ldv_56789;
    }
    ldv_56789: ;
  } else {
    flags = efx_farch_handle_rx_not_ok(rx_queue, event);
  }
  rx_ev_mcast_pkt = (unsigned int )(event->u64[0] >> 39) & 1U;
  if (rx_ev_mcast_pkt != 0U) {
    rx_ev_mcast_hash_match = (unsigned int )(event->u64[0] >> 40) & 1U;
    tmp___6 = ldv__builtin_expect(rx_ev_mcast_hash_match == 0U, 0L);
    if (tmp___6 != 0L) {
      channel->n_rx_mcast_mismatch = channel->n_rx_mcast_mismatch + 1U;
      flags = (u16 )((unsigned int )flags | 4U);
    } else {

    }
  } else {

  }
  channel->irq_mod_score = channel->irq_mod_score + 2U;
  efx_rx_packet(rx_queue, rx_queue->removed_count & rx_queue->ptr_mask, rx_queue->scatter_n,
                rx_ev_byte_cnt, (int )flags);
  rx_queue->removed_count = rx_queue->removed_count + rx_queue->scatter_n;
  rx_queue->scatter_n = 0U;
  return;
}
}
static void efx_farch_handle_tx_flush_done(struct efx_nic *efx , efx_qword_t *event ) 
{ 
  struct efx_tx_queue *tx_queue ;
  int qid ;
    klee_make_symbolic(&qid, sizeof(int), "qid");
  int tmp ;

  {
  qid = (int )event->u64[0] & 16383;
  if ((unsigned int )qid < efx->n_tx_channels * 4U) {
    tx_queue = efx_get_tx_queue(efx, (unsigned int )(qid / 4), (unsigned int )(qid % 4));
    tmp = atomic_cmpxchg(& tx_queue->flush_outstanding, 1, 0);
    if (tmp != 0) {
      efx_farch_magic_event(tx_queue->channel, tx_queue->queue | 66560U);
    } else {

    }
  } else {

  }
  return;
}
}
static void efx_farch_handle_rx_flush_done(struct efx_nic *efx , efx_qword_t *event ) 
{ 
  struct efx_channel *channel ;
  struct efx_rx_queue *rx_queue ;
  int qid ;
  bool failed ;
  bool tmp ;
  int tmp___0 ;
  int tmp___1 ;
  struct efx_channel *tmp___2 ;
  bool tmp___3 ;

  {
  qid = (int )event->u64[0] & 4095;
  failed = ((event->u64[0] >> 12) & 1ULL) != 0ULL;
  if ((unsigned int )qid >= efx->n_channels) {
    return;
  } else {

  }
  channel = efx_get_channel(efx, (unsigned int )qid);
  tmp = efx_channel_has_rx_queue(channel);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return;
  } else {

  }
  rx_queue = efx_channel_get_rx_queue(channel);
  if ((int )failed) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_info((struct net_device  const  *)efx->net_dev, "RXQ %d flush retry\n",
                  qid);
    } else {

    }
    rx_queue->flush_pending = 1;
    atomic_inc(& efx->rxq_flush_pending);
  } else {
    tmp___1 = efx_rx_queue_index(rx_queue);
    tmp___2 = efx_rx_queue_channel(rx_queue);
    efx_farch_magic_event(tmp___2, (u32 )(tmp___1 | 66304));
  }
  atomic_dec(& efx->rxq_flush_outstanding);
  tmp___3 = efx_farch_flush_wake(efx);
  if ((int )tmp___3) {
    __wake_up(& efx->flush_wq, 3U, 1, (void *)0);
  } else {

  }
  return;
}
}
static void efx_farch_handle_drain_event(struct efx_channel *channel ) 
{ 
  struct efx_nic *efx ;
  int __ret_warn_on ;
  int tmp ;
  long tmp___0 ;
  bool tmp___1 ;

  {
  efx = channel->efx;
  tmp = atomic_read((atomic_t const   *)(& efx->active_queues));
  __ret_warn_on = tmp == 0;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c",
                       1152);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  atomic_dec(& efx->active_queues);
  tmp___1 = efx_farch_flush_wake(efx);
  if ((int )tmp___1) {
    __wake_up(& efx->flush_wq, 3U, 1, (void *)0);
  } else {

  }
  return;
}
}
static void efx_farch_handle_generated_event(struct efx_channel *channel , efx_qword_t *event ) 
{ 
  struct efx_nic *efx ;
  struct efx_rx_queue *rx_queue ;
  struct efx_rx_queue *tmp___0 ;
  struct efx_rx_queue *tmp___1 ;
  bool tmp___2 ;
  unsigned int magic ;
  unsigned int code ;
    klee_make_symbolic(&code, sizeof(int), "code");
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  struct _ddebug descriptor ;
  long tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;

  {
  efx = channel->efx;
  tmp___2 = efx_channel_has_rx_queue(channel);
  if ((int )tmp___2) {
    tmp___0 = efx_channel_get_rx_queue(channel);
    tmp___1 = tmp___0;
  } else {
    tmp___1 = (struct efx_rx_queue *)0;
  }
  rx_queue = tmp___1;
  magic = (unsigned int )event->u64[0];
  code = magic >> 8;
  if ((unsigned int )(channel->channel | 65792) == magic) {
    __vpp_verify = (void const   *)0;
    switch (4UL) {
    case 1UL: ;
    switch (4UL) {
    case 1UL: 
    __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
    goto ldv_56824;
    case 2UL: 
    __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
    goto ldv_56824;
    case 4UL: 
    __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
    goto ldv_56824;
    case 8UL: 
    __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
    goto ldv_56824;
    default: 
    __bad_percpu_size();
    }
    ldv_56824: 
    pscr_ret__ = pfo_ret__;
    goto ldv_56830;
    case 2UL: ;
    switch (4UL) {
    case 1UL: 
    __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
    goto ldv_56834;
    case 2UL: 
    __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
    goto ldv_56834;
    case 4UL: 
    __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
    goto ldv_56834;
    case 8UL: 
    __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
    goto ldv_56834;
    default: 
    __bad_percpu_size();
    }
    ldv_56834: 
    pscr_ret__ = pfo_ret_____0;
    goto ldv_56830;
    case 4UL: ;
    switch (4UL) {
    case 1UL: 
    __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
    goto ldv_56843;
    case 2UL: 
    __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
    goto ldv_56843;
    case 4UL: 
    __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
    goto ldv_56843;
    case 8UL: 
    __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
    goto ldv_56843;
    default: 
    __bad_percpu_size();
    }
    ldv_56843: 
    pscr_ret__ = pfo_ret_____1;
    goto ldv_56830;
    case 8UL: ;
    switch (4UL) {
    case 1UL: 
    __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
    goto ldv_56852;
    case 2UL: 
    __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
    goto ldv_56852;
    case 4UL: 
    __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
    goto ldv_56852;
    case 8UL: 
    __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
    goto ldv_56852;
    default: 
    __bad_percpu_size();
    }
    ldv_56852: 
    pscr_ret__ = pfo_ret_____2;
    goto ldv_56830;
    default: 
    __bad_size_call_parameter();
    goto ldv_56830;
    }
    ldv_56830: 
    channel->event_test_cpu = pscr_ret__;
  } else
  if ((unsigned long )rx_queue != (unsigned long )((struct efx_rx_queue *)0)) {
    tmp___5 = efx_rx_queue_index(rx_queue);
    if ((unsigned int )(tmp___5 | 66048) == magic) {
      efx_fast_push_rx_descriptors(rx_queue, 1);
    } else {
      goto _L___0;
    }
  } else
  _L___0: /* CIL Label */ 
  if ((unsigned long )rx_queue != (unsigned long )((struct efx_rx_queue *)0)) {
    tmp___4 = efx_rx_queue_index(rx_queue);
    if ((unsigned int )(tmp___4 | 66304) == magic) {
      efx_farch_handle_drain_event(channel);
    } else {
      goto _L;
    }
  } else
  _L: /* CIL Label */ 
  if (code == 260U) {
    efx_farch_handle_drain_event(channel);
  } else
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_farch_handle_generated_event";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c";
    descriptor.format = "channel %d received generated event %08x:%08x\n";
    descriptor.lineno = 1184U;
    descriptor.flags = 0U;
    tmp___3 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___3 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "channel %d received generated event %08x:%08x\n", channel->channel,
                           event->u32[1], event->u32[0]);
    } else {

    }
  } else {

  }
  return;
}
}
static void efx_farch_handle_driver_event(struct efx_channel *channel , efx_qword_t *event ) 
{ 
  struct efx_nic *efx ;
  unsigned int ev_sub_code ;
    klee_make_symbolic(&ev_sub_code, sizeof(int), "ev_sub_code");
  unsigned int ev_sub_data ;
    klee_make_symbolic(&ev_sub_data, sizeof(int), "ev_sub_data");
  struct _ddebug descriptor ;
  long tmp ;
  int tmp___0 ;

  {
  efx = channel->efx;
  ev_sub_code = (unsigned int )(event->u64[0] >> 56) & 15U;
  ev_sub_data = (unsigned int )event->u64[0] & 16383U;
  switch (ev_sub_code) {
  case 0U: 
  efx_farch_handle_tx_flush_done(efx, event);
  efx_siena_sriov_tx_flush_done(efx, event);
  goto ldv_56871;
  case 1U: 
  efx_farch_handle_rx_flush_done(efx, event);
  efx_siena_sriov_rx_flush_done(efx, event);
  goto ldv_56871;
  case 2U: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_farch_handle_driver_event";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c";
    descriptor.format = "channel %d EVQ %d initialised\n";
    descriptor.lineno = 1218U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "channel %d EVQ %d initialised\n", channel->channel, ev_sub_data);
    } else {

    }
  } else {

  }
  goto ldv_56871;
  case 5U: ;
  goto ldv_56871;
  case 6U: ;
  goto ldv_56871;
  case 10U: ;
  goto ldv_56871;
  case 11U: ;
  if ((efx->msg_enable & 64U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "channel %d seen DRIVER RX_RESET event. Resetting.\n",
               channel->channel);
  } else {

  }
  atomic_inc(& efx->rx_reset);
  tmp___0 = efx_nic_rev(efx);
  efx_schedule_reset(efx, tmp___0 <= 1 ? 11 : 7);
  goto ldv_56871;
  case 14U: ;
  if (ev_sub_data <= 127U) {
    if ((efx->msg_enable & 64U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "RX DMA Q %d reports descriptor fetch error. RX Q %d is disabled.\n",
                 ev_sub_data, ev_sub_data);
    } else {

    }
    efx_schedule_reset(efx, 12);
  } else {
    efx_siena_sriov_desc_fetch_err(efx, ev_sub_data);
  }
  goto ldv_56871;
  case 15U: ;
  if (ev_sub_data <= 127U) {
    if ((efx->msg_enable & 128U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "TX DMA Q %d reports descriptor fetch error. TX Q %d is disabled.\n",
                 ev_sub_data, ev_sub_data);
    } else {

    }
    efx_schedule_reset(efx, 12);
  } else {
    efx_siena_sriov_desc_fetch_err(efx, ev_sub_data);
  }
  goto ldv_56871;
  default: ;
  goto ldv_56871;
  }
  ldv_56871: ;
  return;
}
}
int efx_farch_ev_process(struct efx_channel *channel , int budget ) 
{ 
  struct efx_nic *efx ;
  unsigned int read_ptr ;
    klee_make_symbolic(&read_ptr, sizeof(int), "read_ptr");
  efx_qword_t event ;
  efx_qword_t *p_event ;
  int ev_code ;
    klee_make_symbolic(&ev_code, sizeof(int), "ev_code");
  int tx_packets ;
  int spent ;
  int tmp ;
  int tmp___0 ;
  bool tmp___1 ;

  {
  efx = channel->efx;
  tx_packets = 0;
  spent = 0;
  if (budget <= 0) {
    return (spent);
  } else {

  }
  read_ptr = channel->eventq_read_ptr;
  ldv_56911: 
  p_event = efx_event(channel, read_ptr);
  event = *p_event;
  tmp = efx_event_present(& event);
  if (tmp == 0) {
    goto ldv_56899;
  } else {

  }
  p_event->u64[0] = 0xffffffffffffffffULL;
  read_ptr = read_ptr + 1U;
  ev_code = (int )(event.u64[0] >> 60);
  switch (ev_code) {
  case 0: 
  efx_farch_handle_rx_event(channel, (efx_qword_t const   *)(& event));
  spent = spent + 1;
  if (spent == budget) {
    goto out;
  } else {

  }
  goto ldv_56903;
  case 2: 
  tmp___0 = efx_farch_handle_tx_event(channel, & event);
  tx_packets = tmp___0 + tx_packets;
  if ((unsigned int )tx_packets > efx->txq_entries) {
    spent = budget;
    goto out;
  } else {

  }
  goto ldv_56903;
  case 7: 
  efx_farch_handle_generated_event(channel, & event);
  goto ldv_56903;
  case 5: 
  efx_farch_handle_driver_event(channel, & event);
  goto ldv_56903;
  case 8: 
  efx_siena_sriov_event(channel, & event);
  goto ldv_56903;
  case 12: 
  efx_mcdi_process_event(channel, & event);
  goto ldv_56903;
  case 6: ;
  if ((unsigned long )(efx->type)->handle_global_event != (unsigned long )((bool (*/* const  */)(struct efx_channel * ,
                                                                                                 efx_qword_t * ))0)) {
    tmp___1 = (*((efx->type)->handle_global_event))(channel, & event);
    if ((int )tmp___1) {
      goto ldv_56903;
    } else {

    }
  } else {

  }
  default: ;
  if (((channel->efx)->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)(channel->efx)->net_dev, "channel %d unknown event type %d (data %08x:%08x)\n",
               channel->channel, ev_code, event.u32[1], event.u32[0]);
  } else {

  }
  }
  ldv_56903: ;
  goto ldv_56911;
  ldv_56899: ;
  out: 
  channel->eventq_read_ptr = read_ptr;
  return (spent);
}
}
int efx_farch_ev_probe(struct efx_channel *channel ) 
{ 
  struct efx_nic *efx ;
  unsigned int entries ;
  int tmp ;

  {
  efx = channel->efx;
  entries = channel->eventq_mask + 1U;
  tmp = efx_alloc_special_buffer(efx, & channel->eventq, entries * 8U);
  return (tmp);
}
}
int efx_farch_ev_init(struct efx_channel *channel ) 
{ 
  efx_oword_t reg ;
  struct efx_nic *efx ;
  struct _ddebug descriptor ;
  long tmp ;
  int tmp___0 ;
  unsigned long tmp___1 ;

  {
  efx = channel->efx;
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_farch_ev_init";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c";
    descriptor.format = "channel %d event queue in special buffers %d-%d\n";
    descriptor.lineno = 1377U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "channel %d event queue in special buffers %d-%d\n", channel->channel,
                           channel->eventq.index, (channel->eventq.index + channel->eventq.entries) - 1U);
    } else {

    }
  } else {

  }
  tmp___0 = efx_nic_rev(efx);
  if (tmp___0 > 2) {
    reg.u64[0] = 8589934592ULL;
    reg.u64[1] = 0ULL;
    efx_writeo_table(efx, (efx_oword_t const   *)(& reg), 16187392U, (unsigned int )channel->channel);
  } else {

  }
  efx_init_special_buffer(efx, & channel->eventq);
  memset(channel->eventq.buf.addr, 255, (size_t )channel->eventq.buf.len);
  tmp___1 = __ffs((unsigned long )channel->eventq.entries);
  reg.u64[0] = (((unsigned long long )tmp___1 << 20) | (unsigned long long )channel->eventq.index) | 8388608ULL;
  reg.u64[1] = 0ULL;
  efx_writeo_table(efx, (efx_oword_t const   *)(& reg), (efx->type)->evq_ptr_tbl_base,
                   (unsigned int )channel->channel);
  return (0);
}
}
void efx_farch_ev_fini(struct efx_channel *channel ) 
{ 
  efx_oword_t reg ;
  struct efx_nic *efx ;
  int tmp ;

  {
  efx = channel->efx;
  reg.u64[0] = 0ULL;
  reg.u64[1] = 0ULL;
  efx_writeo_table(efx, (efx_oword_t const   *)(& reg), (efx->type)->evq_ptr_tbl_base,
                   (unsigned int )channel->channel);
  tmp = efx_nic_rev(efx);
  if (tmp > 2) {
    efx_writeo_table(efx, (efx_oword_t const   *)(& reg), 16187392U, (unsigned int )channel->channel);
  } else {

  }
  efx_fini_special_buffer(efx, & channel->eventq);
  return;
}
}
void efx_farch_ev_remove(struct efx_channel *channel ) 
{ 


  {
  efx_free_special_buffer(channel->efx, & channel->eventq);
  return;
}
}
void efx_farch_ev_test_generate(struct efx_channel *channel ) 
{ 


  {
  efx_farch_magic_event(channel, (u32 )(channel->channel | 65792));
  return;
}
}
void efx_farch_rx_defer_refill(struct efx_rx_queue *rx_queue ) 
{ 
  int tmp ;
  struct efx_channel *tmp___0 ;

  {
  tmp = efx_rx_queue_index(rx_queue);
  tmp___0 = efx_rx_queue_channel(rx_queue);
  efx_farch_magic_event(tmp___0, (u32 )(tmp | 66048));
  return;
}
}
__inline static void efx_farch_interrupts(struct efx_nic *efx , bool enabled , bool force ) 
{ 
  efx_oword_t int_en_reg_ker ;

  {
  int_en_reg_ker.u64[0] = (((unsigned long long )efx->irq_level << 8) | ((unsigned long long )force << 3)) | (unsigned long long )enabled;
  int_en_reg_ker.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& int_en_reg_ker), 16U);
  return;
}
}
void efx_farch_irq_enable_master(struct efx_nic *efx ) 
{ 


  {
  ((efx_oword_t *)efx->irq_status.addr)->u64[0] = 0ULL;
  ((efx_oword_t *)efx->irq_status.addr)->u64[1] = 0ULL;
  __asm__  volatile   ("sfence": : : "memory");
  efx_farch_interrupts(efx, 1, 0);
  return;
}
}
void efx_farch_irq_disable_master(struct efx_nic *efx ) 
{ 


  {
  efx_farch_interrupts(efx, 0, 0);
  return;
}
}
void efx_farch_irq_test_generate(struct efx_nic *efx ) 
{ 


  {
  efx_farch_interrupts(efx, 1, 1);
  return;
}
}
irqreturn_t efx_farch_fatal_interrupt(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  efx_oword_t *int_ker ;
  efx_oword_t fatal_intr ;
  int error ;
  int mem_perr ;
    klee_make_symbolic(&mem_perr, sizeof(int), "mem_perr");
  efx_oword_t reg ;
  bool tmp ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  int_ker = (efx_oword_t *)efx->irq_status.addr;
  efx_reado(efx, & fatal_intr, 560U);
  error = (int )fatal_intr.u64[0] & 4095;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "SYSTEM OLD_ERROR %08x:%08x:%08x:%08x status %08x:%08x:%08x:%08x: %s\n",
               int_ker->u32[3], int_ker->u32[2], int_ker->u32[1], int_ker->u32[0],
               fatal_intr.u32[3], fatal_intr.u32[2], fatal_intr.u32[1], fatal_intr.u32[0],
               error != 0 ? (char *)"disabling bus mastering" : (char *)"no recognised error");
  } else {

  }
  mem_perr = (int )(fatal_intr.u64[0] >> 8) & 1 || (int )fatal_intr.u64[0] & 1;
  if (mem_perr != 0) {
    efx_reado(efx, & reg, 608U);
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "SYSTEM OLD_ERROR: memory parity error %08x:%08x:%08x:%08x\n",
                 reg.u32[3], reg.u32[2], reg.u32[1], reg.u32[0]);
    } else {

    }
  } else {

  }
  pci_clear_master(efx->pci_dev);
  tmp = efx_nic_is_dual_func(efx);
  if ((int )tmp) {
    pci_clear_master(nic_data->pci_dev2);
  } else {

  }
  efx_farch_irq_disable_master(efx);
  if (efx->int_error_count == 0U || (long )(efx->int_error_expire - (unsigned long )jiffies) < 0L) {
    efx->int_error_count = 0U;
    efx->int_error_expire = (unsigned long )jiffies + 900000UL;
  } else {

  }
  efx->int_error_count = efx->int_error_count + 1U;
  if (efx->int_error_count <= 4U) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "SYSTEM OLD_ERROR - reset scheduled\n");
    } else {

    }
    efx_schedule_reset(efx, 10);
  } else {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "SYSTEM OLD_ERROR - max number of errors seen.NIC will be disabled\n");
    } else {

    }
    efx_schedule_reset(efx, 7);
  }
  return (1);
}
}
irqreturn_t efx_farch_legacy_interrupt(int irq , void *dev_id ) 
{ 
  struct efx_nic *efx ;
  bool soft_enabled ;
  bool __var ;
  efx_oword_t *int_ker ;
  irqreturn_t result ;
  struct efx_channel *channel ;
  efx_dword_t reg ;
  u32 queues ;
  int syserr ;
    klee_make_symbolic(&syserr, sizeof(int), "syserr");
  int tmp ;
  irqreturn_t tmp___0 ;
  long tmp___1 ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  long tmp___2 ;
  efx_qword_t *event ;
  unsigned int tmp___3 ;
  int tmp___4 ;
  long tmp___5 ;
  int pscr_ret_____0 ;
    klee_make_symbolic(&pscr_ret_____0, sizeof(int), "pscr_ret_____0");
  void const   *__vpp_verify___0 ;
  int pfo_ret_____3 ;
    klee_make_symbolic(&pfo_ret_____3, sizeof(int), "pfo_ret_____3");
  int pfo_ret_____4 ;
    klee_make_symbolic(&pfo_ret_____4, sizeof(int), "pfo_ret_____4");
  int pfo_ret_____5 ;
    klee_make_symbolic(&pfo_ret_____5, sizeof(int), "pfo_ret_____5");
  int pfo_ret_____6 ;
    klee_make_symbolic(&pfo_ret_____6, sizeof(int), "pfo_ret_____6");

  {
  efx = (struct efx_nic *)dev_id;
  __var = 0;
  soft_enabled = *((bool volatile   *)(& efx->irq_soft_enabled));
  int_ker = (efx_oword_t *)efx->irq_status.addr;
  result = 0;
  efx_readd(efx, & reg, 144U);
  queues = reg.u32[0];
  if (reg.u32[0] == 4294967295U) {
    tmp = efx_try_recovery(efx);
    if (tmp != 0) {
      if (! efx->eeh_disabled_legacy_irq) {
        disable_irq_nosync((unsigned int )efx->legacy_irq);
        efx->eeh_disabled_legacy_irq = 1;
      } else {

      }
    } else {

    }
  } else {

  }
  if (((1U << (int )efx->irq_level) & queues) != 0U && (int )soft_enabled) {
    syserr = (int )int_ker->u64[1] & 1;
    tmp___1 = ldv__builtin_expect(syserr != 0, 0L);
    if (tmp___1 != 0L) {
      tmp___0 = efx_farch_fatal_interrupt(efx);
      return (tmp___0);
    } else {

    }
    __vpp_verify = (void const   *)0;
    switch (4UL) {
    case 1UL: ;
    switch (4UL) {
    case 1UL: 
    __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
    goto ldv_56987;
    case 2UL: 
    __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
    goto ldv_56987;
    case 4UL: 
    __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
    goto ldv_56987;
    case 8UL: 
    __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
    goto ldv_56987;
    default: 
    __bad_percpu_size();
    }
    ldv_56987: 
    pscr_ret__ = pfo_ret__;
    goto ldv_56993;
    case 2UL: ;
    switch (4UL) {
    case 1UL: 
    __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
    goto ldv_56997;
    case 2UL: 
    __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
    goto ldv_56997;
    case 4UL: 
    __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
    goto ldv_56997;
    case 8UL: 
    __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
    goto ldv_56997;
    default: 
    __bad_percpu_size();
    }
    ldv_56997: 
    pscr_ret__ = pfo_ret_____0;
    goto ldv_56993;
    case 4UL: ;
    switch (4UL) {
    case 1UL: 
    __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
    goto ldv_57006;
    case 2UL: 
    __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
    goto ldv_57006;
    case 4UL: 
    __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
    goto ldv_57006;
    case 8UL: 
    __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
    goto ldv_57006;
    default: 
    __bad_percpu_size();
    }
    ldv_57006: 
    pscr_ret__ = pfo_ret_____1;
    goto ldv_56993;
    case 8UL: ;
    switch (4UL) {
    case 1UL: 
    __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
    goto ldv_57015;
    case 2UL: 
    __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
    goto ldv_57015;
    case 4UL: 
    __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
    goto ldv_57015;
    case 8UL: 
    __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
    goto ldv_57015;
    default: 
    __bad_percpu_size();
    }
    ldv_57015: 
    pscr_ret__ = pfo_ret_____2;
    goto ldv_56993;
    default: 
    __bad_size_call_parameter();
    goto ldv_56993;
    }
    ldv_56993: 
    efx->last_irq_cpu = pscr_ret__;
  } else {

  }
  if (queues != 0U) {
    efx->irq_zero_count = 0U;
    tmp___2 = ldv__builtin_expect((long )soft_enabled, 1L);
    if (tmp___2 != 0L) {
      channel = efx->channel[0];
      goto ldv_57024;
      ldv_57023: ;
      if ((int )queues & 1) {
        efx_schedule_channel_irq(channel);
      } else {

      }
      queues = queues >> 1;
      channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
      ldv_57024: ;
      if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
        goto ldv_57023;
      } else {

      }

    } else {

    }
    result = 1;
  } else {
    tmp___3 = efx->irq_zero_count;
    efx->irq_zero_count = efx->irq_zero_count + 1U;
    if (tmp___3 == 0U) {
      result = 1;
    } else {

    }
    tmp___5 = ldv__builtin_expect((long )soft_enabled, 1L);
    if (tmp___5 != 0L) {
      channel = efx->channel[0];
      goto ldv_57028;
      ldv_57027: 
      event = efx_event(channel, channel->eventq_read_ptr);
      tmp___4 = efx_event_present(event);
      if (tmp___4 != 0) {
        efx_schedule_channel_irq(channel);
      } else {
        efx_farch_ev_read_ack(channel);
      }
      channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
      ldv_57028: ;
      if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
        goto ldv_57027;
      } else {

      }

    } else {

    }
  }
  if ((unsigned int )result == 1U) {
    if (0) {
      if ((efx->msg_enable & 512U) != 0U) {
        __vpp_verify___0 = (void const   *)0;
        switch (4UL) {
        case 1UL: ;
        switch (4UL) {
        case 1UL: 
        __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____3): "m" (cpu_number));
        goto ldv_57035;
        case 2UL: 
        __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
        goto ldv_57035;
        case 4UL: 
        __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
        goto ldv_57035;
        case 8UL: 
        __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
        goto ldv_57035;
        default: 
        __bad_percpu_size();
        }
        ldv_57035: 
        pscr_ret_____0 = pfo_ret_____3;
        goto ldv_57041;
        case 2UL: ;
        switch (4UL) {
        case 1UL: 
        __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____4): "m" (cpu_number));
        goto ldv_57045;
        case 2UL: 
        __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
        goto ldv_57045;
        case 4UL: 
        __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
        goto ldv_57045;
        case 8UL: 
        __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
        goto ldv_57045;
        default: 
        __bad_percpu_size();
        }
        ldv_57045: 
        pscr_ret_____0 = pfo_ret_____4;
        goto ldv_57041;
        case 4UL: ;
        switch (4UL) {
        case 1UL: 
        __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____5): "m" (cpu_number));
        goto ldv_57054;
        case 2UL: 
        __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
        goto ldv_57054;
        case 4UL: 
        __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
        goto ldv_57054;
        case 8UL: 
        __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
        goto ldv_57054;
        default: 
        __bad_percpu_size();
        }
        ldv_57054: 
        pscr_ret_____0 = pfo_ret_____5;
        goto ldv_57041;
        case 8UL: ;
        switch (4UL) {
        case 1UL: 
        __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____6): "m" (cpu_number));
        goto ldv_57063;
        case 2UL: 
        __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
        goto ldv_57063;
        case 4UL: 
        __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
        goto ldv_57063;
        case 8UL: 
        __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
        goto ldv_57063;
        default: 
        __bad_percpu_size();
        }
        ldv_57063: 
        pscr_ret_____0 = pfo_ret_____6;
        goto ldv_57041;
        default: 
        __bad_size_call_parameter();
        goto ldv_57041;
        }
        ldv_57041: 
        netdev_printk("\017", (struct net_device  const  *)efx->net_dev, "IRQ %d on CPU %d status %08x\n",
                      irq, pscr_ret_____0, reg.u32[0]);
      } else {

      }
    } else {

    }
  } else {

  }
  return (result);
}
}
irqreturn_t efx_farch_msi_interrupt(int irq , void *dev_id ) 
{ 
  struct efx_msi_context *context ;
  struct efx_nic *efx ;
  efx_oword_t *int_ker ;
  int syserr ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  bool __var ;
  long tmp ;
  irqreturn_t tmp___0 ;
  long tmp___1 ;
  int pscr_ret_____0 ;
  void const   *__vpp_verify___0 ;
  int pfo_ret_____3 ;
  int pfo_ret_____4 ;
  int pfo_ret_____5 ;
  int pfo_ret_____6 ;

  {
  context = (struct efx_msi_context *)dev_id;
  efx = context->efx;
  int_ker = (efx_oword_t *)efx->irq_status.addr;
  if (0) {
    if ((efx->msg_enable & 512U) != 0U) {
      __vpp_verify = (void const   *)0;
      switch (4UL) {
      case 1UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
      goto ldv_57085;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_57085;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_57085;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_57085;
      default: 
      __bad_percpu_size();
      }
      ldv_57085: 
      pscr_ret__ = pfo_ret__;
      goto ldv_57091;
      case 2UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57095;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57095;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57095;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_57095;
      default: 
      __bad_percpu_size();
      }
      ldv_57095: 
      pscr_ret__ = pfo_ret_____0;
      goto ldv_57091;
      case 4UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57104;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57104;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57104;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_57104;
      default: 
      __bad_percpu_size();
      }
      ldv_57104: 
      pscr_ret__ = pfo_ret_____1;
      goto ldv_57091;
      case 8UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57113;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57113;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57113;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_57113;
      default: 
      __bad_percpu_size();
      }
      ldv_57113: 
      pscr_ret__ = pfo_ret_____2;
      goto ldv_57091;
      default: 
      __bad_size_call_parameter();
      goto ldv_57091;
      }
      ldv_57091: 
      netdev_printk("\017", (struct net_device  const  *)efx->net_dev, "IRQ %d on CPU %d status %08x:%08x:%08x:%08x\n",
                    irq, pscr_ret__, int_ker->u32[3], int_ker->u32[2], int_ker->u32[1],
                    int_ker->u32[0]);
    } else {

    }
  } else {

  }
  __var = 0;
  tmp = ldv__builtin_expect((long )*((bool volatile   *)(& efx->irq_soft_enabled)), 1L);
  if (tmp == 0L) {
    return (1);
  } else {

  }
  if (context->index == efx->irq_level) {
    syserr = (int )int_ker->u64[1] & 1;
    tmp___1 = ldv__builtin_expect(syserr != 0, 0L);
    if (tmp___1 != 0L) {
      tmp___0 = efx_farch_fatal_interrupt(efx);
      return (tmp___0);
    } else {

    }
    __vpp_verify___0 = (void const   *)0;
    switch (4UL) {
    case 1UL: ;
    switch (4UL) {
    case 1UL: 
    __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____3): "m" (cpu_number));
    goto ldv_57129;
    case 2UL: 
    __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
    goto ldv_57129;
    case 4UL: 
    __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
    goto ldv_57129;
    case 8UL: 
    __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
    goto ldv_57129;
    default: 
    __bad_percpu_size();
    }
    ldv_57129: 
    pscr_ret_____0 = pfo_ret_____3;
    goto ldv_57135;
    case 2UL: ;
    switch (4UL) {
    case 1UL: 
    __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____4): "m" (cpu_number));
    goto ldv_57139;
    case 2UL: 
    __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
    goto ldv_57139;
    case 4UL: 
    __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
    goto ldv_57139;
    case 8UL: 
    __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
    goto ldv_57139;
    default: 
    __bad_percpu_size();
    }
    ldv_57139: 
    pscr_ret_____0 = pfo_ret_____4;
    goto ldv_57135;
    case 4UL: ;
    switch (4UL) {
    case 1UL: 
    __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____5): "m" (cpu_number));
    goto ldv_57148;
    case 2UL: 
    __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
    goto ldv_57148;
    case 4UL: 
    __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
    goto ldv_57148;
    case 8UL: 
    __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
    goto ldv_57148;
    default: 
    __bad_percpu_size();
    }
    ldv_57148: 
    pscr_ret_____0 = pfo_ret_____5;
    goto ldv_57135;
    case 8UL: ;
    switch (4UL) {
    case 1UL: 
    __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____6): "m" (cpu_number));
    goto ldv_57157;
    case 2UL: 
    __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
    goto ldv_57157;
    case 4UL: 
    __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
    goto ldv_57157;
    case 8UL: 
    __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
    goto ldv_57157;
    default: 
    __bad_percpu_size();
    }
    ldv_57157: 
    pscr_ret_____0 = pfo_ret_____6;
    goto ldv_57135;
    default: 
    __bad_size_call_parameter();
    goto ldv_57135;
    }
    ldv_57135: 
    efx->last_irq_cpu = pscr_ret_____0;
  } else {

  }
  efx_schedule_channel_irq(efx->channel[context->index]);
  return (1);
}
}
void efx_farch_rx_push_indir_table(struct efx_nic *efx ) 
{ 
  size_t i ;
  efx_dword_t dword ;
  int tmp ;
  long tmp___0 ;

  {
  i = 0UL;
  tmp = efx_nic_rev(efx);
  tmp___0 = ldv__builtin_expect(tmp <= 1, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c"),
                         "i" (1661), "i" (12UL));
    ldv_57170: ;
    goto ldv_57170;
  } else {

  }
  i = 0UL;
  goto ldv_57172;
  ldv_57171: 
  dword.u32[0] = efx->rx_indir_table[i];
  efx_writed(efx, (efx_dword_t const   *)(& dword), (unsigned int )(i + 1028096UL) * 16U);
  i = i + 1UL;
  ldv_57172: ;
  if (i <= 127UL) {
    goto ldv_57171;
  } else {

  }

  return;
}
}
void efx_farch_dimension_resources(struct efx_nic *efx , unsigned int sram_lim_qw ) 
{ 
  unsigned int vi_count ;
    klee_make_symbolic(&vi_count, sizeof(int), "vi_count");
  unsigned int buftbl_min ;
    klee_make_symbolic(&buftbl_min, sizeof(int), "buftbl_min");
  struct siena_nic_data *nic_data ;
  unsigned int _max1 ;
  unsigned int _max2 ;
  unsigned int vi_dc_entries ;
    klee_make_symbolic(&vi_dc_entries, sizeof(int), "vi_dc_entries");
  unsigned int buftbl_free ;
    klee_make_symbolic(&buftbl_free, sizeof(int), "buftbl_free");
  unsigned int entries_per_vf ;
    klee_make_symbolic(&entries_per_vf, sizeof(int), "entries_per_vf");
  unsigned int vf_limit ;
    klee_make_symbolic(&vf_limit, sizeof(int), "vf_limit");
  unsigned int _max1___0 ;
  unsigned int _max2___0 ;
  unsigned int tmp ;
  unsigned int _min1 ;
  unsigned int _min2 ;
  unsigned int tmp___0 ;
  bool tmp___1 ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  buftbl_min = (unsigned int )(((((unsigned long )efx->n_rx_channels + (unsigned long )(efx->n_tx_channels * 4U)) + (unsigned long )efx->n_channels * 4UL) * 32768UL) / 4096UL);
  _max1 = efx->n_channels;
  _max2 = efx->n_tx_channels * 4U;
  vi_count = _max1 > _max2 ? _max1 : _max2;
  if ((unsigned long )(efx->type)->sriov_wanted != (unsigned long )((bool (*/* const  */)(struct efx_nic * ))0)) {
    tmp___1 = (*((efx->type)->sriov_wanted))(efx);
    if ((int )tmp___1) {
      nic_data->vf_buftbl_base = buftbl_min;
      vi_dc_entries = 80U;
      _max1___0 = vi_count;
      _max2___0 = 128U;
      vi_count = _max1___0 > _max2___0 ? _max1___0 : _max2___0;
      buftbl_free = (sram_lim_qw - buftbl_min) - vi_count * vi_dc_entries;
      tmp = efx_vf_size(efx);
      entries_per_vf = (unsigned int )((unsigned long )vi_dc_entries + 32UL) * tmp;
      _min1 = buftbl_free / entries_per_vf;
      _min2 = 896U >> (int )efx->vi_scale;
      vf_limit = _min1 < _min2 ? _min1 : _min2;
      if (efx->vf_count > vf_limit) {
        if ((efx->msg_enable & 2U) != 0U) {
          netdev_err((struct net_device  const  *)efx->net_dev, "Reducing VF count from from %d to %d\n",
                     efx->vf_count, vf_limit);
        } else {

        }
        efx->vf_count = vf_limit;
      } else {

      }
      tmp___0 = efx_vf_size(efx);
      vi_count = efx->vf_count * tmp___0 + vi_count;
    } else {

    }
  } else {

  }
  efx->tx_dc_base = sram_lim_qw - vi_count * 16U;
  efx->rx_dc_base = efx->tx_dc_base - vi_count * 64U;
  return;
}
}
u32 efx_farch_fpga_ver(struct efx_nic *efx ) 
{ 
  efx_oword_t altera_build ;

  {
  efx_reado(efx, & altera_build, 768U);
  return ((u32 )altera_build.u64[0]);
}
}
void efx_farch_init_common(struct efx_nic *efx ) 
{ 
  efx_oword_t temp ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
  temp.u64[0] = (unsigned long long )efx->tx_dc_base;
  temp.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 1568U);
  temp.u64[0] = (unsigned long long )efx->rx_dc_base;
  temp.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 1552U);
  temp.u64[0] = 1ULL;
  temp.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 2592U);
  temp.u64[0] = 3ULL;
  temp.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 2112U);
  temp.u64[0] = 56ULL;
  temp.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 2128U);
  temp.u64[0] = efx->irq_status.dma_addr;
  temp.u64[1] = (unsigned int )efx->interrupt_mode <= 1U;
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 48U);
  tmp = efx_nic_rev(efx);
  if (tmp == 3 && (unsigned int )efx->interrupt_mode > 1U) {
    efx->irq_level = 31U;
  } else {
    efx->irq_level = 0U;
  }
  temp.u64[0] = 833223655424ULL;
  temp.u64[1] = 0ULL;
  tmp___0 = efx_nic_rev(efx);
  if (tmp___0 > 2) {
    temp.u64[0] = temp.u64[0] | 17592186044416ULL;
    temp.u64[1] = temp.u64[1];
  } else {

  }
  temp.u64[0] = ~ temp.u64[0];
  temp.u64[1] = ~ temp.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 560U);
  efx_reado(efx, & temp, 2688U);
  temp.u64[0] = temp.u64[0];
  temp.u64[1] = (temp.u64[1] & 0xffffffffffffff00ULL) | 254ULL;
  temp.u64[0] = temp.u64[0] | 144115188075855872ULL;
  temp.u64[1] = temp.u64[1];
  temp.u64[0] = temp.u64[0] | 262144ULL;
  temp.u64[1] = temp.u64[1];
  temp.u64[0] = temp.u64[0];
  temp.u64[1] = temp.u64[1] | 33554432ULL;
  temp.u64[0] = temp.u64[0] | 131072ULL;
  temp.u64[1] = temp.u64[1];
  temp.u64[0] = temp.u64[0] | 576460752303423488ULL;
  temp.u64[1] = temp.u64[1];
  temp.u64[0] = (temp.u64[0] & 0xffffffffffe7ffffULL) | 1048576ULL;
  temp.u64[1] = temp.u64[1];
  temp.u64[0] = temp.u64[0] | 17592181850112ULL;
  temp.u64[1] = temp.u64[1];
  tmp___1 = efx_nic_rev(efx);
  if (tmp___1 > 1) {
    temp.u64[0] = temp.u64[0] | 128ULL;
    temp.u64[1] = temp.u64[1];
  } else {

  }
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 2688U);
  tmp___2 = efx_nic_rev(efx);
  if (tmp___2 > 1) {
    temp.u64[0] = 11015701ULL;
    temp.u64[1] = 0ULL;
    efx_writeo(efx, (efx_oword_t const   *)(& temp), 2704U);
  } else {

  }
  return;
}
}
static void efx_farch_filter_table_clear_entry(struct efx_nic *efx , struct efx_farch_filter_table *table ,
                                               unsigned int filter_idx ) ;
static u16 efx_farch_filter_hash(u32 key ) 
{ 
  u16 tmp ;

  {
  tmp = (unsigned int )((u16 )(key >> 16)) ^ 8191U;
  tmp = (u16 )((((int )tmp >> 3) ^ (int )tmp) ^ ((int )tmp >> 6));
  tmp = (u16 )(((int )tmp >> 9) ^ (int )tmp);
  tmp = (int )((u16 )((int )((short )((int )tmp << 13)) ^ (int )((short )tmp))) ^ (int )((u16 )key);
  tmp = (u16 )((((int )tmp >> 3) ^ (int )tmp) ^ ((int )tmp >> 6));
  return ((u16 )(((int )tmp >> 9) ^ (int )tmp));
}
}
static u16 efx_farch_filter_increment(u32 key ) 
{ 


  {
  return ((unsigned int )((u16 )key) * 2U - 1U);
}
}
static enum efx_farch_filter_table_id efx_farch_filter_spec_table_id(struct efx_farch_filter_spec  const  *spec ) 
{ 


  {
  return ((enum efx_farch_filter_table_id )(((int )spec->type >> 2) + (((int )spec->flags & 16) != 0 ? 2 : 0)));
}
}
static void efx_farch_filter_push_rx_config(struct efx_nic *efx ) 
{ 
  struct efx_farch_filter_state *state ;
  struct efx_farch_filter_table *table ;
  efx_oword_t filter_ctl ;
  int tmp ;

  {
  state = (struct efx_farch_filter_state *)efx->filter_state;
  efx_reado(efx, & filter_ctl, 2064U);
  table = (struct efx_farch_filter_table *)(& state->table);
  filter_ctl.u64[0] = (filter_ctl.u64[0] & 0xffffffffffffff00ULL) | (unsigned long long )(table->search_limit[0] + 1U);
  filter_ctl.u64[1] = filter_ctl.u64[1];
  filter_ctl.u64[0] = (filter_ctl.u64[0] & 0xffffffffffff00ffULL) | ((unsigned long long )(table->search_limit[1] + 3U) << 8);
  filter_ctl.u64[1] = filter_ctl.u64[1];
  filter_ctl.u64[0] = (filter_ctl.u64[0] & 0xffffff00ffffffffULL) | ((unsigned long long )(table->search_limit[2] + 1U) << 32);
  filter_ctl.u64[1] = filter_ctl.u64[1];
  filter_ctl.u64[0] = (filter_ctl.u64[0] & 0xffffffffff00ffffULL) | ((unsigned long long )(table->search_limit[3] + 3U) << 16);
  filter_ctl.u64[1] = filter_ctl.u64[1];
  table = (struct efx_farch_filter_table *)(& state->table) + 1UL;
  if (table->size != 0U) {
    filter_ctl.u64[0] = filter_ctl.u64[0];
    filter_ctl.u64[1] = (filter_ctl.u64[1] & 0xffffffffc03fffffULL) | ((unsigned long long )(table->search_limit[4] + 1U) << 22);
    filter_ctl.u64[0] = filter_ctl.u64[0];
    filter_ctl.u64[1] = (filter_ctl.u64[1] & 0xffffffc03fffffffULL) | ((unsigned long long )(table->search_limit[5] + 3U) << 30);
  } else {

  }
  table = (struct efx_farch_filter_table *)(& state->table) + 2UL;
  if (table->size != 0U) {
    filter_ctl.u64[0] = (filter_ctl.u64[0] & 0xff8007ffffffffffULL) | ((unsigned long long )(table->spec)->dmaq_id << 43);
    filter_ctl.u64[1] = filter_ctl.u64[1];
    filter_ctl.u64[0] = (filter_ctl.u64[0] & 0xfffffbffffffffffULL) | (((unsigned long long )(table->spec)->flags & 1ULL) << 42);
    filter_ctl.u64[1] = filter_ctl.u64[1];
    filter_ctl.u64[0] = (filter_ctl.u64[0] & 144115188075855871ULL) | ((unsigned long long )(table->spec + 1UL)->dmaq_id << 57);
    filter_ctl.u64[1] = (filter_ctl.u64[1] & 0xffffffffffffffe0ULL) | (unsigned long long )((int )(table->spec + 1UL)->dmaq_id >> 7);
    filter_ctl.u64[0] = (filter_ctl.u64[0] & 0xfeffffffffffffffULL) | (((unsigned long long )(table->spec + 1UL)->flags & 1ULL) << 56);
    filter_ctl.u64[1] = filter_ctl.u64[1];
    filter_ctl.u64[0] = (filter_ctl.u64[0] & 0xfffffeffffffffffULL) | ((((int )(table->spec)->flags & (int )(table->spec + 1UL)->flags) & 2) != 0 ? 1099511627776ULL : 0ULL);
    filter_ctl.u64[1] = filter_ctl.u64[1];
  } else {
    tmp = efx_nic_rev(efx);
    if (tmp > 1) {
      filter_ctl.u64[0] = (filter_ctl.u64[0] & 0xfffffeffffffffffULL) | ((unsigned long long )efx->rx_scatter << 40);
      filter_ctl.u64[1] = filter_ctl.u64[1];
    } else {

    }
  }
  efx_writeo(efx, (efx_oword_t const   *)(& filter_ctl), 2064U);
  return;
}
}
static void efx_farch_filter_push_tx_limits(struct efx_nic *efx ) 
{ 
  struct efx_farch_filter_state *state ;
  struct efx_farch_filter_table *table ;
  efx_oword_t tx_cfg ;

  {
  state = (struct efx_farch_filter_state *)efx->filter_state;
  efx_reado(efx, & tx_cfg, 2640U);
  table = (struct efx_farch_filter_table *)(& state->table) + 3UL;
  if (table->size != 0U) {
    tx_cfg.u64[0] = tx_cfg.u64[0];
    tx_cfg.u64[1] = (tx_cfg.u64[1] & 0xfffffe01ffffffffULL) | ((unsigned long long )(table->search_limit[4] + 1U) << 33);
    tx_cfg.u64[0] = tx_cfg.u64[0];
    tx_cfg.u64[1] = (tx_cfg.u64[1] & 0xfffe01ffffffffffULL) | ((unsigned long long )(table->search_limit[5] + 3U) << 41);
  } else {

  }
  efx_writeo(efx, (efx_oword_t const   *)(& tx_cfg), 2640U);
  return;
}
}
static int efx_farch_filter_from_gen_spec(struct efx_farch_filter_spec *spec , struct efx_filter_spec  const  *gen_spec ) 
{ 
  bool is_full ;
  __be32 rhost ;
  __be32 host1 ;
  __be32 host2 ;
  __be16 rport ;
  __be16 port1 ;
  __be16 port2 ;
  __u32 tmp ;
  __u16 tmp___0 ;
  __u16 tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;
  __u16 tmp___4 ;
  bool tmp___5 ;

  {
  is_full = 0;
  if ((int )gen_spec->flags & 1 && (unsigned int )gen_spec->rss_context != 4294967295U) {
    return (-22);
  } else {

  }
  spec->priority = (unsigned char )gen_spec->priority;
  spec->flags = (u8 )gen_spec->flags;
  spec->dmaq_id = (u16 )gen_spec->dmaq_id;
  switch ((int )gen_spec->match_flags) {
  case 619: 
  is_full = 1;
  case 610: ;
  if ((unsigned int )((unsigned short )gen_spec->ether_type) != 8U) {
    return (-93);
  } else {

  }
  if ((unsigned int )((unsigned short )gen_spec->loc_port) == 0U || ((int )is_full && (unsigned int )((unsigned short )gen_spec->rem_port) == 0U)) {
    return (-99);
  } else {

  }
  switch ((int )gen_spec->ip_proto) {
  case 6: 
  spec->type = (int )is_full ? 0U : 1U;
  goto ldv_57279;
  case 17: 
  spec->type = (int )is_full ? 2U : 3U;
  goto ldv_57279;
  default: ;
  return (-93);
  }
  ldv_57279: 
  rhost = (int )is_full ? (unsigned int const   )gen_spec->rem_host[0] : 0U;
  rport = (int )is_full ? (__be16 )gen_spec->rem_port : 0U;
  host1 = rhost;
  host2 = gen_spec->loc_host[0];
  if (! is_full && (unsigned int )((unsigned char )gen_spec->ip_proto) == 17U) {
    port1 = gen_spec->loc_port;
    port2 = rport;
  } else {
    port1 = rport;
    port2 = gen_spec->loc_port;
  }
  tmp = __fswab32(host1);
  tmp___0 = __fswab16((int )port1);
  spec->data[0] = (tmp << 16) | (unsigned int )tmp___0;
  tmp___1 = __fswab16((int )port2);
  tmp___2 = __fswab32(host1);
  spec->data[1] = (unsigned int )((int )tmp___1 << 16) | (tmp___2 >> 16);
  tmp___3 = __fswab32(host2);
  spec->data[2] = tmp___3;
  goto ldv_57282;
  case 272: 
  is_full = 1;
  case 16: 
  spec->type = (int )is_full ? 4U : 5U;
  if ((int )is_full) {
    tmp___4 = __fswab16((int )gen_spec->outer_vid);
    spec->data[0] = (u32 )tmp___4;
  } else {
    spec->data[0] = 0U;
  }
  spec->data[1] = (u32 )(((((int )gen_spec->loc_mac[2] << 24) | ((int )gen_spec->loc_mac[3] << 16)) | ((int )gen_spec->loc_mac[4] << 8)) | (int )gen_spec->loc_mac[5]);
  spec->data[2] = (u32 )(((int )gen_spec->loc_mac[0] << 8) | (int )gen_spec->loc_mac[1]);
  goto ldv_57282;
  case 1024: 
  tmp___5 = is_multicast_ether_addr((u8 const   *)(& gen_spec->loc_mac));
  spec->type = (int )tmp___5 ? 9U : 8U;
  memset((void *)(& spec->data), 0, 12UL);
  goto ldv_57282;
  default: ;
  return (-93);
  }
  ldv_57282: ;
  return (0);
}
}
static void efx_farch_filter_to_gen_spec(struct efx_filter_spec *gen_spec , struct efx_farch_filter_spec  const  *spec ) 
{ 
  bool is_full ;
  __be32 host1 ;
  __be32 host2 ;
  __be16 port1 ;
  __be16 port2 ;
  __u32 tmp ;
  __u16 tmp___0 ;
  __u32 tmp___1 ;
  __u16 tmp___2 ;
  __u16 tmp___3 ;
  int __ret_warn_on ;
  long tmp___4 ;

  {
  is_full = 0;
  memset((void *)gen_spec, 0, 64UL);
  gen_spec->priority = (unsigned char )spec->priority;
  gen_spec->flags = (unsigned char )spec->flags;
  gen_spec->dmaq_id = (unsigned short )spec->dmaq_id;
  switch ((int )spec->type) {
  case 0: ;
  case 2: 
  is_full = 1;
  case 1: ;
  case 3: 
  gen_spec->match_flags = 610U;
  if ((int )is_full) {
    gen_spec->match_flags = (unsigned short )((unsigned int )gen_spec->match_flags | 9U);
  } else {

  }
  gen_spec->ether_type = 8U;
  gen_spec->ip_proto = (unsigned int )*((unsigned char *)spec + 0UL) == 0U || (unsigned int )*((unsigned char *)spec + 0UL) == 1U ? 6U : 17U;
  tmp = __fswab32((spec->data[0] >> 16) | (spec->data[1] << 16));
  host1 = tmp;
  tmp___0 = __fswab16((int )((__u16 )spec->data[0]));
  port1 = tmp___0;
  tmp___1 = __fswab32(spec->data[2]);
  host2 = tmp___1;
  tmp___2 = __fswab16((int )((__u16 )(spec->data[1] >> 16)));
  port2 = tmp___2;
  if (((int )spec->flags & 16) != 0) {
    gen_spec->loc_host[0] = host1;
    gen_spec->rem_host[0] = host2;
  } else {
    gen_spec->loc_host[0] = host2;
    gen_spec->rem_host[0] = host1;
  }
  if ((((int )gen_spec->flags & 16) != 0) ^ (int )((_Bool )(! is_full && (unsigned int )gen_spec->ip_proto == 17U))) {
    gen_spec->loc_port = port1;
    gen_spec->rem_port = port2;
  } else {
    gen_spec->loc_port = port2;
    gen_spec->rem_port = port1;
  }
  goto ldv_57300;
  case 4: 
  is_full = 1;
  case 5: 
  gen_spec->match_flags = 16U;
  if ((int )is_full) {
    gen_spec->match_flags = (unsigned short )((unsigned int )gen_spec->match_flags | 256U);
  } else {

  }
  gen_spec->loc_mac[0] = (u8 )(spec->data[2] >> 8);
  gen_spec->loc_mac[1] = (u8 )spec->data[2];
  gen_spec->loc_mac[2] = (u8 )(spec->data[1] >> 24);
  gen_spec->loc_mac[3] = (u8 )(spec->data[1] >> 16);
  gen_spec->loc_mac[4] = (u8 )(spec->data[1] >> 8);
  gen_spec->loc_mac[5] = (u8 )spec->data[1];
  tmp___3 = __fswab16((int )((__u16 )spec->data[0]));
  gen_spec->outer_vid = tmp___3;
  goto ldv_57300;
  case 8: ;
  case 9: 
  gen_spec->match_flags = 1024U;
  gen_spec->loc_mac[0] = (unsigned int )*((unsigned char *)spec + 0UL) == 9U;
  goto ldv_57300;
  default: 
  __ret_warn_on = 1;
  tmp___4 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___4 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c",
                       2229);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  goto ldv_57300;
  }
  ldv_57300: ;
  return;
}
}
static void efx_farch_filter_init_rx_auto(struct efx_nic *efx , struct efx_farch_filter_spec *spec ) 
{ 


  {
  spec->priority = 1U;
  spec->flags = (u8 )((efx->n_rx_channels > 1U ? 9 : 8) | ((int )efx->rx_scatter ? 2 : 0));
  spec->dmaq_id = 0U;
  return;
}
}
static u32 efx_farch_filter_build(efx_oword_t *filter , struct efx_farch_filter_spec *spec ) 
{ 
  u32 data3 ;
  enum efx_farch_filter_table_id tmp ;
  bool is_udp ;
  bool is_wild ;
  bool is_wild___0 ;

  {
  tmp = efx_farch_filter_spec_table_id((struct efx_farch_filter_spec  const  *)spec);
  switch ((unsigned int )tmp) {
  case 0U: 
  is_udp = (bool )((unsigned int )*((unsigned char *)spec + 0UL) == 2U || (unsigned int )*((unsigned char *)spec + 0UL) == 3U);
  filter->u64[0] = ((unsigned long long )spec->data[1] << 32) | (unsigned long long )spec->data[0];
  filter->u64[1] = ((((((unsigned long long )spec->flags & 1ULL) << 46) | (((int )spec->flags & 2) != 0 ? 35184372088832ULL : 0ULL)) | ((unsigned long long )is_udp << 44)) | ((unsigned long long )spec->dmaq_id << 32)) | (unsigned long long )spec->data[2];
  data3 = (u32 )is_udp;
  goto ldv_57319;
  case 1U: 
  is_wild = (unsigned int )*((unsigned char *)spec + 0UL) == 5U;
  filter->u64[0] = (((((unsigned long long )spec->dmaq_id << 61) | ((unsigned long long )is_wild << 60)) | ((unsigned long long )spec->data[2] << 44)) | ((unsigned long long )spec->data[1] << 12)) | (unsigned long long )spec->data[0];
  filter->u64[1] = ((((unsigned long long )spec->flags & 1ULL) << 11) | (((int )spec->flags & 2) != 0 ? 1024ULL : 0ULL)) | (unsigned long long )((int )spec->dmaq_id >> 3);
  data3 = (u32 )is_wild;
  goto ldv_57319;
  case 3U: 
  is_wild___0 = (unsigned int )*((unsigned char *)spec + 0UL) == 5U;
  filter->u64[0] = (((((unsigned long long )spec->dmaq_id << 61) | ((unsigned long long )is_wild___0 << 60)) | ((unsigned long long )spec->data[2] << 44)) | ((unsigned long long )spec->data[1] << 12)) | (unsigned long long )spec->data[0];
  filter->u64[1] = (unsigned long long )((int )spec->dmaq_id >> 3);
  data3 = (u32 )((int )is_wild___0 | ((int )spec->dmaq_id << 1));
  goto ldv_57319;
  default: 
  __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c"),
                       "i" (2303), "i" (12UL));
  ldv_57325: ;
  goto ldv_57325;
  }
  ldv_57319: ;
  return (((spec->data[0] ^ spec->data[1]) ^ spec->data[2]) ^ data3);
}
}
static bool efx_farch_filter_equal(struct efx_farch_filter_spec  const  *left , struct efx_farch_filter_spec  const  *right ) 
{ 
  int tmp ;

  {
  if ((int const   )left->type != (int const   )right->type) {
    return (0);
  } else {
    tmp = memcmp((void const   *)(& left->data), (void const   *)(& right->data),
                 12UL);
    if (tmp != 0) {
      return (0);
    } else {

    }
  }
  if (((int )left->flags & 16) != 0 && (int )((unsigned short )left->dmaq_id) != (int )((unsigned short )right->dmaq_id)) {
    return (0);
  } else {

  }
  return (1);
}
}
static u8 const   efx_farch_filter_type_match_pri[10U]  = 
  {      0U,      1U,      0U,      1U, 
        2U,      3U,      (unsigned char)0,      (unsigned char)0, 
        4U,      4U};
static enum efx_farch_filter_table_id  const  efx_farch_filter_range_table[7U]  = {      0,      0,      1,      1, 
        2,      3,      3};
__inline static u32 efx_farch_filter_make_id(struct efx_farch_filter_spec  const  *spec ,
                                             unsigned int index ) 
{ 
  unsigned int range ;
    klee_make_symbolic(&range, sizeof(int), "range");

  {
  range = (unsigned int )efx_farch_filter_type_match_pri[(int )spec->type];
  if (((int )spec->flags & 8) == 0) {
    range = range + 5U;
  } else {

  }
  return ((range << 13) | index);
}
}
__inline static enum efx_farch_filter_table_id efx_farch_filter_id_table_id(u32 id ) 
{ 
  unsigned int range ;

  {
  range = id >> 13;
  if (range <= 6U) {
    return ((enum efx_farch_filter_table_id )efx_farch_filter_range_table[range]);
  } else {
    return (4);
  }
}
}
__inline static unsigned int efx_farch_filter_id_index(u32 id ) 
{ 


  {
  return (id & 8191U);
}
}
u32 efx_farch_filter_get_rx_id_limit(struct efx_nic *efx ) 
{ 
  struct efx_farch_filter_state *state ;
  unsigned int range ;
  enum efx_farch_filter_table_id table_id ;
  unsigned int tmp ;

  {
  state = (struct efx_farch_filter_state *)efx->filter_state;
  range = 4U;
  ldv_57352: 
  table_id = efx_farch_filter_range_table[range];
  if (state->table[(unsigned int )table_id].size != 0U) {
    return ((range << 13) | state->table[(unsigned int )table_id].size);
  } else {

  }
  tmp = range;
  range = range - 1U;
  if (tmp != 0U) {
    goto ldv_57352;
  } else {

  }

  return (0U);
}
}
s32 efx_farch_filter_insert(struct efx_nic *efx , struct efx_filter_spec *gen_spec ,
                            bool replace_equal ) 
{ 
  struct efx_farch_filter_state *state ;
  struct efx_farch_filter_table *table ;
  struct efx_farch_filter_spec spec ;
  efx_oword_t filter ;
  int rep_index ;
    klee_make_symbolic(&rep_index, sizeof(int), "rep_index");
  int ins_index ;
    klee_make_symbolic(&ins_index, sizeof(int), "ins_index");
  unsigned int depth ;
  int rc ;
  enum efx_farch_filter_table_id tmp ;
  u32 key ;
  u32 tmp___0 ;
  unsigned int hash ;
  u16 tmp___1 ;
  unsigned int incr ;
    klee_make_symbolic(&incr, sizeof(int), "incr");
  u16 tmp___2 ;
  unsigned int max_rep_depth ;
    klee_make_symbolic(&max_rep_depth, sizeof(int), "max_rep_depth");
  unsigned int max_ins_depth ;
    klee_make_symbolic(&max_ins_depth, sizeof(int), "max_ins_depth");
  unsigned int i ;
  bool tmp___3 ;
  int tmp___4 ;
  struct efx_farch_filter_spec *saved_spec ;
  u32 tmp___5 ;

  {
  state = (struct efx_farch_filter_state *)efx->filter_state;
  depth = 0U;
  rc = efx_farch_filter_from_gen_spec(& spec, (struct efx_filter_spec  const  *)gen_spec);
  if (rc != 0) {
    return (rc);
  } else {

  }
  tmp = efx_farch_filter_spec_table_id((struct efx_farch_filter_spec  const  *)(& spec));
  table = (struct efx_farch_filter_table *)(& state->table) + (unsigned long )tmp;
  if (table->size == 0U) {
    return (-22);
  } else {

  }
  if ((unsigned int )table->id == 2U) {
    rep_index = (int )spec.type + -8;
    ins_index = rep_index;
    spin_lock_bh(& efx->filter_lock);
  } else {
    tmp___0 = efx_farch_filter_build(& filter, & spec);
    key = tmp___0;
    tmp___1 = efx_farch_filter_hash(key);
    hash = (unsigned int )tmp___1;
    tmp___2 = efx_farch_filter_increment(key);
    incr = (unsigned int )tmp___2;
    max_rep_depth = table->search_limit[(int )spec.type];
    max_ins_depth = (int )spec.priority <= 0 ? 5U : 200U;
    i = (table->size - 1U) & hash;
    ins_index = -1;
    depth = 1U;
    spin_lock_bh(& efx->filter_lock);
    ldv_57377: 
    tmp___4 = variable_test_bit((long )i, (unsigned long const volatile   *)table->used_bitmap);
    if (tmp___4 == 0) {
      if (ins_index < 0) {
        ins_index = (int )i;
      } else {

      }
    } else {
      tmp___3 = efx_farch_filter_equal((struct efx_farch_filter_spec  const  *)(& spec),
                                       (struct efx_farch_filter_spec  const  *)table->spec + (unsigned long )i);
      if ((int )tmp___3) {
        if (ins_index < 0) {
          ins_index = (int )i;
        } else {

        }
        rep_index = (int )i;
        goto ldv_57375;
      } else {

      }
    }
    if (depth >= max_rep_depth && (ins_index >= 0 || depth >= max_ins_depth)) {
      if (ins_index < 0) {
        rc = -16;
        goto out;
      } else {

      }
      rep_index = -1;
      goto ldv_57375;
    } else {

    }
    i = (i + incr) & (table->size - 1U);
    depth = depth + 1U;
    goto ldv_57377;
    ldv_57375: ;
  }
  if (rep_index >= 0) {
    saved_spec = table->spec + (unsigned long )rep_index;
    if ((int )spec.priority == (int )saved_spec->priority && ! replace_equal) {
      rc = -17;
      goto out;
    } else {

    }
    if ((int )spec.priority < (int )saved_spec->priority) {
      rc = -1;
      goto out;
    } else {

    }
    if ((unsigned int )*((unsigned char *)saved_spec + 0UL) == 16U || ((int )saved_spec->flags & 4) != 0) {
      spec.flags = (u8 )((unsigned int )spec.flags | 4U);
    } else {

    }
  } else {

  }
  if (ins_index != rep_index) {
    __set_bit((long )ins_index, (unsigned long volatile   *)table->used_bitmap);
    table->used = table->used + 1U;
  } else {

  }
  *(table->spec + (unsigned long )ins_index) = spec;
  if ((unsigned int )table->id == 2U) {
    efx_farch_filter_push_rx_config(efx);
  } else {
    if (table->search_limit[(int )spec.type] < depth) {
      table->search_limit[(int )spec.type] = depth;
      if (((int )spec.flags & 16) != 0) {
        efx_farch_filter_push_tx_limits(efx);
      } else {
        efx_farch_filter_push_rx_config(efx);
      }
    } else {

    }
    efx_writeo(efx, (efx_oword_t const   *)(& filter), table->offset + table->step * (unsigned int )ins_index);
    if (ins_index != rep_index && rep_index >= 0) {
      efx_farch_filter_table_clear_entry(efx, table, (unsigned int )rep_index);
    } else {

    }
  }
  tmp___5 = efx_farch_filter_make_id((struct efx_farch_filter_spec  const  *)(& spec),
                                     (unsigned int )ins_index);
  rc = (int )tmp___5;
  out: 
  spin_unlock_bh(& efx->filter_lock);
  return (rc);
}
}
static void efx_farch_filter_table_clear_entry(struct efx_nic *efx , struct efx_farch_filter_table *table ,
                                               unsigned int filter_idx ) 
{ 
  efx_oword_t filter ;
  long tmp ;
  long tmp___0 ;

  {
  tmp = ldv__builtin_expect(table->offset == 0U, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/farch.c"),
                         "i" (2563), "i" (12UL));
    ldv_57386: ;
    goto ldv_57386;
  } else {

  }
  __clear_bit((long )filter_idx, (unsigned long volatile   *)table->used_bitmap);
  table->used = table->used - 1U;
  memset((void *)table->spec + (unsigned long )filter_idx, 0, 16UL);
  efx_writeo(efx, (efx_oword_t const   *)(& filter), table->offset + table->step * filter_idx);
  tmp___0 = ldv__builtin_expect(table->used == 0U, 0L);
  if (tmp___0 != 0L) {
    memset((void *)(& table->search_limit), 0, 40UL);
    if ((unsigned int )table->id == 3U) {
      efx_farch_filter_push_tx_limits(efx);
    } else {
      efx_farch_filter_push_rx_config(efx);
    }
  } else {

  }
  return;
}
}
static int efx_farch_filter_remove(struct efx_nic *efx , struct efx_farch_filter_table *table ,
                                   unsigned int filter_idx , enum efx_filter_priority priority ) 
{ 
  struct efx_farch_filter_spec *spec ;
  int tmp ;

  {
  spec = table->spec + (unsigned long )filter_idx;
  tmp = variable_test_bit((long )filter_idx, (unsigned long const volatile   *)table->used_bitmap);
  if (tmp == 0 || (unsigned int )spec->priority != (unsigned int )priority) {
    return (-2);
  } else {

  }
  if (((int )spec->flags & 4) != 0) {
    efx_farch_filter_init_rx_auto(efx, spec);
    efx_farch_filter_push_rx_config(efx);
  } else {
    efx_farch_filter_table_clear_entry(efx, table, filter_idx);
  }
  return (0);
}
}
int efx_farch_filter_remove_safe(struct efx_nic *efx , enum efx_filter_priority priority ,
                                 u32 filter_id ) 
{ 
  struct efx_farch_filter_state *state ;
  enum efx_farch_filter_table_id table_id ;
  struct efx_farch_filter_table *table ;
  unsigned int filter_idx ;
    klee_make_symbolic(&filter_idx, sizeof(int), "filter_idx");
  struct efx_farch_filter_spec *spec ;
  int rc ;

  {
  state = (struct efx_farch_filter_state *)efx->filter_state;
  table_id = efx_farch_filter_id_table_id(filter_id);
  if ((unsigned int )table_id > 3U) {
    return (-2);
  } else {

  }
  table = (struct efx_farch_filter_table *)(& state->table) + (unsigned long )table_id;
  filter_idx = efx_farch_filter_id_index(filter_id);
  if (table->size <= filter_idx) {
    return (-2);
  } else {

  }
  spec = table->spec + (unsigned long )filter_idx;
  spin_lock_bh(& efx->filter_lock);
  rc = efx_farch_filter_remove(efx, table, filter_idx, priority);
  spin_unlock_bh(& efx->filter_lock);
  return (rc);
}
}
int efx_farch_filter_get_safe(struct efx_nic *efx , enum efx_filter_priority priority ,
                              u32 filter_id , struct efx_filter_spec *spec_buf ) 
{ 
  struct efx_farch_filter_state *state ;
  enum efx_farch_filter_table_id table_id ;
  struct efx_farch_filter_table *table ;
  struct efx_farch_filter_spec *spec ;
  unsigned int filter_idx ;
  int rc ;
  int tmp ;

  {
  state = (struct efx_farch_filter_state *)efx->filter_state;
  table_id = efx_farch_filter_id_table_id(filter_id);
  if ((unsigned int )table_id > 3U) {
    return (-2);
  } else {

  }
  table = (struct efx_farch_filter_table *)(& state->table) + (unsigned long )table_id;
  filter_idx = efx_farch_filter_id_index(filter_id);
  if (table->size <= filter_idx) {
    return (-2);
  } else {

  }
  spec = table->spec + (unsigned long )filter_idx;
  spin_lock_bh(& efx->filter_lock);
  tmp = variable_test_bit((long )filter_idx, (unsigned long const volatile   *)table->used_bitmap);
  if (tmp != 0 && (unsigned int )spec->priority == (unsigned int )priority) {
    efx_farch_filter_to_gen_spec(spec_buf, (struct efx_farch_filter_spec  const  *)spec);
    rc = 0;
  } else {
    rc = -2;
  }
  spin_unlock_bh(& efx->filter_lock);
  return (rc);
}
}
static void efx_farch_filter_table_clear(struct efx_nic *efx , enum efx_farch_filter_table_id table_id ,
                                         enum efx_filter_priority priority ) 
{ 
  struct efx_farch_filter_state *state ;
  struct efx_farch_filter_table *table ;
  unsigned int filter_idx ;

  {
  state = (struct efx_farch_filter_state *)efx->filter_state;
  table = (struct efx_farch_filter_table *)(& state->table) + (unsigned long )table_id;
  spin_lock_bh(& efx->filter_lock);
  filter_idx = 0U;
  goto ldv_57426;
  ldv_57425: ;
  if ((unsigned int )*((unsigned char *)(table->spec + (unsigned long )filter_idx) + 0UL) != 16U) {
    efx_farch_filter_remove(efx, table, filter_idx, priority);
  } else {

  }
  filter_idx = filter_idx + 1U;
  ldv_57426: ;
  if (table->size > filter_idx) {
    goto ldv_57425;
  } else {

  }
  spin_unlock_bh(& efx->filter_lock);
  return;
}
}
int efx_farch_filter_clear_rx(struct efx_nic *efx , enum efx_filter_priority priority ) 
{ 


  {
  efx_farch_filter_table_clear(efx, 0, priority);
  efx_farch_filter_table_clear(efx, 1, priority);
  efx_farch_filter_table_clear(efx, 2, priority);
  return (0);
}
}
u32 efx_farch_filter_count_rx_used(struct efx_nic *efx , enum efx_filter_priority priority ) 
{ 
  struct efx_farch_filter_state *state ;
  enum efx_farch_filter_table_id table_id ;
  struct efx_farch_filter_table *table ;
  unsigned int filter_idx ;
  u32 count ;
  int tmp ;

  {
  state = (struct efx_farch_filter_state *)efx->filter_state;
  count = 0U;
  spin_lock_bh(& efx->filter_lock);
  table_id = 0;
  goto ldv_57445;
  ldv_57444: 
  table = (struct efx_farch_filter_table *)(& state->table) + (unsigned long )table_id;
  filter_idx = 0U;
  goto ldv_57442;
  ldv_57441: 
  tmp = variable_test_bit((long )filter_idx, (unsigned long const volatile   *)table->used_bitmap);
  if (tmp != 0 && (unsigned int )(table->spec + (unsigned long )filter_idx)->priority == (unsigned int )priority) {
    count = count + 1U;
  } else {

  }
  filter_idx = filter_idx + 1U;
  ldv_57442: ;
  if (table->size > filter_idx) {
    goto ldv_57441;
  } else {

  }
  table_id = (enum efx_farch_filter_table_id )((unsigned int )table_id + 1U);
  ldv_57445: ;
  if ((unsigned int )table_id <= 2U) {
    goto ldv_57444;
  } else {

  }
  spin_unlock_bh(& efx->filter_lock);
  return (count);
}
}
s32 efx_farch_filter_get_rx_ids(struct efx_nic *efx , enum efx_filter_priority priority ,
                                u32 *buf , u32 size ) 
{ 
  struct efx_farch_filter_state *state ;
  enum efx_farch_filter_table_id table_id ;
  struct efx_farch_filter_table *table ;
  unsigned int filter_idx ;
  s32 count ;
  s32 tmp ;
  int tmp___0 ;

  {
  state = (struct efx_farch_filter_state *)efx->filter_state;
  count = 0;
  spin_lock_bh(& efx->filter_lock);
  table_id = 0;
  goto ldv_57463;
  ldv_57462: 
  table = (struct efx_farch_filter_table *)(& state->table) + (unsigned long )table_id;
  filter_idx = 0U;
  goto ldv_57460;
  ldv_57459: 
  tmp___0 = variable_test_bit((long )filter_idx, (unsigned long const volatile   *)table->used_bitmap);
  if (tmp___0 != 0 && (unsigned int )(table->spec + (unsigned long )filter_idx)->priority == (unsigned int )priority) {
    if ((u32 )count == size) {
      count = -90;
      goto out;
    } else {

    }
    tmp = count;
    count = count + 1;
    *(buf + (unsigned long )tmp) = efx_farch_filter_make_id((struct efx_farch_filter_spec  const  *)table->spec + (unsigned long )filter_idx,
                                                            filter_idx);
  } else {

  }
  filter_idx = filter_idx + 1U;
  ldv_57460: ;
  if (table->size > filter_idx) {
    goto ldv_57459;
  } else {

  }
  table_id = (enum efx_farch_filter_table_id )((unsigned int )table_id + 1U);
  ldv_57463: ;
  if ((unsigned int )table_id <= 2U) {
    goto ldv_57462;
  } else {

  }

  out: 
  spin_unlock_bh(& efx->filter_lock);
  return (count);
}
}
void efx_farch_filter_table_restore(struct efx_nic *efx ) 
{ 
  struct efx_farch_filter_state *state ;
  enum efx_farch_filter_table_id table_id ;
  struct efx_farch_filter_table *table ;
  efx_oword_t filter ;
  unsigned int filter_idx ;
  int tmp ;

  {
  state = (struct efx_farch_filter_state *)efx->filter_state;
  spin_lock_bh(& efx->filter_lock);
  table_id = 0;
  goto ldv_57479;
  ldv_57478: 
  table = (struct efx_farch_filter_table *)(& state->table) + (unsigned long )table_id;
  if (table->step == 0U) {
    goto ldv_57473;
  } else {

  }
  filter_idx = 0U;
  goto ldv_57476;
  ldv_57475: 
  tmp = variable_test_bit((long )filter_idx, (unsigned long const volatile   *)table->used_bitmap);
  if (tmp == 0) {
    goto ldv_57474;
  } else {

  }
  efx_farch_filter_build(& filter, table->spec + (unsigned long )filter_idx);
  efx_writeo(efx, (efx_oword_t const   *)(& filter), table->offset + table->step * filter_idx);
  ldv_57474: 
  filter_idx = filter_idx + 1U;
  ldv_57476: ;
  if (table->size > filter_idx) {
    goto ldv_57475;
  } else {

  }

  ldv_57473: 
  table_id = (enum efx_farch_filter_table_id )((unsigned int )table_id + 1U);
  ldv_57479: ;
  if ((unsigned int )table_id <= 3U) {
    goto ldv_57478;
  } else {

  }
  efx_farch_filter_push_rx_config(efx);
  efx_farch_filter_push_tx_limits(efx);
  spin_unlock_bh(& efx->filter_lock);
  return;
}
}
void efx_farch_filter_table_remove(struct efx_nic *efx ) 
{ 
  struct efx_farch_filter_state *state ;
  enum efx_farch_filter_table_id table_id ;

  {
  state = (struct efx_farch_filter_state *)efx->filter_state;
  table_id = 0;
  goto ldv_57487;
  ldv_57486: 
  kfree((void const   *)state->table[(unsigned int )table_id].used_bitmap);
  vfree((void const   *)state->table[(unsigned int )table_id].spec);
  table_id = (enum efx_farch_filter_table_id )((unsigned int )table_id + 1U);
  ldv_57487: ;
  if ((unsigned int )table_id <= 3U) {
    goto ldv_57486;
  } else {

  }
  kfree((void const   *)state);
  return;
}
}
int efx_farch_filter_table_probe(struct efx_nic *efx ) 
{ 
  struct efx_farch_filter_state *state ;
  struct efx_farch_filter_table *table ;
  unsigned int table_id ;
    klee_make_symbolic(&table_id, sizeof(int), "table_id");
  void *tmp ;
  int tmp___0 ;
  int tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  struct efx_farch_filter_spec *spec ;
  unsigned int i ;

  {
  tmp = kzalloc(320UL, 208U);
  state = (struct efx_farch_filter_state *)tmp;
  if ((unsigned long )state == (unsigned long )((struct efx_farch_filter_state *)0)) {
    return (-12);
  } else {

  }
  efx->filter_state = (void *)state;
  tmp___0 = efx_nic_rev(efx);
  if (tmp___0 > 1) {
    table = (struct efx_farch_filter_table *)(& state->table);
    table->id = 0;
    table->offset = 15728640U;
    table->size = 8192U;
    table->step = 32U;
  } else {

  }
  tmp___1 = efx_nic_rev(efx);
  if (tmp___1 > 2) {
    table = (struct efx_farch_filter_table *)(& state->table) + 1UL;
    table->id = 1;
    table->offset = 15728656U;
    table->size = 512U;
    table->step = 32U;
    table = (struct efx_farch_filter_table *)(& state->table) + 2UL;
    table->id = 2;
    table->size = 2U;
    table = (struct efx_farch_filter_table *)(& state->table) + 3UL;
    table->id = 3;
    table->offset = 16646144U;
    table->size = 512U;
    table->step = 16U;
  } else {

  }
  table_id = 0U;
  goto ldv_57498;
  ldv_57497: 
  table = (struct efx_farch_filter_table *)(& state->table) + (unsigned long )table_id;
  if (table->size == 0U) {
    goto ldv_57495;
  } else {

  }
  tmp___2 = kcalloc(((unsigned long )table->size + 63UL) / 64UL, 8UL, 208U);
  table->used_bitmap = (unsigned long *)tmp___2;
  if ((unsigned long )table->used_bitmap == (unsigned long )((unsigned long *)0UL)) {
    goto fail;
  } else {

  }
  tmp___3 = vzalloc((unsigned long )table->size * 16UL);
  table->spec = (struct efx_farch_filter_spec *)tmp___3;
  if ((unsigned long )table->spec == (unsigned long )((struct efx_farch_filter_spec *)0)) {
    goto fail;
  } else {

  }
  ldv_57495: 
  table_id = table_id + 1U;
  ldv_57498: ;
  if (table_id <= 3U) {
    goto ldv_57497;
  } else {

  }
  table = (struct efx_farch_filter_table *)(& state->table) + 2UL;
  if (table->size != 0U) {
    i = 0U;
    goto ldv_57503;
    ldv_57502: 
    spec = table->spec + (unsigned long )i;
    spec->type = (unsigned char )((unsigned int )((unsigned char )i) + 8U);
    efx_farch_filter_init_rx_auto(efx, spec);
    __set_bit((long )i, (unsigned long volatile   *)table->used_bitmap);
    i = i + 1U;
    ldv_57503: ;
    if (i <= 1U) {
      goto ldv_57502;
    } else {

    }

  } else {

  }
  efx_farch_filter_push_rx_config(efx);
  return (0);
  fail: 
  efx_farch_filter_table_remove(efx);
  return (-12);
}
}
void efx_farch_filter_update_rx_scatter(struct efx_nic *efx ) 
{ 
  struct efx_farch_filter_state *state ;
  enum efx_farch_filter_table_id table_id ;
  struct efx_farch_filter_table *table ;
  efx_oword_t filter ;
  unsigned int filter_idx ;
  int tmp ;

  {
  state = (struct efx_farch_filter_state *)efx->filter_state;
  spin_lock_bh(& efx->filter_lock);
  table_id = 0;
  goto ldv_57518;
  ldv_57517: 
  table = (struct efx_farch_filter_table *)(& state->table) + (unsigned long )table_id;
  filter_idx = 0U;
  goto ldv_57515;
  ldv_57514: 
  tmp = variable_test_bit((long )filter_idx, (unsigned long const volatile   *)table->used_bitmap);
  if (tmp == 0 || (unsigned int )(table->spec + (unsigned long )filter_idx)->dmaq_id >= efx->n_rx_channels) {
    goto ldv_57513;
  } else {

  }
  if ((int )efx->rx_scatter) {
    (table->spec + (unsigned long )filter_idx)->flags = (u8 )((unsigned int )(table->spec + (unsigned long )filter_idx)->flags | 2U);
  } else {
    (table->spec + (unsigned long )filter_idx)->flags = (unsigned int )(table->spec + (unsigned long )filter_idx)->flags & 253U;
  }
  if ((unsigned int )table_id == 2U) {
    goto ldv_57513;
  } else {

  }
  efx_farch_filter_build(& filter, table->spec + (unsigned long )filter_idx);
  efx_writeo(efx, (efx_oword_t const   *)(& filter), table->offset + table->step * filter_idx);
  ldv_57513: 
  filter_idx = filter_idx + 1U;
  ldv_57515: ;
  if (table->size > filter_idx) {
    goto ldv_57514;
  } else {

  }
  table_id = (enum efx_farch_filter_table_id )((unsigned int )table_id + 1U);
  ldv_57518: ;
  if ((unsigned int )table_id <= 2U) {
    goto ldv_57517;
  } else {

  }
  efx_farch_filter_push_rx_config(efx);
  spin_unlock_bh(& efx->filter_lock);
  return;
}
}
s32 efx_farch_filter_rfs_insert(struct efx_nic *efx , struct efx_filter_spec *gen_spec ) 
{ 
  s32 tmp ;

  {
  tmp = efx_farch_filter_insert(efx, gen_spec, 1);
  return (tmp);
}
}
bool efx_farch_filter_rfs_expire_one(struct efx_nic *efx , u32 flow_id , unsigned int index ) 
{ 
  struct efx_farch_filter_state *state ;
  struct efx_farch_filter_table *table ;
  int tmp ;
  bool tmp___0 ;

  {
  state = (struct efx_farch_filter_state *)efx->filter_state;
  table = (struct efx_farch_filter_table *)(& state->table);
  tmp = variable_test_bit((long )index, (unsigned long const volatile   *)table->used_bitmap);
  if (tmp != 0 && (unsigned int )*((unsigned char *)(table->spec + (unsigned long )index) + 0UL) == 0U) {
    tmp___0 = rps_may_expire_flow(efx->net_dev, (int )(table->spec + (unsigned long )index)->dmaq_id,
                                  flow_id, (int )((u16 )index));
    if ((int )tmp___0) {
      efx_farch_filter_table_clear_entry(efx, table, index);
      return (1);
    } else {

    }
  } else {

  }
  return (0);
}
}
void efx_farch_filter_sync_rx_mode(struct efx_nic *efx ) 
{ 
  struct net_device *net_dev ;
  struct netdev_hw_addr *ha ;
  union efx_multicast_hash *mc_hash ;
  u32 crc ;
  int bit ;
    klee_make_symbolic(&bit, sizeof(int), "bit");
  int tmp ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  net_dev = efx->net_dev;
  mc_hash = & efx->multicast_hash;
  tmp = efx_dev_registered(efx);
  if (tmp == 0) {
    return;
  } else {

  }
  netif_addr_lock_bh(net_dev);
  efx->unicast_filter = (net_dev->flags & 256U) == 0U;
  if ((net_dev->flags & 768U) != 0U) {
    memset((void *)mc_hash, 255, 32UL);
  } else {
    memset((void *)mc_hash, 0, 32UL);
    __mptr = (struct list_head  const  *)net_dev->mc.list.next;
    ha = (struct netdev_hw_addr *)__mptr;
    goto ldv_57544;
    ldv_57543: 
    crc = crc32_le(4294967295U, (unsigned char const   *)(& ha->addr), 6UL);
    bit = (int )crc & 255;
    __set_bit_le(bit, (void *)mc_hash);
    __mptr___0 = (struct list_head  const  *)ha->list.next;
    ha = (struct netdev_hw_addr *)__mptr___0;
    ldv_57544: ;
    if ((unsigned long )(& ha->list) != (unsigned long )(& net_dev->mc.list)) {
      goto ldv_57543;
    } else {

    }
    __set_bit_le(255, (void *)mc_hash);
  }
  netif_addr_unlock_bh(net_dev);
  return;
}
}
bool ldv_queue_work_on_129(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_130(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_131(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_132(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_133(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_134(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_135(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_136(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_137(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_138(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_139(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_140(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
extern void ___might_sleep(char const   * , int  , int  ) ;
extern struct task_struct *current_task ;
__inline static struct task_struct *get_current(void) 
{ 
  struct task_struct *pfo_ret__ ;

  {
  switch (8UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret__): "p" (& current_task));
  goto ldv_2696;
  case 2UL: 
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& current_task));
  goto ldv_2696;
  case 4UL: 
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& current_task));
  goto ldv_2696;
  case 8UL: 
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& current_task));
  goto ldv_2696;
  default: 
  __bad_percpu_size();
  }
  ldv_2696: ;
  return (pfo_ret__);
}
}
extern void *memcpy(void * , void const   * , size_t  ) ;
__inline static int ldv_mutex_is_locked_177(struct mutex *lock ) ;
__inline static int ldv_mutex_is_locked_179(struct mutex *lock ) ;
int ldv_mutex_trylock_165(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_163(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_166(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_167(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_170(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_172(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_174(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_176(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_181(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_183(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_185(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_187(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_189(struct mutex *ldv_func_arg1 ) ;
extern int mutex_lock_interruptible(struct mutex * ) ;
int ldv_mutex_lock_interruptible_169(struct mutex *ldv_func_arg1 ) ;
int ldv_mutex_lock_interruptible_171(struct mutex *ldv_func_arg1 ) ;
int ldv_mutex_lock_interruptible_173(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_162(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_164(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_168(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_175(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_180(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_182(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_184(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_186(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_188(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_mdio_lock_of_falcon_nic_data(struct mutex *lock ) ;
void ldv_mutex_unlock_mdio_lock_of_falcon_nic_data(struct mutex *lock ) ;
int ldv_mutex_lock_interruptible_spi_lock_of_falcon_nic_data(struct mutex *lock ) ;
void ldv_mutex_lock_spi_lock_of_falcon_nic_data(struct mutex *lock ) ;
void ldv_mutex_unlock_spi_lock_of_falcon_nic_data(struct mutex *lock ) ;
__inline static int test_ti_thread_flag(struct thread_info *ti , int flag ) 
{ 
  int tmp ;

  {
  tmp = variable_test_bit((long )flag, (unsigned long const volatile   *)(& ti->flags));
  return (tmp);
}
}
int ldv_mod_timer_178(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
extern int del_timer_sync(struct timer_list * ) ;
int ldv_del_timer_sync_190(struct timer_list *ldv_func_arg1 ) ;
extern unsigned long round_jiffies_up(unsigned long  ) ;
bool ldv_queue_work_on_157(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_159(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_158(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_161(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_160(struct workqueue_struct *ldv_func_arg1 ) ;
extern long schedule_timeout_uninterruptible(long  ) ;
__inline static int test_tsk_thread_flag(struct task_struct *tsk , int flag ) 
{ 
  int tmp ;

  {
  tmp = test_ti_thread_flag((struct thread_info *)tsk->stack, flag);
  return (tmp);
}
}
__inline static int signal_pending(struct task_struct *p ) 
{ 
  int tmp ;
  long tmp___0 ;

  {
  tmp = test_tsk_thread_flag(p, 2);
  tmp___0 = ldv__builtin_expect(tmp != 0, 0L);
  return ((int )tmp___0);
}
}
extern int _cond_resched(void) ;
int reg_timer_12(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) ;
void choose_timer_12(void) ;
void disable_suitable_timer_12(struct timer_list *timer ) ;
void activate_pending_timer_12(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void ldv_timer_12(int state , struct timer_list *timer ) ;
void activate_suitable_timer_12(struct timer_list *timer , unsigned long data ) ;
extern void __const_udelay(unsigned long  ) ;
extern struct pci_dev *pci_dev_get(struct pci_dev * ) ;
extern void pci_dev_put(struct pci_dev * ) ;
extern struct pci_dev *pci_get_device(unsigned int  , unsigned int  , struct pci_dev * ) ;
extern void i2c_del_adapter(struct i2c_adapter * ) ;
__inline static bool efx_link_state_equal(struct efx_link_state  const  *left , struct efx_link_state  const  *right ) 
{ 


  {
  return ((bool )((((int const   )left->up == (int const   )right->up && (int const   )left->fd == (int const   )right->fd) && (int )((unsigned char )left->fc) == (int )((unsigned char )right->fc)) && (unsigned int )left->speed == (unsigned int )right->speed));
}
}
__inline static bool efx_phy_mode_disabled(enum efx_phy_mode mode ) 
{ 


  {
  return (((unsigned int )mode & 4294967294U) != 0U);
}
}
int efx_mtd_add(struct efx_nic *efx , struct efx_mtd_partition *parts , size_t n_parts ,
                size_t sizeof_part ) ;
__inline static void efx_schedule_channel___1(struct efx_channel *channel ) 
{ 
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;

  {
  if (0) {
    if (((channel->efx)->msg_enable & 512U) != 0U) {
      __vpp_verify = (void const   *)0;
      switch (4UL) {
      case 1UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
      goto ldv_55334;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_55334;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_55334;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_55334;
      default: 
      __bad_percpu_size();
      }
      ldv_55334: 
      pscr_ret__ = pfo_ret__;
      goto ldv_55340;
      case 2UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_55344;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_55344;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_55344;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_55344;
      default: 
      __bad_percpu_size();
      }
      ldv_55344: 
      pscr_ret__ = pfo_ret_____0;
      goto ldv_55340;
      case 4UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_55353;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_55353;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_55353;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_55353;
      default: 
      __bad_percpu_size();
      }
      ldv_55353: 
      pscr_ret__ = pfo_ret_____1;
      goto ldv_55340;
      case 8UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_55362;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_55362;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_55362;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_55362;
      default: 
      __bad_percpu_size();
      }
      ldv_55362: 
      pscr_ret__ = pfo_ret_____2;
      goto ldv_55340;
      default: 
      __bad_size_call_parameter();
      goto ldv_55340;
      }
      ldv_55340: 
      netdev_printk("\017", (struct net_device  const  *)(channel->efx)->net_dev,
                    "channel %d scheduling NAPI poll on CPU%d\n", channel->channel,
                    pscr_ret__);
    } else {

    }
  } else {

  }
  napi_schedule(& channel->napi_str);
  return;
}
}
__inline static void efx_schedule_channel_irq___0(struct efx_channel *channel ) 
{ 
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;

  {
  __vpp_verify = (void const   *)0;
  switch (4UL) {
  case 1UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
  goto ldv_55379;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_55379;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_55379;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_55379;
  default: 
  __bad_percpu_size();
  }
  ldv_55379: 
  pscr_ret__ = pfo_ret__;
  goto ldv_55385;
  case 2UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_55389;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_55389;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_55389;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_55389;
  default: 
  __bad_percpu_size();
  }
  ldv_55389: 
  pscr_ret__ = pfo_ret_____0;
  goto ldv_55385;
  case 4UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_55398;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_55398;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_55398;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_55398;
  default: 
  __bad_percpu_size();
  }
  ldv_55398: 
  pscr_ret__ = pfo_ret_____1;
  goto ldv_55385;
  case 8UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_55407;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_55407;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_55407;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_55407;
  default: 
  __bad_percpu_size();
  }
  ldv_55407: 
  pscr_ret__ = pfo_ret_____2;
  goto ldv_55385;
  default: 
  __bad_size_call_parameter();
  goto ldv_55385;
  }
  ldv_55385: 
  channel->event_test_cpu = pscr_ret__;
  efx_schedule_channel___1(channel);
  return;
}
}
extern int i2c_bit_add_bus(struct i2c_adapter * ) ;
__inline static bool falcon_spi_present(struct falcon_spi_device  const  *spi ) 
{ 


  {
  return ((unsigned int )spi->size != 0U);
}
}
__inline static struct falcon_board *falcon_board(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *data ;

  {
  data = (struct falcon_nic_data *)efx->nic_data;
  return (& data->board);
}
}
int falcon_probe_board(struct efx_nic *efx , u16 revision_info ) ;
__inline static void efx_update_diff_stat(u64 *stat , u64 diff ) 
{ 


  {
  if ((long long )(diff - *stat) > 0LL) {
    *stat = diff;
  } else {

  }
  return;
}
}
void falcon_start_nic_stats(struct efx_nic *efx ) ;
void falcon_stop_nic_stats(struct efx_nic *efx ) ;
int falcon_reset_xaui(struct efx_nic *efx ) ;
__inline static void _efx_writed_page_locked(struct efx_nic *efx , efx_dword_t const   *value ,
                                             unsigned int reg , unsigned int page ) 
{ 
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
  if (page == 0U) {
    tmp = spinlock_check(& efx->biu_lock);
    flags = _raw_spin_lock_irqsave(tmp);
    efx_writed(efx, value, page * 8192U + reg);
    spin_unlock_irqrestore(& efx->biu_lock, flags);
  } else {
    efx_writed(efx, value, page * 8192U + reg);
  }
  return;
}
}
struct efx_phy_operations  const  falcon_sfx7101_phy_ops ;
struct efx_phy_operations  const  falcon_qt202x_phy_ops ;
struct efx_phy_operations  const  falcon_txc_phy_ops ;
__inline static int efx_mdio_read(struct efx_nic *efx , int devad , int addr ) 
{ 
  int tmp ;

  {
  tmp = (*(efx->mdio.mdio_read))(efx->net_dev, efx->mdio.prtad, devad, (int )((u16 )addr));
  return (tmp);
}
}
__inline static bool efx_mdio_phyxgxs_lane_sync(struct efx_nic *efx ) 
{ 
  int i ;
  int lane_status ;
    klee_make_symbolic(&lane_status, sizeof(int), "lane_status");
  bool sync ;
  struct _ddebug descriptor ;
  long tmp ;

  {
  i = 0;
  goto ldv_56497;
  ldv_56496: 
  lane_status = efx_mdio_read(efx, 4, 24);
  i = i + 1;
  ldv_56497: ;
  if (i <= 1) {
    goto ldv_56496;
  } else {

  }
  sync = (lane_status & 4096) != 0;
  if (! sync) {
    if ((efx->msg_enable & 8192U) != 0U) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_mdio_phyxgxs_lane_sync";
      descriptor.filename = "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/net/ethernet/sfc/mdio_10g.h";
      descriptor.format = "XGXS lane status: %x\n";
      descriptor.lineno = 55U;
      descriptor.flags = 0U;
      tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "XGXS lane status: %x\n", lane_status);
      } else {

      }
    } else {

    }
  } else {

  }
  return (sync);
}
}
static struct efx_hw_stat_desc  const  falcon_stat_desc[49U]  = 
  {      {"rx_noskb_drops", 0U, 0U}, 
        {"rx_nodesc_trunc", 0U, 0U}, 
        {"tx_bytes", 64U, 136U}, 
        {"tx_packets", 32U, 128U}, 
        {"tx_pause", 32U, 160U}, 
        {"tx_control", 32U, 156U}, 
        {"tx_unicast", 32U, 152U}, 
        {"tx_multicast", 32U, 144U}, 
        {"tx_broadcast", 32U, 148U}, 
        {"tx_lt64", 32U, 192U}, 
        {"tx_64", 32U, 164U}, 
        {"tx_65_to_127", 32U, 168U}, 
        {"tx_128_to_255", 32U, 172U}, 
        {"tx_256_to_511", 32U, 176U}, 
        {"tx_512_to_1023", 32U, 180U}, 
        {"tx_1024_to_15xx", 32U, 184U}, 
        {"tx_15xx_to_jumbo", 32U, 188U}, 
        {"tx_gtjumbo", 32U, 196U}, 
        {"tx_non_tcpudp", 16U, 200U}, 
        {"tx_mac_src_error", 16U, 204U}, 
        {"tx_ip_src_error", 16U, 208U}, 
        {"rx_bytes", 64U, 0U}, 
        {"rx_good_bytes", 64U, 8U}, 
        {"rx_bad_bytes", 0U, 0U}, 
        {"rx_packets", 32U, 16U}, 
        {"rx_good", 32U, 20U}, 
        {"rx_bad", 32U, 56U}, 
        {"rx_pause", 32U, 76U}, 
        {"rx_control", 32U, 72U}, 
        {"rx_unicast", 32U, 32U}, 
        {"rx_multicast", 32U, 28U}, 
        {"rx_broadcast", 32U, 24U}, 
        {"rx_lt64", 32U, 36U}, 
        {"rx_64", 32U, 80U}, 
        {"rx_65_to_127", 32U, 84U}, 
        {"rx_128_to_255", 32U, 88U}, 
        {"rx_256_to_511", 32U, 92U}, 
        {"rx_512_to_1023", 32U, 96U}, 
        {"rx_1024_to_15xx", 32U, 100U}, 
        {"rx_15xx_to_jumbo", 32U, 104U}, 
        {"rx_gtjumbo", 32U, 40U}, 
        {"rx_bad_lt64", 32U, 48U}, 
        {"rx_bad_gtjumbo", 32U, 44U}, 
        {"rx_overflow", 32U, 52U}, 
        {"rx_symbol_error", 32U, 64U}, 
        {"rx_align_error", 32U, 60U}, 
        {"rx_length_error", 32U, 108U}, 
        {"rx_internal_error", 32U, 68U}, 
        {"rx_nodesc_drop_cnt", 0U, 0U}};
static unsigned long const   falcon_stat_mask[1U]  = {      0xffffffffffffffffUL};
static int falcon_reset_hw(struct efx_nic *efx , enum reset_type method ) ;
static void falcon_reconfigure_mac_wrapper(struct efx_nic *efx ) ;
static unsigned int const   large_eeprom_type  =    83886221U;
static unsigned int const   default_flash_type  =    135221969U;
static void falcon_setsda(void *data , int state ) 
{ 
  struct efx_nic *efx ;
  efx_oword_t reg ;

  {
  efx = (struct efx_nic *)data;
  efx_reado(efx, & reg, 528U);
  reg.u64[0] = (reg.u64[0] & 0xfffffffff7ffffffULL) | (state == 0 ? 134217728ULL : 0ULL);
  reg.u64[1] = reg.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 528U);
  return;
}
}
static void falcon_setscl(void *data , int state ) 
{ 
  struct efx_nic *efx ;
  efx_oword_t reg ;

  {
  efx = (struct efx_nic *)data;
  efx_reado(efx, & reg, 528U);
  reg.u64[0] = (reg.u64[0] & 0xfffffffffeffffffULL) | (state == 0 ? 16777216ULL : 0ULL);
  reg.u64[1] = reg.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 528U);
  return;
}
}
static int falcon_getsda(void *data ) 
{ 
  struct efx_nic *efx ;
  efx_oword_t reg ;

  {
  efx = (struct efx_nic *)data;
  efx_reado(efx, & reg, 528U);
  return ((int )(reg.u64[0] >> 11) & 1);
}
}
static int falcon_getscl(void *data ) 
{ 
  struct efx_nic *efx ;
  efx_oword_t reg ;

  {
  efx = (struct efx_nic *)data;
  efx_reado(efx, & reg, 528U);
  return ((int )(reg.u64[0] >> 8) & 1);
}
}
static struct i2c_algo_bit_data  const  falcon_i2c_bit_operations  = 
     {0, & falcon_setsda, & falcon_setscl, & falcon_getsda, & falcon_getscl, 0, 0, 5,
    13};
static void falcon_push_irq_moderation(struct efx_channel *channel ) 
{ 
  efx_dword_t timer_cmd ;
  struct efx_nic *efx ;

  {
  efx = channel->efx;
  if (channel->irq_moderation != 0U) {
    timer_cmd.u32[0] = (channel->irq_moderation - 1U) | 8192U;
  } else {
    timer_cmd.u32[0] = 0U;
  }
  _efx_writed_page_locked(efx, (efx_dword_t const   *)(& timer_cmd), 1056U, (unsigned int )channel->channel);
  return;
}
}
static void falcon_deconfigure_mac_wrapper(struct efx_nic *efx ) ;
static void falcon_prepare_flush(struct efx_nic *efx ) 
{ 


  {
  falcon_deconfigure_mac_wrapper(efx);
  msleep(10U);
  return;
}
}
__inline static void falcon_irq_ack_a1(struct efx_nic *efx ) 
{ 
  efx_dword_t reg ;

  {
  reg.u32[0] = 12053374U;
  efx_writed(efx, (efx_dword_t const   *)(& reg), 80U);
  efx_readd(efx, & reg, 112U);
  return;
}
}
static irqreturn_t falcon_legacy_interrupt_a1(int irq , void *dev_id ) 
{ 
  struct efx_nic *efx ;
  efx_oword_t *int_ker ;
  int syserr ;
  int queues ;
    klee_make_symbolic(&queues, sizeof(int), "queues");
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  long tmp ;
  int pscr_ret_____0 ;
  void const   *__vpp_verify___0 ;
  int pfo_ret_____3 ;
  int pfo_ret_____4 ;
  int pfo_ret_____5 ;
  int pfo_ret_____6 ;
  int pscr_ret_____1 ;
    klee_make_symbolic(&pscr_ret_____1, sizeof(int), "pscr_ret_____1");
  void const   *__vpp_verify___1 ;
  int pfo_ret_____7 ;
    klee_make_symbolic(&pfo_ret_____7, sizeof(int), "pfo_ret_____7");
  int pfo_ret_____8 ;
    klee_make_symbolic(&pfo_ret_____8, sizeof(int), "pfo_ret_____8");
  int pfo_ret_____9 ;
    klee_make_symbolic(&pfo_ret_____9, sizeof(int), "pfo_ret_____9");
  int pfo_ret_____10 ;
    klee_make_symbolic(&pfo_ret_____10, sizeof(int), "pfo_ret_____10");
  bool __var ;
  long tmp___0 ;
  irqreturn_t tmp___1 ;
  long tmp___2 ;
  struct efx_channel *tmp___3 ;
  struct efx_channel *tmp___4 ;

  {
  efx = (struct efx_nic *)dev_id;
  int_ker = (efx_oword_t *)efx->irq_status.addr;
  tmp = ldv__builtin_expect((int_ker->u64[0] | int_ker->u64[1]) == 0ULL, 0L);
  if (tmp != 0L) {
    if (0) {
      if ((efx->msg_enable & 512U) != 0U) {
        __vpp_verify = (void const   *)0;
        switch (4UL) {
        case 1UL: ;
        switch (4UL) {
        case 1UL: 
        __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
        goto ldv_56629;
        case 2UL: 
        __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
        goto ldv_56629;
        case 4UL: 
        __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
        goto ldv_56629;
        case 8UL: 
        __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
        goto ldv_56629;
        default: 
        __bad_percpu_size();
        }
        ldv_56629: 
        pscr_ret__ = pfo_ret__;
        goto ldv_56635;
        case 2UL: ;
        switch (4UL) {
        case 1UL: 
        __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
        goto ldv_56639;
        case 2UL: 
        __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
        goto ldv_56639;
        case 4UL: 
        __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
        goto ldv_56639;
        case 8UL: 
        __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
        goto ldv_56639;
        default: 
        __bad_percpu_size();
        }
        ldv_56639: 
        pscr_ret__ = pfo_ret_____0;
        goto ldv_56635;
        case 4UL: ;
        switch (4UL) {
        case 1UL: 
        __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
        goto ldv_56648;
        case 2UL: 
        __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
        goto ldv_56648;
        case 4UL: 
        __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
        goto ldv_56648;
        case 8UL: 
        __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
        goto ldv_56648;
        default: 
        __bad_percpu_size();
        }
        ldv_56648: 
        pscr_ret__ = pfo_ret_____1;
        goto ldv_56635;
        case 8UL: ;
        switch (4UL) {
        case 1UL: 
        __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
        goto ldv_56657;
        case 2UL: 
        __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
        goto ldv_56657;
        case 4UL: 
        __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
        goto ldv_56657;
        case 8UL: 
        __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
        goto ldv_56657;
        default: 
        __bad_percpu_size();
        }
        ldv_56657: 
        pscr_ret__ = pfo_ret_____2;
        goto ldv_56635;
        default: 
        __bad_size_call_parameter();
        goto ldv_56635;
        }
        ldv_56635: 
        netdev_printk("\017", (struct net_device  const  *)efx->net_dev, "IRQ %d on CPU %d not for me\n",
                      irq, pscr_ret__);
      } else {

      }
    } else {

    }
    return (0);
  } else {

  }
  __vpp_verify___0 = (void const   *)0;
  switch (4UL) {
  case 1UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____3): "m" (cpu_number));
  goto ldv_56671;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
  goto ldv_56671;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
  goto ldv_56671;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
  goto ldv_56671;
  default: 
  __bad_percpu_size();
  }
  ldv_56671: 
  pscr_ret_____0 = pfo_ret_____3;
  goto ldv_56677;
  case 2UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____4): "m" (cpu_number));
  goto ldv_56681;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
  goto ldv_56681;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
  goto ldv_56681;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
  goto ldv_56681;
  default: 
  __bad_percpu_size();
  }
  ldv_56681: 
  pscr_ret_____0 = pfo_ret_____4;
  goto ldv_56677;
  case 4UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____5): "m" (cpu_number));
  goto ldv_56690;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
  goto ldv_56690;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
  goto ldv_56690;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
  goto ldv_56690;
  default: 
  __bad_percpu_size();
  }
  ldv_56690: 
  pscr_ret_____0 = pfo_ret_____5;
  goto ldv_56677;
  case 8UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____6): "m" (cpu_number));
  goto ldv_56699;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
  goto ldv_56699;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
  goto ldv_56699;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
  goto ldv_56699;
  default: 
  __bad_percpu_size();
  }
  ldv_56699: 
  pscr_ret_____0 = pfo_ret_____6;
  goto ldv_56677;
  default: 
  __bad_size_call_parameter();
  goto ldv_56677;
  }
  ldv_56677: 
  efx->last_irq_cpu = pscr_ret_____0;
  if (0) {
    if ((efx->msg_enable & 512U) != 0U) {
      __vpp_verify___1 = (void const   *)0;
      switch (4UL) {
      case 1UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____7): "m" (cpu_number));
      goto ldv_56712;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____7): "m" (cpu_number));
      goto ldv_56712;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____7): "m" (cpu_number));
      goto ldv_56712;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____7): "m" (cpu_number));
      goto ldv_56712;
      default: 
      __bad_percpu_size();
      }
      ldv_56712: 
      pscr_ret_____1 = pfo_ret_____7;
      goto ldv_56718;
      case 2UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____8): "m" (cpu_number));
      goto ldv_56722;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____8): "m" (cpu_number));
      goto ldv_56722;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____8): "m" (cpu_number));
      goto ldv_56722;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____8): "m" (cpu_number));
      goto ldv_56722;
      default: 
      __bad_percpu_size();
      }
      ldv_56722: 
      pscr_ret_____1 = pfo_ret_____8;
      goto ldv_56718;
      case 4UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____9): "m" (cpu_number));
      goto ldv_56731;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____9): "m" (cpu_number));
      goto ldv_56731;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____9): "m" (cpu_number));
      goto ldv_56731;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____9): "m" (cpu_number));
      goto ldv_56731;
      default: 
      __bad_percpu_size();
      }
      ldv_56731: 
      pscr_ret_____1 = pfo_ret_____9;
      goto ldv_56718;
      case 8UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____10): "m" (cpu_number));
      goto ldv_56740;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____10): "m" (cpu_number));
      goto ldv_56740;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____10): "m" (cpu_number));
      goto ldv_56740;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____10): "m" (cpu_number));
      goto ldv_56740;
      default: 
      __bad_percpu_size();
      }
      ldv_56740: 
      pscr_ret_____1 = pfo_ret_____10;
      goto ldv_56718;
      default: 
      __bad_size_call_parameter();
      goto ldv_56718;
      }
      ldv_56718: 
      netdev_printk("\017", (struct net_device  const  *)efx->net_dev, "IRQ %d on CPU %d status %08x:%08x:%08x:%08x\n",
                    irq, pscr_ret_____1, int_ker->u32[3], int_ker->u32[2], int_ker->u32[1],
                    int_ker->u32[0]);
    } else {

    }
  } else {

  }
  __var = 0;
  tmp___0 = ldv__builtin_expect((long )*((bool volatile   *)(& efx->irq_soft_enabled)),
                             1L);
  if (tmp___0 == 0L) {
    return (1);
  } else {

  }
  syserr = (int )int_ker->u64[1] & 1;
  tmp___2 = ldv__builtin_expect(syserr != 0, 0L);
  if (tmp___2 != 0L) {
    tmp___1 = efx_farch_fatal_interrupt(efx);
    return (tmp___1);
  } else {

  }
  queues = (int )(int_ker->u64[0] >> 40) & 15;
  int_ker->u64[0] = 0ULL;
  int_ker->u64[1] = 0ULL;
  __asm__  volatile   ("sfence": : : "memory");
  falcon_irq_ack_a1(efx);
  if (queues & 1) {
    tmp___3 = efx_get_channel(efx, 0U);
    efx_schedule_channel_irq___0(tmp___3);
  } else {

  }
  if ((queues & 2) != 0) {
    tmp___4 = efx_get_channel(efx, 1U);
    efx_schedule_channel_irq___0(tmp___4);
  } else {

  }
  return (1);
}
}
static int dummy_rx_push_rss_config(struct efx_nic *efx , bool user , u32 const   *rx_indir_table ) 
{ 


  {
  return (-38);
}
}
static int falcon_b0_rx_push_rss_config(struct efx_nic *efx , bool user , u32 const   *rx_indir_table ) 
{ 
  efx_oword_t temp ;

  {
  memcpy((void *)(& temp), (void const   *)(& efx->rx_hash_key), 16UL);
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 2144U);
  memcpy((void *)(& efx->rx_indir_table), (void const   *)rx_indir_table, 512UL);
  efx_farch_rx_push_indir_table(efx);
  return (0);
}
}
static int falcon_spi_poll(struct efx_nic *efx ) 
{ 
  efx_oword_t reg ;

  {
  efx_reado(efx, & reg, 256U);
  return ((int )(reg.u64[0] >> 31) & 1 ? -16 : 0);
}
}
static int falcon_spi_wait(struct efx_nic *efx ) 
{ 
  unsigned long timeout ;
  int i ;
  int tmp ;
  int tmp___0 ;

  {
  timeout = (unsigned long )jiffies + 26UL;
  i = 0;
  goto ldv_56772;
  ldv_56771: 
  tmp = falcon_spi_poll(efx);
  if (tmp == 0) {
    return (0);
  } else {

  }
  __const_udelay(42950UL);
  i = i + 1;
  ldv_56772: ;
  if (i <= 9) {
    goto ldv_56771;
  } else {

  }

  ldv_56780: 
  tmp___0 = falcon_spi_poll(efx);
  if (tmp___0 == 0) {
    return (0);
  } else {

  }
  if ((long )((unsigned long )jiffies - timeout) >= 0L) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "timed out waiting for SPI\n");
    } else {

    }
    return (-110);
  } else {

  }
  schedule_timeout_uninterruptible(1L);
  goto ldv_56780;
}
}
static int falcon_spi_cmd(struct efx_nic *efx , struct falcon_spi_device  const  *spi ,
                          unsigned int command , int address , void const   *in ,
                          void *out , size_t len ) 
{ 
  bool addressed ;
  bool reading ;
  efx_oword_t reg ;
  int rc ;

  {
  addressed = address >= 0;
  reading = (unsigned long )out != (unsigned long )((void *)0);
  if (len > 16UL) {
    return (-22);
  } else {

  }
  rc = falcon_spi_poll(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if ((int )addressed) {
    reg.u64[0] = (unsigned long long )address;
    reg.u64[1] = 0ULL;
    efx_writeo(efx, (efx_oword_t const   *)(& reg), 272U);
  } else {

  }
  if ((unsigned long )in != (unsigned long )((void const   *)0)) {
    memcpy((void *)(& reg), in, len);
    efx_writeo(efx, (efx_oword_t const   *)(& reg), 288U);
  } else {

  }
  reg.u64[0] = ((((((unsigned long long )spi->device_id << 24) | ((unsigned long long )len << 16)) | ((unsigned long long )reading << 15)) | ((int )addressed ? (unsigned long long )spi->addr_len << 8 : 0ULL)) | (unsigned long long )command) | 2147483648ULL;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 256U);
  rc = falcon_spi_wait(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if ((unsigned long )out != (unsigned long )((void *)0)) {
    efx_reado(efx, & reg, 288U);
    memcpy(out, (void const   *)(& reg), len);
  } else {

  }
  return (0);
}
}
__inline static u8 falcon_spi_munge_command(struct falcon_spi_device  const  *spi ,
                                            u8 const   command , unsigned int const   address ) 
{ 


  {
  return ((((int )((u8 )(address >> 8)) & (int )((u8 )spi->munge_address)) << 3U) | (int )((u8 )command));
}
}
static int falcon_spi_read(struct efx_nic *efx , struct falcon_spi_device  const  *spi ,
                           loff_t start , size_t len , size_t *retlen , u8 *buffer ) 
{ 
  size_t block_len ;
  size_t pos ;
  unsigned int command ;
    klee_make_symbolic(&command, sizeof(int), "command");
  int rc ;
  size_t _min1 ;
  unsigned long _min2 ;
  u8 tmp ;
  struct task_struct *tmp___0 ;
  int tmp___1 ;

  {
  pos = 0UL;
  rc = 0;
  goto ldv_56817;
  ldv_56816: 
  _min1 = len - pos;
  _min2 = 16UL;
  block_len = _min1 < _min2 ? _min1 : _min2;
  tmp = falcon_spi_munge_command(spi, 3, (unsigned int const   )start + (unsigned int const   )pos);
  command = (unsigned int )tmp;
  rc = falcon_spi_cmd(efx, spi, command, (int )((unsigned int )start + (unsigned int )pos),
                      (void const   *)0, (void *)(buffer + pos), block_len);
  if (rc != 0) {
    goto ldv_56814;
  } else {

  }
  pos = pos + block_len;
  ___might_sleep("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c",
                 632, 0);
  _cond_resched();
  tmp___0 = get_current();
  tmp___1 = signal_pending(tmp___0);
  if (tmp___1 != 0) {
    rc = -4;
    goto ldv_56814;
  } else {

  }
  ldv_56817: ;
  if (pos < len) {
    goto ldv_56816;
  } else {

  }
  ldv_56814: ;
  if ((unsigned long )retlen != (unsigned long )((size_t *)0UL)) {
    *retlen = pos;
  } else {

  }
  return (rc);
}
}
static size_t falcon_spi_write_limit(struct falcon_spi_device  const  *spi , size_t start ) 
{ 
  unsigned long _min1 ;
  size_t _min2 ;

  {
  _min1 = 16UL;
  _min2 = (size_t )spi->block_size - ((size_t )((unsigned int )spi->block_size - 1U) & start);
  return (_min1 < _min2 ? _min1 : _min2);
}
}
static int falcon_spi_wait_write(struct efx_nic *efx , struct falcon_spi_device  const  *spi ) 
{ 
  unsigned long timeout ;
  u8 status ;
  int rc ;

  {
  timeout = (unsigned long )jiffies + 4UL;
  ldv_56842: 
  rc = falcon_spi_cmd(efx, spi, 5U, -1, (void const   *)0, (void *)(& status), 1UL);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (((int )status & 1) == 0) {
    return (0);
  } else {

  }
  if ((long )((unsigned long )jiffies - timeout) >= 0L) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "SPI write timeout on device %d last status=0x%02x\n",
                 spi->device_id, (int )status);
    } else {

    }
    return (-110);
  } else {

  }
  schedule_timeout_uninterruptible(1L);
  goto ldv_56842;
}
}
static int falcon_spi_write(struct efx_nic *efx , struct falcon_spi_device  const  *spi ,
                            loff_t start , size_t len , size_t *retlen , u8 const   *buffer ) 
{ 
  u8 verify_buffer[16U] ;
  size_t block_len ;
  size_t pos ;
  unsigned int command ;
  int rc ;
  size_t _min1 ;
  size_t _min2 ;
  size_t tmp ;
  u8 tmp___0 ;
  u8 tmp___1 ;
  int tmp___2 ;
  struct task_struct *tmp___3 ;
  int tmp___4 ;

  {
  pos = 0UL;
  rc = 0;
  goto ldv_56862;
  ldv_56861: 
  rc = falcon_spi_cmd(efx, spi, 6U, -1, (void const   *)0, (void *)0, 0UL);
  if (rc != 0) {
    goto ldv_56856;
  } else {

  }
  _min1 = len - pos;
  tmp = falcon_spi_write_limit(spi, (size_t )((unsigned long long )start + (unsigned long long )pos));
  _min2 = tmp;
  block_len = _min1 < _min2 ? _min1 : _min2;
  tmp___0 = falcon_spi_munge_command(spi, 2, (unsigned int const   )start + (unsigned int const   )pos);
  command = (unsigned int )tmp___0;
  rc = falcon_spi_cmd(efx, spi, command, (int )((unsigned int )start + (unsigned int )pos),
                      (void const   *)(buffer + pos), (void *)0, block_len);
  if (rc != 0) {
    goto ldv_56856;
  } else {

  }
  rc = falcon_spi_wait_write(efx, spi);
  if (rc != 0) {
    goto ldv_56856;
  } else {

  }
  tmp___1 = falcon_spi_munge_command(spi, 3, (unsigned int const   )start + (unsigned int const   )pos);
  command = (unsigned int )tmp___1;
  rc = falcon_spi_cmd(efx, spi, command, (int )((unsigned int )start + (unsigned int )pos),
                      (void const   *)0, (void *)(& verify_buffer), block_len);
  tmp___2 = memcmp((void const   *)(& verify_buffer), (void const   *)(buffer + pos),
                   block_len);
  if (tmp___2 != 0) {
    rc = -5;
    goto ldv_56856;
  } else {

  }
  pos = pos + block_len;
  ___might_sleep("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c",
                 725, 0);
  _cond_resched();
  tmp___3 = get_current();
  tmp___4 = signal_pending(tmp___3);
  if (tmp___4 != 0) {
    rc = -4;
    goto ldv_56856;
  } else {

  }
  ldv_56862: ;
  if (pos < len) {
    goto ldv_56861;
  } else {

  }
  ldv_56856: ;
  if ((unsigned long )retlen != (unsigned long )((size_t *)0UL)) {
    *retlen = pos;
  } else {

  }
  return (rc);
}
}
static int falcon_spi_slow_wait(struct falcon_mtd_partition *part , bool uninterruptible ) 
{ 
  struct falcon_spi_device  const  *spi ;
  struct efx_nic *efx ;
  u8 status ;
  int rc ;
  int i ;
  struct task_struct *tmp ;
  struct task_struct *tmp___0 ;
  struct task_struct *tmp___1 ;
  int tmp___2 ;

  {
  spi = part->spi;
  efx = (struct efx_nic *)part->common.mtd.priv;
  i = 0;
  goto ldv_56873;
  ldv_56872: 
  tmp = get_current();
  tmp->task_state_change = 0UL;
  tmp___0 = get_current();
  tmp___0->state = (int )uninterruptible ? 2L : 1L;
  schedule_timeout(25L);
  rc = falcon_spi_cmd(efx, spi, 5U, -1, (void const   *)0, (void *)(& status), 1UL);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (((int )status & 1) == 0) {
    return (0);
  } else {

  }
  tmp___1 = get_current();
  tmp___2 = signal_pending(tmp___1);
  if (tmp___2 != 0) {
    return (-4);
  } else {

  }
  i = i + 1;
  ldv_56873: ;
  if (i <= 39) {
    goto ldv_56872;
  } else {

  }
  printk("\v%s: timed out waiting for %s\n", (char *)(& part->common.name), part->common.dev_type_name);
  return (-110);
}
}
static int falcon_spi_unlock(struct efx_nic *efx , struct falcon_spi_device  const  *spi ) 
{ 
  u8 unlock_mask ;
  u8 status ;
  int rc ;

  {
  unlock_mask = 28U;
  rc = falcon_spi_cmd(efx, spi, 5U, -1, (void const   *)0, (void *)(& status), 1UL);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if ((unsigned int )((int )status & (int )unlock_mask) == 0U) {
    return (0);
  } else {

  }
  rc = falcon_spi_cmd(efx, spi, 6U, -1, (void const   *)0, (void *)0, 0UL);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = falcon_spi_cmd(efx, spi, 80U, -1, (void const   *)0, (void *)0, 0UL);
  if (rc != 0) {
    return (rc);
  } else {

  }
  status = (u8 )(~ ((int )((signed char )unlock_mask)) & (int )((signed char )status));
  rc = falcon_spi_cmd(efx, spi, 1U, -1, (void const   *)(& status), (void *)0, 1UL);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = falcon_spi_wait_write(efx, spi);
  if (rc != 0) {
    return (rc);
  } else {

  }
  return (0);
}
}
static int falcon_spi_erase(struct falcon_mtd_partition *part , loff_t start , size_t len ) 
{ 
  struct falcon_spi_device  const  *spi ;
  struct efx_nic *efx ;
  unsigned int pos ;
    klee_make_symbolic(&pos, sizeof(int), "pos");
  unsigned int block_len ;
    klee_make_symbolic(&block_len, sizeof(int), "block_len");
  u8 empty[16U] ;
  u8 buffer[16U] ;
  int rc ;
  size_t _min1 ;
  unsigned long _min2 ;
  int tmp ;
  struct task_struct *tmp___0 ;
  int tmp___1 ;

  {
  spi = part->spi;
  efx = (struct efx_nic *)part->common.mtd.priv;
  if ((size_t )spi->erase_size != len) {
    return (-22);
  } else {

  }
  if ((unsigned int )((unsigned char )spi->erase_command) == 0U) {
    return (-95);
  } else {

  }
  rc = falcon_spi_unlock(efx, spi);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = falcon_spi_cmd(efx, spi, 6U, -1, (void const   *)0, (void *)0, 0UL);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = falcon_spi_cmd(efx, spi, (unsigned int )spi->erase_command, (int )start, (void const   *)0,
                      (void *)0, 0UL);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = falcon_spi_slow_wait(part, 0);
  memset((void *)(& empty), 255, 16UL);
  pos = 0U;
  goto ldv_56899;
  ldv_56898: 
  _min1 = len - (size_t )pos;
  _min2 = 16UL;
  block_len = (unsigned int )(_min1 < _min2 ? _min1 : _min2);
  rc = falcon_spi_read(efx, spi, (loff_t )pos + start, (size_t )block_len, (size_t *)0UL,
                       (u8 *)(& buffer));
  if (rc != 0) {
    return (rc);
  } else {

  }
  tmp = memcmp((void const   *)(& empty), (void const   *)(& buffer), (size_t )block_len);
  if (tmp != 0) {
    return (-5);
  } else {

  }
  ___might_sleep("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c",
                 841, 0);
  _cond_resched();
  tmp___0 = get_current();
  tmp___1 = signal_pending(tmp___0);
  if (tmp___1 != 0) {
    return (-4);
  } else {

  }
  pos = pos + block_len;
  ldv_56899: ;
  if ((size_t )pos < len) {
    goto ldv_56898;
  } else {

  }

  return (rc);
}
}
static void falcon_mtd_rename(struct efx_mtd_partition *part ) 
{ 
  struct efx_nic *efx ;

  {
  efx = (struct efx_nic *)part->mtd.priv;
  snprintf((char *)(& part->name), 36UL, "%s %s", (char *)(& efx->name), part->type_name);
  return;
}
}
static int falcon_mtd_read(struct mtd_info *mtd , loff_t start , size_t len , size_t *retlen ,
                           u8 *buffer ) 
{ 
  struct falcon_mtd_partition *part ;
  struct mtd_info  const  *__mptr ;
  struct efx_nic *efx ;
  struct falcon_nic_data *nic_data ;
  int rc ;

  {
  __mptr = (struct mtd_info  const  *)mtd;
  part = (struct falcon_mtd_partition *)__mptr + 0xfffffffffffffff0UL;
  efx = (struct efx_nic *)mtd->priv;
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  rc = ldv_mutex_lock_interruptible_169(& nic_data->spi_lock);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = falcon_spi_read(efx, part->spi, (loff_t )((unsigned long long )part->offset + (unsigned long long )start),
                       len, retlen, buffer);
  ldv_mutex_unlock_170(& nic_data->spi_lock);
  return (rc);
}
}
static int falcon_mtd_erase(struct mtd_info *mtd , loff_t start , size_t len ) 
{ 
  struct falcon_mtd_partition *part ;
  struct mtd_info  const  *__mptr ;
  struct efx_nic *efx ;
  struct falcon_nic_data *nic_data ;
  int rc ;

  {
  __mptr = (struct mtd_info  const  *)mtd;
  part = (struct falcon_mtd_partition *)__mptr + 0xfffffffffffffff0UL;
  efx = (struct efx_nic *)mtd->priv;
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  rc = ldv_mutex_lock_interruptible_171(& nic_data->spi_lock);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = falcon_spi_erase(part, (loff_t )((unsigned long long )part->offset + (unsigned long long )start),
                        len);
  ldv_mutex_unlock_172(& nic_data->spi_lock);
  return (rc);
}
}
static int falcon_mtd_write(struct mtd_info *mtd , loff_t start , size_t len , size_t *retlen ,
                            u8 const   *buffer ) 
{ 
  struct falcon_mtd_partition *part ;
  struct mtd_info  const  *__mptr ;
  struct efx_nic *efx ;
  struct falcon_nic_data *nic_data ;
  int rc ;

  {
  __mptr = (struct mtd_info  const  *)mtd;
  part = (struct falcon_mtd_partition *)__mptr + 0xfffffffffffffff0UL;
  efx = (struct efx_nic *)mtd->priv;
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  rc = ldv_mutex_lock_interruptible_173(& nic_data->spi_lock);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = falcon_spi_write(efx, part->spi, (loff_t )((unsigned long long )part->offset + (unsigned long long )start),
                        len, retlen, buffer);
  ldv_mutex_unlock_174(& nic_data->spi_lock);
  return (rc);
}
}
static int falcon_mtd_sync(struct mtd_info *mtd ) 
{ 
  struct falcon_mtd_partition *part ;
  struct mtd_info  const  *__mptr ;
  struct efx_nic *efx ;
  struct falcon_nic_data *nic_data ;
  int rc ;

  {
  __mptr = (struct mtd_info  const  *)mtd;
  part = (struct falcon_mtd_partition *)__mptr + 0xfffffffffffffff0UL;
  efx = (struct efx_nic *)mtd->priv;
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  ldv_mutex_lock_175(& nic_data->spi_lock);
  rc = falcon_spi_slow_wait(part, 1);
  ldv_mutex_unlock_176(& nic_data->spi_lock);
  return (rc);
}
}
static int falcon_mtd_probe(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  struct falcon_mtd_partition *parts ;
  struct falcon_spi_device *spi ;
  size_t n_parts ;
  int rc ;
  int tmp ;
  long tmp___0 ;
  void *tmp___1 ;
  bool tmp___2 ;
  unsigned int _min1 ;
  unsigned int _min2 ;
  bool tmp___3 ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  rc = -19;
  tmp = rtnl_is_locked();
  tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
  if (tmp___0 != 0L) {
    printk("\vRTNL: assertion failed at %s (%d)\n", (char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c",
           927);
    dump_stack();
  } else {

  }
  tmp___1 = kcalloc(2UL, 1912UL, 208U);
  parts = (struct falcon_mtd_partition *)tmp___1;
  if ((unsigned long )parts == (unsigned long )((struct falcon_mtd_partition *)0)) {
    return (-12);
  } else {

  }
  n_parts = 0UL;
  spi = & nic_data->spi_flash;
  tmp___2 = falcon_spi_present((struct falcon_spi_device  const  *)spi);
  if ((int )tmp___2 && spi->size > 32768U) {
    (parts + n_parts)->spi = (struct falcon_spi_device  const  *)spi;
    (parts + n_parts)->offset = 32768UL;
    (parts + n_parts)->common.dev_type_name = "flash";
    (parts + n_parts)->common.type_name = "sfc_flash_bootrom";
    (parts + n_parts)->common.mtd.type = 3U;
    (parts + n_parts)->common.mtd.flags = 3072U;
    (parts + n_parts)->common.mtd.size = (uint64_t )(spi->size - 32768U);
    (parts + n_parts)->common.mtd.erasesize = spi->erase_size;
    n_parts = n_parts + 1UL;
  } else {

  }
  spi = & nic_data->spi_eeprom;
  tmp___3 = falcon_spi_present((struct falcon_spi_device  const  *)spi);
  if ((int )tmp___3 && spi->size > 2048U) {
    (parts + n_parts)->spi = (struct falcon_spi_device  const  *)spi;
    (parts + n_parts)->offset = 2048UL;
    (parts + n_parts)->common.dev_type_name = "EEPROM";
    (parts + n_parts)->common.type_name = "sfc_bootconfig";
    (parts + n_parts)->common.mtd.type = 1U;
    (parts + n_parts)->common.mtd.flags = 7168U;
    _min1 = spi->size;
    _min2 = 6144U;
    (parts + n_parts)->common.mtd.size = (uint64_t )((_min1 < _min2 ? _min1 : _min2) - 2048U);
    (parts + n_parts)->common.mtd.erasesize = spi->erase_size;
    n_parts = n_parts + 1UL;
  } else {

  }
  rc = efx_mtd_add(efx, & parts->common, n_parts, 1912UL);
  if (rc != 0) {
    kfree((void const   *)parts);
  } else {

  }
  return (rc);
}
}
static void falcon_setup_xaui(struct efx_nic *efx ) 
{ 
  efx_oword_t sdctl ;
  efx_oword_t txdrv ;

  {
  if (efx->phy_type == 0U) {
    return;
  } else {

  }
  efx_reado(efx, & sdctl, 4880U);
  sdctl.u64[0] = sdctl.u64[0] & 0xffffffffffff7fffULL;
  sdctl.u64[1] = sdctl.u64[1];
  sdctl.u64[0] = sdctl.u64[0] & 0xffffffffffffbfffULL;
  sdctl.u64[1] = sdctl.u64[1];
  sdctl.u64[0] = sdctl.u64[0] & 0xffffffffffffdfffULL;
  sdctl.u64[1] = sdctl.u64[1];
  sdctl.u64[0] = sdctl.u64[0] & 0xffffffffffffefffULL;
  sdctl.u64[1] = sdctl.u64[1];
  sdctl.u64[0] = sdctl.u64[0] & 0xfffffffffffff7ffULL;
  sdctl.u64[1] = sdctl.u64[1];
  sdctl.u64[0] = sdctl.u64[0] & 0xfffffffffffffbffULL;
  sdctl.u64[1] = sdctl.u64[1];
  sdctl.u64[0] = sdctl.u64[0] & 0xfffffffffffffdffULL;
  sdctl.u64[1] = sdctl.u64[1];
  sdctl.u64[0] = sdctl.u64[0] & 0xfffffffffffffeffULL;
  sdctl.u64[1] = sdctl.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& sdctl), 4880U);
  txdrv.u64[0] = 4008596821ULL;
  txdrv.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& txdrv), 4896U);
  return;
}
}
int falcon_reset_xaui(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  efx_oword_t reg ;
  int count ;
  int __ret_warn_on ;
  long tmp ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  __ret_warn_on = nic_data->stats_disable_count == 0U;
  tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c",
                       1018);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  reg.u64[0] = 1ULL;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 4864U);
  count = 0;
  goto ldv_56976;
  ldv_56975: 
  efx_reado(efx, & reg, 4864U);
  if ((reg.u64[0] & 1ULL) == 0ULL && ((reg.u64[0] >> 16) & 1ULL) == 0ULL) {
    falcon_setup_xaui(efx);
    return (0);
  } else {

  }
  __const_udelay(42950UL);
  count = count + 1;
  ldv_56976: ;
  if (count <= 999) {
    goto ldv_56975;
  } else {

  }

  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "timed out waiting for XAUI/XGXS reset\n");
  } else {

  }
  return (-110);
}
}
static void falcon_ack_status_intr(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  efx_oword_t reg ;
  int tmp ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  tmp = efx_nic_rev(efx);
  if (tmp != 2 || (66600958 >> (int )efx->loopback_mode) & 1) {
    return;
  } else {

  }
  if (! efx->link_state.up) {
    return;
  } else {

  }
  if ((int )nic_data->xmac_poll_required) {
    return;
  } else {

  }
  efx_reado(efx, & reg, 4848U);
  return;
}
}
static bool falcon_xgxs_link_ok(struct efx_nic *efx ) 
{ 
  efx_oword_t reg ;
  bool align_done ;
  bool link_ok ;
  int sync_status ;
    klee_make_symbolic(&sync_status, sizeof(int), "sync_status");

  {
  link_ok = 0;
  efx_reado(efx, & reg, 4960U);
  align_done = ((reg.u64[0] >> 20) & 1ULL) != 0ULL;
  sync_status = (int )(reg.u64[0] >> 16) & 15;
  if ((int )align_done && sync_status == 15) {
    link_ok = 1;
  } else {

  }
  reg.u64[0] = reg.u64[0] | 61440ULL;
  reg.u64[1] = reg.u64[1];
  reg.u64[0] = reg.u64[0] | 240ULL;
  reg.u64[1] = reg.u64[1];
  reg.u64[0] = reg.u64[0] | 15ULL;
  reg.u64[1] = reg.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 4960U);
  return (link_ok);
}
}
static bool falcon_xmac_link_ok(struct efx_nic *efx ) 
{ 
  bool tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  if ((unsigned int )efx->loopback_mode == 3U) {
    goto _L;
  } else {
    tmp = falcon_xgxs_link_ok(efx);
    if ((int )tmp) {
      _L: /* CIL Label */ 
      if ((efx->mdio.mmds & 16U) == 0U || (66600958 >> (int )efx->loopback_mode) & 1) {
        tmp___1 = 1;
      } else {
        tmp___0 = efx_mdio_phyxgxs_lane_sync(efx);
        if ((int )tmp___0) {
          tmp___1 = 1;
        } else {
          tmp___1 = 0;
        }
      }
    } else {
      tmp___1 = 0;
    }
  }
  return ((bool )tmp___1);
}
}
static void falcon_reconfigure_xmac_core(struct efx_nic *efx ) 
{ 
  unsigned int max_frame_len ;
    klee_make_symbolic(&max_frame_len, sizeof(int), "max_frame_len");
  efx_oword_t reg ;
  bool rx_fc ;
  bool tx_fc ;

  {
  rx_fc = ((int )efx->link_state.fc & 2) != 0;
  tx_fc = ((int )efx->link_state.fc & 1) != 0;
  reg.u64[0] = 3136ULL;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 4640U);
  reg.u64[0] = ((unsigned long long )tx_fc << 10) | 196902ULL;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 4656U);
  reg.u64[0] = ((unsigned long long )(! efx->unicast_filter) << 9) | 33556482ULL;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 4672U);
  max_frame_len = (((efx->net_dev)->mtu + 29U) & 4294967288U) + 16U;
  reg.u64[0] = (unsigned long long )max_frame_len;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 4832U);
  reg.u64[0] = ((unsigned long long )max_frame_len << 16) | 2147483648ULL;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 4816U);
  reg.u64[0] = (unsigned long long )(! rx_fc) | 4294836224ULL;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 4720U);
  memcpy((void *)(& reg), (void const   *)(efx->net_dev)->dev_addr, 4UL);
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 4608U);
  memcpy((void *)(& reg), (void const   *)(efx->net_dev)->dev_addr + 4U, 2UL);
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 4624U);
  return;
}
}
static void falcon_reconfigure_xgxs_core(struct efx_nic *efx ) 
{ 
  efx_oword_t reg ;
  bool xgxs_loopback ;
  bool xaui_loopback ;
  bool xgmii_loopback ;
  bool old_xgmii_loopback ;
  bool old_xgxs_loopback ;
  bool old_xaui_loopback ;

  {
  xgxs_loopback = (unsigned int )efx->loopback_mode == 4U;
  xaui_loopback = (unsigned int )efx->loopback_mode == 5U;
  xgmii_loopback = (unsigned int )efx->loopback_mode == 3U;
  efx_reado(efx, & reg, 4960U);
  old_xgxs_loopback = ((reg.u64[0] >> 23) & 1ULL) != 0ULL;
  old_xgmii_loopback = ((reg.u64[0] >> 22) & 1ULL) != 0ULL;
  efx_reado(efx, & reg, 4880U);
  old_xaui_loopback = (reg.u64[0] & 1ULL) != 0ULL;
  if (((int )xgxs_loopback != (int )old_xgxs_loopback || (int )xaui_loopback != (int )old_xaui_loopback) || (int )xgmii_loopback != (int )old_xgmii_loopback) {
    falcon_reset_xaui(efx);
  } else {

  }
  efx_reado(efx, & reg, 4960U);
  reg.u64[0] = (reg.u64[0] & 0xffffffff00ffffffULL) | ((int )xgxs_loopback || (int )xaui_loopback ? 4278190080ULL : 0ULL);
  reg.u64[1] = reg.u64[1];
  reg.u64[0] = (reg.u64[0] & 0xffffffffff7fffffULL) | ((unsigned long long )xgxs_loopback << 23);
  reg.u64[1] = reg.u64[1];
  reg.u64[0] = (reg.u64[0] & 0xffffffffffbfffffULL) | ((unsigned long long )xgmii_loopback << 22);
  reg.u64[1] = reg.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 4960U);
  efx_reado(efx, & reg, 4880U);
  reg.u64[0] = (reg.u64[0] & 0xfffffffffffffff7ULL) | ((unsigned long long )xaui_loopback << 3);
  reg.u64[1] = reg.u64[1];
  reg.u64[0] = (reg.u64[0] & 0xfffffffffffffffbULL) | ((unsigned long long )xaui_loopback << 2);
  reg.u64[1] = reg.u64[1];
  reg.u64[0] = (reg.u64[0] & 0xfffffffffffffffdULL) | ((unsigned long long )xaui_loopback << 1);
  reg.u64[1] = reg.u64[1];
  reg.u64[0] = (reg.u64[0] & 0xfffffffffffffffeULL) | (unsigned long long )xaui_loopback;
  reg.u64[1] = reg.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 4880U);
  return;
}
}
static bool falcon_xmac_link_ok_retry(struct efx_nic *efx , int tries ) 
{ 
  bool mac_up ;
  bool tmp ;
  bool tmp___0 ;
  struct _ddebug descriptor ;
  long tmp___1 ;

  {
  tmp = falcon_xmac_link_ok(efx);
  mac_up = tmp;
  if ((((u64 )(1 << (int )efx->loopback_mode) & efx->loopback_modes) & 67108864ULL) != 0ULL) {
    return (mac_up);
  } else {
    tmp___0 = efx_phy_mode_disabled(efx->phy_mode);
    if ((int )tmp___0) {
      return (mac_up);
    } else {

    }
  }
  falcon_stop_nic_stats(efx);
  goto ldv_57018;
  ldv_57017: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "falcon_xmac_link_ok_retry";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c";
    descriptor.format = "bashing xaui\n";
    descriptor.lineno = 1204U;
    descriptor.flags = 0U;
    tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___1 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "bashing xaui\n");
    } else {

    }
  } else {

  }
  falcon_reset_xaui(efx);
  __const_udelay(859000UL);
  mac_up = falcon_xmac_link_ok(efx);
  tries = tries - 1;
  ldv_57018: ;
  if (! mac_up && tries != 0) {
    goto ldv_57017;
  } else {

  }
  falcon_start_nic_stats(efx);
  return (mac_up);
}
}
static bool falcon_xmac_check_fault(struct efx_nic *efx ) 
{ 
  bool tmp ;
  int tmp___0 ;

  {
  tmp = falcon_xmac_link_ok_retry(efx, 5);
  if ((int )tmp != 0) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  return ((bool )tmp___0);
}
}
static int falcon_reconfigure_xmac(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  bool tmp ;
  int tmp___0 ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  efx_farch_filter_sync_rx_mode(efx);
  falcon_reconfigure_xgxs_core(efx);
  falcon_reconfigure_xmac_core(efx);
  falcon_reconfigure_mac_wrapper(efx);
  tmp = falcon_xmac_link_ok_retry(efx, 5);
  if ((int )tmp != 0) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  nic_data->xmac_poll_required = (bool )tmp___0;
  falcon_ack_status_intr(efx);
  return (0);
}
}
static void falcon_poll_xmac(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  bool tmp ;
  int tmp___0 ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  if (! efx->link_state.up || ! nic_data->xmac_poll_required) {
    return;
  } else {

  }
  tmp = falcon_xmac_link_ok_retry(efx, 1);
  if ((int )tmp != 0) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  nic_data->xmac_poll_required = (bool )tmp___0;
  falcon_ack_status_intr(efx);
  return;
}
}
static void falcon_push_multicast_hash(struct efx_nic *efx ) 
{ 
  union efx_multicast_hash *mc_hash ;
  int __ret_warn_on ;
  int tmp ;
  long tmp___0 ;

  {
  mc_hash = & efx->multicast_hash;
  tmp = ldv_mutex_is_locked_177(& efx->mac_lock);
  __ret_warn_on = tmp == 0;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c",
                       1262);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  efx_writeo(efx, (efx_oword_t const   *)(& mc_hash->oword), 3232U);
  efx_writeo(efx, (efx_oword_t const   *)(& mc_hash->oword) + 1U, 3248U);
  return;
}
}
static void falcon_reset_macs(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  efx_oword_t reg ;
  efx_oword_t mac_ctrl ;
  int count ;
  int tmp ;
  int __ret_warn_on ;
  long tmp___0 ;
  struct _ddebug descriptor ;
  long tmp___1 ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  tmp = efx_nic_rev(efx);
  if (tmp <= 1) {
    reg.u64[0] = 1ULL;
    reg.u64[1] = 0ULL;
    efx_writeo(efx, (efx_oword_t const   *)(& reg), 4640U);
    count = 0;
    goto ldv_57045;
    ldv_57044: 
    efx_reado(efx, & reg, 4640U);
    if ((reg.u64[0] & 1ULL) == 0ULL) {
      return;
    } else {

    }
    __const_udelay(42950UL);
    count = count + 1;
    ldv_57045: ;
    if (count <= 9999) {
      goto ldv_57044;
    } else {

    }

    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "timed out waiting for XMAC core reset\n");
    } else {

    }
  } else {

  }
  __ret_warn_on = nic_data->stats_disable_count == 0U;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c",
                       1294);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  efx_reado(efx, & mac_ctrl, 3200U);
  mac_ctrl.u64[0] = mac_ctrl.u64[0] | 128ULL;
  mac_ctrl.u64[1] = mac_ctrl.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& mac_ctrl), 3200U);
  efx_reado(efx, & reg, 544U);
  reg.u64[0] = reg.u64[0] | 8388608ULL;
  reg.u64[1] = reg.u64[1];
  reg.u64[0] = reg.u64[0] | 16777216ULL;
  reg.u64[1] = reg.u64[1];
  reg.u64[0] = reg.u64[0] | 4194304ULL;
  reg.u64[1] = reg.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 544U);
  count = 0;
  ldv_57052: 
  efx_reado(efx, & reg, 544U);
  if ((((reg.u64[0] >> 23) & 1ULL) == 0ULL && ((reg.u64[0] >> 24) & 1ULL) == 0ULL) && ((reg.u64[0] >> 22) & 1ULL) == 0ULL) {
    if ((efx->msg_enable & 8192U) != 0U) {
      descriptor.modname = "sfc";
      descriptor.function = "falcon_reset_macs";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c";
      descriptor.format = "Completed MAC reset after %d loops\n";
      descriptor.lineno = 1314U;
      descriptor.flags = 0U;
      tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp___1 != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "Completed MAC reset after %d loops\n", count);
      } else {

      }
    } else {

    }
    goto ldv_57051;
  } else {

  }
  if (count > 20) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "MAC reset failed\n");
    } else {

    }
    goto ldv_57051;
  } else {

  }
  count = count + 1;
  __const_udelay(42950UL);
  goto ldv_57052;
  ldv_57051: 
  efx_writeo(efx, (efx_oword_t const   *)(& mac_ctrl), 3200U);
  falcon_setup_xaui(efx);
  return;
}
}
static void falcon_drain_tx_fifo(struct efx_nic *efx ) 
{ 
  efx_oword_t reg ;
  int tmp ;

  {
  tmp = efx_nic_rev(efx);
  if (tmp <= 1 || (unsigned int )efx->loopback_mode != 0U) {
    return;
  } else {

  }
  efx_reado(efx, & reg, 3200U);
  if ((int )(reg.u64[0] >> 7) & 1) {
    return;
  } else {

  }
  falcon_reset_macs(efx);
  return;
}
}
static void falcon_deconfigure_mac_wrapper(struct efx_nic *efx ) 
{ 
  efx_oword_t reg ;
  int tmp ;

  {
  tmp = efx_nic_rev(efx);
  if (tmp <= 1) {
    return;
  } else {

  }
  efx_reado(efx, & reg, 2048U);
  reg.u64[0] = reg.u64[0] & 0xffff7fffffffffffULL;
  reg.u64[1] = reg.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 2048U);
  falcon_drain_tx_fifo(efx);
  return;
}
}
static void falcon_reconfigure_mac_wrapper(struct efx_nic *efx ) 
{ 
  struct efx_link_state *link_state ;
  efx_oword_t reg ;
  int link_speed ;
    klee_make_symbolic(&link_speed, sizeof(int), "link_speed");
  int isolate ;
    klee_make_symbolic(&isolate, sizeof(int), "isolate");
  unsigned long __var ;
  int tmp ;
  int tmp___0 ;

  {
  link_state = & efx->link_state;
  __var = 0UL;
  isolate = (unsigned long )*((unsigned long volatile   *)(& efx->reset_pending)) != 0UL;
  switch (link_state->speed) {
  case 10000U: 
  link_speed = 3;
  goto ldv_57071;
  case 1000U: 
  link_speed = 2;
  goto ldv_57071;
  case 100U: 
  link_speed = 1;
  goto ldv_57071;
  default: 
  link_speed = 0;
  goto ldv_57071;
  }
  ldv_57071: 
  reg.u64[0] = (((unsigned long long )(! efx->unicast_filter) << 3) | (unsigned long long )link_speed) | 4294901780ULL;
  reg.u64[1] = 0ULL;
  tmp = efx_nic_rev(efx);
  if (tmp > 1) {
    reg.u64[0] = (reg.u64[0] & 0xffffffffffffff7fULL) | ((unsigned long long )(! link_state->up || isolate != 0) << 7);
    reg.u64[1] = reg.u64[1];
  } else {

  }
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 3200U);
  falcon_push_multicast_hash(efx);
  efx_reado(efx, & reg, 2048U);
  reg.u64[0] = reg.u64[0] | 1ULL;
  reg.u64[1] = reg.u64[1];
  tmp___0 = efx_nic_rev(efx);
  if (tmp___0 > 1) {
    reg.u64[0] = (reg.u64[0] & 0xffff7fffffffffffULL) | (isolate == 0 ? 140737488355328ULL : 0ULL);
    reg.u64[1] = reg.u64[1];
  } else {

  }
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 2048U);
  return;
}
}
static void falcon_stats_request(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  efx_oword_t reg ;
  int __ret_warn_on ;
  long tmp ;
  int __ret_warn_on___0 ;
    klee_make_symbolic(&__ret_warn_on___0, sizeof(int), "__ret_warn_on___0");
  long tmp___0 ;
  unsigned long tmp___1 ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  __ret_warn_on = (int )nic_data->stats_pending;
  tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c",
                       1416);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  __ret_warn_on___0 = nic_data->stats_disable_count != 0U;
  tmp___0 = ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c",
                       1417);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
  *((u32 *)efx->stats_buffer.addr + 212U) = 0U;
  nic_data->stats_pending = 1;
  __asm__  volatile   ("sfence": : : "memory");
  reg.u64[0] = efx->stats_buffer.dma_addr | 281474976710656ULL;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 3168U);
  tmp___1 = round_jiffies_up((unsigned long )jiffies + 125UL);
  ldv_mod_timer_178(& nic_data->stats_timer, tmp___1);
  return;
}
}
static void falcon_stats_complete(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  if (! nic_data->stats_pending) {
    return;
  } else {

  }
  nic_data->stats_pending = 0;
  if (*((u32 *)efx->stats_buffer.addr + 212U) != 0U) {
    __asm__  volatile   ("lfence": : : "memory");
    efx_nic_update_stats((struct efx_hw_stat_desc  const  *)(& falcon_stat_desc),
                         49UL, (unsigned long const   *)(& falcon_stat_mask), (u64 *)(& nic_data->stats),
                         (void const   *)efx->stats_buffer.addr, 1);
  } else
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "timed out waiting for statistics\n");
  } else {

  }
  return;
}
}
static void falcon_stats_timer_func(unsigned long context ) 
{ 
  struct efx_nic *efx ;
  struct falcon_nic_data *nic_data ;

  {
  efx = (struct efx_nic *)context;
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  spin_lock(& efx->stats_lock);
  falcon_stats_complete(efx);
  if (nic_data->stats_disable_count == 0U) {
    falcon_stats_request(efx);
  } else {

  }
  spin_unlock(& efx->stats_lock);
  return;
}
}
static bool falcon_loopback_link_poll(struct efx_nic *efx ) 
{ 
  struct efx_link_state old_state ;
  int __ret_warn_on ;
  int tmp ;
  long tmp___0 ;
  int __ret_warn_on___0 ;
  long tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;

  {
  old_state = efx->link_state;
  tmp = ldv_mutex_is_locked_179(& efx->mac_lock);
  __ret_warn_on = tmp == 0;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c",
                       1470);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  __ret_warn_on___0 = ((66600958 >> (int )efx->loopback_mode) & 1) == 0;
  tmp___1 = ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
  if (tmp___1 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c",
                       1471);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
  efx->link_state.fd = 1;
  efx->link_state.fc = efx->wanted_fc;
  efx->link_state.up = 1;
  efx->link_state.speed = 10000U;
  tmp___2 = efx_link_state_equal((struct efx_link_state  const  *)(& efx->link_state),
                                 (struct efx_link_state  const  *)(& old_state));
  if ((int )tmp___2 != 0) {
    tmp___3 = 0;
  } else {
    tmp___3 = 1;
  }
  return ((bool )tmp___3);
}
}
static int falcon_reconfigure_port(struct efx_nic *efx ) 
{ 
  int rc ;
  int __ret_warn_on ;
  int tmp ;
  long tmp___0 ;
  long tmp___1 ;

  {
  tmp = efx_nic_rev(efx);
  __ret_warn_on = tmp > 2;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c",
                       1485);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if ((66600958 >> (int )efx->loopback_mode) & 1) {
    falcon_loopback_link_poll(efx);
  } else {
    (*((efx->phy_op)->poll))(efx);
  }
  falcon_stop_nic_stats(efx);
  falcon_deconfigure_mac_wrapper(efx);
  falcon_reset_macs(efx);
  (*((efx->phy_op)->reconfigure))(efx);
  rc = falcon_reconfigure_xmac(efx);
  tmp___1 = ldv__builtin_expect(rc != 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c"),
                         "i" (1503), "i" (12UL));
    ldv_57107: ;
    goto ldv_57107;
  } else {

  }
  falcon_start_nic_stats(efx);
  efx_link_status_changed(efx);
  return (0);
}
}
static void falcon_a1_prepare_enable_fc_tx(struct efx_nic *efx ) 
{ 


  {
  efx_schedule_reset(efx, 0);
  return;
}
}
static void falcon_b0_prepare_enable_fc_tx(struct efx_nic *efx ) 
{ 


  {
  falcon_stop_nic_stats(efx);
  falcon_drain_tx_fifo(efx);
  falcon_reconfigure_xmac(efx);
  falcon_start_nic_stats(efx);
  return;
}
}
static int falcon_gmii_wait(struct efx_nic *efx ) 
{ 
  efx_oword_t md_stat ;
  int count ;

  {
  count = 0;
  goto ldv_57120;
  ldv_57119: 
  efx_reado(efx, & md_stat, 3152U);
  if ((md_stat.u64[0] & 1ULL) == 0ULL) {
    if ((int )(md_stat.u64[0] >> 1) & 1 || (int )(md_stat.u64[0] >> 2) & 1) {
      if ((efx->msg_enable & 8192U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "error from GMII access %08x:%08x:%08x:%08x\n",
                   md_stat.u32[3], md_stat.u32[2], md_stat.u32[1], md_stat.u32[0]);
      } else {

      }
      return (-5);
    } else {

    }
    return (0);
  } else {

  }
  __const_udelay(42950UL);
  count = count + 1;
  ldv_57120: ;
  if (count <= 4999) {
    goto ldv_57119;
  } else {

  }

  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "timed out waiting for GMII\n");
  } else {

  }
  return (-110);
}
}
static int falcon_mdio_write(struct net_device *net_dev , int prtad , int devad ,
                             u16 addr , u16 value ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct falcon_nic_data *nic_data ;
  efx_oword_t reg ;
  int rc ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  ldv_mutex_lock_180(& nic_data->mdio_lock);
  rc = falcon_gmii_wait(efx);
  if (rc != 0) {
    goto out;
  } else {

  }
  reg.u64[0] = (unsigned long long )addr;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 3120U);
  reg.u64[0] = ((unsigned long long )prtad << 11) | ((unsigned long long )devad << 6);
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 3136U);
  reg.u64[0] = (unsigned long long )value;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 3072U);
  reg.u64[0] = 1ULL;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 3104U);
  rc = falcon_gmii_wait(efx);
  if (rc != 0) {
    reg.u64[0] = 16ULL;
    reg.u64[1] = 0ULL;
    efx_writeo(efx, (efx_oword_t const   *)(& reg), 3104U);
    __const_udelay(42950UL);
  } else {

  }
  out: 
  ldv_mutex_unlock_181(& nic_data->mdio_lock);
  return (rc);
}
}
static int falcon_mdio_read(struct net_device *net_dev , int prtad , int devad , u16 addr ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct falcon_nic_data *nic_data ;
  efx_oword_t reg ;
  int rc ;
  struct _ddebug descriptor ;
  long tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  ldv_mutex_lock_182(& nic_data->mdio_lock);
  rc = falcon_gmii_wait(efx);
  if (rc != 0) {
    goto out;
  } else {

  }
  reg.u64[0] = (unsigned long long )addr;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 3120U);
  reg.u64[0] = ((unsigned long long )prtad << 11) | ((unsigned long long )devad << 6);
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 3136U);
  reg.u64[0] = 2ULL;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 3104U);
  rc = falcon_gmii_wait(efx);
  if (rc == 0) {
    efx_reado(efx, & reg, 3088U);
    rc = (int )reg.u64[0] & 65535;
  } else {
    reg.u64[0] = 16ULL;
    reg.u64[1] = 0ULL;
    efx_writeo(efx, (efx_oword_t const   *)(& reg), 3104U);
    if ((efx->msg_enable & 8192U) != 0U) {
      descriptor.modname = "sfc";
      descriptor.function = "falcon_mdio_read";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c";
      descriptor.format = "read from MDIO %d register %d.%d, got error %d\n";
      descriptor.lineno = 1665U;
      descriptor.flags = 0U;
      tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp___0 != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "read from MDIO %d register %d.%d, got error %d\n", prtad,
                             devad, (int )addr, rc);
      } else {

      }
    } else {

    }
  }
  out: 
  ldv_mutex_unlock_183(& nic_data->mdio_lock);
  return (rc);
}
}
static int falcon_probe_port(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  int rc ;
  struct lock_class_key __key ;
  int tmp ;
  struct _ddebug descriptor ;
  phys_addr_t tmp___0 ;
  long tmp___1 ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  switch (efx->phy_type) {
  case 3U: 
  efx->phy_op = & falcon_sfx7101_phy_ops;
  goto ldv_57155;
  case 4U: ;
  case 9U: 
  efx->phy_op = & falcon_qt202x_phy_ops;
  goto ldv_57155;
  case 1U: 
  efx->phy_op = & falcon_txc_phy_ops;
  goto ldv_57155;
  default: ;
  if ((efx->msg_enable & 2U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "Unknown PHY type %d\n",
               efx->phy_type);
  } else {

  }
  return (-19);
  }
  ldv_57155: 
  __mutex_init(& nic_data->mdio_lock, "&nic_data->mdio_lock", & __key);
  efx->mdio.mdio_read = & falcon_mdio_read;
  efx->mdio.mdio_write = & falcon_mdio_write;
  rc = (*((efx->phy_op)->probe))(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  efx->link_state.speed = 10000U;
  efx->link_state.fd = 1;
  tmp = efx_nic_rev(efx);
  if (tmp > 1) {
    efx->wanted_fc = 3U;
  } else {
    efx->wanted_fc = 2U;
  }
  if ((efx->mdio.mmds & 128U) != 0U) {
    efx->wanted_fc = (u8 )((unsigned int )efx->wanted_fc | 4U);
  } else {

  }
  rc = efx_nic_alloc_buffer(efx, & efx->stats_buffer, 256U, 208U);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "falcon_probe_port";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c";
    descriptor.format = "stats buffer at %llx (virt %p phys %llx)\n";
    descriptor.lineno = 1725U;
    descriptor.flags = 0U;
    tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___1 != 0L) {
      tmp___0 = virt_to_phys((void volatile   *)efx->stats_buffer.addr);
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "stats buffer at %llx (virt %p phys %llx)\n", efx->stats_buffer.dma_addr,
                           efx->stats_buffer.addr, tmp___0);
    } else {

    }
  } else {

  }
  return (0);
}
}
static void falcon_remove_port(struct efx_nic *efx ) 
{ 


  {
  (*((efx->phy_op)->remove))(efx);
  efx_nic_free_buffer(efx, & efx->stats_buffer);
  return;
}
}
static bool falcon_handle_global_event(struct efx_channel *channel , efx_qword_t *event ) 
{ 
  struct efx_nic *efx ;
  struct falcon_nic_data *nic_data ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
  efx = channel->efx;
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  if (((int )(event->u64[0] >> 7) & 1 || (int )(event->u64[0] >> 9) & 1) || (int )(event->u64[0] >> 10) & 1) {
    return (1);
  } else {

  }
  tmp = efx_nic_rev(efx);
  if (tmp == 2 && (int )(event->u64[0] >> 11) & 1) {
    nic_data->xmac_poll_required = 1;
    return (1);
  } else {

  }
  tmp___1 = efx_nic_rev(efx);
  if (tmp___1 <= 1 ? (int )(event->u64[0] >> 11) & 1 : (int )(event->u64[0] >> 12) & 1) {
    if ((efx->msg_enable & 64U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "channel %d seen global RX_RESET event. Resetting.\n",
                 channel->channel);
    } else {

    }
    atomic_inc(& efx->rx_reset);
    tmp___0 = efx_nic_rev(efx);
    efx_schedule_reset(efx, tmp___0 <= 1 ? 11 : 7);
    return (1);
  } else {

  }
  return (0);
}
}
static int falcon_read_nvram(struct efx_nic *efx , struct falcon_nvconfig *nvconfig_out ) 
{ 
  struct falcon_nic_data *nic_data ;
  struct falcon_nvconfig *nvconfig ;
  struct falcon_spi_device *spi ;
  void *region ;
  int rc ;
  int magic_num ;
    klee_make_symbolic(&magic_num, sizeof(int), "magic_num");
  int struct_ver ;
    klee_make_symbolic(&struct_ver, sizeof(int), "struct_ver");
  __le16 *word ;
  __le16 *limit ;
  u32 csum ;
  bool tmp ;
  bool tmp___0 ;
  bool tmp___1 ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  tmp___0 = falcon_spi_present((struct falcon_spi_device  const  *)(& nic_data->spi_flash));
  if ((int )tmp___0) {
    spi = & nic_data->spi_flash;
  } else {
    tmp = falcon_spi_present((struct falcon_spi_device  const  *)(& nic_data->spi_eeprom));
    if ((int )tmp) {
      spi = & nic_data->spi_eeprom;
    } else {
      return (-22);
    }
  }
  region = kmalloc(1024UL, 208U);
  if ((unsigned long )region == (unsigned long )((void *)0)) {
    return (-12);
  } else {

  }
  nvconfig = (struct falcon_nvconfig *)region + 768U;
  ldv_mutex_lock_184(& nic_data->spi_lock);
  rc = falcon_spi_read(efx, (struct falcon_spi_device  const  *)spi, 0LL, 1024UL,
                       (size_t *)0UL, (u8 *)region);
  ldv_mutex_unlock_185(& nic_data->spi_lock);
  if (rc != 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      tmp___1 = falcon_spi_present((struct falcon_spi_device  const  *)(& nic_data->spi_flash));
      netdev_err((struct net_device  const  *)efx->net_dev, "Failed to read %s\n",
                 (int )tmp___1 ? (char *)"flash" : (char *)"EEPROM");
    } else {

    }
    rc = -5;
    goto out;
  } else {

  }
  magic_num = (int )nvconfig->board_magic_num;
  struct_ver = (int )nvconfig->board_struct_ver;
  rc = -22;
  if (magic_num != 64028) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "NVRAM bad magic 0x%x\n",
                 magic_num);
    } else {

    }
    goto out;
  } else {

  }
  if (struct_ver <= 1) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "NVRAM has ancient version 0x%x\n",
                 struct_ver);
    } else {

    }
    goto out;
  } else
  if (struct_ver <= 3) {
    word = & nvconfig->board_magic_num;
    limit = (__le16 *)nvconfig + 1U;
  } else {
    word = (__le16 *)region;
    limit = (__le16 *)region + 1024U;
  }
  csum = 0U;
  goto ldv_57188;
  ldv_57187: 
  csum = (u32 )*word + csum;
  word = word + 1;
  ldv_57188: ;
  if ((unsigned long )word < (unsigned long )limit) {
    goto ldv_57187;
  } else {

  }

  if ((~ csum & 65535U) != 0U) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "NVRAM has incorrect checksum\n");
    } else {

    }
    goto out;
  } else {

  }
  rc = 0;
  if ((unsigned long )nvconfig_out != (unsigned long )((struct falcon_nvconfig *)0)) {
    memcpy((void *)nvconfig_out, (void const   *)nvconfig, 200UL);
  } else {

  }
  out: 
  kfree((void const   *)region);
  return (rc);
}
}
static int falcon_test_nvram(struct efx_nic *efx ) 
{ 
  int tmp ;

  {
  tmp = falcon_read_nvram(efx, (struct falcon_nvconfig *)0);
  return (tmp);
}
}
static struct efx_farch_register_test  const  falcon_b0_register_tests[18U]  = 
  {      {0U, {.u32 = {262143U, 262143U, 262143U, 262143U}}}, 
        {2048U, {.u32 = {4294967294U, 98303U, 0U, 0U}}}, 
        {2640U, {.u32 = {2147418167U, 0U, 0U, 0U}}}, 
        {2688U, {.u32 = {4294901376U, 536870911U, 33554686U, 8388607U}}}, 
        {3200U, {.u32 = {4294901760U, 0U, 0U, 0U}}}, 
        {1568U, {.u32 = {2097151U, 0U, 0U, 0U}}}, 
        {2112U, {.u32 = {15U, 0U, 0U, 0U}}}, 
        {2128U, {.u32 = {1023U, 0U, 0U, 0U}}}, 
        {592U, {.u32 = {4095U, 0U, 0U, 0U}}}, 
        {3600U, {.u32 = {29495U, 0U, 0U, 0U}}}, 
        {3872U, {.u32 = {7967U, 0U, 0U, 0U}}}, 
        {4640U, {.u32 = {3176U, 0U, 0U, 0U}}}, 
        {4656U, {.u32 = {524644U, 0U, 0U, 0U}}}, 
        {4672U, {.u32 = {118491660U, 0U, 0U, 0U}}}, 
        {4832U, {.u32 = {8184U, 0U, 0U, 0U}}}, 
        {4720U, {.u32 = {4294901761U, 0U, 0U, 0U}}}, 
        {4608U, {.u32 = {4294967295U, 0U, 0U, 0U}}}, 
        {4880U, {.u32 = {261903U, 0U, 0U, 0U}}}};
static int falcon_b0_test_chip(struct efx_nic *efx , struct efx_self_tests *tests ) 
{ 
  enum reset_type reset_method ;
  int rc ;
  int rc2 ;
  unsigned long tmp ;
  int tmp___0 ;

  {
  reset_method = 0;
  ldv_mutex_lock_186(& efx->mac_lock);
  if (efx->loopback_modes != 0ULL) {
    if ((efx->loopback_modes & 8ULL) != 0ULL) {
      efx->loopback_mode = 3;
    } else {
      tmp = __ffs((unsigned long )efx->loopback_modes);
      efx->loopback_mode = (enum efx_loopback_mode )tmp;
    }
  } else {

  }
  __efx_reconfigure_port(efx);
  ldv_mutex_unlock_187(& efx->mac_lock);
  efx_reset_down(efx, reset_method);
  tmp___0 = efx_farch_test_registers(efx, (struct efx_farch_register_test  const  *)(& falcon_b0_register_tests),
                                     18UL);
  tests->registers = tmp___0 != 0 ? -1 : 1;
  rc = falcon_reset_hw(efx, reset_method);
  rc2 = efx_reset_up(efx, reset_method, rc == 0);
  return (rc != 0 ? rc : rc2);
}
}
static enum reset_type falcon_map_reset_reason(enum reset_type reason ) 
{ 


  {
  switch ((unsigned int )reason) {
  case 11U: ;
  case 12U: ;
  case 13U: ;
  return (0);
  default: ;
  return (2);
  }
}
}
static int falcon_map_reset_flags(u32 *flags ) 
{ 


  {
  if ((*flags & 126U) == 126U) {
    *flags = *flags & 4294967169U;
    return (3);
  } else {

  }
  if ((*flags & 124U) == 124U) {
    *flags = *flags & 4294967171U;
    return (2);
  } else {

  }
  if ((*flags & 60U) == 60U) {
    *flags = *flags & 4294967235U;
    return (0);
  } else {

  }
  return (-22);
}
}
static int __falcon_reset_hw(struct efx_nic *efx , enum reset_type method ) 
{ 
  struct falcon_nic_data *nic_data ;
  efx_oword_t glb_ctl_reg_ker ;
  int rc ;
  struct _ddebug descriptor ;
  long tmp ;
  bool tmp___0 ;
  struct _ddebug descriptor___0 ;
  long tmp___1 ;
  bool tmp___2 ;
  struct _ddebug descriptor___1 ;
  long tmp___3 ;
  struct _ddebug descriptor___2 ;
  long tmp___4 ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "__falcon_reset_hw";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c";
    descriptor.format = "performing %s hardware reset\n";
    descriptor.lineno = 1981U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "performing %s hardware reset\n", (unsigned int )method < (unsigned int )efx_reset_type_max ? efx_reset_type_names[(unsigned int )method] : (char const   */* const  */)"(invalid)");
    } else {

    }
  } else {

  }
  if ((unsigned int )method == 3U) {
    rc = pci_save_state(efx->pci_dev);
    if (rc != 0) {
      if ((int )efx->msg_enable & 1) {
        netdev_err((struct net_device  const  *)efx->net_dev, "failed to backup PCI state of primary function prior to hardware reset\n");
      } else {

      }
      goto fail1;
    } else {

    }
    tmp___0 = efx_nic_is_dual_func(efx);
    if ((int )tmp___0) {
      rc = pci_save_state(nic_data->pci_dev2);
      if (rc != 0) {
        if ((int )efx->msg_enable & 1) {
          netdev_err((struct net_device  const  *)efx->net_dev, "failed to backup PCI state of secondary function prior to hardware reset\n");
        } else {

        }
        goto fail2;
      } else {

      }
    } else {

    }
    glb_ctl_reg_ker.u64[0] = 15ULL;
    glb_ctl_reg_ker.u64[1] = 0ULL;
  } else {
    glb_ctl_reg_ker.u64[0] = (unsigned int )method == 0U ? 0xa60200000000000fULL : 2738751523394682895ULL;
    glb_ctl_reg_ker.u64[1] = 0ULL;
  }
  efx_writeo(efx, (efx_oword_t const   *)(& glb_ctl_reg_ker), 544U);
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor___0.modname = "sfc";
    descriptor___0.function = "__falcon_reset_hw";
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c";
    descriptor___0.format = "waiting for hardware reset\n";
    descriptor___0.lineno = 2023U;
    descriptor___0.flags = 0U;
    tmp___1 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
    if (tmp___1 != 0L) {
      __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                           "waiting for hardware reset\n");
    } else {

    }
  } else {

  }
  schedule_timeout_uninterruptible(12L);
  if ((unsigned int )method == 3U) {
    tmp___2 = efx_nic_is_dual_func(efx);
    if ((int )tmp___2) {
      pci_restore_state(nic_data->pci_dev2);
    } else {

    }
    pci_restore_state(efx->pci_dev);
    if ((int )efx->msg_enable & 1) {
      descriptor___1.modname = "sfc";
      descriptor___1.function = "__falcon_reset_hw";
      descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c";
      descriptor___1.format = "successfully restored PCI config\n";
      descriptor___1.lineno = 2032U;
      descriptor___1.flags = 0U;
      tmp___3 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
      if (tmp___3 != 0L) {
        __dynamic_netdev_dbg(& descriptor___1, (struct net_device  const  *)efx->net_dev,
                             "successfully restored PCI config\n");
      } else {

      }
    } else {

    }
  } else {

  }
  efx_reado(efx, & glb_ctl_reg_ker, 544U);
  if ((int )glb_ctl_reg_ker.u64[0] & 1) {
    rc = -110;
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "timed out waiting for hardware reset\n");
    } else {

    }
    goto fail3;
  } else {

  }
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor___2.modname = "sfc";
    descriptor___2.function = "__falcon_reset_hw";
    descriptor___2.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c";
    descriptor___2.format = "hardware reset complete\n";
    descriptor___2.lineno = 2043U;
    descriptor___2.flags = 0U;
    tmp___4 = ldv__builtin_expect((long )descriptor___2.flags & 1L, 0L);
    if (tmp___4 != 0L) {
      __dynamic_netdev_dbg(& descriptor___2, (struct net_device  const  *)efx->net_dev,
                           "hardware reset complete\n");
    } else {

    }
  } else {

  }
  return (0);
  fail2: 
  pci_restore_state(efx->pci_dev);
  fail1: ;
  fail3: ;
  return (rc);
}
}
static int falcon_reset_hw(struct efx_nic *efx , enum reset_type method ) 
{ 
  struct falcon_nic_data *nic_data ;
  int rc ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  ldv_mutex_lock_188(& nic_data->spi_lock);
  rc = __falcon_reset_hw(efx, method);
  ldv_mutex_unlock_189(& nic_data->spi_lock);
  return (rc);
}
}
static void falcon_monitor(struct efx_nic *efx ) 
{ 
  bool link_changed ;
  int rc ;
  int tmp ;
  long tmp___0 ;
  struct falcon_board *tmp___1 ;
  int __ret_warn_on ;
  long tmp___2 ;
  long tmp___3 ;

  {
  tmp = mutex_is_locked(& efx->mac_lock);
  tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c"),
                         "i" (2072), "i" (12UL));
    ldv_57243: ;
    goto ldv_57243;
  } else {

  }
  tmp___1 = falcon_board(efx);
  rc = (*((tmp___1->type)->monitor))(efx);
  if (rc != 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Board sensor %s; shutting down PHY\n",
                 rc == -34 ? (char *)"reported fault" : (char *)"failed");
    } else {

    }
    efx->phy_mode = (enum efx_phy_mode )((unsigned int )efx->phy_mode | 2U);
    rc = __efx_reconfigure_port(efx);
    __ret_warn_on = rc != 0;
    tmp___2 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___2 != 0L) {
      warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c",
                         2081);
    } else {

    }
    ldv__builtin_expect(__ret_warn_on != 0, 0L);
  } else {

  }
  if ((66600958 >> (int )efx->loopback_mode) & 1) {
    link_changed = falcon_loopback_link_poll(efx);
  } else {
    link_changed = (*((efx->phy_op)->poll))(efx);
  }
  if ((int )link_changed) {
    falcon_stop_nic_stats(efx);
    falcon_deconfigure_mac_wrapper(efx);
    falcon_reset_macs(efx);
    rc = falcon_reconfigure_xmac(efx);
    tmp___3 = ldv__builtin_expect(rc != 0, 0L);
    if (tmp___3 != 0L) {
      __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c"),
                           "i" (2095), "i" (12UL));
      ldv_57246: ;
      goto ldv_57246;
    } else {

    }
    falcon_start_nic_stats(efx);
    efx_link_status_changed(efx);
  } else {

  }
  falcon_poll_xmac(efx);
  return;
}
}
static int falcon_reset_sram(struct efx_nic *efx ) 
{ 
  efx_oword_t srm_cfg_reg_ker ;
  efx_oword_t gpio_cfg_reg_ker ;
  int count ;
  struct _ddebug descriptor ;
  long tmp ;
  struct _ddebug descriptor___0 ;
  long tmp___0 ;

  {
  efx_reado(efx, & gpio_cfg_reg_ker, 528U);
  gpio_cfg_reg_ker.u64[0] = gpio_cfg_reg_ker.u64[0] | 33554432ULL;
  gpio_cfg_reg_ker.u64[1] = gpio_cfg_reg_ker.u64[1];
  gpio_cfg_reg_ker.u64[0] = gpio_cfg_reg_ker.u64[0] | 131072ULL;
  gpio_cfg_reg_ker.u64[1] = gpio_cfg_reg_ker.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& gpio_cfg_reg_ker), 528U);
  srm_cfg_reg_ker.u64[0] = 8ULL;
  srm_cfg_reg_ker.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& srm_cfg_reg_ker), 1584U);
  count = 0;
  ldv_57256: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "falcon_reset_sram";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c";
    descriptor.format = "waiting for SRAM reset (attempt %d)...\n";
    descriptor.lineno = 2129U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "waiting for SRAM reset (attempt %d)...\n", count);
    } else {

    }
  } else {

  }
  schedule_timeout_uninterruptible(5L);
  efx_reado(efx, & srm_cfg_reg_ker, 1584U);
  if (((srm_cfg_reg_ker.u64[0] >> 3) & 1ULL) == 0ULL) {
    if ((efx->msg_enable & 8192U) != 0U) {
      descriptor___0.modname = "sfc";
      descriptor___0.function = "falcon_reset_sram";
      descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c";
      descriptor___0.format = "SRAM reset complete\n";
      descriptor___0.lineno = 2138U;
      descriptor___0.flags = 0U;
      tmp___0 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
      if (tmp___0 != 0L) {
        __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                             "SRAM reset complete\n");
      } else {

      }
    } else {

    }
    return (0);
  } else {

  }
  count = count + 1;
  if (count <= 19) {
    goto ldv_57256;
  } else {

  }

  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "timed out waiting for SRAM reset\n");
  } else {

  }
  return (-110);
}
}
static void falcon_spi_device_init(struct efx_nic *efx , struct falcon_spi_device *spi_device ,
                                   unsigned int device_id , u32 device_type ) 
{ 


  {
  if (device_type != 0U) {
    spi_device->device_id = (int )device_id;
    spi_device->size = (unsigned int )(1 << ((int )device_type & 31));
    spi_device->addr_len = (device_type >> 6) & 3U;
    spi_device->munge_address = (unsigned char )(spi_device->size == 512U && spi_device->addr_len == 1U);
    spi_device->erase_command = (u8 )(device_type >> 8);
    spi_device->erase_size = (unsigned int )(1 << ((int )(device_type >> 16) & 31));
    spi_device->block_size = (unsigned int )(1 << ((int )(device_type >> 24) & 31));
  } else {
    spi_device->size = 0U;
  }
  return;
}
}
static int falcon_probe_nvconfig(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  struct falcon_nvconfig *nvconfig ;
  int rc ;
  void *tmp ;
  struct _ddebug descriptor ;
  long tmp___0 ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  tmp = kmalloc(200UL, 208U);
  nvconfig = (struct falcon_nvconfig *)tmp;
  if ((unsigned long )nvconfig == (unsigned long )((struct falcon_nvconfig *)0)) {
    return (-12);
  } else {

  }
  rc = falcon_read_nvram(efx, nvconfig);
  if (rc != 0) {
    goto out;
  } else {

  }
  efx->phy_type = (unsigned int )nvconfig->board_v2.port0_phy_type;
  efx->mdio.prtad = (int )nvconfig->board_v2.port0_phy_addr;
  if ((unsigned int )nvconfig->board_struct_ver > 2U) {
    falcon_spi_device_init(efx, & nic_data->spi_flash, 1U, nvconfig->board_v3.spi_device_type[1]);
    falcon_spi_device_init(efx, & nic_data->spi_eeprom, 0U, nvconfig->board_v3.spi_device_type[0]);
  } else {

  }
  ether_addr_copy((u8 *)(& (efx->net_dev)->perm_addr), (u8 const   *)(& nvconfig->mac_address));
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "falcon_probe_nvconfig";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c";
    descriptor.format = "PHY is %d phy_id %d\n";
    descriptor.lineno = 2206U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "PHY is %d phy_id %d\n", efx->phy_type, efx->mdio.prtad);
    } else {

    }
  } else {

  }
  rc = falcon_probe_board(efx, (int )nvconfig->board_v2.board_revision);
  out: 
  kfree((void const   *)nvconfig);
  return (rc);
}
}
static int falcon_dimension_resources(struct efx_nic *efx ) 
{ 


  {
  efx->rx_dc_base = 131072U;
  efx->tx_dc_base = 155648U;
  return (0);
}
}
static void falcon_probe_spi_devices(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  efx_oword_t nic_stat ;
  efx_oword_t gpio_ctl ;
  efx_oword_t ee_vpd_cfg ;
  int boot_dev ;
    klee_make_symbolic(&boot_dev, sizeof(int), "boot_dev");
  struct _ddebug descriptor ;
  long tmp ;
  struct _ddebug descriptor___0 ;
  long tmp___0 ;
  struct lock_class_key __key ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  efx_reado(efx, & gpio_ctl, 528U);
  efx_reado(efx, & nic_stat, 512U);
  efx_reado(efx, & ee_vpd_cfg, 320U);
  if ((int )(gpio_ctl.u64[0] >> 3) & 1) {
    boot_dev = (int )(nic_stat.u64[0] >> 9) & 1;
    if ((efx->msg_enable & 2U) != 0U) {
      descriptor.modname = "sfc";
      descriptor.function = "falcon_probe_spi_devices";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c";
      descriptor.format = "Booted from %s\n";
      descriptor.lineno = 2238U;
      descriptor.flags = 0U;
      tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "Booted from %s\n", boot_dev == 1 ? (char *)"flash" : (char *)"EEPROM");
      } else {

      }
    } else {

    }
  } else {
    boot_dev = -1;
    if ((efx->msg_enable & 2U) != 0U) {
      descriptor___0.modname = "sfc";
      descriptor___0.function = "falcon_probe_spi_devices";
      descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c";
      descriptor___0.format = "Booted from internal ASIC settings; setting SPI config\n";
      descriptor___0.lineno = 2245U;
      descriptor___0.flags = 0U;
      tmp___0 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
      if (tmp___0 != 0L) {
        __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                             "Booted from internal ASIC settings; setting SPI config\n");
      } else {

      }
    } else {

    }
    ee_vpd_cfg.u64[0] = 0ULL;
    ee_vpd_cfg.u64[1] = 522136081798266880ULL;
    efx_writeo(efx, (efx_oword_t const   *)(& ee_vpd_cfg), 320U);
  }
  __mutex_init(& nic_data->spi_lock, "&nic_data->spi_lock", & __key);
  if (boot_dev == 1) {
    falcon_spi_device_init(efx, & nic_data->spi_flash, 1U, default_flash_type);
  } else {

  }
  if (boot_dev == 0) {
    falcon_spi_device_init(efx, & nic_data->spi_eeprom, 0U, large_eeprom_type);
  } else {

  }
  return;
}
}
static unsigned int falcon_a1_mem_map_size(struct efx_nic *efx ) 
{ 


  {
  return (131072U);
}
}
static unsigned int falcon_b0_mem_map_size(struct efx_nic *efx ) 
{ 


  {
  return (16451584U);
}
}
static int falcon_probe_nic(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  struct falcon_board *board ;
  int rc ;
  void *tmp ;
  u32 tmp___0 ;
  efx_oword_t nic_stat ;
  struct pci_dev *dev ;
  u8 pci_rev ;
  int tmp___1 ;
  long tmp___2 ;
  struct _ddebug descriptor ;
  phys_addr_t tmp___3 ;
  long tmp___4 ;
  int tmp___5 ;
  struct falcon_board *tmp___6 ;

  {
  efx->primary = efx;
  tmp = kzalloc(2944UL, 208U);
  nic_data = (struct falcon_nic_data *)tmp;
  if ((unsigned long )nic_data == (unsigned long )((struct falcon_nic_data *)0)) {
    return (-12);
  } else {

  }
  efx->nic_data = (void *)nic_data;
  rc = -19;
  tmp___0 = efx_farch_fpga_ver(efx);
  if (tmp___0 != 0U) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Falcon FPGA not supported\n");
    } else {

    }
    goto fail1;
  } else {

  }
  tmp___1 = efx_nic_rev(efx);
  if (tmp___1 <= 1) {
    pci_rev = (efx->pci_dev)->revision;
    if ((unsigned int )pci_rev == 255U || (unsigned int )pci_rev == 0U) {
      if ((efx->msg_enable & 2U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "Falcon rev A0 not supported\n");
      } else {

      }
      goto fail1;
    } else {

    }
    efx_reado(efx, & nic_stat, 512U);
    if (((nic_stat.u64[0] >> 2) & 1ULL) == 0ULL) {
      if ((efx->msg_enable & 2U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "Falcon rev A1 1G not supported\n");
      } else {

      }
      goto fail1;
    } else {

    }
    if ((nic_stat.u64[0] & 1ULL) == 0ULL) {
      if ((efx->msg_enable & 2U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "Falcon rev A1 PCI-X not supported\n");
      } else {

      }
      goto fail1;
    } else {

    }
    dev = pci_dev_get(efx->pci_dev);
    goto ldv_57306;
    ldv_57305: ;
    if ((unsigned long )dev->bus == (unsigned long )(efx->pci_dev)->bus && dev->devfn == (efx->pci_dev)->devfn + 1U) {
      nic_data->pci_dev2 = dev;
      goto ldv_57304;
    } else {

    }
    ldv_57306: 
    dev = pci_get_device(6436U, 26371U, dev);
    if ((unsigned long )dev != (unsigned long )((struct pci_dev *)0)) {
      goto ldv_57305;
    } else {

    }
    ldv_57304: ;
    if ((unsigned long )nic_data->pci_dev2 == (unsigned long )((struct pci_dev *)0)) {
      if ((efx->msg_enable & 2U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "failed to find secondary function\n");
      } else {

      }
      rc = -19;
      goto fail2;
    } else {

    }
  } else {

  }
  rc = __falcon_reset_hw(efx, 2);
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to reset NIC\n");
    } else {

    }
    goto fail3;
  } else {

  }
  rc = efx_nic_alloc_buffer(efx, & efx->irq_status, 16U, 208U);
  if (rc != 0) {
    goto fail4;
  } else {

  }
  tmp___2 = ldv__builtin_expect((efx->irq_status.dma_addr & 15ULL) != 0ULL, 0L);
  if (tmp___2 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c"),
                         "i" (2354), "i" (12UL));
    ldv_57310: ;
    goto ldv_57310;
  } else {

  }
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "falcon_probe_nic";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c";
    descriptor.format = "INT_KER at %llx (virt %p phys %llx)\n";
    descriptor.lineno = 2360U;
    descriptor.flags = 0U;
    tmp___4 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___4 != 0L) {
      tmp___3 = virt_to_phys((void volatile   *)efx->irq_status.addr);
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "INT_KER at %llx (virt %p phys %llx)\n", efx->irq_status.dma_addr,
                           efx->irq_status.addr, tmp___3);
    } else {

    }
  } else {

  }
  falcon_probe_spi_devices(efx);
  rc = falcon_probe_nvconfig(efx);
  if (rc != 0) {
    if (rc == -22) {
      if ((efx->msg_enable & 2U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "NVRAM is invalid\n");
      } else {

      }
    } else {

    }
    goto fail5;
  } else {

  }
  tmp___5 = efx_nic_rev(efx);
  efx->max_channels = tmp___5 <= 1 ? 4U : 32U;
  efx->timer_quantum_ns = 4968U;
  board = falcon_board(efx);
  board->i2c_adap.owner = & __this_module;
  board->i2c_data = falcon_i2c_bit_operations;
  board->i2c_data.data = (void *)efx;
  board->i2c_adap.algo_data = (void *)(& board->i2c_data);
  board->i2c_adap.dev.parent = & (efx->pci_dev)->dev;
  strlcpy((char *)(& board->i2c_adap.name), "SFC4000 GPIO", 48UL);
  rc = i2c_bit_add_bus(& board->i2c_adap);
  if (rc != 0) {
    goto fail5;
  } else {

  }
  tmp___6 = falcon_board(efx);
  rc = (*((tmp___6->type)->init))(efx);
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to initialise board\n");
    } else {

    }
    goto fail6;
  } else {

  }
  nic_data->stats_disable_count = 1U;
  reg_timer_10(& nic_data->stats_timer, & falcon_stats_timer_func, (unsigned long )efx);
  return (0);
  fail6: 
  i2c_del_adapter(& board->i2c_adap);
  memset((void *)(& board->i2c_adap), 0, 1936UL);
  fail5: 
  efx_nic_free_buffer(efx, & efx->irq_status);
  fail4: ;
  fail3: ;
  if ((unsigned long )nic_data->pci_dev2 != (unsigned long )((struct pci_dev *)0)) {
    pci_dev_put(nic_data->pci_dev2);
    nic_data->pci_dev2 = (struct pci_dev *)0;
  } else {

  }
  fail2: ;
  fail1: 
  kfree((void const   *)efx->nic_data);
  return (rc);
}
}
static void falcon_init_rx_cfg(struct efx_nic *efx ) 
{ 
  unsigned int ctrl_xon_thr ;
    klee_make_symbolic(&ctrl_xon_thr, sizeof(int), "ctrl_xon_thr");
  unsigned int ctrl_xoff_thr ;
    klee_make_symbolic(&ctrl_xoff_thr, sizeof(int), "ctrl_xoff_thr");
  efx_oword_t reg ;
  int tmp ;

  {
  ctrl_xon_thr = 20U;
  ctrl_xoff_thr = 25U;
  efx_reado(efx, & reg, 2048U);
  tmp = efx_nic_rev(efx);
  if (tmp <= 1) {
    reg.u64[0] = reg.u64[0] & 0xfffffff7ffffffffULL;
    reg.u64[1] = reg.u64[1];
    reg.u64[0] = (reg.u64[0] & 0xfffffffffff007ffULL) | 786432ULL;
    reg.u64[1] = reg.u64[1];
    reg.u64[0] = (reg.u64[0] & 0xfffffffffffff83fULL) | 128ULL;
    reg.u64[1] = reg.u64[1];
    reg.u64[0] = (reg.u64[0] & 0xffffffffffffffc1ULL) | 16ULL;
    reg.u64[1] = reg.u64[1];
    reg.u64[0] = (reg.u64[0] & 0xffffffffc1ffffffULL) | ((unsigned long long )ctrl_xon_thr << 25);
    reg.u64[1] = reg.u64[1];
    reg.u64[0] = (reg.u64[0] & 0xfffffffffe0fffffULL) | ((unsigned long long )ctrl_xoff_thr << 20);
    reg.u64[1] = reg.u64[1];
  } else {
    reg.u64[0] = reg.u64[0] & 0xfffff7ffffffffffULL;
    reg.u64[1] = reg.u64[1];
    reg.u64[0] = (reg.u64[0] & 0xfffffffff007ffffULL) | 29360128ULL;
    reg.u64[1] = reg.u64[1];
    reg.u64[0] = (reg.u64[0] & 0xfffffffffff803ffULL) | 110592ULL;
    reg.u64[1] = reg.u64[1];
    reg.u64[0] = (reg.u64[0] & 0xfffffffffffffc01ULL) | 424ULL;
    reg.u64[1] = reg.u64[1];
    reg.u64[0] = (reg.u64[0] & 0xffffffc1ffffffffULL) | ((unsigned long long )ctrl_xon_thr << 33);
    reg.u64[1] = reg.u64[1];
    reg.u64[0] = (reg.u64[0] & 0xfffffffe0fffffffULL) | ((unsigned long long )ctrl_xoff_thr << 28);
    reg.u64[1] = reg.u64[1];
    reg.u64[0] = reg.u64[0] | 140737488355328ULL;
    reg.u64[1] = reg.u64[1];
    reg.u64[0] = reg.u64[0] | 17592186044416ULL;
    reg.u64[1] = reg.u64[1];
    reg.u64[0] = reg.u64[0] | 35184372088832ULL;
    reg.u64[1] = reg.u64[1];
    reg.u64[0] = reg.u64[0] | 70368744177664ULL;
    reg.u64[1] = reg.u64[1];
  }
  reg.u64[0] = reg.u64[0] | 1ULL;
  reg.u64[1] = reg.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 2048U);
  return;
}
}
static int falcon_init_nic(struct efx_nic *efx ) 
{ 
  efx_oword_t temp ;
  int rc ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
  efx_reado(efx, & temp, 512U);
  temp.u64[0] = temp.u64[0] | 65536ULL;
  temp.u64[1] = temp.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 512U);
  rc = falcon_reset_sram(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  tmp = efx_nic_rev(efx);
  if (tmp <= 1) {
    efx_reado(efx, & temp, 784U);
    temp.u64[0] = temp.u64[0];
    temp.u64[1] = temp.u64[1] & 0xfffffffffffffcffULL;
    efx_writeo(efx, (efx_oword_t const   *)(& temp), 784U);
  } else {

  }
  tmp___0 = efx_nic_rev(efx);
  if (tmp___0 <= 1) {
    efx_reado(efx, & temp, 2064U);
    temp.u64[0] = (temp.u64[0] & 0xffffff00ffffffffULL) | 34359738368ULL;
    temp.u64[1] = temp.u64[1];
    temp.u64[0] = (temp.u64[0] & 0xffffffffff00ffffULL) | 524288ULL;
    temp.u64[1] = temp.u64[1];
    temp.u64[0] = (temp.u64[0] & 0xffffffffffffff00ULL) | 8ULL;
    temp.u64[1] = temp.u64[1];
    temp.u64[0] = (temp.u64[0] & 0xffffffffffff00ffULL) | 2048ULL;
    temp.u64[1] = temp.u64[1];
    efx_writeo(efx, (efx_oword_t const   *)(& temp), 2064U);
  } else {

  }
  efx_reado(efx, & temp, 2192U);
  temp.u64[0] = temp.u64[0] | 512ULL;
  temp.u64[1] = temp.u64[1];
  temp.u64[0] = temp.u64[0] | 256ULL;
  temp.u64[1] = temp.u64[1];
  tmp___1 = efx_nic_rev(efx);
  if (tmp___1 <= 1) {
    temp.u64[0] = temp.u64[0] | 131072ULL;
    temp.u64[1] = temp.u64[1];
  } else {

  }
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 2192U);
  efx_reado(efx, & temp, 2640U);
  temp.u64[0] = temp.u64[0] & 0xffffffffffffffdfULL;
  temp.u64[1] = temp.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 2640U);
  falcon_init_rx_cfg(efx);
  tmp___2 = efx_nic_rev(efx);
  if (tmp___2 > 1) {
    falcon_b0_rx_push_rss_config(efx, 0, (u32 const   *)(& efx->rx_indir_table));
    temp.u64[0] = 0ULL;
    temp.u64[1] = 0ULL;
    efx_writeo(efx, (efx_oword_t const   *)(& temp), 592U);
  } else {

  }
  efx_farch_init_common(efx);
  return (0);
}
}
static void falcon_remove_nic(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  struct falcon_board *board ;
  struct falcon_board *tmp ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  tmp = falcon_board(efx);
  board = tmp;
  (*((board->type)->fini))(efx);
  i2c_del_adapter(& board->i2c_adap);
  memset((void *)(& board->i2c_adap), 0, 1936UL);
  efx_nic_free_buffer(efx, & efx->irq_status);
  __falcon_reset_hw(efx, 2);
  if ((unsigned long )nic_data->pci_dev2 != (unsigned long )((struct pci_dev *)0)) {
    pci_dev_put(nic_data->pci_dev2);
    nic_data->pci_dev2 = (struct pci_dev *)0;
  } else {

  }
  kfree((void const   *)efx->nic_data);
  efx->nic_data = (void *)0;
  return;
}
}
static size_t falcon_describe_nic_stats(struct efx_nic *efx , u8 *names ) 
{ 
  size_t tmp ;

  {
  tmp = efx_nic_describe_stats((struct efx_hw_stat_desc  const  *)(& falcon_stat_desc),
                               49UL, (unsigned long const   *)(& falcon_stat_mask),
                               names);
  return (tmp);
}
}
static size_t falcon_update_nic_stats(struct efx_nic *efx , u64 *full_stats , struct rtnl_link_stats64 *core_stats ) 
{ 
  struct falcon_nic_data *nic_data ;
  u64 *stats ;
  efx_oword_t cnt ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  stats = (u64 *)(& nic_data->stats);
  if (nic_data->stats_disable_count == 0U) {
    efx_reado(efx, & cnt, 2176U);
    *(stats + 48UL) = *(stats + 48UL) + (cnt.u64[0] & 65535ULL);
    if ((int )nic_data->stats_pending && *((u32 *)efx->stats_buffer.addr + 212U) != 0U) {
      nic_data->stats_pending = 0;
      __asm__  volatile   ("lfence": : : "memory");
      efx_nic_update_stats((struct efx_hw_stat_desc  const  *)(& falcon_stat_desc),
                           49UL, (unsigned long const   *)(& falcon_stat_mask), stats,
                           (void const   *)efx->stats_buffer.addr, 1);
    } else {

    }
    efx_update_diff_stat(stats + 23UL, (*(stats + 21UL) - *(stats + 22UL)) - *(stats + 28UL) * 64ULL);
    efx_update_sw_stats(efx, stats);
  } else {

  }
  if ((unsigned long )full_stats != (unsigned long )((u64 *)0ULL)) {
    memcpy((void *)full_stats, (void const   *)stats, 392UL);
  } else {

  }
  if ((unsigned long )core_stats != (unsigned long )((struct rtnl_link_stats64 *)0)) {
    core_stats->rx_packets = *(stats + 24UL);
    core_stats->tx_packets = *(stats + 3UL);
    core_stats->rx_bytes = *(stats + 21UL);
    core_stats->tx_bytes = *(stats + 2UL);
    core_stats->rx_dropped = (*(stats + 48UL) + *(stats + 1UL)) + *stats;
    core_stats->multicast = *(stats + 30UL);
    core_stats->rx_length_errors = *(stats + 40UL) + *(stats + 46UL);
    core_stats->rx_crc_errors = *(stats + 26UL);
    core_stats->rx_frame_errors = *(stats + 45UL);
    core_stats->rx_fifo_errors = *(stats + 43UL);
    core_stats->rx_errors = ((core_stats->rx_length_errors + core_stats->rx_crc_errors) + core_stats->rx_frame_errors) + *(stats + 44UL);
  } else {

  }
  return (49UL);
}
}
void falcon_start_nic_stats(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  spin_lock_bh(& efx->stats_lock);
  nic_data->stats_disable_count = nic_data->stats_disable_count - 1U;
  if (nic_data->stats_disable_count == 0U) {
    falcon_stats_request(efx);
  } else {

  }
  spin_unlock_bh(& efx->stats_lock);
  return;
}
}
static void falcon_pull_nic_stats(struct efx_nic *efx ) 
{ 


  {
  msleep(10U);
  return;
}
}
void falcon_stop_nic_stats(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  int i ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  __might_sleep("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/falcon.c",
                2648, 0);
  spin_lock_bh(& efx->stats_lock);
  nic_data->stats_disable_count = nic_data->stats_disable_count + 1U;
  spin_unlock_bh(& efx->stats_lock);
  ldv_del_timer_sync_190(& nic_data->stats_timer);
  i = 0;
  goto ldv_57357;
  ldv_57356: ;
  if (*((u32 *)efx->stats_buffer.addr + 212U) != 0U) {
    goto ldv_57355;
  } else {

  }
  msleep(1U);
  i = i + 1;
  ldv_57357: ;
  if (i <= 3 && (int )nic_data->stats_pending) {
    goto ldv_57356;
  } else {

  }
  ldv_57355: 
  spin_lock_bh(& efx->stats_lock);
  falcon_stats_complete(efx);
  spin_unlock_bh(& efx->stats_lock);
  return;
}
}
static void falcon_set_id_led(struct efx_nic *efx , enum efx_led_mode mode ) 
{ 
  struct falcon_board *tmp ;

  {
  tmp = falcon_board(efx);
  (*((tmp->type)->set_id_led))(efx, mode);
  return;
}
}
static void falcon_get_wol(struct efx_nic *efx , struct ethtool_wolinfo *wol ) 
{ 


  {
  wol->supported = 0U;
  wol->wolopts = 0U;
  memset((void *)(& wol->sopass), 0, 6UL);
  return;
}
}
static int falcon_set_wol(struct efx_nic *efx , u32 type ) 
{ 


  {
  if (type != 0U) {
    return (-22);
  } else {

  }
  return (0);
}
}
struct efx_nic_type  const  falcon_a1_nic_type  = 
     {0, 2U, & falcon_a1_mem_map_size, & falcon_probe_nic, & falcon_remove_nic, & falcon_init_nic,
    & falcon_dimension_resources, & falcon_irq_ack_a1, & falcon_monitor, & falcon_map_reset_reason,
    & falcon_map_reset_flags, & falcon_reset_hw, & falcon_probe_port, & falcon_remove_port,
    & falcon_handle_global_event, & efx_farch_fini_dmaq, & falcon_prepare_flush, & efx_port_dummy_op_void,
    & efx_port_dummy_op_void, & efx_farch_finish_flr, & falcon_describe_nic_stats,
    & falcon_update_nic_stats, & falcon_start_nic_stats, & falcon_pull_nic_stats,
    & falcon_stop_nic_stats, & falcon_set_id_led, & falcon_push_irq_moderation, & falcon_reconfigure_port,
    & falcon_a1_prepare_enable_fc_tx, & falcon_reconfigure_xmac, & falcon_xmac_check_fault,
    & falcon_get_wol, & falcon_set_wol, & efx_port_dummy_op_void, 0, & falcon_test_nvram,
    0, 0, 0, 0, & efx_farch_irq_enable_master, & efx_farch_irq_test_generate, & efx_farch_irq_disable_master,
    & efx_farch_msi_interrupt, & falcon_legacy_interrupt_a1, & efx_farch_tx_probe,
    & efx_farch_tx_init, & efx_farch_tx_remove, & efx_farch_tx_write, & dummy_rx_push_rss_config,
    & efx_farch_rx_probe, & efx_farch_rx_init, & efx_farch_rx_remove, & efx_farch_rx_write,
    & efx_farch_rx_defer_refill, & efx_farch_ev_probe, & efx_farch_ev_init, & efx_farch_ev_fini,
    & efx_farch_ev_remove, & efx_farch_ev_process, & efx_farch_ev_read_ack, & efx_farch_ev_test_generate,
    & efx_farch_filter_table_probe, & efx_farch_filter_table_restore, & efx_farch_filter_table_remove,
    0, & efx_farch_filter_insert, & efx_farch_filter_remove_safe, & efx_farch_filter_get_safe,
    & efx_farch_filter_clear_rx, & efx_farch_filter_count_rx_used, & efx_farch_filter_get_rx_id_limit,
    & efx_farch_filter_get_rx_ids, 0, 0, & falcon_mtd_probe, & falcon_mtd_rename,
    & falcon_mtd_read, & falcon_mtd_erase, & falcon_mtd_write, & falcon_mtd_sync,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 71936U, 71680U,
    98304U, 72192U, 72448U, 70368744177663ULL, 0U, 0U, 0U, 36U, 0, (_Bool)0, 1U, 4096U,
    2ULL, -1, 0U, 0U};
struct efx_nic_type  const  falcon_b0_nic_type  = 
     {0, 2U, & falcon_b0_mem_map_size, & falcon_probe_nic, & falcon_remove_nic, & falcon_init_nic,
    & falcon_dimension_resources, & efx_port_dummy_op_void, & falcon_monitor, & falcon_map_reset_reason,
    & falcon_map_reset_flags, & falcon_reset_hw, & falcon_probe_port, & falcon_remove_port,
    & falcon_handle_global_event, & efx_farch_fini_dmaq, & falcon_prepare_flush, & efx_port_dummy_op_void,
    & efx_port_dummy_op_void, & efx_farch_finish_flr, & falcon_describe_nic_stats,
    & falcon_update_nic_stats, & falcon_start_nic_stats, & falcon_pull_nic_stats,
    & falcon_stop_nic_stats, & falcon_set_id_led, & falcon_push_irq_moderation, & falcon_reconfigure_port,
    & falcon_b0_prepare_enable_fc_tx, & falcon_reconfigure_xmac, & falcon_xmac_check_fault,
    & falcon_get_wol, & falcon_set_wol, & efx_port_dummy_op_void, & falcon_b0_test_chip,
    & falcon_test_nvram, 0, 0, 0, 0, & efx_farch_irq_enable_master, & efx_farch_irq_test_generate,
    & efx_farch_irq_disable_master, & efx_farch_msi_interrupt, & efx_farch_legacy_interrupt,
    & efx_farch_tx_probe, & efx_farch_tx_init, & efx_farch_tx_remove, & efx_farch_tx_write,
    & falcon_b0_rx_push_rss_config, & efx_farch_rx_probe, & efx_farch_rx_init, & efx_farch_rx_remove,
    & efx_farch_rx_write, & efx_farch_rx_defer_refill, & efx_farch_ev_probe, & efx_farch_ev_init,
    & efx_farch_ev_fini, & efx_farch_ev_remove, & efx_farch_ev_process, & efx_farch_ev_read_ack,
    & efx_farch_ev_test_generate, & efx_farch_filter_table_probe, & efx_farch_filter_table_restore,
    & efx_farch_filter_table_remove, & efx_farch_filter_update_rx_scatter, & efx_farch_filter_insert,
    & efx_farch_filter_remove_safe, & efx_farch_filter_get_safe, & efx_farch_filter_clear_rx,
    & efx_farch_filter_count_rx_used, & efx_farch_filter_get_rx_id_limit, & efx_farch_filter_get_rx_ids,
    & efx_farch_filter_rfs_insert, & efx_farch_filter_rfs_expire_one, & falcon_mtd_probe,
    & falcon_mtd_rename, & falcon_mtd_read, & falcon_mtd_erase, & falcon_mtd_write,
    & falcon_mtd_sync, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    2, 16056320U, 15990784U, 8388608U, 16121856U, 16384000U, 70368744177663ULL, 16U,
    12U, 0U, 0U, 1, (_Bool)0, 0U, 4096U, 12884901890ULL, -1, 8192U, 0U};
void ldv_initialize_efx_nic_type_29(void) 
{ 
  void *tmp ;
  void *tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  void *tmp___4 ;

  {
  tmp = ldv_init_zalloc(288UL);
  falcon_a1_nic_type_group0 = (struct efx_rx_queue *)tmp;
  tmp___0 = ldv_init_zalloc(2176UL);
  falcon_a1_nic_type_group2 = (struct efx_channel *)tmp___0;
  tmp___1 = ldv_init_zalloc(1824UL);
  falcon_a1_nic_type_group3 = (struct mtd_info *)tmp___1;
  tmp___2 = ldv_init_zalloc(320UL);
  falcon_a1_nic_type_group4 = (struct efx_tx_queue *)tmp___2;
  tmp___3 = ldv_init_zalloc(4032UL);
  falcon_a1_nic_type_group1 = (struct efx_nic *)tmp___3;
  tmp___4 = ldv_init_zalloc(64UL);
  falcon_a1_nic_type_group5 = (struct efx_filter_spec *)tmp___4;
  return;
}
}
void timer_init_12(void) 
{ 


  {
  ldv_timer_12_0 = 0;
  ldv_timer_12_1 = 0;
  ldv_timer_12_2 = 0;
  ldv_timer_12_3 = 0;
  return;
}
}
int reg_timer_12(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) 
{ 


  {
  if ((unsigned long )function == (unsigned long )(& falcon_stats_timer_func)) {
    activate_suitable_timer_12(timer, data);
  } else {

  }
  return (0);
}
}
void choose_timer_12(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_12_0 == 1) {
    ldv_timer_12_0 = 2;
    ldv_timer_12(ldv_timer_12_0, ldv_timer_list_12_0);
  } else {

  }
  goto ldv_57388;
  case 1: ;
  if (ldv_timer_12_1 == 1) {
    ldv_timer_12_1 = 2;
    ldv_timer_12(ldv_timer_12_1, ldv_timer_list_12_1);
  } else {

  }
  goto ldv_57388;
  case 2: ;
  if (ldv_timer_12_2 == 1) {
    ldv_timer_12_2 = 2;
    ldv_timer_12(ldv_timer_12_2, ldv_timer_list_12_2);
  } else {

  }
  goto ldv_57388;
  case 3: ;
  if (ldv_timer_12_3 == 1) {
    ldv_timer_12_3 = 2;
    ldv_timer_12(ldv_timer_12_3, ldv_timer_list_12_3);
  } else {

  }
  goto ldv_57388;
  default: 
  ldv_stop();
  }
  ldv_57388: ;
  return;
}
}
void ldv_initialize_efx_nic_type_28(void) 
{ 
  void *tmp ;
  void *tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  void *tmp___4 ;

  {
  tmp = ldv_init_zalloc(288UL);
  falcon_b0_nic_type_group0 = (struct efx_rx_queue *)tmp;
  tmp___0 = ldv_init_zalloc(2176UL);
  falcon_b0_nic_type_group2 = (struct efx_channel *)tmp___0;
  tmp___1 = ldv_init_zalloc(1824UL);
  falcon_b0_nic_type_group3 = (struct mtd_info *)tmp___1;
  tmp___2 = ldv_init_zalloc(320UL);
  falcon_b0_nic_type_group4 = (struct efx_tx_queue *)tmp___2;
  tmp___3 = ldv_init_zalloc(4032UL);
  falcon_b0_nic_type_group1 = (struct efx_nic *)tmp___3;
  tmp___4 = ldv_init_zalloc(64UL);
  falcon_b0_nic_type_group5 = (struct efx_filter_spec *)tmp___4;
  return;
}
}
void disable_suitable_timer_12(struct timer_list *timer ) 
{ 


  {
  if (ldv_timer_12_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_12_0) {
    ldv_timer_12_0 = 0;
    return;
  } else {

  }
  if (ldv_timer_12_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_12_1) {
    ldv_timer_12_1 = 0;
    return;
  } else {

  }
  if (ldv_timer_12_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_12_2) {
    ldv_timer_12_2 = 0;
    return;
  } else {

  }
  if (ldv_timer_12_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_12_3) {
    ldv_timer_12_3 = 0;
    return;
  } else {

  }
  return;
}
}
void activate_pending_timer_12(struct timer_list *timer , unsigned long data , int pending_flag ) 
{ 


  {
  if ((unsigned long )ldv_timer_list_12_0 == (unsigned long )timer) {
    if (ldv_timer_12_0 == 2 || pending_flag != 0) {
      ldv_timer_list_12_0 = timer;
      ldv_timer_list_12_0->data = data;
      ldv_timer_12_0 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_12_1 == (unsigned long )timer) {
    if (ldv_timer_12_1 == 2 || pending_flag != 0) {
      ldv_timer_list_12_1 = timer;
      ldv_timer_list_12_1->data = data;
      ldv_timer_12_1 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_12_2 == (unsigned long )timer) {
    if (ldv_timer_12_2 == 2 || pending_flag != 0) {
      ldv_timer_list_12_2 = timer;
      ldv_timer_list_12_2->data = data;
      ldv_timer_12_2 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_12_3 == (unsigned long )timer) {
    if (ldv_timer_12_3 == 2 || pending_flag != 0) {
      ldv_timer_list_12_3 = timer;
      ldv_timer_list_12_3->data = data;
      ldv_timer_12_3 = 1;
    } else {

    }
    return;
  } else {

  }
  activate_suitable_timer_12(timer, data);
  return;
}
}
void ldv_timer_12(int state , struct timer_list *timer ) 
{ 


  {
  LDV_IN_INTERRUPT = 2;
  falcon_stats_timer_func(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void activate_suitable_timer_12(struct timer_list *timer , unsigned long data ) 
{ 


  {
  if (ldv_timer_12_0 == 0 || ldv_timer_12_0 == 2) {
    ldv_timer_list_12_0 = timer;
    ldv_timer_list_12_0->data = data;
    ldv_timer_12_0 = 1;
    return;
  } else {

  }
  if (ldv_timer_12_1 == 0 || ldv_timer_12_1 == 2) {
    ldv_timer_list_12_1 = timer;
    ldv_timer_list_12_1->data = data;
    ldv_timer_12_1 = 1;
    return;
  } else {

  }
  if (ldv_timer_12_2 == 0 || ldv_timer_12_2 == 2) {
    ldv_timer_list_12_2 = timer;
    ldv_timer_list_12_2->data = data;
    ldv_timer_12_2 = 1;
    return;
  } else {

  }
  if (ldv_timer_12_3 == 0 || ldv_timer_12_3 == 2) {
    ldv_timer_list_12_3 = timer;
    ldv_timer_list_12_3->data = data;
    ldv_timer_12_3 = 1;
    return;
  } else {

  }
  return;
}
}
void ldv_main_exported_28(void) 
{ 
  void *ldvarg117 ;
  void *tmp ;
  size_t ldvarg130 ;
  size_t *ldvarg92 ;
  void *tmp___0 ;
  u32 ldvarg108 ;
  u8 *ldvarg124 ;
  void *tmp___1 ;
  int ldvarg116 ;
    klee_make_symbolic(&ldvarg116, sizeof(int), "ldvarg116");
  u32 *ldvarg127 ;
  void *tmp___2 ;
  bool ldvarg99 ;
  u32 ldvarg96 ;
  size_t *ldvarg119 ;
  void *tmp___3 ;
  size_t ldvarg120 ;
  enum efx_filter_priority ldvarg113 ;
  enum efx_led_mode ldvarg112 ;
  struct rtnl_link_stats64 *ldvarg102 ;
  void *tmp___4 ;
  struct ethtool_wolinfo *ldvarg111 ;
  void *tmp___5 ;
  int ldvarg123 ;
    klee_make_symbolic(&ldvarg123, sizeof(int), "ldvarg123");
  enum reset_type ldvarg126 ;
  efx_qword_t *ldvarg128 ;
  void *tmp___6 ;
  u8 *ldvarg122 ;
  void *tmp___7 ;
  bool ldvarg104 ;
  loff_t ldvarg121 ;
  void *ldvarg107 ;
  void *tmp___8 ;
  enum reset_type ldvarg129 ;
  enum efx_filter_priority ldvarg110 ;
  size_t ldvarg93 ;
  struct efx_self_tests *ldvarg105 ;
  void *tmp___9 ;
  u8 *ldvarg95 ;
  void *tmp___10 ;
  u64 *ldvarg103 ;
  void *tmp___11 ;
  u32 ldvarg114 ;
  enum efx_filter_priority ldvarg125 ;
  enum efx_filter_priority ldvarg97 ;
  u32 *ldvarg98 ;
  void *tmp___12 ;
  u32 *ldvarg109 ;
  void *tmp___13 ;
  enum efx_filter_priority ldvarg115 ;
  u32 ldvarg118 ;
  unsigned int ldvarg100 ;
    klee_make_symbolic(&ldvarg100, sizeof(int), "ldvarg100");
  struct efx_mtd_partition *ldvarg91 ;
  void *tmp___14 ;
  loff_t ldvarg94 ;
  u32 ldvarg101 ;
  int ldvarg106 ;
    klee_make_symbolic(&ldvarg106, sizeof(int), "ldvarg106");
  loff_t ldvarg131 ;
  int tmp___15 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg117 = tmp;
  tmp___0 = ldv_init_zalloc(8UL);
  ldvarg92 = (size_t *)tmp___0;
  tmp___1 = ldv_init_zalloc(1UL);
  ldvarg124 = (u8 *)tmp___1;
  tmp___2 = ldv_init_zalloc(4UL);
  ldvarg127 = (u32 *)tmp___2;
  tmp___3 = ldv_init_zalloc(8UL);
  ldvarg119 = (size_t *)tmp___3;
  tmp___4 = ldv_init_zalloc(184UL);
  ldvarg102 = (struct rtnl_link_stats64 *)tmp___4;
  tmp___5 = ldv_init_zalloc(20UL);
  ldvarg111 = (struct ethtool_wolinfo *)tmp___5;
  tmp___6 = ldv_init_zalloc(8UL);
  ldvarg128 = (efx_qword_t *)tmp___6;
  tmp___7 = ldv_init_zalloc(1UL);
  ldvarg122 = (u8 *)tmp___7;
  tmp___8 = ldv_init_zalloc(1UL);
  ldvarg107 = tmp___8;
  tmp___9 = ldv_init_zalloc(1076UL);
  ldvarg105 = (struct efx_self_tests *)tmp___9;
  tmp___10 = ldv_init_zalloc(1UL);
  ldvarg95 = (u8 *)tmp___10;
  tmp___11 = ldv_init_zalloc(8UL);
  ldvarg103 = (u64 *)tmp___11;
  tmp___12 = ldv_init_zalloc(4UL);
  ldvarg98 = (u32 *)tmp___12;
  tmp___13 = ldv_init_zalloc(4UL);
  ldvarg109 = (u32 *)tmp___13;
  tmp___14 = ldv_init_zalloc(1896UL);
  ldvarg91 = (struct efx_mtd_partition *)tmp___14;
  ldv_memset((void *)(& ldvarg130), 0, 8UL);
  ldv_memset((void *)(& ldvarg108), 0, 4UL);
  ldv_memset((void *)(& ldvarg116), 0, 4UL);
  ldv_memset((void *)(& ldvarg99), 0, 1UL);
  ldv_memset((void *)(& ldvarg96), 0, 4UL);
  ldv_memset((void *)(& ldvarg120), 0, 8UL);
  ldv_memset((void *)(& ldvarg113), 0, 4UL);
  ldv_memset((void *)(& ldvarg112), 0, 4UL);
  ldv_memset((void *)(& ldvarg123), 0, 4UL);
  ldv_memset((void *)(& ldvarg126), 0, 4UL);
  ldv_memset((void *)(& ldvarg104), 0, 1UL);
  ldv_memset((void *)(& ldvarg121), 0, 8UL);
  ldv_memset((void *)(& ldvarg129), 0, 4UL);
  ldv_memset((void *)(& ldvarg110), 0, 4UL);
  ldv_memset((void *)(& ldvarg93), 0, 8UL);
  ldv_memset((void *)(& ldvarg114), 0, 4UL);
  ldv_memset((void *)(& ldvarg125), 0, 4UL);
  ldv_memset((void *)(& ldvarg97), 0, 4UL);
  ldv_memset((void *)(& ldvarg115), 0, 4UL);
  ldv_memset((void *)(& ldvarg118), 0, 4UL);
  ldv_memset((void *)(& ldvarg100), 0, 4UL);
  ldv_memset((void *)(& ldvarg94), 0, 8UL);
  ldv_memset((void *)(& ldvarg101), 0, 4UL);
  ldv_memset((void *)(& ldvarg106), 0, 4UL);
  ldv_memset((void *)(& ldvarg131), 0, 8UL);
  tmp___15 = __VERIFIER_nondet_int();
  switch (tmp___15) {
  case 0: ;
  if (ldv_state_variable_28 == 1) {
    efx_port_dummy_op_void(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 1: ;
  if (ldv_state_variable_28 == 1) {
    falcon_reconfigure_xmac(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 2: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_fini_dmaq(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 3: ;
  if (ldv_state_variable_28 == 1) {
    falcon_mtd_erase(falcon_b0_nic_type_group3, ldvarg131, ldvarg130);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 4: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_rx_init(falcon_b0_nic_type_group0);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 5: ;
  if (ldv_state_variable_28 == 1) {
    falcon_map_reset_reason(ldvarg129);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 6: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_ev_read_ack(falcon_b0_nic_type_group2);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 7: ;
  if (ldv_state_variable_28 == 1) {
    falcon_handle_global_event(falcon_b0_nic_type_group2, ldvarg128);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 8: ;
  if (ldv_state_variable_28 == 1) {
    falcon_map_reset_flags(ldvarg127);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 9: ;
  if (ldv_state_variable_28 == 1) {
    falcon_mtd_sync(falcon_b0_nic_type_group3);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 10: ;
  if (ldv_state_variable_28 == 1) {
    falcon_pull_nic_stats(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 11: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_rx_write(falcon_b0_nic_type_group0);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 12: ;
  if (ldv_state_variable_28 == 1) {
    falcon_probe_port(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 13: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_filter_table_remove(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 14: ;
  if (ldv_state_variable_28 == 1) {
    falcon_b0_mem_map_size(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 15: ;
  if (ldv_state_variable_28 == 1) {
    falcon_reset_hw(falcon_b0_nic_type_group1, ldvarg126);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 16: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_filter_rfs_insert(falcon_b0_nic_type_group1, falcon_b0_nic_type_group5);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 17: ;
  if (ldv_state_variable_28 == 1) {
    falcon_monitor(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 18: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_ev_probe(falcon_b0_nic_type_group2);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 19: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_filter_count_rx_used(falcon_b0_nic_type_group1, ldvarg125);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 20: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_tx_probe(falcon_b0_nic_type_group4);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 21: ;
  if (ldv_state_variable_28 == 1) {
    falcon_describe_nic_stats(falcon_b0_nic_type_group1, ldvarg124);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 22: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_filter_table_probe(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 23: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_irq_disable_master(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 24: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_ev_process(falcon_b0_nic_type_group2, ldvarg123);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 25: ;
  if (ldv_state_variable_28 == 1) {
    falcon_mtd_read(falcon_b0_nic_type_group3, ldvarg121, ldvarg120, ldvarg119, ldvarg122);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 26: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_rx_probe(falcon_b0_nic_type_group0);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 27: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_filter_table_restore(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 28: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_ev_remove(falcon_b0_nic_type_group2);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 29: ;
  if (ldv_state_variable_28 == 1) {
    falcon_set_wol(falcon_b0_nic_type_group1, ldvarg118);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 30: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_legacy_interrupt(ldvarg116, ldvarg117);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 31: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_filter_remove_safe(falcon_b0_nic_type_group1, ldvarg115, ldvarg114);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 32: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_filter_clear_rx(falcon_b0_nic_type_group1, ldvarg113);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 33: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_filter_get_rx_id_limit(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 34: ;
  if (ldv_state_variable_28 == 1) {
    falcon_set_id_led(falcon_b0_nic_type_group1, ldvarg112);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 35: ;
  if (ldv_state_variable_28 == 1) {
    falcon_get_wol(falcon_b0_nic_type_group1, ldvarg111);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 36: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_tx_remove(falcon_b0_nic_type_group4);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 37: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_rx_defer_refill(falcon_b0_nic_type_group0);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 38: ;
  if (ldv_state_variable_28 == 1) {
    falcon_remove_nic(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 39: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_irq_enable_master(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 40: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_filter_get_rx_ids(falcon_b0_nic_type_group1, ldvarg110, ldvarg109, ldvarg108);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 41: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_msi_interrupt(ldvarg106, ldvarg107);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 42: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_ev_fini(falcon_b0_nic_type_group2);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 43: ;
  if (ldv_state_variable_28 == 1) {
    falcon_mtd_probe(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 44: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_irq_test_generate(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 45: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_finish_flr(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 46: ;
  if (ldv_state_variable_28 == 1) {
    falcon_b0_test_chip(falcon_b0_nic_type_group1, ldvarg105);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 47: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_ev_init(falcon_b0_nic_type_group2);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 48: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_filter_insert(falcon_b0_nic_type_group1, falcon_b0_nic_type_group5,
                            (int )ldvarg104);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 49: ;
  if (ldv_state_variable_28 == 1) {
    falcon_update_nic_stats(falcon_b0_nic_type_group1, ldvarg103, ldvarg102);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 50: ;
  if (ldv_state_variable_28 == 1) {
    falcon_push_irq_moderation(falcon_b0_nic_type_group2);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 51: ;
  if (ldv_state_variable_28 == 1) {
    falcon_remove_port(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 52: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_rx_remove(falcon_b0_nic_type_group0);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 53: ;
  if (ldv_state_variable_28 == 1) {
    falcon_b0_prepare_enable_fc_tx(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 54: ;
  if (ldv_state_variable_28 == 1) {
    falcon_stop_nic_stats(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 55: ;
  if (ldv_state_variable_28 == 1) {
    falcon_probe_nic(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 56: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_filter_update_rx_scatter(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 57: ;
  if (ldv_state_variable_28 == 1) {
    falcon_xmac_check_fault(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 58: ;
  if (ldv_state_variable_28 == 1) {
    falcon_dimension_resources(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 59: ;
  if (ldv_state_variable_28 == 1) {
    falcon_start_nic_stats(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 60: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_tx_write(falcon_b0_nic_type_group4);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 61: ;
  if (ldv_state_variable_28 == 1) {
    efx_port_dummy_op_void(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 62: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_filter_rfs_expire_one(falcon_b0_nic_type_group1, ldvarg101, ldvarg100);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 63: ;
  if (ldv_state_variable_28 == 1) {
    efx_port_dummy_op_void(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 64: ;
  if (ldv_state_variable_28 == 1) {
    falcon_b0_rx_push_rss_config(falcon_b0_nic_type_group1, (int )ldvarg99, (u32 const   *)ldvarg98);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 65: ;
  if (ldv_state_variable_28 == 1) {
    efx_port_dummy_op_void(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 66: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_filter_get_safe(falcon_b0_nic_type_group1, ldvarg97, ldvarg96, falcon_b0_nic_type_group5);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 67: ;
  if (ldv_state_variable_28 == 1) {
    falcon_mtd_write(falcon_b0_nic_type_group3, ldvarg94, ldvarg93, ldvarg92, (u8 const   *)ldvarg95);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 68: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_tx_init(falcon_b0_nic_type_group4);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 69: ;
  if (ldv_state_variable_28 == 1) {
    falcon_test_nvram(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 70: ;
  if (ldv_state_variable_28 == 1) {
    efx_farch_ev_test_generate(falcon_b0_nic_type_group2);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 71: ;
  if (ldv_state_variable_28 == 1) {
    falcon_init_nic(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 72: ;
  if (ldv_state_variable_28 == 1) {
    falcon_mtd_rename(ldvarg91);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 73: ;
  if (ldv_state_variable_28 == 1) {
    falcon_reconfigure_port(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  case 74: ;
  if (ldv_state_variable_28 == 1) {
    falcon_prepare_flush(falcon_b0_nic_type_group1);
    ldv_state_variable_28 = 1;
  } else {

  }
  goto ldv_57457;
  default: 
  ldv_stop();
  }
  ldv_57457: ;
  return;
}
}
void ldv_main_exported_30(void) 
{ 
  void *ldvarg16 ;
  void *tmp ;
  int ldvarg19 ;
    klee_make_symbolic(&ldvarg19, sizeof(int), "ldvarg19");
  int ldvarg17 ;
    klee_make_symbolic(&ldvarg17, sizeof(int), "ldvarg17");
  void *ldvarg20 ;
  void *tmp___0 ;
  void *ldvarg18 ;
  void *tmp___1 ;
  void *ldvarg21 ;
  void *tmp___2 ;
  int tmp___3 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg16 = tmp;
  tmp___0 = ldv_init_zalloc(1UL);
  ldvarg20 = tmp___0;
  tmp___1 = ldv_init_zalloc(1UL);
  ldvarg18 = tmp___1;
  tmp___2 = ldv_init_zalloc(1UL);
  ldvarg21 = tmp___2;
  ldv_memset((void *)(& ldvarg19), 0, 4UL);
  ldv_memset((void *)(& ldvarg17), 0, 4UL);
  tmp___3 = __VERIFIER_nondet_int();
  switch (tmp___3) {
  case 0: ;
  if (ldv_state_variable_30 == 1) {
    falcon_getscl(ldvarg21);
    ldv_state_variable_30 = 1;
  } else {

  }
  goto ldv_57543;
  case 1: ;
  if (ldv_state_variable_30 == 1) {
    falcon_getsda(ldvarg20);
    ldv_state_variable_30 = 1;
  } else {

  }
  goto ldv_57543;
  case 2: ;
  if (ldv_state_variable_30 == 1) {
    falcon_setscl(ldvarg18, ldvarg19);
    ldv_state_variable_30 = 1;
  } else {

  }
  goto ldv_57543;
  case 3: ;
  if (ldv_state_variable_30 == 1) {
    falcon_setsda(ldvarg16, ldvarg17);
    ldv_state_variable_30 = 1;
  } else {

  }
  goto ldv_57543;
  default: 
  ldv_stop();
  }
  ldv_57543: ;
  return;
}
}
void ldv_main_exported_29(void) 
{ 
  int ldvarg294 ;
    klee_make_symbolic(&ldvarg294, sizeof(int), "ldvarg294");
  size_t ldvarg298 ;
  u32 ldvarg292 ;
  u32 *ldvarg279 ;
  void *tmp ;
  size_t *ldvarg273 ;
  void *tmp___0 ;
  u64 *ldvarg283 ;
  void *tmp___1 ;
  size_t *ldvarg297 ;
  void *tmp___2 ;
  u8 *ldvarg276 ;
  void *tmp___3 ;
  enum efx_filter_priority ldvarg286 ;
  int ldvarg287 ;
    klee_make_symbolic(&ldvarg287, sizeof(int), "ldvarg287");
  int ldvarg301 ;
    klee_make_symbolic(&ldvarg301, sizeof(int), "ldvarg301");
  struct rtnl_link_stats64 *ldvarg282 ;
  void *tmp___4 ;
  efx_qword_t *ldvarg306 ;
  void *tmp___5 ;
  struct ethtool_wolinfo *ldvarg289 ;
  void *tmp___6 ;
  enum efx_filter_priority ldvarg291 ;
  void *ldvarg288 ;
  void *tmp___7 ;
  u32 ldvarg277 ;
  loff_t ldvarg275 ;
  enum efx_filter_priority ldvarg293 ;
  struct efx_mtd_partition *ldvarg272 ;
  void *tmp___8 ;
  size_t ldvarg274 ;
  enum reset_type ldvarg304 ;
  bool ldvarg280 ;
  u32 ldvarg284 ;
  u8 *ldvarg302 ;
  void *tmp___9 ;
  enum efx_filter_priority ldvarg303 ;
  bool ldvarg281 ;
  u32 ldvarg296 ;
  void *ldvarg295 ;
  void *tmp___10 ;
  u8 *ldvarg300 ;
  void *tmp___11 ;
  u32 *ldvarg285 ;
  void *tmp___12 ;
  loff_t ldvarg309 ;
  enum efx_filter_priority ldvarg278 ;
  loff_t ldvarg299 ;
  enum reset_type ldvarg307 ;
  u32 *ldvarg305 ;
  void *tmp___13 ;
  size_t ldvarg308 ;
  enum efx_led_mode ldvarg290 ;
  int tmp___14 ;

  {
  tmp = ldv_init_zalloc(4UL);
  ldvarg279 = (u32 *)tmp;
  tmp___0 = ldv_init_zalloc(8UL);
  ldvarg273 = (size_t *)tmp___0;
  tmp___1 = ldv_init_zalloc(8UL);
  ldvarg283 = (u64 *)tmp___1;
  tmp___2 = ldv_init_zalloc(8UL);
  ldvarg297 = (size_t *)tmp___2;
  tmp___3 = ldv_init_zalloc(1UL);
  ldvarg276 = (u8 *)tmp___3;
  tmp___4 = ldv_init_zalloc(184UL);
  ldvarg282 = (struct rtnl_link_stats64 *)tmp___4;
  tmp___5 = ldv_init_zalloc(8UL);
  ldvarg306 = (efx_qword_t *)tmp___5;
  tmp___6 = ldv_init_zalloc(20UL);
  ldvarg289 = (struct ethtool_wolinfo *)tmp___6;
  tmp___7 = ldv_init_zalloc(1UL);
  ldvarg288 = tmp___7;
  tmp___8 = ldv_init_zalloc(1896UL);
  ldvarg272 = (struct efx_mtd_partition *)tmp___8;
  tmp___9 = ldv_init_zalloc(1UL);
  ldvarg302 = (u8 *)tmp___9;
  tmp___10 = ldv_init_zalloc(1UL);
  ldvarg295 = tmp___10;
  tmp___11 = ldv_init_zalloc(1UL);
  ldvarg300 = (u8 *)tmp___11;
  tmp___12 = ldv_init_zalloc(4UL);
  ldvarg285 = (u32 *)tmp___12;
  tmp___13 = ldv_init_zalloc(4UL);
  ldvarg305 = (u32 *)tmp___13;
  ldv_memset((void *)(& ldvarg294), 0, 4UL);
  ldv_memset((void *)(& ldvarg298), 0, 8UL);
  ldv_memset((void *)(& ldvarg292), 0, 4UL);
  ldv_memset((void *)(& ldvarg286), 0, 4UL);
  ldv_memset((void *)(& ldvarg287), 0, 4UL);
  ldv_memset((void *)(& ldvarg301), 0, 4UL);
  ldv_memset((void *)(& ldvarg291), 0, 4UL);
  ldv_memset((void *)(& ldvarg277), 0, 4UL);
  ldv_memset((void *)(& ldvarg275), 0, 8UL);
  ldv_memset((void *)(& ldvarg293), 0, 4UL);
  ldv_memset((void *)(& ldvarg274), 0, 8UL);
  ldv_memset((void *)(& ldvarg304), 0, 4UL);
  ldv_memset((void *)(& ldvarg280), 0, 1UL);
  ldv_memset((void *)(& ldvarg284), 0, 4UL);
  ldv_memset((void *)(& ldvarg303), 0, 4UL);
  ldv_memset((void *)(& ldvarg281), 0, 1UL);
  ldv_memset((void *)(& ldvarg296), 0, 4UL);
  ldv_memset((void *)(& ldvarg309), 0, 8UL);
  ldv_memset((void *)(& ldvarg278), 0, 4UL);
  ldv_memset((void *)(& ldvarg299), 0, 8UL);
  ldv_memset((void *)(& ldvarg307), 0, 4UL);
  ldv_memset((void *)(& ldvarg308), 0, 8UL);
  ldv_memset((void *)(& ldvarg290), 0, 4UL);
  tmp___14 = __VERIFIER_nondet_int();
  switch (tmp___14) {
  case 0: ;
  if (ldv_state_variable_29 == 1) {
    efx_port_dummy_op_void(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 1: ;
  if (ldv_state_variable_29 == 1) {
    falcon_reconfigure_xmac(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 2: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_fini_dmaq(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 3: ;
  if (ldv_state_variable_29 == 1) {
    falcon_mtd_erase(falcon_a1_nic_type_group3, ldvarg309, ldvarg308);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 4: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_rx_init(falcon_a1_nic_type_group0);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 5: ;
  if (ldv_state_variable_29 == 1) {
    falcon_map_reset_reason(ldvarg307);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 6: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_ev_read_ack(falcon_a1_nic_type_group2);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 7: ;
  if (ldv_state_variable_29 == 1) {
    falcon_handle_global_event(falcon_a1_nic_type_group2, ldvarg306);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 8: ;
  if (ldv_state_variable_29 == 1) {
    falcon_map_reset_flags(ldvarg305);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 9: ;
  if (ldv_state_variable_29 == 1) {
    falcon_pull_nic_stats(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 10: ;
  if (ldv_state_variable_29 == 1) {
    falcon_mtd_sync(falcon_a1_nic_type_group3);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 11: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_rx_write(falcon_a1_nic_type_group0);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 12: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_filter_table_remove(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 13: ;
  if (ldv_state_variable_29 == 1) {
    falcon_probe_port(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 14: ;
  if (ldv_state_variable_29 == 1) {
    falcon_a1_mem_map_size(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 15: ;
  if (ldv_state_variable_29 == 1) {
    falcon_reset_hw(falcon_a1_nic_type_group1, ldvarg304);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 16: ;
  if (ldv_state_variable_29 == 1) {
    falcon_monitor(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 17: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_ev_probe(falcon_a1_nic_type_group2);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 18: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_filter_count_rx_used(falcon_a1_nic_type_group1, ldvarg303);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 19: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_tx_probe(falcon_a1_nic_type_group4);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 20: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_filter_table_probe(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 21: ;
  if (ldv_state_variable_29 == 1) {
    falcon_describe_nic_stats(falcon_a1_nic_type_group1, ldvarg302);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 22: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_irq_disable_master(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 23: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_ev_process(falcon_a1_nic_type_group2, ldvarg301);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 24: ;
  if (ldv_state_variable_29 == 1) {
    falcon_mtd_read(falcon_a1_nic_type_group3, ldvarg299, ldvarg298, ldvarg297, ldvarg300);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 25: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_rx_probe(falcon_a1_nic_type_group0);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 26: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_filter_table_restore(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 27: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_ev_remove(falcon_a1_nic_type_group2);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 28: ;
  if (ldv_state_variable_29 == 1) {
    falcon_set_wol(falcon_a1_nic_type_group1, ldvarg296);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 29: ;
  if (ldv_state_variable_29 == 1) {
    falcon_legacy_interrupt_a1(ldvarg294, ldvarg295);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 30: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_filter_remove_safe(falcon_a1_nic_type_group1, ldvarg293, ldvarg292);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 31: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_filter_clear_rx(falcon_a1_nic_type_group1, ldvarg291);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 32: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_filter_get_rx_id_limit(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 33: ;
  if (ldv_state_variable_29 == 1) {
    falcon_set_id_led(falcon_a1_nic_type_group1, ldvarg290);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 34: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_tx_remove(falcon_a1_nic_type_group4);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 35: ;
  if (ldv_state_variable_29 == 1) {
    falcon_get_wol(falcon_a1_nic_type_group1, ldvarg289);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 36: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_rx_defer_refill(falcon_a1_nic_type_group0);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 37: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_irq_enable_master(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 38: ;
  if (ldv_state_variable_29 == 1) {
    falcon_remove_nic(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 39: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_msi_interrupt(ldvarg287, ldvarg288);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 40: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_filter_get_rx_ids(falcon_a1_nic_type_group1, ldvarg286, ldvarg285, ldvarg284);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 41: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_ev_fini(falcon_a1_nic_type_group2);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 42: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_irq_test_generate(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 43: ;
  if (ldv_state_variable_29 == 1) {
    falcon_mtd_probe(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 44: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_finish_flr(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 45: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_ev_init(falcon_a1_nic_type_group2);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 46: ;
  if (ldv_state_variable_29 == 1) {
    falcon_update_nic_stats(falcon_a1_nic_type_group1, ldvarg283, ldvarg282);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 47: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_filter_insert(falcon_a1_nic_type_group1, falcon_a1_nic_type_group5,
                            (int )ldvarg281);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 48: ;
  if (ldv_state_variable_29 == 1) {
    falcon_push_irq_moderation(falcon_a1_nic_type_group2);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 49: ;
  if (ldv_state_variable_29 == 1) {
    falcon_remove_port(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 50: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_rx_remove(falcon_a1_nic_type_group0);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 51: ;
  if (ldv_state_variable_29 == 1) {
    falcon_a1_prepare_enable_fc_tx(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 52: ;
  if (ldv_state_variable_29 == 1) {
    falcon_stop_nic_stats(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 53: ;
  if (ldv_state_variable_29 == 1) {
    falcon_probe_nic(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 54: ;
  if (ldv_state_variable_29 == 1) {
    falcon_xmac_check_fault(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 55: ;
  if (ldv_state_variable_29 == 1) {
    falcon_dimension_resources(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 56: ;
  if (ldv_state_variable_29 == 1) {
    falcon_start_nic_stats(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 57: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_tx_write(falcon_a1_nic_type_group4);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 58: ;
  if (ldv_state_variable_29 == 1) {
    falcon_irq_ack_a1(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 59: ;
  if (ldv_state_variable_29 == 1) {
    efx_port_dummy_op_void(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 60: ;
  if (ldv_state_variable_29 == 1) {
    dummy_rx_push_rss_config(falcon_a1_nic_type_group1, (int )ldvarg280, (u32 const   *)ldvarg279);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 61: ;
  if (ldv_state_variable_29 == 1) {
    efx_port_dummy_op_void(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 62: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_filter_get_safe(falcon_a1_nic_type_group1, ldvarg278, ldvarg277, falcon_a1_nic_type_group5);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 63: ;
  if (ldv_state_variable_29 == 1) {
    falcon_mtd_write(falcon_a1_nic_type_group3, ldvarg275, ldvarg274, ldvarg273, (u8 const   *)ldvarg276);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 64: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_tx_init(falcon_a1_nic_type_group4);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 65: ;
  if (ldv_state_variable_29 == 1) {
    falcon_test_nvram(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 66: ;
  if (ldv_state_variable_29 == 1) {
    efx_farch_ev_test_generate(falcon_a1_nic_type_group2);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 67: ;
  if (ldv_state_variable_29 == 1) {
    falcon_init_nic(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 68: ;
  if (ldv_state_variable_29 == 1) {
    falcon_mtd_rename(ldvarg272);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 69: ;
  if (ldv_state_variable_29 == 1) {
    falcon_reconfigure_port(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  case 70: ;
  if (ldv_state_variable_29 == 1) {
    falcon_prepare_flush(falcon_a1_nic_type_group1);
    ldv_state_variable_29 = 1;
  } else {

  }
  goto ldv_57590;
  default: 
  ldv_stop();
  }
  ldv_57590: ;
  return;
}
}
bool ldv_queue_work_on_157(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_158(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_159(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_160(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_161(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_162(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_163(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_164(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_165(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_166(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_167(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_168(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_lock_interruptible_169(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_lock_interruptible(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_lock_interruptible_spi_lock_of_falcon_nic_data(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_170(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_spi_lock_of_falcon_nic_data(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_lock_interruptible_171(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_lock_interruptible(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_lock_interruptible_spi_lock_of_falcon_nic_data(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_172(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_spi_lock_of_falcon_nic_data(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_lock_interruptible_173(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___11 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_lock_interruptible(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_lock_interruptible_spi_lock_of_falcon_nic_data(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_174(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_spi_lock_of_falcon_nic_data(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_175(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_spi_lock_of_falcon_nic_data(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_176(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_spi_lock_of_falcon_nic_data(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
__inline static int ldv_mutex_is_locked_177(struct mutex *lock ) 
{ 
  ldv_func_ret_type___12 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_is_locked(lock);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_is_locked_mac_lock_of_efx_nic(lock);
  return (tmp___0);
  return (ldv_func_res);
}
}
int ldv_mod_timer_178(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___8 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_10(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
__inline static int ldv_mutex_is_locked_179(struct mutex *lock ) 
{ 
  ldv_func_ret_type___13 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_is_locked(lock);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_is_locked_mac_lock_of_efx_nic(lock);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_180(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mdio_lock_of_falcon_nic_data(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_181(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mdio_lock_of_falcon_nic_data(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_182(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mdio_lock_of_falcon_nic_data(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_183(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mdio_lock_of_falcon_nic_data(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_184(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_spi_lock_of_falcon_nic_data(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_185(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_spi_lock_of_falcon_nic_data(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_186(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_187(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_188(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_spi_lock_of_falcon_nic_data(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_189(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_spi_lock_of_falcon_nic_data(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
int ldv_del_timer_sync_190(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___10 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_10(ldv_func_arg1);
  return (ldv_func_res);
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
__inline static unsigned int __arch_hweight32(unsigned int w ) 
{ 
  unsigned int res ;
    klee_make_symbolic(&res, sizeof(int), "res");

  {
  res = 0U;
  __asm__  ("661:\n\tcall __sw_hweight32\n662:\n.skip -(((6651f-6641f)-(662b-661b)) > 0) * ((6651f-6641f)-(662b-661b)),0x90\n663:\n.pushsection .altinstructions,\"a\"\n .long 661b - .\n .long 6641f - .\n .word ( 4*32+23)\n .byte 663b-661b\n .byte 6651f-6641f\n .byte 663b-662b\n.popsection\n.pushsection .altinstr_replacement, \"ax\"\n6641:\n\t.byte 0xf3,0x40,0x0f,0xb8,0xc7\n6651:\n\t.popsection": "=a" (res): "D" (w));
  return (res);
}
}
__inline static int ldv_mutex_is_locked_241(struct mutex *lock ) ;
int ldv_mutex_trylock_237(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_235(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_238(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_239(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_234(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_236(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_240(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_229(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_231(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_230(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_233(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_232(struct workqueue_struct *ldv_func_arg1 ) ;
extern int pci_wake_from_d3(struct pci_dev * , bool  ) ;
__inline static unsigned int efx_port_num(struct efx_nic *efx ) 
{ 


  {
  return (efx->port_num);
}
}
int efx_mcdi_init(struct efx_nic *efx ) ;
void efx_mcdi_fini(struct efx_nic *efx ) ;
int efx_mcdi_rpc(struct efx_nic *efx , unsigned int cmd , efx_dword_t const   *inbuf ,
                 size_t inlen , efx_dword_t *outbuf , size_t outlen , size_t *outlen_actual ) ;
int efx_mcdi_get_board_cfg(struct efx_nic *efx , u8 *mac_address , u16 *fw_subtype_list ,
                           u32 *capabilities ) ;
int efx_mcdi_log_ctrl(struct efx_nic *efx , bool evq , bool uart , u32 dest_evq ) ;
int efx_mcdi_nvram_types(struct efx_nic *efx , u32 *nvram_types_out ) ;
int efx_mcdi_nvram_info(struct efx_nic *efx , unsigned int type , size_t *size_out ,
                        size_t *erase_size_out , bool *protected_out ) ;
int efx_mcdi_nvram_test_all(struct efx_nic *efx ) ;
int efx_mcdi_handle_assertion(struct efx_nic *efx ) ;
void efx_mcdi_set_id_led(struct efx_nic *efx , enum efx_led_mode mode ) ;
int efx_mcdi_wol_filter_set_magic(struct efx_nic *efx , u8 const   *mac , int *id_out ) ;
int efx_mcdi_wol_filter_get_magic(struct efx_nic *efx , int *id_out ) ;
int efx_mcdi_wol_filter_remove(struct efx_nic *efx , int id ) ;
int efx_mcdi_wol_filter_reset(struct efx_nic *efx ) ;
int efx_mcdi_port_probe(struct efx_nic *efx ) ;
void efx_mcdi_port_remove(struct efx_nic *efx ) ;
int efx_mcdi_port_reconfigure(struct efx_nic *efx ) ;
int efx_mcdi_set_mac(struct efx_nic *efx ) ;
void efx_mcdi_mac_start_stats(struct efx_nic *efx ) ;
void efx_mcdi_mac_stop_stats(struct efx_nic *efx ) ;
void efx_mcdi_mac_pull_stats(struct efx_nic *efx ) ;
bool efx_mcdi_mac_check_fault(struct efx_nic *efx ) ;
enum reset_type efx_mcdi_map_reset_reason(enum reset_type reason ) ;
int efx_mcdi_reset(struct efx_nic *efx , enum reset_type method ) ;
int efx_mcdi_mon_probe(struct efx_nic *efx ) ;
void efx_mcdi_mon_remove(struct efx_nic *efx ) ;
int efx_mcdi_mtd_read(struct mtd_info *mtd , loff_t start , size_t len , size_t *retlen ,
                      u8 *buffer ) ;
int efx_mcdi_mtd_erase(struct mtd_info *mtd , loff_t start , size_t len ) ;
int efx_mcdi_mtd_write(struct mtd_info *mtd , loff_t start , size_t len , size_t *retlen ,
                       u8 const   *buffer ) ;
int efx_mcdi_mtd_sync(struct mtd_info *mtd ) ;
void efx_mcdi_mtd_rename(struct efx_mtd_partition *part ) ;
void efx_ptp_defer_probe_with_channel(struct efx_nic *efx ) ;
int efx_ptp_get_mode(struct efx_nic *efx ) ;
int efx_ptp_change_mode(struct efx_nic *efx , bool enable_wanted , unsigned int new_mode ) ;
void siena_prepare_flush(struct efx_nic *efx ) ;
void siena_finish_flush(struct efx_nic *efx ) ;
int efx_siena_sriov_configure(struct efx_nic *efx , int num_vfs ) ;
int efx_siena_sriov_init(struct efx_nic *efx ) ;
void efx_siena_sriov_fini(struct efx_nic *efx ) ;
int efx_siena_sriov_mac_address_changed(struct efx_nic *efx ) ;
bool efx_siena_sriov_wanted(struct efx_nic *efx ) ;
void efx_siena_sriov_reset(struct efx_nic *efx ) ;
void efx_siena_sriov_flr(struct efx_nic *efx , unsigned int vf_i ) ;
int efx_siena_sriov_set_vf_mac(struct efx_nic *efx , int vf_i , u8 *mac ) ;
int efx_siena_sriov_set_vf_vlan(struct efx_nic *efx , int vf_i , u16 vlan , u8 qos ) ;
int efx_siena_sriov_set_vf_spoofchk(struct efx_nic *efx , int vf_i , bool spoofchk ) ;
int efx_siena_sriov_get_vf_config(struct efx_nic *efx , int vf_i , struct ifla_vf_info *ivi ) ;
void efx_siena_sriov_probe(struct efx_nic *efx ) ;
static void siena_init_wol(struct efx_nic *efx ) ;
static void siena_push_irq_moderation(struct efx_channel *channel ) 
{ 
  efx_dword_t timer_cmd ;

  {
  if (channel->irq_moderation != 0U) {
    timer_cmd.u32[0] = (channel->irq_moderation - 1U) | 49152U;
  } else {
    timer_cmd.u32[0] = 0U;
  }
  _efx_writed_page_locked(channel->efx, (efx_dword_t const   *)(& timer_cmd), 1056U,
                          (unsigned int )channel->channel);
  return;
}
}
void siena_prepare_flush(struct efx_nic *efx ) 
{ 
  unsigned int tmp ;

  {
  tmp = efx->fc_disable;
  efx->fc_disable = efx->fc_disable + 1U;
  if (tmp == 0U) {
    efx_mcdi_set_mac(efx);
  } else {

  }
  return;
}
}
void siena_finish_flush(struct efx_nic *efx ) 
{ 


  {
  efx->fc_disable = efx->fc_disable - 1U;
  if (efx->fc_disable == 0U) {
    efx_mcdi_set_mac(efx);
  } else {

  }
  return;
}
}
static struct efx_farch_register_test  const  siena_register_tests[13U]  = 
  {      {0U, {.u32 = {262143U, 262143U, 262143U, 262143U}}}, 
        {256U, {.u32 = {66559U, 0U, 0U, 0U}}}, 
        {2048U, {.u32 = {4294967294U, 4294967295U, 262143U, 0U}}}, 
        {2640U, {.u32 = {2147418167U, 4294934528U, 4294967295U, 67108863U}}}, 
        {2688U, {.u32 = {4294901376U, 536870911U, 33554686U, 8388607U}}}, 
        {1568U, {.u32 = {2097151U, 0U, 0U, 0U}}}, 
        {2112U, {.u32 = {3U, 0U, 0U, 0U}}}, 
        {2128U, {.u32 = {1023U, 0U, 0U, 0U}}}, 
        {592U, {.u32 = {4095U, 0U, 0U, 0U}}}, 
        {2144U, {.u32 = {4294967295U, 4294967295U, 4294967295U, 4294967295U}}}, 
        {2256U, {.u32 = {4294967295U, 4294967295U, 4294967295U, 4294967295U}}}, 
        {2272U, {.u32 = {4294967295U, 4294967295U, 4294967295U, 4294967295U}}}, 
        {2288U, {.u32 = {4294967295U, 4294967295U, 7U, 0U}}}};
static int siena_test_chip(struct efx_nic *efx , struct efx_self_tests *tests ) 
{ 
  enum reset_type reset_method ;
  int rc ;
  int rc2 ;
  int tmp ;

  {
  reset_method = 2;
  efx_reset_down(efx, reset_method);
  rc = efx_mcdi_reset(efx, reset_method);
  if (rc != 0) {
    goto out;
  } else {

  }
  tmp = efx_farch_test_registers(efx, (struct efx_farch_register_test  const  *)(& siena_register_tests),
                                 13UL);
  tests->registers = tmp != 0 ? -1 : 1;
  rc = efx_mcdi_reset(efx, reset_method);
  out: 
  rc2 = efx_reset_up(efx, reset_method, rc == 0);
  return (rc != 0 ? rc : rc2);
}
}
static void siena_ptp_write_host_time(struct efx_nic *efx , u32 host_time ) 
{ 


  {
  _efx_writed(efx, host_time, 16713712U);
  return;
}
}
static int siena_ptp_set_ts_config(struct efx_nic *efx , struct hwtstamp_config *init ) 
{ 
  int rc ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
  switch (init->rx_filter) {
  case 0: 
  tmp = efx_ptp_get_mode(efx);
  tmp___0 = efx_ptp_change_mode(efx, init->tx_type != 0, (unsigned int )tmp);
  return (tmp___0);
  case 3: ;
  case 4: ;
  case 5: 
  init->rx_filter = 3;
  tmp___1 = efx_ptp_change_mode(efx, 1, 0U);
  return (tmp___1);
  case 6: ;
  case 7: ;
  case 8: 
  init->rx_filter = 6;
  rc = efx_ptp_change_mode(efx, 1, 4U);
  if (rc != 0) {
    rc = efx_ptp_change_mode(efx, 1, 2U);
  } else {

  }
  return (rc);
  default: ;
  return (-34);
  }
}
}
static int siena_map_reset_flags(u32 *flags ) 
{ 


  {
  if ((*flags & 65660U) == 65660U) {
    *flags = *flags & 4294901635U;
    return (3);
  } else {

  }
  if ((*flags & 124U) == 124U) {
    *flags = *flags & 4294967171U;
    return (2);
  } else {

  }
  return (-22);
}
}
static int siena_probe_nvconfig(struct efx_nic *efx ) 
{ 
  u32 caps ;
  int rc ;

  {
  caps = 0U;
  rc = efx_mcdi_get_board_cfg(efx, (u8 *)(& (efx->net_dev)->perm_addr), (u16 *)0U,
                              & caps);
  efx->timer_quantum_ns = (caps & 4U) != 0U ? 3072U : 6144U;
  return (rc);
}
}
static int siena_dimension_resources(struct efx_nic *efx ) 
{ 


  {
  efx_farch_dimension_resources(efx, 73728U);
  return (0);
}
}
static unsigned int siena_mem_map_size(struct efx_nic *efx ) 
{ 


  {
  return (16713728U);
}
}
static int siena_probe_nic(struct efx_nic *efx ) 
{ 
  struct siena_nic_data *nic_data ;
  efx_oword_t reg ;
  int rc ;
  void *tmp ;
  u32 tmp___0 ;
  long tmp___1 ;
  struct _ddebug descriptor ;
  phys_addr_t tmp___2 ;
  long tmp___3 ;

  {
  tmp = kzalloc(808UL, 208U);
  nic_data = (struct siena_nic_data *)tmp;
  if ((unsigned long )nic_data == (unsigned long )((struct siena_nic_data *)0)) {
    return (-12);
  } else {

  }
  nic_data->efx = efx;
  efx->nic_data = (void *)nic_data;
  tmp___0 = efx_farch_fpga_ver(efx);
  if (tmp___0 != 0U) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Siena FPGA not supported\n");
    } else {

    }
    rc = -19;
    goto fail1;
  } else {

  }
  efx->max_channels = 32U;
  efx_reado(efx, & reg, 624U);
  efx->port_num = ((unsigned int )(reg.u64[0] >> 40) & 3U) - 1U;
  rc = efx_mcdi_init(efx);
  if (rc != 0) {
    goto fail1;
  } else {

  }
  rc = efx_mcdi_reset(efx, 2);
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to reset NIC\n");
    } else {

    }
    goto fail3;
  } else {

  }
  siena_init_wol(efx);
  rc = efx_nic_alloc_buffer(efx, & efx->irq_status, 16U, 208U);
  if (rc != 0) {
    goto fail4;
  } else {

  }
  tmp___1 = ldv__builtin_expect((efx->irq_status.dma_addr & 15ULL) != 0ULL, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena.c"),
                         "i" (287), "i" (12UL));
    ldv_56496: ;
    goto ldv_56496;
  } else {

  }
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "siena_probe_nic";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena.c";
    descriptor.format = "INT_KER at %llx (virt %p phys %llx)\n";
    descriptor.lineno = 293U;
    descriptor.flags = 0U;
    tmp___3 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___3 != 0L) {
      tmp___2 = virt_to_phys((void volatile   *)efx->irq_status.addr);
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "INT_KER at %llx (virt %p phys %llx)\n", efx->irq_status.dma_addr,
                           efx->irq_status.addr, tmp___2);
    } else {

    }
  } else {

  }
  rc = siena_probe_nvconfig(efx);
  if (rc == -22) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "NVRAM is invalid therefore using defaults\n");
    } else {

    }
    efx->phy_type = 0U;
    efx->mdio.prtad = -1;
  } else
  if (rc != 0) {
    goto fail5;
  } else {

  }
  rc = efx_mcdi_mon_probe(efx);
  if (rc != 0) {
    goto fail5;
  } else {

  }
  efx_siena_sriov_probe(efx);
  efx_ptp_defer_probe_with_channel(efx);
  return (0);
  fail5: 
  efx_nic_free_buffer(efx, & efx->irq_status);
  fail4: ;
  fail3: 
  efx_mcdi_fini(efx);
  fail1: 
  kfree((void const   *)efx->nic_data);
  return (rc);
}
}
static int siena_rx_push_rss_config(struct efx_nic *efx , bool user , u32 const   *rx_indir_table ) 
{ 
  efx_oword_t temp ;

  {
  memcpy((void *)(& temp), (void const   *)(& efx->rx_hash_key), 16UL);
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 2144U);
  memcpy((void *)(& temp), (void const   *)(& efx->rx_hash_key), 16UL);
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 2256U);
  memcpy((void *)(& temp), (void const   *)(& efx->rx_hash_key) + 16U, 16UL);
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 2272U);
  temp.u64[0] = 0ULL;
  temp.u64[1] = 6ULL;
  memcpy((void *)(& temp), (void const   *)(& efx->rx_hash_key) + 32U, 8UL);
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 2288U);
  memcpy((void *)(& efx->rx_indir_table), (void const   *)rx_indir_table, 512UL);
  efx_farch_rx_push_indir_table(efx);
  return (0);
}
}
static int siena_init_nic(struct efx_nic *efx ) 
{ 
  efx_oword_t temp ;
  int rc ;

  {
  rc = efx_mcdi_handle_assertion(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  efx_reado(efx, & temp, 2688U);
  temp.u64[0] = temp.u64[0] | 128ULL;
  temp.u64[1] = temp.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 2688U);
  efx_reado(efx, & temp, 2640U);
  temp.u64[0] = temp.u64[0] & 0xffffffffffffffdfULL;
  temp.u64[1] = temp.u64[1];
  temp.u64[0] = temp.u64[0] | 140737488355328ULL;
  temp.u64[1] = temp.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 2640U);
  efx_reado(efx, & temp, 2048U);
  temp.u64[0] = temp.u64[0] & 0xfffff7ffffffffffULL;
  temp.u64[1] = temp.u64[1];
  temp.u64[0] = temp.u64[0] | 140737488355328ULL;
  temp.u64[1] = temp.u64[1];
  temp.u64[0] = temp.u64[0] | 17592186044416ULL;
  temp.u64[1] = temp.u64[1];
  temp.u64[0] = temp.u64[0] | 35184372088832ULL;
  temp.u64[1] = temp.u64[1];
  temp.u64[0] = temp.u64[0] | 70368744177664ULL;
  temp.u64[1] = temp.u64[1];
  temp.u64[0] = (temp.u64[0] & 0xfffffffff007ffffULL) | 29360128ULL;
  temp.u64[1] = temp.u64[1];
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 2048U);
  siena_rx_push_rss_config(efx, 0, (u32 const   *)(& efx->rx_indir_table));
  rc = efx_mcdi_log_ctrl(efx, 1, 0, 0U);
  if (rc != 0) {
    return (rc);
  } else {

  }
  temp.u64[0] = 0ULL;
  temp.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 592U);
  temp.u64[0] = 65536ULL;
  temp.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& temp), 256U);
  efx_farch_init_common(efx);
  return (0);
}
}
static void siena_remove_nic(struct efx_nic *efx ) 
{ 


  {
  efx_mcdi_mon_remove(efx);
  efx_nic_free_buffer(efx, & efx->irq_status);
  efx_mcdi_reset(efx, 2);
  efx_mcdi_fini(efx);
  kfree((void const   *)efx->nic_data);
  efx->nic_data = (void *)0;
  return;
}
}
static struct efx_hw_stat_desc  const  siena_stat_desc[59U]  = 
  {      {"rx_noskb_drops", 0U, 0U}, 
        {"rx_nodesc_trunc", 0U, 0U}, 
        {"tx_bytes", 64U, 56U}, 
        {"tx_good_bytes", 0U, 0U}, 
        {"tx_bad_bytes", 64U, 64U}, 
        {"tx_packets", 64U, 8U}, 
        {"tx_bad", 64U, 144U}, 
        {"tx_pause", 64U, 16U}, 
        {"tx_control", 64U, 24U}, 
        {"tx_unicast", 64U, 32U}, 
        {"tx_multicast", 64U, 40U}, 
        {"tx_broadcast", 64U, 48U}, 
        {"tx_lt64", 64U, 72U}, 
        {"tx_64", 64U, 80U}, 
        {"tx_65_to_127", 64U, 88U}, 
        {"tx_128_to_255", 64U, 96U}, 
        {"tx_256_to_511", 64U, 104U}, 
        {"tx_512_to_1023", 64U, 112U}, 
        {"tx_1024_to_15xx", 64U, 120U}, 
        {"tx_15xx_to_jumbo", 64U, 128U}, 
        {"tx_gtjumbo", 64U, 136U}, 
        {"tx_collision", 0U, 0U}, 
        {"tx_single_collision", 64U, 152U}, 
        {"tx_multiple_collision", 64U, 160U}, 
        {"tx_excessive_collision", 64U, 168U}, 
        {"tx_deferred", 64U, 184U}, 
        {"tx_late_collision", 64U, 176U}, 
        {"tx_excessive_deferred", 64U, 192U}, 
        {"tx_non_tcpudp", 64U, 200U}, 
        {"tx_mac_src_error", 64U, 208U}, 
        {"tx_ip_src_error", 64U, 216U}, 
        {"rx_bytes", 64U, 280U}, 
        {"rx_good_bytes", 0U, 0U}, 
        {"rx_bad_bytes", 64U, 288U}, 
        {"rx_packets", 64U, 224U}, 
        {"rx_good", 64U, 240U}, 
        {"rx_bad", 64U, 368U}, 
        {"rx_pause", 64U, 232U}, 
        {"rx_control", 64U, 248U}, 
        {"rx_unicast", 64U, 256U}, 
        {"rx_multicast", 64U, 264U}, 
        {"rx_broadcast", 64U, 272U}, 
        {"rx_lt64", 64U, 360U}, 
        {"rx_64", 64U, 296U}, 
        {"rx_65_to_127", 64U, 304U}, 
        {"rx_128_to_255", 64U, 312U}, 
        {"rx_256_to_511", 64U, 320U}, 
        {"rx_512_to_1023", 64U, 328U}, 
        {"rx_1024_to_15xx", 64U, 336U}, 
        {"rx_15xx_to_jumbo", 64U, 344U}, 
        {"rx_gtjumbo", 64U, 352U}, 
        {"rx_bad_gtjumbo", 64U, 424U}, 
        {"rx_overflow", 64U, 376U}, 
        {"rx_false_carrier", 64U, 384U}, 
        {"rx_symbol_error", 64U, 392U}, 
        {"rx_align_error", 64U, 400U}, 
        {"rx_length_error", 64U, 408U}, 
        {"rx_internal_error", 64U, 416U}, 
        {"rx_nodesc_drop_cnt", 64U, 432U}};
static unsigned long const   siena_stat_mask[1U]  = {      0xffffffffffffffffUL};
static size_t siena_describe_nic_stats(struct efx_nic *efx , u8 *names ) 
{ 
  size_t tmp ;

  {
  tmp = efx_nic_describe_stats((struct efx_hw_stat_desc  const  *)(& siena_stat_desc),
                               59UL, (unsigned long const   *)(& siena_stat_mask),
                               names);
  return (tmp);
}
}
static int siena_try_update_nic_stats(struct efx_nic *efx ) 
{ 
  struct siena_nic_data *nic_data ;
  u64 *stats ;
  __le64 *dma_stats ;
  __le64 generation_start ;
  __le64 generation_end ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  stats = (u64 *)(& nic_data->stats);
  dma_stats = (__le64 *)efx->stats_buffer.addr;
  generation_end = *(dma_stats + 96UL);
  if (generation_end == 0xffffffffffffffffULL) {
    return (0);
  } else {

  }
  __asm__  volatile   ("lfence": : : "memory");
  efx_nic_update_stats((struct efx_hw_stat_desc  const  *)(& siena_stat_desc), 59UL,
                       (unsigned long const   *)(& siena_stat_mask), stats, (void const   *)efx->stats_buffer.addr,
                       0);
  __asm__  volatile   ("lfence": : : "memory");
  generation_start = *dma_stats;
  if (generation_end != generation_start) {
    return (-11);
  } else {

  }
  efx_nic_fix_nodesc_drop_stat(efx, stats + 58UL);
  efx_update_diff_stat(stats + 3UL, *(stats + 2UL) - *(stats + 4UL));
  *(stats + 21UL) = ((*(stats + 22UL) + *(stats + 23UL)) + *(stats + 24UL)) + *(stats + 26UL);
  efx_update_diff_stat(stats + 32UL, *(stats + 31UL) - *(stats + 33UL));
  efx_update_sw_stats(efx, stats);
  return (0);
}
}
static size_t siena_update_nic_stats(struct efx_nic *efx , u64 *full_stats , struct rtnl_link_stats64 *core_stats ) 
{ 
  struct siena_nic_data *nic_data ;
  u64 *stats ;
  int retry ;
    klee_make_symbolic(&retry, sizeof(int), "retry");
  int tmp ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  stats = (u64 *)(& nic_data->stats);
  retry = 0;
  goto ldv_56538;
  ldv_56537: 
  tmp = siena_try_update_nic_stats(efx);
  if (tmp == 0) {
    goto ldv_56536;
  } else {

  }
  __const_udelay(429500UL);
  retry = retry + 1;
  ldv_56538: ;
  if (retry <= 99) {
    goto ldv_56537;
  } else {

  }
  ldv_56536: ;
  if ((unsigned long )full_stats != (unsigned long )((u64 *)0ULL)) {
    memcpy((void *)full_stats, (void const   *)stats, 472UL);
  } else {

  }
  if ((unsigned long )core_stats != (unsigned long )((struct rtnl_link_stats64 *)0)) {
    core_stats->rx_packets = *(stats + 34UL);
    core_stats->tx_packets = *(stats + 5UL);
    core_stats->rx_bytes = *(stats + 31UL);
    core_stats->tx_bytes = *(stats + 2UL);
    core_stats->rx_dropped = (*(stats + 58UL) + *(stats + 1UL)) + *stats;
    core_stats->multicast = *(stats + 40UL);
    core_stats->collisions = *(stats + 21UL);
    core_stats->rx_length_errors = *(stats + 50UL) + *(stats + 56UL);
    core_stats->rx_crc_errors = *(stats + 36UL);
    core_stats->rx_frame_errors = *(stats + 55UL);
    core_stats->rx_fifo_errors = *(stats + 52UL);
    core_stats->tx_window_errors = *(stats + 26UL);
    core_stats->rx_errors = ((core_stats->rx_length_errors + core_stats->rx_crc_errors) + core_stats->rx_frame_errors) + *(stats + 54UL);
    core_stats->tx_errors = core_stats->tx_window_errors + *(stats + 6UL);
  } else {

  }
  return (59UL);
}
}
static int siena_mac_reconfigure(struct efx_nic *efx ) 
{ 
  efx_dword_t inbuf[8U] ;
  unsigned int tmp ;
  int rc ;
  int __ret_warn_on ;
  int tmp___0 ;
  long tmp___1 ;
  int tmp___2 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 8U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  efx_farch_filter_sync_rx_mode(efx);
  tmp___0 = ldv_mutex_is_locked_241(& efx->mac_lock);
  __ret_warn_on = tmp___0 == 0;
  tmp___1 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___1 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena.c",
                       606);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  rc = efx_mcdi_set_mac(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  memcpy((void *)(& inbuf), (void const   *)(& efx->multicast_hash.byte), 32UL);
  tmp___2 = efx_mcdi_rpc(efx, 53U, (efx_dword_t const   *)(& inbuf), 32UL, (efx_dword_t *)0,
                         0UL, (size_t *)0UL);
  return (tmp___2);
}
}
static void siena_get_wol(struct efx_nic *efx , struct ethtool_wolinfo *wol ) 
{ 
  struct siena_nic_data *nic_data ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  wol->supported = 32U;
  if (nic_data->wol_filter_id != -1) {
    wol->wolopts = 32U;
  } else {
    wol->wolopts = 0U;
  }
  memset((void *)(& wol->sopass), 0, 6UL);
  return;
}
}
static int siena_set_wol(struct efx_nic *efx , u32 type ) 
{ 
  struct siena_nic_data *nic_data ;
  int rc ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  if ((type & 4294967263U) != 0U) {
    return (-22);
  } else {

  }
  if ((type & 32U) != 0U) {
    if (nic_data->wol_filter_id != -1) {
      efx_mcdi_wol_filter_remove(efx, nic_data->wol_filter_id);
    } else {

    }
    rc = efx_mcdi_wol_filter_set_magic(efx, (u8 const   *)(efx->net_dev)->dev_addr,
                                       & nic_data->wol_filter_id);
    if (rc != 0) {
      goto fail;
    } else {

    }
    pci_wake_from_d3(efx->pci_dev, 1);
  } else {
    rc = efx_mcdi_wol_filter_reset(efx);
    nic_data->wol_filter_id = -1;
    pci_wake_from_d3(efx->pci_dev, 0);
    if (rc != 0) {
      goto fail;
    } else {

    }
  }
  return (0);
  fail: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s failed: type=%d rc=%d\n",
               "siena_set_wol", type, rc);
  } else {

  }
  return (rc);
}
}
static void siena_init_wol(struct efx_nic *efx ) 
{ 
  struct siena_nic_data *nic_data ;
  int rc ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  rc = efx_mcdi_wol_filter_get_magic(efx, & nic_data->wol_filter_id);
  if (rc != 0) {
    efx_mcdi_wol_filter_reset(efx);
    nic_data->wol_filter_id = -1;
  } else
  if (nic_data->wol_filter_id != -1) {
    pci_wake_from_d3(efx->pci_dev, 1);
  } else {

  }
  return;
}
}
static void siena_mcdi_request(struct efx_nic *efx , efx_dword_t const   *hdr , size_t hdr_len ,
                               efx_dword_t const   *sdu , size_t sdu_len ) 
{ 
  unsigned int pdu ;
    klee_make_symbolic(&pdu, sizeof(int), "pdu");
  unsigned int tmp ;
  unsigned int doorbell ;
    klee_make_symbolic(&doorbell, sizeof(int), "doorbell");
  unsigned int tmp___0 ;
  unsigned int i ;
  unsigned int inlen_dw ;
    klee_make_symbolic(&inlen_dw, sizeof(int), "inlen_dw");

  {
  tmp = efx_port_num(efx);
  pdu = tmp != 0U ? 16711944U : 16711688U;
  tmp___0 = efx_port_num(efx);
  doorbell = tmp___0 != 0U ? 16711684U : 16711680U;
  inlen_dw = (unsigned int )((sdu_len + 3UL) / 4UL);
  efx_writed(efx, hdr, pdu);
  i = 0U;
  goto ldv_56576;
  ldv_56575: 
  efx_writed(efx, sdu + (unsigned long )i, ((unsigned int )hdr_len + pdu) + i * 4U);
  i = i + 1U;
  ldv_56576: ;
  if (i < inlen_dw) {
    goto ldv_56575;
  } else {

  }
  __asm__  volatile   ("sfence": : : "memory");
  _efx_writed(efx, 1165531836U, doorbell);
  return;
}
}
static bool siena_mcdi_poll_response(struct efx_nic *efx ) 
{ 
  unsigned int pdu ;
  unsigned int tmp ;
  efx_dword_t hdr ;

  {
  tmp = efx_port_num(efx);
  pdu = tmp != 0U ? 16711944U : 16711688U;
  efx_readd(efx, & hdr, pdu);
  return ((bool )(hdr.u32[0] != 4294967295U && (hdr.u32[0] & 8388608U) != 0U));
}
}
static void siena_mcdi_read_response(struct efx_nic *efx , efx_dword_t *outbuf , size_t offset ,
                                     size_t outlen ) 
{ 
  unsigned int pdu ;
  unsigned int tmp ;
  unsigned int outlen_dw ;
    klee_make_symbolic(&outlen_dw, sizeof(int), "outlen_dw");
  int i ;

  {
  tmp = efx_port_num(efx);
  pdu = tmp != 0U ? 16711944U : 16711688U;
  outlen_dw = (unsigned int )((outlen + 3UL) / 4UL);
  i = 0;
  goto ldv_56593;
  ldv_56592: 
  efx_readd(efx, outbuf + (unsigned long )i, ((unsigned int )offset + pdu) + (unsigned int )(i * 4));
  i = i + 1;
  ldv_56593: ;
  if ((unsigned int )i < outlen_dw) {
    goto ldv_56592;
  } else {

  }

  return;
}
}
static int siena_mcdi_poll_reboot(struct efx_nic *efx ) 
{ 
  struct siena_nic_data *nic_data ;
  unsigned int addr ;
  unsigned int tmp ;
  efx_dword_t reg ;
  u32 value ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  tmp = efx_port_num(efx);
  addr = tmp != 0U ? 16713724U : 16713720U;
  efx_readd(efx, & reg, addr);
  value = reg.u32[0];
  if (value == 0U) {
    return (0);
  } else {

  }
  reg.u32[0] = 0U;
  efx_writed(efx, (efx_dword_t const   *)(& reg), addr);
  nic_data->stats[3] = 0ULL;
  nic_data->stats[32] = 0ULL;
  if (value == 3735936685U) {
    return (-4);
  } else {
    return (-5);
  }
}
}
static struct siena_nvram_type_info  const  siena_nvram_types[14U]  = 
  {      {0, "sfc_dummy_phy"}, 
        {0, "sfc_mcfw"}, 
        {0, "sfc_mcfw_backup"}, 
        {0, "sfc_static_cfg"}, 
        {1, "sfc_static_cfg"}, 
        {0, "sfc_dynamic_cfg"}, 
        {1, "sfc_dynamic_cfg"}, 
        {0, "sfc_exp_rom"}, 
        {0, "sfc_exp_rom_cfg"}, 
        {1, "sfc_exp_rom_cfg"}, 
        {0, "sfc_phy_fw"}, 
        {1, "sfc_phy_fw"}, 
        {0, 0}, 
        {0, "sfc_fpga"}};
static int siena_mtd_probe_partition(struct efx_nic *efx , struct efx_mcdi_mtd_partition *part ,
                                     unsigned int type ) 
{ 
  struct siena_nvram_type_info  const  *info ;
  size_t size ;
  size_t erase_size ;
  bool protected ;
  int rc ;
  unsigned int tmp ;

  {
  if (type > 13U || (unsigned long )siena_nvram_types[type].name == (unsigned long )((char const   */* const  */)0)) {
    return (-19);
  } else {

  }
  info = (struct siena_nvram_type_info  const  *)(& siena_nvram_types) + (unsigned long )type;
  tmp = efx_port_num(efx);
  if ((unsigned int )info->port != tmp) {
    return (-19);
  } else {

  }
  rc = efx_mcdi_nvram_info(efx, type, & size, & erase_size, & protected);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if ((int )protected) {
    return (-19);
  } else {

  }
  part->nvram_type = (u16 )type;
  part->common.dev_type_name = "Siena NVRAM manager";
  part->common.type_name = info->name;
  part->common.mtd.type = 3U;
  part->common.mtd.flags = 3072U;
  part->common.mtd.size = (uint64_t )size;
  part->common.mtd.erasesize = (uint32_t )erase_size;
  return (0);
}
}
static int siena_mtd_get_fw_subtypes(struct efx_nic *efx , struct efx_mcdi_mtd_partition *parts ,
                                     size_t n_parts ) 
{ 
  uint16_t fw_subtype_list[32U] ;
  size_t i ;
  int rc ;

  {
  rc = efx_mcdi_get_board_cfg(efx, (u8 *)0U, (u16 *)(& fw_subtype_list), (u32 *)0U);
  if (rc != 0) {
    return (rc);
  } else {

  }
  i = 0UL;
  goto ldv_56627;
  ldv_56626: 
  (parts + i)->fw_subtype = fw_subtype_list[(int )(parts + i)->nvram_type];
  i = i + 1UL;
  ldv_56627: ;
  if (i < n_parts) {
    goto ldv_56626;
  } else {

  }

  return (0);
}
}
static int siena_mtd_probe(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_mtd_partition *parts ;
  u32 nvram_types ;
  unsigned int type ;
  size_t n_parts ;
  int rc ;
  int tmp ;
  long tmp___0 ;
  unsigned int tmp___1 ;
  void *tmp___2 ;

  {
  tmp = rtnl_is_locked();
  tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
  if (tmp___0 != 0L) {
    printk("\vRTNL: assertion failed at %s (%d)\n", (char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena.c",
           873);
    dump_stack();
  } else {

  }
  rc = efx_mcdi_nvram_types(efx, & nvram_types);
  if (rc != 0) {
    return (rc);
  } else {

  }
  tmp___1 = __arch_hweight32(nvram_types);
  tmp___2 = kcalloc((size_t )tmp___1, 1904UL, 208U);
  parts = (struct efx_mcdi_mtd_partition *)tmp___2;
  if ((unsigned long )parts == (unsigned long )((struct efx_mcdi_mtd_partition *)0)) {
    return (-12);
  } else {

  }
  type = 0U;
  n_parts = 0UL;
  goto ldv_56639;
  ldv_56638: ;
  if ((int )nvram_types & 1) {
    rc = siena_mtd_probe_partition(efx, parts + n_parts, type);
    if (rc == 0) {
      n_parts = n_parts + 1UL;
    } else
    if (rc != -19) {
      goto fail;
    } else {

    }
  } else {

  }
  type = type + 1U;
  nvram_types = nvram_types >> 1;
  ldv_56639: ;
  if (nvram_types != 0U) {
    goto ldv_56638;
  } else {

  }
  rc = siena_mtd_get_fw_subtypes(efx, parts, n_parts);
  if (rc != 0) {
    goto fail;
  } else {

  }
  rc = efx_mtd_add(efx, & parts->common, n_parts, 1904UL);
  fail: ;
  if (rc != 0) {
    kfree((void const   *)parts);
  } else {

  }
  return (rc);
}
}
struct efx_nic_type  const  siena_a0_nic_type  = 
     {0, 2U, & siena_mem_map_size, & siena_probe_nic, & siena_remove_nic, & siena_init_nic,
    & siena_dimension_resources, & efx_port_dummy_op_void, (void (*)(struct efx_nic * ))0,
    & efx_mcdi_map_reset_reason, & siena_map_reset_flags, & efx_mcdi_reset, & efx_mcdi_port_probe,
    & efx_mcdi_port_remove, 0, & efx_farch_fini_dmaq, & siena_prepare_flush, & siena_finish_flush,
    & efx_port_dummy_op_void, & efx_farch_finish_flr, & siena_describe_nic_stats,
    & siena_update_nic_stats, & efx_mcdi_mac_start_stats, & efx_mcdi_mac_pull_stats,
    & efx_mcdi_mac_stop_stats, & efx_mcdi_set_id_led, & siena_push_irq_moderation,
    & efx_mcdi_port_reconfigure, 0, & siena_mac_reconfigure, & efx_mcdi_mac_check_fault,
    & siena_get_wol, & siena_set_wol, & siena_init_wol, & siena_test_chip, & efx_mcdi_nvram_test_all,
    & siena_mcdi_request, & siena_mcdi_poll_response, & siena_mcdi_read_response,
    & siena_mcdi_poll_reboot, & efx_farch_irq_enable_master, & efx_farch_irq_test_generate,
    & efx_farch_irq_disable_master, & efx_farch_msi_interrupt, & efx_farch_legacy_interrupt,
    & efx_farch_tx_probe, & efx_farch_tx_init, & efx_farch_tx_remove, & efx_farch_tx_write,
    & siena_rx_push_rss_config, & efx_farch_rx_probe, & efx_farch_rx_init, & efx_farch_rx_remove,
    & efx_farch_rx_write, & efx_farch_rx_defer_refill, & efx_farch_ev_probe, & efx_farch_ev_init,
    & efx_farch_ev_fini, & efx_farch_ev_remove, & efx_farch_ev_process, & efx_farch_ev_read_ack,
    & efx_farch_ev_test_generate, & efx_farch_filter_table_probe, & efx_farch_filter_table_restore,
    & efx_farch_filter_table_remove, & efx_farch_filter_update_rx_scatter, & efx_farch_filter_insert,
    & efx_farch_filter_remove_safe, & efx_farch_filter_get_safe, & efx_farch_filter_clear_rx,
    & efx_farch_filter_count_rx_used, & efx_farch_filter_get_rx_id_limit, & efx_farch_filter_get_rx_ids,
    & efx_farch_filter_rfs_insert, & efx_farch_filter_rfs_expire_one, & siena_mtd_probe,
    & efx_mcdi_mtd_rename, & efx_mcdi_mtd_read, & efx_mcdi_mtd_erase, & efx_mcdi_mtd_write,
    & efx_mcdi_mtd_sync, & siena_ptp_write_host_time, 0, & siena_ptp_set_ts_config,
    & efx_siena_sriov_configure, & efx_siena_sriov_init, & efx_siena_sriov_fini, & efx_siena_sriov_wanted,
    & efx_siena_sriov_reset, & efx_siena_sriov_flr, & efx_siena_sriov_set_vf_mac,
    & efx_siena_sriov_set_vf_vlan, & efx_siena_sriov_set_vf_spoofchk, & efx_siena_sriov_get_vf_config,
    0, 0, & efx_port_dummy_op_int, & efx_port_dummy_op_int, & efx_port_dummy_op_void,
    0, & efx_siena_sriov_mac_address_changed, 3, 16056320U, 15990784U, 8388608U, 16121856U,
    16384000U, 70368744177663ULL, 16U, 12U, 0U, 0U, 1, (_Bool)0, 0U, 16384U, 12884901906ULL,
    1, 8192U, 505U};
void ldv_initialize_efx_nic_type_27(void) 
{ 
  void *tmp ;
  void *tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  void *tmp___4 ;

  {
  tmp = ldv_init_zalloc(288UL);
  siena_a0_nic_type_group0 = (struct efx_rx_queue *)tmp;
  tmp___0 = ldv_init_zalloc(2176UL);
  siena_a0_nic_type_group2 = (struct efx_channel *)tmp___0;
  tmp___1 = ldv_init_zalloc(1824UL);
  siena_a0_nic_type_group3 = (struct mtd_info *)tmp___1;
  tmp___2 = ldv_init_zalloc(320UL);
  siena_a0_nic_type_group4 = (struct efx_tx_queue *)tmp___2;
  tmp___3 = ldv_init_zalloc(4032UL);
  siena_a0_nic_type_group1 = (struct efx_nic *)tmp___3;
  tmp___4 = ldv_init_zalloc(64UL);
  siena_a0_nic_type_group5 = (struct efx_filter_spec *)tmp___4;
  return;
}
}
void ldv_main_exported_27(void) 
{ 
  int ldvarg75 ;
    klee_make_symbolic(&ldvarg75, sizeof(int), "ldvarg75");
  size_t ldvarg52 ;
  u8 *ldvarg74 ;
  void *tmp ;
  u8 *ldvarg76 ;
  void *tmp___0 ;
  size_t ldvarg82 ;
  bool ldvarg61 ;
  int ldvarg54 ;
    klee_make_symbolic(&ldvarg54, sizeof(int), "ldvarg54");
  size_t ldvarg30 ;
  int ldvarg68 ;
    klee_make_symbolic(&ldvarg68, sizeof(int), "ldvarg68");
  enum efx_filter_priority ldvarg78 ;
  u32 ldvarg70 ;
  loff_t ldvarg73 ;
  struct ethtool_wolinfo *ldvarg63 ;
  void *tmp___1 ;
  struct ifla_vf_info *ldvarg45 ;
  void *tmp___2 ;
  efx_dword_t *ldvarg81 ;
  void *tmp___3 ;
  int ldvarg40 ;
    klee_make_symbolic(&ldvarg40, sizeof(int), "ldvarg40");
  void *ldvarg55 ;
  void *tmp___4 ;
  bool ldvarg36 ;
  u32 ldvarg66 ;
  efx_dword_t *ldvarg79 ;
  void *tmp___5 ;
  u32 *ldvarg57 ;
  void *tmp___6 ;
  enum efx_filter_priority ldvarg65 ;
  int ldvarg62 ;
    klee_make_symbolic(&ldvarg62, sizeof(int), "ldvarg62");
  bool ldvarg49 ;
  size_t ldvarg86 ;
  struct hwtstamp_config *ldvarg59 ;
  void *tmp___7 ;
  loff_t ldvarg87 ;
  size_t ldvarg80 ;
  unsigned int ldvarg41 ;
    klee_make_symbolic(&ldvarg41, sizeof(int), "ldvarg41");
  int ldvarg60 ;
    klee_make_symbolic(&ldvarg60, sizeof(int), "ldvarg60");
  loff_t ldvarg31 ;
  u8 *ldvarg39 ;
  void *tmp___8 ;
  struct rtnl_link_stats64 *ldvarg47 ;
  void *tmp___9 ;
  struct efx_mtd_partition *ldvarg28 ;
  void *tmp___10 ;
  enum efx_filter_priority ldvarg34 ;
  u64 *ldvarg48 ;
  void *tmp___11 ;
  u32 ldvarg33 ;
  void *ldvarg69 ;
  void *tmp___12 ;
  u32 ldvarg38 ;
  u32 *ldvarg35 ;
  void *tmp___13 ;
  enum reset_type ldvarg85 ;
  enum reset_type ldvarg83 ;
  int ldvarg44 ;
    klee_make_symbolic(&ldvarg44, sizeof(int), "ldvarg44");
  size_t *ldvarg29 ;
  void *tmp___14 ;
  enum efx_led_mode ldvarg64 ;
  efx_dword_t *ldvarg53 ;
  void *tmp___15 ;
  unsigned int ldvarg37 ;
    klee_make_symbolic(&ldvarg37, sizeof(int), "ldvarg37");
  enum efx_filter_priority ldvarg58 ;
  int ldvarg46 ;
    klee_make_symbolic(&ldvarg46, sizeof(int), "ldvarg46");
  struct efx_self_tests *ldvarg50 ;
  void *tmp___16 ;
  u32 ldvarg56 ;
  size_t ldvarg72 ;
  size_t *ldvarg71 ;
  void *tmp___17 ;
  u8 ldvarg42 ;
  u16 ldvarg43 ;
  enum efx_filter_priority ldvarg67 ;
  u8 *ldvarg32 ;
  void *tmp___18 ;
  size_t ldvarg51 ;
  u32 *ldvarg84 ;
  void *tmp___19 ;
  u32 ldvarg77 ;
  int tmp___20 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg74 = (u8 *)tmp;
  tmp___0 = ldv_init_zalloc(1UL);
  ldvarg76 = (u8 *)tmp___0;
  tmp___1 = ldv_init_zalloc(20UL);
  ldvarg63 = (struct ethtool_wolinfo *)tmp___1;
  tmp___2 = ldv_init_zalloc(64UL);
  ldvarg45 = (struct ifla_vf_info *)tmp___2;
  tmp___3 = ldv_init_zalloc(4UL);
  ldvarg81 = (efx_dword_t *)tmp___3;
  tmp___4 = ldv_init_zalloc(1UL);
  ldvarg55 = tmp___4;
  tmp___5 = ldv_init_zalloc(4UL);
  ldvarg79 = (efx_dword_t *)tmp___5;
  tmp___6 = ldv_init_zalloc(4UL);
  ldvarg57 = (u32 *)tmp___6;
  tmp___7 = ldv_init_zalloc(12UL);
  ldvarg59 = (struct hwtstamp_config *)tmp___7;
  tmp___8 = ldv_init_zalloc(1UL);
  ldvarg39 = (u8 *)tmp___8;
  tmp___9 = ldv_init_zalloc(184UL);
  ldvarg47 = (struct rtnl_link_stats64 *)tmp___9;
  tmp___10 = ldv_init_zalloc(1896UL);
  ldvarg28 = (struct efx_mtd_partition *)tmp___10;
  tmp___11 = ldv_init_zalloc(8UL);
  ldvarg48 = (u64 *)tmp___11;
  tmp___12 = ldv_init_zalloc(1UL);
  ldvarg69 = tmp___12;
  tmp___13 = ldv_init_zalloc(4UL);
  ldvarg35 = (u32 *)tmp___13;
  tmp___14 = ldv_init_zalloc(8UL);
  ldvarg29 = (size_t *)tmp___14;
  tmp___15 = ldv_init_zalloc(4UL);
  ldvarg53 = (efx_dword_t *)tmp___15;
  tmp___16 = ldv_init_zalloc(1076UL);
  ldvarg50 = (struct efx_self_tests *)tmp___16;
  tmp___17 = ldv_init_zalloc(8UL);
  ldvarg71 = (size_t *)tmp___17;
  tmp___18 = ldv_init_zalloc(1UL);
  ldvarg32 = (u8 *)tmp___18;
  tmp___19 = ldv_init_zalloc(4UL);
  ldvarg84 = (u32 *)tmp___19;
  ldv_memset((void *)(& ldvarg75), 0, 4UL);
  ldv_memset((void *)(& ldvarg52), 0, 8UL);
  ldv_memset((void *)(& ldvarg82), 0, 8UL);
  ldv_memset((void *)(& ldvarg61), 0, 1UL);
  ldv_memset((void *)(& ldvarg54), 0, 4UL);
  ldv_memset((void *)(& ldvarg30), 0, 8UL);
  ldv_memset((void *)(& ldvarg68), 0, 4UL);
  ldv_memset((void *)(& ldvarg78), 0, 4UL);
  ldv_memset((void *)(& ldvarg70), 0, 4UL);
  ldv_memset((void *)(& ldvarg73), 0, 8UL);
  ldv_memset((void *)(& ldvarg40), 0, 4UL);
  ldv_memset((void *)(& ldvarg36), 0, 1UL);
  ldv_memset((void *)(& ldvarg66), 0, 4UL);
  ldv_memset((void *)(& ldvarg65), 0, 4UL);
  ldv_memset((void *)(& ldvarg62), 0, 4UL);
  ldv_memset((void *)(& ldvarg49), 0, 1UL);
  ldv_memset((void *)(& ldvarg86), 0, 8UL);
  ldv_memset((void *)(& ldvarg87), 0, 8UL);
  ldv_memset((void *)(& ldvarg80), 0, 8UL);
  ldv_memset((void *)(& ldvarg41), 0, 4UL);
  ldv_memset((void *)(& ldvarg60), 0, 4UL);
  ldv_memset((void *)(& ldvarg31), 0, 8UL);
  ldv_memset((void *)(& ldvarg34), 0, 4UL);
  ldv_memset((void *)(& ldvarg33), 0, 4UL);
  ldv_memset((void *)(& ldvarg38), 0, 4UL);
  ldv_memset((void *)(& ldvarg85), 0, 4UL);
  ldv_memset((void *)(& ldvarg83), 0, 4UL);
  ldv_memset((void *)(& ldvarg44), 0, 4UL);
  ldv_memset((void *)(& ldvarg64), 0, 4UL);
  ldv_memset((void *)(& ldvarg37), 0, 4UL);
  ldv_memset((void *)(& ldvarg58), 0, 4UL);
  ldv_memset((void *)(& ldvarg46), 0, 4UL);
  ldv_memset((void *)(& ldvarg56), 0, 4UL);
  ldv_memset((void *)(& ldvarg72), 0, 8UL);
  ldv_memset((void *)(& ldvarg42), 0, 1UL);
  ldv_memset((void *)(& ldvarg43), 0, 2UL);
  ldv_memset((void *)(& ldvarg67), 0, 4UL);
  ldv_memset((void *)(& ldvarg51), 0, 8UL);
  ldv_memset((void *)(& ldvarg77), 0, 4UL);
  tmp___20 = __VERIFIER_nondet_int();
  switch (tmp___20) {
  case 0: ;
  if (ldv_state_variable_27 == 1) {
    efx_port_dummy_op_void(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 1: ;
  if (ldv_state_variable_27 == 1) {
    siena_mcdi_poll_reboot(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 2: ;
  if (ldv_state_variable_27 == 1) {
    siena_mac_reconfigure(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 3: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_fini_dmaq(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 4: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_mtd_erase(siena_a0_nic_type_group3, ldvarg87, ldvarg86);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 5: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_rx_init(siena_a0_nic_type_group0);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 6: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_map_reset_reason(ldvarg85);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 7: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_ev_read_ack(siena_a0_nic_type_group2);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 8: ;
  if (ldv_state_variable_27 == 1) {
    siena_map_reset_flags(ldvarg84);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 9: ;
  if (ldv_state_variable_27 == 1) {
    efx_port_dummy_op_int(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 10: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_mtd_sync(siena_a0_nic_type_group3);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 11: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_mac_pull_stats(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 12: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_rx_write(siena_a0_nic_type_group0);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 13: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_port_probe(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 14: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_filter_table_remove(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 15: ;
  if (ldv_state_variable_27 == 1) {
    siena_mem_map_size(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 16: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_reset(siena_a0_nic_type_group1, ldvarg83);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 17: ;
  if (ldv_state_variable_27 == 1) {
    siena_mcdi_request(siena_a0_nic_type_group1, (efx_dword_t const   *)ldvarg81,
                       ldvarg80, (efx_dword_t const   *)ldvarg79, ldvarg82);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 18: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_filter_rfs_insert(siena_a0_nic_type_group1, siena_a0_nic_type_group5);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 19: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_ev_probe(siena_a0_nic_type_group2);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 20: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_filter_count_rx_used(siena_a0_nic_type_group1, ldvarg78);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 21: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_tx_probe(siena_a0_nic_type_group4);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 22: ;
  if (ldv_state_variable_27 == 1) {
    siena_ptp_write_host_time(siena_a0_nic_type_group1, ldvarg77);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 23: ;
  if (ldv_state_variable_27 == 1) {
    siena_describe_nic_stats(siena_a0_nic_type_group1, ldvarg76);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 24: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_filter_table_probe(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 25: ;
  if (ldv_state_variable_27 == 1) {
    efx_port_dummy_op_void(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 26: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_irq_disable_master(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 27: ;
  if (ldv_state_variable_27 == 1) {
    efx_siena_sriov_reset(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 28: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_ev_process(siena_a0_nic_type_group2, ldvarg75);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 29: ;
  if (ldv_state_variable_27 == 1) {
    efx_siena_sriov_mac_address_changed(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 30: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_mtd_read(siena_a0_nic_type_group3, ldvarg73, ldvarg72, ldvarg71, ldvarg74);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 31: ;
  if (ldv_state_variable_27 == 1) {
    efx_siena_sriov_wanted(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 32: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_rx_probe(siena_a0_nic_type_group0);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 33: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_filter_table_restore(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 34: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_ev_remove(siena_a0_nic_type_group2);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 35: ;
  if (ldv_state_variable_27 == 1) {
    siena_set_wol(siena_a0_nic_type_group1, ldvarg70);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 36: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_legacy_interrupt(ldvarg68, ldvarg69);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 37: ;
  if (ldv_state_variable_27 == 1) {
    siena_mcdi_poll_response(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 38: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_filter_remove_safe(siena_a0_nic_type_group1, ldvarg67, ldvarg66);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 39: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_filter_clear_rx(siena_a0_nic_type_group1, ldvarg65);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 40: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_filter_get_rx_id_limit(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 41: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_set_id_led(siena_a0_nic_type_group1, ldvarg64);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 42: ;
  if (ldv_state_variable_27 == 1) {
    siena_get_wol(siena_a0_nic_type_group1, ldvarg63);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 43: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_tx_remove(siena_a0_nic_type_group4);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 44: ;
  if (ldv_state_variable_27 == 1) {
    efx_siena_sriov_set_vf_spoofchk(siena_a0_nic_type_group1, ldvarg62, (int )ldvarg61);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 45: ;
  if (ldv_state_variable_27 == 1) {
    efx_port_dummy_op_int(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 46: ;
  if (ldv_state_variable_27 == 1) {
    efx_siena_sriov_configure(siena_a0_nic_type_group1, ldvarg60);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 47: ;
  if (ldv_state_variable_27 == 1) {
    siena_ptp_set_ts_config(siena_a0_nic_type_group1, ldvarg59);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 48: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_rx_defer_refill(siena_a0_nic_type_group0);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 49: ;
  if (ldv_state_variable_27 == 1) {
    siena_remove_nic(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 50: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_irq_enable_master(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 51: ;
  if (ldv_state_variable_27 == 1) {
    efx_siena_sriov_fini(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 52: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_filter_get_rx_ids(siena_a0_nic_type_group1, ldvarg58, ldvarg57, ldvarg56);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 53: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_msi_interrupt(ldvarg54, ldvarg55);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 54: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_ev_fini(siena_a0_nic_type_group2);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 55: ;
  if (ldv_state_variable_27 == 1) {
    siena_mtd_probe(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 56: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_irq_test_generate(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 57: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_finish_flr(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 58: ;
  if (ldv_state_variable_27 == 1) {
    siena_mcdi_read_response(siena_a0_nic_type_group1, ldvarg53, ldvarg52, ldvarg51);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 59: ;
  if (ldv_state_variable_27 == 1) {
    siena_test_chip(siena_a0_nic_type_group1, ldvarg50);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 60: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_ev_init(siena_a0_nic_type_group2);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 61: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_filter_insert(siena_a0_nic_type_group1, siena_a0_nic_type_group5, (int )ldvarg49);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 62: ;
  if (ldv_state_variable_27 == 1) {
    siena_update_nic_stats(siena_a0_nic_type_group1, ldvarg48, ldvarg47);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 63: ;
  if (ldv_state_variable_27 == 1) {
    siena_push_irq_moderation(siena_a0_nic_type_group2);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 64: ;
  if (ldv_state_variable_27 == 1) {
    efx_siena_sriov_get_vf_config(siena_a0_nic_type_group1, ldvarg46, ldvarg45);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 65: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_port_remove(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 66: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_rx_remove(siena_a0_nic_type_group0);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 67: ;
  if (ldv_state_variable_27 == 1) {
    efx_siena_sriov_set_vf_vlan(siena_a0_nic_type_group1, ldvarg44, (int )ldvarg43,
                                (int )ldvarg42);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 68: ;
  if (ldv_state_variable_27 == 1) {
    efx_siena_sriov_flr(siena_a0_nic_type_group1, ldvarg41);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 69: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_mac_stop_stats(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 70: ;
  if (ldv_state_variable_27 == 1) {
    siena_probe_nic(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 71: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_filter_update_rx_scatter(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 72: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_mac_check_fault(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 73: ;
  if (ldv_state_variable_27 == 1) {
    siena_dimension_resources(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 74: ;
  if (ldv_state_variable_27 == 1) {
    efx_siena_sriov_set_vf_mac(siena_a0_nic_type_group1, ldvarg40, ldvarg39);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 75: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_mac_start_stats(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 76: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_tx_write(siena_a0_nic_type_group4);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 77: ;
  if (ldv_state_variable_27 == 1) {
    efx_siena_sriov_init(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 78: ;
  if (ldv_state_variable_27 == 1) {
    efx_port_dummy_op_void(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 79: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_filter_rfs_expire_one(siena_a0_nic_type_group1, ldvarg38, ldvarg37);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 80: ;
  if (ldv_state_variable_27 == 1) {
    siena_init_wol(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 81: ;
  if (ldv_state_variable_27 == 1) {
    siena_rx_push_rss_config(siena_a0_nic_type_group1, (int )ldvarg36, (u32 const   *)ldvarg35);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 82: ;
  if (ldv_state_variable_27 == 1) {
    siena_finish_flush(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 83: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_filter_get_safe(siena_a0_nic_type_group1, ldvarg34, ldvarg33, siena_a0_nic_type_group5);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 84: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_mtd_write(siena_a0_nic_type_group3, ldvarg31, ldvarg30, ldvarg29, (u8 const   *)ldvarg32);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 85: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_tx_init(siena_a0_nic_type_group4);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 86: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_nvram_test_all(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 87: ;
  if (ldv_state_variable_27 == 1) {
    efx_farch_ev_test_generate(siena_a0_nic_type_group2);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 88: ;
  if (ldv_state_variable_27 == 1) {
    siena_init_nic(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 89: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_mtd_rename(ldvarg28);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 90: ;
  if (ldv_state_variable_27 == 1) {
    efx_mcdi_port_reconfigure(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  case 91: ;
  if (ldv_state_variable_27 == 1) {
    siena_prepare_flush(siena_a0_nic_type_group1);
    ldv_state_variable_27 = 1;
  } else {

  }
  goto ldv_56709;
  default: 
  ldv_stop();
  }
  ldv_56709: ;
  return;
}
}
bool ldv_queue_work_on_229(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_230(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_231(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_232(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_233(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_234(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_235(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_236(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_237(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_238(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_239(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_240(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
__inline static int ldv_mutex_is_locked_241(struct mutex *lock ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_is_locked(lock);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_is_locked_mac_lock_of_efx_nic(lock);
  return (tmp___0);
  return (ldv_func_res);
}
}
void *__builtin_alloca(unsigned long  ) ;
__inline static long ldv__builtin_expect(long exp , long c ) ;
__inline static __u32 rol32(__u32 word , unsigned int shift ) 
{ 


  {
  return ((word << shift) | (word >> (8UL * sizeof(word) - (unsigned long )shift)));
}
}
__inline static unsigned long __rounddown_pow_of_two(unsigned long n ) 
{ 
  unsigned int tmp ;

  {
  tmp = fls_long(n);
  return (1UL << (int )(tmp - 1U));
}
}
extern char *strchr(char const   * , int  ) ;
__inline static void bitmap_zero(unsigned long *dst , unsigned int nbits ) 
{ 
  unsigned int len ;

  {
  len = (unsigned int )(((unsigned long )nbits + 63UL) / 64UL) * 8U;
  memset((void *)dst, 0, (size_t )len);
  return;
}
}
extern void warn_slowpath_fmt(char const   * , int const    , char const   *  , ...) ;
__inline static int atomic_dec_and_test(atomic_t *v ) 
{ 
  char c ;

  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; decl %0; sete %1": "+m" (v->counter),
                       "=qm" (c): : "memory");
  return ((int )((signed char )c) != 0);
}
}
int ldv_mutex_trylock_267(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_265(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_268(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_269(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_264(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_266(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_270(struct mutex *ldv_func_arg1 ) ;
extern int __preempt_count ;
    klee_make_symbolic(&__preempt_count, sizeof(int), "__preempt_count");
__inline static int preempt_count(void) 
{ 
  int pfo_ret__ ;

  {
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (__preempt_count));
  goto ldv_6656;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (__preempt_count));
  goto ldv_6656;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (__preempt_count));
  goto ldv_6656;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (__preempt_count));
  goto ldv_6656;
  default: 
  __bad_percpu_size();
  }
  ldv_6656: ;
  return (pfo_ret__ & 2147483647);
}
}
extern void prepare_to_wait(wait_queue_head_t * , wait_queue_t * , int  ) ;
extern int autoremove_wake_function(wait_queue_t * , unsigned int  , int  , void * ) ;
bool ldv_queue_work_on_259(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_261(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_260(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_263(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_262(struct workqueue_struct *ldv_func_arg1 ) ;
__inline static int rwsem_is_locked(struct rw_semaphore *sem ) 
{ 


  {
  return (sem->count != 0L);
}
}
__inline static resource_size_t resource_size(struct resource  const  *res ) 
{ 


  {
  return (((unsigned long long )res->end - (unsigned long long )res->start) + 1ULL);
}
}
extern void *ioremap_wc(resource_size_t  , unsigned long  ) ;
extern void schedule(void) ;
__inline static void ssleep(unsigned int seconds ) 
{ 


  {
  msleep(seconds * 1000U);
  return;
}
}
__inline static bool ipv4_is_multicast(__be32 addr ) 
{ 


  {
  return ((addr & 240U) == 224U);
}
}
__inline static void netif_tx_lock___1(struct net_device *dev ) 
{ 
  unsigned int i ;
  int cpu ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  spin_lock(& dev->tx_global_lock);
  __vpp_verify = (void const   *)0;
  switch (4UL) {
  case 1UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
  goto ldv_42757;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_42757;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_42757;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_42757;
  default: 
  __bad_percpu_size();
  }
  ldv_42757: 
  pscr_ret__ = pfo_ret__;
  goto ldv_42763;
  case 2UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_42767;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_42767;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_42767;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_42767;
  default: 
  __bad_percpu_size();
  }
  ldv_42767: 
  pscr_ret__ = pfo_ret_____0;
  goto ldv_42763;
  case 4UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_42776;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_42776;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_42776;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_42776;
  default: 
  __bad_percpu_size();
  }
  ldv_42776: 
  pscr_ret__ = pfo_ret_____1;
  goto ldv_42763;
  case 8UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_42785;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_42785;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_42785;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_42785;
  default: 
  __bad_percpu_size();
  }
  ldv_42785: 
  pscr_ret__ = pfo_ret_____2;
  goto ldv_42763;
  default: 
  __bad_size_call_parameter();
  goto ldv_42763;
  }
  ldv_42763: 
  cpu = pscr_ret__;
  i = 0U;
  goto ldv_42795;
  ldv_42794: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  __netif_tx_lock(txq, cpu);
  set_bit(2L, (unsigned long volatile   *)(& txq->state));
  __netif_tx_unlock(txq);
  i = i + 1U;
  ldv_42795: ;
  if (dev->num_tx_queues > i) {
    goto ldv_42794;
  } else {

  }

  return;
}
}
__inline static void netif_tx_lock_bh___0(struct net_device *dev ) 
{ 


  {
  local_bh_disable();
  netif_tx_lock___1(dev);
  return;
}
}
__inline static void netif_tx_unlock___1(struct net_device *dev ) 
{ 
  unsigned int i ;
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  i = 0U;
  goto ldv_42806;
  ldv_42805: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  clear_bit(2L, (unsigned long volatile   *)(& txq->state));
  netif_schedule_queue(txq);
  i = i + 1U;
  ldv_42806: ;
  if (dev->num_tx_queues > i) {
    goto ldv_42805;
  } else {

  }
  spin_unlock(& dev->tx_global_lock);
  return;
}
}
__inline static void netif_tx_unlock_bh___0(struct net_device *dev ) 
{ 


  {
  netif_tx_unlock___1(dev);
  local_bh_enable();
  return;
}
}
__inline static char const   *netdev_name(struct net_device  const  *dev ) 
{ 
  char *tmp ;

  {
  if ((int )((signed char )dev->name[0]) == 0) {
    return ("(unnamed net_device)");
  } else {
    tmp = strchr((char const   *)(& dev->name), 37);
    if ((unsigned long )tmp != (unsigned long )((char *)0)) {
      return ("(unnamed net_device)");
    } else {

    }
  }
  return ((char const   *)(& dev->name));
}
}
__inline static char const   *netdev_reg_state(struct net_device  const  *dev ) 
{ 
  bool __warned ;
  int __ret_warn_once ;
  int __ret_warn_on ;
  long tmp ;
  long tmp___0 ;
  long tmp___1 ;

  {
  switch ((int )dev->reg_state) {
  case 0: ;
  return (" (uninitialized)");
  case 1: ;
  return ("");
  case 2: ;
  return (" (unregistering)");
  case 3: ;
  return (" (unregistered)");
  case 4: ;
  return (" (released)");
  case 5: ;
  return (" (dummy)");
  }
  __ret_warn_once = 1;
  tmp___1 = ldv__builtin_expect(__ret_warn_once != 0, 0L);
  if (tmp___1 != 0L) {
    __ret_warn_on = ! __warned;
    tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp != 0L) {
      warn_slowpath_fmt("include/linux/netdevice.h", 3814, "%s: unknown reg_state %d\n",
                        (char const   *)(& dev->name), (int )dev->reg_state);
    } else {

    }
    tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___0 != 0L) {
      __warned = 1;
    } else {

    }
  } else {

  }
  ldv__builtin_expect(__ret_warn_once != 0, 0L);
  return (" (unknown)");
}
}
__inline static void eth_broadcast_addr(u8 *addr ) 
{ 


  {
  memset((void *)addr, 255, 6UL);
  return;
}
}
__inline static u32 jhash2(u32 const   *k , u32 length , u32 initval ) 
{ 
  u32 a ;
  u32 b ;
  u32 c ;
  __u32 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;
  __u32 tmp___4 ;
  __u32 tmp___5 ;
  __u32 tmp___6 ;
  __u32 tmp___7 ;
  __u32 tmp___8 ;
  __u32 tmp___9 ;
  __u32 tmp___10 ;
  __u32 tmp___11 ;

  {
  c = ((length << 2) + initval) + 3735928559U;
  b = c;
  a = b;
  goto ldv_47035;
  ldv_47034: 
  a = (u32 )*k + a;
  b = (u32 )*(k + 1UL) + b;
  c = (u32 )*(k + 2UL) + c;
  a = a - c;
  tmp = rol32(c, 4U);
  a = tmp ^ a;
  c = c + b;
  b = b - a;
  tmp___0 = rol32(a, 6U);
  b = tmp___0 ^ b;
  a = a + c;
  c = c - b;
  tmp___1 = rol32(b, 8U);
  c = tmp___1 ^ c;
  b = b + a;
  a = a - c;
  tmp___2 = rol32(c, 16U);
  a = tmp___2 ^ a;
  c = c + b;
  b = b - a;
  tmp___3 = rol32(a, 19U);
  b = tmp___3 ^ b;
  a = a + c;
  c = c - b;
  tmp___4 = rol32(b, 4U);
  c = tmp___4 ^ c;
  b = b + a;
  length = length - 3U;
  k = k + 3UL;
  ldv_47035: ;
  if (length > 3U) {
    goto ldv_47034;
  } else {

  }

  switch (length) {
  case 3U: 
  c = (u32 )*(k + 2UL) + c;
  case 2U: 
  b = (u32 )*(k + 1UL) + b;
  case 1U: 
  a = (u32 )*k + a;
  c = c ^ b;
  tmp___5 = rol32(b, 14U);
  c = c - tmp___5;
  a = a ^ c;
  tmp___6 = rol32(c, 11U);
  a = a - tmp___6;
  b = b ^ a;
  tmp___7 = rol32(a, 25U);
  b = b - tmp___7;
  c = c ^ b;
  tmp___8 = rol32(b, 16U);
  c = c - tmp___8;
  a = a ^ c;
  tmp___9 = rol32(c, 4U);
  a = a - tmp___9;
  b = b ^ a;
  tmp___10 = rol32(a, 14U);
  b = b - tmp___10;
  c = c ^ b;
  tmp___11 = rol32(b, 24U);
  c = c - tmp___11;
  case 0U: ;
  goto ldv_47041;
  }
  ldv_47041: ;
  return (c);
}
}
__inline static void efx_filter_init_rx(struct efx_filter_spec *spec , enum efx_filter_priority priority ,
                                        enum efx_filter_flags flags , unsigned int rxq_id ) 
{ 


  {
  memset((void *)spec, 0, 64UL);
  spec->priority = (unsigned char )priority;
  spec->flags = (unsigned char )((unsigned int )((unsigned char )flags) | 8U);
  spec->rss_context = 4294967295U;
  spec->dmaq_id = (unsigned short )rxq_id;
  return;
}
}
__inline static int efx_filter_set_eth_local(struct efx_filter_spec *spec , u16 vid ,
                                             u8 const   *addr ) 
{ 
  __u16 tmp ;

  {
  if ((unsigned int )vid == 65535U && (unsigned long )addr == (unsigned long )((u8 const   *)0U)) {
    return (-22);
  } else {

  }
  if ((unsigned int )vid != 65535U) {
    spec->match_flags = (unsigned short )((unsigned int )spec->match_flags | 256U);
    tmp = __fswab16((int )vid);
    spec->outer_vid = tmp;
  } else {

  }
  if ((unsigned long )addr != (unsigned long )((u8 const   *)0U)) {
    spec->match_flags = (unsigned short )((unsigned int )spec->match_flags | 16U);
    ether_addr_copy((u8 *)(& spec->loc_mac), addr);
  } else {

  }
  return (0);
}
}
__inline static int efx_filter_set_uc_def(struct efx_filter_spec *spec ) 
{ 


  {
  spec->match_flags = (unsigned short )((unsigned int )spec->match_flags | 1024U);
  return (0);
}
}
__inline static int efx_filter_set_mc_def(struct efx_filter_spec *spec ) 
{ 


  {
  spec->match_flags = (unsigned short )((unsigned int )spec->match_flags | 1024U);
  spec->loc_mac[0] = 1U;
  return (0);
}
}
int efx_mcdi_rpc_quiet(struct efx_nic *efx , unsigned int cmd , efx_dword_t const   *inbuf ,
                       size_t inlen , efx_dword_t *outbuf , size_t outlen , size_t *outlen_actual ) ;
int efx_mcdi_rpc_async(struct efx_nic *efx , unsigned int cmd , efx_dword_t const   *inbuf ,
                       size_t inlen , size_t outlen , efx_mcdi_async_completer *complete___0 ,
                       unsigned long cookie ) ;
void efx_mcdi_display_error(struct efx_nic *efx , unsigned int cmd , size_t inlen ,
                            efx_dword_t *outbuf , size_t outlen , int rc ) ;
int efx_mcdi_port_get_number(struct efx_nic *efx ) ;
u32 efx_mcdi_phy_get_caps(struct efx_nic *efx ) ;
int efx_mcdi_set_workaround(struct efx_nic *efx , u32 type , bool enabled ) ;
int efx_mcdi_get_workarounds(struct efx_nic *efx , unsigned int *impl_out , unsigned int *enabled_out ) ;
unsigned int efx_piobuf_size ;
    klee_make_symbolic(&efx_piobuf_size, sizeof(int), "efx_piobuf_size");
bool efx_filter_is_mc_recipient(struct efx_filter_spec  const  *spec ) ;
__inline static void efx_schedule_channel___2(struct efx_channel *channel ) 
{ 
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;

  {
  if (0) {
    if (((channel->efx)->msg_enable & 512U) != 0U) {
      __vpp_verify = (void const   *)0;
      switch (4UL) {
      case 1UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
      goto ldv_54715;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_54715;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_54715;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_54715;
      default: 
      __bad_percpu_size();
      }
      ldv_54715: 
      pscr_ret__ = pfo_ret__;
      goto ldv_54721;
      case 2UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_54725;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_54725;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_54725;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_54725;
      default: 
      __bad_percpu_size();
      }
      ldv_54725: 
      pscr_ret__ = pfo_ret_____0;
      goto ldv_54721;
      case 4UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_54734;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_54734;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_54734;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_54734;
      default: 
      __bad_percpu_size();
      }
      ldv_54734: 
      pscr_ret__ = pfo_ret_____1;
      goto ldv_54721;
      case 8UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_54743;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_54743;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_54743;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_54743;
      default: 
      __bad_percpu_size();
      }
      ldv_54743: 
      pscr_ret__ = pfo_ret_____2;
      goto ldv_54721;
      default: 
      __bad_size_call_parameter();
      goto ldv_54721;
      }
      ldv_54721: 
      netdev_printk("\017", (struct net_device  const  *)(channel->efx)->net_dev,
                    "channel %d scheduling NAPI poll on CPU%d\n", channel->channel,
                    pscr_ret__);
    } else {

    }
  } else {

  }
  napi_schedule(& channel->napi_str);
  return;
}
}
__inline static void efx_schedule_channel_irq___1(struct efx_channel *channel ) 
{ 
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;

  {
  __vpp_verify = (void const   *)0;
  switch (4UL) {
  case 1UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
  goto ldv_54760;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_54760;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_54760;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_54760;
  default: 
  __bad_percpu_size();
  }
  ldv_54760: 
  pscr_ret__ = pfo_ret__;
  goto ldv_54766;
  case 2UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_54770;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_54770;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_54770;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_54770;
  default: 
  __bad_percpu_size();
  }
  ldv_54770: 
  pscr_ret__ = pfo_ret_____0;
  goto ldv_54766;
  case 4UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_54779;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_54779;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_54779;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_54779;
  default: 
  __bad_percpu_size();
  }
  ldv_54779: 
  pscr_ret__ = pfo_ret_____1;
  goto ldv_54766;
  case 8UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_54788;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_54788;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_54788;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_54788;
  default: 
  __bad_percpu_size();
  }
  ldv_54788: 
  pscr_ret__ = pfo_ret_____2;
  goto ldv_54766;
  default: 
  __bad_size_call_parameter();
  goto ldv_54766;
  }
  ldv_54766: 
  channel->event_test_cpu = pscr_ret__;
  efx_schedule_channel___2(channel);
  return;
}
}
__inline static void efx_device_detach_sync___0(struct efx_nic *efx ) 
{ 
  struct net_device *dev ;

  {
  dev = efx->net_dev;
  netif_tx_lock_bh___0(dev);
  netif_device_detach(dev);
  netif_tx_unlock_bh___0(dev);
  return;
}
}
int efx_ptp_probe(struct efx_nic *efx , struct efx_channel *channel ) ;
void efx_ptp_remove(struct efx_nic *efx ) ;
void efx_ef10_handle_drain_event(struct efx_nic *efx ) ;
__inline static bool efx_ef10_sriov_wanted(struct efx_nic *efx ) 
{ 


  {
  return (0);
}
}
int efx_ef10_sriov_configure(struct efx_nic *efx , int num_vfs ) ;
int efx_ef10_sriov_init(struct efx_nic *efx ) ;
__inline static void efx_ef10_sriov_reset(struct efx_nic *efx ) 
{ 


  {
  return;
}
}
void efx_ef10_sriov_fini(struct efx_nic *efx ) ;
__inline static void efx_ef10_sriov_flr(struct efx_nic *efx , unsigned int vf_i ) 
{ 


  {
  return;
}
}
int efx_ef10_sriov_set_vf_mac(struct efx_nic *efx , int vf_i , u8 *mac ) ;
int efx_ef10_sriov_set_vf_vlan(struct efx_nic *efx , int vf_i , u16 vlan , u8 qos ) ;
int efx_ef10_sriov_set_vf_spoofchk(struct efx_nic *efx , int vf_i , bool spoofchk ) ;
int efx_ef10_sriov_get_vf_config(struct efx_nic *efx , int vf_i , struct ifla_vf_info *ivf ) ;
int efx_ef10_sriov_set_vf_link_state(struct efx_nic *efx , int vf_i , int link_state ) ;
int efx_ef10_sriov_get_phys_port_id(struct efx_nic *efx , struct netdev_phys_item_id *ppid ) ;
int efx_ef10_vswitching_probe_pf(struct efx_nic *efx ) ;
int efx_ef10_vswitching_probe_vf(struct efx_nic *efx ) ;
int efx_ef10_vswitching_restore_pf(struct efx_nic *efx ) ;
int efx_ef10_vswitching_restore_vf(struct efx_nic *efx ) ;
void efx_ef10_vswitching_remove_pf(struct efx_nic *efx ) ;
void efx_ef10_vswitching_remove_vf(struct efx_nic *efx ) ;
static void efx_ef10_rx_free_indir_table(struct efx_nic *efx ) ;
static void efx_ef10_filter_table_remove(struct efx_nic *efx ) ;
static int efx_ef10_get_warm_boot_count(struct efx_nic *efx ) 
{ 
  efx_dword_t reg ;

  {
  efx_readd(efx, & reg, 16U);
  return (reg.u32[0] >> 16 == 45063U ? (int )reg.u32[0] & 65535 : -5);
}
}
static unsigned int efx_ef10_mem_map_size(struct efx_nic *efx ) 
{ 
  int bar ;
  resource_size_t tmp ;

  {
  bar = (int )(efx->type)->mem_bar;
  tmp = resource_size((struct resource  const  *)(& (efx->pci_dev)->resource) + (unsigned long )bar);
  return ((unsigned int )tmp);
}
}
static int efx_ef10_get_pf_index(struct efx_nic *efx ) 
{ 
  efx_dword_t outbuf[2U] ;
  unsigned int tmp ;
  struct efx_ef10_nic_data *nic_data ;
  size_t outlen ;
  int rc ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  rc = efx_mcdi_rpc(efx, 236U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    8UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 7UL) {
    return (-5);
  } else {

  }
  nic_data->pf_index = ((efx_dword_t *)(& outbuf))->u32[0];
  return (0);
}
}
static int efx_ef10_get_vf_index(struct efx_nic *efx ) 
{ 
  efx_dword_t outbuf[2U] ;
  unsigned int tmp ;
  struct efx_ef10_nic_data *nic_data ;
  size_t outlen ;
  int rc ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  rc = efx_mcdi_rpc(efx, 236U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    8UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 7UL) {
    return (-5);
  } else {

  }
  nic_data->vf_index = ((efx_dword_t *)(& outbuf) + 1UL)->u32[0];
  return (0);
}
}
static int efx_ef10_init_datapath_caps(struct efx_nic *efx ) 
{ 
  efx_dword_t outbuf[5U] ;
  unsigned int tmp ;
  struct efx_ef10_nic_data *nic_data ;
  size_t outlen ;
  int rc ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 5U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  rc = efx_mcdi_rpc(efx, 190U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    20UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 19UL) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "unable to read datapath firmware capabilities\n");
    } else {

    }
    return (-5);
  } else {

  }
  nic_data->datapath_caps = ((efx_dword_t *)(& outbuf))->u32[0];
  nic_data->rx_dpcpu_fw_id = (unsigned int )*((__le16 const   *)(& outbuf) + 4U);
  nic_data->tx_dpcpu_fw_id = (unsigned int )*((__le16 const   *)(& outbuf) + 6U);
  if ((nic_data->datapath_caps & 2097152U) == 0U) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "current firmware does not support TSO\n");
    } else {

    }
    return (-19);
  } else {

  }
  if ((nic_data->datapath_caps & 8388608U) == 0U) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "current firmware does not support an RX prefix\n");
    } else {

    }
    return (-19);
  } else {

  }
  return (0);
}
}
static int efx_ef10_get_sysclk_freq(struct efx_nic *efx ) 
{ 
  efx_dword_t outbuf[2U] ;
  unsigned int tmp ;
  int rc ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  rc = efx_mcdi_rpc(efx, 172U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    8UL, (size_t *)0UL);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = (int )((efx_dword_t *)(& outbuf))->u32[0];
  return (rc > 0 ? rc : -34);
}
}
static int efx_ef10_get_mac_address_pf(struct efx_nic *efx , u8 *mac_address ) 
{ 
  efx_dword_t outbuf[4U] ;
  unsigned int tmp ;
  size_t outlen ;
  int rc ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 4U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  rc = efx_mcdi_rpc(efx, 85U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    16UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 15UL) {
    return (-5);
  } else {

  }
  ether_addr_copy(mac_address, (u8 const   *)(& outbuf));
  return (0);
}
}
static int efx_ef10_get_mac_address_vf(struct efx_nic *efx , u8 *mac_address ) 
{ 
  efx_dword_t inbuf[1U] ;
  efx_dword_t outbuf[63U] ;
  unsigned int tmp ;
  size_t outlen ;
  int num_addrs ;
    klee_make_symbolic(&num_addrs, sizeof(int), "num_addrs");
  int rc ;
  int __ret_warn_on ;
  long tmp___0 ;

  {
  inbuf[0].u32[0] = 0U;
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 63U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = 16777216U;
  rc = efx_mcdi_rpc(efx, 170U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)(& outbuf),
                    252UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 3UL) {
    return (-5);
  } else {

  }
  num_addrs = (int )((efx_dword_t *)(& outbuf))->u32[0];
  __ret_warn_on = num_addrs != 1;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                       241);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  ether_addr_copy(mac_address, (u8 const   *)(& outbuf) + 4U);
  return (0);
}
}
static ssize_t efx_ef10_show_link_control_flag(struct device *dev , struct device_attribute *attr ,
                                               char *buf ) 
{ 
  struct efx_nic *efx ;
  struct device  const  *__mptr ;
  void *tmp ;
  int tmp___0 ;

  {
  __mptr = (struct device  const  *)dev;
  tmp = pci_get_drvdata((struct pci_dev *)__mptr + 0xffffffffffffff68UL);
  efx = (struct efx_nic *)tmp;
  tmp___0 = sprintf(buf, "%d\n", ((efx->mcdi)->fn_flags & 2U) != 0U);
  return ((ssize_t )tmp___0);
}
}
static ssize_t efx_ef10_show_primary_flag(struct device *dev , struct device_attribute *attr ,
                                          char *buf ) 
{ 
  struct efx_nic *efx ;
  struct device  const  *__mptr ;
  void *tmp ;
  int tmp___0 ;

  {
  __mptr = (struct device  const  *)dev;
  tmp = pci_get_drvdata((struct pci_dev *)__mptr + 0xffffffffffffff68UL);
  efx = (struct efx_nic *)tmp;
  tmp___0 = sprintf(buf, "%d\n", (int )(efx->mcdi)->fn_flags & 1);
  return ((ssize_t )tmp___0);
}
}
static struct device_attribute dev_attr_link_control_flag  =    {{"link_control_flag", 292U, (_Bool)0, 0, {{{(char)0}, {(char)0}, {(char)0}, {(char)0},
                                               {(char)0}, {(char)0}, {(char)0}, {(char)0}}}},
    & efx_ef10_show_link_control_flag, (ssize_t (*)(struct device * , struct device_attribute * ,
                                                    char const   * , size_t  ))0};
static struct device_attribute dev_attr_primary_flag  =    {{"primary_flag", 292U, (_Bool)0, 0, {{{(char)0}, {(char)0}, {(char)0}, {(char)0},
                                          {(char)0}, {(char)0}, {(char)0}, {(char)0}}}},
    & efx_ef10_show_primary_flag, (ssize_t (*)(struct device * , struct device_attribute * ,
                                               char const   * , size_t  ))0};
static int efx_ef10_probe(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  struct net_device *net_dev ;
  int i ;
  int rc ;
  unsigned int __min1 ;
    klee_make_symbolic(&__min1, sizeof(int), "__min1");
  unsigned int __min2 ;
    klee_make_symbolic(&__min2, sizeof(int), "__min2");
  unsigned int tmp ;
  int __ret_warn_on ;
  long tmp___0 ;
  long tmp___1 ;
  void *tmp___2 ;
  unsigned int enabled ;
    klee_make_symbolic(&enabled, sizeof(int), "enabled");
  struct _ddebug descriptor ;
  long tmp___3 ;
  struct pci_dev *pci_dev_pf ;
  struct efx_nic *efx_pf ;
  void *tmp___4 ;

  {
  net_dev = efx->net_dev;
  __min1 = 32U;
  tmp = efx_ef10_mem_map_size(efx);
  __min2 = tmp / 32768U;
  efx->max_channels = __min1 < __min2 ? __min1 : __min2;
  __ret_warn_on = efx->max_channels == 0U;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                       291);
  } else {

  }
  tmp___1 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___1 != 0L) {
    return (-5);
  } else {

  }
  tmp___2 = kzalloc(784UL, 208U);
  nic_data = (struct efx_ef10_nic_data *)tmp___2;
  if ((unsigned long )nic_data == (unsigned long )((struct efx_ef10_nic_data *)0)) {
    return (-12);
  } else {

  }
  efx->nic_data = (void *)nic_data;
  rc = efx_nic_alloc_buffer(efx, & nic_data->mcdi_buf, 1032U, 208U);
  if (rc != 0) {
    goto fail1;
  } else {

  }
  i = 0;
  ldv_55676: 
  rc = efx_ef10_get_warm_boot_count(efx);
  if (rc >= 0) {
    goto ldv_55674;
  } else {

  }
  i = i + 1;
  if (i == 5) {
    goto fail2;
  } else {

  }
  ssleep(1U);
  goto ldv_55676;
  ldv_55674: 
  nic_data->warm_boot_count = (u16 )rc;
  nic_data->rx_rss_context = 4294967295U;
  nic_data->vport_id = 16777216U;
  _efx_writed(efx, 1U, 516U);
  rc = efx_mcdi_init(efx);
  if (rc != 0) {
    goto fail2;
  } else {

  }
  rc = efx_mcdi_reset(efx, 2);
  if (rc != 0) {
    goto fail3;
  } else {

  }
  rc = efx_mcdi_log_ctrl(efx, 1, 0, 0U);
  if (rc != 0) {
    goto fail3;
  } else {

  }
  rc = device_create_file(& (efx->pci_dev)->dev, (struct device_attribute  const  *)(& dev_attr_link_control_flag));
  if (rc != 0) {
    goto fail3;
  } else {

  }
  rc = device_create_file(& (efx->pci_dev)->dev, (struct device_attribute  const  *)(& dev_attr_primary_flag));
  if (rc != 0) {
    goto fail4;
  } else {

  }
  rc = efx_ef10_get_pf_index(efx);
  if (rc != 0) {
    goto fail5;
  } else {

  }
  rc = efx_ef10_init_datapath_caps(efx);
  if (rc < 0) {
    goto fail5;
  } else {

  }
  efx->rx_packet_len_offset = -6;
  rc = efx_mcdi_port_get_number(efx);
  if (rc < 0) {
    goto fail5;
  } else {

  }
  efx->port_num = (unsigned int )rc;
  net_dev->dev_port = (unsigned short )rc;
  rc = (*((efx->type)->get_mac_address))(efx, (unsigned char *)(& (efx->net_dev)->perm_addr));
  if (rc != 0) {
    goto fail5;
  } else {

  }
  rc = efx_ef10_get_sysclk_freq(efx);
  if (rc < 0) {
    goto fail5;
  } else {

  }
  efx->timer_quantum_ns = (unsigned int )(1536000 / rc);
  rc = efx_mcdi_set_workaround(efx, 2U, 1);
  if (rc == 0) {
    nic_data->workaround_35388 = 1;
  } else
  if (rc == -1) {
    rc = efx_mcdi_get_workarounds(efx, (unsigned int *)0U, & enabled);
    if (rc != 0) {
      goto fail3;
    } else {

    }
    nic_data->workaround_35388 = (enabled & 4U) != 0U;
  } else
  if (rc != -38 && rc != -2) {
    goto fail5;
  } else {

  }
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_ef10_probe";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
    descriptor.format = "workaround for bug 35388 is %sabled\n";
    descriptor.lineno = 401U;
    descriptor.flags = 0U;
    tmp___3 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___3 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "workaround for bug 35388 is %sabled\n", (int )nic_data->workaround_35388 ? (char *)"en" : (char *)"dis");
    } else {

    }
  } else {

  }
  rc = efx_mcdi_mon_probe(efx);
  if (rc != 0 && rc != -1) {
    goto fail5;
  } else {

  }
  efx_ptp_probe(efx, (struct efx_channel *)0);
  if ((unsigned long )(efx->pci_dev)->__annonCompField58.physfn != (unsigned long )((struct pci_dev *)0) && (unsigned int )*((unsigned char *)efx->pci_dev + 2531UL) == 0U) {
    pci_dev_pf = (efx->pci_dev)->__annonCompField58.physfn;
    tmp___4 = pci_get_drvdata(pci_dev_pf);
    efx_pf = (struct efx_nic *)tmp___4;
    (*((efx_pf->type)->get_mac_address))(efx_pf, (unsigned char *)(& nic_data->port_id));
  } else {
    ether_addr_copy((u8 *)(& nic_data->port_id), (u8 const   *)(& (efx->net_dev)->perm_addr));
  }
  return (0);
  fail5: 
  device_remove_file(& (efx->pci_dev)->dev, (struct device_attribute  const  *)(& dev_attr_primary_flag));
  fail4: 
  device_remove_file(& (efx->pci_dev)->dev, (struct device_attribute  const  *)(& dev_attr_link_control_flag));
  fail3: 
  efx_mcdi_fini(efx);
  fail2: 
  efx_nic_free_buffer(efx, & nic_data->mcdi_buf);
  fail1: 
  kfree((void const   *)nic_data);
  efx->nic_data = (void *)0;
  return (rc);
}
}
static int efx_ef10_free_vis(struct efx_nic *efx ) 
{ 
  efx_dword_t outbuf[2U] ;
  unsigned int tmp ;
  size_t outlen ;
  int rc ;
  int tmp___0 ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  tmp___0 = efx_mcdi_rpc_quiet(efx, 140U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                               8UL, & outlen);
  rc = tmp___0;
  if (rc == -114) {
    rc = 0;
  } else {

  }
  if (rc != 0) {
    efx_mcdi_display_error(efx, 140U, 0UL, (efx_dword_t *)(& outbuf), outlen, rc);
  } else {

  }
  return (rc);
}
}
static void efx_ef10_free_piobufs(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  efx_dword_t inbuf[1U] ;
  unsigned int i ;
  int rc ;
  int __ret_warn_on ;
  long tmp ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  inbuf[0].u32[0] = 0U;
  i = 0U;
  goto ldv_55703;
  ldv_55702: 
  ((efx_dword_t *)(& inbuf))->u32[0] = nic_data->piobuf_handle[i];
  rc = efx_mcdi_rpc(efx, 144U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  __ret_warn_on = rc != 0;
  tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                       467);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  i = i + 1U;
  ldv_55703: ;
  if (nic_data->n_piobufs > i) {
    goto ldv_55702;
  } else {

  }
  nic_data->n_piobufs = 0U;
  return;
}
}
static int efx_ef10_alloc_piobufs(struct efx_nic *efx , unsigned int n ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  efx_dword_t outbuf[1U] ;
  unsigned int i ;
  size_t outlen ;
  int rc ;
  struct _ddebug descriptor ;
  long tmp ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  outbuf[0].u32[0] = 0U;
  rc = 0;
  i = 0U;
  goto ldv_55722;
  ldv_55721: 
  rc = efx_mcdi_rpc(efx, 143U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    4UL, & outlen);
  if (rc != 0) {
    goto ldv_55714;
  } else {

  }
  if (outlen <= 3UL) {
    rc = -5;
    goto ldv_55714;
  } else {

  }
  nic_data->piobuf_handle[i] = ((efx_dword_t *)(& outbuf))->u32[0];
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_ef10_alloc_piobufs";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
    descriptor.format = "allocated PIO buffer %u handle %x\n";
    descriptor.lineno = 496U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "allocated PIO buffer %u handle %x\n", i, nic_data->piobuf_handle[i]);
    } else {

    }
  } else {

  }
  i = i + 1U;
  ldv_55722: ;
  if (i < n) {
    goto ldv_55721;
  } else {

  }
  ldv_55714: 
  nic_data->n_piobufs = i;
  if (rc != 0) {
    efx_ef10_free_piobufs(efx);
  } else {

  }
  return (rc);
}
}
static int efx_ef10_link_piobufs(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  int _max1 ;
  int _max2 ;
  efx_dword_t *inbuf ;
  unsigned long __lengthofinbuf ;
    klee_make_symbolic(&__lengthofinbuf, sizeof(long), "__lengthofinbuf");
  void *tmp ;
  struct efx_channel *channel ;
  struct efx_tx_queue *tx_queue ;
  unsigned int offset ;
  unsigned int index ;
  int rc ;
  int _max1___0 ;
  int _max2___0 ;
  struct _ddebug descriptor ;
  long tmp___0 ;
  long tmp___1 ;
  struct _ddebug descriptor___0 ;
  long tmp___2 ;
  bool tmp___3 ;
  bool tmp___4 ;
  int tmp___5 ;
  unsigned int tmp___6 ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  _max1 = 8;
  _max2 = 4;
  __lengthofinbuf = (unsigned long )((long )(((_max1 > _max2 ? _max1 : _max2) + 3) / 4));
  tmp = __builtin_alloca(sizeof(*inbuf) * __lengthofinbuf);
  inbuf = (efx_dword_t *)tmp;
  _max1___0 = 8;
  _max2___0 = 4;
  memset((void *)(& inbuf), 0, (unsigned long )(((_max1___0 > _max2___0 ? _max1___0 : _max2___0) + 3) / 4) * 4UL);
  index = 0U;
  goto ldv_55744;
  ldv_55743: 
  ((efx_dword_t *)(& inbuf))->u32[0] = nic_data->piobuf_handle[index];
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = nic_data->pio_write_vi_base + index;
  rc = efx_mcdi_rpc(efx, 146U, (efx_dword_t const   *)(& inbuf), 8UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  if (rc != 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to link VI %u to PIO buffer %u (%d)\n",
                 nic_data->pio_write_vi_base + index, index, rc);
    } else {

    }
    goto fail;
  } else {

  }
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_ef10_link_piobufs";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
    descriptor.format = "linked VI %u to PIO buffer %u\n";
    descriptor.lineno = 539U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "linked VI %u to PIO buffer %u\n", nic_data->pio_write_vi_base + index,
                           index);
    } else {

    }
  } else {

  }
  index = index + 1U;
  ldv_55744: ;
  if (nic_data->n_piobufs > index) {
    goto ldv_55743;
  } else {

  }
  channel = efx->channel[0];
  goto ldv_55756;
  ldv_55755: 
  tmp___4 = efx_channel_has_tx_queues(channel);
  if (tmp___4) {
    tmp___5 = 0;
  } else {
    tmp___5 = 1;
  }
  if (tmp___5) {

  } else {
    tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
    goto ldv_55753;
    ldv_55752: 
    offset = (((efx->tx_channel_offset + efx->n_tx_channels) - (unsigned int )(tx_queue->channel)->channel) - 1U) * efx_piobuf_size;
    index = offset / 2048U;
    offset = offset & 2047U;
    if (tx_queue->queue == nic_data->pio_write_vi_base) {
      tmp___1 = ldv__builtin_expect(index != 0U, 0L);
      if (tmp___1 != 0L) {
        __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c"),
                             "i" (561), "i" (12UL));
        ldv_55746: ;
        goto ldv_55746;
      } else {

      }
      rc = 0;
    } else {
      ((efx_dword_t *)(& inbuf))->u32[0] = nic_data->piobuf_handle[index];
      ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = tx_queue->queue;
      rc = efx_mcdi_rpc(efx, 146U, (efx_dword_t const   *)(& inbuf), 8UL, (efx_dword_t *)0,
                        0UL, (size_t *)0UL);
    }
    if (rc != 0) {
      if ((int )efx->msg_enable & 1) {
        netdev_err((struct net_device  const  *)efx->net_dev, "failed to link VI %u to PIO buffer %u (%d)\n",
                   tx_queue->queue, index, rc);
      } else {

      }
      tx_queue->piobuf = (void *)0;
    } else {
      tx_queue->piobuf = nic_data->pio_write_base + ((unsigned long )(index * 8192U) + (unsigned long )offset);
      tx_queue->piobuf_offset = offset;
      if ((efx->msg_enable & 2U) != 0U) {
        descriptor___0.modname = "sfc";
        descriptor___0.function = "efx_ef10_link_piobufs";
        descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
        descriptor___0.format = "linked VI %u to PIO buffer %u offset %x addr %p\n";
        descriptor___0.lineno = 592U;
        descriptor___0.flags = 0U;
        tmp___2 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
        if (tmp___2 != 0L) {
          __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                               "linked VI %u to PIO buffer %u offset %x addr %p\n",
                               tx_queue->queue, index, tx_queue->piobuf_offset, tx_queue->piobuf);
        } else {

        }
      } else {

      }
    }
    tx_queue = tx_queue + 1;
    ldv_55753: ;
    if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
      tmp___3 = efx_tx_queue_used(tx_queue);
      if ((int )tmp___3) {
        goto ldv_55752;
      } else {
        goto ldv_55754;
      }
    } else {

    }
    ldv_55754: ;
  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_55756: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_55755;
  } else {

  }

  return (0);
  fail: ;
  goto ldv_55761;
  ldv_55760: 
  ((efx_dword_t *)(& inbuf))->u32[0] = nic_data->pio_write_vi_base + index;
  efx_mcdi_rpc(efx, 147U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
               0UL, (size_t *)0UL);
  ldv_55761: 
  tmp___6 = index;
  index = index - 1U;
  if (tmp___6 != 0U) {
    goto ldv_55760;
  } else {

  }

  return (rc);
}
}
static void efx_ef10_remove(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  int rc ;
  struct efx_ef10_nic_data *nic_data_pf ;
  struct pci_dev *pci_dev_pf ;
  struct efx_nic *efx_pf ;
  struct ef10_vf *vf ;
  void *tmp ;
  int __ret_warn_on ;
  long tmp___0 ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  if ((unsigned int )*((unsigned char *)efx->pci_dev + 2531UL) != 0U) {
    pci_dev_pf = (efx->pci_dev)->__annonCompField58.physfn;
    if ((unsigned long )pci_dev_pf != (unsigned long )((struct pci_dev *)0)) {
      tmp = pci_get_drvdata(pci_dev_pf);
      efx_pf = (struct efx_nic *)tmp;
      nic_data_pf = (struct efx_ef10_nic_data *)efx_pf->nic_data;
      vf = nic_data_pf->vf + (unsigned long )nic_data->vf_index;
      vf->efx = (struct efx_nic *)0;
    } else
    if ((int )efx->msg_enable & 1) {
      netdev_info((struct net_device  const  *)efx->net_dev, "Could not get the PF id from VF\n");
    } else {

    }
  } else {

  }
  efx_ptp_remove(efx);
  efx_mcdi_mon_remove(efx);
  efx_ef10_rx_free_indir_table(efx);
  if ((unsigned long )nic_data->wc_membase != (unsigned long )((void *)0)) {
    iounmap((void volatile   *)nic_data->wc_membase);
  } else {

  }
  rc = efx_ef10_free_vis(efx);
  __ret_warn_on = rc != 0;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                       662);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (! nic_data->must_restore_piobufs) {
    efx_ef10_free_piobufs(efx);
  } else {

  }
  device_remove_file(& (efx->pci_dev)->dev, (struct device_attribute  const  *)(& dev_attr_primary_flag));
  device_remove_file(& (efx->pci_dev)->dev, (struct device_attribute  const  *)(& dev_attr_link_control_flag));
  efx_mcdi_fini(efx);
  efx_nic_free_buffer(efx, & nic_data->mcdi_buf);
  kfree((void const   *)nic_data);
  return;
}
}
static int efx_ef10_probe_pf(struct efx_nic *efx ) 
{ 
  int tmp ;

  {
  tmp = efx_ef10_probe(efx);
  return (tmp);
}
}
static int efx_ef10_probe_vf(struct efx_nic *efx ) 
{ 
  int rc ;
  struct pci_dev *pci_dev_pf ;
  struct efx_nic *efx_pf ;
  void *tmp ;
  struct efx_ef10_nic_data *nic_data_pf ;
  struct efx_nic *efx_pf___0 ;
  void *tmp___0 ;
  struct efx_ef10_nic_data *nic_data_p ;
  struct efx_ef10_nic_data *nic_data ;

  {
  pci_dev_pf = (efx->pci_dev)->__annonCompField58.physfn;
  if ((unsigned long )pci_dev_pf != (unsigned long )((struct pci_dev *)0)) {
    tmp = pci_get_drvdata(pci_dev_pf);
    efx_pf = (struct efx_nic *)tmp;
    nic_data_pf = (struct efx_ef10_nic_data *)efx_pf->nic_data;
    if ((unsigned long )nic_data_pf->vf == (unsigned long )((struct ef10_vf *)0)) {
      if ((int )efx->msg_enable & 1) {
        netdev_info((struct net_device  const  *)efx->net_dev, "The VF cannot link to its parent PF; please destroy and re-create the VF\n");
      } else {

      }
      return (-16);
    } else {

    }
  } else {

  }
  rc = efx_ef10_probe(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = efx_ef10_get_vf_index(efx);
  if (rc != 0) {
    goto fail;
  } else {

  }
  if ((unsigned int )*((unsigned char *)efx->pci_dev + 2531UL) != 0U) {
    if ((unsigned long )(efx->pci_dev)->__annonCompField58.physfn != (unsigned long )((struct pci_dev *)0)) {
      tmp___0 = pci_get_drvdata((efx->pci_dev)->__annonCompField58.physfn);
      efx_pf___0 = (struct efx_nic *)tmp___0;
      nic_data_p = (struct efx_ef10_nic_data *)efx_pf___0->nic_data;
      nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
      (nic_data_p->vf + (unsigned long )nic_data->vf_index)->efx = efx;
      (nic_data_p->vf + (unsigned long )nic_data->vf_index)->pci_dev = efx->pci_dev;
    } else
    if ((int )efx->msg_enable & 1) {
      netdev_info((struct net_device  const  *)efx->net_dev, "Could not get the PF id from VF\n");
    } else {

    }
  } else {

  }
  return (0);
  fail: 
  efx_ef10_remove(efx);
  return (rc);
}
}
static int efx_ef10_alloc_vis(struct efx_nic *efx , unsigned int min_vis , unsigned int max_vis ) 
{ 
  efx_dword_t inbuf[2U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[2U] ;
  unsigned int tmp___0 ;
  struct efx_ef10_nic_data *nic_data ;
  size_t outlen ;
  int rc ;
  struct _ddebug descriptor ;
  long tmp___1 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 2U) {
      break;
    } else {

    }
    outbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  ((efx_dword_t *)(& inbuf))->u32[0] = min_vis;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = max_vis;
  rc = efx_mcdi_rpc(efx, 139U, (efx_dword_t const   *)(& inbuf), 8UL, (efx_dword_t *)(& outbuf),
                    8UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 7UL) {
    return (-5);
  } else {

  }
  if ((int )efx->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_ef10_alloc_vis";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
    descriptor.format = "base VI is A0x%03x\n";
    descriptor.lineno = 759U;
    descriptor.flags = 0U;
    tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___1 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "base VI is A0x%03x\n", ((efx_dword_t *)(& outbuf) + 1UL)->u32[0]);
    } else {

    }
  } else {

  }
  nic_data->vi_base = ((efx_dword_t *)(& outbuf) + 1UL)->u32[0];
  nic_data->n_allocated_vis = ((efx_dword_t *)(& outbuf))->u32[0];
  return (0);
}
}
static int efx_ef10_dimension_resources(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  unsigned int uc_mem_map_size ;
    klee_make_symbolic(&uc_mem_map_size, sizeof(int), "uc_mem_map_size");
  unsigned int wc_mem_map_size ;
    klee_make_symbolic(&wc_mem_map_size, sizeof(int), "wc_mem_map_size");
  unsigned int min_vis ;
    klee_make_symbolic(&min_vis, sizeof(int), "min_vis");
  unsigned int pio_write_vi_base ;
  unsigned int max_vis ;
    klee_make_symbolic(&max_vis, sizeof(int), "max_vis");
  void *membase ;
  int rc ;
  unsigned int _max1 ;
  unsigned int _max2 ;
  unsigned int n_piobufs ;
  struct _ddebug descriptor ;
  long tmp ;
  struct _ddebug descriptor___0 ;
  long tmp___0 ;
  struct _ddebug descriptor___1 ;
  long tmp___1 ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  _max1 = efx->n_channels;
  _max2 = efx->n_tx_channels * 4U;
  min_vis = _max1 > _max2 ? _max1 : _max2;
  if (efx_piobuf_size != 0U && (2048U / efx_piobuf_size) * 16U >= efx->n_tx_channels) {
    n_piobufs = ((efx->n_tx_channels + 2048U / efx_piobuf_size) - 1U) / (2048U / efx_piobuf_size);
    rc = efx_ef10_alloc_piobufs(efx, n_piobufs);
    if (rc != 0) {
      if ((efx->msg_enable & 2U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "failed to allocate PIO buffers (%d)\n",
                   rc);
      } else {

      }
    } else
    if ((efx->msg_enable & 2U) != 0U) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_ef10_dimension_resources";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
      descriptor.format = "allocated %u PIO buffers\n";
      descriptor.lineno = 799U;
      descriptor.flags = 0U;
      tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "allocated %u PIO buffers\n", n_piobufs);
      } else {

      }
    } else {

    }
  } else {

  }
  uc_mem_map_size = ((min_vis + 524287U) * 8192U + 8191U) & 4294963200U;
  if (nic_data->n_piobufs != 0U) {
    pio_write_vi_base = uc_mem_map_size / 8192U;
    wc_mem_map_size = (((nic_data->n_piobufs + pio_write_vi_base) * 8192U + 4095U) & 4294963200U) - uc_mem_map_size;
    max_vis = nic_data->n_piobufs + pio_write_vi_base;
  } else {
    pio_write_vi_base = 0U;
    wc_mem_map_size = 0U;
    max_vis = min_vis;
  }
  rc = efx_ef10_free_vis(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = efx_ef10_alloc_vis(efx, min_vis, max_vis);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (nic_data->n_piobufs != 0U && nic_data->n_allocated_vis < nic_data->n_piobufs + pio_write_vi_base) {
    if ((efx->msg_enable & 2U) != 0U) {
      descriptor___0.modname = "sfc";
      descriptor___0.function = "efx_ef10_dimension_resources";
      descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
      descriptor___0.format = "%u VIs are not sufficient to map %u PIO buffers\n";
      descriptor___0.lineno = 850U;
      descriptor___0.flags = 0U;
      tmp___0 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
      if (tmp___0 != 0L) {
        __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                             "%u VIs are not sufficient to map %u PIO buffers\n",
                             nic_data->n_allocated_vis, nic_data->n_piobufs);
      } else {

      }
    } else {

    }
    efx_ef10_free_piobufs(efx);
  } else {

  }
  membase = ioremap_nocache(efx->membase_phys, (unsigned long )uc_mem_map_size);
  if ((unsigned long )membase == (unsigned long )((void *)0)) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "could not shrink memory BAR to %x\n",
                 uc_mem_map_size);
    } else {

    }
    return (-12);
  } else {

  }
  iounmap((void volatile   *)efx->membase);
  efx->membase = membase;
  if (wc_mem_map_size != 0U) {
    nic_data->wc_membase = ioremap_wc(efx->membase_phys + (resource_size_t )uc_mem_map_size,
                                      (unsigned long )wc_mem_map_size);
    if ((unsigned long )nic_data->wc_membase == (unsigned long )((void *)0)) {
      if ((efx->msg_enable & 2U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "could not allocate WC mapping of size %x\n",
                   wc_mem_map_size);
      } else {

      }
      return (-12);
    } else {

    }
    nic_data->pio_write_vi_base = pio_write_vi_base;
    nic_data->pio_write_base = nic_data->wc_membase + (unsigned long )((pio_write_vi_base * 8192U - uc_mem_map_size) + 4096U);
    rc = efx_ef10_link_piobufs(efx);
    if (rc != 0) {
      efx_ef10_free_piobufs(efx);
    } else {

    }
  } else {

  }
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor___1.modname = "sfc";
    descriptor___1.function = "efx_ef10_dimension_resources";
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
    descriptor___1.format = "memory BAR at %pa (virtual %p+%x UC, %p+%x WC)\n";
    descriptor___1.lineno = 890U;
    descriptor___1.flags = 0U;
    tmp___1 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
    if (tmp___1 != 0L) {
      __dynamic_netdev_dbg(& descriptor___1, (struct net_device  const  *)efx->net_dev,
                           "memory BAR at %pa (virtual %p+%x UC, %p+%x WC)\n", & efx->membase_phys,
                           efx->membase, uc_mem_map_size, nic_data->wc_membase, wc_mem_map_size);
    } else {

    }
  } else {

  }
  return (0);
}
}
static int efx_ef10_init_nic(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  int rc ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  if ((int )nic_data->must_check_datapath_caps) {
    rc = efx_ef10_init_datapath_caps(efx);
    if (rc != 0) {
      return (rc);
    } else {

    }
    nic_data->must_check_datapath_caps = 0;
  } else {

  }
  if ((int )nic_data->must_realloc_vis) {
    rc = efx_ef10_alloc_vis(efx, nic_data->n_allocated_vis, nic_data->n_allocated_vis);
    if (rc != 0) {
      return (rc);
    } else {

    }
    nic_data->must_realloc_vis = 0;
  } else {

  }
  if ((int )nic_data->must_restore_piobufs && nic_data->n_piobufs != 0U) {
    rc = efx_ef10_alloc_piobufs(efx, nic_data->n_piobufs);
    if (rc == 0) {
      rc = efx_ef10_link_piobufs(efx);
      if (rc != 0) {
        efx_ef10_free_piobufs(efx);
      } else {

      }
    } else {

    }
    if (rc != 0) {
      if ((int )efx->msg_enable & 1) {
        netdev_err((struct net_device  const  *)efx->net_dev, "failed to restore PIO buffers (%d)\n",
                   rc);
      } else {

      }
    } else {

    }
    nic_data->must_restore_piobufs = 0;
  } else {

  }
  (*((efx->type)->rx_push_rss_config))(efx, 0, (u32 const   *)(& efx->rx_indir_table));
  return (0);
}
}
static void efx_ef10_reset_mc_allocations(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  nic_data->must_realloc_vis = 1;
  nic_data->must_restore_filters = 1;
  nic_data->must_restore_piobufs = 1;
  nic_data->rx_rss_context = 4294967295U;
  return;
}
}
static enum reset_type efx_ef10_map_reset_reason(enum reset_type reason ) 
{ 
  enum reset_type tmp ;

  {
  if ((unsigned int )reason == 14U) {
    return (5);
  } else {

  }
  tmp = efx_mcdi_map_reset_reason(reason);
  return (tmp);
}
}
static int efx_ef10_map_reset_flags(u32 *flags ) 
{ 


  {
  if ((*flags & 8192000U) == 8192000U) {
    *flags = *flags & 4286775295U;
    return (3);
  } else {

  }
  if ((*flags & 6291456U) == 6291456U) {
    *flags = *flags & 4288675839U;
    return (2);
  } else {

  }
  return (-22);
}
}
static int efx_ef10_reset(struct efx_nic *efx , enum reset_type reset_type ) 
{ 
  int rc ;
  int tmp ;

  {
  tmp = efx_mcdi_reset(efx, reset_type);
  rc = tmp;
  if (((unsigned int )reset_type == 2U || (unsigned int )reset_type == 15U) && rc == 0) {
    efx_ef10_reset_mc_allocations(efx);
  } else {

  }
  return (rc);
}
}
static struct efx_hw_stat_desc  const  efx_ef10_stat_desc[73U]  = 
  {      {"rx_noskb_drops", 0U, 0U}, 
        {"rx_nodesc_trunc", 0U, 0U}, 
        {"port_tx_bytes", 64U, 56U}, 
        {"port_tx_packets", 64U, 8U}, 
        {"port_tx_pause", 64U, 16U}, 
        {"port_tx_control", 64U, 24U}, 
        {"port_tx_unicast", 64U, 32U}, 
        {"port_tx_multicast", 64U, 40U}, 
        {"port_tx_broadcast", 64U, 48U}, 
        {"port_tx_lt64", 64U, 72U}, 
        {"port_tx_64", 64U, 80U}, 
        {"port_tx_65_to_127", 64U, 88U}, 
        {"port_tx_128_to_255", 64U, 96U}, 
        {"port_tx_256_to_511", 64U, 104U}, 
        {"port_tx_512_to_1023", 64U, 112U}, 
        {"port_tx_1024_to_15xx", 64U, 120U}, 
        {"port_tx_15xx_to_jumbo", 64U, 128U}, 
        {"port_rx_bytes", 64U, 280U}, 
        {(char const   *)0, 64U, 288U}, 
        {"port_rx_good_bytes", 0U, 0U}, 
        {"port_rx_bad_bytes", 0U, 0U}, 
        {"port_rx_packets", 64U, 224U}, 
        {"port_rx_good", 64U, 240U}, 
        {"port_rx_bad", 64U, 368U}, 
        {"port_rx_pause", 64U, 232U}, 
        {"port_rx_control", 64U, 248U}, 
        {"port_rx_unicast", 64U, 256U}, 
        {"port_rx_multicast", 64U, 264U}, 
        {"port_rx_broadcast", 64U, 272U}, 
        {"port_rx_lt64", 64U, 360U}, 
        {"port_rx_64", 64U, 296U}, 
        {"port_rx_65_to_127", 64U, 304U}, 
        {"port_rx_128_to_255", 64U, 312U}, 
        {"port_rx_256_to_511", 64U, 320U}, 
        {"port_rx_512_to_1023", 64U, 328U}, 
        {"port_rx_1024_to_15xx", 64U, 336U}, 
        {"port_rx_15xx_to_jumbo", 64U, 344U}, 
        {"port_rx_gtjumbo", 64U, 352U}, 
        {"port_rx_bad_gtjumbo", 64U, 424U}, 
        {"port_rx_overflow", 64U, 376U}, 
        {"port_rx_align_error", 64U, 400U}, 
        {"port_rx_length_error", 64U, 408U}, 
        {"port_rx_nodesc_drops", 64U, 432U}, 
        {"port_rx_pm_trunc_bb_overflow", 64U, 480U}, 
        {"port_rx_pm_discard_bb_overflow", 64U, 488U}, 
        {"port_rx_pm_trunc_vfifo_full", 64U, 496U}, 
        {"port_rx_pm_discard_vfifo_full", 64U, 504U}, 
        {"port_rx_pm_trunc_qbb", 64U, 512U}, 
        {"port_rx_pm_discard_qbb", 64U, 520U}, 
        {"port_rx_pm_discard_mapping", 64U, 528U}, 
        {"port_rx_dp_q_disabled_packets", 64U, 536U}, 
        {"port_rx_dp_di_dropped_packets", 64U, 552U}, 
        {"port_rx_dp_streaming_packets", 64U, 560U}, 
        {"port_rx_dp_hlb_fetch", 64U, 568U}, 
        {"port_rx_dp_hlb_wait", 64U, 576U}, 
        {"rx_unicast", 64U, 608U}, 
        {"rx_unicast_bytes", 64U, 616U}, 
        {"rx_multicast", 64U, 624U}, 
        {"rx_multicast_bytes", 64U, 632U}, 
        {"rx_broadcast", 64U, 640U}, 
        {"rx_broadcast_bytes", 64U, 648U}, 
        {"rx_bad", 64U, 656U}, 
        {"rx_bad_bytes", 64U, 664U}, 
        {"rx_overflow", 64U, 672U}, 
        {"tx_unicast", 64U, 696U}, 
        {"tx_unicast_bytes", 64U, 704U}, 
        {"tx_multicast", 64U, 712U}, 
        {"tx_multicast_bytes", 64U, 720U}, 
        {"tx_broadcast", 64U, 728U}, 
        {"tx_broadcast_bytes", 64U, 736U}, 
        {"tx_bad", 64U, 744U}, 
        {"tx_bad_bytes", 64U, 752U}, 
        {"tx_overflow", 64U, 760U}};
static u64 efx_ef10_raw_stat_mask(struct efx_nic *efx ) 
{ 
  u64 raw_mask ;
  u32 port_caps ;
  u32 tmp ;
  struct efx_ef10_nic_data *nic_data ;

  {
  raw_mask = 5497558008287ULL;
  tmp = efx_mcdi_phy_get_caps(efx);
  port_caps = tmp;
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  if (((efx->mcdi)->fn_flags & 2U) == 0U) {
    return (0ULL);
  } else {

  }
  if ((port_caps & 2048U) != 0U) {
    raw_mask = raw_mask | 3298534883328ULL;
  } else {
    raw_mask = raw_mask | 130592ULL;
  }
  if ((nic_data->datapath_caps & 134217728U) != 0U) {
    raw_mask = raw_mask | 36020000925941760ULL;
  } else {

  }
  return (raw_mask);
}
}
static void efx_ef10_get_stat_mask(struct efx_nic *efx , unsigned long *mask ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  u64 raw_mask[2U] ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  raw_mask[0] = efx_ef10_raw_stat_mask(efx);
  if ((nic_data->datapath_caps & 1073741824U) != 0U) {
    raw_mask[0] = raw_mask[0] | 0xff80000000000000ULL;
    raw_mask[1] = 1023ULL;
  } else {
    raw_mask[1] = 0ULL;
  }
  *mask = (unsigned long )raw_mask[0];
  *(mask + 1UL) = (unsigned long )raw_mask[1];
  return;
}
}
static size_t efx_ef10_describe_stats(struct efx_nic *efx , u8 *names ) 
{ 
  unsigned long mask[2U] ;
  size_t tmp ;

  {
  efx_ef10_get_stat_mask(efx, (unsigned long *)(& mask));
  tmp = efx_nic_describe_stats((struct efx_hw_stat_desc  const  *)(& efx_ef10_stat_desc),
                               73UL, (unsigned long const   *)(& mask), names);
  return (tmp);
}
}
static size_t efx_ef10_update_stats_common(struct efx_nic *efx , u64 *full_stats ,
                                           struct rtnl_link_stats64 *core_stats ) 
{ 
  unsigned long mask[2U] ;
  struct efx_ef10_nic_data *nic_data ;
  u64 *stats ;
  size_t stats_count ;
  size_t index ;
  u64 *tmp ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  stats = (u64 *)(& nic_data->stats);
  stats_count = 0UL;
  efx_ef10_get_stat_mask(efx, (unsigned long *)(& mask));
  if ((unsigned long )full_stats != (unsigned long )((u64 *)0ULL)) {
    index = find_first_bit((unsigned long const   *)(& mask), 73UL);
    goto ldv_55887;
    ldv_55886: ;
    if ((unsigned long )efx_ef10_stat_desc[index].name != (unsigned long )((char const   */* const  */)0)) {
      tmp = full_stats;
      full_stats = full_stats + 1;
      *tmp = *(stats + index);
      stats_count = stats_count + 1UL;
    } else {

    }
    index = find_next_bit((unsigned long const   *)(& mask), 73UL, index + 1UL);
    ldv_55887: ;
    if (index <= 72UL) {
      goto ldv_55886;
    } else {

    }

  } else {

  }
  if ((unsigned long )core_stats != (unsigned long )((struct rtnl_link_stats64 *)0)) {
    core_stats->rx_packets = (*(stats + 55UL) + *(stats + 57UL)) + *(stats + 59UL);
    core_stats->tx_packets = (*(stats + 64UL) + *(stats + 66UL)) + *(stats + 68UL);
    core_stats->rx_bytes = (*(stats + 56UL) + *(stats + 58UL)) + *(stats + 60UL);
    core_stats->tx_bytes = (*(stats + 65UL) + *(stats + 67UL)) + *(stats + 69UL);
    core_stats->rx_dropped = *(stats + 1UL) + *stats;
    core_stats->multicast = *(stats + 57UL);
    core_stats->rx_crc_errors = *(stats + 61UL);
    core_stats->rx_fifo_errors = *(stats + 63UL);
    core_stats->rx_errors = core_stats->rx_crc_errors;
    core_stats->tx_errors = *(stats + 70UL);
  } else {

  }
  return (stats_count);
}
}
static int efx_ef10_try_update_nic_stats_pf(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  unsigned long mask[2U] ;
  __le64 generation_start ;
  __le64 generation_end ;
  u64 *stats ;
  __le64 *dma_stats ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  stats = (u64 *)(& nic_data->stats);
  efx_ef10_get_stat_mask(efx, (unsigned long *)(& mask));
  dma_stats = (__le64 *)efx->stats_buffer.addr;
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  generation_end = *(dma_stats + 96UL);
  if (generation_end == 0xffffffffffffffffULL) {
    return (0);
  } else {

  }
  __asm__  volatile   ("lfence": : : "memory");
  efx_nic_update_stats((struct efx_hw_stat_desc  const  *)(& efx_ef10_stat_desc),
                       73UL, (unsigned long const   *)(& mask), stats, (void const   *)efx->stats_buffer.addr,
                       0);
  __asm__  volatile   ("lfence": : : "memory");
  generation_start = *dma_stats;
  if (generation_end != generation_start) {
    return (-11);
  } else {

  }
  efx_nic_fix_nodesc_drop_stat(efx, stats + 42UL);
  *(stats + 19UL) = *(stats + 17UL) - *(stats + 18UL);
  efx_update_diff_stat(stats + 20UL, *(stats + 18UL));
  efx_update_sw_stats(efx, stats);
  return (0);
}
}
static size_t efx_ef10_update_stats_pf(struct efx_nic *efx , u64 *full_stats , struct rtnl_link_stats64 *core_stats ) 
{ 
  int retry ;
  int tmp ;
  size_t tmp___0 ;

  {
  retry = 0;
  goto ldv_55906;
  ldv_55905: 
  tmp = efx_ef10_try_update_nic_stats_pf(efx);
  if (tmp == 0) {
    goto ldv_55904;
  } else {

  }
  __const_udelay(429500UL);
  retry = retry + 1;
  ldv_55906: ;
  if (retry <= 99) {
    goto ldv_55905;
  } else {

  }
  ldv_55904: 
  tmp___0 = efx_ef10_update_stats_common(efx, full_stats, core_stats);
  return (tmp___0);
}
}
static int efx_ef10_try_update_nic_stats_vf(struct efx_nic *efx ) 
{ 
  efx_dword_t inbuf[5U] ;
  unsigned int tmp ;
  struct efx_ef10_nic_data *nic_data ;
  unsigned long mask[2U] ;
  __le64 generation_start ;
  __le64 generation_end ;
  u64 *stats ;
  u32 dma_len ;
  struct efx_buffer stats_buf ;
  __le64 *dma_stats ;
  int rc ;
  int tmp___0 ;
  int tmp___1 ;
  bool __warned ;
  int __ret_warn_once ;
  int __ret_warn_on ;
  long tmp___2 ;
  long tmp___3 ;
  long tmp___4 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 5U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  stats = (u64 *)(& nic_data->stats);
  dma_len = 776U;
  spin_unlock_bh(& efx->stats_lock);
  tmp___0 = preempt_count();
  if (((unsigned long )tmp___0 & 2096896UL) != 0UL) {
    spin_lock_bh(& efx->stats_lock);
    efx_update_sw_stats(efx, stats);
    return (0);
  } else {

  }
  efx_ef10_get_stat_mask(efx, (unsigned long *)(& mask));
  rc = efx_nic_alloc_buffer(efx, & stats_buf, dma_len, 32U);
  if (rc != 0) {
    spin_lock_bh(& efx->stats_lock);
    return (rc);
  } else {

  }
  dma_stats = (__le64 *)stats_buf.addr;
  *(dma_stats + 96UL) = 0xffffffffffffffffULL;
  ((efx_dword_t *)(& inbuf))->u32[0] = (unsigned int )stats_buf.dma_addr;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )(stats_buf.dma_addr >> 32);
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = 1U;
  ((efx_dword_t *)(& inbuf) + 3UL)->u32[0] = dma_len;
  ((efx_dword_t *)(& inbuf) + 4UL)->u32[0] = 16777216U;
  rc = efx_mcdi_rpc_quiet(efx, 46U, (efx_dword_t const   *)(& inbuf), 20UL, (efx_dword_t *)0,
                          0UL, (size_t *)0UL);
  spin_lock_bh(& efx->stats_lock);
  if (rc != 0) {
    if (rc != -2) {
      efx_mcdi_display_error(efx, 46U, 20UL, (efx_dword_t *)0, 0UL, rc);
    } else {
      tmp___1 = atomic_read((atomic_t const   *)(& efx->active_queues));
      if (tmp___1 != 0) {
        efx_mcdi_display_error(efx, 46U, 20UL, (efx_dword_t *)0, 0UL, rc);
      } else {

      }
    }
    goto out;
  } else {

  }
  generation_end = *(dma_stats + 96UL);
  if (generation_end == 0xffffffffffffffffULL) {
    __ret_warn_once = 1;
    tmp___4 = ldv__builtin_expect(__ret_warn_once != 0, 0L);
    if (tmp___4 != 0L) {
      __ret_warn_on = ! __warned;
      tmp___2 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
      if (tmp___2 != 0L) {
        warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                           1370);
      } else {

      }
      tmp___3 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
      if (tmp___3 != 0L) {
        __warned = 1;
      } else {

      }
    } else {

    }
    ldv__builtin_expect(__ret_warn_once != 0, 0L);
    goto out;
  } else {

  }
  __asm__  volatile   ("lfence": : : "memory");
  efx_nic_update_stats((struct efx_hw_stat_desc  const  *)(& efx_ef10_stat_desc),
                       73UL, (unsigned long const   *)(& mask), stats, (void const   *)stats_buf.addr,
                       0);
  __asm__  volatile   ("lfence": : : "memory");
  generation_start = *dma_stats;
  if (generation_end != generation_start) {
    rc = -11;
    goto out;
  } else {

  }
  efx_update_sw_stats(efx, stats);
  out: 
  efx_nic_free_buffer(efx, & stats_buf);
  return (rc);
}
}
static size_t efx_ef10_update_stats_vf(struct efx_nic *efx , u64 *full_stats , struct rtnl_link_stats64 *core_stats ) 
{ 
  int tmp ;
  size_t tmp___0 ;

  {
  tmp = efx_ef10_try_update_nic_stats_vf(efx);
  if (tmp != 0) {
    return (0UL);
  } else {

  }
  tmp___0 = efx_ef10_update_stats_common(efx, full_stats, core_stats);
  return (tmp___0);
}
}
static void efx_ef10_push_irq_moderation(struct efx_channel *channel ) 
{ 
  struct efx_nic *efx ;
  unsigned int mode ;
  unsigned int value ;
  efx_dword_t timer_cmd ;

  {
  efx = channel->efx;
  if (channel->irq_moderation != 0U) {
    mode = 3U;
    value = channel->irq_moderation - 1U;
  } else {
    mode = 0U;
    value = 0U;
  }
  if ((int )((struct efx_ef10_nic_data *)efx->nic_data)->workaround_35388) {
    timer_cmd.u32[0] = ((mode << 8) | value) | 3072U;
    _efx_writed_page(efx, (efx_dword_t const   *)(& timer_cmd), 2584U, (unsigned int )channel->channel);
  } else {
    timer_cmd.u32[0] = (mode << 14) | value;
    _efx_writed_page(efx, (efx_dword_t const   *)(& timer_cmd), 1056U, (unsigned int )channel->channel);
  }
  return;
}
}
static void efx_ef10_get_wol_vf(struct efx_nic *efx , struct ethtool_wolinfo *wol ) 
{ 


  {
  return;
}
}
static int efx_ef10_set_wol_vf(struct efx_nic *efx , u32 type ) 
{ 


  {
  return (-95);
}
}
static void efx_ef10_get_wol(struct efx_nic *efx , struct ethtool_wolinfo *wol ) 
{ 


  {
  wol->supported = 0U;
  wol->wolopts = 0U;
  memset((void *)(& wol->sopass), 0, 6UL);
  return;
}
}
static int efx_ef10_set_wol(struct efx_nic *efx , u32 type ) 
{ 


  {
  if (type != 0U) {
    return (-22);
  } else {

  }
  return (0);
}
}
static void efx_ef10_mcdi_request(struct efx_nic *efx , efx_dword_t const   *hdr ,
                                  size_t hdr_len , efx_dword_t const   *sdu , size_t sdu_len ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  u8 *pdu ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  pdu = (u8 *)nic_data->mcdi_buf.addr;
  memcpy((void *)pdu, (void const   *)hdr, hdr_len);
  memcpy((void *)(pdu + hdr_len), (void const   *)sdu, sdu_len);
  __asm__  volatile   ("sfence": : : "memory");
  _efx_writed(efx, (unsigned int )(nic_data->mcdi_buf.dma_addr >> 32), 512U);
  _efx_writed(efx, (unsigned int )nic_data->mcdi_buf.dma_addr, 516U);
  return;
}
}
static bool efx_ef10_mcdi_poll_response(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  efx_dword_t hdr ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  hdr = *((efx_dword_t const   *)nic_data->mcdi_buf.addr);
  __asm__  volatile   ("lfence": : : "memory");
  return (((hdr.u32[0] >> 23) & 1U) != 0U);
}
}
static void efx_ef10_mcdi_read_response(struct efx_nic *efx , efx_dword_t *outbuf ,
                                        size_t offset , size_t outlen ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  u8 const   *pdu ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  pdu = (u8 const   *)nic_data->mcdi_buf.addr;
  memcpy((void *)outbuf, (void const   *)(pdu + offset), outlen);
  return;
}
}
static int efx_ef10_mcdi_poll_reboot(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  int rc ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  rc = efx_ef10_get_warm_boot_count(efx);
  if (rc < 0) {
    return (0);
  } else {

  }
  if ((int )nic_data->warm_boot_count == rc) {
    return (0);
  } else {

  }
  nic_data->warm_boot_count = (u16 )rc;
  efx_ef10_reset_mc_allocations(efx);
  nic_data->must_probe_vswitching = 1;
  nic_data->vport_id = 16777216U;
  nic_data->must_check_datapath_caps = 1;
  nic_data->stats[20] = 0ULL;
  return (-5);
}
}
static irqreturn_t efx_ef10_msi_interrupt(int irq , void *dev_id ) 
{ 
  struct efx_msi_context *context ;
  struct efx_nic *efx ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  int pscr_ret_____0 ;
  void const   *__vpp_verify___0 ;
  int pfo_ret_____3 ;
  int pfo_ret_____4 ;
  int pfo_ret_____5 ;
  int pfo_ret_____6 ;
  bool __var ;
  long tmp ;

  {
  context = (struct efx_msi_context *)dev_id;
  efx = context->efx;
  if (0) {
    if ((efx->msg_enable & 512U) != 0U) {
      __vpp_verify = (void const   *)0;
      switch (4UL) {
      case 1UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
      goto ldv_56006;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_56006;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_56006;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_56006;
      default: 
      __bad_percpu_size();
      }
      ldv_56006: 
      pscr_ret__ = pfo_ret__;
      goto ldv_56012;
      case 2UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_56016;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_56016;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_56016;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_56016;
      default: 
      __bad_percpu_size();
      }
      ldv_56016: 
      pscr_ret__ = pfo_ret_____0;
      goto ldv_56012;
      case 4UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_56025;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_56025;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_56025;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_56025;
      default: 
      __bad_percpu_size();
      }
      ldv_56025: 
      pscr_ret__ = pfo_ret_____1;
      goto ldv_56012;
      case 8UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_56034;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_56034;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_56034;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_56034;
      default: 
      __bad_percpu_size();
      }
      ldv_56034: 
      pscr_ret__ = pfo_ret_____2;
      goto ldv_56012;
      default: 
      __bad_size_call_parameter();
      goto ldv_56012;
      }
      ldv_56012: 
      netdev_printk("\017", (struct net_device  const  *)efx->net_dev, "IRQ %d on CPU %d\n",
                    irq, pscr_ret__);
    } else {

    }
  } else {

  }
  __var = 0;
  tmp = ldv__builtin_expect((long )*((bool volatile   *)(& efx->irq_soft_enabled)), 1L);
  if (tmp != 0L) {
    if (context->index == efx->irq_level) {
      __vpp_verify___0 = (void const   *)0;
      switch (4UL) {
      case 1UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____3): "m" (cpu_number));
      goto ldv_56050;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
      goto ldv_56050;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
      goto ldv_56050;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
      goto ldv_56050;
      default: 
      __bad_percpu_size();
      }
      ldv_56050: 
      pscr_ret_____0 = pfo_ret_____3;
      goto ldv_56056;
      case 2UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____4): "m" (cpu_number));
      goto ldv_56060;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
      goto ldv_56060;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
      goto ldv_56060;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
      goto ldv_56060;
      default: 
      __bad_percpu_size();
      }
      ldv_56060: 
      pscr_ret_____0 = pfo_ret_____4;
      goto ldv_56056;
      case 4UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____5): "m" (cpu_number));
      goto ldv_56069;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
      goto ldv_56069;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
      goto ldv_56069;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
      goto ldv_56069;
      default: 
      __bad_percpu_size();
      }
      ldv_56069: 
      pscr_ret_____0 = pfo_ret_____5;
      goto ldv_56056;
      case 8UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____6): "m" (cpu_number));
      goto ldv_56078;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
      goto ldv_56078;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
      goto ldv_56078;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
      goto ldv_56078;
      default: 
      __bad_percpu_size();
      }
      ldv_56078: 
      pscr_ret_____0 = pfo_ret_____6;
      goto ldv_56056;
      default: 
      __bad_size_call_parameter();
      goto ldv_56056;
      }
      ldv_56056: 
      efx->last_irq_cpu = pscr_ret_____0;
    } else {

    }
    efx_schedule_channel_irq___1(efx->channel[context->index]);
  } else {

  }
  return (1);
}
}
static irqreturn_t efx_ef10_legacy_interrupt(int irq , void *dev_id ) 
{ 
  struct efx_nic *efx ;
  bool soft_enabled ;
  bool __var ;
  struct efx_channel *channel ;
  efx_dword_t reg ;
  u32 queues ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  long tmp ;
  int pscr_ret_____0 ;
  void const   *__vpp_verify___0 ;
  int pfo_ret_____3 ;
  int pfo_ret_____4 ;
  int pfo_ret_____5 ;
  int pfo_ret_____6 ;

  {
  efx = (struct efx_nic *)dev_id;
  __var = 0;
  soft_enabled = *((bool volatile   *)(& efx->irq_soft_enabled));
  efx_readd(efx, & reg, 144U);
  queues = reg.u32[0];
  if (queues == 0U) {
    return (0);
  } else {

  }
  tmp = ldv__builtin_expect((long )soft_enabled, 1L);
  if (tmp != 0L) {
    if (((1U << (int )efx->irq_level) & queues) != 0U) {
      __vpp_verify = (void const   *)0;
      switch (4UL) {
      case 1UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
      goto ldv_56102;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_56102;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_56102;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
      goto ldv_56102;
      default: 
      __bad_percpu_size();
      }
      ldv_56102: 
      pscr_ret__ = pfo_ret__;
      goto ldv_56108;
      case 2UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_56112;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_56112;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_56112;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
      goto ldv_56112;
      default: 
      __bad_percpu_size();
      }
      ldv_56112: 
      pscr_ret__ = pfo_ret_____0;
      goto ldv_56108;
      case 4UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_56121;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_56121;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_56121;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
      goto ldv_56121;
      default: 
      __bad_percpu_size();
      }
      ldv_56121: 
      pscr_ret__ = pfo_ret_____1;
      goto ldv_56108;
      case 8UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_56130;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_56130;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_56130;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
      goto ldv_56130;
      default: 
      __bad_percpu_size();
      }
      ldv_56130: 
      pscr_ret__ = pfo_ret_____2;
      goto ldv_56108;
      default: 
      __bad_size_call_parameter();
      goto ldv_56108;
      }
      ldv_56108: 
      efx->last_irq_cpu = pscr_ret__;
    } else {

    }
    channel = efx->channel[0];
    goto ldv_56139;
    ldv_56138: ;
    if ((int )queues & 1) {
      efx_schedule_channel_irq___1(channel);
    } else {

    }
    queues = queues >> 1;
    channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
    ldv_56139: ;
    if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
      goto ldv_56138;
    } else {

    }

  } else {

  }
  if (0) {
    if ((efx->msg_enable & 512U) != 0U) {
      __vpp_verify___0 = (void const   *)0;
      switch (4UL) {
      case 1UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____3): "m" (cpu_number));
      goto ldv_56146;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
      goto ldv_56146;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
      goto ldv_56146;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____3): "m" (cpu_number));
      goto ldv_56146;
      default: 
      __bad_percpu_size();
      }
      ldv_56146: 
      pscr_ret_____0 = pfo_ret_____3;
      goto ldv_56152;
      case 2UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____4): "m" (cpu_number));
      goto ldv_56156;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
      goto ldv_56156;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
      goto ldv_56156;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____4): "m" (cpu_number));
      goto ldv_56156;
      default: 
      __bad_percpu_size();
      }
      ldv_56156: 
      pscr_ret_____0 = pfo_ret_____4;
      goto ldv_56152;
      case 4UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____5): "m" (cpu_number));
      goto ldv_56165;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
      goto ldv_56165;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
      goto ldv_56165;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____5): "m" (cpu_number));
      goto ldv_56165;
      default: 
      __bad_percpu_size();
      }
      ldv_56165: 
      pscr_ret_____0 = pfo_ret_____5;
      goto ldv_56152;
      case 8UL: ;
      switch (4UL) {
      case 1UL: 
      __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____6): "m" (cpu_number));
      goto ldv_56174;
      case 2UL: 
      __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
      goto ldv_56174;
      case 4UL: 
      __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
      goto ldv_56174;
      case 8UL: 
      __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____6): "m" (cpu_number));
      goto ldv_56174;
      default: 
      __bad_percpu_size();
      }
      ldv_56174: 
      pscr_ret_____0 = pfo_ret_____6;
      goto ldv_56152;
      default: 
      __bad_size_call_parameter();
      goto ldv_56152;
      }
      ldv_56152: 
      netdev_printk("\017", (struct net_device  const  *)efx->net_dev, "IRQ %d on CPU %d status %08x\n",
                    irq, pscr_ret_____0, reg.u32[0]);
    } else {

    }
  } else {

  }
  return (1);
}
}
static void efx_ef10_irq_test_generate(struct efx_nic *efx ) 
{ 
  efx_dword_t inbuf[1U] ;

  {
  inbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = efx->irq_level;
  efx_mcdi_rpc(efx, 227U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
               0UL, (size_t *)0UL);
  return;
}
}
static int efx_ef10_tx_probe(struct efx_tx_queue *tx_queue ) 
{ 
  int tmp ;

  {
  tmp = efx_nic_alloc_buffer(tx_queue->efx, & tx_queue->txd.buf, (tx_queue->ptr_mask + 1U) * 8U,
                             208U);
  return (tmp);
}
}
__inline static void efx_ef10_push_tx_desc(struct efx_tx_queue *tx_queue , efx_qword_t const   *txd ) 
{ 
  unsigned int write_ptr ;
  efx_oword_t reg ;

  {
  write_ptr = tx_queue->write_count & tx_queue->ptr_mask;
  reg.u64[0] = 0ULL;
  reg.u64[1] = (unsigned long long )write_ptr;
  reg.qword[0] = *txd;
  _efx_writeo_page(tx_queue->efx, & reg, 2576U, tx_queue->queue);
  return;
}
}
static void efx_ef10_tx_init(struct efx_tx_queue *tx_queue ) 
{ 
  efx_dword_t inbuf[23U] ;
  unsigned int tmp ;
  bool csum_offload ;
  size_t entries ;
  struct efx_channel *channel ;
  struct efx_nic *efx ;
  struct efx_ef10_nic_data *nic_data ;
  size_t inlen ;
  dma_addr_t dma_addr ;
  efx_qword_t *txd ;
  int rc ;
  int i ;
  struct _ddebug descriptor ;
  long tmp___0 ;
  int __ret_warn_on ;
  char const   *tmp___1 ;
  char const   *tmp___2 ;
  long tmp___3 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 23U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  csum_offload = (tx_queue->queue & 1U) != 0U;
  entries = (size_t )(tx_queue->txd.buf.len / 4096U);
  channel = tx_queue->channel;
  efx = tx_queue->efx;
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  ((efx_dword_t *)(& inbuf))->u32[0] = tx_queue->ptr_mask + 1U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )channel->channel;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = tx_queue->queue;
  ((efx_dword_t *)(& inbuf) + 3UL)->u32[0] = tx_queue->queue;
  ((efx_dword_t *)(& inbuf) + 4UL)->u32[0] = ((unsigned int )(! csum_offload) << 1) | ((unsigned int )(! csum_offload) << 2);
  ((efx_dword_t *)(& inbuf) + 5UL)->u32[0] = 0U;
  ((efx_dword_t *)(& inbuf) + 6UL)->u32[0] = nic_data->vport_id;
  dma_addr = tx_queue->txd.buf.dma_addr;
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_ef10_tx_init";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
    descriptor.format = "pushing TXQ %d. %zu entries (%llx)\n";
    descriptor.lineno = 1652U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "pushing TXQ %d. %zu entries (%llx)\n", tx_queue->queue,
                           entries, dma_addr);
    } else {

    }
  } else {

  }
  i = 0;
  goto ldv_56255;
  ldv_56254: 
  ((efx_dword_t *)(& inbuf) + ((unsigned long )i * 8UL + 28UL))->u32[0] = (__le32 )dma_addr;
  ((efx_dword_t *)(& inbuf) + ((unsigned long )i * 8UL + 29UL))->u32[0] = (__le32 )(dma_addr >> 32);
  dma_addr = dma_addr + 4096ULL;
  i = i + 1;
  ldv_56255: ;
  if ((size_t )i < entries) {
    goto ldv_56254;
  } else {

  }
  inlen = entries * 8UL + 28UL;
  rc = efx_mcdi_rpc(efx, 130U, (efx_dword_t const   *)(& inbuf), inlen, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  if (rc != 0) {
    goto fail;
  } else {

  }
  (tx_queue->buffer)->flags = 16U;
  tx_queue->insert_count = 1U;
  txd = efx_tx_desc(tx_queue, 0U);
  txd->u64[0] = (((unsigned long long )csum_offload << 1) | (unsigned long long )csum_offload) | 0x8000000000000000ULL;
  tx_queue->write_count = 1U;
  __asm__  volatile   ("sfence": : : "memory");
  efx_ef10_push_tx_desc(tx_queue, (efx_qword_t const   *)txd);
  return;
  fail: 
  __ret_warn_on = 1;
  tmp___3 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___3 != 0L) {
    tmp___1 = netdev_reg_state((struct net_device  const  *)efx->net_dev);
    tmp___2 = netdev_name((struct net_device  const  *)efx->net_dev);
    warn_slowpath_fmt("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                      1689, "netdevice: %s%s\nfailed to initialise TXQ %d\n", tmp___2,
                      tmp___1, tx_queue->queue);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  return;
}
}
static void efx_ef10_tx_fini(struct efx_tx_queue *tx_queue ) 
{ 
  efx_dword_t inbuf[1U] ;
  efx_dword_t outbuf[2U] ;
  unsigned int tmp ;
  struct efx_nic *efx ;
  size_t outlen ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  efx = tx_queue->efx;
  ((efx_dword_t *)(& inbuf))->u32[0] = tx_queue->queue;
  rc = efx_mcdi_rpc_quiet(efx, 133U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)(& outbuf),
                          8UL, & outlen);
  if (rc != 0 && rc != -114) {
    goto fail;
  } else {

  }
  return;
  fail: 
  efx_mcdi_display_error(efx, 133U, 4UL, (efx_dword_t *)(& outbuf), outlen, rc);
  return;
}
}
static void efx_ef10_tx_remove(struct efx_tx_queue *tx_queue ) 
{ 


  {
  efx_nic_free_buffer(tx_queue->efx, & tx_queue->txd.buf);
  return;
}
}
__inline static void efx_ef10_notify_tx_desc(struct efx_tx_queue *tx_queue ) 
{ 
  unsigned int write_ptr ;
  efx_dword_t reg ;

  {
  write_ptr = tx_queue->write_count & tx_queue->ptr_mask;
  reg.u32[0] = write_ptr;
  _efx_writed_page(tx_queue->efx, (efx_dword_t const   *)(& reg), 2584U, tx_queue->queue);
  return;
}
}
static void efx_ef10_tx_write(struct efx_tx_queue *tx_queue ) 
{ 
  unsigned int old_write_count ;
  struct efx_tx_buffer *buffer ;
  unsigned int write_ptr ;
  efx_qword_t *txd ;
  long tmp ;
  bool tmp___0 ;

  {
  old_write_count = tx_queue->write_count;
  tmp = ldv__builtin_expect(tx_queue->write_count == tx_queue->insert_count, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c"),
                         "i" (1740), "i" (12UL));
    ldv_56288: ;
    goto ldv_56288;
  } else {

  }
  ldv_56289: 
  write_ptr = tx_queue->write_count & tx_queue->ptr_mask;
  buffer = tx_queue->buffer + (unsigned long )write_ptr;
  txd = efx_tx_desc(tx_queue, write_ptr);
  tx_queue->write_count = tx_queue->write_count + 1U;
  if (((int )buffer->flags & 16) != 0) {
    *txd = buffer->__annonCompField116.option;
  } else {
    txd->u64[0] = ((((unsigned long long )buffer->flags & 1ULL) << 62) | ((unsigned long long )buffer->len << 48)) | buffer->__annonCompField116.dma_addr;
  }
  if (tx_queue->write_count != tx_queue->insert_count) {
    goto ldv_56289;
  } else {

  }
  __asm__  volatile   ("sfence": : : "memory");
  tmp___0 = efx_nic_may_push_tx_desc(tx_queue, old_write_count);
  if ((int )tmp___0) {
    txd = efx_tx_desc(tx_queue, tx_queue->ptr_mask & old_write_count);
    efx_ef10_push_tx_desc(tx_queue, (efx_qword_t const   *)txd);
    tx_queue->pushes = tx_queue->pushes + 1U;
  } else {
    efx_ef10_notify_tx_desc(tx_queue);
  }
  return;
}
}
static int efx_ef10_alloc_rss_context(struct efx_nic *efx , u32 *context , bool exclusive ,
                                      unsigned int *context_size ) 
{ 
  efx_dword_t inbuf[3U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[1U] ;
  struct efx_ef10_nic_data *nic_data ;
  size_t outlen ;
  int rc ;
  u32 alloc_type ;
  unsigned int rss_spread ;
  unsigned long _min1 ;
  unsigned long tmp___0 ;
  unsigned long _min2 ;
  unsigned int tmp___1 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 3U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  alloc_type = (int )exclusive ? 0U : 1U;
  if ((int )exclusive) {
    tmp___1 = efx->rss_spread;
  } else {
    tmp___0 = __rounddown_pow_of_two((unsigned long )efx->rss_spread);
    _min1 = tmp___0;
    _min2 = 64UL;
    tmp___1 = (unsigned int )(_min1 < _min2 ? _min1 : _min2);
  }
  rss_spread = tmp___1;
  if (! exclusive && rss_spread == 1U) {
    *context = 4294967295U;
    if ((unsigned long )context_size != (unsigned long )((unsigned int *)0U)) {
      *context_size = 1U;
    } else {

    }
    return (0);
  } else {

  }
  ((efx_dword_t *)(& inbuf))->u32[0] = nic_data->vport_id;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = alloc_type;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = rss_spread;
  rc = efx_mcdi_rpc(efx, 158U, (efx_dword_t const   *)(& inbuf), 12UL, (efx_dword_t *)(& outbuf),
                    4UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 3UL) {
    return (-5);
  } else {

  }
  *context = ((efx_dword_t *)(& outbuf))->u32[0];
  if ((unsigned long )context_size != (unsigned long )((unsigned int *)0U)) {
    *context_size = rss_spread;
  } else {

  }
  return (0);
}
}
static void efx_ef10_free_rss_context(struct efx_nic *efx , u32 context ) 
{ 
  efx_dword_t inbuf[1U] ;
  int rc ;
  int __ret_warn_on ;
  long tmp ;

  {
  inbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = context;
  rc = efx_mcdi_rpc(efx, 159U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  __ret_warn_on = rc != 0;
  tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                       1828);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  return;
}
}
static int efx_ef10_populate_rss_table(struct efx_nic *efx , u32 context , u32 const   *rx_indir_table ) 
{ 
  efx_dword_t tablebuf[33U] ;
  unsigned int tmp ;
  efx_dword_t keybuf[11U] ;
  unsigned int tmp___0 ;
  int i ;
  int rc ;
  int tmp___1 ;

  {
  tablebuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 33U) {
      break;
    } else {

    }
    tablebuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  keybuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 11U) {
      break;
    } else {

    }
    keybuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  ((efx_dword_t *)(& tablebuf))->u32[0] = context;
  i = 0;
  goto ldv_56341;
  ldv_56340: 
  *((u8 *)(& tablebuf) + ((unsigned long )i + 4UL)) = (unsigned char )*(rx_indir_table + (unsigned long )i);
  i = i + 1;
  ldv_56341: ;
  if ((unsigned int )i <= 127U) {
    goto ldv_56340;
  } else {

  }
  rc = efx_mcdi_rpc(efx, 162U, (efx_dword_t const   *)(& tablebuf), 132UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  if (rc != 0) {
    return (rc);
  } else {

  }
  ((efx_dword_t *)(& keybuf))->u32[0] = context;
  i = 0;
  goto ldv_56348;
  ldv_56347: 
  *((u8 *)(& keybuf) + ((unsigned long )i + 4UL)) = efx->rx_hash_key[i];
  i = i + 1;
  ldv_56348: ;
  if ((unsigned int )i <= 39U) {
    goto ldv_56347;
  } else {

  }
  tmp___1 = efx_mcdi_rpc(efx, 160U, (efx_dword_t const   *)(& keybuf), 44UL, (efx_dword_t *)0,
                         0UL, (size_t *)0UL);
  return (tmp___1);
}
}
static void efx_ef10_rx_free_indir_table(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  if (nic_data->rx_rss_context != 4294967295U) {
    efx_ef10_free_rss_context(efx, nic_data->rx_rss_context);
  } else {

  }
  nic_data->rx_rss_context = 4294967295U;
  return;
}
}
static int efx_ef10_rx_push_shared_rss_config(struct efx_nic *efx , unsigned int *context_size ) 
{ 
  u32 new_rx_rss_context ;
  struct efx_ef10_nic_data *nic_data ;
  int rc ;
  int tmp ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  tmp = efx_ef10_alloc_rss_context(efx, & new_rx_rss_context, 0, context_size);
  rc = tmp;
  if (rc != 0) {
    return (rc);
  } else {

  }
  nic_data->rx_rss_context = new_rx_rss_context;
  nic_data->rx_rss_context_exclusive = 0;
  efx_set_default_rx_indir_table(efx);
  return (0);
}
}
static int efx_ef10_rx_push_exclusive_rss_config(struct efx_nic *efx , u32 const   *rx_indir_table ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  int rc ;
  u32 new_rx_rss_context ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  if (nic_data->rx_rss_context == 4294967295U || ! nic_data->rx_rss_context_exclusive) {
    rc = efx_ef10_alloc_rss_context(efx, & new_rx_rss_context, 1, (unsigned int *)0U);
    if (rc == -95) {
      return (rc);
    } else
    if (rc != 0) {
      goto fail1;
    } else {

    }
  } else {
    new_rx_rss_context = nic_data->rx_rss_context;
  }
  rc = efx_ef10_populate_rss_table(efx, new_rx_rss_context, rx_indir_table);
  if (rc != 0) {
    goto fail2;
  } else {

  }
  if (nic_data->rx_rss_context != new_rx_rss_context) {
    efx_ef10_rx_free_indir_table(efx);
  } else {

  }
  nic_data->rx_rss_context = new_rx_rss_context;
  nic_data->rx_rss_context_exclusive = 1;
  if ((unsigned long )((unsigned int const   *)(& efx->rx_indir_table)) != (unsigned long )rx_indir_table) {
    memcpy((void *)(& efx->rx_indir_table), (void const   *)rx_indir_table, 512UL);
  } else {

  }
  return (0);
  fail2: ;
  if (nic_data->rx_rss_context != new_rx_rss_context) {
    efx_ef10_free_rss_context(efx, new_rx_rss_context);
  } else {

  }
  fail1: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s: failed rc=%d\n", "efx_ef10_rx_push_exclusive_rss_config",
               rc);
  } else {

  }
  return (rc);
}
}
static int efx_ef10_pf_rx_push_rss_config(struct efx_nic *efx , bool user , u32 const   *rx_indir_table ) 
{ 
  int rc ;
  unsigned int context_size ;
    klee_make_symbolic(&context_size, sizeof(int), "context_size");
  bool mismatch ;
  size_t i ;
  u32 tmp ;

  {
  if (efx->rss_spread == 1U) {
    return (0);
  } else {

  }
  rc = efx_ef10_rx_push_exclusive_rss_config(efx, rx_indir_table);
  if (rc == -105 && ! user) {
    mismatch = 0;
    i = 0UL;
    goto ldv_56383;
    ldv_56382: 
    tmp = ethtool_rxfh_indir_default((u32 )i, efx->rss_spread);
    mismatch = (unsigned int )*(rx_indir_table + i) != tmp;
    i = i + 1UL;
    ldv_56383: ;
    if (i <= 127UL && ! mismatch) {
      goto ldv_56382;
    } else {

    }
    rc = efx_ef10_rx_push_shared_rss_config(efx, & context_size);
    if (rc == 0) {
      if (efx->rss_spread != context_size) {
        if ((efx->msg_enable & 2U) != 0U) {
          netdev_warn((struct net_device  const  *)efx->net_dev, "Could not allocate an exclusive RSS context; allocated a shared one of different size. Wanted %u, got %u.\n",
                      efx->rss_spread, context_size);
        } else {

        }
      } else
      if ((int )mismatch) {
        if ((efx->msg_enable & 2U) != 0U) {
          netdev_warn((struct net_device  const  *)efx->net_dev, "Could not allocate an exclusive RSS context; allocated a shared one but could not apply custom indirection.\n");
        } else {

        }
      } else
      if ((efx->msg_enable & 2U) != 0U) {
        netdev_info((struct net_device  const  *)efx->net_dev, "Could not allocate an exclusive RSS context; allocated a shared one.\n");
      } else {

      }
    } else {

    }
  } else {

  }
  return (rc);
}
}
static int efx_ef10_vf_rx_push_rss_config(struct efx_nic *efx , bool user , u32 const   *rx_indir_table ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  int tmp ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  if ((int )user) {
    return (-95);
  } else {

  }
  if (nic_data->rx_rss_context != 4294967295U) {
    return (0);
  } else {

  }
  tmp = efx_ef10_rx_push_shared_rss_config(efx, (unsigned int *)0U);
  return (tmp);
}
}
static int efx_ef10_rx_probe(struct efx_rx_queue *rx_queue ) 
{ 
  int tmp ;

  {
  tmp = efx_nic_alloc_buffer(rx_queue->efx, & rx_queue->rxd.buf, (rx_queue->ptr_mask + 1U) * 8U,
                             208U);
  return (tmp);
}
}
static void efx_ef10_rx_init(struct efx_rx_queue *rx_queue ) 
{ 
  efx_dword_t inbuf[23U] ;
  unsigned int tmp ;
  struct efx_channel *channel ;
  struct efx_channel *tmp___0 ;
  size_t entries ;
  struct efx_nic *efx ;
  struct efx_ef10_nic_data *nic_data ;
  size_t inlen ;
  dma_addr_t dma_addr ;
  int rc ;
  int i ;
  int tmp___1 ;
  int tmp___2 ;
  struct _ddebug descriptor ;
  int tmp___3 ;
  long tmp___4 ;
  int __ret_warn_on ;
  int tmp___5 ;
  char const   *tmp___6 ;
  char const   *tmp___7 ;
  long tmp___8 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 23U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  tmp___0 = efx_rx_queue_channel(rx_queue);
  channel = tmp___0;
  entries = (size_t )(rx_queue->rxd.buf.len / 4096U);
  efx = rx_queue->efx;
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  rx_queue->scatter_n = 0U;
  rx_queue->scatter_len = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = rx_queue->ptr_mask + 1U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )channel->channel;
  tmp___1 = efx_rx_queue_index(rx_queue);
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = (unsigned int )tmp___1;
  tmp___2 = efx_rx_queue_index(rx_queue);
  ((efx_dword_t *)(& inbuf) + 3UL)->u32[0] = (unsigned int )tmp___2;
  ((efx_dword_t *)(& inbuf) + 4UL)->u32[0] = 260U;
  ((efx_dword_t *)(& inbuf) + 5UL)->u32[0] = 0U;
  ((efx_dword_t *)(& inbuf) + 6UL)->u32[0] = nic_data->vport_id;
  dma_addr = rx_queue->rxd.buf.dma_addr;
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_ef10_rx_init";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
    descriptor.format = "pushing RXQ %d. %zu entries (%llx)\n";
    descriptor.lineno = 2029U;
    descriptor.flags = 0U;
    tmp___4 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___4 != 0L) {
      tmp___3 = efx_rx_queue_index(rx_queue);
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "pushing RXQ %d. %zu entries (%llx)\n", tmp___3, entries,
                           dma_addr);
    } else {

    }
  } else {

  }
  i = 0;
  goto ldv_56447;
  ldv_56446: 
  ((efx_dword_t *)(& inbuf) + ((unsigned long )i * 8UL + 28UL))->u32[0] = (__le32 )dma_addr;
  ((efx_dword_t *)(& inbuf) + ((unsigned long )i * 8UL + 29UL))->u32[0] = (__le32 )(dma_addr >> 32);
  dma_addr = dma_addr + 4096ULL;
  i = i + 1;
  ldv_56447: ;
  if ((size_t )i < entries) {
    goto ldv_56446;
  } else {

  }
  inlen = entries * 8UL + 28UL;
  rc = efx_mcdi_rpc(efx, 129U, (efx_dword_t const   *)(& inbuf), inlen, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  if (rc != 0) {
    __ret_warn_on = 1;
    tmp___8 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___8 != 0L) {
      tmp___5 = efx_rx_queue_index(rx_queue);
      tmp___6 = netdev_reg_state((struct net_device  const  *)efx->net_dev);
      tmp___7 = netdev_name((struct net_device  const  *)efx->net_dev);
      warn_slowpath_fmt("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                        2042, "netdevice: %s%s\nfailed to initialise RXQ %d\n", tmp___7,
                        tmp___6, tmp___5);
    } else {

    }
    ldv__builtin_expect(__ret_warn_on != 0, 0L);
  } else {

  }
  return;
}
}
static void efx_ef10_rx_fini(struct efx_rx_queue *rx_queue ) 
{ 
  efx_dword_t inbuf[1U] ;
  efx_dword_t outbuf[2U] ;
  unsigned int tmp ;
  struct efx_nic *efx ;
  size_t outlen ;
  int rc ;
  int tmp___0 ;

  {
  inbuf[0].u32[0] = 0U;
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  efx = rx_queue->efx;
  tmp___0 = efx_rx_queue_index(rx_queue);
  ((efx_dword_t *)(& inbuf))->u32[0] = (unsigned int )tmp___0;
  rc = efx_mcdi_rpc_quiet(efx, 132U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)(& outbuf),
                          8UL, & outlen);
  if (rc != 0 && rc != -114) {
    goto fail;
  } else {

  }
  return;
  fail: 
  efx_mcdi_display_error(efx, 132U, 4UL, (efx_dword_t *)(& outbuf), outlen, rc);
  return;
}
}
static void efx_ef10_rx_remove(struct efx_rx_queue *rx_queue ) 
{ 


  {
  efx_nic_free_buffer(rx_queue->efx, & rx_queue->rxd.buf);
  return;
}
}
__inline static void efx_ef10_build_rx_desc(struct efx_rx_queue *rx_queue , unsigned int index ) 
{ 
  struct efx_rx_buffer *rx_buf ;
  efx_qword_t *rxd ;

  {
  rxd = efx_rx_desc(rx_queue, index);
  rx_buf = efx_rx_buffer(rx_queue, index);
  rxd->u64[0] = ((unsigned long long )rx_buf->len << 48) | rx_buf->dma_addr;
  return;
}
}
static void efx_ef10_rx_write(struct efx_rx_queue *rx_queue ) 
{ 
  struct efx_nic *efx ;
  unsigned int write_count ;
  efx_dword_t reg ;
  int tmp ;

  {
  efx = rx_queue->efx;
  write_count = rx_queue->added_count & 4294967288U;
  if (rx_queue->notified_count == write_count) {
    return;
  } else {

  }
  ldv_56477: 
  efx_ef10_build_rx_desc(rx_queue, rx_queue->notified_count & rx_queue->ptr_mask);
  rx_queue->notified_count = rx_queue->notified_count + 1U;
  if (rx_queue->notified_count != write_count) {
    goto ldv_56477;
  } else {

  }
  __asm__  volatile   ("sfence": : : "memory");
  reg.u32[0] = rx_queue->ptr_mask & write_count;
  tmp = efx_rx_queue_index(rx_queue);
  _efx_writed_page(efx, (efx_dword_t const   *)(& reg), 2096U, (unsigned int )tmp);
  return;
}
}
static void efx_ef10_rx_defer_refill_complete(struct efx_nic *efx , unsigned long cookie ,
                                              int rc , efx_dword_t *outbuf , size_t outlen_actual ) ;
static void efx_ef10_rx_defer_refill(struct efx_rx_queue *rx_queue ) 
{ 
  struct efx_channel *channel ;
  struct efx_channel *tmp ;
  efx_dword_t inbuf[3U] ;
  unsigned int tmp___0 ;
  efx_qword_t event ;

  {
  tmp = efx_rx_queue_channel(rx_queue);
  channel = tmp;
  inbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 3U) {
      break;
    } else {

    }
    inbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  event.u64[0] = 8070450532247928834ULL;
  ((efx_dword_t *)(& inbuf))->u32[0] = (unsigned int )channel->channel;
  memcpy((void *)(& inbuf) + 4U, (void const   *)(& event.u64), 8UL);
  efx_mcdi_rpc_async(channel->efx, 134U, (efx_dword_t const   *)(& inbuf), 12UL, 0UL,
                     & efx_ef10_rx_defer_refill_complete, 0UL);
  return;
}
}
static void efx_ef10_rx_defer_refill_complete(struct efx_nic *efx , unsigned long cookie ,
                                              int rc , efx_dword_t *outbuf , size_t outlen_actual ) 
{ 


  {
  return;
}
}
static int efx_ef10_ev_probe(struct efx_channel *channel ) 
{ 
  int tmp ;

  {
  tmp = efx_nic_alloc_buffer(channel->efx, & channel->eventq.buf, (channel->eventq_mask + 1U) * 8U,
                             208U);
  return (tmp);
}
}
static int efx_ef10_ev_init(struct efx_channel *channel ) 
{ 
  efx_dword_t inbuf[73U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[1U] ;
  size_t entries ;
  struct efx_nic *efx ;
  struct efx_ef10_nic_data *nic_data ;
  bool supports_rx_merge ;
  size_t inlen ;
  size_t outlen ;
  dma_addr_t dma_addr ;
  int rc ;
  int i ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 73U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  entries = (size_t )(channel->eventq.buf.len / 4096U);
  efx = channel->efx;
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  supports_rx_merge = (nic_data->datapath_caps & 33554432U) != 0U;
  memset(channel->eventq.buf.addr, 255, (size_t )channel->eventq.buf.len);
  ((efx_dword_t *)(& inbuf))->u32[0] = channel->eventq_mask + 1U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )channel->channel;
  ((efx_dword_t *)(& inbuf) + 6UL)->u32[0] = (unsigned int )channel->channel;
  ((efx_dword_t *)(& inbuf) + 4UL)->u32[0] = ((unsigned int )(! supports_rx_merge) << 3) | 49U;
  ((efx_dword_t *)(& inbuf) + 5UL)->u32[0] = 0U;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = 0U;
  ((efx_dword_t *)(& inbuf) + 3UL)->u32[0] = 0U;
  ((efx_dword_t *)(& inbuf) + 7UL)->u32[0] = 0U;
  ((efx_dword_t *)(& inbuf) + 8UL)->u32[0] = 0U;
  dma_addr = channel->eventq.buf.dma_addr;
  i = 0;
  goto ldv_56557;
  ldv_56556: 
  ((efx_dword_t *)(& inbuf) + ((unsigned long )i * 8UL + 36UL))->u32[0] = (__le32 )dma_addr;
  ((efx_dword_t *)(& inbuf) + ((unsigned long )i * 8UL + 37UL))->u32[0] = (__le32 )(dma_addr >> 32);
  dma_addr = dma_addr + 4096ULL;
  i = i + 1;
  ldv_56557: ;
  if ((size_t )i < entries) {
    goto ldv_56556;
  } else {

  }
  inlen = entries * 8UL + 36UL;
  rc = efx_mcdi_rpc(efx, 128U, (efx_dword_t const   *)(& inbuf), inlen, (efx_dword_t *)(& outbuf),
                    4UL, & outlen);
  return (rc);
}
}
static void efx_ef10_ev_fini(struct efx_channel *channel ) 
{ 
  efx_dword_t inbuf[1U] ;
  efx_dword_t outbuf[2U] ;
  unsigned int tmp ;
  struct efx_nic *efx ;
  size_t outlen ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  efx = channel->efx;
  ((efx_dword_t *)(& inbuf))->u32[0] = (unsigned int )channel->channel;
  rc = efx_mcdi_rpc_quiet(efx, 131U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)(& outbuf),
                          8UL, & outlen);
  if (rc != 0 && rc != -114) {
    goto fail;
  } else {

  }
  return;
  fail: 
  efx_mcdi_display_error(efx, 131U, 4UL, (efx_dword_t *)(& outbuf), outlen, rc);
  return;
}
}
static void efx_ef10_ev_remove(struct efx_channel *channel ) 
{ 


  {
  efx_nic_free_buffer(channel->efx, & channel->eventq.buf);
  return;
}
}
static void efx_ef10_handle_rx_wrong_queue(struct efx_rx_queue *rx_queue , unsigned int rx_queue_label ) 
{ 
  struct efx_nic *efx ;
  int tmp ;

  {
  efx = rx_queue->efx;
  if ((efx->msg_enable & 8192U) != 0U) {
    tmp = efx_rx_queue_index(rx_queue);
    netdev_info((struct net_device  const  *)efx->net_dev, "rx event arrived on queue %d labeled as queue %u\n",
                tmp, rx_queue_label);
  } else {

  }
  efx_schedule_reset(efx, 7);
  return;
}
}
static void efx_ef10_handle_rx_bad_lbits(struct efx_rx_queue *rx_queue , unsigned int actual ,
                                         unsigned int expected ) 
{ 
  unsigned int dropped ;
  struct efx_nic *efx ;

  {
  dropped = (actual - expected) & rx_queue->ptr_mask;
  efx = rx_queue->efx;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_info((struct net_device  const  *)efx->net_dev, "dropped %d events (index=%d expected=%d)\n",
                dropped, actual, expected);
  } else {

  }
  efx_schedule_reset(efx, 7);
  return;
}
}
static void efx_ef10_handle_rx_abort(struct efx_rx_queue *rx_queue ) 
{ 
  unsigned int rx_desc_ptr ;
    klee_make_symbolic(&rx_desc_ptr, sizeof(int), "rx_desc_ptr");
  struct _ddebug descriptor ;
  long tmp ;
  struct efx_channel *tmp___0 ;

  {
  if (((rx_queue->efx)->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_ef10_handle_rx_abort";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
    descriptor.format = "scattered RX aborted (dropping %u buffers)\n";
    descriptor.lineno = 2268U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)(rx_queue->efx)->net_dev,
                           "scattered RX aborted (dropping %u buffers)\n", rx_queue->scatter_n);
    } else {

    }
  } else {

  }
  rx_desc_ptr = rx_queue->removed_count & rx_queue->ptr_mask;
  efx_rx_packet(rx_queue, rx_desc_ptr, rx_queue->scatter_n, 0U, 4);
  rx_queue->removed_count = rx_queue->removed_count + rx_queue->scatter_n;
  rx_queue->scatter_n = 0U;
  rx_queue->scatter_len = 0U;
  tmp___0 = efx_rx_queue_channel(rx_queue);
  tmp___0->n_rx_nodesc_trunc = tmp___0->n_rx_nodesc_trunc + 1U;
  return;
}
}
static int efx_ef10_handle_rx_event(struct efx_channel *channel , efx_qword_t const   *event ) 
{ 
  unsigned int rx_bytes ;
  unsigned int next_ptr_lbits ;
    klee_make_symbolic(&next_ptr_lbits, sizeof(int), "next_ptr_lbits");
  unsigned int rx_queue_label ;
    klee_make_symbolic(&rx_queue_label, sizeof(int), "rx_queue_label");
  unsigned int rx_l4_class ;
    klee_make_symbolic(&rx_l4_class, sizeof(int), "rx_l4_class");
  unsigned int n_descs ;
    klee_make_symbolic(&n_descs, sizeof(int), "n_descs");
  unsigned int n_packets ;
    klee_make_symbolic(&n_packets, sizeof(int), "n_packets");
  unsigned int i ;
  struct efx_nic *efx ;
  struct efx_rx_queue *rx_queue ;
  bool rx_cont ;
  u16 flags ;
  unsigned long __var ;
  long tmp ;
  int __ret_warn_on ;
  char const   *tmp___0 ;
  char const   *tmp___1 ;
  long tmp___2 ;
  int tmp___3 ;
  long tmp___4 ;
  struct efx_ef10_nic_data *nic_data ;
  int __ret_warn_on___0 ;
  char const   *tmp___5 ;
  char const   *tmp___6 ;
  long tmp___7 ;
  long tmp___8 ;
  long tmp___9 ;
  long tmp___10 ;
  long tmp___11 ;
    klee_make_symbolic(&tmp___11, sizeof(long), "tmp___11");

  {
  efx = channel->efx;
  flags = 0U;
  __var = 0UL;
  tmp = ldv__builtin_expect((unsigned long )*((unsigned long volatile   *)(& efx->reset_pending)) != 0UL,
                         0L);
  if (tmp != 0L) {
    return (0);
  } else {

  }
  rx_bytes = (unsigned int )event->u64[0] & 16383U;
  next_ptr_lbits = (unsigned int )(event->u64[0] >> 48) & 15U;
  rx_queue_label = (unsigned int )(event->u64[0] >> 16) & 31U;
  rx_l4_class = (unsigned int )(event->u64[0] >> 45) & 7U;
  rx_cont = ((event->u64[0] >> 14) & 1ULL) != 0ULL;
  if ((int )(event->u64[0] >> 58) & 1) {
    __ret_warn_on = 1;
    tmp___2 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___2 != 0L) {
      tmp___0 = netdev_reg_state((struct net_device  const  *)efx->net_dev);
      tmp___1 = netdev_name((struct net_device  const  *)efx->net_dev);
      warn_slowpath_fmt("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                        2304, "netdevice: %s%s\nsaw RX_DROP_EVENT: event=%08x:%08x\n",
                        tmp___1, tmp___0, event->u32[1], event->u32[0]);
    } else {

    }
    ldv__builtin_expect(__ret_warn_on != 0, 0L);
  } else {

  }
  rx_queue = efx_channel_get_rx_queue(channel);
  tmp___3 = efx_rx_queue_index(rx_queue);
  tmp___4 = ldv__builtin_expect((unsigned int )tmp___3 != rx_queue_label, 0L);
  if (tmp___4 != 0L) {
    efx_ef10_handle_rx_wrong_queue(rx_queue, rx_queue_label);
  } else {

  }
  n_descs = (next_ptr_lbits - rx_queue->removed_count) & 15U;
  if (rx_queue->scatter_n + 1U != n_descs) {
    nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
    tmp___8 = ldv__builtin_expect(rx_queue->scatter_n == n_descs, 0L);
    if (tmp___8 != 0L) {
      if (rx_queue->scatter_n == 0U || rx_bytes != 0U) {
        __ret_warn_on___0 = 1;
        tmp___7 = ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
        if (tmp___7 != 0L) {
          tmp___5 = netdev_reg_state((struct net_device  const  *)efx->net_dev);
          tmp___6 = netdev_name((struct net_device  const  *)efx->net_dev);
          warn_slowpath_fmt("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                            2324, "netdevice: %s%s\ninvalid RX abort: scatter_n=%u event=%08x:%08x\n",
                            tmp___6, tmp___5, rx_queue->scatter_n, event->u32[1],
                            event->u32[0]);
        } else {

        }
        ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
      } else {

      }
      efx_ef10_handle_rx_abort(rx_queue);
      return (0);
    } else {

    }
    if (((nic_data->datapath_caps & 33554432U) == 0U || rx_queue->scatter_n != 0U) || (int )rx_cont) {
      efx_ef10_handle_rx_bad_lbits(rx_queue, next_ptr_lbits, ((rx_queue->removed_count + rx_queue->scatter_n) + 1U) & 15U);
      return (0);
    } else {

    }
    rx_queue->scatter_n = 1U;
    rx_queue->scatter_len = 0U;
    n_packets = n_descs;
    channel->n_rx_merge_events = channel->n_rx_merge_events + 1U;
    channel->n_rx_merge_packets = channel->n_rx_merge_packets + n_packets;
    flags = (u16 )((unsigned int )flags | 128U);
  } else {
    rx_queue->scatter_n = rx_queue->scatter_n + 1U;
    rx_queue->scatter_len = rx_queue->scatter_len + rx_bytes;
    if ((int )rx_cont) {
      return (0);
    } else {

    }
    n_packets = 1U;
  }
  tmp___9 = ldv__builtin_expect((long )((int )(event->u64[0] >> 24)) & 1L, 0L);
  if (tmp___9 != 0L) {
    flags = (u16 )((unsigned int )flags | 4U);
  } else {

  }
  tmp___11 = ldv__builtin_expect((long )((int )(event->u64[0] >> 25)) & 1L, 0L);
  if (tmp___11 != 0L) {
    channel->n_rx_ip_hdr_chksum_err = channel->n_rx_ip_hdr_chksum_err + n_packets;
  } else {
    tmp___10 = ldv__builtin_expect((long )((int )(event->u64[0] >> 26)) & 1L, 0L);
    if (tmp___10 != 0L) {
      channel->n_rx_tcp_udp_chksum_err = channel->n_rx_tcp_udp_chksum_err + n_packets;
    } else
    if (rx_l4_class == 1U || rx_l4_class == 2U) {
      flags = (u16 )((unsigned int )flags | 2U);
    } else {

    }
  }
  if (rx_l4_class == 1U) {
    flags = (u16 )((unsigned int )flags | 64U);
  } else {

  }
  channel->irq_mod_score = channel->irq_mod_score + n_packets * 2U;
  i = 0U;
  goto ldv_56614;
  ldv_56613: 
  efx_rx_packet(rx_queue, rx_queue->removed_count & rx_queue->ptr_mask, rx_queue->scatter_n,
                rx_queue->scatter_len, (int )flags);
  rx_queue->removed_count = rx_queue->removed_count + rx_queue->scatter_n;
  i = i + 1U;
  ldv_56614: ;
  if (i < n_packets) {
    goto ldv_56613;
  } else {

  }
  rx_queue->scatter_n = 0U;
  rx_queue->scatter_len = 0U;
  return ((int )n_packets);
}
}
static int efx_ef10_handle_tx_event(struct efx_channel *channel , efx_qword_t *event ) 
{ 
  struct efx_nic *efx ;
  struct efx_tx_queue *tx_queue ;
  unsigned int tx_ev_desc_ptr ;
  unsigned int tx_ev_q_label ;
  int tx_descs ;
    klee_make_symbolic(&tx_descs, sizeof(int), "tx_descs");
  unsigned long __var ;
  long tmp ;
  long tmp___0 ;

  {
  efx = channel->efx;
  tx_descs = 0;
  __var = 0UL;
  tmp = ldv__builtin_expect((unsigned long )*((unsigned long volatile   *)(& efx->reset_pending)) != 0UL,
                         0L);
  if (tmp != 0L) {
    return (0);
  } else {

  }
  tmp___0 = ldv__builtin_expect((long )((int )(event->u64[0] >> 58)) & 1L, 0L);
  if (tmp___0 != 0L) {
    return (0);
  } else {

  }
  tx_ev_desc_ptr = (unsigned int )event->u64[0] & 65535U;
  tx_ev_q_label = (unsigned int )(event->u64[0] >> 16) & 31U;
  tx_queue = efx_channel_get_tx_queue(channel, tx_ev_q_label & 3U);
  tx_descs = (int )(((tx_ev_desc_ptr - tx_queue->read_count) + 1U) & tx_queue->ptr_mask);
  efx_xmit_done(tx_queue, tx_queue->ptr_mask & tx_ev_desc_ptr);
  return (tx_descs);
}
}
static void efx_ef10_handle_driver_event(struct efx_channel *channel , efx_qword_t *event ) 
{ 
  struct efx_nic *efx ;
  int subcode ;
    klee_make_symbolic(&subcode, sizeof(int), "subcode");

  {
  efx = channel->efx;
  subcode = (int )(event->u64[0] >> 56) & 15;
  switch (subcode) {
  case 3: ;
  case 1: ;
  goto ldv_56635;
  case 2: ;
  goto ldv_56635;
  default: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "channel %d unknown driver event type %d (data %08x:%08x)\n",
               channel->channel, subcode, event->u32[1], event->u32[0]);
  } else {

  }
  }
  ldv_56635: ;
  return;
}
}
static void efx_ef10_handle_driver_generated_event(struct efx_channel *channel , efx_qword_t *event ) 
{ 
  struct efx_nic *efx ;
  u32 subcode ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;

  {
  efx = channel->efx;
  subcode = (u32 )event->u64[0];
  switch (subcode) {
  case 1U: 
  __vpp_verify = (void const   *)0;
  switch (4UL) {
  case 1UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
  goto ldv_56650;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_56650;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_56650;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_56650;
  default: 
  __bad_percpu_size();
  }
  ldv_56650: 
  pscr_ret__ = pfo_ret__;
  goto ldv_56656;
  case 2UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_56660;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_56660;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_56660;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_56660;
  default: 
  __bad_percpu_size();
  }
  ldv_56660: 
  pscr_ret__ = pfo_ret_____0;
  goto ldv_56656;
  case 4UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_56669;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_56669;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_56669;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_56669;
  default: 
  __bad_percpu_size();
  }
  ldv_56669: 
  pscr_ret__ = pfo_ret_____1;
  goto ldv_56656;
  case 8UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_56678;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_56678;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_56678;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_56678;
  default: 
  __bad_percpu_size();
  }
  ldv_56678: 
  pscr_ret__ = pfo_ret_____2;
  goto ldv_56656;
  default: 
  __bad_size_call_parameter();
  goto ldv_56656;
  }
  ldv_56656: 
  channel->event_test_cpu = pscr_ret__;
  goto ldv_56686;
  case 2U: 
  efx_fast_push_rx_descriptors(& channel->rx_queue, 1);
  goto ldv_56686;
  default: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "channel %d unknown driver event type %u (data %08x:%08x)\n",
               channel->channel, subcode, event->u32[1], event->u32[0]);
  } else {

  }
  }
  ldv_56686: ;
  return;
}
}
static int efx_ef10_ev_process(struct efx_channel *channel , int quota ) 
{ 
  struct efx_nic *efx ;
  efx_qword_t event ;
  efx_qword_t *p_event ;
  unsigned int read_ptr ;
  int ev_code ;
  int tx_descs ;
  int spent ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
  efx = channel->efx;
  tx_descs = 0;
  spent = 0;
  if (quota <= 0) {
    return (spent);
  } else {

  }
  read_ptr = channel->eventq_read_ptr;
  ldv_56710: 
  p_event = efx_event(channel, read_ptr);
  event = *p_event;
  tmp = efx_event_present(& event);
  if (tmp == 0) {
    goto ldv_56700;
  } else {

  }
  p_event->u64[0] = 0xffffffffffffffffULL;
  read_ptr = read_ptr + 1U;
  ev_code = (int )(event.u64[0] >> 60);
  switch (ev_code) {
  case 12: 
  efx_mcdi_process_event(channel, & event);
  goto ldv_56703;
  case 0: 
  tmp___0 = efx_ef10_handle_rx_event(channel, (efx_qword_t const   *)(& event));
  spent = tmp___0 + spent;
  if (spent >= quota) {
    spent = quota;
    goto out;
  } else {

  }
  goto ldv_56703;
  case 2: 
  tmp___1 = efx_ef10_handle_tx_event(channel, & event);
  tx_descs = tmp___1 + tx_descs;
  if ((unsigned int )tx_descs > efx->txq_entries) {
    spent = quota;
    goto out;
  } else {
    spent = spent + 1;
    if (spent == quota) {
      goto out;
    } else {

    }
  }
  goto ldv_56703;
  case 5: 
  efx_ef10_handle_driver_event(channel, & event);
  spent = spent + 1;
  if (spent == quota) {
    goto out;
  } else {

  }
  goto ldv_56703;
  case 7: 
  efx_ef10_handle_driver_generated_event(channel, & event);
  goto ldv_56703;
  default: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "channel %d unknown event type %d (data %08x:%08x)\n",
               channel->channel, ev_code, event.u32[1], event.u32[0]);
  } else {

  }
  }
  ldv_56703: ;
  goto ldv_56710;
  ldv_56700: ;
  out: 
  channel->eventq_read_ptr = read_ptr;
  return (spent);
}
}
static void efx_ef10_ev_read_ack(struct efx_channel *channel ) 
{ 
  struct efx_nic *efx ;
  efx_dword_t rptr ;

  {
  efx = channel->efx;
  if ((int )((struct efx_ef10_nic_data *)efx->nic_data)->workaround_35388) {
    rptr.u32[0] = ((channel->eventq_read_ptr & channel->eventq_mask) >> 8) | 2048U;
    _efx_writed_page(efx, (efx_dword_t const   *)(& rptr), 2584U, (unsigned int )channel->channel);
    rptr.u32[0] = (channel->eventq_read_ptr & 255U) | 2304U;
    _efx_writed_page(efx, (efx_dword_t const   *)(& rptr), 2584U, (unsigned int )channel->channel);
  } else {
    rptr.u32[0] = channel->eventq_read_ptr & channel->eventq_mask;
    _efx_writed_page(efx, (efx_dword_t const   *)(& rptr), 1024U, (unsigned int )channel->channel);
  }
  return;
}
}
static void efx_ef10_ev_test_generate(struct efx_channel *channel ) 
{ 
  efx_dword_t inbuf[3U] ;
  unsigned int tmp ;
  struct efx_nic *efx ;
  efx_qword_t event ;
  int rc ;
  int __ret_warn_on ;
  long tmp___0 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 3U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  efx = channel->efx;
  event.u64[0] = 8070450532247928833ULL;
  ((efx_dword_t *)(& inbuf))->u32[0] = (unsigned int )channel->channel;
  memcpy((void *)(& inbuf) + 4U, (void const   *)(& event.u64), 8UL);
  rc = efx_mcdi_rpc(efx, 134U, (efx_dword_t const   *)(& inbuf), 12UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  if (rc != 0) {
    goto fail;
  } else {

  }
  return;
  fail: 
  __ret_warn_on = 1;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                       2609);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s: failed rc=%d\n", "efx_ef10_ev_test_generate",
               rc);
  } else {

  }
  return;
}
}
void efx_ef10_handle_drain_event(struct efx_nic *efx ) 
{ 
  int tmp ;
  int __ret_warn_on ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp = atomic_dec_and_test(& efx->active_queues);
  if (tmp != 0) {
    __wake_up(& efx->flush_wq, 3U, 1, (void *)0);
  } else {

  }
  tmp___0 = atomic_read((atomic_t const   *)(& efx->active_queues));
  __ret_warn_on = tmp___0 < 0;
  tmp___1 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___1 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                       2618);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  return;
}
}
static int efx_ef10_fini_dmaq(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  struct efx_channel *channel ;
  struct efx_tx_queue *tx_queue ;
  struct efx_rx_queue *rx_queue ;
  int pending ;
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  long __ret ;
  unsigned long tmp___4 ;
  wait_queue_t __wait ;
  long __ret___0 ;
  unsigned long tmp___5 ;
  long __int ;
  long tmp___6 ;
  bool __cond ;
  int tmp___7 ;
  bool __cond___0 ;
  int tmp___8 ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  if ((int )nic_data->must_realloc_vis) {
    atomic_set(& efx->active_queues, 0);
    return (0);
  } else {

  }
  if ((unsigned int )efx->state != 3U) {
    channel = efx->channel[0];
    goto ldv_56755;
    ldv_56754: 
    tmp = efx_channel_has_rx_queue(channel);
    if (tmp) {
      tmp___0 = 0;
    } else {
      tmp___0 = 1;
    }
    if (tmp___0) {

    } else {
      rx_queue = & channel->rx_queue;
      goto ldv_56749;
      ldv_56748: 
      efx_ef10_rx_fini(rx_queue);
      rx_queue = (struct efx_rx_queue *)0;
      ldv_56749: ;
      if ((unsigned long )rx_queue != (unsigned long )((struct efx_rx_queue *)0)) {
        goto ldv_56748;
      } else {

      }

    }
    tmp___2 = efx_channel_has_tx_queues(channel);
    if (tmp___2) {
      tmp___3 = 0;
    } else {
      tmp___3 = 1;
    }
    if (tmp___3) {

    } else {
      tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
      goto ldv_56752;
      ldv_56751: 
      efx_ef10_tx_fini(tx_queue);
      tx_queue = tx_queue + 1;
      ldv_56752: ;
      if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
        tmp___1 = efx_tx_queue_used(tx_queue);
        if ((int )tmp___1) {
          goto ldv_56751;
        } else {
          goto ldv_56753;
        }
      } else {

      }
      ldv_56753: ;
    }
    channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
    ldv_56755: ;
    if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
      goto ldv_56754;
    } else {

    }
    tmp___4 = msecs_to_jiffies(5000U);
    __ret = (long )tmp___4;
    __might_sleep("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                  2648, 0);
    tmp___8 = atomic_read((atomic_t const   *)(& efx->active_queues));
    __cond___0 = tmp___8 == 0;
    if ((int )__cond___0 && __ret == 0L) {
      __ret = 1L;
    } else {

    }
    if (((int )__cond___0 || __ret == 0L) == 0) {
      tmp___5 = msecs_to_jiffies(5000U);
      __ret___0 = (long )tmp___5;
      INIT_LIST_HEAD(& __wait.task_list);
      __wait.flags = 0U;
      ldv_56767: 
      tmp___6 = prepare_to_wait_event(& efx->flush_wq, & __wait, 2);
      __int = tmp___6;
      tmp___7 = atomic_read((atomic_t const   *)(& efx->active_queues));
      __cond = tmp___7 == 0;
      if ((int )__cond && __ret___0 == 0L) {
        __ret___0 = 1L;
      } else {

      }
      if (((int )__cond || __ret___0 == 0L) != 0) {
        goto ldv_56766;
      } else {

      }
      __ret___0 = schedule_timeout(__ret___0);
      goto ldv_56767;
      ldv_56766: 
      finish_wait(& efx->flush_wq, & __wait);
      __ret = __ret___0;
    } else {

    }
    pending = atomic_read((atomic_t const   *)(& efx->active_queues));
    if (pending != 0) {
      if ((efx->msg_enable & 8192U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "failed to flush %d queues\n",
                   pending);
      } else {

      }
      return (-110);
    } else {

    }
  } else {

  }
  return (0);
}
}
static void efx_ef10_prepare_flr(struct efx_nic *efx ) 
{ 


  {
  atomic_set(& efx->active_queues, 0);
  return;
}
}
static bool efx_ef10_filter_equal(struct efx_filter_spec  const  *left , struct efx_filter_spec  const  *right ) 
{ 
  int tmp ;

  {
  if ((((int )left->match_flags ^ (int )right->match_flags) | (((int )left->flags ^ (int )right->flags) & 24)) != 0) {
    return (0);
  } else {

  }
  tmp = memcmp((void const   *)(& left->outer_vid), (void const   *)(& right->outer_vid),
               56UL);
  return (tmp == 0);
}
}
static unsigned int efx_ef10_filter_hash(struct efx_filter_spec  const  *spec ) 
{ 
  u32 tmp ;

  {
  tmp = jhash2((u32 const   *)(& spec->outer_vid), 14U, 0U);
  return (tmp);
}
}
static bool efx_ef10_filter_is_exclusive(struct efx_filter_spec  const  *spec ) 
{ 
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;

  {
  if (((int )spec->match_flags & 16) != 0) {
    tmp = is_multicast_ether_addr((u8 const   *)(& spec->loc_mac));
    if (tmp) {
      tmp___0 = 0;
    } else {
      tmp___0 = 1;
    }
    if (tmp___0) {
      return (1);
    } else {

    }
  } else {

  }
  if (((int )spec->match_flags & 66) == 66) {
    if ((unsigned int )((unsigned short )spec->ether_type) == 8U) {
      tmp___1 = ipv4_is_multicast(spec->loc_host[0]);
      if (tmp___1) {
        tmp___2 = 0;
      } else {
        tmp___2 = 1;
      }
      if (tmp___2) {
        return (1);
      } else {

      }
    } else {

    }
    if ((unsigned int )((unsigned short )spec->ether_type) == 56710U && (unsigned int )((unsigned char )*((u8 const   *)(& spec->loc_host))) != 255U) {
      return (1);
    } else {

    }
  } else {

  }
  return (0);
}
}
static struct efx_filter_spec *efx_ef10_filter_entry_spec(struct efx_ef10_filter_table  const  *table ,
                                                          unsigned int filter_idx ) 
{ 


  {
  return ((struct efx_filter_spec *)((table->entry + (unsigned long )filter_idx)->spec & 0xfffffffffffffffcUL));
}
}
static unsigned int efx_ef10_filter_entry_flags(struct efx_ef10_filter_table  const  *table ,
                                                unsigned int filter_idx ) 
{ 


  {
  return ((unsigned int )(table->entry + (unsigned long )filter_idx)->spec & 3U);
}
}
static void efx_ef10_filter_set_entry(struct efx_ef10_filter_table *table , unsigned int filter_idx ,
                                      struct efx_filter_spec  const  *spec , unsigned int flags ) 
{ 


  {
  (table->entry + (unsigned long )filter_idx)->spec = (unsigned long )flags | (unsigned long )spec;
  return;
}
}
static void efx_ef10_filter_push_prep(struct efx_nic *efx , struct efx_filter_spec  const  *spec ,
                                      efx_dword_t *inbuf , u64 handle , bool replacing ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  u32 match_fields ;
  bool tmp ;
  bool tmp___0 ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  memset((void *)inbuf, 0, 108UL);
  if ((int )replacing) {
    inbuf->u32[0] = 4U;
    (inbuf + 1UL)->u32[0] = (unsigned int )handle;
    (inbuf + 2U)->u32[0] = (unsigned int )(handle >> 32);
  } else {
    match_fields = 0U;
    tmp = efx_ef10_filter_is_exclusive(spec);
    inbuf->u32[0] = (int )tmp ? 0U : 2U;
    if (((int )spec->match_flags & 1024) != 0) {
      tmp___0 = is_multicast_ether_addr((u8 const   *)(& spec->loc_mac));
      match_fields = ((int )tmp___0 ? 1073741824U : 2147483648U) | match_fields;
    } else {

    }
    if ((int )spec->match_flags & 1) {
      match_fields = match_fields | 1U;
      memcpy((void *)inbuf + 76U, (void const   *)(& spec->rem_host), 16UL);
    } else {

    }
    if (((int )spec->match_flags & 2) != 0) {
      match_fields = match_fields | 2U;
      memcpy((void *)inbuf + 92U, (void const   *)(& spec->loc_host), 16UL);
    } else {

    }
    if (((int )spec->match_flags & 4) != 0) {
      match_fields = match_fields | 4U;
      memcpy((void *)inbuf + 44U, (void const   *)(& spec->rem_mac), 6UL);
    } else {

    }
    if (((int )spec->match_flags & 8) != 0) {
      match_fields = match_fields | 8U;
      memcpy((void *)inbuf + 50U, (void const   *)(& spec->rem_port), 2UL);
    } else {

    }
    if (((int )spec->match_flags & 16) != 0) {
      match_fields = match_fields | 16U;
      memcpy((void *)inbuf + 52U, (void const   *)(& spec->loc_mac), 6UL);
    } else {

    }
    if (((int )spec->match_flags & 32) != 0) {
      match_fields = match_fields | 32U;
      memcpy((void *)inbuf + 58U, (void const   *)(& spec->loc_port), 2UL);
    } else {

    }
    if (((int )spec->match_flags & 64) != 0) {
      match_fields = match_fields | 64U;
      memcpy((void *)inbuf + 60U, (void const   *)(& spec->ether_type), 2UL);
    } else {

    }
    if (((int )spec->match_flags & 128) != 0) {
      match_fields = match_fields | 128U;
      memcpy((void *)inbuf + 62U, (void const   *)(& spec->inner_vid), 2UL);
    } else {

    }
    if (((int )spec->match_flags & 256) != 0) {
      match_fields = match_fields | 256U;
      memcpy((void *)inbuf + 64U, (void const   *)(& spec->outer_vid), 2UL);
    } else {

    }
    if (((int )spec->match_flags & 512) != 0) {
      match_fields = match_fields | 512U;
      memcpy((void *)inbuf + 66U, (void const   *)(& spec->ip_proto), 1UL);
    } else {

    }
    (inbuf + 4UL)->u32[0] = match_fields;
  }
  (inbuf + 3UL)->u32[0] = nic_data->vport_id;
  (inbuf + 5UL)->u32[0] = (unsigned int )*((unsigned short *)spec + 1UL) != 65520U;
  (inbuf + 9UL)->u32[0] = 0U;
  (inbuf + 10UL)->u32[0] = 4294967295U;
  (inbuf + 6UL)->u32[0] = (unsigned int )*((unsigned short *)spec + 1UL) != 65520U ? (unsigned int )spec->dmaq_id : 0U;
  (inbuf + 7UL)->u32[0] = (int )spec->flags & 1 ? 1U : 0U;
  if ((int )spec->flags & 1) {
    (inbuf + 8UL)->u32[0] = (unsigned int )spec->rss_context != 4294967295U ? (unsigned int )spec->rss_context : nic_data->rx_rss_context;
  } else {

  }
  return;
}
}
static int efx_ef10_filter_push(struct efx_nic *efx , struct efx_filter_spec  const  *spec ,
                                u64 *handle , bool replacing ) 
{ 
  efx_dword_t inbuf[27U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[3U] ;
  unsigned int tmp___0 ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 27U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 3U) {
      break;
    } else {

    }
    outbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  efx_ef10_filter_push_prep(efx, spec, (efx_dword_t *)(& inbuf), *handle, (int )replacing);
  rc = efx_mcdi_rpc(efx, 138U, (efx_dword_t const   *)(& inbuf), 108UL, (efx_dword_t *)(& outbuf),
                    12UL, (size_t *)0UL);
  if (rc == 0) {
    *handle = (unsigned long long )((efx_dword_t *)(& outbuf) + 1UL)->u32[0] | ((unsigned long long )((efx_dword_t *)(& outbuf) + 2U)->u32[0] << 32);
  } else {

  }
  if (rc == -28) {
    rc = -16;
  } else {

  }
  return (rc);
}
}
static int efx_ef10_filter_rx_match_pri(struct efx_ef10_filter_table *table , enum efx_filter_match_flags match_flags ) 
{ 
  unsigned int match_pri ;
    klee_make_symbolic(&match_pri, sizeof(int), "match_pri");

  {
  match_pri = 0U;
  goto ldv_56853;
  ldv_56852: ;
  if ((unsigned int )table->rx_match_flags[match_pri] == (unsigned int )match_flags) {
    return ((int )match_pri);
  } else {

  }
  match_pri = match_pri + 1U;
  ldv_56853: ;
  if (table->rx_match_count > match_pri) {
    goto ldv_56852;
  } else {

  }

  return (-93);
}
}
static s32 efx_ef10_filter_insert(struct efx_nic *efx , struct efx_filter_spec *spec ,
                                  bool replace_equal ) 
{ 
  struct efx_ef10_filter_table *table ;
  unsigned long mc_rem_map[4U] ;
  struct efx_filter_spec *saved_spec ;
  unsigned int match_pri ;
  unsigned int hash ;
  unsigned int priv_flags ;
  bool replacing ;
  int ins_index ;
  wait_queue_t wait ;
  struct task_struct *tmp ;
  bool is_mc_recip ;
  s32 rc ;
  unsigned int depth ;
  unsigned int i ;
  bool tmp___0 ;
  void *tmp___1 ;
  unsigned int depth___0 ;
    klee_make_symbolic(&depth___0, sizeof(int), "depth___0");
  unsigned int i___0 ;
    klee_make_symbolic(&i___0, sizeof(int), "i___0");
  int tmp___2 ;
  efx_dword_t inbuf[27U] ;
  unsigned int tmp___3 ;
  unsigned int depth___1 ;
    klee_make_symbolic(&depth___1, sizeof(int), "depth___1");
  unsigned int i___1 ;
    klee_make_symbolic(&i___1, sizeof(int), "i___1");
  int tmp___4 ;

  {
  table = (struct efx_ef10_filter_table *)efx->filter_state;
  replacing = 0;
  ins_index = -1;
  tmp = get_current();
  wait.flags = 0U;
  wait.private = (void *)tmp;
  wait.func = & autoremove_wake_function;
  wait.task_list.next = & wait.task_list;
  wait.task_list.prev = & wait.task_list;
  if (((int )spec->flags & 24) != 8) {
    return (-22);
  } else {

  }
  rc = efx_ef10_filter_rx_match_pri(table, (enum efx_filter_match_flags )spec->match_flags);
  if (rc < 0) {
    return (rc);
  } else {

  }
  match_pri = (unsigned int )rc;
  hash = efx_ef10_filter_hash((struct efx_filter_spec  const  *)spec);
  is_mc_recip = efx_filter_is_mc_recipient((struct efx_filter_spec  const  *)spec);
  if ((int )is_mc_recip) {
    bitmap_zero((unsigned long *)(& mc_rem_map), 200U);
  } else {

  }
  ldv_56877: 
  depth = 1U;
  spin_lock_bh(& efx->filter_lock);
  ldv_56876: 
  i = (hash + depth) & 8191U;
  saved_spec = efx_ef10_filter_entry_spec((struct efx_ef10_filter_table  const  *)table,
                                          i);
  if ((unsigned long )saved_spec == (unsigned long )((struct efx_filter_spec *)0)) {
    if (ins_index < 0) {
      ins_index = (int )i;
    } else {

    }
  } else {
    tmp___0 = efx_ef10_filter_equal((struct efx_filter_spec  const  *)spec, (struct efx_filter_spec  const  *)saved_spec);
    if ((int )tmp___0) {
      if ((int )(table->entry + (unsigned long )i)->spec & 1) {
        goto ldv_56873;
      } else {

      }
      if ((int )spec->priority < (int )saved_spec->priority && (unsigned int )*((unsigned char *)spec + 1UL) != 16U) {
        rc = -1;
        goto out_unlock;
      } else {

      }
      if (! is_mc_recip) {
        if ((int )spec->priority == (int )saved_spec->priority && ! replace_equal) {
          rc = -17;
          goto out_unlock;
        } else {

        }
        ins_index = (int )i;
        goto found;
      } else
      if ((int )spec->priority > (int )saved_spec->priority || ((int )spec->priority == (int )saved_spec->priority && (int )replace_equal)) {
        if (ins_index < 0) {
          ins_index = (int )i;
        } else {
          __set_bit((long )depth, (unsigned long volatile   *)(& mc_rem_map));
        }
      } else {

      }
    } else {

    }
  }
  if (depth == 200U) {
    if (ins_index < 0) {
      rc = -16;
      goto out_unlock;
    } else {

    }
    goto found;
  } else {

  }
  depth = depth + 1U;
  goto ldv_56876;
  ldv_56873: 
  prepare_to_wait(& table->waitq, & wait, 2);
  spin_unlock_bh(& efx->filter_lock);
  schedule();
  goto ldv_56877;
  found: 
  saved_spec = efx_ef10_filter_entry_spec((struct efx_ef10_filter_table  const  *)table,
                                          (unsigned int )ins_index);
  if ((unsigned long )saved_spec != (unsigned long )((struct efx_filter_spec *)0)) {
    if ((unsigned int )*((unsigned char *)spec + 1UL) == 16U && (int )saved_spec->priority > 0) {
      if ((int )saved_spec->priority > 1) {
        saved_spec->flags = (unsigned char )((unsigned int )saved_spec->flags | 4U);
      } else {

      }
      (table->entry + (unsigned long )ins_index)->spec = (table->entry + (unsigned long )ins_index)->spec & 0xfffffffffffffffdUL;
      rc = ins_index;
      goto out_unlock;
    } else {

    }
    replacing = 1;
    priv_flags = efx_ef10_filter_entry_flags((struct efx_ef10_filter_table  const  *)table,
                                             (unsigned int )ins_index);
  } else {
    tmp___1 = kmalloc(64UL, 32U);
    saved_spec = (struct efx_filter_spec *)tmp___1;
    if ((unsigned long )saved_spec == (unsigned long )((struct efx_filter_spec *)0)) {
      rc = -12;
      goto out_unlock;
    } else {

    }
    *saved_spec = *spec;
    priv_flags = 0U;
  }
  efx_ef10_filter_set_entry(table, (unsigned int )ins_index, (struct efx_filter_spec  const  *)saved_spec,
                            priv_flags | 1U);
  if ((int )is_mc_recip) {
    depth___0 = 0U;
    goto ldv_56881;
    ldv_56880: 
    i___0 = (hash + depth___0) & 8191U;
    tmp___2 = variable_test_bit((long )depth___0, (unsigned long const volatile   *)(& mc_rem_map));
    if (tmp___2 != 0) {
      (table->entry + (unsigned long )i___0)->spec = (table->entry + (unsigned long )i___0)->spec | 1UL;
    } else {

    }
    depth___0 = depth___0 + 1U;
    ldv_56881: ;
    if (depth___0 <= 199U) {
      goto ldv_56880;
    } else {

    }

  } else {

  }
  spin_unlock_bh(& efx->filter_lock);
  rc = efx_ef10_filter_push(efx, (struct efx_filter_spec  const  *)spec, & (table->entry + (unsigned long )ins_index)->handle,
                            (int )replacing);
  spin_lock_bh(& efx->filter_lock);
  if (rc == 0) {
    if ((int )replacing) {
      if ((unsigned int )*((unsigned char *)saved_spec + 1UL) == 16U) {
        saved_spec->flags = (unsigned char )((unsigned int )saved_spec->flags | 4U);
      } else {

      }
      saved_spec->priority = spec->priority;
      saved_spec->flags = (unsigned int )saved_spec->flags & 4U;
      saved_spec->flags = (unsigned char )((int )saved_spec->flags | (int )spec->flags);
      saved_spec->rss_context = spec->rss_context;
      saved_spec->dmaq_id = spec->dmaq_id;
    } else {

    }
  } else
  if (! replacing) {
    kfree((void const   *)saved_spec);
    saved_spec = (struct efx_filter_spec *)0;
  } else {

  }
  efx_ef10_filter_set_entry(table, (unsigned int )ins_index, (struct efx_filter_spec  const  *)saved_spec,
                            priv_flags);
  if ((int )is_mc_recip) {
    inbuf[0].u32[0] = 0U;
    tmp___3 = 1U;
    while (1) {
      if (tmp___3 >= 27U) {
        break;
      } else {

      }
      inbuf[tmp___3].u32[0] = 0U;
      tmp___3 = tmp___3 + 1U;
    }
    memset((void *)(& inbuf), 0, 108UL);
    depth___1 = 0U;
    goto ldv_56894;
    ldv_56893: 
    tmp___4 = variable_test_bit((long )depth___1, (unsigned long const volatile   *)(& mc_rem_map));
    if (tmp___4 == 0) {
      goto ldv_56886;
    } else {

    }
    i___1 = (hash + depth___1) & 8191U;
    saved_spec = efx_ef10_filter_entry_spec((struct efx_ef10_filter_table  const  *)table,
                                            i___1);
    priv_flags = efx_ef10_filter_entry_flags((struct efx_ef10_filter_table  const  *)table,
                                             i___1);
    if (rc == 0) {
      spin_unlock_bh(& efx->filter_lock);
      ((efx_dword_t *)(& inbuf))->u32[0] = 3U;
      ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )(table->entry + (unsigned long )i___1)->handle;
      ((efx_dword_t *)(& inbuf) + 2U)->u32[0] = (unsigned int )((table->entry + (unsigned long )i___1)->handle >> 32);
      rc = efx_mcdi_rpc(efx, 138U, (efx_dword_t const   *)(& inbuf), 108UL, (efx_dword_t *)0,
                        0UL, (size_t *)0UL);
      spin_lock_bh(& efx->filter_lock);
    } else {

    }
    if (rc == 0) {
      kfree((void const   *)saved_spec);
      saved_spec = (struct efx_filter_spec *)0;
      priv_flags = 0U;
    } else {
      priv_flags = priv_flags & 4294967294U;
    }
    efx_ef10_filter_set_entry(table, i___1, (struct efx_filter_spec  const  *)saved_spec,
                              priv_flags);
    ldv_56886: 
    depth___1 = depth___1 + 1U;
    ldv_56894: ;
    if (depth___1 <= 199U) {
      goto ldv_56893;
    } else {

    }

  } else {

  }
  if (rc == 0) {
    rc = (s32 )(match_pri * 8192U + (unsigned int )ins_index);
  } else {

  }
  __wake_up(& table->waitq, 3U, 0, (void *)0);
  out_unlock: 
  spin_unlock_bh(& efx->filter_lock);
  finish_wait(& table->waitq, & wait);
  return (rc);
}
}
static void efx_ef10_filter_update_rx_scatter(struct efx_nic *efx ) 
{ 


  {
  return;
}
}
static int efx_ef10_filter_remove_internal(struct efx_nic *efx , unsigned int priority_mask ,
                                           u32 filter_id , bool by_index ) 
{ 
  unsigned int filter_idx ;
  struct efx_ef10_filter_table *table ;
  efx_dword_t inbuf[3U] ;
  unsigned int tmp ;
  struct efx_filter_spec *spec ;
  wait_queue_t wait ;
  struct task_struct *tmp___0 ;
  int rc ;
  int tmp___1 ;
  struct efx_filter_spec new_spec ;
  bool tmp___2 ;

  {
  filter_idx = filter_id & 8191U;
  table = (struct efx_ef10_filter_table *)efx->filter_state;
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 3U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  tmp___0 = get_current();
  wait.flags = 0U;
  wait.private = (void *)tmp___0;
  wait.func = & autoremove_wake_function;
  wait.task_list.next = & wait.task_list;
  wait.task_list.prev = & wait.task_list;
  ldv_56912: 
  spin_lock_bh(& efx->filter_lock);
  if (((table->entry + (unsigned long )filter_idx)->spec & 1UL) == 0UL) {
    goto ldv_56911;
  } else {

  }
  prepare_to_wait(& table->waitq, & wait, 2);
  spin_unlock_bh(& efx->filter_lock);
  schedule();
  goto ldv_56912;
  ldv_56911: 
  spec = efx_ef10_filter_entry_spec((struct efx_ef10_filter_table  const  *)table,
                                    filter_idx);
  if ((unsigned long )spec == (unsigned long )((struct efx_filter_spec *)0)) {
    rc = -2;
    goto out_unlock;
  } else
  if (! by_index) {
    tmp___1 = efx_ef10_filter_rx_match_pri(table, (enum efx_filter_match_flags )spec->match_flags);
    if ((u32 )tmp___1 != filter_id / 8192U) {
      rc = -2;
      goto out_unlock;
    } else {

    }
  } else {

  }
  if (((int )spec->flags & 4) != 0 && priority_mask == 2U) {
    spec->flags = (unsigned int )spec->flags & 59U;
    (table->entry + (unsigned long )filter_idx)->spec = (table->entry + (unsigned long )filter_idx)->spec & 0xfffffffffffffffdUL;
    rc = 0;
    goto out_unlock;
  } else {

  }
  if (((priority_mask >> (int )spec->priority) & 1U) == 0U) {
    rc = -2;
    goto out_unlock;
  } else {

  }
  (table->entry + (unsigned long )filter_idx)->spec = (table->entry + (unsigned long )filter_idx)->spec | 1UL;
  spin_unlock_bh(& efx->filter_lock);
  if (((int )spec->flags & 4) != 0) {
    new_spec = *spec;
    new_spec.priority = 1U;
    new_spec.flags = 9U;
    new_spec.dmaq_id = 0U;
    new_spec.rss_context = 4294967295U;
    rc = efx_ef10_filter_push(efx, (struct efx_filter_spec  const  *)(& new_spec),
                              & (table->entry + (unsigned long )filter_idx)->handle,
                              1);
    spin_lock_bh(& efx->filter_lock);
    if (rc == 0) {
      *spec = new_spec;
    } else {

    }
  } else {
    tmp___2 = efx_ef10_filter_is_exclusive((struct efx_filter_spec  const  *)spec);
    ((efx_dword_t *)(& inbuf))->u32[0] = (int )tmp___2 ? 1U : 3U;
    ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )(table->entry + (unsigned long )filter_idx)->handle;
    ((efx_dword_t *)(& inbuf) + 2U)->u32[0] = (unsigned int )((table->entry + (unsigned long )filter_idx)->handle >> 32);
    rc = efx_mcdi_rpc(efx, 138U, (efx_dword_t const   *)(& inbuf), 12UL, (efx_dword_t *)0,
                      0UL, (size_t *)0UL);
    spin_lock_bh(& efx->filter_lock);
    if (rc == 0) {
      kfree((void const   *)spec);
      efx_ef10_filter_set_entry(table, filter_idx, (struct efx_filter_spec  const  *)0,
                                0U);
    } else {

    }
  }
  (table->entry + (unsigned long )filter_idx)->spec = (table->entry + (unsigned long )filter_idx)->spec & 0xfffffffffffffffeUL;
  __wake_up(& table->waitq, 3U, 0, (void *)0);
  out_unlock: 
  spin_unlock_bh(& efx->filter_lock);
  finish_wait(& table->waitq, & wait);
  return (rc);
}
}
static int efx_ef10_filter_remove_safe(struct efx_nic *efx , enum efx_filter_priority priority ,
                                       u32 filter_id ) 
{ 
  int tmp ;

  {
  tmp = efx_ef10_filter_remove_internal(efx, 1U << (int )priority, filter_id, 0);
  return (tmp);
}
}
static int efx_ef10_filter_get_safe(struct efx_nic *efx , enum efx_filter_priority priority ,
                                    u32 filter_id , struct efx_filter_spec *spec ) 
{ 
  unsigned int filter_idx ;
  struct efx_ef10_filter_table *table ;
  struct efx_filter_spec  const  *saved_spec ;
  int rc ;
  struct efx_filter_spec *tmp ;
  int tmp___0 ;

  {
  filter_idx = filter_id & 8191U;
  table = (struct efx_ef10_filter_table *)efx->filter_state;
  spin_lock_bh(& efx->filter_lock);
  tmp = efx_ef10_filter_entry_spec((struct efx_ef10_filter_table  const  *)table,
                                   filter_idx);
  saved_spec = (struct efx_filter_spec  const  *)tmp;
  if ((unsigned long )saved_spec != (unsigned long )((struct efx_filter_spec  const  *)0) && (unsigned int )saved_spec->priority == (unsigned int )priority) {
    tmp___0 = efx_ef10_filter_rx_match_pri(table, (enum efx_filter_match_flags )saved_spec->match_flags);
    if ((u32 )tmp___0 == filter_id / 8192U) {
      *spec = *saved_spec;
      rc = 0;
    } else {
      rc = -2;
    }
  } else {
    rc = -2;
  }
  spin_unlock_bh(& efx->filter_lock);
  return (rc);
}
}
static int efx_ef10_filter_clear_rx(struct efx_nic *efx , enum efx_filter_priority priority ) 
{ 
  unsigned int priority_mask ;
    klee_make_symbolic(&priority_mask, sizeof(int), "priority_mask");
  unsigned int i ;
  int rc ;

  {
  priority_mask = ((1U << (int )((unsigned int )priority + 1U)) - 1U) & 4294967293U;
  i = 0U;
  goto ldv_56944;
  ldv_56943: 
  rc = efx_ef10_filter_remove_internal(efx, priority_mask, i, 1);
  if (rc != 0 && rc != -2) {
    return (rc);
  } else {

  }
  i = i + 1U;
  ldv_56944: ;
  if (i <= 8191U) {
    goto ldv_56943;
  } else {

  }

  return (0);
}
}
static u32 efx_ef10_filter_count_rx_used(struct efx_nic *efx , enum efx_filter_priority priority ) 
{ 
  struct efx_ef10_filter_table *table ;
  unsigned int filter_idx ;
  s32 count ;
  struct efx_filter_spec *tmp ;

  {
  table = (struct efx_ef10_filter_table *)efx->filter_state;
  count = 0;
  spin_lock_bh(& efx->filter_lock);
  filter_idx = 0U;
  goto ldv_56954;
  ldv_56953: ;
  if ((table->entry + (unsigned long )filter_idx)->spec != 0UL) {
    tmp = efx_ef10_filter_entry_spec((struct efx_ef10_filter_table  const  *)table,
                                     filter_idx);
    if ((unsigned int )tmp->priority == (unsigned int )priority) {
      count = count + 1;
    } else {

    }
  } else {

  }
  filter_idx = filter_idx + 1U;
  ldv_56954: ;
  if (filter_idx <= 8191U) {
    goto ldv_56953;
  } else {

  }
  spin_unlock_bh(& efx->filter_lock);
  return ((u32 )count);
}
}
static u32 efx_ef10_filter_get_rx_id_limit(struct efx_nic *efx ) 
{ 
  struct efx_ef10_filter_table *table ;

  {
  table = (struct efx_ef10_filter_table *)efx->filter_state;
  return (table->rx_match_count * 8192U);
}
}
static s32 efx_ef10_filter_get_rx_ids(struct efx_nic *efx , enum efx_filter_priority priority ,
                                      u32 *buf , u32 size ) 
{ 
  struct efx_ef10_filter_table *table ;
  struct efx_filter_spec *spec ;
  unsigned int filter_idx ;
  s32 count ;
  s32 tmp ;
  int tmp___0 ;

  {
  table = (struct efx_ef10_filter_table *)efx->filter_state;
  count = 0;
  spin_lock_bh(& efx->filter_lock);
  filter_idx = 0U;
  goto ldv_56972;
  ldv_56971: 
  spec = efx_ef10_filter_entry_spec((struct efx_ef10_filter_table  const  *)table,
                                    filter_idx);
  if ((unsigned long )spec != (unsigned long )((struct efx_filter_spec *)0) && (unsigned int )spec->priority == (unsigned int )priority) {
    if ((u32 )count == size) {
      count = -90;
      goto ldv_56970;
    } else {

    }
    tmp = count;
    count = count + 1;
    tmp___0 = efx_ef10_filter_rx_match_pri(table, (enum efx_filter_match_flags )spec->match_flags);
    *(buf + (unsigned long )tmp) = (unsigned int )(tmp___0 * 8192) + filter_idx;
  } else {

  }
  filter_idx = filter_idx + 1U;
  ldv_56972: ;
  if (filter_idx <= 8191U) {
    goto ldv_56971;
  } else {

  }
  ldv_56970: 
  spin_unlock_bh(& efx->filter_lock);
  return (count);
}
}
static void efx_ef10_filter_rfs_insert_complete(struct efx_nic *efx , unsigned long cookie ,
                                                int rc , efx_dword_t *outbuf , size_t outlen_actual ) ;
static s32 efx_ef10_filter_rfs_insert(struct efx_nic *efx , struct efx_filter_spec *spec ) 
{ 
  struct efx_ef10_filter_table *table ;
  efx_dword_t inbuf[27U] ;
  unsigned int tmp ;
  struct efx_filter_spec *saved_spec ;
  unsigned int hash ;
  unsigned int i ;
  unsigned int depth ;
  bool replacing ;
  int ins_index ;
  u64 cookie ;
  s32 rc ;
  bool tmp___0 ;
  void *tmp___1 ;

  {
  table = (struct efx_ef10_filter_table *)efx->filter_state;
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 27U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  depth = 1U;
  replacing = 0;
  ins_index = -1;
  hash = efx_ef10_filter_hash((struct efx_filter_spec  const  *)spec);
  spin_lock_bh(& efx->filter_lock);
  ldv_56990: 
  i = (hash + depth) & 8191U;
  saved_spec = efx_ef10_filter_entry_spec((struct efx_ef10_filter_table  const  *)table,
                                          i);
  if ((unsigned long )saved_spec == (unsigned long )((struct efx_filter_spec *)0)) {
    if (ins_index < 0) {
      ins_index = (int )i;
    } else {

    }
  } else {
    tmp___0 = efx_ef10_filter_equal((struct efx_filter_spec  const  *)spec, (struct efx_filter_spec  const  *)saved_spec);
    if ((int )tmp___0) {
      if ((int )(table->entry + (unsigned long )i)->spec & 1) {
        rc = -16;
        goto fail_unlock;
      } else {

      }
      if ((int )spec->priority < (int )saved_spec->priority) {
        rc = -1;
        goto fail_unlock;
      } else {

      }
      ins_index = (int )i;
      goto ldv_56989;
    } else {

    }
  }
  if (depth == 200U) {
    if (ins_index < 0) {
      rc = -16;
      goto fail_unlock;
    } else {

    }
    goto ldv_56989;
  } else {

  }
  depth = depth + 1U;
  goto ldv_56990;
  ldv_56989: 
  saved_spec = efx_ef10_filter_entry_spec((struct efx_ef10_filter_table  const  *)table,
                                          (unsigned int )ins_index);
  if ((unsigned long )saved_spec != (unsigned long )((struct efx_filter_spec *)0)) {
    replacing = 1;
  } else {
    tmp___1 = kmalloc(64UL, 32U);
    saved_spec = (struct efx_filter_spec *)tmp___1;
    if ((unsigned long )saved_spec == (unsigned long )((struct efx_filter_spec *)0)) {
      rc = -12;
      goto fail_unlock;
    } else {

    }
    *saved_spec = *spec;
  }
  efx_ef10_filter_set_entry(table, (unsigned int )ins_index, (struct efx_filter_spec  const  *)saved_spec,
                            1U);
  spin_unlock_bh(& efx->filter_lock);
  cookie = (u64 )((((int )replacing << 31) | (ins_index << 16)) | (int )spec->dmaq_id);
  efx_ef10_filter_push_prep(efx, (struct efx_filter_spec  const  *)spec, (efx_dword_t *)(& inbuf),
                            (table->entry + (unsigned long )ins_index)->handle, (int )replacing);
  efx_mcdi_rpc_async(efx, 138U, (efx_dword_t const   *)(& inbuf), 108UL, 12UL, & efx_ef10_filter_rfs_insert_complete,
                     (unsigned long )cookie);
  return (ins_index);
  fail_unlock: 
  spin_unlock_bh(& efx->filter_lock);
  return (rc);
}
}
static void efx_ef10_filter_rfs_insert_complete(struct efx_nic *efx , unsigned long cookie ,
                                                int rc , efx_dword_t *outbuf , size_t outlen_actual ) 
{ 
  struct efx_ef10_filter_table *table ;
  unsigned int ins_index ;
  unsigned int dmaq_id ;
    klee_make_symbolic(&dmaq_id, sizeof(int), "dmaq_id");
  struct efx_filter_spec *spec ;
  bool replacing ;

  {
  table = (struct efx_ef10_filter_table *)efx->filter_state;
  replacing = cookie >> 31 != 0UL;
  ins_index = (unsigned int )(cookie >> 16) & 8191U;
  dmaq_id = (unsigned int )cookie & 65535U;
  spin_lock_bh(& efx->filter_lock);
  spec = efx_ef10_filter_entry_spec((struct efx_ef10_filter_table  const  *)table,
                                    ins_index);
  if (rc == 0) {
    (table->entry + (unsigned long )ins_index)->handle = (unsigned long long )(outbuf + 1UL)->u32[0] | ((unsigned long long )(outbuf + 2U)->u32[0] << 32);
    if ((int )replacing) {
      spec->dmaq_id = (unsigned short )dmaq_id;
    } else {

    }
  } else
  if (! replacing) {
    kfree((void const   *)spec);
    spec = (struct efx_filter_spec *)0;
  } else {

  }
  efx_ef10_filter_set_entry(table, ins_index, (struct efx_filter_spec  const  *)spec,
                            0U);
  spin_unlock_bh(& efx->filter_lock);
  __wake_up(& table->waitq, 3U, 0, (void *)0);
  return;
}
}
static void efx_ef10_filter_rfs_expire_complete(struct efx_nic *efx , unsigned long filter_idx ,
                                                int rc , efx_dword_t *outbuf , size_t outlen_actual ) ;
static bool efx_ef10_filter_rfs_expire_one(struct efx_nic *efx , u32 flow_id , unsigned int filter_idx ) 
{ 
  struct efx_ef10_filter_table *table ;
  struct efx_filter_spec *spec ;
  struct efx_filter_spec *tmp ;
  efx_dword_t inbuf[3U] ;
  unsigned int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
  table = (struct efx_ef10_filter_table *)efx->filter_state;
  tmp = efx_ef10_filter_entry_spec((struct efx_ef10_filter_table  const  *)table,
                                   filter_idx);
  spec = tmp;
  inbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 3U) {
      break;
    } else {

    }
    inbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  if (((unsigned long )spec == (unsigned long )((struct efx_filter_spec *)0) || (int )(table->entry + (unsigned long )filter_idx)->spec & 1) || (unsigned int )*((unsigned char *)spec + 1UL) != 0U) {
    return (0);
  } else {
    tmp___1 = rps_may_expire_flow(efx->net_dev, (int )spec->dmaq_id, flow_id, (int )((u16 )filter_idx));
    if (tmp___1) {
      tmp___2 = 0;
    } else {
      tmp___2 = 1;
    }
    if (tmp___2) {
      return (0);
    } else {

    }
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = 1U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )(table->entry + (unsigned long )filter_idx)->handle;
  ((efx_dword_t *)(& inbuf) + 2U)->u32[0] = (unsigned int )((table->entry + (unsigned long )filter_idx)->handle >> 32);
  tmp___3 = efx_mcdi_rpc_async(efx, 138U, (efx_dword_t const   *)(& inbuf), 12UL,
                               0UL, & efx_ef10_filter_rfs_expire_complete, (unsigned long )filter_idx);
  if (tmp___3 != 0) {
    return (0);
  } else {

  }
  (table->entry + (unsigned long )filter_idx)->spec = (table->entry + (unsigned long )filter_idx)->spec | 1UL;
  return (1);
}
}
static void efx_ef10_filter_rfs_expire_complete(struct efx_nic *efx , unsigned long filter_idx ,
                                                int rc , efx_dword_t *outbuf , size_t outlen_actual ) 
{ 
  struct efx_ef10_filter_table *table ;
  struct efx_filter_spec *spec ;
  struct efx_filter_spec *tmp ;

  {
  table = (struct efx_ef10_filter_table *)efx->filter_state;
  tmp = efx_ef10_filter_entry_spec((struct efx_ef10_filter_table  const  *)table,
                                   (unsigned int )filter_idx);
  spec = tmp;
  spin_lock_bh(& efx->filter_lock);
  if (rc == 0) {
    kfree((void const   *)spec);
    efx_ef10_filter_set_entry(table, (unsigned int )filter_idx, (struct efx_filter_spec  const  *)0,
                              0U);
  } else {

  }
  (table->entry + filter_idx)->spec = (table->entry + filter_idx)->spec & 0xfffffffffffffffeUL;
  __wake_up(& table->waitq, 3U, 0, (void *)0);
  spin_unlock_bh(& efx->filter_lock);
  return;
}
}
static int efx_ef10_filter_match_flags_from_mcdi(u32 mcdi_flags ) 
{ 
  int match_flags ;
    klee_make_symbolic(&match_flags, sizeof(int), "match_flags");
  u32 old_mcdi_flags ;
  u32 old_mcdi_flags___0 ;
  u32 old_mcdi_flags___1 ;
  u32 old_mcdi_flags___2 ;
  u32 old_mcdi_flags___3 ;
  u32 old_mcdi_flags___4 ;
  u32 old_mcdi_flags___5 ;
  u32 old_mcdi_flags___6 ;
  u32 old_mcdi_flags___7 ;
  u32 old_mcdi_flags___8 ;
  u32 old_mcdi_flags___9 ;
  u32 old_mcdi_flags___10 ;

  {
  match_flags = 0;
  old_mcdi_flags = mcdi_flags;
  mcdi_flags = mcdi_flags & 2147483647U;
  if (mcdi_flags != old_mcdi_flags) {
    match_flags = match_flags | 1024;
  } else {

  }
  old_mcdi_flags___0 = mcdi_flags;
  mcdi_flags = mcdi_flags & 3221225471U;
  if (mcdi_flags != old_mcdi_flags___0) {
    match_flags = match_flags | 1024;
  } else {

  }
  old_mcdi_flags___1 = mcdi_flags;
  mcdi_flags = mcdi_flags & 4294967294U;
  if (mcdi_flags != old_mcdi_flags___1) {
    match_flags = match_flags | 1;
  } else {

  }
  old_mcdi_flags___2 = mcdi_flags;
  mcdi_flags = mcdi_flags & 4294967293U;
  if (mcdi_flags != old_mcdi_flags___2) {
    match_flags = match_flags | 2;
  } else {

  }
  old_mcdi_flags___3 = mcdi_flags;
  mcdi_flags = mcdi_flags & 4294967291U;
  if (mcdi_flags != old_mcdi_flags___3) {
    match_flags = match_flags | 4;
  } else {

  }
  old_mcdi_flags___4 = mcdi_flags;
  mcdi_flags = mcdi_flags & 4294967287U;
  if (mcdi_flags != old_mcdi_flags___4) {
    match_flags = match_flags | 8;
  } else {

  }
  old_mcdi_flags___5 = mcdi_flags;
  mcdi_flags = mcdi_flags & 4294967279U;
  if (mcdi_flags != old_mcdi_flags___5) {
    match_flags = match_flags | 16;
  } else {

  }
  old_mcdi_flags___6 = mcdi_flags;
  mcdi_flags = mcdi_flags & 4294967263U;
  if (mcdi_flags != old_mcdi_flags___6) {
    match_flags = match_flags | 32;
  } else {

  }
  old_mcdi_flags___7 = mcdi_flags;
  mcdi_flags = mcdi_flags & 4294967231U;
  if (mcdi_flags != old_mcdi_flags___7) {
    match_flags = match_flags | 64;
  } else {

  }
  old_mcdi_flags___8 = mcdi_flags;
  mcdi_flags = mcdi_flags & 4294967167U;
  if (mcdi_flags != old_mcdi_flags___8) {
    match_flags = match_flags | 128;
  } else {

  }
  old_mcdi_flags___9 = mcdi_flags;
  mcdi_flags = mcdi_flags & 4294967039U;
  if (mcdi_flags != old_mcdi_flags___9) {
    match_flags = match_flags | 256;
  } else {

  }
  old_mcdi_flags___10 = mcdi_flags;
  mcdi_flags = mcdi_flags & 4294966783U;
  if (mcdi_flags != old_mcdi_flags___10) {
    match_flags = match_flags | 512;
  } else {

  }
  if (mcdi_flags != 0U) {
    return (-22);
  } else {

  }
  return (match_flags);
}
}
static int efx_ef10_filter_table_probe(struct efx_nic *efx ) 
{ 
  efx_dword_t inbuf[1U] ;
  efx_dword_t outbuf[63U] ;
  unsigned int tmp ;
  unsigned int pd_match_pri ;
    klee_make_symbolic(&pd_match_pri, sizeof(int), "pd_match_pri");
  unsigned int pd_match_count ;
    klee_make_symbolic(&pd_match_count, sizeof(int), "pd_match_count");
  struct efx_ef10_filter_table *table ;
  size_t outlen ;
  int rc ;
  void *tmp___0 ;
  size_t __min1 ;
  size_t __min2 ;
  u32 mcdi_flags ;
  struct _ddebug descriptor ;
  long tmp___1 ;
  struct _ddebug descriptor___0 ;
  long tmp___2 ;
  unsigned int tmp___3 ;
  void *tmp___4 ;
  struct lock_class_key __key ;

  {
  inbuf[0].u32[0] = 0U;
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 63U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  tmp___0 = kzalloc(2656UL, 208U);
  table = (struct efx_ef10_filter_table *)tmp___0;
  if ((unsigned long )table == (unsigned long )((struct efx_ef10_filter_table *)0)) {
    return (-12);
  } else {

  }
  ((efx_dword_t *)(& inbuf))->u32[0] = 1U;
  rc = efx_mcdi_rpc(efx, 228U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)(& outbuf),
                    252UL, & outlen);
  if (rc != 0) {
    goto fail;
  } else {

  }
  __min1 = 61UL;
  __min2 = (outlen - 8UL) / 4UL;
  pd_match_count = (unsigned int )(__min1 < __min2 ? __min1 : __min2);
  table->rx_match_count = 0U;
  pd_match_pri = 0U;
  goto ldv_57089;
  ldv_57088: 
  mcdi_flags = ((efx_dword_t *)(& outbuf) + ((unsigned long )pd_match_pri + 2UL) * 4UL)->u32[0];
  rc = efx_ef10_filter_match_flags_from_mcdi(mcdi_flags);
  if (rc < 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_ef10_filter_table_probe";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
      descriptor.format = "%s: fw flags %#x pri %u not supported in driver\n";
      descriptor.lineno = 3538U;
      descriptor.flags = 0U;
      tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp___1 != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "%s: fw flags %#x pri %u not supported in driver\n",
                             "efx_ef10_filter_table_probe", mcdi_flags, pd_match_pri);
      } else {

      }
    } else {

    }
  } else {
    if ((efx->msg_enable & 2U) != 0U) {
      descriptor___0.modname = "sfc";
      descriptor___0.function = "efx_ef10_filter_table_probe";
      descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
      descriptor___0.format = "%s: fw flags %#x pri %u supported as driver flags %#x pri %u\n";
      descriptor___0.lineno = 3543U;
      descriptor___0.flags = 0U;
      tmp___2 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
      if (tmp___2 != 0L) {
        __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                             "%s: fw flags %#x pri %u supported as driver flags %#x pri %u\n",
                             "efx_ef10_filter_table_probe", mcdi_flags, pd_match_pri,
                             rc, table->rx_match_count);
      } else {

      }
    } else {

    }
    tmp___3 = table->rx_match_count;
    table->rx_match_count = table->rx_match_count + 1U;
    table->rx_match_flags[tmp___3] = (enum efx_filter_match_flags )rc;
  }
  pd_match_pri = pd_match_pri + 1U;
  ldv_57089: ;
  if (pd_match_pri < pd_match_count) {
    goto ldv_57088;
  } else {

  }
  tmp___4 = vzalloc(131072UL);
  table->entry = (struct __anonstruct_531 *)tmp___4;
  if ((unsigned long )table->entry == (unsigned long )((struct __anonstruct_533 *)0)) {
    rc = -12;
    goto fail;
  } else {

  }
  efx->filter_state = (void *)table;
  __init_waitqueue_head(& table->waitq, "&table->waitq", & __key);
  return (0);
  fail: 
  kfree((void const   *)table);
  return (rc);
}
}
static void efx_ef10_filter_table_restore(struct efx_nic *efx ) 
{ 
  struct efx_ef10_filter_table *table ;
  struct efx_ef10_nic_data *nic_data ;
  struct efx_filter_spec *spec ;
  unsigned int filter_idx ;
  bool failed ;
  int rc ;
  int __ret_warn_on ;
  int tmp ;
  long tmp___0 ;

  {
  table = (struct efx_ef10_filter_table *)efx->filter_state;
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  failed = 0;
  tmp = rwsem_is_locked(& efx->filter_sem);
  __ret_warn_on = tmp == 0;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                       3575);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (! nic_data->must_restore_filters) {
    return;
  } else {

  }
  if ((unsigned long )table == (unsigned long )((struct efx_ef10_filter_table *)0)) {
    return;
  } else {

  }
  spin_lock_bh(& efx->filter_lock);
  filter_idx = 0U;
  goto ldv_57105;
  ldv_57104: 
  spec = efx_ef10_filter_entry_spec((struct efx_ef10_filter_table  const  *)table,
                                    filter_idx);
  if ((unsigned long )spec == (unsigned long )((struct efx_filter_spec *)0)) {
    goto ldv_57103;
  } else {

  }
  (table->entry + (unsigned long )filter_idx)->spec = (table->entry + (unsigned long )filter_idx)->spec | 1UL;
  spin_unlock_bh(& efx->filter_lock);
  rc = efx_ef10_filter_push(efx, (struct efx_filter_spec  const  *)spec, & (table->entry + (unsigned long )filter_idx)->handle,
                            0);
  if (rc != 0) {
    failed = 1;
  } else {

  }
  spin_lock_bh(& efx->filter_lock);
  if (rc != 0) {
    kfree((void const   *)spec);
    efx_ef10_filter_set_entry(table, filter_idx, (struct efx_filter_spec  const  *)0,
                              0U);
  } else {
    (table->entry + (unsigned long )filter_idx)->spec = (table->entry + (unsigned long )filter_idx)->spec & 0xfffffffffffffffeUL;
  }
  ldv_57103: 
  filter_idx = filter_idx + 1U;
  ldv_57105: ;
  if (filter_idx <= 8191U) {
    goto ldv_57104;
  } else {

  }
  spin_unlock_bh(& efx->filter_lock);
  if ((int )failed) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "unable to restore all filters\n");
    } else {

    }
  } else {
    nic_data->must_restore_filters = 0;
  }
  return;
}
}
static void efx_ef10_filter_table_remove(struct efx_nic *efx ) 
{ 
  struct efx_ef10_filter_table *table ;
  efx_dword_t inbuf[27U] ;
  unsigned int tmp ;
  struct efx_filter_spec *spec ;
  unsigned int filter_idx ;
  int rc ;
  bool tmp___0 ;
  int __ret_warn_on ;
  char const   *tmp___1 ;
  char const   *tmp___2 ;
  long tmp___3 ;

  {
  table = (struct efx_ef10_filter_table *)efx->filter_state;
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 27U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  efx->filter_state = (void *)0;
  if ((unsigned long )table == (unsigned long )((struct efx_ef10_filter_table *)0)) {
    return;
  } else {

  }
  filter_idx = 0U;
  goto ldv_57125;
  ldv_57124: 
  spec = efx_ef10_filter_entry_spec((struct efx_ef10_filter_table  const  *)table,
                                    filter_idx);
  if ((unsigned long )spec == (unsigned long )((struct efx_filter_spec *)0)) {
    goto ldv_57115;
  } else {

  }
  tmp___0 = efx_ef10_filter_is_exclusive((struct efx_filter_spec  const  *)spec);
  ((efx_dword_t *)(& inbuf))->u32[0] = (int )tmp___0 ? 1U : 3U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )(table->entry + (unsigned long )filter_idx)->handle;
  ((efx_dword_t *)(& inbuf) + 2U)->u32[0] = (unsigned int )((table->entry + (unsigned long )filter_idx)->handle >> 32);
  rc = efx_mcdi_rpc(efx, 138U, (efx_dword_t const   *)(& inbuf), 108UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  if (rc != 0) {
    __ret_warn_on = 1;
    tmp___3 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___3 != 0L) {
      tmp___1 = netdev_reg_state((struct net_device  const  *)efx->net_dev);
      tmp___2 = netdev_name((struct net_device  const  *)efx->net_dev);
      warn_slowpath_fmt("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                        3648, "netdevice: %s%s\nfilter_idx=%#x handle=%#llx\n", tmp___2,
                        tmp___1, filter_idx, (table->entry + (unsigned long )filter_idx)->handle);
    } else {

    }
    ldv__builtin_expect(__ret_warn_on != 0, 0L);
  } else {

  }
  kfree((void const   *)spec);
  ldv_57115: 
  filter_idx = filter_idx + 1U;
  ldv_57125: ;
  if (filter_idx <= 8191U) {
    goto ldv_57124;
  } else {

  }
  vfree((void const   *)table->entry);
  kfree((void const   *)table);
  return;
}
}
static void efx_ef10_filter_sync_rx_mode(struct efx_nic *efx ) 
{ 
  struct efx_ef10_filter_table *table ;
  struct net_device *net_dev ;
  struct efx_filter_spec spec ;
  bool remove_failed ;
  struct netdev_hw_addr *uc ;
  struct netdev_hw_addr *mc ;
  unsigned int filter_idx ;
  int i ;
  int n ;
    klee_make_symbolic(&n, sizeof(int), "n");
  int rc ;
  int tmp ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;
  struct list_head  const  *__mptr___2 ;
  int tmp___0 ;
  int __ret_warn_on ;
  long tmp___1 ;
  int tmp___2 ;
  int __ret_warn_on___0 ;
  long tmp___3 ;
  int tmp___4 ;
  unsigned long __var ;
  int __ret_warn_on___1 ;
    klee_make_symbolic(&__ret_warn_on___1, sizeof(int), "__ret_warn_on___1");
  long tmp___5 ;

  {
  table = (struct efx_ef10_filter_table *)efx->filter_state;
  net_dev = efx->net_dev;
  remove_failed = 0;
  tmp = efx_dev_registered(efx);
  if (tmp == 0) {
    return;
  } else {

  }
  if ((unsigned long )table == (unsigned long )((struct efx_ef10_filter_table *)0)) {
    return;
  } else {

  }
  spin_lock_bh(& efx->filter_lock);
  n = table->dev_uc_count >= 0 ? table->dev_uc_count : 1;
  i = 0;
  goto ldv_57141;
  ldv_57140: 
  filter_idx = (unsigned int )table->dev_uc_list[i].id & 8191U;
  (table->entry + (unsigned long )filter_idx)->spec = (table->entry + (unsigned long )filter_idx)->spec | 2UL;
  i = i + 1;
  ldv_57141: ;
  if (i < n) {
    goto ldv_57140;
  } else {

  }
  n = table->dev_mc_count >= 0 ? table->dev_mc_count : 1;
  i = 0;
  goto ldv_57144;
  ldv_57143: 
  filter_idx = (unsigned int )table->dev_mc_list[i].id & 8191U;
  (table->entry + (unsigned long )filter_idx)->spec = (table->entry + (unsigned long )filter_idx)->spec | 2UL;
  i = i + 1;
  ldv_57144: ;
  if (i < n) {
    goto ldv_57143;
  } else {

  }
  spin_unlock_bh(& efx->filter_lock);
  netif_addr_lock_bh(net_dev);
  if ((net_dev->flags & 256U) != 0U || net_dev->uc.count > 31) {
    table->dev_uc_count = -1;
  } else {
    table->dev_uc_count = net_dev->uc.count + 1;
    ether_addr_copy((u8 *)(& table->dev_uc_list[0].addr), (u8 const   *)net_dev->dev_addr);
    i = 1;
    __mptr = (struct list_head  const  *)net_dev->uc.list.next;
    uc = (struct netdev_hw_addr *)__mptr;
    goto ldv_57151;
    ldv_57150: 
    ether_addr_copy((u8 *)(& table->dev_uc_list[i].addr), (u8 const   *)(& uc->addr));
    i = i + 1;
    __mptr___0 = (struct list_head  const  *)uc->list.next;
    uc = (struct netdev_hw_addr *)__mptr___0;
    ldv_57151: ;
    if ((unsigned long )(& uc->list) != (unsigned long )(& net_dev->uc.list)) {
      goto ldv_57150;
    } else {

    }

  }
  if ((net_dev->flags & 768U) != 0U || net_dev->mc.count > 255) {
    table->dev_mc_count = -1;
  } else {
    table->dev_mc_count = net_dev->mc.count + 1;
    eth_broadcast_addr((u8 *)(& table->dev_mc_list[0].addr));
    i = 1;
    __mptr___1 = (struct list_head  const  *)net_dev->mc.list.next;
    mc = (struct netdev_hw_addr *)__mptr___1;
    goto ldv_57158;
    ldv_57157: 
    ether_addr_copy((u8 *)(& table->dev_mc_list[i].addr), (u8 const   *)(& mc->addr));
    i = i + 1;
    __mptr___2 = (struct list_head  const  *)mc->list.next;
    mc = (struct netdev_hw_addr *)__mptr___2;
    ldv_57158: ;
    if ((unsigned long )(& mc->list) != (unsigned long )(& net_dev->mc.list)) {
      goto ldv_57157;
    } else {

    }

  }
  netif_addr_unlock_bh(net_dev);
  if (table->dev_uc_count >= 0) {
    i = 0;
    goto ldv_57165;
    ldv_57164: 
    efx_filter_init_rx(& spec, 1, 1, 0U);
    efx_filter_set_eth_local(& spec, 65535, (u8 const   *)(& table->dev_uc_list[i].addr));
    rc = efx_ef10_filter_insert(efx, & spec, 1);
    if (rc < 0) {
      goto ldv_57161;
      ldv_57160: 
      efx_ef10_filter_remove_safe(efx, 1, (u32 )table->dev_uc_list[i].id);
      ldv_57161: 
      tmp___0 = i;
      i = i - 1;
      if (tmp___0 != 0) {
        goto ldv_57160;
      } else {

      }
      table->dev_uc_count = -1;
      goto ldv_57163;
    } else {

    }
    table->dev_uc_list[i].id = (u16 )rc;
    i = i + 1;
    ldv_57165: ;
    if (table->dev_uc_count > i) {
      goto ldv_57164;
    } else {

    }
    ldv_57163: ;
  } else {

  }
  if (table->dev_uc_count < 0) {
    efx_filter_init_rx(& spec, 1, 1, 0U);
    efx_filter_set_uc_def(& spec);
    rc = efx_ef10_filter_insert(efx, & spec, 1);
    if (rc < 0) {
      __ret_warn_on = 1;
      tmp___1 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
      if (tmp___1 != 0L) {
        warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                           3748);
      } else {

      }
      ldv__builtin_expect(__ret_warn_on != 0, 0L);
      table->dev_uc_count = 0;
    } else {
      table->dev_uc_list[0].id = (u16 )rc;
    }
  } else {

  }
  if (table->dev_mc_count >= 0) {
    i = 0;
    goto ldv_57173;
    ldv_57172: 
    efx_filter_init_rx(& spec, 1, 1, 0U);
    efx_filter_set_eth_local(& spec, 65535, (u8 const   *)(& table->dev_mc_list[i].addr));
    rc = efx_ef10_filter_insert(efx, & spec, 1);
    if (rc < 0) {
      goto ldv_57169;
      ldv_57168: 
      efx_ef10_filter_remove_safe(efx, 1, (u32 )table->dev_mc_list[i].id);
      ldv_57169: 
      tmp___2 = i;
      i = i - 1;
      if (tmp___2 != 0) {
        goto ldv_57168;
      } else {

      }
      table->dev_mc_count = -1;
      goto ldv_57171;
    } else {

    }
    table->dev_mc_list[i].id = (u16 )rc;
    i = i + 1;
    ldv_57173: ;
    if (table->dev_mc_count > i) {
      goto ldv_57172;
    } else {

    }
    ldv_57171: ;
  } else {

  }
  if (table->dev_mc_count < 0) {
    efx_filter_init_rx(& spec, 1, 1, 0U);
    efx_filter_set_mc_def(& spec);
    rc = efx_ef10_filter_insert(efx, & spec, 1);
    if (rc < 0) {
      __ret_warn_on___0 = 1;
      tmp___3 = ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
      if (tmp___3 != 0L) {
        warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                           3783);
      } else {

      }
      ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
      table->dev_mc_count = 0;
    } else {
      table->dev_mc_list[0].id = (u16 )rc;
    }
  } else {

  }
  i = 0;
  goto ldv_57179;
  ldv_57178: 
  __var = 0UL;
  if (((unsigned long )*((unsigned long volatile   *)(& (table->entry + (unsigned long )i)->spec)) & 2UL) != 0UL) {
    tmp___4 = efx_ef10_filter_remove_internal(efx, 2U, (u32 )i, 1);
    if (tmp___4 < 0) {
      remove_failed = 1;
    } else {

    }
  } else {

  }
  i = i + 1;
  ldv_57179: ;
  if (i <= 8191) {
    goto ldv_57178;
  } else {

  }
  __ret_warn_on___1 = (int )remove_failed;
  tmp___5 = ldv__builtin_expect(__ret_warn_on___1 != 0, 0L);
  if (tmp___5 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
                       3804);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on___1 != 0, 0L);
  return;
}
}
static int efx_ef10_set_mac_address(struct efx_nic *efx ) 
{ 
  efx_dword_t inbuf[3U] ;
  unsigned int tmp ;
  struct efx_ef10_nic_data *nic_data ;
  bool was_enabled ;
  int rc ;
  struct pci_dev *pci_dev_pf ;
  struct efx_nic *efx_pf ;
  void *tmp___0 ;
  int tmp___1 ;
  struct pci_dev *pci_dev_pf___0 ;
  struct efx_nic *efx_pf___0 ;
  void *tmp___2 ;
  struct efx_ef10_nic_data *nic_data___0 ;
  unsigned int i ;
  struct ef10_vf *vf ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 3U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  was_enabled = efx->port_enabled;
  efx_device_detach_sync___0(efx);
  efx_net_stop(efx->net_dev);
  down_write(& efx->filter_sem);
  efx_ef10_filter_table_remove(efx);
  ether_addr_copy((u8 *)(& inbuf) + 4UL, (u8 const   *)(efx->net_dev)->dev_addr);
  ((efx_dword_t *)(& inbuf))->u32[0] = nic_data->vport_id;
  rc = efx_mcdi_rpc(efx, 93U, (efx_dword_t const   *)(& inbuf), 12UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  efx_ef10_filter_table_probe(efx);
  up_write(& efx->filter_sem);
  if ((int )was_enabled) {
    efx_net_open(efx->net_dev);
  } else {

  }
  netif_device_attach(efx->net_dev);
  if (rc == -1) {
    pci_dev_pf = (efx->pci_dev)->__annonCompField58.physfn;
    if ((unsigned int )*((unsigned char *)efx->pci_dev + 2531UL) != 0U && (unsigned long )pci_dev_pf != (unsigned long )((struct pci_dev *)0)) {
      tmp___0 = pci_get_drvdata(pci_dev_pf);
      efx_pf = (struct efx_nic *)tmp___0;
      tmp___1 = efx_ef10_sriov_set_vf_mac(efx_pf, (int )nic_data->vf_index, (efx->net_dev)->dev_addr);
      if (tmp___1 == 0) {
        return (0);
      } else {

      }
    } else {

    }
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Cannot change MAC address; use sfboot to enable mac-spoofing on this interface\n");
    } else {

    }
  } else
  if ((unsigned int )*((unsigned char *)efx->pci_dev + 2531UL) != 0U) {
    pci_dev_pf___0 = (efx->pci_dev)->__annonCompField58.physfn;
    if ((unsigned long )pci_dev_pf___0 != (unsigned long )((struct pci_dev *)0)) {
      tmp___2 = pci_get_drvdata(pci_dev_pf___0);
      efx_pf___0 = (struct efx_nic *)tmp___2;
      nic_data___0 = (struct efx_ef10_nic_data *)efx_pf___0->nic_data;
      i = 0U;
      goto ldv_57200;
      ldv_57199: 
      vf = nic_data___0->vf + (unsigned long )i;
      if ((unsigned long )vf->efx == (unsigned long )efx) {
        ether_addr_copy((u8 *)(& vf->mac), (u8 const   *)(efx->net_dev)->dev_addr);
        return (0);
      } else {

      }
      i = i + 1U;
      ldv_57200: ;
      if (efx_pf___0->vf_count > i) {
        goto ldv_57199;
      } else {

      }

    } else {

    }
  } else {

  }
  return (rc);
}
}
static int efx_ef10_mac_reconfigure(struct efx_nic *efx ) 
{ 
  int tmp ;

  {
  efx_ef10_filter_sync_rx_mode(efx);
  tmp = efx_mcdi_set_mac(efx);
  return (tmp);
}
}
static int efx_ef10_mac_reconfigure_vf(struct efx_nic *efx ) 
{ 


  {
  efx_ef10_filter_sync_rx_mode(efx);
  return (0);
}
}
static int efx_ef10_start_bist(struct efx_nic *efx , u32 bist_type ) 
{ 
  efx_dword_t inbuf[1U] ;
  int tmp ;

  {
  inbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = bist_type;
  tmp = efx_mcdi_rpc(efx, 37U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
                     0UL, (size_t *)0UL);
  return (tmp);
}
}
static int efx_ef10_poll_bist(struct efx_nic *efx ) 
{ 
  int rc ;
  efx_dword_t outbuf[2U] ;
  unsigned int tmp ;
  size_t outlen ;
  u32 result ;
  struct _ddebug descriptor ;
  long tmp___0 ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  rc = efx_mcdi_rpc(efx, 38U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    8UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 7UL) {
    return (-5);
  } else {

  }
  result = ((efx_dword_t *)(& outbuf))->u32[0];
  switch (result) {
  case 2U: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_ef10_poll_bist";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
    descriptor.format = "BIST passed.\n";
    descriptor.lineno = 3924U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "BIST passed.\n");
    } else {

    }
  } else {

  }
  return (0);
  case 4U: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "BIST timed out\n");
  } else {

  }
  return (-5);
  case 3U: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "BIST failed.\n");
  } else {

  }
  return (-5);
  default: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "BIST returned unknown result %u",
               result);
  } else {

  }
  return (-5);
  }
}
}
static int efx_ef10_run_bist(struct efx_nic *efx , u32 bist_type ) 
{ 
  int rc ;
  struct _ddebug descriptor ;
  long tmp ;
  int tmp___0 ;

  {
  if ((int )efx->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_ef10_run_bist";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c";
    descriptor.format = "starting BIST type %u\n";
    descriptor.lineno = 3943U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "starting BIST type %u\n", bist_type);
    } else {

    }
  } else {

  }
  rc = efx_ef10_start_bist(efx, bist_type);
  if (rc != 0) {
    return (rc);
  } else {

  }
  tmp___0 = efx_ef10_poll_bist(efx);
  return (tmp___0);
}
}
static int efx_ef10_test_chip(struct efx_nic *efx , struct efx_self_tests *tests ) 
{ 
  int rc ;
  int rc2 ;
  int tmp ;
  int tmp___0 ;

  {
  efx_reset_down(efx, 3);
  rc = efx_mcdi_rpc(efx, 237U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)0, 0UL,
                    (size_t *)0UL);
  if (rc != 0) {
    goto out;
  } else {

  }
  tmp = efx_ef10_run_bist(efx, 6U);
  tests->memory = tmp != 0 ? -1 : 1;
  tmp___0 = efx_ef10_run_bist(efx, 8U);
  tests->registers = tmp___0 != 0 ? -1 : 1;
  rc = efx_mcdi_reset(efx, 3);
  out: 
  rc2 = efx_reset_up(efx, 3, rc == 0);
  return (rc != 0 ? rc : rc2);
}
}
static struct efx_ef10_nvram_type_info  const  efx_ef10_nvram_types[11U]  = 
  {      {256U, 0U, 0U, "sfc_mcfw"}, 
        {512U, 0U, 0U, "sfc_mcfw_backup"}, 
        {768U, 0U, 0U, "sfc_exp_rom"}, 
        {1024U, 0U, 0U, "sfc_static_cfg"}, 
        {1280U, 0U, 0U, "sfc_dynamic_cfg"}, 
        {1536U, 0U, 0U, "sfc_exp_rom_cfg"}, 
        {1537U, 0U, 1U, "sfc_exp_rom_cfg"}, 
        {1538U, 0U, 2U, "sfc_exp_rom_cfg"}, 
        {1539U, 0U, 3U, "sfc_exp_rom_cfg"}, 
        {2304U, 0U, 0U, "sfc_license"}, 
        {2560U, 255U, 0U, "sfc_phy_fw"}};
static int efx_ef10_mtd_probe_partition(struct efx_nic *efx , struct efx_mcdi_mtd_partition *part ,
                                        unsigned int type ) 
{ 
  efx_dword_t inbuf[1U] ;
  efx_dword_t outbuf[63U] ;
  unsigned int tmp ;
  struct efx_ef10_nvram_type_info  const  *info ;
  size_t size ;
  size_t erase_size ;
  size_t outlen ;
  bool protected ;
  int rc ;
  unsigned int tmp___0 ;

  {
  inbuf[0].u32[0] = 0U;
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 63U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  info = (struct efx_ef10_nvram_type_info  const  *)(& efx_ef10_nvram_types);
  ldv_57268: ;
  if ((unsigned long )info == (unsigned long )((struct efx_ef10_nvram_type_info  const  *)(& efx_ef10_nvram_types) + 11UL)) {
    return (-19);
  } else {

  }
  if (((unsigned int )(~ ((int )info->type_mask)) & type) == (unsigned int )info->type) {
    goto ldv_57267;
  } else {

  }
  info = info + 1;
  goto ldv_57268;
  ldv_57267: 
  tmp___0 = efx_port_num(efx);
  if ((unsigned int )info->port != tmp___0) {
    return (-19);
  } else {

  }
  rc = efx_mcdi_nvram_info(efx, type, & size, & erase_size, & protected);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if ((int )protected) {
    return (-19);
  } else {

  }
  part->nvram_type = (u16 )type;
  ((efx_dword_t *)(& inbuf))->u32[0] = type;
  rc = efx_mcdi_rpc(efx, 82U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)(& outbuf),
                    252UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 19UL) {
    return (-5);
  } else {

  }
  if ((int )((efx_dword_t *)(& outbuf) + 1UL)->u32[0] & 1) {
    part->fw_subtype = (u16 )((efx_dword_t *)(& outbuf) + 2UL)->u32[0];
  } else {

  }
  part->common.dev_type_name = "EF10 NVRAM manager";
  part->common.type_name = info->name;
  part->common.mtd.type = 3U;
  part->common.mtd.flags = 3072U;
  part->common.mtd.size = (uint64_t )size;
  part->common.mtd.erasesize = (uint32_t )erase_size;
  return (0);
}
}
static int efx_ef10_mtd_probe(struct efx_nic *efx ) 
{ 
  efx_dword_t outbuf[63U] ;
  unsigned int tmp ;
  struct efx_mcdi_mtd_partition *parts ;
  size_t outlen ;
  size_t n_parts_total ;
  size_t i ;
  size_t n_parts ;
  unsigned int type ;
  int rc ;
  int tmp___0 ;
  long tmp___1 ;
  size_t __min1 ;
  size_t __min2 ;
  void *tmp___2 ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 63U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  tmp___0 = rtnl_is_locked();
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    printk("\vRTNL: assertion failed at %s (%d)\n", (char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10.c",
           4056);
    dump_stack();
  } else {

  }
  rc = efx_mcdi_rpc(efx, 81U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    252UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 3UL) {
    return (-5);
  } else {

  }
  n_parts_total = (size_t )((efx_dword_t *)(& outbuf))->u32[0];
  __min1 = 62UL;
  __min2 = (outlen - 4UL) / 4UL;
  if ((__min1 < __min2 ? __min1 : __min2) < n_parts_total) {
    return (-5);
  } else {

  }
  tmp___2 = kcalloc(n_parts_total, 1904UL, 208U);
  parts = (struct efx_mcdi_mtd_partition *)tmp___2;
  if ((unsigned long )parts == (unsigned long )((struct efx_mcdi_mtd_partition *)0)) {
    return (-12);
  } else {

  }
  n_parts = 0UL;
  i = 0UL;
  goto ldv_57311;
  ldv_57310: 
  type = ((efx_dword_t *)(& outbuf) + (i + 1UL) * 4UL)->u32[0];
  rc = efx_ef10_mtd_probe_partition(efx, parts + n_parts, type);
  if (rc == 0) {
    n_parts = n_parts + 1UL;
  } else
  if (rc != -19) {
    goto fail;
  } else {

  }
  i = i + 1UL;
  ldv_57311: ;
  if (i < n_parts_total) {
    goto ldv_57310;
  } else {

  }
  rc = efx_mtd_add(efx, & parts->common, n_parts, 1904UL);
  fail: ;
  if (rc != 0) {
    kfree((void const   *)parts);
  } else {

  }
  return (rc);
}
}
static void efx_ef10_ptp_write_host_time(struct efx_nic *efx , u32 host_time ) 
{ 


  {
  _efx_writed(efx, host_time, 512U);
  return;
}
}
static void efx_ef10_ptp_write_host_time_vf(struct efx_nic *efx , u32 host_time ) 
{ 


  {
  return;
}
}
static int efx_ef10_rx_enable_timestamping(struct efx_channel *channel , bool temp ) 
{ 
  efx_dword_t inbuf[3U] ;
  unsigned int tmp ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 3U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  if (((unsigned int )channel->sync_events_state == 2U || (unsigned int )channel->sync_events_state == 3U) || ((int )temp && (unsigned int )channel->sync_events_state == 0U)) {
    return (0);
  } else {

  }
  channel->sync_events_state = 2;
  ((efx_dword_t *)(& inbuf))->u32[0] = 24U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = 0U;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = (unsigned int )channel->channel;
  rc = efx_mcdi_rpc(channel->efx, 11U, (efx_dword_t const   *)(& inbuf), 12UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  if (rc != 0) {
    channel->sync_events_state = (enum efx_sync_events_state )temp;
  } else {

  }
  return (rc);
}
}
static int efx_ef10_rx_disable_timestamping(struct efx_channel *channel , bool temp ) 
{ 
  efx_dword_t inbuf[4U] ;
  unsigned int tmp ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 4U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  if ((unsigned int )channel->sync_events_state == 0U || ((int )temp && (unsigned int )channel->sync_events_state == 1U)) {
    return (0);
  } else {

  }
  if ((unsigned int )channel->sync_events_state == 1U) {
    channel->sync_events_state = 0;
    return (0);
  } else {

  }
  channel->sync_events_state = (enum efx_sync_events_state )temp;
  ((efx_dword_t *)(& inbuf))->u32[0] = 25U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = 0U;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = 0U;
  ((efx_dword_t *)(& inbuf) + 3UL)->u32[0] = (unsigned int )channel->channel;
  rc = efx_mcdi_rpc(channel->efx, 11U, (efx_dword_t const   *)(& inbuf), 16UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  return (rc);
}
}
static int efx_ef10_ptp_set_ts_sync_events(struct efx_nic *efx , bool en , bool temp ) 
{ 
  int (*set)(struct efx_channel * , bool  ) ;
  struct efx_channel *channel ;
  int rc ;
  int tmp ;

  {
  set = (int )en ? & efx_ef10_rx_enable_timestamping : & efx_ef10_rx_disable_timestamping;
  channel = efx->channel[0];
  goto ldv_57358;
  ldv_57357: 
  tmp = (*set)(channel, (int )temp);
  rc = tmp;
  if ((int )en && rc != 0) {
    efx_ef10_ptp_set_ts_sync_events(efx, 0, (int )temp);
    return (rc);
  } else {

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_57358: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_57357;
  } else {

  }

  return (0);
}
}
static int efx_ef10_ptp_set_ts_config_vf(struct efx_nic *efx , struct hwtstamp_config *init ) 
{ 


  {
  return (-95);
}
}
static int efx_ef10_ptp_set_ts_config(struct efx_nic *efx , struct hwtstamp_config *init ) 
{ 
  int rc ;
  int tmp ;

  {
  switch (init->rx_filter) {
  case 0: 
  efx_ef10_ptp_set_ts_sync_events(efx, 0, 0);
  tmp = efx_ptp_change_mode(efx, init->tx_type != 0, 0U);
  return (tmp);
  case 1: ;
  case 3: ;
  case 4: ;
  case 5: ;
  case 6: ;
  case 7: ;
  case 8: ;
  case 9: ;
  case 10: ;
  case 11: ;
  case 12: ;
  case 13: ;
  case 14: 
  init->rx_filter = 1;
  rc = efx_ptp_change_mode(efx, 1, 0U);
  if (rc == 0) {
    rc = efx_ef10_ptp_set_ts_sync_events(efx, 1, 0);
  } else {

  }
  if (rc != 0) {
    efx_ptp_change_mode(efx, 0, 0U);
  } else {

  }
  return (rc);
  default: ;
  return (-34);
  }
}
}
struct efx_nic_type  const  efx_hunt_a0_vf_nic_type  = 
     {1, 0U, & efx_ef10_mem_map_size, & efx_ef10_probe_vf, & efx_ef10_remove, & efx_ef10_init_nic,
    & efx_ef10_dimension_resources, & efx_port_dummy_op_void, 0, & efx_ef10_map_reset_reason,
    & efx_ef10_map_reset_flags, & efx_ef10_reset, & efx_mcdi_port_probe, & efx_mcdi_port_remove,
    0, & efx_ef10_fini_dmaq, 0, 0, & efx_ef10_prepare_flr, & efx_port_dummy_op_void,
    & efx_ef10_describe_stats, & efx_ef10_update_stats_vf, & efx_port_dummy_op_void,
    & efx_port_dummy_op_void, & efx_port_dummy_op_void, & efx_mcdi_set_id_led, & efx_ef10_push_irq_moderation,
    & efx_mcdi_port_reconfigure, 0, & efx_ef10_mac_reconfigure_vf, & efx_mcdi_mac_check_fault,
    & efx_ef10_get_wol_vf, & efx_ef10_set_wol_vf, & efx_port_dummy_op_void, 0, 0,
    & efx_ef10_mcdi_request, & efx_ef10_mcdi_poll_response, & efx_ef10_mcdi_read_response,
    & efx_ef10_mcdi_poll_reboot, & efx_port_dummy_op_void, & efx_ef10_irq_test_generate,
    & efx_port_dummy_op_void, & efx_ef10_msi_interrupt, & efx_ef10_legacy_interrupt,
    & efx_ef10_tx_probe, & efx_ef10_tx_init, & efx_ef10_tx_remove, & efx_ef10_tx_write,
    & efx_ef10_vf_rx_push_rss_config, & efx_ef10_rx_probe, & efx_ef10_rx_init, & efx_ef10_rx_remove,
    & efx_ef10_rx_write, & efx_ef10_rx_defer_refill, & efx_ef10_ev_probe, & efx_ef10_ev_init,
    & efx_ef10_ev_fini, & efx_ef10_ev_remove, & efx_ef10_ev_process, & efx_ef10_ev_read_ack,
    & efx_ef10_ev_test_generate, & efx_ef10_filter_table_probe, & efx_ef10_filter_table_restore,
    & efx_ef10_filter_table_remove, & efx_ef10_filter_update_rx_scatter, & efx_ef10_filter_insert,
    & efx_ef10_filter_remove_safe, & efx_ef10_filter_get_safe, & efx_ef10_filter_clear_rx,
    & efx_ef10_filter_count_rx_used, & efx_ef10_filter_get_rx_id_limit, & efx_ef10_filter_get_rx_ids,
    & efx_ef10_filter_rfs_insert, & efx_ef10_filter_rfs_expire_one, & efx_port_dummy_op_int,
    0, 0, 0, 0, 0, & efx_ef10_ptp_write_host_time_vf, 0, & efx_ef10_ptp_set_ts_config_vf,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, & efx_ef10_sriov_get_phys_port_id, & efx_ef10_vswitching_probe_vf,
    & efx_ef10_vswitching_restore_vf, & efx_ef10_vswitching_remove_vf, & efx_ef10_get_mac_address_vf,
    & efx_ef10_set_mac_address, 4, 0U, 0U, 0U, 0U, 0U, 281474976710655ULL, 14U, 0U,
    10U, 0U, 1, 1, 0U, 256U, 12884901906ULL, 2, 8192U, 3U};
struct efx_nic_type  const  efx_hunt_a0_nic_type  = 
     {0, 2U, & efx_ef10_mem_map_size, & efx_ef10_probe_pf, & efx_ef10_remove, & efx_ef10_init_nic,
    & efx_ef10_dimension_resources, & efx_port_dummy_op_void, 0, & efx_ef10_map_reset_reason,
    & efx_ef10_map_reset_flags, & efx_ef10_reset, & efx_mcdi_port_probe, & efx_mcdi_port_remove,
    0, & efx_ef10_fini_dmaq, 0, 0, & efx_ef10_prepare_flr, & efx_port_dummy_op_void,
    & efx_ef10_describe_stats, & efx_ef10_update_stats_pf, & efx_mcdi_mac_start_stats,
    & efx_mcdi_mac_pull_stats, & efx_mcdi_mac_stop_stats, & efx_mcdi_set_id_led, & efx_ef10_push_irq_moderation,
    & efx_mcdi_port_reconfigure, 0, & efx_ef10_mac_reconfigure, & efx_mcdi_mac_check_fault,
    & efx_ef10_get_wol, & efx_ef10_set_wol, & efx_port_dummy_op_void, & efx_ef10_test_chip,
    & efx_mcdi_nvram_test_all, & efx_ef10_mcdi_request, & efx_ef10_mcdi_poll_response,
    & efx_ef10_mcdi_read_response, & efx_ef10_mcdi_poll_reboot, & efx_port_dummy_op_void,
    & efx_ef10_irq_test_generate, & efx_port_dummy_op_void, & efx_ef10_msi_interrupt,
    & efx_ef10_legacy_interrupt, & efx_ef10_tx_probe, & efx_ef10_tx_init, & efx_ef10_tx_remove,
    & efx_ef10_tx_write, & efx_ef10_pf_rx_push_rss_config, & efx_ef10_rx_probe, & efx_ef10_rx_init,
    & efx_ef10_rx_remove, & efx_ef10_rx_write, & efx_ef10_rx_defer_refill, & efx_ef10_ev_probe,
    & efx_ef10_ev_init, & efx_ef10_ev_fini, & efx_ef10_ev_remove, & efx_ef10_ev_process,
    & efx_ef10_ev_read_ack, & efx_ef10_ev_test_generate, & efx_ef10_filter_table_probe,
    & efx_ef10_filter_table_restore, & efx_ef10_filter_table_remove, & efx_ef10_filter_update_rx_scatter,
    & efx_ef10_filter_insert, & efx_ef10_filter_remove_safe, & efx_ef10_filter_get_safe,
    & efx_ef10_filter_clear_rx, & efx_ef10_filter_count_rx_used, & efx_ef10_filter_get_rx_id_limit,
    & efx_ef10_filter_get_rx_ids, & efx_ef10_filter_rfs_insert, & efx_ef10_filter_rfs_expire_one,
    & efx_ef10_mtd_probe, & efx_mcdi_mtd_rename, & efx_mcdi_mtd_read, & efx_mcdi_mtd_erase,
    & efx_mcdi_mtd_write, & efx_mcdi_mtd_sync, & efx_ef10_ptp_write_host_time, & efx_ef10_ptp_set_ts_sync_events,
    & efx_ef10_ptp_set_ts_config, & efx_ef10_sriov_configure, & efx_ef10_sriov_init,
    & efx_ef10_sriov_fini, & efx_ef10_sriov_wanted, & efx_ef10_sriov_reset, & efx_ef10_sriov_flr,
    & efx_ef10_sriov_set_vf_mac, & efx_ef10_sriov_set_vf_vlan, & efx_ef10_sriov_set_vf_spoofchk,
    & efx_ef10_sriov_get_vf_config, & efx_ef10_sriov_set_vf_link_state, 0, & efx_ef10_vswitching_probe_pf,
    & efx_ef10_vswitching_restore_pf, & efx_ef10_vswitching_remove_pf, & efx_ef10_get_mac_address_pf,
    & efx_ef10_set_mac_address, 4, 0U, 0U, 0U, 0U, 0U, 281474976710655ULL, 14U, 0U,
    10U, 0U, 1, 1, 0U, 256U, 12884901906ULL, 2, 8192U, 3U};
void ldv_initialize_efx_nic_type_24(void) 
{ 
  void *tmp ;
  void *tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;

  {
  tmp = ldv_init_zalloc(288UL);
  efx_hunt_a0_vf_nic_type_group0 = (struct efx_rx_queue *)tmp;
  tmp___0 = ldv_init_zalloc(2176UL);
  efx_hunt_a0_vf_nic_type_group2 = (struct efx_channel *)tmp___0;
  tmp___1 = ldv_init_zalloc(320UL);
  efx_hunt_a0_vf_nic_type_group3 = (struct efx_tx_queue *)tmp___1;
  tmp___2 = ldv_init_zalloc(4032UL);
  efx_hunt_a0_vf_nic_type_group1 = (struct efx_nic *)tmp___2;
  tmp___3 = ldv_init_zalloc(64UL);
  efx_hunt_a0_vf_nic_type_group4 = (struct efx_filter_spec *)tmp___3;
  return;
}
}
void ldv_initialize_efx_nic_type_23(void) 
{ 
  void *tmp ;
  void *tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  void *tmp___4 ;

  {
  tmp = ldv_init_zalloc(288UL);
  efx_hunt_a0_nic_type_group0 = (struct efx_rx_queue *)tmp;
  tmp___0 = ldv_init_zalloc(2176UL);
  efx_hunt_a0_nic_type_group2 = (struct efx_channel *)tmp___0;
  tmp___1 = ldv_init_zalloc(1824UL);
  efx_hunt_a0_nic_type_group3 = (struct mtd_info *)tmp___1;
  tmp___2 = ldv_init_zalloc(320UL);
  efx_hunt_a0_nic_type_group4 = (struct efx_tx_queue *)tmp___2;
  tmp___3 = ldv_init_zalloc(4032UL);
  efx_hunt_a0_nic_type_group1 = (struct efx_nic *)tmp___3;
  tmp___4 = ldv_init_zalloc(64UL);
  efx_hunt_a0_nic_type_group5 = (struct efx_filter_spec *)tmp___4;
  return;
}
}
void ldv_main_exported_25(void) 
{ 
  struct device_attribute *ldvarg90 ;
  void *tmp ;
  char *ldvarg89 ;
  void *tmp___0 ;
  struct device *ldvarg88 ;
  void *tmp___1 ;
  int tmp___2 ;

  {
  tmp = ldv_init_zalloc(48UL);
  ldvarg90 = (struct device_attribute *)tmp;
  tmp___0 = ldv_init_zalloc(1UL);
  ldvarg89 = (char *)tmp___0;
  tmp___1 = ldv_init_zalloc(1416UL);
  ldvarg88 = (struct device *)tmp___1;
  tmp___2 = __VERIFIER_nondet_int();
  switch (tmp___2) {
  case 0: ;
  if (ldv_state_variable_25 == 1) {
    efx_ef10_show_primary_flag(ldvarg88, ldvarg90, ldvarg89);
    ldv_state_variable_25 = 1;
  } else {

  }
  goto ldv_57399;
  default: 
  ldv_stop();
  }
  ldv_57399: ;
  return;
}
}
void ldv_main_exported_24(void) 
{ 
  size_t ldvarg148 ;
  int ldvarg162 ;
    klee_make_symbolic(&ldvarg162, sizeof(int), "ldvarg162");
  u32 ldvarg139 ;
  enum efx_filter_priority ldvarg159 ;
  unsigned int ldvarg143 ;
    klee_make_symbolic(&ldvarg143, sizeof(int), "ldvarg143");
  efx_dword_t *ldvarg171 ;
  void *tmp ;
  efx_dword_t *ldvarg150 ;
  void *tmp___0 ;
  enum reset_type ldvarg173 ;
  enum reset_type ldvarg176 ;
  u32 ldvarg164 ;
  bool ldvarg147 ;
  u8 *ldvarg166 ;
  void *tmp___1 ;
  struct hwtstamp_config *ldvarg156 ;
  void *tmp___2 ;
  u32 ldvarg153 ;
  struct netdev_phys_item_id *ldvarg177 ;
  void *tmp___3 ;
  size_t ldvarg172 ;
  u32 ldvarg144 ;
  u32 *ldvarg154 ;
  void *tmp___4 ;
  int ldvarg151 ;
    klee_make_symbolic(&ldvarg151, sizeof(int), "ldvarg151");
  u32 *ldvarg175 ;
  void *tmp___5 ;
  enum efx_led_mode ldvarg158 ;
  u32 ldvarg160 ;
  bool ldvarg142 ;
  enum efx_filter_priority ldvarg161 ;
  size_t ldvarg149 ;
  efx_dword_t *ldvarg169 ;
  void *tmp___6 ;
  void *ldvarg163 ;
  void *tmp___7 ;
  size_t ldvarg170 ;
  void *ldvarg152 ;
  void *tmp___8 ;
  struct rtnl_link_stats64 *ldvarg145 ;
  void *tmp___9 ;
  enum efx_filter_priority ldvarg140 ;
  u32 ldvarg167 ;
  enum efx_filter_priority ldvarg155 ;
  int ldvarg165 ;
    klee_make_symbolic(&ldvarg165, sizeof(int), "ldvarg165");
  enum efx_filter_priority ldvarg168 ;
  unsigned char *ldvarg174 ;
  void *tmp___10 ;
  u32 *ldvarg141 ;
  void *tmp___11 ;
  struct ethtool_wolinfo *ldvarg157 ;
  void *tmp___12 ;
  u64 *ldvarg146 ;
  void *tmp___13 ;
  int tmp___14 ;

  {
  tmp = ldv_init_zalloc(4UL);
  ldvarg171 = (efx_dword_t *)tmp;
  tmp___0 = ldv_init_zalloc(4UL);
  ldvarg150 = (efx_dword_t *)tmp___0;
  tmp___1 = ldv_init_zalloc(1UL);
  ldvarg166 = (u8 *)tmp___1;
  tmp___2 = ldv_init_zalloc(12UL);
  ldvarg156 = (struct hwtstamp_config *)tmp___2;
  tmp___3 = ldv_init_zalloc(33UL);
  ldvarg177 = (struct netdev_phys_item_id *)tmp___3;
  tmp___4 = ldv_init_zalloc(4UL);
  ldvarg154 = (u32 *)tmp___4;
  tmp___5 = ldv_init_zalloc(4UL);
  ldvarg175 = (u32 *)tmp___5;
  tmp___6 = ldv_init_zalloc(4UL);
  ldvarg169 = (efx_dword_t *)tmp___6;
  tmp___7 = ldv_init_zalloc(1UL);
  ldvarg163 = tmp___7;
  tmp___8 = ldv_init_zalloc(1UL);
  ldvarg152 = tmp___8;
  tmp___9 = ldv_init_zalloc(184UL);
  ldvarg145 = (struct rtnl_link_stats64 *)tmp___9;
  tmp___10 = ldv_init_zalloc(1UL);
  ldvarg174 = (unsigned char *)tmp___10;
  tmp___11 = ldv_init_zalloc(4UL);
  ldvarg141 = (u32 *)tmp___11;
  tmp___12 = ldv_init_zalloc(20UL);
  ldvarg157 = (struct ethtool_wolinfo *)tmp___12;
  tmp___13 = ldv_init_zalloc(8UL);
  ldvarg146 = (u64 *)tmp___13;
  ldv_memset((void *)(& ldvarg148), 0, 8UL);
  ldv_memset((void *)(& ldvarg162), 0, 4UL);
  ldv_memset((void *)(& ldvarg139), 0, 4UL);
  ldv_memset((void *)(& ldvarg159), 0, 4UL);
  ldv_memset((void *)(& ldvarg143), 0, 4UL);
  ldv_memset((void *)(& ldvarg173), 0, 4UL);
  ldv_memset((void *)(& ldvarg176), 0, 4UL);
  ldv_memset((void *)(& ldvarg164), 0, 4UL);
  ldv_memset((void *)(& ldvarg147), 0, 1UL);
  ldv_memset((void *)(& ldvarg153), 0, 4UL);
  ldv_memset((void *)(& ldvarg172), 0, 8UL);
  ldv_memset((void *)(& ldvarg144), 0, 4UL);
  ldv_memset((void *)(& ldvarg151), 0, 4UL);
  ldv_memset((void *)(& ldvarg158), 0, 4UL);
  ldv_memset((void *)(& ldvarg160), 0, 4UL);
  ldv_memset((void *)(& ldvarg142), 0, 1UL);
  ldv_memset((void *)(& ldvarg161), 0, 4UL);
  ldv_memset((void *)(& ldvarg149), 0, 8UL);
  ldv_memset((void *)(& ldvarg170), 0, 8UL);
  ldv_memset((void *)(& ldvarg140), 0, 4UL);
  ldv_memset((void *)(& ldvarg167), 0, 4UL);
  ldv_memset((void *)(& ldvarg155), 0, 4UL);
  ldv_memset((void *)(& ldvarg165), 0, 4UL);
  ldv_memset((void *)(& ldvarg168), 0, 4UL);
  tmp___14 = __VERIFIER_nondet_int();
  switch (tmp___14) {
  case 0: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_sriov_get_phys_port_id(efx_hunt_a0_vf_nic_type_group1, ldvarg177);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 1: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_prepare_flr(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 2: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_mcdi_poll_reboot(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 3: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_mac_reconfigure_vf(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 4: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_fini_dmaq(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 5: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_rx_init(efx_hunt_a0_vf_nic_type_group0);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 6: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_map_reset_reason(ldvarg176);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 7: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_ev_read_ack(efx_hunt_a0_vf_nic_type_group2);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 8: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_map_reset_flags(ldvarg175);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 9: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_vswitching_restore_vf(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 10: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_get_mac_address_vf(efx_hunt_a0_vf_nic_type_group1, ldvarg174);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 11: ;
  if (ldv_state_variable_24 == 1) {
    efx_port_dummy_op_void(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 12: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_rx_write(efx_hunt_a0_vf_nic_type_group0);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 13: ;
  if (ldv_state_variable_24 == 1) {
    efx_mcdi_port_probe(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 14: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_filter_table_remove(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 15: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_mem_map_size(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 16: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_reset(efx_hunt_a0_vf_nic_type_group1, ldvarg173);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 17: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_mcdi_request(efx_hunt_a0_vf_nic_type_group1, (efx_dword_t const   *)ldvarg171,
                          ldvarg170, (efx_dword_t const   *)ldvarg169, ldvarg172);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 18: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_filter_rfs_insert(efx_hunt_a0_vf_nic_type_group1, efx_hunt_a0_vf_nic_type_group4);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 19: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_ev_probe(efx_hunt_a0_vf_nic_type_group2);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 20: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_tx_probe(efx_hunt_a0_vf_nic_type_group3);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 21: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_filter_count_rx_used(efx_hunt_a0_vf_nic_type_group1, ldvarg168);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 22: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_ptp_write_host_time_vf(efx_hunt_a0_vf_nic_type_group1, ldvarg167);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 23: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_describe_stats(efx_hunt_a0_vf_nic_type_group1, ldvarg166);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 24: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_filter_table_probe(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 25: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_vswitching_remove_vf(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 26: ;
  if (ldv_state_variable_24 == 1) {
    efx_port_dummy_op_void(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 27: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_ev_process(efx_hunt_a0_vf_nic_type_group2, ldvarg165);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 28: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_set_mac_address(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 29: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_rx_probe(efx_hunt_a0_vf_nic_type_group0);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 30: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_filter_table_restore(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 31: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_ev_remove(efx_hunt_a0_vf_nic_type_group2);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 32: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_set_wol_vf(efx_hunt_a0_vf_nic_type_group1, ldvarg164);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 33: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_legacy_interrupt(ldvarg162, ldvarg163);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 34: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_mcdi_poll_response(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 35: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_filter_remove_safe(efx_hunt_a0_vf_nic_type_group1, ldvarg161, ldvarg160);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 36: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_filter_clear_rx(efx_hunt_a0_vf_nic_type_group1, ldvarg159);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 37: ;
  if (ldv_state_variable_24 == 1) {
    efx_mcdi_set_id_led(efx_hunt_a0_vf_nic_type_group1, ldvarg158);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 38: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_filter_get_rx_id_limit(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 39: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_get_wol_vf(efx_hunt_a0_vf_nic_type_group1, ldvarg157);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 40: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_tx_remove(efx_hunt_a0_vf_nic_type_group3);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 41: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_vswitching_probe_vf(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 42: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_ptp_set_ts_config_vf(efx_hunt_a0_vf_nic_type_group1, ldvarg156);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 43: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_rx_defer_refill(efx_hunt_a0_vf_nic_type_group0);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 44: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_remove(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 45: ;
  if (ldv_state_variable_24 == 1) {
    efx_port_dummy_op_void(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 46: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_filter_get_rx_ids(efx_hunt_a0_vf_nic_type_group1, ldvarg155, ldvarg154,
                               ldvarg153);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 47: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_msi_interrupt(ldvarg151, ldvarg152);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 48: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_ev_fini(efx_hunt_a0_vf_nic_type_group2);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 49: ;
  if (ldv_state_variable_24 == 1) {
    efx_port_dummy_op_int(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 50: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_irq_test_generate(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 51: ;
  if (ldv_state_variable_24 == 1) {
    efx_port_dummy_op_void(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 52: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_mcdi_read_response(efx_hunt_a0_vf_nic_type_group1, ldvarg150, ldvarg149,
                                ldvarg148);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 53: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_ev_init(efx_hunt_a0_vf_nic_type_group2);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 54: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_filter_insert(efx_hunt_a0_vf_nic_type_group1, efx_hunt_a0_vf_nic_type_group4,
                           (int )ldvarg147);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 55: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_update_stats_vf(efx_hunt_a0_vf_nic_type_group1, ldvarg146, ldvarg145);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 56: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_push_irq_moderation(efx_hunt_a0_vf_nic_type_group2);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 57: ;
  if (ldv_state_variable_24 == 1) {
    efx_mcdi_port_remove(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 58: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_rx_remove(efx_hunt_a0_vf_nic_type_group0);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 59: ;
  if (ldv_state_variable_24 == 1) {
    efx_port_dummy_op_void(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 60: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_probe_vf(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 61: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_filter_update_rx_scatter(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 62: ;
  if (ldv_state_variable_24 == 1) {
    efx_mcdi_mac_check_fault(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 63: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_dimension_resources(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 64: ;
  if (ldv_state_variable_24 == 1) {
    efx_port_dummy_op_void(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 65: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_tx_write(efx_hunt_a0_vf_nic_type_group3);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 66: ;
  if (ldv_state_variable_24 == 1) {
    efx_port_dummy_op_void(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 67: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_filter_rfs_expire_one(efx_hunt_a0_vf_nic_type_group1, ldvarg144, ldvarg143);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 68: ;
  if (ldv_state_variable_24 == 1) {
    efx_port_dummy_op_void(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 69: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_vf_rx_push_rss_config(efx_hunt_a0_vf_nic_type_group1, (int )ldvarg142,
                                   (u32 const   *)ldvarg141);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 70: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_filter_get_safe(efx_hunt_a0_vf_nic_type_group1, ldvarg140, ldvarg139,
                             efx_hunt_a0_vf_nic_type_group4);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 71: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_tx_init(efx_hunt_a0_vf_nic_type_group3);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 72: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_ev_test_generate(efx_hunt_a0_vf_nic_type_group2);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 73: ;
  if (ldv_state_variable_24 == 1) {
    efx_ef10_init_nic(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  case 74: ;
  if (ldv_state_variable_24 == 1) {
    efx_mcdi_port_reconfigure(efx_hunt_a0_vf_nic_type_group1);
    ldv_state_variable_24 = 1;
  } else {

  }
  goto ldv_57444;
  default: 
  ldv_stop();
  }
  ldv_57444: ;
  return;
}
}
void ldv_main_exported_26(void) 
{ 
  struct device_attribute *ldvarg6 ;
  void *tmp ;
  char *ldvarg5 ;
  void *tmp___0 ;
  struct device *ldvarg4 ;
  void *tmp___1 ;
  int tmp___2 ;

  {
  tmp = ldv_init_zalloc(48UL);
  ldvarg6 = (struct device_attribute *)tmp;
  tmp___0 = ldv_init_zalloc(1UL);
  ldvarg5 = (char *)tmp___0;
  tmp___1 = ldv_init_zalloc(1416UL);
  ldvarg4 = (struct device *)tmp___1;
  tmp___2 = __VERIFIER_nondet_int();
  switch (tmp___2) {
  case 0: ;
  if (ldv_state_variable_26 == 1) {
    efx_ef10_show_link_control_flag(ldvarg4, ldvarg6, ldvarg5);
    ldv_state_variable_26 = 1;
  } else {

  }
  goto ldv_57527;
  default: 
  ldv_stop();
  }
  ldv_57527: ;
  return;
}
}
void ldv_main_exported_23(void) 
{ 
  u8 *ldvarg253 ;
  void *tmp ;
  size_t *ldvarg250 ;
  void *tmp___0 ;
  bool ldvarg265 ;
  size_t ldvarg251 ;
  u64 *ldvarg227 ;
  void *tmp___1 ;
  u32 ldvarg217 ;
  u32 *ldvarg264 ;
  void *tmp___2 ;
  loff_t ldvarg252 ;
  u32 ldvarg256 ;
  size_t ldvarg261 ;
  u32 ldvarg235 ;
  int ldvarg223 ;
    klee_make_symbolic(&ldvarg223, sizeof(int), "ldvarg223");
  int ldvarg254 ;
    klee_make_symbolic(&ldvarg254, sizeof(int), "ldvarg254");
  efx_dword_t *ldvarg231 ;
  void *tmp___3 ;
  int ldvarg241 ;
    klee_make_symbolic(&ldvarg241, sizeof(int), "ldvarg241");
  enum efx_filter_priority ldvarg213 ;
  u8 *ldvarg255 ;
  void *tmp___4 ;
  struct efx_self_tests *ldvarg232 ;
  void *tmp___5 ;
  efx_dword_t *ldvarg258 ;
  void *tmp___6 ;
  u8 *ldvarg211 ;
  void *tmp___7 ;
  struct rtnl_link_stats64 *ldvarg226 ;
  void *tmp___8 ;
  void *ldvarg234 ;
  void *tmp___9 ;
  size_t *ldvarg208 ;
  void *tmp___10 ;
  unsigned int ldvarg216 ;
    klee_make_symbolic(&ldvarg216, sizeof(int), "ldvarg216");
  loff_t ldvarg210 ;
  enum efx_led_mode ldvarg243 ;
  int ldvarg233 ;
    klee_make_symbolic(&ldvarg233, sizeof(int), "ldvarg233");
  unsigned char *ldvarg263 ;
  void *tmp___11 ;
  bool ldvarg266 ;
  int ldvarg225 ;
    klee_make_symbolic(&ldvarg225, sizeof(int), "ldvarg225");
  struct ethtool_wolinfo *ldvarg242 ;
  void *tmp___12 ;
  enum reset_type ldvarg267 ;
  int ldvarg239 ;
    klee_make_symbolic(&ldvarg239, sizeof(int), "ldvarg239");
  u32 ldvarg249 ;
  unsigned int ldvarg220 ;
    klee_make_symbolic(&ldvarg220, sizeof(int), "ldvarg220");
  int ldvarg270 ;
    klee_make_symbolic(&ldvarg270, sizeof(int), "ldvarg270");
  size_t ldvarg229 ;
  u32 ldvarg245 ;
  struct ifla_vf_info *ldvarg224 ;
  void *tmp___13 ;
  void *ldvarg248 ;
  void *tmp___14 ;
  size_t ldvarg209 ;
  struct hwtstamp_config *ldvarg238 ;
  void *tmp___15 ;
  size_t ldvarg259 ;
  enum efx_filter_priority ldvarg246 ;
  struct efx_mtd_partition *ldvarg207 ;
  void *tmp___16 ;
  bool ldvarg240 ;
  size_t ldvarg230 ;
  efx_dword_t *ldvarg260 ;
  void *tmp___17 ;
  u16 ldvarg222 ;
  enum reset_type ldvarg262 ;
  int ldvarg271 ;
    klee_make_symbolic(&ldvarg271, sizeof(int), "ldvarg271");
  u8 ldvarg221 ;
  enum efx_filter_priority ldvarg257 ;
  u32 *ldvarg214 ;
  void *tmp___18 ;
  bool ldvarg228 ;
  enum efx_filter_priority ldvarg244 ;
  u32 *ldvarg236 ;
  void *tmp___19 ;
  u8 *ldvarg218 ;
  void *tmp___20 ;
  bool ldvarg215 ;
  int ldvarg219 ;
    klee_make_symbolic(&ldvarg219, sizeof(int), "ldvarg219");
  u32 ldvarg212 ;
  int ldvarg247 ;
    klee_make_symbolic(&ldvarg247, sizeof(int), "ldvarg247");
  size_t ldvarg268 ;
  loff_t ldvarg269 ;
  enum efx_filter_priority ldvarg237 ;
  int tmp___21 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg253 = (u8 *)tmp;
  tmp___0 = ldv_init_zalloc(8UL);
  ldvarg250 = (size_t *)tmp___0;
  tmp___1 = ldv_init_zalloc(8UL);
  ldvarg227 = (u64 *)tmp___1;
  tmp___2 = ldv_init_zalloc(4UL);
  ldvarg264 = (u32 *)tmp___2;
  tmp___3 = ldv_init_zalloc(4UL);
  ldvarg231 = (efx_dword_t *)tmp___3;
  tmp___4 = ldv_init_zalloc(1UL);
  ldvarg255 = (u8 *)tmp___4;
  tmp___5 = ldv_init_zalloc(1076UL);
  ldvarg232 = (struct efx_self_tests *)tmp___5;
  tmp___6 = ldv_init_zalloc(4UL);
  ldvarg258 = (efx_dword_t *)tmp___6;
  tmp___7 = ldv_init_zalloc(1UL);
  ldvarg211 = (u8 *)tmp___7;
  tmp___8 = ldv_init_zalloc(184UL);
  ldvarg226 = (struct rtnl_link_stats64 *)tmp___8;
  tmp___9 = ldv_init_zalloc(1UL);
  ldvarg234 = tmp___9;
  tmp___10 = ldv_init_zalloc(8UL);
  ldvarg208 = (size_t *)tmp___10;
  tmp___11 = ldv_init_zalloc(1UL);
  ldvarg263 = (unsigned char *)tmp___11;
  tmp___12 = ldv_init_zalloc(20UL);
  ldvarg242 = (struct ethtool_wolinfo *)tmp___12;
  tmp___13 = ldv_init_zalloc(64UL);
  ldvarg224 = (struct ifla_vf_info *)tmp___13;
  tmp___14 = ldv_init_zalloc(1UL);
  ldvarg248 = tmp___14;
  tmp___15 = ldv_init_zalloc(12UL);
  ldvarg238 = (struct hwtstamp_config *)tmp___15;
  tmp___16 = ldv_init_zalloc(1896UL);
  ldvarg207 = (struct efx_mtd_partition *)tmp___16;
  tmp___17 = ldv_init_zalloc(4UL);
  ldvarg260 = (efx_dword_t *)tmp___17;
  tmp___18 = ldv_init_zalloc(4UL);
  ldvarg214 = (u32 *)tmp___18;
  tmp___19 = ldv_init_zalloc(4UL);
  ldvarg236 = (u32 *)tmp___19;
  tmp___20 = ldv_init_zalloc(1UL);
  ldvarg218 = (u8 *)tmp___20;
  ldv_memset((void *)(& ldvarg265), 0, 1UL);
  ldv_memset((void *)(& ldvarg251), 0, 8UL);
  ldv_memset((void *)(& ldvarg217), 0, 4UL);
  ldv_memset((void *)(& ldvarg252), 0, 8UL);
  ldv_memset((void *)(& ldvarg256), 0, 4UL);
  ldv_memset((void *)(& ldvarg261), 0, 8UL);
  ldv_memset((void *)(& ldvarg235), 0, 4UL);
  ldv_memset((void *)(& ldvarg223), 0, 4UL);
  ldv_memset((void *)(& ldvarg254), 0, 4UL);
  ldv_memset((void *)(& ldvarg241), 0, 4UL);
  ldv_memset((void *)(& ldvarg213), 0, 4UL);
  ldv_memset((void *)(& ldvarg216), 0, 4UL);
  ldv_memset((void *)(& ldvarg210), 0, 8UL);
  ldv_memset((void *)(& ldvarg243), 0, 4UL);
  ldv_memset((void *)(& ldvarg233), 0, 4UL);
  ldv_memset((void *)(& ldvarg266), 0, 1UL);
  ldv_memset((void *)(& ldvarg225), 0, 4UL);
  ldv_memset((void *)(& ldvarg267), 0, 4UL);
  ldv_memset((void *)(& ldvarg239), 0, 4UL);
  ldv_memset((void *)(& ldvarg249), 0, 4UL);
  ldv_memset((void *)(& ldvarg220), 0, 4UL);
  ldv_memset((void *)(& ldvarg270), 0, 4UL);
  ldv_memset((void *)(& ldvarg229), 0, 8UL);
  ldv_memset((void *)(& ldvarg245), 0, 4UL);
  ldv_memset((void *)(& ldvarg209), 0, 8UL);
  ldv_memset((void *)(& ldvarg259), 0, 8UL);
  ldv_memset((void *)(& ldvarg246), 0, 4UL);
  ldv_memset((void *)(& ldvarg240), 0, 1UL);
  ldv_memset((void *)(& ldvarg230), 0, 8UL);
  ldv_memset((void *)(& ldvarg222), 0, 2UL);
  ldv_memset((void *)(& ldvarg262), 0, 4UL);
  ldv_memset((void *)(& ldvarg271), 0, 4UL);
  ldv_memset((void *)(& ldvarg221), 0, 1UL);
  ldv_memset((void *)(& ldvarg257), 0, 4UL);
  ldv_memset((void *)(& ldvarg228), 0, 1UL);
  ldv_memset((void *)(& ldvarg244), 0, 4UL);
  ldv_memset((void *)(& ldvarg215), 0, 1UL);
  ldv_memset((void *)(& ldvarg219), 0, 4UL);
  ldv_memset((void *)(& ldvarg212), 0, 4UL);
  ldv_memset((void *)(& ldvarg247), 0, 4UL);
  ldv_memset((void *)(& ldvarg268), 0, 8UL);
  ldv_memset((void *)(& ldvarg269), 0, 8UL);
  ldv_memset((void *)(& ldvarg237), 0, 4UL);
  tmp___21 = __VERIFIER_nondet_int();
  switch (tmp___21) {
  case 0: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_sriov_set_vf_link_state(efx_hunt_a0_nic_type_group1, ldvarg271, ldvarg270);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 1: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_prepare_flr(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 2: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_mcdi_poll_reboot(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 3: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_mac_reconfigure(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 4: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_fini_dmaq(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 5: ;
  if (ldv_state_variable_23 == 1) {
    efx_mcdi_mtd_erase(efx_hunt_a0_nic_type_group3, ldvarg269, ldvarg268);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 6: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_rx_init(efx_hunt_a0_nic_type_group0);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 7: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_map_reset_reason(ldvarg267);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 8: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_ev_read_ack(efx_hunt_a0_nic_type_group2);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 9: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_ptp_set_ts_sync_events(efx_hunt_a0_nic_type_group1, (int )ldvarg266,
                                    (int )ldvarg265);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 10: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_map_reset_flags(ldvarg264);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 11: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_vswitching_restore_pf(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 12: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_get_mac_address_pf(efx_hunt_a0_nic_type_group1, ldvarg263);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 13: ;
  if (ldv_state_variable_23 == 1) {
    efx_mcdi_mtd_sync(efx_hunt_a0_nic_type_group3);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 14: ;
  if (ldv_state_variable_23 == 1) {
    efx_mcdi_mac_pull_stats(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 15: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_rx_write(efx_hunt_a0_nic_type_group0);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 16: ;
  if (ldv_state_variable_23 == 1) {
    efx_mcdi_port_probe(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 17: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_filter_table_remove(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 18: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_mem_map_size(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 19: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_reset(efx_hunt_a0_nic_type_group1, ldvarg262);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 20: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_mcdi_request(efx_hunt_a0_nic_type_group1, (efx_dword_t const   *)ldvarg260,
                          ldvarg259, (efx_dword_t const   *)ldvarg258, ldvarg261);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 21: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_filter_rfs_insert(efx_hunt_a0_nic_type_group1, efx_hunt_a0_nic_type_group5);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 22: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_ev_probe(efx_hunt_a0_nic_type_group2);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 23: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_tx_probe(efx_hunt_a0_nic_type_group4);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 24: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_filter_count_rx_used(efx_hunt_a0_nic_type_group1, ldvarg257);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 25: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_ptp_write_host_time(efx_hunt_a0_nic_type_group1, ldvarg256);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 26: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_describe_stats(efx_hunt_a0_nic_type_group1, ldvarg255);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 27: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_filter_table_probe(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 28: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_vswitching_remove_pf(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 29: ;
  if (ldv_state_variable_23 == 1) {
    efx_port_dummy_op_void(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 30: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_sriov_reset(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 31: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_ev_process(efx_hunt_a0_nic_type_group2, ldvarg254);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 32: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_set_mac_address(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 33: ;
  if (ldv_state_variable_23 == 1) {
    efx_mcdi_mtd_read(efx_hunt_a0_nic_type_group3, ldvarg252, ldvarg251, ldvarg250,
                      ldvarg253);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 34: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_sriov_wanted(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 35: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_rx_probe(efx_hunt_a0_nic_type_group0);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 36: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_filter_table_restore(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 37: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_ev_remove(efx_hunt_a0_nic_type_group2);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 38: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_set_wol(efx_hunt_a0_nic_type_group1, ldvarg249);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 39: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_legacy_interrupt(ldvarg247, ldvarg248);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 40: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_mcdi_poll_response(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 41: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_filter_remove_safe(efx_hunt_a0_nic_type_group1, ldvarg246, ldvarg245);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 42: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_filter_clear_rx(efx_hunt_a0_nic_type_group1, ldvarg244);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 43: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_filter_get_rx_id_limit(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 44: ;
  if (ldv_state_variable_23 == 1) {
    efx_mcdi_set_id_led(efx_hunt_a0_nic_type_group1, ldvarg243);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 45: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_get_wol(efx_hunt_a0_nic_type_group1, ldvarg242);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 46: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_tx_remove(efx_hunt_a0_nic_type_group4);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 47: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_sriov_set_vf_spoofchk(efx_hunt_a0_nic_type_group1, ldvarg241, (int )ldvarg240);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 48: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_vswitching_probe_pf(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 49: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_sriov_configure(efx_hunt_a0_nic_type_group1, ldvarg239);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 50: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_ptp_set_ts_config(efx_hunt_a0_nic_type_group1, ldvarg238);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 51: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_rx_defer_refill(efx_hunt_a0_nic_type_group0);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 52: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_remove(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 53: ;
  if (ldv_state_variable_23 == 1) {
    efx_port_dummy_op_void(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 54: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_sriov_fini(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 55: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_filter_get_rx_ids(efx_hunt_a0_nic_type_group1, ldvarg237, ldvarg236,
                               ldvarg235);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 56: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_msi_interrupt(ldvarg233, ldvarg234);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 57: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_ev_fini(efx_hunt_a0_nic_type_group2);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 58: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_mtd_probe(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 59: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_irq_test_generate(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 60: ;
  if (ldv_state_variable_23 == 1) {
    efx_port_dummy_op_void(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 61: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_test_chip(efx_hunt_a0_nic_type_group1, ldvarg232);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 62: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_mcdi_read_response(efx_hunt_a0_nic_type_group1, ldvarg231, ldvarg230,
                                ldvarg229);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 63: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_ev_init(efx_hunt_a0_nic_type_group2);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 64: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_filter_insert(efx_hunt_a0_nic_type_group1, efx_hunt_a0_nic_type_group5,
                           (int )ldvarg228);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 65: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_update_stats_pf(efx_hunt_a0_nic_type_group1, ldvarg227, ldvarg226);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 66: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_push_irq_moderation(efx_hunt_a0_nic_type_group2);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 67: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_sriov_get_vf_config(efx_hunt_a0_nic_type_group1, ldvarg225, ldvarg224);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 68: ;
  if (ldv_state_variable_23 == 1) {
    efx_mcdi_port_remove(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 69: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_rx_remove(efx_hunt_a0_nic_type_group0);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 70: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_sriov_set_vf_vlan(efx_hunt_a0_nic_type_group1, ldvarg223, (int )ldvarg222,
                               (int )ldvarg221);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 71: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_sriov_flr(efx_hunt_a0_nic_type_group1, ldvarg220);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 72: ;
  if (ldv_state_variable_23 == 1) {
    efx_mcdi_mac_stop_stats(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 73: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_probe_pf(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 74: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_filter_update_rx_scatter(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 75: ;
  if (ldv_state_variable_23 == 1) {
    efx_mcdi_mac_check_fault(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 76: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_dimension_resources(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 77: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_sriov_set_vf_mac(efx_hunt_a0_nic_type_group1, ldvarg219, ldvarg218);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 78: ;
  if (ldv_state_variable_23 == 1) {
    efx_mcdi_mac_start_stats(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 79: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_tx_write(efx_hunt_a0_nic_type_group4);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 80: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_sriov_init(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 81: ;
  if (ldv_state_variable_23 == 1) {
    efx_port_dummy_op_void(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 82: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_filter_rfs_expire_one(efx_hunt_a0_nic_type_group1, ldvarg217, ldvarg216);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 83: ;
  if (ldv_state_variable_23 == 1) {
    efx_port_dummy_op_void(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 84: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_pf_rx_push_rss_config(efx_hunt_a0_nic_type_group1, (int )ldvarg215, (u32 const   *)ldvarg214);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 85: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_filter_get_safe(efx_hunt_a0_nic_type_group1, ldvarg213, ldvarg212, efx_hunt_a0_nic_type_group5);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 86: ;
  if (ldv_state_variable_23 == 1) {
    efx_mcdi_mtd_write(efx_hunt_a0_nic_type_group3, ldvarg210, ldvarg209, ldvarg208,
                       (u8 const   *)ldvarg211);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 87: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_tx_init(efx_hunt_a0_nic_type_group4);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 88: ;
  if (ldv_state_variable_23 == 1) {
    efx_mcdi_nvram_test_all(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 89: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_ev_test_generate(efx_hunt_a0_nic_type_group2);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 90: ;
  if (ldv_state_variable_23 == 1) {
    efx_ef10_init_nic(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 91: ;
  if (ldv_state_variable_23 == 1) {
    efx_mcdi_mtd_rename(ldvarg207);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  case 92: ;
  if (ldv_state_variable_23 == 1) {
    efx_mcdi_port_reconfigure(efx_hunt_a0_nic_type_group1);
    ldv_state_variable_23 = 1;
  } else {

  }
  goto ldv_57598;
  default: 
  ldv_stop();
  }
  ldv_57598: ;
  return;
}
}
bool ldv_queue_work_on_259(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_260(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_261(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_262(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_263(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_264(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_265(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_266(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_267(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_268(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_269(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_270(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
__inline static int test_and_clear_bit(long nr , unsigned long volatile   *addr ) 
{ 
  char c ;

  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; btr %2, %0; setc %1": "+m" (*addr),
                       "=qm" (c): "Ir" (nr): "memory");
  return ((int )((signed char )c) != 0);
}
}
int ldv_mutex_trylock_295(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_293(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_296(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_297(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_292(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_294(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_298(struct mutex *ldv_func_arg1 ) ;
__inline static void __preempt_count_add(int val ) 
{ 
  int pao_ID__ ;
    klee_make_symbolic(&pao_ID__, sizeof(int), "pao_ID__");

  {
  pao_ID__ = 0;
  switch (4UL) {
  case 1UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incb %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decb %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addb %1, %%gs:%0": "+m" (__preempt_count): "qi" (val));
  }
  goto ldv_6713;
  case 2UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incw %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decw %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addw %1, %%gs:%0": "+m" (__preempt_count): "ri" (val));
  }
  goto ldv_6713;
  case 4UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incl %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decl %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addl %1, %%gs:%0": "+m" (__preempt_count): "ri" (val));
  }
  goto ldv_6713;
  case 8UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incq %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decq %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addq %1, %%gs:%0": "+m" (__preempt_count): "re" (val));
  }
  goto ldv_6713;
  default: 
  __bad_percpu_size();
  }
  ldv_6713: ;
  return;
}
}
__inline static void __preempt_count_sub(int val ) 
{ 
  int pao_ID__ ;

  {
  pao_ID__ = 0;
  switch (4UL) {
  case 1UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incb %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decb %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addb %1, %%gs:%0": "+m" (__preempt_count): "qi" (- val));
  }
  goto ldv_6725;
  case 2UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incw %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decw %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addw %1, %%gs:%0": "+m" (__preempt_count): "ri" (- val));
  }
  goto ldv_6725;
  case 4UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incl %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decl %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addl %1, %%gs:%0": "+m" (__preempt_count): "ri" (- val));
  }
  goto ldv_6725;
  case 8UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incq %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decq %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addq %1, %%gs:%0": "+m" (__preempt_count): "re" (- val));
  }
  goto ldv_6725;
  default: 
  __bad_percpu_size();
  }
  ldv_6725: ;
  return;
}
}
bool ldv_queue_work_on_287(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_289(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_288(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_291(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_290(struct workqueue_struct *ldv_func_arg1 ) ;
extern void __iowrite64_copy(void * , void const   * , size_t  ) ;
__inline static void *lowmem_page_address(struct page  const  *page ) 
{ 


  {
  return ((void *)((unsigned long )((unsigned long long )(((long )page + 24189255811072L) / 64L) << 12) + 0xffff880000000000UL));
}
}
__inline static int valid_dma_direction(int dma_direction ) 
{ 


  {
  return ((dma_direction == 0 || dma_direction == 1) || dma_direction == 2);
}
}
__inline static void kmemcheck_mark_initialized(void *address , unsigned int n ) 
{ 


  {
  return;
}
}
extern void debug_dma_map_page(struct device * , struct page * , size_t  , size_t  ,
                               int  , dma_addr_t  , bool  ) ;
extern void debug_dma_mapping_error(struct device * , dma_addr_t  ) ;
extern void debug_dma_unmap_page(struct device * , dma_addr_t  , size_t  , int  ,
                                 bool  ) ;
extern struct dma_map_ops *dma_ops ;
__inline static struct dma_map_ops *get_dma_ops(struct device *dev ) 
{ 
  long tmp ;

  {
  tmp = ldv__builtin_expect((unsigned long )dev == (unsigned long )((struct device *)0),
                         0L);
  if (tmp != 0L || (unsigned long )dev->archdata.dma_ops == (unsigned long )((struct dma_map_ops *)0)) {
    return (dma_ops);
  } else {
    return (dev->archdata.dma_ops);
  }
}
}
__inline static dma_addr_t dma_map_single_attrs(struct device *dev , void *ptr , size_t size ,
                                                enum dma_data_direction dir , struct dma_attrs *attrs ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  dma_addr_t addr ;
  int tmp___0 ;
  long tmp___1 ;
  unsigned long tmp___2 ;
  unsigned long tmp___3 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  kmemcheck_mark_initialized(ptr, (unsigned int )size);
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (19), "i" (12UL));
    ldv_26094: ;
    goto ldv_26094;
  } else {

  }
  tmp___2 = __phys_addr((unsigned long )ptr);
  addr = (*(ops->map_page))(dev, (struct page *)-24189255811072L + (tmp___2 >> 12),
                            (unsigned long )ptr & 4095UL, size, dir, attrs);
  tmp___3 = __phys_addr((unsigned long )ptr);
  debug_dma_map_page(dev, (struct page *)-24189255811072L + (tmp___3 >> 12), (unsigned long )ptr & 4095UL,
                     size, (int )dir, addr, 1);
  return (addr);
}
}
__inline static void dma_unmap_single_attrs(struct device *dev , dma_addr_t addr ,
                                            size_t size , enum dma_data_direction dir ,
                                            struct dma_attrs *attrs ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (36), "i" (12UL));
    ldv_26103: ;
    goto ldv_26103;
  } else {

  }
  if ((unsigned long )ops->unmap_page != (unsigned long )((void (*)(struct device * ,
                                                                    dma_addr_t  ,
                                                                    size_t  , enum dma_data_direction  ,
                                                                    struct dma_attrs * ))0)) {
    (*(ops->unmap_page))(dev, addr, size, dir, attrs);
  } else {

  }
  debug_dma_unmap_page(dev, addr, size, (int )dir, 1);
  return;
}
}
__inline static dma_addr_t dma_map_page(struct device *dev , struct page *page , size_t offset ,
                                        size_t size , enum dma_data_direction dir ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  dma_addr_t addr ;
  void *tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = lowmem_page_address((struct page  const  *)page);
  kmemcheck_mark_initialized(tmp___0 + offset, (unsigned int )size);
  tmp___1 = valid_dma_direction((int )dir);
  tmp___2 = ldv__builtin_expect(tmp___1 == 0, 0L);
  if (tmp___2 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (84), "i" (12UL));
    ldv_26138: ;
    goto ldv_26138;
  } else {

  }
  addr = (*(ops->map_page))(dev, page, offset, size, dir, (struct dma_attrs *)0);
  debug_dma_map_page(dev, page, offset, size, (int )dir, addr, 0);
  return (addr);
}
}
__inline static void dma_unmap_page(struct device *dev , dma_addr_t addr , size_t size ,
                                    enum dma_data_direction dir ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (96), "i" (12UL));
    ldv_26146: ;
    goto ldv_26146;
  } else {

  }
  if ((unsigned long )ops->unmap_page != (unsigned long )((void (*)(struct device * ,
                                                                    dma_addr_t  ,
                                                                    size_t  , enum dma_data_direction  ,
                                                                    struct dma_attrs * ))0)) {
    (*(ops->unmap_page))(dev, addr, size, dir, (struct dma_attrs *)0);
  } else {

  }
  debug_dma_unmap_page(dev, addr, size, (int )dir, 0);
  return;
}
}
__inline static int dma_mapping_error(struct device *dev , dma_addr_t dma_addr ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  debug_dma_mapping_error(dev, dma_addr);
  if ((unsigned long )ops->mapping_error != (unsigned long )((int (*)(struct device * ,
                                                                      dma_addr_t  ))0)) {
    tmp___0 = (*(ops->mapping_error))(dev, dma_addr);
    return (tmp___0);
  } else {

  }
  return (dma_addr == 0ULL);
}
}
__inline static unsigned int skb_frag_size(skb_frag_t const   *frag ) 
{ 


  {
  return ((unsigned int )frag->size);
}
}
extern int skb_pad(struct sk_buff * , int  ) ;
__inline static unsigned char *skb_end_pointer(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->end);
}
}
__inline static unsigned int skb_headlen(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned int )skb->len - (unsigned int )skb->data_len);
}
}
__inline static unsigned char *skb_transport_header(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->transport_header);
}
}
__inline static unsigned char *skb_network_header(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->network_header);
}
}
__inline static struct page *skb_frag_page(skb_frag_t const   *frag ) 
{ 


  {
  return ((struct page *)frag->page.p);
}
}
__inline static dma_addr_t skb_frag_dma_map(struct device *dev , skb_frag_t const   *frag ,
                                            size_t offset , size_t size , enum dma_data_direction dir ) 
{ 
  struct page *tmp ;
  dma_addr_t tmp___0 ;

  {
  tmp = skb_frag_page(frag);
  tmp___0 = dma_map_page(dev, tmp, (size_t )frag->page_offset + offset, size, dir);
  return (tmp___0);
}
}
__inline static u16 skb_get_queue_mapping(struct sk_buff  const  *skb ) 
{ 


  {
  return ((u16 )skb->queue_mapping);
}
}
__inline static void dql_queued(struct dql *dql , unsigned int count ) 
{ 
  long tmp ;

  {
  tmp = ldv__builtin_expect(count > 268435455U, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/dynamic_queue_limits.h"),
                         "i" (74), "i" (12UL));
    ldv_31325: ;
    goto ldv_31325;
  } else {

  }
  dql->last_obj_cnt = count;
  __asm__  volatile   ("": : : "memory");
  dql->num_queued = dql->num_queued + count;
  return;
}
}
__inline static int dql_avail(struct dql  const  *dql ) 
{ 
  unsigned int __var ;
  unsigned int __var___0 ;
    klee_make_symbolic(&__var___0, sizeof(int), "__var___0");

  {
  __var = 0U;
  __var___0 = 0U;
  return ((int )((unsigned int )*((unsigned int const volatile   *)(& dql->adj_limit)) - (unsigned int )*((unsigned int const volatile   *)(& dql->num_queued))));
}
}
extern void dql_completed(struct dql * , unsigned int  ) ;
extern void dql_reset(struct dql * ) ;
__inline static void netif_tx_start_queue(struct netdev_queue *dev_queue ) 
{ 


  {
  clear_bit(0L, (unsigned long volatile   *)(& dev_queue->state));
  return;
}
}
__inline static bool netif_tx_queue_stopped(struct netdev_queue  const  *dev_queue ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(0L, (unsigned long const volatile   *)(& dev_queue->state));
  return (tmp != 0);
}
}
__inline static bool netif_xmit_stopped(struct netdev_queue  const  *dev_queue ) 
{ 


  {
  return (((unsigned long )dev_queue->state & 3UL) != 0UL);
}
}
__inline static void netdev_tx_sent_queue(struct netdev_queue *dev_queue , unsigned int bytes ) 
{ 
  int tmp ;
  long tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;

  {
  dql_queued(& dev_queue->dql, bytes);
  tmp = dql_avail((struct dql  const  *)(& dev_queue->dql));
  tmp___0 = ldv__builtin_expect(tmp >= 0, 1L);
  if (tmp___0 != 0L) {
    return;
  } else {

  }
  set_bit(1L, (unsigned long volatile   *)(& dev_queue->state));
  __asm__  volatile   ("mfence": : : "memory");
  tmp___1 = dql_avail((struct dql  const  *)(& dev_queue->dql));
  tmp___2 = ldv__builtin_expect(tmp___1 >= 0, 0L);
  if (tmp___2 != 0L) {
    clear_bit(1L, (unsigned long volatile   *)(& dev_queue->state));
  } else {

  }
  return;
}
}
__inline static void netdev_tx_completed_queue(struct netdev_queue *dev_queue , unsigned int pkts ,
                                               unsigned int bytes ) 
{ 
  long tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
  tmp = ldv__builtin_expect(bytes == 0U, 0L);
  if (tmp != 0L) {
    return;
  } else {

  }
  dql_completed(& dev_queue->dql, bytes);
  __asm__  volatile   ("mfence": : : "memory");
  tmp___0 = dql_avail((struct dql  const  *)(& dev_queue->dql));
  if (tmp___0 < 0) {
    return;
  } else {

  }
  tmp___1 = test_and_clear_bit(1L, (unsigned long volatile   *)(& dev_queue->state));
  if (tmp___1 != 0) {
    netif_schedule_queue(dev_queue);
  } else {

  }
  return;
}
}
__inline static void netdev_tx_reset_queue(struct netdev_queue *q ) 
{ 


  {
  clear_bit(1L, (unsigned long volatile   *)(& q->state));
  dql_reset(& q->dql);
  return;
}
}
extern void __dev_kfree_skb_any(struct sk_buff * , enum skb_free_reason  ) ;
__inline static void dev_kfree_skb_any(struct sk_buff *skb ) 
{ 


  {
  __dev_kfree_skb_any(skb, 1);
  return;
}
}
__inline static void dev_consume_skb_any(struct sk_buff *skb ) 
{ 


  {
  __dev_kfree_skb_any(skb, 0);
  return;
}
}
__inline static void pagefault_disabled_inc(void) 
{ 
  struct task_struct *tmp ;

  {
  tmp = get_current();
  tmp->pagefault_disabled = tmp->pagefault_disabled + 1;
  return;
}
}
__inline static void pagefault_disabled_dec(void) 
{ 
  struct task_struct *tmp ;
  int __ret_warn_on ;
  struct task_struct *tmp___0 ;
  long tmp___1 ;

  {
  tmp = get_current();
  tmp->pagefault_disabled = tmp->pagefault_disabled - 1;
  tmp___0 = get_current();
  __ret_warn_on = tmp___0->pagefault_disabled < 0;
  tmp___1 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___1 != 0L) {
    warn_slowpath_null("include/linux/uaccess.h", 15);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  return;
}
}
__inline static void pagefault_disable(void) 
{ 


  {
  pagefault_disabled_inc();
  __asm__  volatile   ("": : : "memory");
  return;
}
}
__inline static void pagefault_enable(void) 
{ 


  {
  __asm__  volatile   ("": : : "memory");
  pagefault_disabled_dec();
  return;
}
}
__inline static struct tcphdr *tcp_hdr(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_transport_header(skb);
  return ((struct tcphdr *)tmp);
}
}
__inline static struct iphdr *ip_hdr(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_network_header(skb);
  return ((struct iphdr *)tmp);
}
}
__inline static void *kmap_atomic(struct page *page ) 
{ 
  void *tmp ;

  {
  __preempt_count_add(1);
  __asm__  volatile   ("": : : "memory");
  pagefault_disable();
  tmp = lowmem_page_address((struct page  const  *)page);
  return (tmp);
}
}
__inline static void __kunmap_atomic(void *addr ) 
{ 


  {
  pagefault_enable();
  __asm__  volatile   ("": : : "memory");
  __preempt_count_sub(1);
  return;
}
}
__inline static bool efx_xmit_with_hwtstamp(struct sk_buff *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  return (((int )((struct skb_shared_info *)tmp)->tx_flags & 1) != 0);
}
}
netdev_tx_t efx_enqueue_skb(struct efx_tx_queue *tx_queue , struct sk_buff *skb ) ;
static struct efx_tx_queue *efx_tx_queue_partner(struct efx_tx_queue *tx_queue ) 
{ 


  {
  if ((int )tx_queue->queue & 1) {
    return (tx_queue + 0xffffffffffffffffUL);
  } else {
    return (tx_queue + 1UL);
  }
}
}
__inline static bool efx_nic_may_tx_pio(struct efx_tx_queue *tx_queue ) 
{ 
  struct efx_tx_queue *partner ;
  struct efx_tx_queue *tmp ;
  bool tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;

  {
  tmp = efx_tx_queue_partner(tx_queue);
  partner = tmp;
  if ((unsigned long )tx_queue->piobuf != (unsigned long )((void *)0)) {
    tmp___0 = __efx_nic_tx_is_empty(tx_queue, tx_queue->insert_count);
    if ((int )tmp___0) {
      tmp___1 = __efx_nic_tx_is_empty(partner, partner->insert_count);
      if ((int )tmp___1) {
        tmp___2 = 1;
      } else {
        tmp___2 = 0;
      }
    } else {
      tmp___2 = 0;
    }
  } else {
    tmp___2 = 0;
  }
  return ((bool )tmp___2);
}
}
bool efx_ptp_is_ptp_tx(struct efx_nic *efx , struct sk_buff *skb ) ;
int efx_ptp_tx(struct efx_nic *efx , struct sk_buff *skb ) ;
__inline static int efx_nic_probe_tx(struct efx_tx_queue *tx_queue ) 
{ 
  int tmp ;

  {
  tmp = (*(((tx_queue->efx)->type)->tx_probe))(tx_queue);
  return (tmp);
}
}
__inline static void efx_nic_init_tx(struct efx_tx_queue *tx_queue ) 
{ 


  {
  (*(((tx_queue->efx)->type)->tx_init))(tx_queue);
  return;
}
}
__inline static void efx_nic_remove_tx(struct efx_tx_queue *tx_queue ) 
{ 


  {
  (*(((tx_queue->efx)->type)->tx_remove))(tx_queue);
  return;
}
}
__inline static void efx_nic_push_buffers(struct efx_tx_queue *tx_queue ) 
{ 


  {
  (*(((tx_queue->efx)->type)->tx_write))(tx_queue);
  return;
}
}
unsigned int efx_piobuf_size  =    256U;
__inline static unsigned int efx_tx_queue_get_insert_index(struct efx_tx_queue  const  *tx_queue ) 
{ 


  {
  return ((unsigned int )tx_queue->insert_count & (unsigned int )tx_queue->ptr_mask);
}
}
__inline static struct efx_tx_buffer *__efx_tx_queue_get_insert_buffer(struct efx_tx_queue  const  *tx_queue ) 
{ 
  unsigned int tmp ;

  {
  tmp = efx_tx_queue_get_insert_index(tx_queue);
  return ((struct efx_tx_buffer *)tx_queue->buffer + (unsigned long )tmp);
}
}
__inline static struct efx_tx_buffer *efx_tx_queue_get_insert_buffer(struct efx_tx_queue  const  *tx_queue ) 
{ 
  struct efx_tx_buffer *buffer ;
  struct efx_tx_buffer *tmp ;

  {
  tmp = __efx_tx_queue_get_insert_buffer(tx_queue);
  buffer = tmp;
  return (buffer);
}
}
static void efx_dequeue_buffer(struct efx_tx_queue *tx_queue , struct efx_tx_buffer *buffer ,
                               unsigned int *pkts_compl , unsigned int *bytes_compl ) 
{ 
  struct device *dma_dev ;
  dma_addr_t unmap_addr ;

  {
  if ((unsigned int )buffer->unmap_len != 0U) {
    dma_dev = & ((tx_queue->efx)->pci_dev)->dev;
    unmap_addr = buffer->__annonCompField116.dma_addr - (dma_addr_t )buffer->dma_offset;
    if (((int )buffer->flags & 8) != 0) {
      dma_unmap_single_attrs(dma_dev, unmap_addr, (size_t )buffer->unmap_len, 1, (struct dma_attrs *)0);
    } else {
      dma_unmap_page(dma_dev, unmap_addr, (size_t )buffer->unmap_len, 1);
    }
    buffer->unmap_len = 0U;
  } else {

  }
  if (((int )buffer->flags & 2) != 0) {
    *pkts_compl = *pkts_compl + 1U;
    *bytes_compl = *bytes_compl + (unsigned int )(buffer->__annonCompField115.skb)->len;
    dev_consume_skb_any((struct sk_buff *)buffer->__annonCompField115.skb);
  } else
  if (((int )buffer->flags & 4) != 0) {
    kfree((void const   *)buffer->__annonCompField115.heap_buf);
  } else {

  }
  buffer->len = 0U;
  buffer->flags = 0U;
  return;
}
}
static int efx_enqueue_skb_tso(struct efx_tx_queue *tx_queue , struct sk_buff *skb ) ;
__inline static unsigned int efx_max_tx_len(struct efx_nic *efx , dma_addr_t dma_addr ) 
{ 
  unsigned int len ;
  unsigned int __min1 ;
  unsigned int __min2 ;
  int tmp ;

  {
  len = (~ ((unsigned int )dma_addr) & 4095U) + 1U;
  tmp = efx_nic_rev(efx);
  if (tmp <= 1 && (dma_addr & 15ULL) != 0ULL) {
    __min1 = len;
    __min2 = 512U - ((unsigned int )dma_addr & 15U);
    len = __min1 < __min2 ? __min1 : __min2;
  } else {

  }
  return (len);
}
}
unsigned int efx_tx_max_skb_descs(struct efx_nic *efx ) 
{ 
  unsigned int max_descs ;
    klee_make_symbolic(&max_descs, sizeof(int), "max_descs");
  int tmp ;
  int tmp___0 ;

  {
  max_descs = 217U;
  tmp = efx_nic_rev(efx);
  if (tmp <= 1) {
    max_descs = max_descs + 100U;
  } else {
    tmp___0 = efx_nic_rev(efx);
    if (tmp___0 > 3) {
      max_descs = max_descs + 100U;
    } else {

    }
  }
  return (max_descs);
}
}
static void efx_tx_maybe_stop_queue(struct efx_tx_queue *txq1 ) 
{ 
  struct efx_tx_queue *txq2 ;
  struct efx_tx_queue *tmp ;
  struct efx_nic *efx ;
  unsigned int fill_level ;
    klee_make_symbolic(&fill_level, sizeof(int), "fill_level");
  unsigned int _max1 ;
  unsigned int _max2 ;
  long tmp___0 ;
  unsigned int __var ;
  unsigned int __var___0 ;
  unsigned int _max1___0 ;
  unsigned int _max2___0 ;
  long tmp___1 ;
  long tmp___2 ;

  {
  tmp = efx_tx_queue_partner(txq1);
  txq2 = tmp;
  efx = txq1->efx;
  _max1 = txq1->insert_count - txq1->old_read_count;
  _max2 = txq2->insert_count - txq2->old_read_count;
  fill_level = _max1 > _max2 ? _max1 : _max2;
  tmp___0 = ldv__builtin_expect(efx->txq_stop_thresh > fill_level, 1L);
  if (tmp___0 != 0L) {
    return;
  } else {

  }
  netif_tx_stop_queue(txq1->core_txq);
  __asm__  volatile   ("mfence": : : "memory");
  __var = 0U;
  txq1->old_read_count = *((unsigned int volatile   *)(& txq1->read_count));
  __var___0 = 0U;
  txq2->old_read_count = *((unsigned int volatile   *)(& txq2->read_count));
  _max1___0 = txq1->insert_count - txq1->old_read_count;
  _max2___0 = txq2->insert_count - txq2->old_read_count;
  fill_level = _max1___0 > _max2___0 ? _max1___0 : _max2___0;
  tmp___2 = ldv__builtin_expect(efx->txq_stop_thresh > fill_level, 1L);
  if (tmp___2 != 0L) {
    __asm__  volatile   ("mfence": : : "memory");
    tmp___1 = ldv__builtin_expect((unsigned long )efx->loopback_selftest == (unsigned long )((void *)0),
                               1L);
    if (tmp___1 != 0L) {
      netif_tx_start_queue(txq1->core_txq);
    } else {

    }
  } else {

  }
  return;
}
}
static void efx_memcpy_toio_aligned(struct efx_nic *efx , u8 **piobuf , u8 *data ,
                                    int len , struct efx_short_copy_buffer *copy_buf ) 
{ 
  int block_len ;
  long tmp ;
  long tmp___0 ;

  {
  block_len = len & -64;
  __iowrite64_copy((void *)*piobuf, (void const   *)data, (size_t )(block_len >> 3));
  *piobuf = *piobuf + (unsigned long )block_len;
  len = len - block_len;
  if (len != 0) {
    data = data + (unsigned long )block_len;
    tmp = ldv__builtin_expect(copy_buf->used != 0, 0L);
    if (tmp != 0L) {
      __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/tx.c"),
                           "i" (198), "i" (12UL));
      ldv_55497: ;
      goto ldv_55497;
    } else {

    }
    tmp___0 = ldv__builtin_expect((unsigned int )len > 64U, 0L);
    if (tmp___0 != 0L) {
      __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/tx.c"),
                           "i" (199), "i" (12UL));
      ldv_55498: ;
      goto ldv_55498;
    } else {

    }
    memcpy((void *)(& copy_buf->buf), (void const   *)data, (size_t )len);
    copy_buf->used = len;
  } else {

  }
  return;
}
}
static void efx_memcpy_toio_aligned_cb(struct efx_nic *efx , u8 **piobuf , u8 *data ,
                                       int len , struct efx_short_copy_buffer *copy_buf ) 
{ 
  int copy_to_buf ;
    klee_make_symbolic(&copy_to_buf, sizeof(int), "copy_to_buf");
  int __min1 ;
  int __min2 ;

  {
  if (copy_buf->used != 0) {
    __min1 = (int )(64U - (unsigned int )copy_buf->used);
    __min2 = len;
    copy_to_buf = __min1 < __min2 ? __min1 : __min2;
    memcpy((void *)(& copy_buf->buf) + (unsigned long )copy_buf->used, (void const   *)data,
             (size_t )copy_to_buf);
    copy_buf->used = copy_buf->used + copy_to_buf;
    if ((unsigned int )copy_buf->used <= 63U) {
      return;
    } else {

    }
    __iowrite64_copy((void *)*piobuf, (void const   *)(& copy_buf->buf), 8UL);
    *piobuf = *piobuf + 64UL;
    data = data + (unsigned long )copy_to_buf;
    len = len - copy_to_buf;
    copy_buf->used = 0;
  } else {

  }
  efx_memcpy_toio_aligned(efx, piobuf, data, len, copy_buf);
  return;
}
}
static void efx_flush_copy_buffer(struct efx_nic *efx , u8 *piobuf , struct efx_short_copy_buffer *copy_buf ) 
{ 


  {
  if (copy_buf->used != 0) {
    __iowrite64_copy((void *)piobuf, (void const   *)(& copy_buf->buf), 8UL);
  } else {

  }
  return;
}
}
static void efx_skb_copy_bits_to_pio(struct efx_nic *efx , struct sk_buff *skb , u8 **piobuf ,
                                     struct efx_short_copy_buffer *copy_buf ) 
{ 
  int i ;
  unsigned int tmp ;
  skb_frag_t *f ;
  unsigned char *tmp___0 ;
  u8 *vaddr ;
  struct page *tmp___1 ;
  void *tmp___2 ;
  unsigned int tmp___3 ;
  unsigned char *tmp___4 ;

  {
  tmp = skb_headlen((struct sk_buff  const  *)skb);
  efx_memcpy_toio_aligned(efx, piobuf, skb->data, (int )tmp, copy_buf);
  i = 0;
  goto ldv_55525;
  ldv_55524: 
  tmp___0 = skb_end_pointer((struct sk_buff  const  *)skb);
  f = (skb_frag_t *)(& ((struct skb_shared_info *)tmp___0)->frags) + (unsigned long )i;
  tmp___1 = skb_frag_page((skb_frag_t const   *)f);
  tmp___2 = kmap_atomic(tmp___1);
  vaddr = (u8 *)tmp___2;
  tmp___3 = skb_frag_size((skb_frag_t const   *)f);
  efx_memcpy_toio_aligned_cb(efx, piobuf, vaddr + (unsigned long )f->page_offset,
                             (int )tmp___3, copy_buf);
  __kunmap_atomic((void *)vaddr);
  i = i + 1;
  ldv_55525: 
  tmp___4 = skb_end_pointer((struct sk_buff  const  *)skb);
  if ((int )((struct skb_shared_info *)tmp___4)->nr_frags > i) {
    goto ldv_55524;
  } else {

  }

  return;
}
}
static struct efx_tx_buffer *efx_enqueue_skb_pio(struct efx_tx_queue *tx_queue , struct sk_buff *skb ) 
{ 
  struct efx_tx_buffer *buffer ;
  struct efx_tx_buffer *tmp ;
  u8 *piobuf ;
  struct efx_short_copy_buffer copy_buf ;
  unsigned char *tmp___0 ;

  {
  tmp = efx_tx_queue_get_insert_buffer((struct efx_tx_queue  const  *)tx_queue);
  buffer = tmp;
  piobuf = (u8 *)tx_queue->piobuf;
  tmp___0 = skb_end_pointer((struct sk_buff  const  *)skb);
  if ((unsigned int )((struct skb_shared_info *)tmp___0)->nr_frags != 0U) {
    copy_buf.used = 0;
    efx_skb_copy_bits_to_pio(tx_queue->efx, skb, & piobuf, & copy_buf);
    efx_flush_copy_buffer(tx_queue->efx, piobuf, & copy_buf);
  } else {
    __iowrite64_copy(tx_queue->piobuf, (void const   *)skb->data, (size_t )(((skb->len + 63U) & 4294967232U) >> 3));
  }
  buffer->__annonCompField116.option.u64[0] = (((unsigned long long )skb->len << 32) | (unsigned long long )tx_queue->piobuf_offset) | 0x9000000000000000ULL;
  tx_queue->pio_packets = tx_queue->pio_packets + 1U;
  tx_queue->insert_count = tx_queue->insert_count + 1U;
  return (buffer);
}
}
netdev_tx_t efx_enqueue_skb(struct efx_tx_queue *tx_queue , struct sk_buff *skb ) 
{ 
  struct efx_nic *efx ;
  struct device *dma_dev ;
  struct efx_tx_buffer *buffer ;
  unsigned int old_insert_count ;
    klee_make_symbolic(&old_insert_count, sizeof(int), "old_insert_count");
  skb_frag_t *fragment ;
  unsigned int len ;
  unsigned int unmap_len ;
  dma_addr_t dma_addr ;
  dma_addr_t unmap_addr ;
  unsigned int dma_len ;
    klee_make_symbolic(&dma_len, sizeof(int), "dma_len");
  unsigned short dma_flags ;
  int i ;
  int tmp ;
  unsigned char *tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  bool tmp___3 ;
  int tmp___4 ;
  long tmp___5 ;
  long tmp___6 ;
  unsigned char *tmp___7 ;
  unsigned char *tmp___8 ;
  bool tmp___9 ;
  unsigned char *tmp___10 ;
  unsigned int pkts_compl ;
    klee_make_symbolic(&pkts_compl, sizeof(int), "pkts_compl");
  unsigned int bytes_compl ;
    klee_make_symbolic(&bytes_compl, sizeof(int), "bytes_compl");

  {
  efx = tx_queue->efx;
  dma_dev = & (efx->pci_dev)->dev;
  old_insert_count = tx_queue->insert_count;
  unmap_len = 0U;
  unmap_addr = 0ULL;
  i = 0;
  tmp___0 = skb_end_pointer((struct sk_buff  const  *)skb);
  if ((unsigned int )((struct skb_shared_info *)tmp___0)->gso_size != 0U) {
    tmp = efx_enqueue_skb_tso(tx_queue, skb);
    return ((netdev_tx_t )tmp);
  } else {

  }
  len = skb_headlen((struct sk_buff  const  *)skb);
  tmp___2 = efx_nic_rev(efx);
  if (tmp___2 <= 2 && skb->len <= 32U) {
    len = 33U;
    tmp___1 = skb_pad(skb, (int )(len - skb->len));
    if (tmp___1 != 0) {
      return (0);
    } else {

    }
  } else {

  }
  if (skb->len <= efx_piobuf_size && (unsigned int )*((unsigned char *)skb + 142UL) == 0U) {
    tmp___3 = efx_nic_may_tx_pio(tx_queue);
    if ((int )tmp___3) {
      buffer = efx_enqueue_skb_pio(tx_queue, skb);
      dma_flags = 16U;
      goto finish_packet;
    } else {

    }
  } else {

  }
  dma_flags = 8U;
  dma_addr = dma_map_single_attrs(dma_dev, (void *)skb->data, (size_t )len, 1, (struct dma_attrs *)0);
  ldv_55555: 
  tmp___4 = dma_mapping_error(dma_dev, dma_addr);
  tmp___5 = ldv__builtin_expect(tmp___4 != 0, 0L);
  if (tmp___5 != 0L) {
    goto dma_err;
  } else {

  }
  unmap_len = len;
  unmap_addr = dma_addr;
  ldv_55552: 
  buffer = efx_tx_queue_get_insert_buffer((struct efx_tx_queue  const  *)tx_queue);
  dma_len = efx_max_tx_len(efx, dma_addr);
  tmp___6 = ldv__builtin_expect(dma_len >= len, 1L);
  if (tmp___6 != 0L) {
    dma_len = len;
  } else {

  }
  buffer->len = (unsigned short )dma_len;
  buffer->__annonCompField116.dma_addr = dma_addr;
  buffer->flags = 1U;
  len = len - dma_len;
  dma_addr = (dma_addr_t )dma_len + dma_addr;
  tx_queue->insert_count = tx_queue->insert_count + 1U;
  if (len != 0U) {
    goto ldv_55552;
  } else {

  }
  buffer->flags = (unsigned int )dma_flags | 1U;
  buffer->unmap_len = (unsigned short )unmap_len;
  buffer->dma_offset = (int )((unsigned short )buffer->__annonCompField116.dma_addr) - (int )((unsigned short )unmap_addr);
  unmap_len = 0U;
  tmp___7 = skb_end_pointer((struct sk_buff  const  *)skb);
  if ((int )((struct skb_shared_info *)tmp___7)->nr_frags <= i) {
    goto ldv_55554;
  } else {

  }
  tmp___8 = skb_end_pointer((struct sk_buff  const  *)skb);
  fragment = (skb_frag_t *)(& ((struct skb_shared_info *)tmp___8)->frags) + (unsigned long )i;
  len = skb_frag_size((skb_frag_t const   *)fragment);
  i = i + 1;
  dma_flags = 0U;
  dma_addr = skb_frag_dma_map(dma_dev, (skb_frag_t const   *)fragment, 0UL, (size_t )len,
                              1);
  goto ldv_55555;
  ldv_55554: ;
  finish_packet: 
  buffer->__annonCompField115.skb = (struct sk_buff  const  *)skb;
  buffer->flags = (unsigned int )dma_flags | 2U;
  netdev_tx_sent_queue(tx_queue->core_txq, skb->len);
  efx_tx_maybe_stop_queue(tx_queue);
  if ((unsigned int )*((unsigned char *)skb + 142UL) == 0U) {
    efx_nic_push_buffers(tx_queue);
  } else {
    tmp___9 = netif_xmit_stopped((struct netdev_queue  const  *)tx_queue->core_txq);
    if ((int )tmp___9) {
      efx_nic_push_buffers(tx_queue);
    } else {

    }
  }
  tx_queue->tx_packets = tx_queue->tx_packets + 1UL;
  return (0);
  dma_err: ;
  if ((efx->msg_enable & 128U) != 0U) {
    tmp___10 = skb_end_pointer((struct sk_buff  const  *)skb);
    netdev_err((struct net_device  const  *)efx->net_dev, " TX queue %d could not map skb with %d bytes %d fragments for DMA\n",
               tx_queue->queue, skb->len, (int )((struct skb_shared_info *)tmp___10)->nr_frags + 1);
  } else {

  }
  dev_kfree_skb_any(skb);
  goto ldv_55559;
  ldv_55558: 
  pkts_compl = 0U;
  bytes_compl = 0U;
  tx_queue->insert_count = tx_queue->insert_count - 1U;
  buffer = __efx_tx_queue_get_insert_buffer((struct efx_tx_queue  const  *)tx_queue);
  efx_dequeue_buffer(tx_queue, buffer, & pkts_compl, & bytes_compl);
  ldv_55559: ;
  if (tx_queue->insert_count != old_insert_count) {
    goto ldv_55558;
  } else {

  }

  if (unmap_len != 0U) {
    if (((int )dma_flags & 8) != 0) {
      dma_unmap_single_attrs(dma_dev, unmap_addr, (size_t )unmap_len, 1, (struct dma_attrs *)0);
    } else {
      dma_unmap_page(dma_dev, unmap_addr, (size_t )unmap_len, 1);
    }
  } else {

  }
  return (0);
}
}
static void efx_dequeue_buffers(struct efx_tx_queue *tx_queue , unsigned int index ,
                                unsigned int *pkts_compl , unsigned int *bytes_compl ) 
{ 
  struct efx_nic *efx ;
  unsigned int stop_index ;
    klee_make_symbolic(&stop_index, sizeof(int), "stop_index");
  unsigned int read_ptr ;
  struct efx_tx_buffer *buffer ;
  long tmp ;

  {
  efx = tx_queue->efx;
  stop_index = (index + 1U) & tx_queue->ptr_mask;
  read_ptr = tx_queue->read_count & tx_queue->ptr_mask;
  goto ldv_55572;
  ldv_55571: 
  buffer = tx_queue->buffer + (unsigned long )read_ptr;
  if (((int )buffer->flags & 16) == 0) {
    tmp = ldv__builtin_expect((unsigned int )buffer->len == 0U, 0L);
    if (tmp != 0L) {
      if ((efx->msg_enable & 128U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "TX queue %d spurious TX completion id %x\n",
                   tx_queue->queue, read_ptr);
      } else {

      }
      efx_schedule_reset(efx, 13);
      return;
    } else {

    }
  } else {

  }
  efx_dequeue_buffer(tx_queue, buffer, pkts_compl, bytes_compl);
  tx_queue->read_count = tx_queue->read_count + 1U;
  read_ptr = tx_queue->read_count & tx_queue->ptr_mask;
  ldv_55572: ;
  if (read_ptr != stop_index) {
    goto ldv_55571;
  } else {

  }

  return;
}
}
netdev_tx_t efx_hard_start_xmit(struct sk_buff *skb , struct net_device *net_dev ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct efx_tx_queue *tx_queue ;
  unsigned int index ;
  unsigned int type ;
  int tmp___0 ;
  bool tmp___1 ;
  long tmp___2 ;
  bool tmp___3 ;
  long tmp___4 ;
  u16 tmp___5 ;
  netdev_tx_t tmp___6 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  tmp___1 = efx_xmit_with_hwtstamp(skb);
  tmp___2 = ldv__builtin_expect((long )tmp___1, 0L);
  if (tmp___2 != 0L) {
    tmp___3 = efx_ptp_is_ptp_tx(efx, skb);
    tmp___4 = ldv__builtin_expect((long )tmp___3, 0L);
    if (tmp___4 != 0L) {
      tmp___0 = efx_ptp_tx(efx, skb);
      return ((netdev_tx_t )tmp___0);
    } else {

    }
  } else {

  }
  tmp___5 = skb_get_queue_mapping((struct sk_buff  const  *)skb);
  index = (unsigned int )tmp___5;
  type = (unsigned int )*((unsigned char *)skb + 145UL) == 6U;
  if (efx->n_tx_channels <= index) {
    index = index - efx->n_tx_channels;
    type = type | 2U;
  } else {

  }
  tx_queue = efx_get_tx_queue(efx, index, type);
  tmp___6 = efx_enqueue_skb(tx_queue, skb);
  return (tmp___6);
}
}
void efx_init_tx_queue_core_txq(struct efx_tx_queue *tx_queue ) 
{ 
  struct efx_nic *efx ;

  {
  efx = tx_queue->efx;
  tx_queue->core_txq = netdev_get_tx_queue((struct net_device  const  *)efx->net_dev,
                                           tx_queue->queue / 4U + ((tx_queue->queue & 2U) != 0U ? efx->n_tx_channels : 0U));
  return;
}
}
int efx_setup_tc(struct net_device *net_dev , u8 num_tc ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct efx_channel *channel ;
  struct efx_tx_queue *tx_queue ;
  unsigned int tc ;
    klee_make_symbolic(&tc, sizeof(int), "tc");
  int rc ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int __max1 ;
    klee_make_symbolic(&__max1, sizeof(int), "__max1");
  int __max2 ;
    klee_make_symbolic(&__max2, sizeof(int), "__max2");

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  tmp___0 = efx_nic_rev(efx);
  if (tmp___0 <= 1 || (unsigned int )num_tc > 2U) {
    return (-22);
  } else {

  }
  if ((int )net_dev->num_tc == (int )num_tc) {
    return (0);
  } else {

  }
  tc = 0U;
  goto ldv_55596;
  ldv_55595: 
  net_dev->tc_to_txq[tc].offset = (int )((u16 )efx->n_tx_channels) * (int )((u16 )tc);
  net_dev->tc_to_txq[tc].count = (u16 )efx->n_tx_channels;
  tc = tc + 1U;
  ldv_55596: ;
  if ((unsigned int )num_tc > tc) {
    goto ldv_55595;
  } else {

  }

  if ((int )net_dev->num_tc < (int )num_tc) {
    channel = efx->channel[0];
    goto ldv_55603;
    ldv_55602: 
    tmp___1 = efx_channel_has_tx_queues(channel);
    if (tmp___1) {
      tmp___2 = 0;
    } else {
      tmp___2 = 1;
    }
    if (tmp___2) {

    } else {
      tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
      goto ldv_55600;
      ldv_55599: ;
      if ((tx_queue->queue & 2U) == 0U) {
        goto ldv_55598;
      } else {

      }
      if ((unsigned long )tx_queue->buffer == (unsigned long )((struct efx_tx_buffer *)0)) {
        rc = efx_probe_tx_queue(tx_queue);
        if (rc != 0) {
          return (rc);
        } else {

        }
      } else {

      }
      if (! tx_queue->initialised) {
        efx_init_tx_queue(tx_queue);
      } else {

      }
      efx_init_tx_queue_core_txq(tx_queue);
      ldv_55598: 
      tx_queue = tx_queue + 1;
      ldv_55600: ;
      if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
        goto ldv_55599;
      } else {

      }

    }
    channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
    ldv_55603: ;
    if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
      goto ldv_55602;
    } else {

    }

  } else {
    net_dev->num_tc = num_tc;
  }
  __max1 = (int )num_tc;
  __max2 = 1;
  rc = netif_set_real_num_tx_queues(net_dev, (unsigned int )(__max1 > __max2 ? __max1 : __max2) * efx->n_tx_channels);
  if (rc != 0) {
    return (rc);
  } else {

  }
  net_dev->num_tc = num_tc;
  return (0);
}
}
void efx_xmit_done(struct efx_tx_queue *tx_queue , unsigned int index ) 
{ 
  unsigned int fill_level ;
  struct efx_nic *efx ;
  struct efx_tx_queue *txq2 ;
  unsigned int pkts_compl ;
  unsigned int bytes_compl ;
  unsigned int _max1 ;
  unsigned int _max2 ;
  bool tmp ;
  long tmp___0 ;
  long tmp___1 ;
  bool tmp___2 ;
  long tmp___3 ;
  unsigned int __var ;

  {
  efx = tx_queue->efx;
  pkts_compl = 0U;
  bytes_compl = 0U;
  efx_dequeue_buffers(tx_queue, index, & pkts_compl, & bytes_compl);
  netdev_tx_completed_queue(tx_queue->core_txq, pkts_compl, bytes_compl);
  if (pkts_compl > 1U) {
    tx_queue->merge_events = tx_queue->merge_events + 1U;
  } else {

  }
  __asm__  volatile   ("mfence": : : "memory");
  tmp = netif_tx_queue_stopped((struct netdev_queue  const  *)tx_queue->core_txq);
  tmp___0 = ldv__builtin_expect((long )tmp, 0L);
  if (tmp___0 != 0L) {
    tmp___1 = ldv__builtin_expect((long )efx->port_enabled, 1L);
    if (tmp___1 != 0L) {
      tmp___2 = netif_device_present(efx->net_dev);
      tmp___3 = ldv__builtin_expect((long )tmp___2, 1L);
      if (tmp___3 != 0L) {
        txq2 = efx_tx_queue_partner(tx_queue);
        _max1 = tx_queue->insert_count - tx_queue->read_count;
        _max2 = txq2->insert_count - txq2->read_count;
        fill_level = _max1 > _max2 ? _max1 : _max2;
        if (efx->txq_wake_thresh >= fill_level) {
          netif_tx_wake_queue(tx_queue->core_txq);
        } else {

        }
      } else {

      }
    } else {

    }
  } else {

  }
  if ((int )(tx_queue->read_count - tx_queue->old_write_count) >= 0) {
    __var = 0U;
    tx_queue->old_write_count = *((unsigned int volatile   *)(& tx_queue->write_count));
    if (tx_queue->read_count == tx_queue->old_write_count) {
      __asm__  volatile   ("mfence": : : "memory");
      tx_queue->empty_read_count = tx_queue->read_count | 2147483648U;
    } else {

    }
  } else {

  }
  return;
}
}
static unsigned int efx_tsoh_page_count(struct efx_tx_queue *tx_queue ) 
{ 


  {
  return ((unsigned int )(((unsigned long )(tx_queue->ptr_mask + 1U) + 63UL) / 64UL));
}
}
int efx_probe_tx_queue(struct efx_tx_queue *tx_queue ) 
{ 
  struct efx_nic *efx ;
  unsigned int entries ;
  int rc ;
  unsigned long _max1 ;
  unsigned long tmp ;
  unsigned long _max2 ;
  struct _ddebug descriptor ;
  long tmp___0 ;
  void *tmp___1 ;
  unsigned int tmp___2 ;
  void *tmp___3 ;

  {
  efx = tx_queue->efx;
  tmp = __roundup_pow_of_two((unsigned long )efx->txq_entries);
  _max1 = tmp;
  _max2 = 512UL;
  entries = (unsigned int )(_max1 > _max2 ? _max1 : _max2);
  tx_queue->ptr_mask = entries - 1U;
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_probe_tx_queue";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/tx.c";
    descriptor.format = "creating TX queue %d size %#x mask %#x\n";
    descriptor.lineno = 679U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "creating TX queue %d size %#x mask %#x\n", tx_queue->queue,
                           efx->txq_entries, tx_queue->ptr_mask);
    } else {

    }
  } else {

  }
  tmp___1 = kcalloc((size_t )entries, 24UL, 208U);
  tx_queue->buffer = (struct efx_tx_buffer *)tmp___1;
  if ((unsigned long )tx_queue->buffer == (unsigned long )((struct efx_tx_buffer *)0)) {
    return (-12);
  } else {

  }
  if ((int )tx_queue->queue & 1) {
    tmp___2 = efx_tsoh_page_count(tx_queue);
    tmp___3 = kcalloc((size_t )tmp___2, 24UL, 208U);
    tx_queue->tsoh_page = (struct efx_buffer *)tmp___3;
    if ((unsigned long )tx_queue->tsoh_page == (unsigned long )((struct efx_buffer *)0)) {
      rc = -12;
      goto fail1;
    } else {

    }
  } else {

  }
  rc = efx_nic_probe_tx(tx_queue);
  if (rc != 0) {
    goto fail2;
  } else {

  }
  return (0);
  fail2: 
  kfree((void const   *)tx_queue->tsoh_page);
  tx_queue->tsoh_page = (struct efx_buffer *)0;
  fail1: 
  kfree((void const   *)tx_queue->buffer);
  tx_queue->buffer = (struct efx_tx_buffer *)0;
  return (rc);
}
}
void efx_init_tx_queue(struct efx_tx_queue *tx_queue ) 
{ 
  struct _ddebug descriptor ;
  long tmp ;

  {
  if ((int )(tx_queue->efx)->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_init_tx_queue";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/tx.c";
    descriptor.format = "initialising TX queue %d\n";
    descriptor.lineno = 716U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)(tx_queue->efx)->net_dev,
                           "initialising TX queue %d\n", tx_queue->queue);
    } else {

    }
  } else {

  }
  tx_queue->insert_count = 0U;
  tx_queue->write_count = 0U;
  tx_queue->old_write_count = 0U;
  tx_queue->read_count = 0U;
  tx_queue->old_read_count = 0U;
  tx_queue->empty_read_count = 2147483648U;
  efx_nic_init_tx(tx_queue);
  tx_queue->initialised = 1;
  return;
}
}
void efx_fini_tx_queue(struct efx_tx_queue *tx_queue ) 
{ 
  struct efx_tx_buffer *buffer ;
  struct _ddebug descriptor ;
  long tmp ;
  unsigned int pkts_compl ;
  unsigned int bytes_compl ;

  {
  if ((int )(tx_queue->efx)->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_fini_tx_queue";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/tx.c";
    descriptor.format = "shutting down TX queue %d\n";
    descriptor.lineno = 736U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)(tx_queue->efx)->net_dev,
                           "shutting down TX queue %d\n", tx_queue->queue);
    } else {

    }
  } else {

  }
  if ((unsigned long )tx_queue->buffer == (unsigned long )((struct efx_tx_buffer *)0)) {
    return;
  } else {

  }
  goto ldv_55652;
  ldv_55651: 
  pkts_compl = 0U;
  bytes_compl = 0U;
  buffer = tx_queue->buffer + (unsigned long )(tx_queue->read_count & tx_queue->ptr_mask);
  efx_dequeue_buffer(tx_queue, buffer, & pkts_compl, & bytes_compl);
  tx_queue->read_count = tx_queue->read_count + 1U;
  ldv_55652: ;
  if (tx_queue->read_count != tx_queue->write_count) {
    goto ldv_55651;
  } else {

  }
  netdev_tx_reset_queue(tx_queue->core_txq);
  return;
}
}
void efx_remove_tx_queue(struct efx_tx_queue *tx_queue ) 
{ 
  int i ;
  struct _ddebug descriptor ;
  long tmp ;
  unsigned int tmp___0 ;

  {
  if ((unsigned long )tx_queue->buffer == (unsigned long )((struct efx_tx_buffer *)0)) {
    return;
  } else {

  }
  if ((int )(tx_queue->efx)->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_remove_tx_queue";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/tx.c";
    descriptor.format = "destroying TX queue %d\n";
    descriptor.lineno = 760U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)(tx_queue->efx)->net_dev,
                           "destroying TX queue %d\n", tx_queue->queue);
    } else {

    }
  } else {

  }
  efx_nic_remove_tx(tx_queue);
  if ((unsigned long )tx_queue->tsoh_page != (unsigned long )((struct efx_buffer *)0)) {
    i = 0;
    goto ldv_55661;
    ldv_55660: 
    efx_nic_free_buffer(tx_queue->efx, tx_queue->tsoh_page + (unsigned long )i);
    i = i + 1;
    ldv_55661: 
    tmp___0 = efx_tsoh_page_count(tx_queue);
    if ((unsigned int )i < tmp___0) {
      goto ldv_55660;
    } else {

    }
    kfree((void const   *)tx_queue->tsoh_page);
    tx_queue->tsoh_page = (struct efx_buffer *)0;
  } else {

  }
  kfree((void const   *)tx_queue->buffer);
  tx_queue->buffer = (struct efx_tx_buffer *)0;
  return;
}
}
static __be16 efx_tso_check_protocol(struct sk_buff *skb ) 
{ 
  __be16 protocol ;
  struct vlan_ethhdr *veh ;

  {
  protocol = skb->protocol;
  if ((unsigned int )protocol == 129U) {
    veh = (struct vlan_ethhdr *)skb->data;
    protocol = veh->h_vlan_encapsulated_proto;
  } else {

  }
  return (protocol);
}
}
static u8 *efx_tsoh_get_buffer(struct efx_tx_queue *tx_queue , struct efx_tx_buffer *buffer ,
                               unsigned int len ) 
{ 
  u8 *result ;
  unsigned int index ;
  struct efx_buffer *page_buf ;
  unsigned int offset ;
  long tmp ;
  int tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;

  {
  tmp___2 = ldv__builtin_expect(len <= 128U, 1L);
  if (tmp___2 != 0L) {
    index = (tx_queue->insert_count & tx_queue->ptr_mask) / 2U;
    page_buf = tx_queue->tsoh_page + (unsigned long )(index / 32U);
    offset = (index & 31U) * 128U;
    tmp = ldv__builtin_expect((unsigned long )page_buf->addr == (unsigned long )((void *)0),
                           0L);
    if (tmp != 0L) {
      tmp___0 = efx_nic_alloc_buffer(tx_queue->efx, page_buf, 4096U, 32U);
      if (tmp___0 != 0) {
        return ((u8 *)0U);
      } else {

      }
    } else {

    }
    result = (u8 *)page_buf->addr + (unsigned long )offset;
    buffer->__annonCompField116.dma_addr = page_buf->dma_addr + (dma_addr_t )offset;
    buffer->flags = 1U;
  } else {
    tx_queue->tso_long_headers = tx_queue->tso_long_headers + 1U;
    buffer->__annonCompField115.heap_buf = kmalloc((size_t )len, 32U);
    tmp___1 = ldv__builtin_expect((unsigned long )buffer->__annonCompField115.heap_buf == (unsigned long )((void *)0),
                               0L);
    if (tmp___1 != 0L) {
      return ((u8 *)0U);
    } else {

    }
    result = (u8 *)buffer->__annonCompField115.heap_buf;
    buffer->flags = 5U;
  }
  buffer->len = (unsigned short )len;
  return (result);
}
}
static void efx_tx_queue_insert(struct efx_tx_queue *tx_queue , dma_addr_t dma_addr ,
                                unsigned int len , struct efx_tx_buffer **final_buffer ) 
{ 
  struct efx_tx_buffer *buffer ;
  struct efx_nic *efx ;
  unsigned int dma_len ;

  {
  efx = tx_queue->efx;
  ldv_55704: 
  buffer = efx_tx_queue_get_insert_buffer((struct efx_tx_queue  const  *)tx_queue);
  tx_queue->insert_count = tx_queue->insert_count + 1U;
  buffer->__annonCompField116.dma_addr = dma_addr;
  dma_len = efx_max_tx_len(efx, dma_addr);
  if (dma_len >= len) {
    goto ldv_55703;
  } else {

  }
  buffer->len = (unsigned short )dma_len;
  buffer->flags = 1U;
  dma_addr = (dma_addr_t )dma_len + dma_addr;
  len = len - dma_len;
  goto ldv_55704;
  ldv_55703: 
  buffer->len = (unsigned short )len;
  *final_buffer = buffer;
  return;
}
}
static int efx_tso_put_header(struct efx_tx_queue *tx_queue , struct efx_tx_buffer *buffer ,
                              u8 *header ) 
{ 
  int tmp ;
  long tmp___0 ;
  long tmp___1 ;

  {
  tmp___1 = ldv__builtin_expect(((int )buffer->flags & 4) != 0, 0L);
  if (tmp___1 != 0L) {
    buffer->__annonCompField116.dma_addr = dma_map_single_attrs(& ((tx_queue->efx)->pci_dev)->dev,
                                                                (void *)header, (size_t )buffer->len,
                                                                1, (struct dma_attrs *)0);
    tmp = dma_mapping_error(& ((tx_queue->efx)->pci_dev)->dev, buffer->__annonCompField116.dma_addr);
    tmp___0 = ldv__builtin_expect(tmp != 0, 0L);
    if (tmp___0 != 0L) {
      kfree((void const   *)buffer->__annonCompField115.heap_buf);
      buffer->len = 0U;
      buffer->flags = 0U;
      return (-12);
    } else {

    }
    buffer->unmap_len = buffer->len;
    buffer->dma_offset = 0U;
    buffer->flags = (unsigned int )buffer->flags | 8U;
  } else {

  }
  tx_queue->insert_count = tx_queue->insert_count + 1U;
  return (0);
}
}
static void efx_enqueue_unwind(struct efx_tx_queue *tx_queue , unsigned int insert_count ) 
{ 
  struct efx_tx_buffer *buffer ;

  {
  goto ldv_55716;
  ldv_55715: 
  tx_queue->insert_count = tx_queue->insert_count - 1U;
  buffer = __efx_tx_queue_get_insert_buffer((struct efx_tx_queue  const  *)tx_queue);
  efx_dequeue_buffer(tx_queue, buffer, (unsigned int *)0U, (unsigned int *)0U);
  ldv_55716: ;
  if (tx_queue->insert_count != insert_count) {
    goto ldv_55715;
  } else {

  }

  return;
}
}
static int tso_start(struct tso_state *st , struct efx_nic *efx , struct sk_buff  const  *skb ) 
{ 
  bool use_opt_desc ;
  int tmp ;
  struct device *dma_dev ;
  unsigned int header_len ;
  unsigned int in_len ;
  dma_addr_t dma_addr ;
  unsigned char *tmp___0 ;
  unsigned char *tmp___1 ;
  struct tcphdr *tmp___2 ;
  unsigned int tmp___3 ;
  struct iphdr *tmp___4 ;
  __u16 tmp___5 ;
  struct tcphdr *tmp___6 ;
  __u32 tmp___7 ;
  long tmp___8 ;
  unsigned int tmp___9 ;
  int tmp___10 ;
  long tmp___11 ;

  {
  tmp = efx_nic_rev(efx);
  use_opt_desc = tmp > 3;
  dma_dev = & (efx->pci_dev)->dev;
  tmp___0 = skb_network_header(skb);
  st->ip_off = (unsigned int )((long )tmp___0) - (unsigned int )((long )skb->data);
  tmp___1 = skb_transport_header(skb);
  st->tcp_off = (unsigned int )((long )tmp___1) - (unsigned int )((long )skb->data);
  tmp___2 = tcp_hdr(skb);
  header_len = st->tcp_off + (unsigned int )((int )tmp___2->doff << 2);
  tmp___3 = skb_headlen(skb);
  in_len = tmp___3 - header_len;
  st->header_len = header_len;
  st->in_len = in_len;
  if ((unsigned int )st->protocol == 8U) {
    st->ip_base_len = st->header_len - st->ip_off;
    tmp___4 = ip_hdr(skb);
    tmp___5 = __fswab16((int )tmp___4->id);
    st->ipv4_id = tmp___5;
  } else {
    st->ip_base_len = st->header_len - st->tcp_off;
    st->ipv4_id = 0U;
  }
  tmp___6 = tcp_hdr(skb);
  tmp___7 = __fswab32(tmp___6->seq);
  st->seqnum = tmp___7;
  st->out_len = (unsigned int )skb->len - header_len;
  if (! use_opt_desc) {
    st->header_unmap_len = 0U;
    tmp___8 = ldv__builtin_expect(in_len == 0U, 1L);
    if (tmp___8 != 0L) {
      st->dma_flags = 0U;
      st->unmap_len = 0U;
      return (0);
    } else {

    }
    dma_addr = dma_map_single_attrs(dma_dev, (void *)skb->data + (unsigned long )header_len,
                                    (size_t )in_len, 1, (struct dma_attrs *)0);
    st->dma_flags = 8U;
    st->dma_addr = dma_addr;
    st->unmap_addr = dma_addr;
    st->unmap_len = in_len;
  } else {
    tmp___9 = skb_headlen(skb);
    dma_addr = dma_map_single_attrs(dma_dev, (void *)skb->data, (size_t )tmp___9,
                                    1, (struct dma_attrs *)0);
    st->header_dma_addr = dma_addr;
    st->header_unmap_len = skb_headlen(skb);
    st->dma_flags = 0U;
    st->dma_addr = (dma_addr_t )header_len + dma_addr;
    st->unmap_len = 0U;
  }
  tmp___10 = dma_mapping_error(dma_dev, dma_addr);
  tmp___11 = ldv__builtin_expect(tmp___10 != 0, 0L);
  return (tmp___11 != 0L ? -12 : 0);
}
}
static int tso_get_fragment(struct tso_state *st , struct efx_nic *efx , skb_frag_t *frag ) 
{ 
  unsigned int tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp = skb_frag_size((skb_frag_t const   *)frag);
  st->unmap_addr = skb_frag_dma_map(& (efx->pci_dev)->dev, (skb_frag_t const   *)frag,
                                    0UL, (size_t )tmp, 1);
  tmp___0 = dma_mapping_error(& (efx->pci_dev)->dev, st->unmap_addr);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 1L);
  if (tmp___1 != 0L) {
    st->dma_flags = 0U;
    st->unmap_len = skb_frag_size((skb_frag_t const   *)frag);
    st->in_len = skb_frag_size((skb_frag_t const   *)frag);
    st->dma_addr = st->unmap_addr;
    return (0);
  } else {

  }
  return (-12);
}
}
static void tso_fill_packet_with_fragment(struct efx_tx_queue *tx_queue , struct sk_buff  const  *skb ,
                                          struct tso_state *st ) 
{ 
  struct efx_tx_buffer *buffer ;
  int n ;
  unsigned int _min1 ;
  unsigned int _min2 ;

  {
  if (st->in_len == 0U) {
    return;
  } else {

  }
  if (st->packet_space == 0U) {
    return;
  } else {

  }
  _min1 = st->in_len;
  _min2 = st->packet_space;
  n = (int )(_min1 < _min2 ? _min1 : _min2);
  st->packet_space = st->packet_space - (unsigned int )n;
  st->out_len = st->out_len - (unsigned int )n;
  st->in_len = st->in_len - (unsigned int )n;
  efx_tx_queue_insert(tx_queue, st->dma_addr, (unsigned int )n, & buffer);
  if (st->out_len == 0U) {
    buffer->__annonCompField115.skb = skb;
    buffer->flags = 2U;
  } else
  if (st->packet_space != 0U) {
    buffer->flags = 1U;
  } else {

  }
  if (st->in_len == 0U) {
    buffer->unmap_len = (unsigned short )st->unmap_len;
    buffer->dma_offset = (int )buffer->unmap_len - (int )buffer->len;
    buffer->flags = (int )buffer->flags | (int )st->dma_flags;
    st->unmap_len = 0U;
  } else {

  }
  st->dma_addr = st->dma_addr + (dma_addr_t )n;
  return;
}
}
static int tso_start_new_packet(struct efx_tx_queue *tx_queue , struct sk_buff  const  *skb ,
                                struct tso_state *st ) 
{ 
  struct efx_tx_buffer *buffer ;
  struct efx_tx_buffer *tmp ;
  bool is_last ;
  unsigned char *tmp___0 ;
  u8 tcp_flags_clear ;
  unsigned char *tmp___1 ;
  struct tcphdr *tsoh_th ;
  unsigned int ip_length ;
    klee_make_symbolic(&ip_length, sizeof(int), "ip_length");
  u8 *header ;
  int rc ;
  __u32 tmp___2 ;
  struct iphdr *tsoh_iph ;
  __u16 tmp___3 ;
  __u16 tmp___4 ;
  struct ipv6hdr *tsoh_iph___0 ;
  __u16 tmp___5 ;
  long tmp___6 ;
  u8 tcp_flags ;
  struct tcphdr *tmp___7 ;
  unsigned char *tmp___8 ;

  {
  tmp = efx_tx_queue_get_insert_buffer((struct efx_tx_queue  const  *)tx_queue);
  buffer = tmp;
  tmp___0 = skb_end_pointer(skb);
  is_last = st->out_len <= (unsigned int )((struct skb_shared_info *)tmp___0)->gso_size;
  if (! is_last) {
    tmp___1 = skb_end_pointer(skb);
    st->packet_space = (unsigned int )((struct skb_shared_info *)tmp___1)->gso_size;
    tcp_flags_clear = 9U;
  } else {
    st->packet_space = st->out_len;
    tcp_flags_clear = 0U;
  }
  if (st->header_unmap_len == 0U) {
    header = efx_tsoh_get_buffer(tx_queue, buffer, st->header_len);
    if ((unsigned long )header == (unsigned long )((u8 *)0U)) {
      return (-12);
    } else {

    }
    tsoh_th = (struct tcphdr *)header + (unsigned long )st->tcp_off;
    memcpy((void *)header, (void const   *)skb->data, (size_t )st->header_len);
    tmp___2 = __fswab32(st->seqnum);
    tsoh_th->seq = tmp___2;
    *((u8 *)tsoh_th + 13UL) = (u8 )((int )((signed char )*((u8 *)tsoh_th + 13UL)) & ~ ((int )((signed char )tcp_flags_clear)));
    ip_length = st->ip_base_len + st->packet_space;
    if ((unsigned int )st->protocol == 8U) {
      tsoh_iph = (struct iphdr *)header + (unsigned long )st->ip_off;
      tmp___3 = __fswab16((int )((__u16 )ip_length));
      tsoh_iph->tot_len = tmp___3;
      tmp___4 = __fswab16((int )st->ipv4_id);
      tsoh_iph->id = tmp___4;
    } else {
      tsoh_iph___0 = (struct ipv6hdr *)header + (unsigned long )st->ip_off;
      tmp___5 = __fswab16((int )((__u16 )ip_length));
      tsoh_iph___0->payload_len = tmp___5;
    }
    rc = efx_tso_put_header(tx_queue, buffer, header);
    tmp___6 = ldv__builtin_expect(rc != 0, 0L);
    if (tmp___6 != 0L) {
      return (rc);
    } else {

    }
  } else {
    tmp___7 = tcp_hdr(skb);
    tcp_flags = (u8 )((int )((signed char )*((u8 *)tmp___7 + 13UL)) & ~ ((int )((signed char )tcp_flags_clear)));
    buffer->flags = 16U;
    buffer->len = 0U;
    buffer->unmap_len = 0U;
    buffer->__annonCompField116.option.u64[0] = ((((unsigned long long )tcp_flags << 48) | ((unsigned long long )st->ipv4_id << 32)) | (unsigned long long )st->seqnum) | 0xf000000000000000ULL;
    tx_queue->insert_count = tx_queue->insert_count + 1U;
    buffer = efx_tx_queue_get_insert_buffer((struct efx_tx_queue  const  *)tx_queue);
    buffer->__annonCompField116.dma_addr = st->header_dma_addr;
    buffer->len = (unsigned short )st->header_len;
    if ((int )is_last) {
      buffer->flags = 9U;
      buffer->unmap_len = (unsigned short )st->header_unmap_len;
      buffer->dma_offset = 0U;
      st->header_unmap_len = 0U;
    } else {
      buffer->flags = 1U;
      buffer->unmap_len = 0U;
    }
    tx_queue->insert_count = tx_queue->insert_count + 1U;
  }
  tmp___8 = skb_end_pointer(skb);
  st->seqnum = st->seqnum + (unsigned int )((struct skb_shared_info *)tmp___8)->gso_size;
  st->ipv4_id = (u16 )((int )st->ipv4_id + 1);
  tx_queue->tso_packets = tx_queue->tso_packets + 1U;
  tx_queue->tx_packets = tx_queue->tx_packets + 1UL;
  return (0);
}
}
static int efx_enqueue_skb_tso(struct efx_tx_queue *tx_queue , struct sk_buff *skb ) 
{ 
  struct efx_nic *efx ;
  unsigned int old_insert_count ;
  int frag_i ;
    klee_make_symbolic(&frag_i, sizeof(int), "frag_i");
  int rc ;
  struct tso_state state ;
  unsigned char *tmp ;
  long tmp___0 ;
  int tmp___1 ;
  unsigned char *tmp___2 ;
  unsigned char *tmp___3 ;
  int tmp___4 ;
  bool tmp___5 ;

  {
  efx = tx_queue->efx;
  old_insert_count = tx_queue->insert_count;
  state.protocol = efx_tso_check_protocol(skb);
  rc = tso_start(& state, efx, (struct sk_buff  const  *)skb);
  if (rc != 0) {
    goto mem_err;
  } else {

  }
  tmp___0 = ldv__builtin_expect(state.in_len == 0U, 1L);
  if (tmp___0 != 0L) {
    frag_i = 0;
    tmp = skb_end_pointer((struct sk_buff  const  *)skb);
    rc = tso_get_fragment(& state, efx, (skb_frag_t *)(& ((struct skb_shared_info *)tmp)->frags) + (unsigned long )frag_i);
    if (rc != 0) {
      goto mem_err;
    } else {

    }
  } else {
    frag_i = -1;
  }
  tmp___1 = tso_start_new_packet(tx_queue, (struct sk_buff  const  *)skb, & state);
  if (tmp___1 < 0) {
    goto mem_err;
  } else {

  }
  ldv_55769: 
  tso_fill_packet_with_fragment(tx_queue, (struct sk_buff  const  *)skb, & state);
  if (state.in_len == 0U) {
    frag_i = frag_i + 1;
    tmp___2 = skb_end_pointer((struct sk_buff  const  *)skb);
    if (frag_i >= (int )((struct skb_shared_info *)tmp___2)->nr_frags) {
      goto ldv_55768;
    } else {

    }
    tmp___3 = skb_end_pointer((struct sk_buff  const  *)skb);
    rc = tso_get_fragment(& state, efx, (skb_frag_t *)(& ((struct skb_shared_info *)tmp___3)->frags) + (unsigned long )frag_i);
    if (rc != 0) {
      goto mem_err;
    } else {

    }
  } else {

  }
  if (state.packet_space == 0U) {
    tmp___4 = tso_start_new_packet(tx_queue, (struct sk_buff  const  *)skb, & state);
    if (tmp___4 < 0) {
      goto mem_err;
    } else {

    }
  } else {

  }
  goto ldv_55769;
  ldv_55768: 
  netdev_tx_sent_queue(tx_queue->core_txq, skb->len);
  efx_tx_maybe_stop_queue(tx_queue);
  if ((unsigned int )*((unsigned char *)skb + 142UL) == 0U) {
    efx_nic_push_buffers(tx_queue);
  } else {
    tmp___5 = netif_xmit_stopped((struct netdev_queue  const  *)tx_queue->core_txq);
    if ((int )tmp___5) {
      efx_nic_push_buffers(tx_queue);
    } else {

    }
  }
  tx_queue->tso_bursts = tx_queue->tso_bursts + 1U;
  return (0);
  mem_err: ;
  if ((efx->msg_enable & 128U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "Out of memory for TSO headers, or DMA mapping error\n");
  } else {

  }
  dev_kfree_skb_any(skb);
  if (state.unmap_len != 0U) {
    if (((int )state.dma_flags & 8) != 0) {
      dma_unmap_single_attrs(& (efx->pci_dev)->dev, state.unmap_addr, (size_t )state.unmap_len,
                             1, (struct dma_attrs *)0);
    } else {
      dma_unmap_page(& (efx->pci_dev)->dev, state.unmap_addr, (size_t )state.unmap_len,
                     1);
    }
  } else {

  }
  if (state.header_unmap_len != 0U) {
    dma_unmap_single_attrs(& (efx->pci_dev)->dev, state.header_dma_addr, (size_t )state.header_unmap_len,
                           1, (struct dma_attrs *)0);
  } else {

  }
  efx_enqueue_unwind(tx_queue, old_insert_count);
  return (0);
}
}
bool ldv_queue_work_on_287(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_288(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_289(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_290(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_291(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_292(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_293(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_294(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_295(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_296(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_297(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_298(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void __builtin_prefetch(void const   *  , ...) ;
__inline static long ldv__builtin_expect(long exp , long c ) ;
int ldv_mutex_trylock_323(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_321(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_324(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_325(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_320(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_322(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_326(struct mutex *ldv_func_arg1 ) ;
extern int _raw_spin_trylock_bh(raw_spinlock_t * ) ;
__inline static int spin_trylock_bh(spinlock_t *lock ) 
{ 
  int tmp ;

  {
  tmp = _raw_spin_trylock_bh(& lock->__annonCompField17.rlock);
  return (tmp);
}
}
int ldv_del_timer_sync_327(struct timer_list *ldv_func_arg1 ) ;
bool ldv_queue_work_on_315(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_317(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_316(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_319(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_318(struct workqueue_struct *ldv_func_arg1 ) ;
extern void dump_page(struct page * , char const   * ) ;
extern struct page *alloc_pages_current(gfp_t  , unsigned int  ) ;
__inline static struct page *alloc_pages(gfp_t gfp_mask , unsigned int order ) 
{ 
  struct page *tmp ;

  {
  tmp = alloc_pages_current(gfp_mask, order);
  return (tmp);
}
}
extern void __free_pages(struct page * , unsigned int  ) ;
extern int net_ratelimit(void) ;
__inline static int PageTail(struct page  const  *page ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(15L, (unsigned long const volatile   *)(& page->flags));
  return (tmp);
}
}
__inline static struct page *compound_head_by_tail(struct page *tail ) 
{ 
  struct page *head ;
  int tmp ;
  long tmp___0 ;

  {
  head = tail->__annonCompField46.first_page;
  __asm__  volatile   ("": : : "memory");
  tmp = PageTail((struct page  const  *)tail);
  tmp___0 = ldv__builtin_expect(tmp != 0, 1L);
  if (tmp___0 != 0L) {
    return (head);
  } else {

  }
  return (tail);
}
}
__inline static struct page *compound_head(struct page *page ) 
{ 
  struct page *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp___0 = PageTail((struct page  const  *)page);
  tmp___1 = ldv__builtin_expect(tmp___0 != 0, 0L);
  if (tmp___1 != 0L) {
    tmp = compound_head_by_tail(page);
    return (tmp);
  } else {

  }
  return (page);
}
}
__inline static int page_count(struct page *page ) 
{ 
  struct page *tmp ;
  int tmp___0 ;

  {
  tmp = compound_head(page);
  tmp___0 = atomic_read((atomic_t const   *)(& tmp->__annonCompField42.__annonCompField41.__annonCompField40._count));
  return (tmp___0);
}
}
extern bool __get_page_tail(struct page * ) ;
__inline static void get_page(struct page *page ) 
{ 
  bool tmp ;
  long tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;
  int tmp___3 ;
  long tmp___4 ;

  {
  tmp___1 = PageTail((struct page  const  *)page);
  tmp___2 = ldv__builtin_expect(tmp___1 != 0, 0L);
  if (tmp___2 != 0L) {
    tmp = __get_page_tail(page);
    tmp___0 = ldv__builtin_expect((long )tmp, 1L);
    if (tmp___0 != 0L) {
      return;
    } else {

    }
  } else {

  }
  tmp___3 = atomic_read((atomic_t const   *)(& page->__annonCompField42.__annonCompField41.__annonCompField40._count));
  tmp___4 = ldv__builtin_expect(tmp___3 <= 0, 0L);
  if (tmp___4 != 0L) {
    dump_page(page, "VM_BUG_ON_PAGE(atomic_read(&page->_count) <= 0)");
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/mm.h"),
                         "i" (543), "i" (12UL));
    ldv_23606: ;
    goto ldv_23606;
  } else {

  }
  atomic_inc(& page->__annonCompField42.__annonCompField41.__annonCompField40._count);
  return;
}
}
extern void put_page(struct page * ) ;
extern void debug_dma_sync_single_for_cpu(struct device * , dma_addr_t  , size_t  ,
                                          int  ) ;
__inline static dma_addr_t dma_map_page___0(struct device *dev , struct page *page ,
                                            size_t offset , size_t size , enum dma_data_direction dir ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  dma_addr_t addr ;
  void *tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = lowmem_page_address((struct page  const  *)page);
  kmemcheck_mark_initialized(tmp___0 + offset, (unsigned int )size);
  tmp___1 = valid_dma_direction((int )dir);
  tmp___2 = ldv__builtin_expect(tmp___1 == 0, 0L);
  if (tmp___2 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (84), "i" (12UL));
    ldv_25702: ;
    goto ldv_25702;
  } else {

  }
  addr = (*(ops->map_page))(dev, page, offset, size, dir, (struct dma_attrs *)0);
  debug_dma_map_page(dev, page, offset, size, (int )dir, addr, 0);
  return (addr);
}
}
__inline static void dma_unmap_page___0(struct device *dev , dma_addr_t addr , size_t size ,
                                        enum dma_data_direction dir ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (96), "i" (12UL));
    ldv_25710: ;
    goto ldv_25710;
  } else {

  }
  if ((unsigned long )ops->unmap_page != (unsigned long )((void (*)(struct device * ,
                                                                    dma_addr_t  ,
                                                                    size_t  , enum dma_data_direction  ,
                                                                    struct dma_attrs * ))0)) {
    (*(ops->unmap_page))(dev, addr, size, dir, (struct dma_attrs *)0);
  } else {

  }
  debug_dma_unmap_page(dev, addr, size, (int )dir, 0);
  return;
}
}
__inline static void dma_sync_single_for_cpu(struct device *dev , dma_addr_t addr ,
                                             size_t size , enum dma_data_direction dir ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (108), "i" (12UL));
    ldv_25718: ;
    goto ldv_25718;
  } else {

  }
  if ((unsigned long )ops->sync_single_for_cpu != (unsigned long )((void (*)(struct device * ,
                                                                             dma_addr_t  ,
                                                                             size_t  ,
                                                                             enum dma_data_direction  ))0)) {
    (*(ops->sync_single_for_cpu))(dev, addr, size, dir);
  } else {

  }
  debug_dma_sync_single_for_cpu(dev, addr, size, (int )dir);
  return;
}
}
__inline static void skb_frag_size_set(skb_frag_t *frag , unsigned int size ) 
{ 


  {
  frag->size = size;
  return;
}
}
__inline static void skb_set_hash(struct sk_buff *skb , __u32 hash , enum pkt_hash_types type ) 
{ 


  {
  skb->l4_hash = (unsigned int )type == 3U;
  skb->sw_hash = 0U;
  skb->hash = hash;
  return;
}
}
__inline static bool skb_is_nonlinear(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned int )skb->data_len != 0U);
}
}
__inline static void __skb_fill_page_desc(struct sk_buff *skb , int i , struct page *page ,
                                          int off , int size ) 
{ 
  skb_frag_t *frag ;
  unsigned char *tmp ;

  {
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  frag = (skb_frag_t *)(& ((struct skb_shared_info *)tmp)->frags) + (unsigned long )i;
  frag->page.p = page;
  frag->page_offset = (__u32 )off;
  skb_frag_size_set(frag, (unsigned int )size);
  page = compound_head(page);
  if ((int )page->__annonCompField42.__annonCompField37.pfmemalloc && (unsigned long )page->__annonCompField36.mapping == (unsigned long )((struct address_space *)0)) {
    skb->pfmemalloc = 1U;
  } else {

  }
  return;
}
}
__inline static void skb_fill_page_desc(struct sk_buff *skb , int i , struct page *page ,
                                        int off , int size ) 
{ 
  unsigned char *tmp ;

  {
  __skb_fill_page_desc(skb, i, page, off, size);
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  ((struct skb_shared_info *)tmp)->nr_frags = (unsigned int )((unsigned char )i) + 1U;
  return;
}
}
__inline static unsigned char *skb_tail_pointer(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->tail);
}
}
__inline static unsigned char *__skb_put(struct sk_buff *skb , unsigned int len ) 
{ 
  unsigned char *tmp ;
  unsigned char *tmp___0 ;
  bool tmp___1 ;
  long tmp___2 ;

  {
  tmp___0 = skb_tail_pointer((struct sk_buff  const  *)skb);
  tmp = tmp___0;
  tmp___1 = skb_is_nonlinear((struct sk_buff  const  *)skb);
  tmp___2 = ldv__builtin_expect((long )tmp___1, 0L);
  if (tmp___2 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/skbuff.h"),
                         "i" (1696), "i" (12UL));
    ldv_27006: ;
    goto ldv_27006;
  } else {

  }
  skb->tail = skb->tail + len;
  skb->len = skb->len + len;
  return (tmp);
}
}
__inline static void skb_reserve(struct sk_buff *skb , int len ) 
{ 


  {
  skb->data = skb->data + (unsigned long )len;
  skb->tail = skb->tail + (sk_buff_data_t )len;
  return;
}
}
extern struct sk_buff *__netdev_alloc_skb(struct net_device * , unsigned int  , gfp_t  ) ;
__inline static struct sk_buff *netdev_alloc_skb(struct net_device *dev , unsigned int length ) 
{ 
  struct sk_buff *tmp ;

  {
  tmp = __netdev_alloc_skb(dev, length, 32U);
  return (tmp);
}
}
__inline static void skb_record_rx_queue(struct sk_buff *skb , u16 rx_queue ) 
{ 


  {
  skb->queue_mapping = (unsigned int )rx_queue + 1U;
  return;
}
}
__inline static u16 skb_get_rx_queue(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned int )((u16 )skb->queue_mapping) + 65535U);
}
}
__inline static void skb_checksum_none_assert(struct sk_buff  const  *skb ) 
{ 


  {
  return;
}
}
extern int netif_receive_skb_sk(struct sock * , struct sk_buff * ) ;
__inline static int netif_receive_skb(struct sk_buff *skb ) 
{ 
  int tmp ;

  {
  tmp = netif_receive_skb_sk(skb->sk, skb);
  return (tmp);
}
}
extern struct sk_buff *napi_get_frags(struct napi_struct * ) ;
extern gro_result_t napi_gro_frags(struct napi_struct * ) ;
extern struct bus_type pci_bus_type ;
extern bool iommu_present(struct bus_type * ) ;
__inline static bool ip_is_fragment(struct iphdr  const  *iph ) 
{ 


  {
  return (((int )iph->frag_off & 65343) != 0);
}
}
extern __be16 eth_type_trans(struct sk_buff * , struct net_device * ) ;
__inline static void skb_mark_napi_id(struct sk_buff *skb , struct napi_struct *napi ) 
{ 


  {
  skb->__annonCompField83.napi_id = napi->napi_id;
  return;
}
}
__inline static bool efx_channel_busy_polling(struct efx_channel *channel ) 
{ 
  int __ret_warn_on ;
  long tmp ;

  {
  __ret_warn_on = (channel->state & 3U) == 0U;
  tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/net/ethernet/sfc/net_driver.h",
                       545);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  return ((channel->state & 18U) != 0U);
}
}
void __efx_rx_skb_attach_timestamp(struct efx_channel *channel , struct sk_buff *skb ) ;
__inline static void efx_rx_skb_attach_timestamp(struct efx_channel *channel , struct sk_buff *skb ) 
{ 


  {
  if ((unsigned int )channel->sync_events_state == 3U) {
    __efx_rx_skb_attach_timestamp(channel, skb);
  } else {

  }
  return;
}
}
__inline static int efx_nic_probe_rx(struct efx_rx_queue *rx_queue ) 
{ 
  int tmp ;

  {
  tmp = (*(((rx_queue->efx)->type)->rx_probe))(rx_queue);
  return (tmp);
}
}
__inline static void efx_nic_init_rx(struct efx_rx_queue *rx_queue ) 
{ 


  {
  (*(((rx_queue->efx)->type)->rx_init))(rx_queue);
  return;
}
}
__inline static void efx_nic_remove_rx(struct efx_rx_queue *rx_queue ) 
{ 


  {
  (*(((rx_queue->efx)->type)->rx_remove))(rx_queue);
  return;
}
}
__inline static void efx_nic_notify_rx_desc(struct efx_rx_queue *rx_queue ) 
{ 


  {
  (*(((rx_queue->efx)->type)->rx_write))(rx_queue);
  return;
}
}
__inline static void efx_nic_generate_fill_event(struct efx_rx_queue *rx_queue ) 
{ 


  {
  (*(((rx_queue->efx)->type)->rx_defer_refill))(rx_queue);
  return;
}
}
void efx_loopback_rx_packet(struct efx_nic *efx , char const   *buf_ptr , int pkt_len ) ;
static unsigned int rx_refill_threshold  ;
    klee_make_symbolic(&rx_refill_threshold, sizeof(int), "rx_refill_threshold");
__inline static u8 *efx_rx_buf_va(struct efx_rx_buffer *buf ) 
{ 
  void *tmp ;

  {
  tmp = lowmem_page_address((struct page  const  *)buf->page);
  return ((u8 *)tmp + (unsigned long )buf->page_offset);
}
}
__inline static u32 efx_rx_buf_hash(struct efx_nic *efx , u8 const   *eh ) 
{ 
  __u32 tmp ;

  {
  tmp = __le32_to_cpup((__le32 const   *)eh + (unsigned long )efx->rx_packet_hash_offset);
  return (tmp);
}
}
__inline static struct efx_rx_buffer *efx_rx_buf_next(struct efx_rx_queue *rx_queue ,
                                                      struct efx_rx_buffer *rx_buf ) 
{ 
  struct efx_rx_buffer *tmp ;
  struct efx_rx_buffer *tmp___0 ;
  long tmp___1 ;

  {
  tmp___0 = efx_rx_buffer(rx_queue, rx_queue->ptr_mask);
  tmp___1 = ldv__builtin_expect((unsigned long )tmp___0 == (unsigned long )rx_buf, 0L);
  if (tmp___1 != 0L) {
    tmp = efx_rx_buffer(rx_queue, 0U);
    return (tmp);
  } else {
    return (rx_buf + 1UL);
  }
}
}
__inline static void efx_sync_rx_buffer(struct efx_nic *efx , struct efx_rx_buffer *rx_buf ,
                                        unsigned int len ) 
{ 


  {
  dma_sync_single_for_cpu(& (efx->pci_dev)->dev, rx_buf->dma_addr, (size_t )len, 2);
  return;
}
}
void efx_rx_config_page_split(struct efx_nic *efx ) 
{ 


  {
  efx->rx_page_buf_step = ((efx->rx_dma_len + efx->rx_ip_align) + 63U) & 4294967232U;
  efx->rx_bufs_per_page = efx->rx_buffer_order == 0U ? 4032U / efx->rx_page_buf_step : 1U;
  efx->rx_buffer_truesize = (unsigned int )((4096UL << (int )efx->rx_buffer_order) / (unsigned long )efx->rx_bufs_per_page);
  efx->rx_pages_per_batch = (efx->rx_bufs_per_page + 7U) / efx->rx_bufs_per_page;
  return;
}
}
static struct page *efx_reuse_page(struct efx_rx_queue *rx_queue ) 
{ 
  struct efx_nic *efx ;
  struct page *page ;
  struct efx_rx_page_state *state ;
  unsigned int index ;
  void *tmp ;
  int tmp___0 ;

  {
  efx = rx_queue->efx;
  index = rx_queue->page_remove & rx_queue->page_ptr_mask;
  page = *(rx_queue->page_ring + (unsigned long )index);
  if ((unsigned long )page == (unsigned long )((struct page *)0)) {
    return ((struct page *)0);
  } else {

  }
  *(rx_queue->page_ring + (unsigned long )index) = (struct page *)0;
  if (rx_queue->page_remove != rx_queue->page_add) {
    rx_queue->page_remove = rx_queue->page_remove + 1U;
  } else {

  }
  tmp___0 = page_count(page);
  if (tmp___0 == 1) {
    rx_queue->page_recycle_count = rx_queue->page_recycle_count + 1U;
    return (page);
  } else {
    tmp = lowmem_page_address((struct page  const  *)page);
    state = (struct efx_rx_page_state *)tmp;
    dma_unmap_page___0(& (efx->pci_dev)->dev, state->dma_addr, 4096UL << (int )efx->rx_buffer_order,
                       2);
    put_page(page);
    rx_queue->page_recycle_failed = rx_queue->page_recycle_failed + 1U;
  }
  return ((struct page *)0);
}
}
static int efx_init_rx_buffers(struct efx_rx_queue *rx_queue , bool atomic ) 
{ 
  struct efx_nic *efx ;
  struct efx_rx_buffer *rx_buf ;
  struct page *page ;
  unsigned int page_offset ;
    klee_make_symbolic(&page_offset, sizeof(int), "page_offset");
  struct efx_rx_page_state *state ;
  dma_addr_t dma_addr ;
  unsigned int index ;
  unsigned int count ;
  long tmp ;
  int tmp___0 ;
  long tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;

  {
  efx = rx_queue->efx;
  count = 0U;
  ldv_56252: 
  page = efx_reuse_page(rx_queue);
  if ((unsigned long )page == (unsigned long )((struct page *)0)) {
    page = alloc_pages((int )atomic ? 16672U : 16848U, efx->rx_buffer_order);
    tmp = ldv__builtin_expect((unsigned long )page == (unsigned long )((struct page *)0),
                           0L);
    if (tmp != 0L) {
      return (-12);
    } else {

    }
    dma_addr = dma_map_page___0(& (efx->pci_dev)->dev, page, 0UL, 4096UL << (int )efx->rx_buffer_order,
                                2);
    tmp___0 = dma_mapping_error(& (efx->pci_dev)->dev, dma_addr);
    tmp___1 = ldv__builtin_expect(tmp___0 != 0, 0L);
    if (tmp___1 != 0L) {
      __free_pages(page, efx->rx_buffer_order);
      return (-5);
    } else {

    }
    tmp___2 = lowmem_page_address((struct page  const  *)page);
    state = (struct efx_rx_page_state *)tmp___2;
    state->dma_addr = dma_addr;
  } else {
    tmp___3 = lowmem_page_address((struct page  const  *)page);
    state = (struct efx_rx_page_state *)tmp___3;
    dma_addr = state->dma_addr;
  }
  dma_addr = dma_addr + 64ULL;
  page_offset = 64U;
  ldv_56250: 
  index = rx_queue->added_count & rx_queue->ptr_mask;
  rx_buf = efx_rx_buffer(rx_queue, index);
  rx_buf->dma_addr = (dma_addr_t )efx->rx_ip_align + dma_addr;
  rx_buf->page = page;
  rx_buf->page_offset = (int )((u16 )efx->rx_ip_align) + (int )((u16 )page_offset);
  rx_buf->len = (u16 )efx->rx_dma_len;
  rx_buf->flags = 0U;
  rx_queue->added_count = rx_queue->added_count + 1U;
  get_page(page);
  dma_addr = (dma_addr_t )efx->rx_page_buf_step + dma_addr;
  page_offset = efx->rx_page_buf_step + page_offset;
  if (efx->rx_page_buf_step + page_offset <= 4096U) {
    goto ldv_56250;
  } else {

  }
  rx_buf->flags = 1U;
  count = count + 1U;
  if (count < efx->rx_pages_per_batch) {
    goto ldv_56252;
  } else {

  }

  return (0);
}
}
static void efx_unmap_rx_buffer(struct efx_nic *efx , struct efx_rx_buffer *rx_buf ) 
{ 
  struct page *page ;
  struct efx_rx_page_state *state ;
  void *tmp ;

  {
  page = rx_buf->page;
  if ((unsigned long )page != (unsigned long )((struct page *)0)) {
    tmp = lowmem_page_address((struct page  const  *)page);
    state = (struct efx_rx_page_state *)tmp;
    dma_unmap_page___0(& (efx->pci_dev)->dev, state->dma_addr, 4096UL << (int )efx->rx_buffer_order,
                       2);
  } else {

  }
  return;
}
}
static void efx_free_rx_buffers(struct efx_rx_queue *rx_queue , struct efx_rx_buffer *rx_buf ,
                                unsigned int num_bufs ) 
{ 


  {
  ldv_56265: ;
  if ((unsigned long )rx_buf->page != (unsigned long )((struct page *)0)) {
    put_page(rx_buf->page);
    rx_buf->page = (struct page *)0;
  } else {

  }
  rx_buf = efx_rx_buf_next(rx_queue, rx_buf);
  num_bufs = num_bufs - 1U;
  if (num_bufs != 0U) {
    goto ldv_56265;
  } else {

  }

  return;
}
}
static void efx_recycle_rx_page(struct efx_channel *channel , struct efx_rx_buffer *rx_buf ) 
{ 
  struct page *page ;
  struct efx_rx_queue *rx_queue ;
  struct efx_rx_queue *tmp ;
  struct efx_nic *efx ;
  unsigned int index ;
  unsigned int read_index ;
    klee_make_symbolic(&read_index, sizeof(int), "read_index");

  {
  page = rx_buf->page;
  tmp = efx_channel_get_rx_queue(channel);
  rx_queue = tmp;
  efx = rx_queue->efx;
  if (((int )rx_buf->flags & 1) == 0) {
    return;
  } else {

  }
  index = rx_queue->page_add & rx_queue->page_ptr_mask;
  if ((unsigned long )*(rx_queue->page_ring + (unsigned long )index) == (unsigned long )((struct page *)0)) {
    read_index = rx_queue->page_remove & rx_queue->page_ptr_mask;
    if (read_index == index) {
      rx_queue->page_remove = rx_queue->page_remove + 1U;
    } else {

    }
    *(rx_queue->page_ring + (unsigned long )index) = page;
    rx_queue->page_add = rx_queue->page_add + 1U;
    return;
  } else {

  }
  rx_queue->page_recycle_full = rx_queue->page_recycle_full + 1U;
  efx_unmap_rx_buffer(efx, rx_buf);
  put_page(rx_buf->page);
  return;
}
}
static void efx_fini_rx_buffer(struct efx_rx_queue *rx_queue , struct efx_rx_buffer *rx_buf ) 
{ 


  {
  if ((unsigned long )rx_buf->page != (unsigned long )((struct page *)0)) {
    put_page(rx_buf->page);
  } else {

  }
  if ((int )rx_buf->flags & 1) {
    efx_unmap_rx_buffer(rx_queue->efx, rx_buf);
    efx_free_rx_buffers(rx_queue, rx_buf, 1U);
  } else {

  }
  rx_buf->page = (struct page *)0;
  return;
}
}
static void efx_recycle_rx_pages(struct efx_channel *channel , struct efx_rx_buffer *rx_buf ,
                                 unsigned int n_frags ) 
{ 
  struct efx_rx_queue *rx_queue ;
  struct efx_rx_queue *tmp ;

  {
  tmp = efx_channel_get_rx_queue(channel);
  rx_queue = tmp;
  ldv_56286: 
  efx_recycle_rx_page(channel, rx_buf);
  rx_buf = efx_rx_buf_next(rx_queue, rx_buf);
  n_frags = n_frags - 1U;
  if (n_frags != 0U) {
    goto ldv_56286;
  } else {

  }

  return;
}
}
static void efx_discard_rx_packet(struct efx_channel *channel , struct efx_rx_buffer *rx_buf ,
                                  unsigned int n_frags ) 
{ 
  struct efx_rx_queue *rx_queue ;
  struct efx_rx_queue *tmp ;

  {
  tmp = efx_channel_get_rx_queue(channel);
  rx_queue = tmp;
  efx_recycle_rx_pages(channel, rx_buf, n_frags);
  efx_free_rx_buffers(rx_queue, rx_buf, n_frags);
  return;
}
}
void efx_fast_push_rx_descriptors(struct efx_rx_queue *rx_queue , bool atomic ) 
{ 
  struct efx_nic *efx ;
  unsigned int fill_level ;
  unsigned int batch_size ;
    klee_make_symbolic(&batch_size, sizeof(int), "batch_size");
  int space ;
    klee_make_symbolic(&space, sizeof(int), "space");
  int rc ;
  long tmp ;
  long tmp___1 ;

  {
  efx = rx_queue->efx;
  rc = 0;
  if (! rx_queue->refill_enabled) {
    return;
  } else {

  }
  fill_level = rx_queue->added_count - rx_queue->removed_count;
  if (rx_queue->fast_fill_trigger <= fill_level) {
    goto out;
  } else {

  }
  tmp = ldv__builtin_expect(rx_queue->min_fill > fill_level, 0L);
  if (tmp != 0L) {
    if (fill_level != 0U) {
      rx_queue->min_fill = fill_level;
    } else {

    }
  } else {

  }
  batch_size = efx->rx_pages_per_batch * efx->rx_bufs_per_page;
  space = (int )(rx_queue->max_fill - fill_level);
  ldv_56305: 
  rc = efx_init_rx_buffers(rx_queue, (int )atomic);
  tmp___1 = ldv__builtin_expect(rc != 0, 0L);
  if (tmp___1 != 0L) {
    if (rx_queue->added_count == rx_queue->removed_count) {
      efx_schedule_slow_fill(rx_queue);
    } else {

    }
    goto out;
  } else {

  }
  space = (int )((unsigned int )space - batch_size);
  if ((unsigned int )space >= batch_size) {
    goto ldv_56305;
  } else {

  }

  out: ;
  if (rx_queue->notified_count != rx_queue->added_count) {
    efx_nic_notify_rx_desc(rx_queue);
  } else {

  }
  return;
}
}
void efx_rx_slow_fill(unsigned long context ) 
{ 
  struct efx_rx_queue *rx_queue ;

  {
  rx_queue = (struct efx_rx_queue *)context;
  efx_nic_generate_fill_event(rx_queue);
  rx_queue->slow_fill_count = rx_queue->slow_fill_count + 1U;
  return;
}
}
static void efx_rx_packet__check_len(struct efx_rx_queue *rx_queue , struct efx_rx_buffer *rx_buf ,
                                     int len ) 
{ 
  struct efx_nic *efx ;
  unsigned int max_len ;
    klee_make_symbolic(&max_len, sizeof(int), "max_len");
  long tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  struct efx_channel *tmp___5 ;

  {
  efx = rx_queue->efx;
  max_len = (unsigned int )rx_buf->len - (unsigned int )(efx->type)->rx_buffer_padding;
  tmp = ldv__builtin_expect((unsigned int )len <= max_len, 1L);
  if (tmp != 0L) {
    return;
  } else {

  }
  rx_buf->flags = (u16 )((unsigned int )rx_buf->flags | 4U);
  if ((int )rx_buf->len < len) {
    tmp___4 = efx_nic_rev(efx);
    if (tmp___4 <= 1) {
      tmp___1 = net_ratelimit();
      if (tmp___1 != 0) {
        if ((efx->msg_enable & 64U) != 0U) {
          tmp___0 = efx_rx_queue_index(rx_queue);
          netdev_err((struct net_device  const  *)efx->net_dev, " RX queue %d seriously overlength RX event (0x%x > 0x%x+0x%x). Leaking\n",
                     tmp___0, len, max_len, (efx->type)->rx_buffer_padding);
        } else {

        }
      } else {

      }
      efx_schedule_reset(efx, 11);
    } else {
      goto _L;
    }
  } else {
    _L: /* CIL Label */ 
    tmp___3 = net_ratelimit();
    if (tmp___3 != 0) {
      if ((efx->msg_enable & 64U) != 0U) {
        tmp___2 = efx_rx_queue_index(rx_queue);
        netdev_err((struct net_device  const  *)efx->net_dev, " RX queue %d overlength RX event (0x%x > 0x%x)\n",
                   tmp___2, len, max_len);
      } else {

      }
    } else {

    }
  }
  tmp___5 = efx_rx_queue_channel(rx_queue);
  tmp___5->n_rx_overlength = tmp___5->n_rx_overlength + 1U;
  return;
}
}
static void efx_rx_packet_gro(struct efx_channel *channel , struct efx_rx_buffer *rx_buf ,
                              unsigned int n_frags , u8 *eh ) 
{ 
  struct napi_struct *napi ;
  gro_result_t gro_result ;
  struct efx_nic *efx ;
  struct sk_buff *skb ;
  struct efx_rx_queue *rx_queue ;
  long tmp ;
  u32 tmp___0 ;
  unsigned char *tmp___1 ;
  unsigned char *tmp___2 ;

  {
  napi = & channel->napi_str;
  efx = channel->efx;
  skb = napi_get_frags(napi);
  tmp = ldv__builtin_expect((unsigned long )skb == (unsigned long )((struct sk_buff *)0),
                         0L);
  if (tmp != 0L) {
    rx_queue = efx_channel_get_rx_queue(channel);
    efx_free_rx_buffers(rx_queue, rx_buf, n_frags);
    return;
  } else {

  }
  if (((efx->net_dev)->features & 8589934592ULL) != 0ULL) {
    tmp___0 = efx_rx_buf_hash(efx, (u8 const   *)eh);
    skb_set_hash(skb, tmp___0, 2);
  } else {

  }
  skb->ip_summed = ((int )rx_buf->flags & 2) != 0;
  ldv_56331: 
  tmp___1 = skb_end_pointer((struct sk_buff  const  *)skb);
  skb_fill_page_desc(skb, (int )((struct skb_shared_info *)tmp___1)->nr_frags, rx_buf->page,
                     (int )rx_buf->page_offset, (int )rx_buf->len);
  rx_buf->page = (struct page *)0;
  skb->len = skb->len + (unsigned int )rx_buf->len;
  tmp___2 = skb_end_pointer((struct sk_buff  const  *)skb);
  if ((unsigned int )((struct skb_shared_info *)tmp___2)->nr_frags == n_frags) {
    goto ldv_56330;
  } else {

  }
  rx_buf = efx_rx_buf_next(& channel->rx_queue, rx_buf);
  goto ldv_56331;
  ldv_56330: 
  skb->data_len = skb->len;
  skb->truesize = skb->truesize + efx->rx_buffer_truesize * n_frags;
  skb_record_rx_queue(skb, (int )((u16 )channel->rx_queue.core_index));
  skb_mark_napi_id(skb, & channel->napi_str);
  gro_result = napi_gro_frags(napi);
  if ((unsigned int )gro_result != 4U) {
    channel->irq_mod_score = channel->irq_mod_score + 2U;
  } else {

  }
  return;
}
}
static struct sk_buff *efx_rx_mk_skb(struct efx_channel *channel , struct efx_rx_buffer *rx_buf ,
                                     unsigned int n_frags , u8 *eh , int hdr_len ) 
{ 
  struct efx_nic *efx ;
  struct sk_buff *skb ;
  long tmp ;
  unsigned char *tmp___0 ;
  unsigned char *tmp___1 ;

  {
  efx = channel->efx;
  skb = netdev_alloc_skb(efx->net_dev, (efx->rx_ip_align + efx->rx_prefix_size) + (unsigned int )hdr_len);
  tmp = ldv__builtin_expect((unsigned long )skb == (unsigned long )((struct sk_buff *)0),
                         0L);
  if (tmp != 0L) {
    atomic_inc(& efx->n_rx_noskb_drops);
    return ((struct sk_buff *)0);
  } else {

  }
  memcpy((void *)skb->data + (unsigned long )efx->rx_ip_align, (void const   *)(eh + - ((unsigned long )efx->rx_prefix_size)),
           (size_t )(efx->rx_prefix_size + (unsigned int )hdr_len));
  skb_reserve(skb, (int )(efx->rx_ip_align + efx->rx_prefix_size));
  __skb_put(skb, (unsigned int )hdr_len);
  if ((int )rx_buf->len > hdr_len) {
    rx_buf->page_offset = (int )rx_buf->page_offset + (int )((u16 )hdr_len);
    rx_buf->len = (int )rx_buf->len - (int )((u16 )hdr_len);
    ldv_56342: 
    tmp___0 = skb_end_pointer((struct sk_buff  const  *)skb);
    skb_fill_page_desc(skb, (int )((struct skb_shared_info *)tmp___0)->nr_frags, rx_buf->page,
                       (int )rx_buf->page_offset, (int )rx_buf->len);
    rx_buf->page = (struct page *)0;
    skb->len = skb->len + (unsigned int )rx_buf->len;
    skb->data_len = skb->data_len + (unsigned int )rx_buf->len;
    tmp___1 = skb_end_pointer((struct sk_buff  const  *)skb);
    if ((unsigned int )((struct skb_shared_info *)tmp___1)->nr_frags == n_frags) {
      goto ldv_56341;
    } else {

    }
    rx_buf = efx_rx_buf_next(& channel->rx_queue, rx_buf);
    goto ldv_56342;
    ldv_56341: ;
  } else {
    __free_pages(rx_buf->page, efx->rx_buffer_order);
    rx_buf->page = (struct page *)0;
    n_frags = 0U;
  }
  skb->truesize = skb->truesize + efx->rx_buffer_truesize * n_frags;
  skb->protocol = eth_type_trans(skb, efx->net_dev);
  skb_mark_napi_id(skb, & channel->napi_str);
  return (skb);
}
}
void efx_rx_packet(struct efx_rx_queue *rx_queue , unsigned int index , unsigned int n_frags ,
                   unsigned int len , u16 flags ) 
{ 
  struct efx_nic *efx ;
  struct efx_channel *channel ;
  struct efx_channel *tmp ;
  struct efx_rx_buffer *rx_buf ;
  int __ret_warn_on ;
  long tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;
  long tmp___3 ;
  long tmp___4 ;
  long tmp___6 ;
  u8 *tmp___7 ;
  unsigned int tail_frags ;
    klee_make_symbolic(&tail_frags, sizeof(int), "tail_frags");

  {
  efx = rx_queue->efx;
  tmp = efx_rx_queue_channel(rx_queue);
  channel = tmp;
  rx_queue->rx_packets = rx_queue->rx_packets + 1UL;
  rx_buf = efx_rx_buffer(rx_queue, index);
  rx_buf->flags = (u16 )((int )rx_buf->flags | (int )flags);
  if (n_frags == 1U) {
    if (((int )flags & 128) == 0) {
      efx_rx_packet__check_len(rx_queue, rx_buf, (int )len);
    } else {

    }
  } else {
    tmp___1 = ldv__builtin_expect(n_frags > 6U, 0L);
    if (tmp___1 != 0L) {
      goto _L;
    } else {
      tmp___2 = ldv__builtin_expect((n_frags - 1U) * efx->rx_dma_len >= len, 0L);
      if (tmp___2 != 0L) {
        goto _L;
      } else {
        tmp___3 = ldv__builtin_expect(efx->rx_dma_len * n_frags < len, 0L);
        if (tmp___3 != 0L) {
          goto _L;
        } else {
          tmp___4 = ldv__builtin_expect((long )(! efx->rx_scatter), 0L);
          if (tmp___4 != 0L) {
            _L: /* CIL Label */ 
            __ret_warn_on = len != 0U || ((int )rx_buf->flags & 4) == 0;
            tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
            if (tmp___0 != 0L) {
              warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/rx.c",
                                 553);
            } else {

            }
            ldv__builtin_expect(__ret_warn_on != 0, 0L);
            rx_buf->flags = (u16 )((unsigned int )rx_buf->flags | 4U);
          } else {

          }
        }
      }
    }
  }
  tmp___6 = ldv__builtin_expect(((int )rx_buf->flags & 4) != 0, 0L);
  if (tmp___6 != 0L) {
    efx_rx_flush_packet(channel);
    efx_discard_rx_packet(channel, rx_buf, n_frags);
    return;
  } else {

  }
  if (n_frags == 1U && ((int )flags & 128) == 0) {
    rx_buf->len = (u16 )len;
  } else {

  }
  efx_sync_rx_buffer(efx, rx_buf, (unsigned int )rx_buf->len);
  tmp___7 = efx_rx_buf_va(rx_buf);
  __builtin_prefetch((void const   *)tmp___7);
  rx_buf->page_offset = (int )rx_buf->page_offset + (int )((u16 )efx->rx_prefix_size);
  rx_buf->len = (int )rx_buf->len - (int )((u16 )efx->rx_prefix_size);
  if (n_frags > 1U) {
    tail_frags = n_frags - 1U;
    ldv_56358: 
    rx_buf = efx_rx_buf_next(rx_queue, rx_buf);
    tail_frags = tail_frags - 1U;
    if (tail_frags == 0U) {
      goto ldv_56357;
    } else {

    }
    efx_sync_rx_buffer(efx, rx_buf, efx->rx_dma_len);
    goto ldv_56358;
    ldv_56357: 
    rx_buf->len = (int )((u16 )len) - (int )((u16 )(n_frags - 1U)) * (int )((u16 )efx->rx_dma_len);
    efx_sync_rx_buffer(efx, rx_buf, (unsigned int )rx_buf->len);
  } else {

  }
  rx_buf = efx_rx_buffer(rx_queue, index);
  efx_recycle_rx_pages(channel, rx_buf, n_frags);
  efx_rx_flush_packet(channel);
  channel->rx_pkt_n_frags = n_frags;
  channel->rx_pkt_index = index;
  return;
}
}
static void efx_rx_deliver(struct efx_channel *channel , u8 *eh , struct efx_rx_buffer *rx_buf ,
                           unsigned int n_frags ) 
{ 
  struct sk_buff *skb ;
  u16 hdr_len ;
  u16 __min1 ;
  u16 __min2 ;
  struct efx_rx_queue *rx_queue ;
  long tmp ;
  long tmp___0 ;
  bool tmp___1 ;

  {
  __min1 = rx_buf->len;
  __min2 = 128U;
  hdr_len = (u16 )((int )__min1 < (int )__min2 ? __min1 : __min2);
  skb = efx_rx_mk_skb(channel, rx_buf, n_frags, eh, (int )hdr_len);
  tmp = ldv__builtin_expect((unsigned long )skb == (unsigned long )((struct sk_buff *)0),
                         0L);
  if (tmp != 0L) {
    rx_queue = efx_channel_get_rx_queue(channel);
    efx_free_rx_buffers(rx_queue, rx_buf, n_frags);
    return;
  } else {

  }
  skb_record_rx_queue(skb, (int )((u16 )channel->rx_queue.core_index));
  skb_checksum_none_assert((struct sk_buff  const  *)skb);
  tmp___0 = ldv__builtin_expect(((int )rx_buf->flags & 2) != 0, 1L);
  if (tmp___0 != 0L) {
    skb->ip_summed = 1U;
  } else {

  }
  efx_rx_skb_attach_timestamp(channel, skb);
  if ((unsigned long )(channel->type)->receive_skb != (unsigned long )((bool (*/* const  */)(struct efx_channel * ,
                                                                                             struct sk_buff * ))0)) {
    tmp___1 = (*((channel->type)->receive_skb))(channel, skb);
    if ((int )tmp___1) {
      return;
    } else {

    }
  } else {

  }
  netif_receive_skb(skb);
  return;
}
}
void __efx_rx_packet(struct efx_channel *channel ) 
{ 
  struct efx_nic *efx ;
  struct efx_rx_buffer *rx_buf ;
  struct efx_rx_buffer *tmp ;
  u8 *eh ;
  u8 *tmp___0 ;
  struct efx_rx_queue *rx_queue ;
  long tmp___1 ;
  long tmp___2 ;
  bool tmp___3 ;
  int tmp___4 ;

  {
  efx = channel->efx;
  tmp = efx_rx_buffer(& channel->rx_queue, channel->rx_pkt_index);
  rx_buf = tmp;
  tmp___0 = efx_rx_buf_va(rx_buf);
  eh = tmp___0;
  if (((int )rx_buf->flags & 128) != 0) {
    rx_buf->len = __le16_to_cpup((__le16 const   *)eh + (unsigned long )efx->rx_packet_len_offset);
  } else {

  }
  tmp___1 = ldv__builtin_expect((unsigned long )efx->loopback_selftest != (unsigned long )((void *)0),
                             0L);
  if (tmp___1 != 0L) {
    efx_loopback_rx_packet(efx, (char const   *)eh, (int )rx_buf->len);
    rx_queue = efx_channel_get_rx_queue(channel);
    efx_free_rx_buffers(rx_queue, rx_buf, channel->rx_pkt_n_frags);
    goto out;
  } else {

  }
  tmp___2 = ldv__builtin_expect(((efx->net_dev)->features & 17179869184ULL) == 0ULL,
                             0L);
  if (tmp___2 != 0L) {
    rx_buf->flags = (unsigned int )rx_buf->flags & 65533U;
  } else {

  }
  if (((int )rx_buf->flags & 64) != 0 && (unsigned long )(channel->type)->receive_skb == (unsigned long )((bool (*/* const  */)(struct efx_channel * ,
                                                                                                                                struct sk_buff * ))0)) {
    tmp___3 = efx_channel_busy_polling(channel);
    if (tmp___3) {
      tmp___4 = 0;
    } else {
      tmp___4 = 1;
    }
    if (tmp___4) {
      efx_rx_packet_gro(channel, rx_buf, channel->rx_pkt_n_frags, eh);
    } else {
      efx_rx_deliver(channel, eh, rx_buf, channel->rx_pkt_n_frags);
    }
  } else {
    efx_rx_deliver(channel, eh, rx_buf, channel->rx_pkt_n_frags);
  }
  out: 
  channel->rx_pkt_n_frags = 0U;
  return;
}
}
int efx_probe_rx_queue(struct efx_rx_queue *rx_queue ) 
{ 
  struct efx_nic *efx ;
  unsigned int entries ;
  int rc ;
  unsigned long _max1 ;
  unsigned long tmp ;
  unsigned long _max2 ;
  struct _ddebug descriptor ;
  int tmp___0 ;
  long tmp___1 ;
  void *tmp___2 ;

  {
  efx = rx_queue->efx;
  tmp = __roundup_pow_of_two((unsigned long )efx->rxq_entries);
  _max1 = tmp;
  _max2 = 512UL;
  entries = (unsigned int )(_max1 > _max2 ? _max1 : _max2);
  rx_queue->ptr_mask = entries - 1U;
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_probe_rx_queue";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/rx.c";
    descriptor.format = "creating RX queue %d size %#x mask %#x\n";
    descriptor.lineno = 703U;
    descriptor.flags = 0U;
    tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___1 != 0L) {
      tmp___0 = efx_rx_queue_index(rx_queue);
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "creating RX queue %d size %#x mask %#x\n", tmp___0, efx->rxq_entries,
                           rx_queue->ptr_mask);
    } else {

    }
  } else {

  }
  tmp___2 = kcalloc((size_t )entries, 24UL, 208U);
  rx_queue->buffer = (struct efx_rx_buffer *)tmp___2;
  if ((unsigned long )rx_queue->buffer == (unsigned long )((struct efx_rx_buffer *)0)) {
    return (-12);
  } else {

  }
  rc = efx_nic_probe_rx(rx_queue);
  if (rc != 0) {
    kfree((void const   *)rx_queue->buffer);
    rx_queue->buffer = (struct efx_rx_buffer *)0;
  } else {

  }
  return (rc);
}
}
static void efx_init_rx_recycle_ring(struct efx_nic *efx , struct efx_rx_queue *rx_queue ) 
{ 
  unsigned int bufs_in_recycle_ring ;
    klee_make_symbolic(&bufs_in_recycle_ring, sizeof(int), "bufs_in_recycle_ring");
  unsigned int page_ring_size ;
    klee_make_symbolic(&page_ring_size, sizeof(int), "page_ring_size");
  bool tmp ;
  unsigned long tmp___0 ;
  void *tmp___1 ;

  {
  tmp = iommu_present(& pci_bus_type);
  if ((int )tmp) {
    bufs_in_recycle_ring = 4096U;
  } else {
    bufs_in_recycle_ring = 16U;
  }
  tmp___0 = __roundup_pow_of_two((unsigned long )(bufs_in_recycle_ring / efx->rx_bufs_per_page));
  page_ring_size = (unsigned int )tmp___0;
  tmp___1 = kcalloc((size_t )page_ring_size, 8UL, 208U);
  rx_queue->page_ring = (struct page **)tmp___1;
  rx_queue->page_ptr_mask = page_ring_size - 1U;
  return;
}
}
void efx_init_rx_queue(struct efx_rx_queue *rx_queue ) 
{ 
  struct efx_nic *efx ;
  unsigned int max_fill ;
  unsigned int trigger ;
    klee_make_symbolic(&trigger, sizeof(int), "trigger");
  unsigned int max_trigger ;
    klee_make_symbolic(&max_trigger, sizeof(int), "max_trigger");
  struct _ddebug descriptor ;
  int tmp ;
  long tmp___0 ;
  unsigned int _min1 ;
  unsigned int _min2 ;

  {
  efx = rx_queue->efx;
  if ((int )(rx_queue->efx)->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_init_rx_queue";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/rx.c";
    descriptor.format = "initialising RX queue %d\n";
    descriptor.lineno = 748U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      tmp = efx_rx_queue_index(rx_queue);
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)(rx_queue->efx)->net_dev,
                           "initialising RX queue %d\n", tmp);
    } else {

    }
  } else {

  }
  rx_queue->added_count = 0U;
  rx_queue->notified_count = 0U;
  rx_queue->removed_count = 0U;
  rx_queue->min_fill = 4294967295U;
  efx_init_rx_recycle_ring(efx, rx_queue);
  rx_queue->page_remove = 0U;
  rx_queue->page_add = rx_queue->page_ptr_mask + 1U;
  rx_queue->page_recycle_count = 0U;
  rx_queue->page_recycle_failed = 0U;
  rx_queue->page_recycle_full = 0U;
  max_fill = efx->rxq_entries - 7U;
  max_trigger = max_fill - efx->rx_pages_per_batch * efx->rx_bufs_per_page;
  if (rx_refill_threshold != 0U) {
    _min1 = rx_refill_threshold;
    _min2 = 100U;
    trigger = ((_min1 < _min2 ? _min1 : _min2) * max_fill) / 100U;
    if (trigger > max_trigger) {
      trigger = max_trigger;
    } else {

    }
  } else {
    trigger = max_trigger;
  }
  rx_queue->max_fill = max_fill;
  rx_queue->fast_fill_trigger = trigger;
  rx_queue->refill_enabled = 1;
  efx_nic_init_rx(rx_queue);
  return;
}
}
void efx_fini_rx_queue(struct efx_rx_queue *rx_queue ) 
{ 
  int i ;
  struct efx_nic *efx ;
  struct efx_rx_buffer *rx_buf ;
  struct _ddebug descriptor ;
  int tmp ;
  long tmp___0 ;
  unsigned int index ;
  struct page *page ;
  struct efx_rx_page_state *state ;
  void *tmp___1 ;

  {
  efx = rx_queue->efx;
  if ((int )(rx_queue->efx)->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_fini_rx_queue";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/rx.c";
    descriptor.format = "shutting down RX queue %d\n";
    descriptor.lineno = 790U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      tmp = efx_rx_queue_index(rx_queue);
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)(rx_queue->efx)->net_dev,
                           "shutting down RX queue %d\n", tmp);
    } else {

    }
  } else {

  }
  ldv_del_timer_sync_327(& rx_queue->slow_fill);
  if ((unsigned long )rx_queue->buffer != (unsigned long )((struct efx_rx_buffer *)0)) {
    i = (int )rx_queue->removed_count;
    goto ldv_56418;
    ldv_56417: 
    index = rx_queue->ptr_mask & (unsigned int )i;
    rx_buf = efx_rx_buffer(rx_queue, index);
    efx_fini_rx_buffer(rx_queue, rx_buf);
    i = i + 1;
    ldv_56418: ;
    if ((unsigned int )i < rx_queue->added_count) {
      goto ldv_56417;
    } else {

    }

  } else {

  }
  i = 0;
  goto ldv_56424;
  ldv_56423: 
  page = *(rx_queue->page_ring + (unsigned long )i);
  if ((unsigned long )page == (unsigned long )((struct page *)0)) {
    goto ldv_56422;
  } else {

  }
  tmp___1 = lowmem_page_address((struct page  const  *)page);
  state = (struct efx_rx_page_state *)tmp___1;
  dma_unmap_page___0(& (efx->pci_dev)->dev, state->dma_addr, 4096UL << (int )efx->rx_buffer_order,
                     2);
  put_page(page);
  ldv_56422: 
  i = i + 1;
  ldv_56424: ;
  if ((unsigned int )i <= rx_queue->page_ptr_mask) {
    goto ldv_56423;
  } else {

  }
  kfree((void const   *)rx_queue->page_ring);
  rx_queue->page_ring = (struct page **)0;
  return;
}
}
void efx_remove_rx_queue(struct efx_rx_queue *rx_queue ) 
{ 
  struct _ddebug descriptor ;
  int tmp ;
  long tmp___0 ;

  {
  if ((int )(rx_queue->efx)->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_remove_rx_queue";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/rx.c";
    descriptor.format = "destroying RX queue %d\n";
    descriptor.lineno = 825U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      tmp = efx_rx_queue_index(rx_queue);
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)(rx_queue->efx)->net_dev,
                           "destroying RX queue %d\n", tmp);
    } else {

    }
  } else {

  }
  efx_nic_remove_rx(rx_queue);
  kfree((void const   *)rx_queue->buffer);
  rx_queue->buffer = (struct efx_rx_buffer *)0;
  return;
}
}
int efx_filter_rfs(struct net_device *net_dev , struct sk_buff  const  *skb , u16 rxq_index ,
                   u32 flow_id ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct efx_channel *channel ;
  struct efx_filter_spec spec ;
  __be16 const   *ports ;
  __be16 ether_type ;
  int nhoff ;
    klee_make_symbolic(&nhoff, sizeof(int), "nhoff");
  int rc ;
  struct vlan_hdr  const  *vh ;
  struct iphdr  const  *ip ;
  bool tmp___0 ;
  struct ipv6hdr  const  *ip6 ;
  u16 tmp___1 ;
  __u16 tmp___2 ;
  __u16 tmp___3 ;
  __u16 tmp___4 ;
  __u16 tmp___5 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((unsigned int )((unsigned short )skb->protocol) == 129U) {
    vh = (struct vlan_hdr  const  *)skb->data;
    ether_type = vh->h_vlan_encapsulated_proto;
    nhoff = 4;
  } else {
    ether_type = skb->protocol;
    nhoff = 0;
  }
  if ((unsigned int )ether_type != 8U && (unsigned int )ether_type != 56710U) {
    return (-93);
  } else {

  }
  efx_filter_init_rx(& spec, 0, (int )efx->rx_scatter ? 2 : 0, (unsigned int )rxq_index);
  spec.match_flags = 619U;
  spec.ether_type = ether_type;
  if ((unsigned int )ether_type == 8U) {
    ip = (struct iphdr  const  *)skb->data + (unsigned long )nhoff;
    tmp___0 = ip_is_fragment(ip);
    if ((int )tmp___0) {
      return (-93);
    } else {

    }
    spec.ip_proto = ip->protocol;
    spec.rem_host[0] = ip->saddr;
    spec.loc_host[0] = ip->daddr;
    ports = (__be16 const   *)(skb->data + ((unsigned long )nhoff + (unsigned long )((int )ip->ihl * 4)));
  } else {
    ip6 = (struct ipv6hdr  const  *)skb->data + (unsigned long )nhoff;
    spec.ip_proto = ip6->nexthdr;
    memcpy((void *)(& spec.rem_host), (void const   *)(& ip6->saddr), 16UL);
    memcpy((void *)(& spec.loc_host), (void const   *)(& ip6->daddr), 16UL);
    ports = (__be16 const   *)ip6 + 1U;
  }
  spec.rem_port = *ports;
  spec.loc_port = *(ports + 1UL);
  rc = (*((efx->type)->filter_rfs_insert))(efx, & spec);
  if (rc < 0) {
    return (rc);
  } else {

  }
  *(efx->rps_flow_id + (unsigned long )rc) = flow_id;
  tmp___1 = skb_get_rx_queue(skb);
  channel = efx_get_channel(efx, (unsigned int )tmp___1);
  channel->rfs_filters_added = channel->rfs_filters_added + 1U;
  if ((unsigned int )ether_type == 8U) {
    if ((efx->msg_enable & 2048U) != 0U) {
      tmp___2 = __fswab16((int )*(ports + 1UL));
      tmp___3 = __fswab16((int )*ports);
      netdev_info((struct net_device  const  *)efx->net_dev, "steering %s %pI4:%u:%pI4:%u to queue %u [flow %u filter %d]\n",
                  (unsigned int )spec.ip_proto == 6U ? (char *)"TCP" : (char *)"UDP",
                  (__be32 *)(& spec.rem_host), (int )tmp___3, (__be32 *)(& spec.loc_host),
                  (int )tmp___2, (int )rxq_index, flow_id, rc);
    } else {

    }
  } else
  if ((efx->msg_enable & 2048U) != 0U) {
    tmp___4 = __fswab16((int )*(ports + 1UL));
    tmp___5 = __fswab16((int )*ports);
    netdev_info((struct net_device  const  *)efx->net_dev, "steering %s [%pI6]:%u:[%pI6]:%u to queue %u [flow %u filter %d]\n",
                (unsigned int )spec.ip_proto == 6U ? (char *)"TCP" : (char *)"UDP",
                (__be32 *)(& spec.rem_host), (int )tmp___5, (__be32 *)(& spec.loc_host),
                (int )tmp___4, (int )rxq_index, flow_id, rc);
  } else {

  }
  return (rc);
}
}
bool __efx_filter_rfs_expire(struct efx_nic *efx , unsigned int quota ) 
{ 
  bool (*expire_one)(struct efx_nic * , u32  , unsigned int  ) ;
  unsigned int index ;
  unsigned int size ;
  u32 flow_id ;
  int tmp ;
  bool tmp___0 ;
  unsigned int tmp___1 ;

  {
  tmp = spin_trylock_bh(& efx->filter_lock);
  if (tmp == 0) {
    return (0);
  } else {

  }
  expire_one = (efx->type)->filter_rfs_expire_one;
  index = efx->rps_expire_index;
  size = (efx->type)->max_rx_ip_filters;
  goto ldv_56478;
  ldv_56477: 
  flow_id = *(efx->rps_flow_id + (unsigned long )index);
  tmp___0 = (*expire_one)(efx, flow_id, index);
  if ((int )tmp___0) {
    if ((efx->msg_enable & 2048U) != 0U) {
      netdev_info((struct net_device  const  *)efx->net_dev, "expired filter %d [flow %u]\n",
                  index, flow_id);
    } else {

    }
  } else {

  }
  index = index + 1U;
  if (index == size) {
    index = 0U;
  } else {

  }
  ldv_56478: 
  tmp___1 = quota;
  quota = quota - 1U;
  if (tmp___1 != 0U) {
    goto ldv_56477;
  } else {

  }
  efx->rps_expire_index = index;
  spin_unlock_bh(& efx->filter_lock);
  return (1);
}
}
bool efx_filter_is_mc_recipient(struct efx_filter_spec  const  *spec ) 
{ 
  bool tmp ;
  bool tmp___0 ;

  {
  if (((int )spec->flags & 8) == 0 || (unsigned int )*((unsigned short *)spec + 1UL) == 65520U) {
    return (0);
  } else {

  }
  if (((int )spec->match_flags & 1040) != 0) {
    tmp = is_multicast_ether_addr((u8 const   *)(& spec->loc_mac));
    if ((int )tmp) {
      return (1);
    } else {

    }
  } else {

  }
  if (((int )spec->match_flags & 66) == 66) {
    if ((unsigned int )((unsigned short )spec->ether_type) == 8U) {
      tmp___0 = ipv4_is_multicast(spec->loc_host[0]);
      if ((int )tmp___0) {
        return (1);
      } else {

      }
    } else {

    }
    if ((unsigned int )((unsigned short )spec->ether_type) == 56710U && (unsigned int )((unsigned char )*((u8 const   *)(& spec->loc_host))) == 255U) {
      return (1);
    } else {

    }
  } else {

  }
  return (0);
}
}
bool ldv_queue_work_on_315(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_316(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_317(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_318(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_319(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_320(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_321(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_322(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_323(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_324(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_325(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_326(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_del_timer_sync_327(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_10(ldv_func_arg1);
  return (ldv_func_res);
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
int ldv_mutex_trylock_353(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_351(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_354(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_355(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_358(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_360(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_362(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_364(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_366(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_368(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_350(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_352(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_356(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_357(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_359(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_361(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_363(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_365(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_367(struct mutex *ldv_func_arg1 ) ;
extern struct workqueue_struct *system_wq ;
bool ldv_queue_work_on_345(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_347(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_346(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_349(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_348(struct workqueue_struct *ldv_func_arg1 ) ;
bool ldv_cancel_delayed_work_sync_369(struct delayed_work *ldv_func_arg1 ) ;
__inline static bool queue_delayed_work___0(struct workqueue_struct *wq , struct delayed_work *dwork ,
                                            unsigned long delay ) 
{ 
  bool tmp ;

  {
  tmp = ldv_queue_delayed_work_on_346(8192, wq, dwork, delay);
  return (tmp);
}
}
__inline static bool schedule_delayed_work(struct delayed_work *dwork , unsigned long delay ) 
{ 
  bool tmp ;

  {
  tmp = queue_delayed_work___0(system_wq, dwork, delay);
  return (tmp);
}
}
extern void kfree_skb(struct sk_buff * ) ;
extern void consume_skb(struct sk_buff * ) ;
extern struct sk_buff *__alloc_skb(unsigned int  , gfp_t  , int  , int  ) ;
__inline static struct sk_buff *alloc_skb(unsigned int size , gfp_t priority ) 
{ 
  struct sk_buff *tmp ;

  {
  tmp = __alloc_skb(size, priority, 0, -1);
  return (tmp);
}
}
__inline static struct sk_buff *skb_get(struct sk_buff *skb ) 
{ 


  {
  atomic_inc(& skb->users);
  return (skb);
}
}
__inline static int skb_shared(struct sk_buff  const  *skb ) 
{ 
  int tmp ;

  {
  tmp = atomic_read(& skb->users);
  return (tmp != 1);
}
}
extern unsigned char *skb_put(struct sk_buff * , unsigned int  ) ;
__inline static void netif_tx_lock___2(struct net_device *dev ) 
{ 
  unsigned int i ;
  int cpu ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  spin_lock(& dev->tx_global_lock);
  __vpp_verify = (void const   *)0;
  switch (4UL) {
  case 1UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
  goto ldv_42809;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_42809;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_42809;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_42809;
  default: 
  __bad_percpu_size();
  }
  ldv_42809: 
  pscr_ret__ = pfo_ret__;
  goto ldv_42815;
  case 2UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_42819;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_42819;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_42819;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_42819;
  default: 
  __bad_percpu_size();
  }
  ldv_42819: 
  pscr_ret__ = pfo_ret_____0;
  goto ldv_42815;
  case 4UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_42828;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_42828;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_42828;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_42828;
  default: 
  __bad_percpu_size();
  }
  ldv_42828: 
  pscr_ret__ = pfo_ret_____1;
  goto ldv_42815;
  case 8UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_42837;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_42837;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_42837;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_42837;
  default: 
  __bad_percpu_size();
  }
  ldv_42837: 
  pscr_ret__ = pfo_ret_____2;
  goto ldv_42815;
  default: 
  __bad_size_call_parameter();
  goto ldv_42815;
  }
  ldv_42815: 
  cpu = pscr_ret__;
  i = 0U;
  goto ldv_42847;
  ldv_42846: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  __netif_tx_lock(txq, cpu);
  set_bit(2L, (unsigned long volatile   *)(& txq->state));
  __netif_tx_unlock(txq);
  i = i + 1U;
  ldv_42847: ;
  if (dev->num_tx_queues > i) {
    goto ldv_42846;
  } else {

  }

  return;
}
}
__inline static void netif_tx_lock_bh___1(struct net_device *dev ) 
{ 


  {
  local_bh_disable();
  netif_tx_lock___2(dev);
  return;
}
}
__inline static void netif_tx_unlock___2(struct net_device *dev ) 
{ 
  unsigned int i ;
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  i = 0U;
  goto ldv_42858;
  ldv_42857: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  clear_bit(2L, (unsigned long volatile   *)(& txq->state));
  netif_schedule_queue(txq);
  i = i + 1U;
  ldv_42858: ;
  if (dev->num_tx_queues > i) {
    goto ldv_42857;
  } else {

  }
  spin_unlock(& dev->tx_global_lock);
  return;
}
}
__inline static void netif_tx_unlock_bh___1(struct net_device *dev ) 
{ 


  {
  netif_tx_unlock___2(dev);
  local_bh_enable();
  return;
}
}
__inline static void efx_device_detach_sync___1(struct efx_nic *efx ) 
{ 
  struct net_device *dev ;

  {
  dev = efx->net_dev;
  netif_tx_lock_bh___1(dev);
  netif_device_detach(dev);
  netif_tx_unlock_bh___1(dev);
  return;
}
}
__inline static int efx_nic_event_test_irq_cpu(struct efx_channel *channel ) 
{ 
  int __var ;

  {
  __var = 0;
  return ((int )*((int volatile   *)(& channel->event_test_cpu)));
}
}
__inline static int efx_nic_irq_test_irq_cpu(struct efx_nic *efx ) 
{ 
  int __var ;

  {
  __var = 0;
  return ((int )*((int volatile   *)(& efx->last_irq_cpu)));
}
}
int efx_selftest(struct efx_nic *efx , struct efx_self_tests *tests , unsigned int flags ) ;
static u8 const   payload_source[6U]  = {      0U,      15U,      83U,      27U, 
        27U,      27U};
static char const   payload_msg[55U]  = 
  {      'H',      'e',      'l',      'l', 
        'o',      ' ',      'w',      'o', 
        'r',      'l',      'd',      '!', 
        ' ',      'T',      'h',      'i', 
        's',      ' ',      'i',      's', 
        ' ',      'a',      'n',      ' ', 
        'E',      'f',      'x',      ' ', 
        'l',      'o',      'o',      'p', 
        'b',      'a',      'c',      'k', 
        ' ',      't',      'e',      's', 
        't',      ' ',      'i',      'n', 
        ' ',      'p',      'r',      'o', 
        'g',      'r',      'e',      's', 
        's',      '!',      '\000'};
static unsigned int const   efx_interrupt_mode_max  =    3U;
static char const   * const  efx_interrupt_mode_names[3U]  = {      "MSI-X",      "MSI",      "legacy"};
static int efx_test_phy_alive(struct efx_nic *efx , struct efx_self_tests *tests ) 
{ 
  int rc ;

  {
  rc = 0;
  if ((unsigned long )(efx->phy_op)->test_alive != (unsigned long )((int (*/* const  */)(struct efx_nic * ))0)) {
    rc = (*((efx->phy_op)->test_alive))(efx);
    tests->phy_alive = rc != 0 ? -1 : 1;
  } else {

  }
  return (rc);
}
}
static int efx_test_nvram(struct efx_nic *efx , struct efx_self_tests *tests ) 
{ 
  int rc ;

  {
  rc = 0;
  if ((unsigned long )(efx->type)->test_nvram != (unsigned long )((int (*/* const  */)(struct efx_nic * ))0)) {
    rc = (*((efx->type)->test_nvram))(efx);
    tests->nvram = rc != 0 ? -1 : 1;
  } else {

  }
  return (rc);
}
}
static int efx_test_interrupts(struct efx_nic *efx , struct efx_self_tests *tests ) 
{ 
  unsigned long timeout ;
  unsigned long wait ;
    klee_make_symbolic(&wait, sizeof(long), "wait");
  int cpu ;
  struct _ddebug descriptor ;
  long tmp ;
  struct _ddebug descriptor___0 ;
  long tmp___0 ;
  struct _ddebug descriptor___1 ;
  long tmp___1 ;

  {
  if ((int )efx->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_test_interrupts";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/selftest.c";
    descriptor.format = "testing interrupts\n";
    descriptor.lineno = 136U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "testing interrupts\n");
    } else {

    }
  } else {

  }
  tests->interrupt = -1;
  efx_nic_irq_test_start(efx);
  timeout = (unsigned long )jiffies + 250UL;
  wait = 1UL;
  if ((int )efx->msg_enable & 1) {
    descriptor___0.modname = "sfc";
    descriptor___0.function = "efx_test_interrupts";
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/selftest.c";
    descriptor___0.format = "waiting for test interrupt\n";
    descriptor___0.lineno = 144U;
    descriptor___0.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                           "waiting for test interrupt\n");
    } else {

    }
  } else {

  }
  ldv_56456: 
  schedule_timeout_uninterruptible((long )wait);
  cpu = efx_nic_irq_test_irq_cpu(efx);
  if (cpu >= 0) {
    goto success;
  } else {

  }
  wait = wait * 2UL;
  if ((long )((unsigned long )jiffies - timeout) < 0L) {
    goto ldv_56456;
  } else {

  }

  if ((int )efx->msg_enable & 1) {
    netdev_err((struct net_device  const  *)efx->net_dev, "timed out waiting for interrupt\n");
  } else {

  }
  return (-110);
  success: ;
  if ((int )efx->msg_enable & 1) {
    descriptor___1.modname = "sfc";
    descriptor___1.function = "efx_test_interrupts";
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/selftest.c";
    descriptor___1.format = "%s test interrupt seen on CPU%d\n";
    descriptor___1.lineno = 158U;
    descriptor___1.flags = 0U;
    tmp___1 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
    if (tmp___1 != 0L) {
      __dynamic_netdev_dbg(& descriptor___1, (struct net_device  const  *)efx->net_dev,
                           "%s test interrupt seen on CPU%d\n", (unsigned int )efx->interrupt_mode < (unsigned int )efx_interrupt_mode_max ? efx_interrupt_mode_names[(unsigned int )efx->interrupt_mode] : (char const   */* const  */)"(invalid)",
                           cpu);
    } else {

    }
  } else {

  }
  tests->interrupt = 1;
  return (0);
}
}
static int efx_test_eventq_irq(struct efx_nic *efx , struct efx_self_tests *tests ) 
{ 
  struct efx_channel *channel ;
  unsigned int read_ptr[32U] ;
  unsigned long napi_ran ;
    klee_make_symbolic(&napi_ran, sizeof(long), "napi_ran");
  unsigned long dma_pend ;
    klee_make_symbolic(&dma_pend, sizeof(long), "dma_pend");
  unsigned long int_pend ;
    klee_make_symbolic(&int_pend, sizeof(long), "int_pend");
  unsigned long timeout ;
  unsigned long wait ;
  bool tmp ;
  int tmp___0 ;
  bool dma_seen ;
  int tmp___1 ;
  bool int_seen ;
  int tmp___2 ;
  struct _ddebug descriptor ;
  int tmp___3 ;
  long tmp___4 ;

  {
  napi_ran = 0UL;
  dma_pend = 0UL;
  int_pend = 0UL;
  channel = efx->channel[0];
  goto ldv_56471;
  ldv_56470: 
  read_ptr[channel->channel] = channel->eventq_read_ptr;
  set_bit((long )channel->channel, (unsigned long volatile   *)(& dma_pend));
  set_bit((long )channel->channel, (unsigned long volatile   *)(& int_pend));
  efx_nic_event_test_start(channel);
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56471: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56470;
  } else {

  }
  timeout = (unsigned long )jiffies + 250UL;
  wait = 1UL;
  ldv_56482: 
  schedule_timeout_uninterruptible((long )wait);
  channel = efx->channel[0];
  goto ldv_56474;
  ldv_56473: 
  efx_stop_eventq(channel);
  if (channel->eventq_read_ptr != read_ptr[channel->channel]) {
    set_bit((long )channel->channel, (unsigned long volatile   *)(& napi_ran));
    clear_bit((long )channel->channel, (unsigned long volatile   *)(& dma_pend));
    clear_bit((long )channel->channel, (unsigned long volatile   *)(& int_pend));
  } else {
    tmp = efx_nic_event_present(channel);
    if ((int )tmp) {
      clear_bit((long )channel->channel, (unsigned long volatile   *)(& dma_pend));
    } else {

    }
    tmp___0 = efx_nic_event_test_irq_cpu(channel);
    if (tmp___0 >= 0) {
      clear_bit((long )channel->channel, (unsigned long volatile   *)(& int_pend));
    } else {

    }
  }
  efx_start_eventq(channel);
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56474: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56473;
  } else {

  }
  wait = wait * 2UL;
  if ((dma_pend != 0UL || int_pend != 0UL) && (long )((unsigned long )jiffies - timeout) < 0L) {
    goto ldv_56482;
  } else {

  }
  channel = efx->channel[0];
  goto ldv_56489;
  ldv_56488: 
  tmp___1 = variable_test_bit((long )channel->channel, (unsigned long const volatile   *)(& dma_pend));
  dma_seen = tmp___1 == 0;
  tmp___2 = variable_test_bit((long )channel->channel, (unsigned long const volatile   *)(& int_pend));
  int_seen = tmp___2 == 0;
  tests->eventq_dma[channel->channel] = (int )dma_seen ? 1 : -1;
  tests->eventq_int[channel->channel] = (int )int_seen ? 1 : -1;
  if ((int )dma_seen && (int )int_seen) {
    if ((int )efx->msg_enable & 1) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_test_eventq_irq";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/selftest.c";
      descriptor.format = "channel %d event queue passed (with%s NAPI)\n";
      descriptor.lineno = 221U;
      descriptor.flags = 0U;
      tmp___4 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp___4 != 0L) {
        tmp___3 = variable_test_bit((long )channel->channel, (unsigned long const volatile   *)(& napi_ran));
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "channel %d event queue passed (with%s NAPI)\n", channel->channel,
                             tmp___3 != 0 ? (char *)"" : (char *)"out");
      } else {

      }
    } else {

    }
  } else {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "channel %d timed out waiting for event queue\n",
                 channel->channel);
    } else {

    }
    if ((int )int_seen) {
      if ((int )efx->msg_enable & 1) {
        netdev_err((struct net_device  const  *)efx->net_dev, "channel %d saw interrupt during event queue test\n",
                   channel->channel);
      } else {

      }
    } else {

    }
    if ((int )dma_seen) {
      if ((int )efx->msg_enable & 1) {
        netdev_err((struct net_device  const  *)efx->net_dev, "channel %d event was generated, but failed to trigger an interrupt\n",
                   channel->channel);
      } else {

      }
    } else {

    }
  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56489: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56488;
  } else {

  }

  return (dma_pend != 0UL || int_pend != 0UL ? -110 : 0);
}
}
static int efx_test_phy(struct efx_nic *efx , struct efx_self_tests *tests , unsigned int flags ) 
{ 
  int rc ;

  {
  if ((unsigned long )(efx->phy_op)->run_tests == (unsigned long )((int (*/* const  */)(struct efx_nic * ,
                                                                                        int * ,
                                                                                        unsigned int  ))0)) {
    return (0);
  } else {

  }
  ldv_mutex_lock_357(& efx->mac_lock);
  rc = (*((efx->phy_op)->run_tests))(efx, (int *)(& tests->phy_ext), flags);
  ldv_mutex_unlock_358(& efx->mac_lock);
  return (rc);
}
}
void efx_loopback_rx_packet(struct efx_nic *efx , char const   *buf_ptr , int pkt_len ) 
{ 
  struct efx_loopback_state *state ;
  struct efx_loopback_payload *received ;
  struct efx_loopback_payload *payload ;
  long tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  __u16 tmp___3 ;
  __u16 tmp___4 ;

  {
  state = (struct efx_loopback_state *)efx->loopback_selftest;
  tmp = ldv__builtin_expect((unsigned long )buf_ptr == (unsigned long )((char const   *)0),
                         0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/selftest.c"),
                         "i" (276), "i" (12UL));
    ldv_56505: ;
    goto ldv_56505;
  } else {

  }
  if ((unsigned long )state == (unsigned long )((struct efx_loopback_state *)0) || (int )state->flush) {
    return;
  } else {

  }
  payload = & state->payload;
  received = (struct efx_loopback_payload *)buf_ptr;
  received->ip.saddr = payload->ip.saddr;
  if ((int )state->offload_csum) {
    received->ip.check = payload->ip.check;
  } else {

  }
  if ((unsigned int )pkt_len <= 13U) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "saw runt RX packet (length %d) in %s loopback test\n",
                 pkt_len, (unsigned int )efx->loopback_mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )efx->loopback_mode] : (char const   */* const  */)"(invalid)");
    } else {

    }
    goto err;
  } else {

  }
  tmp___0 = memcmp((void const   *)(& received->header), (void const   *)(& payload->header),
                   14UL);
  if (tmp___0 != 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "saw non-loopback RX packet in %s loopback test\n",
                 (unsigned int )efx->loopback_mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )efx->loopback_mode] : (char const   */* const  */)"(invalid)");
    } else {

    }
    goto err;
  } else {

  }
  if (pkt_len != 108) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "saw incorrect RX packet length %d (wanted %d) in %s loopback test\n",
                 pkt_len, 108, (unsigned int )efx->loopback_mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )efx->loopback_mode] : (char const   */* const  */)"(invalid)");
    } else {

    }
    goto err;
  } else {

  }
  tmp___1 = memcmp((void const   *)(& received->ip), (void const   *)(& payload->ip),
                   20UL);
  if (tmp___1 != 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "saw corrupted IP header in %s loopback test\n",
                 (unsigned int )efx->loopback_mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )efx->loopback_mode] : (char const   */* const  */)"(invalid)");
    } else {

    }
    goto err;
  } else {

  }
  tmp___2 = memcmp((void const   *)(& received->msg), (void const   *)(& payload->msg),
                   64UL);
  if (tmp___2 != 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "saw corrupted RX packet in %s loopback test\n",
                 (unsigned int )efx->loopback_mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )efx->loopback_mode] : (char const   */* const  */)"(invalid)");
    } else {

    }
    goto err;
  } else {

  }
  if ((int )received->iteration != (int )payload->iteration) {
    if ((int )efx->msg_enable & 1) {
      tmp___3 = __fswab16((int )payload->iteration);
      tmp___4 = __fswab16((int )received->iteration);
      netdev_err((struct net_device  const  *)efx->net_dev, "saw RX packet from iteration %d (wanted %d) in %s loopback test\n",
                 (int )tmp___4, (int )tmp___3, (unsigned int )efx->loopback_mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )efx->loopback_mode] : (char const   */* const  */)"(invalid)");
    } else {

    }
    goto err;
  } else {

  }
  atomic_inc(& state->rx_good);
  return;
  err: 
  atomic_inc(& state->rx_bad);
  return;
}
}
static void efx_iterate_state(struct efx_nic *efx ) 
{ 
  struct efx_loopback_state *state ;
  struct net_device *net_dev ;
  struct efx_loopback_payload *payload ;
  __u16 tmp ;
  __u16 tmp___0 ;

  {
  state = (struct efx_loopback_state *)efx->loopback_selftest;
  net_dev = efx->net_dev;
  payload = & state->payload;
  ether_addr_copy((u8 *)(& payload->header.h_dest), (u8 const   *)net_dev->dev_addr);
  ether_addr_copy((u8 *)(& payload->header.h_source), (u8 const   *)(& payload_source));
  payload->header.h_proto = 8U;
  payload->ip.daddr = 16777343U;
  payload->ip.ihl = 5U;
  payload->ip.check = 44510U;
  payload->ip.tot_len = 24064U;
  payload->ip.version = 4U;
  payload->ip.protocol = 17U;
  payload->udp.source = 0U;
  payload->udp.len = 18944U;
  payload->udp.check = 0U;
  tmp = __fswab16((int )payload->iteration);
  tmp___0 = __fswab16((int )((unsigned int )tmp + 1U));
  payload->iteration = tmp___0;
  memcpy((void *)(& payload->msg), (void const   *)(& payload_msg), 55UL);
  atomic_set(& state->rx_good, 0);
  atomic_set(& state->rx_bad, 0);
  __asm__  volatile   ("": : : "memory");
  return;
}
}
static int efx_begin_loopback(struct efx_tx_queue *tx_queue ) 
{ 
  struct efx_nic *efx ;
  struct efx_loopback_state *state ;
  struct efx_loopback_payload *payload ;
  struct sk_buff *skb ;
  int i ;
  netdev_tx_t rc ;
  unsigned char *tmp ;
  __u32 tmp___0 ;

  {
  efx = tx_queue->efx;
  state = (struct efx_loopback_state *)efx->loopback_selftest;
  i = 0;
  goto ldv_56524;
  ldv_56523: 
  skb = alloc_skb(108U, 208U);
  if ((unsigned long )skb == (unsigned long )((struct sk_buff *)0)) {
    return (-12);
  } else {

  }
  *(state->skbs + (unsigned long )i) = skb;
  skb_get(skb);
  tmp = skb_put(skb, 108U);
  payload = (struct efx_loopback_payload *)tmp;
  memcpy((void *)payload, (void const   *)(& state->payload), 108UL);
  tmp___0 = __fswab32((__u32 )((i << 2) | 2130706433));
  payload->ip.saddr = tmp___0;
  __asm__  volatile   ("": : : "memory");
  netif_tx_lock_bh___1(efx->net_dev);
  rc = efx_enqueue_skb(tx_queue, skb);
  netif_tx_unlock_bh___1(efx->net_dev);
  if ((int )rc != 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "TX queue %d could not transmit packet %d of %d in %s loopback test\n",
                 tx_queue->queue, i + 1, state->packet_count, (unsigned int )efx->loopback_mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )efx->loopback_mode] : (char const   */* const  */)"(invalid)");
    } else {

    }
    kfree_skb(skb);
    return (-32);
  } else {

  }
  i = i + 1;
  ldv_56524: ;
  if (state->packet_count > i) {
    goto ldv_56523;
  } else {

  }

  return (0);
}
}
static int efx_poll_loopback(struct efx_nic *efx ) 
{ 
  struct efx_loopback_state *state ;
  int tmp ;

  {
  state = (struct efx_loopback_state *)efx->loopback_selftest;
  tmp = atomic_read((atomic_t const   *)(& state->rx_good));
  return (tmp == state->packet_count);
}
}
static int efx_end_loopback(struct efx_tx_queue *tx_queue , struct efx_loopback_self_tests *lb_tests ) 
{ 
  struct efx_nic *efx ;
  struct efx_loopback_state *state ;
  struct sk_buff *skb ;
  int tx_done ;
    klee_make_symbolic(&tx_done, sizeof(int), "tx_done");
  int rx_good ;
  int rx_bad ;
  int i ;
  int rc ;
  int tmp ;
  struct _ddebug descriptor ;
  long tmp___0 ;

  {
  efx = tx_queue->efx;
  state = (struct efx_loopback_state *)efx->loopback_selftest;
  tx_done = 0;
  rc = 0;
  netif_tx_lock_bh___1(efx->net_dev);
  i = 0;
  goto ldv_56543;
  ldv_56542: 
  skb = *(state->skbs + (unsigned long )i);
  if ((unsigned long )skb != (unsigned long )((struct sk_buff *)0)) {
    tmp = skb_shared((struct sk_buff  const  *)skb);
    if (tmp == 0) {
      tx_done = tx_done + 1;
    } else {

    }
  } else {

  }
  consume_skb(skb);
  i = i + 1;
  ldv_56543: ;
  if (state->packet_count > i) {
    goto ldv_56542;
  } else {

  }
  netif_tx_unlock_bh___1(efx->net_dev);
  rx_good = atomic_read((atomic_t const   *)(& state->rx_good));
  rx_bad = atomic_read((atomic_t const   *)(& state->rx_bad));
  if (state->packet_count != tx_done) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "TX queue %d saw only %d out of an expected %d TX completion events in %s loopback test\n",
                 tx_queue->queue, tx_done, state->packet_count, (unsigned int )efx->loopback_mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )efx->loopback_mode] : (char const   */* const  */)"(invalid)");
    } else {

    }
    rc = -110;
  } else {

  }
  if (state->packet_count != rx_good) {
    if ((int )efx->msg_enable & 1) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_end_loopback";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/selftest.c";
      descriptor.format = "TX queue %d saw only %d out of an expected %d received packets in %s loopback test\n";
      descriptor.lineno = 497U;
      descriptor.flags = 0U;
      tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp___0 != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "TX queue %d saw only %d out of an expected %d received packets in %s loopback test\n",
                             tx_queue->queue, rx_good, state->packet_count, (unsigned int )efx->loopback_mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )efx->loopback_mode] : (char const   */* const  */)"(invalid)");
      } else {

      }
    } else {

    }
    rc = -110;
  } else {

  }
  lb_tests->tx_sent[tx_queue->queue] = lb_tests->tx_sent[tx_queue->queue] + state->packet_count;
  lb_tests->tx_done[tx_queue->queue] = lb_tests->tx_done[tx_queue->queue] + tx_done;
  lb_tests->rx_good = lb_tests->rx_good + rx_good;
  lb_tests->rx_bad = lb_tests->rx_bad + rx_bad;
  return (rc);
}
}
static int efx_test_loopback(struct efx_tx_queue *tx_queue , struct efx_loopback_self_tests *lb_tests ) 
{ 
  struct efx_nic *efx ;
  struct efx_loopback_state *state ;
  int i ;
  int begin_rc ;
    klee_make_symbolic(&begin_rc, sizeof(int), "begin_rc");
  int end_rc ;
    klee_make_symbolic(&end_rc, sizeof(int), "end_rc");
  int _min1 ;
  int _min2 ;
  void *tmp ;
  struct _ddebug descriptor ;
  long tmp___0 ;
  int tmp___1 ;
  struct _ddebug descriptor___0 ;
  long tmp___2 ;

  {
  efx = tx_queue->efx;
  state = (struct efx_loopback_state *)efx->loopback_selftest;
  i = 0;
  goto ldv_56562;
  ldv_56561: 
  state->packet_count = (int )(efx->txq_entries / 3U);
  _min1 = 1 << (i << 2);
  _min2 = state->packet_count;
  state->packet_count = _min1 < _min2 ? _min1 : _min2;
  tmp = kcalloc((size_t )state->packet_count, 8UL, 208U);
  state->skbs = (struct sk_buff **)tmp;
  if ((unsigned long )state->skbs == (unsigned long )((struct sk_buff **)0)) {
    return (-12);
  } else {

  }
  state->flush = 0;
  if ((int )efx->msg_enable & 1) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_test_loopback";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/selftest.c";
    descriptor.format = "TX queue %d testing %s loopback with %d packets\n";
    descriptor.lineno = 532U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "TX queue %d testing %s loopback with %d packets\n", tx_queue->queue,
                           (unsigned int )efx->loopback_mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )efx->loopback_mode] : (char const   */* const  */)"(invalid)",
                           state->packet_count);
    } else {

    }
  } else {

  }
  efx_iterate_state(efx);
  begin_rc = efx_begin_loopback(tx_queue);
  msleep(1U);
  tmp___1 = efx_poll_loopback(efx);
  if (tmp___1 == 0) {
    msleep(1000U);
    efx_poll_loopback(efx);
  } else {

  }
  end_rc = efx_end_loopback(tx_queue, lb_tests);
  kfree((void const   *)state->skbs);
  if (begin_rc != 0 || end_rc != 0) {
    schedule_timeout_uninterruptible(25L);
    return (begin_rc != 0 ? begin_rc : end_rc);
  } else {

  }
  i = i + 1;
  ldv_56562: ;
  if (i <= 2) {
    goto ldv_56561;
  } else {

  }

  if ((int )efx->msg_enable & 1) {
    descriptor___0.modname = "sfc";
    descriptor___0.function = "efx_test_loopback";
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/selftest.c";
    descriptor___0.format = "TX queue %d passed %s loopback test with a burst length of %d packets\n";
    descriptor___0.lineno = 559U;
    descriptor___0.flags = 0U;
    tmp___2 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
    if (tmp___2 != 0L) {
      __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                           "TX queue %d passed %s loopback test with a burst length of %d packets\n",
                           tx_queue->queue, (unsigned int )efx->loopback_mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )efx->loopback_mode] : (char const   */* const  */)"(invalid)",
                           state->packet_count);
    } else {

    }
  } else {

  }
  return (0);
}
}
static int efx_wait_for_link(struct efx_nic *efx ) 
{ 
  struct efx_link_state *link_state ;
  int count ;
  int link_up_count ;
    klee_make_symbolic(&link_up_count, sizeof(int), "link_up_count");
  bool link_up ;
  bool tmp ;
  int tmp___0 ;

  {
  link_state = & efx->link_state;
  link_up_count = 0;
  count = 0;
  goto ldv_56573;
  ldv_56572: 
  schedule_timeout_uninterruptible(25L);
  if ((unsigned long )(efx->type)->monitor != (unsigned long )((void (*/* const  */)(struct efx_nic * ))0)) {
    ldv_mutex_lock_359(& efx->mac_lock);
    (*((efx->type)->monitor))(efx);
    ldv_mutex_unlock_360(& efx->mac_lock);
  } else {

  }
  ldv_mutex_lock_361(& efx->mac_lock);
  link_up = link_state->up;
  if ((int )link_up) {
    tmp = (*((efx->type)->check_mac_fault))(efx);
    if ((int )tmp != 0) {
      tmp___0 = 0;
    } else {
      tmp___0 = 1;
    }
    link_up = (bool )tmp___0;
  } else {

  }
  ldv_mutex_unlock_362(& efx->mac_lock);
  if ((int )link_up) {
    link_up_count = link_up_count + 1;
    if (link_up_count == 2) {
      return (0);
    } else {

    }
  } else {
    link_up_count = 0;
  }
  count = count + 1;
  ldv_56573: ;
  if (count <= 39) {
    goto ldv_56572;
  } else {

  }

  return (-110);
}
}
static int efx_test_loopbacks(struct efx_nic *efx , struct efx_self_tests *tests ,
                              unsigned int loopback_modes ) 
{ 
  enum efx_loopback_mode mode ;
  struct efx_loopback_state *state ;
  struct efx_channel *channel ;
  struct efx_channel *tmp ;
  struct efx_tx_queue *tx_queue ;
  int rc ;
  void *tmp___0 ;
  long tmp___1 ;
  bool tmp___2 ;
  bool tmp___3 ;
  int tmp___4 ;

  {
  tmp = efx_get_channel(efx, efx->tx_channel_offset);
  channel = tmp;
  rc = 0;
  tmp___0 = kzalloc(136UL, 208U);
  state = (struct efx_loopback_state *)tmp___0;
  if ((unsigned long )state == (unsigned long )((struct efx_loopback_state *)0)) {
    return (-12);
  } else {

  }
  tmp___1 = ldv__builtin_expect((unsigned long )efx->loopback_selftest != (unsigned long )((void *)0),
                             0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/selftest.c"),
                         "i" (616), "i" (12UL));
    ldv_56585: ;
    goto ldv_56585;
  } else {

  }
  state->flush = 1;
  efx->loopback_selftest = (void *)state;
  mode = 0;
  goto ldv_56592;
  ldv_56591: ;
  if (((unsigned int )(1 << (int )mode) & loopback_modes) == 0U) {
    goto ldv_56586;
  } else {

  }
  state->flush = 1;
  ldv_mutex_lock_363(& efx->mac_lock);
  efx->loopback_mode = mode;
  rc = __efx_reconfigure_port(efx);
  ldv_mutex_unlock_364(& efx->mac_lock);
  if (rc != 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "unable to move into %s loopback\n",
                 (unsigned int )efx->loopback_mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )efx->loopback_mode] : (char const   */* const  */)"(invalid)");
    } else {

    }
    goto out;
  } else {

  }
  rc = efx_wait_for_link(efx);
  if (rc != 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "loopback %s never came up\n",
                 (unsigned int )efx->loopback_mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )efx->loopback_mode] : (char const   */* const  */)"(invalid)");
    } else {

    }
    goto out;
  } else {

  }
  tmp___3 = efx_channel_has_tx_queues(channel);
  if (tmp___3) {
    tmp___4 = 0;
  } else {
    tmp___4 = 1;
  }
  if (tmp___4) {

  } else {
    tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
    goto ldv_56589;
    ldv_56588: 
    state->offload_csum = (tx_queue->queue & 1U) != 0U;
    rc = efx_test_loopback(tx_queue, (struct efx_loopback_self_tests *)(& tests->loopback) + (unsigned long )mode);
    if (rc != 0) {
      goto out;
    } else {

    }
    tx_queue = tx_queue + 1;
    ldv_56589: ;
    if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
      tmp___2 = efx_tx_queue_used(tx_queue);
      if ((int )tmp___2) {
        goto ldv_56588;
      } else {
        goto ldv_56590;
      }
    } else {

    }
    ldv_56590: ;
  }
  ldv_56586: 
  mode = (enum efx_loopback_mode )((unsigned int )mode + 1U);
  ldv_56592: ;
  if ((unsigned int )mode <= 17U) {
    goto ldv_56591;
  } else {

  }

  out: 
  state->flush = 1;
  efx->loopback_selftest = (void *)0;
  __asm__  volatile   ("sfence": : : "memory");
  kfree((void const   *)state);
  return (rc);
}
}
int efx_selftest(struct efx_nic *efx , struct efx_self_tests *tests , unsigned int flags ) 
{ 
  enum efx_loopback_mode loopback_mode ;
  int phy_mode ;
    klee_make_symbolic(&phy_mode, sizeof(int), "phy_mode");
  int rc_test ;
    klee_make_symbolic(&rc_test, sizeof(int), "rc_test");
  int rc_reset ;
    klee_make_symbolic(&rc_reset, sizeof(int), "rc_reset");
  int rc ;
  int tmp ;

  {
  loopback_mode = efx->loopback_mode;
  phy_mode = (int )efx->phy_mode;
  rc_test = 0;
  efx_selftest_async_cancel(efx);
  rc = efx_test_phy_alive(efx, tests);
  if (rc != 0 && rc_test == 0) {
    rc_test = rc;
  } else {

  }
  rc = efx_test_nvram(efx, tests);
  if (rc != 0 && rc_test == 0) {
    rc_test = rc;
  } else {

  }
  rc = efx_test_interrupts(efx, tests);
  if (rc != 0 && rc_test == 0) {
    rc_test = rc;
  } else {

  }
  rc = efx_test_eventq_irq(efx, tests);
  if (rc != 0 && rc_test == 0) {
    rc_test = rc;
  } else {

  }
  if (rc_test != 0) {
    return (rc_test);
  } else {

  }
  if ((flags & 1U) == 0U) {
    tmp = efx_test_phy(efx, tests, flags);
    return (tmp);
  } else {

  }
  efx_device_detach_sync___1(efx);
  if ((unsigned long )(efx->type)->test_chip != (unsigned long )((int (*/* const  */)(struct efx_nic * ,
                                                                                      struct efx_self_tests * ))0)) {
    rc_reset = (*((efx->type)->test_chip))(efx, tests);
    if (rc_reset != 0) {
      if ((efx->msg_enable & 8192U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "Unable to recover from chip test\n");
      } else {

      }
      efx_schedule_reset(efx, 7);
      return (rc_reset);
    } else {

    }
    if ((tests->memory < 0 || tests->registers < 0) && rc_test == 0) {
      rc_test = -5;
    } else {

    }
  } else {

  }
  ldv_mutex_lock_365(& efx->mac_lock);
  efx->phy_mode = (enum efx_phy_mode )((unsigned int )efx->phy_mode & 4294967293U);
  efx->loopback_mode = 0;
  __efx_reconfigure_port(efx);
  ldv_mutex_unlock_366(& efx->mac_lock);
  rc = efx_test_phy(efx, tests, flags);
  if (rc != 0 && rc_test == 0) {
    rc_test = rc;
  } else {

  }
  rc = efx_test_loopbacks(efx, tests, (unsigned int )efx->loopback_modes);
  if (rc != 0 && rc_test == 0) {
    rc_test = rc;
  } else {

  }
  ldv_mutex_lock_367(& efx->mac_lock);
  efx->phy_mode = (enum efx_phy_mode )phy_mode;
  efx->loopback_mode = loopback_mode;
  __efx_reconfigure_port(efx);
  ldv_mutex_unlock_368(& efx->mac_lock);
  netif_device_attach(efx->net_dev);
  return (rc_test);
}
}
void efx_selftest_async_start(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;

  {
  channel = efx->channel[0];
  goto ldv_56609;
  ldv_56608: 
  efx_nic_event_test_start(channel);
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56609: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56608;
  } else {

  }
  schedule_delayed_work(& efx->selftest_work, 250UL);
  return;
}
}
void efx_selftest_async_cancel(struct efx_nic *efx ) 
{ 


  {
  ldv_cancel_delayed_work_sync_369(& efx->selftest_work);
  return;
}
}
void efx_selftest_async_work(struct work_struct *data ) 
{ 
  struct efx_nic *efx ;
  struct work_struct  const  *__mptr ;
  struct efx_channel *channel ;
  int cpu ;
  struct _ddebug descriptor ;
  long tmp ;

  {
  __mptr = (struct work_struct  const  *)data;
  efx = (struct efx_nic *)__mptr + 0xfffffffffffff638UL;
  channel = efx->channel[0];
  goto ldv_56625;
  ldv_56624: 
  cpu = efx_nic_event_test_irq_cpu(channel);
  if (cpu < 0) {
    if ((efx->msg_enable & 32U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "channel %d failed to trigger an interrupt\n",
                 channel->channel);
    } else {

    }
  } else
  if ((efx->msg_enable & 32U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_selftest_async_work";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/selftest.c";
    descriptor.format = "channel %d triggered interrupt on CPU %d\n";
    descriptor.lineno = 786U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "channel %d triggered interrupt on CPU %d\n", channel->channel,
                           cpu);
    } else {

    }
  } else {

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56625: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56624;
  } else {

  }

  return;
}
}
bool ldv_queue_work_on_345(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_346(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_347(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_348(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_349(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_350(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_351(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_352(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_353(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_354(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_355(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_356(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_357(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_358(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_359(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_360(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_361(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_362(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_363(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_364(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_365(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_366(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_367(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_368(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
bool ldv_cancel_delayed_work_sync_369(struct delayed_work *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___14 ldv_func_res ;
  bool tmp ;

  {
  tmp = cancel_delayed_work_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_work_7(& ldv_func_arg1->work);
  return (ldv_func_res);
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
int ldv_mutex_trylock_407(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_405(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_408(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_409(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_412(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_414(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_416(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_418(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_420(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_404(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_406(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_410(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_411(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_413(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_415(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_417(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_419(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_399(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_401(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_400(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_403(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_402(struct workqueue_struct *ldv_func_arg1 ) ;
__inline static void ethtool_cmd_speed_set(struct ethtool_cmd *ep , __u32 speed ) 
{ 


  {
  ep->speed = (unsigned short )speed;
  ep->speed_hi = (unsigned short )(speed >> 16);
  return;
}
}
__inline static __u32 ethtool_cmd_speed(struct ethtool_cmd  const  *ep ) 
{ 


  {
  return ((__u32 )(((int )ep->speed_hi << 16) | (int )ep->speed));
}
}
extern u32 ethtool_op_get_link(struct net_device * ) ;
extern int dev_open(struct net_device * ) ;
__inline static bool is_broadcast_ether_addr(u8 const   *addr ) 
{ 


  {
  return ((unsigned int )(((int )((unsigned short )*((u16 const   *)addr)) & (int )((unsigned short )*((u16 const   *)addr + 2U))) & (int )((unsigned short )*((u16 const   *)addr + 4U))) == 65535U);
}
}
__inline static bool ether_addr_equal(u8 const   *addr1 , u8 const   *addr2 ) 
{ 
  u32 fold ;

  {
  fold = ((unsigned int )*((u32 const   *)addr1) ^ (unsigned int )*((u32 const   *)addr2)) | (unsigned int )((int )((unsigned short )*((u16 const   *)addr1 + 4U)) ^ (int )((unsigned short )*((u16 const   *)addr2 + 4U)));
  return (fold == 0U);
}
}
extern int mdio45_nway_restart(struct mdio_if_info  const  * ) ;
__inline static s32 efx_filter_insert_filter(struct efx_nic *efx , struct efx_filter_spec *spec ,
                                             bool replace_equal ) 
{ 
  s32 tmp ;

  {
  tmp = (*((efx->type)->filter_insert))(efx, spec, (int )replace_equal);
  return (tmp);
}
}
__inline static int efx_filter_remove_id_safe(struct efx_nic *efx , enum efx_filter_priority priority ,
                                              u32 filter_id ) 
{ 
  int tmp ;

  {
  tmp = (*((efx->type)->filter_remove_safe))(efx, priority, filter_id);
  return (tmp);
}
}
__inline static int efx_filter_get_filter_safe(struct efx_nic *efx , enum efx_filter_priority priority ,
                                               u32 filter_id , struct efx_filter_spec *spec ) 
{ 
  int tmp ;

  {
  tmp = (*((efx->type)->filter_get_safe))(efx, priority, filter_id, spec);
  return (tmp);
}
}
__inline static u32 efx_filter_count_rx_used(struct efx_nic *efx , enum efx_filter_priority priority ) 
{ 
  u32 tmp ;

  {
  tmp = (*((efx->type)->filter_count_rx_used))(efx, priority);
  return (tmp);
}
}
__inline static u32 efx_filter_get_rx_id_limit(struct efx_nic *efx ) 
{ 
  u32 tmp ;

  {
  tmp = (*((efx->type)->filter_get_rx_id_limit))(efx);
  return (tmp);
}
}
__inline static s32 efx_filter_get_rx_ids(struct efx_nic *efx , enum efx_filter_priority priority ,
                                          u32 *buf , u32 size ) 
{ 
  s32 tmp ;

  {
  tmp = (*((efx->type)->filter_get_rx_ids))(efx, priority, buf, size);
  return (tmp);
}
}
void efx_mcdi_print_fwver(struct efx_nic *efx , char *buf , size_t len ) ;
void efx_ptp_get_ts_info(struct efx_nic *efx , struct ethtool_ts_info *ts_info ) ;
size_t efx_ptp_describe_stats(struct efx_nic *efx , u8 *strings ) ;
size_t efx_ptp_update_stats(struct efx_nic *efx , u64 *stats ) ;
static u64 efx_get_uint_stat(void *field ) 
{ 


  {
  return ((u64 )*((unsigned int *)field));
}
}
static u64 efx_get_atomic_stat(void *field ) 
{ 
  int tmp ;

  {
  tmp = atomic_read((atomic_t const   *)field);
  return ((u64 )tmp);
}
}
static struct efx_sw_stat_desc  const  efx_sw_stat_desc[14U]  = 
  {      {"tx_merge_events", 2, 136U, & efx_get_uint_stat}, 
        {"tx_tso_bursts", 2, 204U, & efx_get_uint_stat}, 
        {"tx_tso_long_headers", 2, 208U, & efx_get_uint_stat}, 
        {"tx_tso_packets", 2, 212U, & efx_get_uint_stat}, 
        {"tx_pushes", 2, 216U, & efx_get_uint_stat}, 
        {"tx_pio_packets", 2, 220U, & efx_get_uint_stat}, 
        {"rx_reset", 0, 3192U, & efx_get_atomic_stat}, 
        {"rx_tobe_disc", 1, 464U, & efx_get_uint_stat}, 
        {"rx_ip_hdr_chksum_err", 1, 468U, & efx_get_uint_stat}, 
        {"rx_tcp_udp_chksum_err", 1, 472U, & efx_get_uint_stat}, 
        {"rx_mcast_mismatch", 1, 476U, & efx_get_uint_stat}, 
        {"rx_frm_trunc", 1, 480U, & efx_get_uint_stat}, 
        {"rx_merge_events", 1, 496U, & efx_get_uint_stat}, 
        {"rx_merge_packets", 1, 500U, & efx_get_uint_stat}};
static int efx_ethtool_phys_id(struct net_device *net_dev , enum ethtool_phys_id_state state ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  enum efx_led_mode mode ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  mode = 2;
  switch ((unsigned int )state) {
  case 2U: 
  mode = 1;
  goto ldv_55415;
  case 3U: 
  mode = 0;
  goto ldv_55415;
  case 0U: 
  mode = 2;
  goto ldv_55415;
  case 1U: ;
  return (1);
  }
  ldv_55415: 
  (*((efx->type)->set_id_led))(efx, mode);
  return (0);
}
}
static int efx_ethtool_get_settings(struct net_device *net_dev , struct ethtool_cmd *ecmd ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct efx_link_state *link_state ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  link_state = & efx->link_state;
  ldv_mutex_lock_411(& efx->mac_lock);
  (*((efx->phy_op)->get_settings))(efx, ecmd);
  ldv_mutex_unlock_412(& efx->mac_lock);
  ecmd->supported = ecmd->supported | 24576U;
  if ((66600958 >> (int )efx->loopback_mode) & 1) {
    ethtool_cmd_speed_set(ecmd, link_state->speed);
    ecmd->duplex = (__u8 )link_state->fd;
  } else {

  }
  return (0);
}
}
static int efx_ethtool_set_settings(struct net_device *net_dev , struct ethtool_cmd *ecmd ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int rc ;
  struct _ddebug descriptor ;
  long tmp___0 ;
  __u32 tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  tmp___1 = ethtool_cmd_speed((struct ethtool_cmd  const  *)ecmd);
  if (tmp___1 == 1000U && (unsigned int )ecmd->duplex != 1U) {
    if ((int )efx->msg_enable & 1) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_ethtool_set_settings";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ethtool.c";
      descriptor.format = "rejecting unsupported 1000Mbps HD setting\n";
      descriptor.lineno = 153U;
      descriptor.flags = 0U;
      tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp___0 != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "rejecting unsupported 1000Mbps HD setting\n");
      } else {

      }
    } else {

    }
    return (-22);
  } else {

  }
  ldv_mutex_lock_413(& efx->mac_lock);
  rc = (*((efx->phy_op)->set_settings))(efx, ecmd);
  ldv_mutex_unlock_414(& efx->mac_lock);
  return (rc);
}
}
static void efx_ethtool_get_drvinfo(struct net_device *net_dev , struct ethtool_drvinfo *info ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int tmp___0 ;
  char const   *tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  strlcpy((char *)(& info->driver), "sfc", 32UL);
  strlcpy((char *)(& info->version), "4.0", 32UL);
  tmp___0 = efx_nic_rev(efx);
  if (tmp___0 > 2) {
    efx_mcdi_print_fwver(efx, (char *)(& info->fw_version), 32UL);
  } else {

  }
  tmp___1 = pci_name((struct pci_dev  const  *)efx->pci_dev);
  strlcpy((char *)(& info->bus_info), tmp___1, 32UL);
  return;
}
}
static int efx_ethtool_get_regs_len(struct net_device *net_dev ) 
{ 
  void *tmp ;
  size_t tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  tmp___0 = efx_nic_get_regs_len((struct efx_nic *)tmp);
  return ((int )tmp___0);
}
}
static void efx_ethtool_get_regs(struct net_device *net_dev , struct ethtool_regs *regs ,
                                 void *buf ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  regs->version = (__u32 )(efx->type)->revision;
  efx_nic_get_regs(efx, buf);
  return;
}
}
static u32 efx_ethtool_get_msglevel(struct net_device *net_dev ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  return (efx->msg_enable);
}
}
static void efx_ethtool_set_msglevel(struct net_device *net_dev , u32 msg_enable ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  efx->msg_enable = msg_enable;
  return;
}
}
static void efx_fill_test(unsigned int test_index , u8 *strings , u64 *data , int *test ,
                          char const   *unit_format , int unit_id , char const   *test_format ,
                          char const   *test_id ) 
{ 
  char unit_str[32U] ;
  char test_str[32U] ;
  char *tmp ;

  {
  if ((unsigned long )data != (unsigned long )((u64 *)0ULL)) {
    *(data + (unsigned long )test_index) = (u64 )*test;
  } else {

  }
  if ((unsigned long )strings != (unsigned long )((u8 *)0U)) {
    tmp = strchr(unit_format, 37);
    if ((unsigned long )tmp != (unsigned long )((char *)0)) {
      snprintf((char *)(& unit_str), 32UL, unit_format, unit_id);
    } else {
      strcpy((char *)(& unit_str), unit_format);
    }
    snprintf((char *)(& test_str), 32UL, test_format, test_id);
    snprintf((char *)strings + (unsigned long )(test_index * 32U), 32UL, "%-6s %-24s",
             (char *)(& unit_str), (char *)(& test_str));
  } else {

  }
  return;
}
}
static int efx_fill_loopback_test(struct efx_nic *efx , struct efx_loopback_self_tests *lb_tests ,
                                  enum efx_loopback_mode mode , unsigned int test_index ,
                                  u8 *strings , u64 *data ) 
{ 
  struct efx_channel *channel ;
  struct efx_channel *tmp ;
  struct efx_tx_queue *tx_queue ;
  unsigned int tmp___0 ;
  unsigned int tmp___1 ;
  bool tmp___2 ;
  bool tmp___3 ;
  int tmp___4 ;
  unsigned int tmp___5 ;
  unsigned int tmp___6 ;

  {
  tmp = efx_get_channel(efx, efx->tx_channel_offset);
  channel = tmp;
  tmp___3 = efx_channel_has_tx_queues(channel);
  if (tmp___3) {
    tmp___4 = 0;
  } else {
    tmp___4 = 1;
  }
  if (tmp___4) {

  } else {
    tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
    goto ldv_55479;
    ldv_55478: 
    tmp___0 = test_index;
    test_index = test_index + 1U;
    efx_fill_test(tmp___0, strings, data, (int *)(& lb_tests->tx_sent) + (unsigned long )tx_queue->queue,
                  "txq%d", (int )tx_queue->queue, "loopback.%s.tx_sent", (unsigned int )mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )mode] : (char const   */* const  */)"(invalid)");
    tmp___1 = test_index;
    test_index = test_index + 1U;
    efx_fill_test(tmp___1, strings, data, (int *)(& lb_tests->tx_done) + (unsigned long )tx_queue->queue,
                  "txq%d", (int )tx_queue->queue, "loopback.%s.tx_done", (unsigned int )mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )mode] : (char const   */* const  */)"(invalid)");
    tx_queue = tx_queue + 1;
    ldv_55479: ;
    if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
      tmp___2 = efx_tx_queue_used(tx_queue);
      if ((int )tmp___2) {
        goto ldv_55478;
      } else {
        goto ldv_55480;
      }
    } else {

    }
    ldv_55480: ;
  }
  tmp___5 = test_index;
  test_index = test_index + 1U;
  efx_fill_test(tmp___5, strings, data, & lb_tests->rx_good, "rx", 0, "loopback.%s.rx_good",
                (unsigned int )mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )mode] : (char const   */* const  */)"(invalid)");
  tmp___6 = test_index;
  test_index = test_index + 1U;
  efx_fill_test(tmp___6, strings, data, & lb_tests->rx_bad, "rx", 0, "loopback.%s.rx_bad",
                (unsigned int )mode < (unsigned int )efx_loopback_mode_max ? efx_loopback_mode_names[(unsigned int )mode] : (char const   */* const  */)"(invalid)");
  return ((int )test_index);
}
}
static int efx_ethtool_fill_self_tests(struct efx_nic *efx , struct efx_self_tests *tests ,
                                       u8 *strings , u64 *data ) 
{ 
  struct efx_channel *channel ;
  unsigned int n ;
  unsigned int i ;
  enum efx_loopback_mode mode ;
  unsigned int tmp ;
  unsigned int tmp___0 ;
  unsigned int tmp___1 ;
  unsigned int tmp___2 ;
  unsigned int tmp___3 ;
  unsigned int tmp___4 ;
  unsigned int tmp___5 ;
  char const   *name ;
  unsigned int tmp___6 ;
  int tmp___7 ;

  {
  n = 0U;
  tmp = n;
  n = n + 1U;
  efx_fill_test(tmp, strings, data, & tests->phy_alive, "phy", 0, "alive", (char const   *)0);
  tmp___0 = n;
  n = n + 1U;
  efx_fill_test(tmp___0, strings, data, & tests->nvram, "core", 0, "nvram", (char const   *)0);
  tmp___1 = n;
  n = n + 1U;
  efx_fill_test(tmp___1, strings, data, & tests->interrupt, "core", 0, "interrupt",
                (char const   *)0);
  channel = efx->channel[0];
  goto ldv_55492;
  ldv_55491: 
  tmp___2 = n;
  n = n + 1U;
  efx_fill_test(tmp___2, strings, data, (int *)(& tests->eventq_dma) + (unsigned long )channel->channel,
                "chan%d", channel->channel, "eventq.dma", (char const   *)0);
  tmp___3 = n;
  n = n + 1U;
  efx_fill_test(tmp___3, strings, data, (int *)(& tests->eventq_int) + (unsigned long )channel->channel,
                "chan%d", channel->channel, "eventq.int", (char const   *)0);
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_55492: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_55491;
  } else {

  }
  tmp___4 = n;
  n = n + 1U;
  efx_fill_test(tmp___4, strings, data, & tests->memory, "core", 0, "memory", (char const   *)0);
  tmp___5 = n;
  n = n + 1U;
  efx_fill_test(tmp___5, strings, data, & tests->registers, "core", 0, "registers",
                (char const   *)0);
  if ((unsigned long )(efx->phy_op)->run_tests != (unsigned long )((int (*/* const  */)(struct efx_nic * ,
                                                                                        int * ,
                                                                                        unsigned int  ))0)) {
    i = 0U;
    ldv_55496: 
    name = (*((efx->phy_op)->test_name))(efx, i);
    if ((unsigned long )name == (unsigned long )((char const   *)0)) {
      goto ldv_55495;
    } else {

    }
    tmp___6 = n;
    n = n + 1U;
    efx_fill_test(tmp___6, strings, data, (int *)(& tests->phy_ext) + (unsigned long )i,
                  "phy", 0, name, (char const   *)0);
    i = i + 1U;
    goto ldv_55496;
    ldv_55495: ;
  } else {

  }
  mode = 0;
  goto ldv_55499;
  ldv_55498: ;
  if ((efx->loopback_modes & (u64 )(1 << (int )mode)) == 0ULL) {
    goto ldv_55497;
  } else {

  }
  tmp___7 = efx_fill_loopback_test(efx, (struct efx_loopback_self_tests *)(& tests->loopback) + (unsigned long )mode,
                                   mode, n, strings, data);
  n = (unsigned int )tmp___7;
  ldv_55497: 
  mode = (enum efx_loopback_mode )((unsigned int )mode + 1U);
  ldv_55499: ;
  if ((unsigned int )mode <= 17U) {
    goto ldv_55498;
  } else {

  }

  return ((int )n);
}
}
static size_t efx_describe_per_queue_stats(struct efx_nic *efx , u8 *strings ) 
{ 
  size_t n_stats ;
  struct efx_channel *channel ;
  bool tmp ;
  bool tmp___0 ;

  {
  n_stats = 0UL;
  channel = efx->channel[0];
  goto ldv_55508;
  ldv_55507: 
  tmp = efx_channel_has_tx_queues(channel);
  if ((int )tmp) {
    n_stats = n_stats + 1UL;
    if ((unsigned long )strings != (unsigned long )((u8 *)0U)) {
      snprintf((char *)strings, 32UL, "tx-%u.tx_packets", channel->tx_queue[0].queue / 4U);
      strings = strings + 32UL;
    } else {

    }
  } else {

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_55508: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_55507;
  } else {

  }
  channel = efx->channel[0];
  goto ldv_55511;
  ldv_55510: 
  tmp___0 = efx_channel_has_rx_queue(channel);
  if ((int )tmp___0) {
    n_stats = n_stats + 1UL;
    if ((unsigned long )strings != (unsigned long )((u8 *)0U)) {
      snprintf((char *)strings, 32UL, "rx-%d.rx_packets", channel->channel);
      strings = strings + 32UL;
    } else {

    }
  } else {

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_55511: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_55510;
  } else {

  }

  return (n_stats);
}
}
static int efx_ethtool_get_sset_count(struct net_device *net_dev , int string_set ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  size_t tmp___0 ;
  size_t tmp___1 ;
  size_t tmp___2 ;
  int tmp___3 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  switch (string_set) {
  case 1: 
  tmp___0 = (*((efx->type)->describe_stats))(efx, (u8 *)0U);
  tmp___1 = efx_describe_per_queue_stats(efx, (u8 *)0U);
  tmp___2 = efx_ptp_describe_stats(efx, (u8 *)0U);
  return ((int )((((unsigned int )tmp___0 + (unsigned int )tmp___1) + (unsigned int )tmp___2) + 14U));
  case 0: 
  tmp___3 = efx_ethtool_fill_self_tests(efx, (struct efx_self_tests *)0, (u8 *)0U,
                                        (u64 *)0ULL);
  return (tmp___3);
  default: ;
  return (-22);
  }
}
}
static void efx_ethtool_get_strings(struct net_device *net_dev , u32 string_set ,
                                    u8 *strings ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int i ;
  size_t tmp___0 ;
  size_t tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  switch (string_set) {
  case 1U: 
  tmp___0 = (*((efx->type)->describe_stats))(efx, strings);
  strings = strings + tmp___0 * 32UL;
  i = 0;
  goto ldv_55534;
  ldv_55533: 
  strlcpy((char *)strings + (unsigned long )(i * 32), efx_sw_stat_desc[i].name, 32UL);
  i = i + 1;
  ldv_55534: ;
  if ((unsigned int )i <= 13U) {
    goto ldv_55533;
  } else {

  }
  strings = strings + 448UL;
  tmp___1 = efx_describe_per_queue_stats(efx, strings);
  strings = strings + tmp___1 * 32UL;
  efx_ptp_describe_stats(efx, strings);
  goto ldv_55538;
  case 0U: 
  efx_ethtool_fill_self_tests(efx, (struct efx_self_tests *)0, strings, (u64 *)0ULL);
  goto ldv_55538;
  default: ;
  goto ldv_55538;
  }
  ldv_55538: ;
  return;
}
}
static void efx_ethtool_get_stats(struct net_device *net_dev , struct ethtool_stats *stats ,
                                  u64 *data ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct efx_sw_stat_desc  const  *stat ;
  struct efx_channel *channel ;
  struct efx_tx_queue *tx_queue ;
  struct efx_rx_queue *rx_queue ;
  int i ;
  size_t tmp___0 ;
  u64 tmp___1 ;
  u64 tmp___2 ;
  bool tmp___3 ;
  bool tmp___4 ;
  int tmp___5 ;
  bool tmp___6 ;
  bool tmp___7 ;
  int tmp___8 ;
  bool tmp___9 ;
  bool tmp___10 ;
  int tmp___11 ;
  bool tmp___12 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  spin_lock_bh(& efx->stats_lock);
  tmp___0 = (*((efx->type)->update_stats))(efx, data, (struct rtnl_link_stats64 *)0);
  data = data + tmp___0;
  i = 0;
  goto ldv_55568;
  ldv_55567: 
  stat = (struct efx_sw_stat_desc  const  *)(& efx_sw_stat_desc) + (unsigned long )i;
  switch ((unsigned int )stat->source) {
  case 0U: 
  *(data + (unsigned long )i) = (*(stat->get_stat))((void *)efx + (unsigned long )stat->offset);
  goto ldv_55555;
  case 1U: 
  *(data + (unsigned long )i) = 0ULL;
  channel = efx->channel[0];
  goto ldv_55558;
  ldv_55557: 
  tmp___1 = (*(stat->get_stat))((void *)channel + (unsigned long )stat->offset);
  *(data + (unsigned long )i) = *(data + (unsigned long )i) + tmp___1;
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_55558: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_55557;
  } else {

  }

  goto ldv_55555;
  case 2U: 
  *(data + (unsigned long )i) = 0ULL;
  channel = efx->channel[0];
  goto ldv_55565;
  ldv_55564: 
  tmp___4 = efx_channel_has_tx_queues(channel);
  if (tmp___4) {
    tmp___5 = 0;
  } else {
    tmp___5 = 1;
  }
  if (tmp___5) {

  } else {
    tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
    goto ldv_55562;
    ldv_55561: 
    tmp___2 = (*(stat->get_stat))((void *)tx_queue + (unsigned long )stat->offset);
    *(data + (unsigned long )i) = *(data + (unsigned long )i) + tmp___2;
    tx_queue = tx_queue + 1;
    ldv_55562: ;
    if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
      tmp___3 = efx_tx_queue_used(tx_queue);
      if ((int )tmp___3) {
        goto ldv_55561;
      } else {
        goto ldv_55563;
      }
    } else {

    }
    ldv_55563: ;
  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_55565: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_55564;
  } else {

  }

  goto ldv_55555;
  }
  ldv_55555: 
  i = i + 1;
  ldv_55568: ;
  if ((unsigned int )i <= 13U) {
    goto ldv_55567;
  } else {

  }
  data = data + 14UL;
  spin_unlock_bh(& efx->stats_lock);
  channel = efx->channel[0];
  goto ldv_55576;
  ldv_55575: 
  tmp___9 = efx_channel_has_tx_queues(channel);
  if ((int )tmp___9) {
    *data = 0ULL;
    tmp___7 = efx_channel_has_tx_queues(channel);
    if (tmp___7) {
      tmp___8 = 0;
    } else {
      tmp___8 = 1;
    }
    if (tmp___8) {

    } else {
      tx_queue = (struct efx_tx_queue *)(& channel->tx_queue);
      goto ldv_55573;
      ldv_55572: 
      *data = *data + (unsigned long long )tx_queue->tx_packets;
      tx_queue = tx_queue + 1;
      ldv_55573: ;
      if ((unsigned long )((struct efx_tx_queue *)(& channel->tx_queue) + 4UL) > (unsigned long )tx_queue) {
        tmp___6 = efx_tx_queue_used(tx_queue);
        if ((int )tmp___6) {
          goto ldv_55572;
        } else {
          goto ldv_55574;
        }
      } else {

      }
      ldv_55574: ;
    }
    data = data + 1;
  } else {

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_55576: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_55575;
  } else {

  }
  channel = efx->channel[0];
  goto ldv_55582;
  ldv_55581: 
  tmp___12 = efx_channel_has_rx_queue(channel);
  if ((int )tmp___12) {
    *data = 0ULL;
    tmp___10 = efx_channel_has_rx_queue(channel);
    if (tmp___10) {
      tmp___11 = 0;
    } else {
      tmp___11 = 1;
    }
    if (tmp___11) {

    } else {
      rx_queue = & channel->rx_queue;
      goto ldv_55579;
      ldv_55578: 
      *data = *data + (unsigned long long )rx_queue->rx_packets;
      rx_queue = (struct efx_rx_queue *)0;
      ldv_55579: ;
      if ((unsigned long )rx_queue != (unsigned long )((struct efx_rx_queue *)0)) {
        goto ldv_55578;
      } else {

      }

    }
    data = data + 1;
  } else {

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_55582: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_55581;
  } else {

  }
  efx_ptp_update_stats(efx, data);
  return;
}
}
static void efx_ethtool_self_test(struct net_device *net_dev , struct ethtool_test *test ,
                                  u64 *data ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct efx_self_tests *efx_tests ;
  bool already_up ;
  int rc ;
  void *tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  rc = -12;
  tmp___0 = kzalloc(1076UL, 208U);
  efx_tests = (struct efx_self_tests *)tmp___0;
  if ((unsigned long )efx_tests == (unsigned long )((struct efx_self_tests *)0)) {
    goto fail;
  } else {

  }
  if ((unsigned int )efx->state != 1U) {
    rc = -16;
    goto out;
  } else {

  }
  if ((int )efx->msg_enable & 1) {
    netdev_info((struct net_device  const  *)efx->net_dev, "starting %sline testing\n",
                (int )test->flags & 1 ? (char *)"off" : (char *)"on");
  } else {

  }
  already_up = ((efx->net_dev)->flags & 1U) != 0U;
  if (! already_up) {
    rc = dev_open(efx->net_dev);
    if (rc != 0) {
      if ((int )efx->msg_enable & 1) {
        netdev_err((struct net_device  const  *)efx->net_dev, "failed opening device.\n");
      } else {

      }
      goto out;
    } else {

    }
  } else {

  }
  rc = efx_selftest(efx, efx_tests, test->flags);
  if (! already_up) {
    dev_close(efx->net_dev);
  } else {

  }
  if ((int )efx->msg_enable & 1) {
    netdev_info((struct net_device  const  *)efx->net_dev, "%s %sline self-tests\n",
                rc == 0 ? (char *)"passed" : (char *)"failed", (int )test->flags & 1 ? (char *)"off" : (char *)"on");
  } else {

  }
  out: 
  efx_ethtool_fill_self_tests(efx, efx_tests, (u8 *)0U, data);
  kfree((void const   *)efx_tests);
  fail: ;
  if (rc != 0) {
    test->flags = test->flags | 2U;
  } else {

  }
  return;
}
}
static int efx_ethtool_nway_reset(struct net_device *net_dev ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  tmp___0 = mdio45_nway_restart((struct mdio_if_info  const  *)(& efx->mdio));
  return (tmp___0);
}
}
static int efx_ethtool_get_coalesce(struct net_device *net_dev , struct ethtool_coalesce *coalesce ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  unsigned int tx_usecs ;
    klee_make_symbolic(&tx_usecs, sizeof(int), "tx_usecs");
  unsigned int rx_usecs ;
    klee_make_symbolic(&rx_usecs, sizeof(int), "rx_usecs");
  bool rx_adaptive ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  efx_get_irq_moderation(efx, & tx_usecs, & rx_usecs, & rx_adaptive);
  coalesce->tx_coalesce_usecs = tx_usecs;
  coalesce->tx_coalesce_usecs_irq = tx_usecs;
  coalesce->rx_coalesce_usecs = rx_usecs;
  coalesce->rx_coalesce_usecs_irq = rx_usecs;
  coalesce->use_adaptive_rx_coalesce = (__u32 )rx_adaptive;
  return (0);
}
}
static int efx_ethtool_set_coalesce(struct net_device *net_dev , struct ethtool_coalesce *coalesce ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct efx_channel *channel ;
  unsigned int tx_usecs ;
  unsigned int rx_usecs ;
  bool adaptive ;
  bool rx_may_override_tx ;
  int rc ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if (coalesce->use_adaptive_tx_coalesce != 0U) {
    return (-22);
  } else {

  }
  efx_get_irq_moderation(efx, & tx_usecs, & rx_usecs, & adaptive);
  if (coalesce->rx_coalesce_usecs != rx_usecs) {
    rx_usecs = coalesce->rx_coalesce_usecs;
  } else {
    rx_usecs = coalesce->rx_coalesce_usecs_irq;
  }
  adaptive = coalesce->use_adaptive_rx_coalesce != 0U;
  rx_may_override_tx = (bool )(coalesce->tx_coalesce_usecs == tx_usecs && coalesce->tx_coalesce_usecs_irq == tx_usecs);
  if (coalesce->tx_coalesce_usecs != tx_usecs) {
    tx_usecs = coalesce->tx_coalesce_usecs;
  } else {
    tx_usecs = coalesce->tx_coalesce_usecs_irq;
  }
  rc = efx_init_irq_moderation(efx, tx_usecs, rx_usecs, (int )adaptive, (int )rx_may_override_tx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  channel = efx->channel[0];
  goto ldv_55619;
  ldv_55618: 
  (*((efx->type)->push_irq_moderation))(channel);
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_55619: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_55618;
  } else {

  }

  return (0);
}
}
static void efx_ethtool_get_ringparam(struct net_device *net_dev , struct ethtool_ringparam *ring ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  ring->rx_max_pending = 4096U;
  tmp___0 = efx_nic_rev(efx);
  ring->tx_max_pending = tmp___0 == 4 && (int )((struct efx_ef10_nic_data *)efx->nic_data)->workaround_35388 ? 2048U : 4096U;
  ring->rx_pending = efx->rxq_entries;
  ring->tx_pending = efx->txq_entries;
  return;
}
}
static int efx_ethtool_set_ringparam(struct net_device *net_dev , struct ethtool_ringparam *ring ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  u32 txq_entries ;
  int tmp___0 ;
  __u32 _max1 ;
  unsigned int _max2 ;
  unsigned int tmp___1 ;
  int tmp___2 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((ring->rx_mini_pending != 0U || ring->rx_jumbo_pending != 0U) || ring->rx_pending > 4096U) {
    return (-22);
  } else {
    tmp___0 = efx_nic_rev(efx);
    if ((unsigned long )ring->tx_pending > (tmp___0 == 4 && (int )((struct efx_ef10_nic_data *)efx->nic_data)->workaround_35388 ? 2048UL : 4096UL)) {
      return (-22);
    } else {

    }
  }
  if (ring->rx_pending <= 127U) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "RX queues cannot be smaller than %u\n",
                 128U);
    } else {

    }
    return (-22);
  } else {

  }
  _max1 = ring->tx_pending;
  tmp___1 = efx_tx_max_skb_descs(efx);
  _max2 = tmp___1 * 2U;
  txq_entries = _max1 > _max2 ? _max1 : _max2;
  if (ring->tx_pending != txq_entries) {
    if ((int )efx->msg_enable & 1) {
      netdev_warn((struct net_device  const  *)efx->net_dev, "increasing TX queue size to minimum of %u\n",
                  txq_entries);
    } else {

    }
  } else {

  }
  tmp___2 = efx_realloc_channels(efx, ring->rx_pending, txq_entries);
  return (tmp___2);
}
}
static int efx_ethtool_set_pauseparam(struct net_device *net_dev , struct ethtool_pauseparam *pause ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  u8 wanted_fc ;
  u8 old_fc ;
  u32 old_adv ;
  int rc ;
  struct _ddebug descriptor ;
  long tmp___0 ;
  struct _ddebug descriptor___0 ;
  long tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  rc = 0;
  ldv_mutex_lock_415(& efx->mac_lock);
  wanted_fc = (u8 )(((pause->rx_pause != 0U ? 2 : 0) | (pause->tx_pause != 0U)) | (pause->autoneg != 0U ? 4 : 0));
  if ((int )wanted_fc & 1 && ((int )wanted_fc & 2) == 0) {
    if ((int )efx->msg_enable & 1) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_ethtool_set_pauseparam";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ethtool.c";
      descriptor.format = "Flow control unsupported: tx ON rx OFF\n";
      descriptor.lineno = 703U;
      descriptor.flags = 0U;
      tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp___0 != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "Flow control unsupported: tx ON rx OFF\n");
      } else {

      }
    } else {

    }
    rc = -22;
    goto out;
  } else {

  }
  if (((int )wanted_fc & 4) != 0 && efx->link_advertising == 0U) {
    if ((int )efx->msg_enable & 1) {
      descriptor___0.modname = "sfc";
      descriptor___0.function = "efx_ethtool_set_pauseparam";
      descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ethtool.c";
      descriptor___0.format = "Autonegotiation is disabled\n";
      descriptor___0.lineno = 710U;
      descriptor___0.flags = 0U;
      tmp___1 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
      if (tmp___1 != 0L) {
        __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                             "Autonegotiation is disabled\n");
      } else {

      }
    } else {

    }
    rc = -22;
    goto out;
  } else {

  }
  if (((unsigned long )(efx->type)->prepare_enable_fc_tx != (unsigned long )((void (*/* const  */)(struct efx_nic * ))0) && (int )wanted_fc & 1) && ((int )efx->wanted_fc & 1) == 0) {
    (*((efx->type)->prepare_enable_fc_tx))(efx);
  } else {

  }
  old_adv = efx->link_advertising;
  old_fc = efx->wanted_fc;
  efx_link_set_wanted_fc(efx, (int )wanted_fc);
  if (efx->link_advertising != old_adv || (((int )efx->wanted_fc ^ (int )old_fc) & 4) != 0) {
    rc = (*((efx->phy_op)->reconfigure))(efx);
    if (rc != 0) {
      if ((int )efx->msg_enable & 1) {
        netdev_err((struct net_device  const  *)efx->net_dev, "Unable to advertise requested flow control setting\n");
      } else {

      }
      goto out;
    } else {

    }
  } else {

  }
  efx_mac_reconfigure(efx);
  out: 
  ldv_mutex_unlock_416(& efx->mac_lock);
  return (rc);
}
}
static void efx_ethtool_get_pauseparam(struct net_device *net_dev , struct ethtool_pauseparam *pause ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  pause->rx_pause = ((int )efx->wanted_fc & 2) != 0;
  pause->tx_pause = (__u32 )efx->wanted_fc & 1U;
  pause->autoneg = ((int )efx->wanted_fc & 4) != 0;
  return;
}
}
static void efx_ethtool_get_wol(struct net_device *net_dev , struct ethtool_wolinfo *wol ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  return;
}
}
static int efx_ethtool_set_wol(struct net_device *net_dev , struct ethtool_wolinfo *wol ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  tmp___0 = (*((efx->type)->set_wol))(efx, wol->wolopts);
  return (tmp___0);
}
}
static int efx_ethtool_reset(struct net_device *net_dev , u32 *flags ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int rc ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  rc = (*((efx->type)->map_reset_flags))(flags);
  if (rc < 0) {
    return (rc);
  } else {

  }
  tmp___0 = efx_reset(efx, (enum reset_type )rc);
  return (tmp___0);
}
}
static u8 const   mac_addr_ig_mask[6U]  = {      1U,      0U,      0U,      0U, 
        0U,      0U};
static int efx_ethtool_get_class_rule(struct efx_nic *efx , struct ethtool_rx_flow_spec *rule ) 
{ 
  struct ethtool_tcpip4_spec *ip_entry ;
  struct ethtool_tcpip4_spec *ip_mask ;
  struct ethhdr *mac_entry ;
  struct ethhdr *mac_mask ;
  struct efx_filter_spec spec ;
  int rc ;
  int __ret_warn_on ;
  long tmp ;

  {
  ip_entry = & rule->h_u.tcp_ip4_spec;
  ip_mask = & rule->m_u.tcp_ip4_spec;
  mac_entry = & rule->h_u.ether_spec;
  mac_mask = & rule->m_u.ether_spec;
  rc = efx_filter_get_filter_safe(efx, 2, rule->location, & spec);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if ((unsigned int )*((unsigned short *)(& spec) + 1UL) == 65520U) {
    rule->ring_cookie = 0xffffffffffffffffULL;
  } else {
    rule->ring_cookie = (__u64 )spec.dmaq_id;
  }
  if ((((((int )spec.match_flags & 64) != 0 && (unsigned int )spec.ether_type == 8U) && ((int )spec.match_flags & 512) != 0) && ((unsigned int )spec.ip_proto == 6U || (unsigned int )spec.ip_proto == 17U)) && ((int )spec.match_flags & -876) == 0) {
    rule->flow_type = (unsigned int )spec.ip_proto == 6U ? 1U : 2U;
    if (((int )spec.match_flags & 2) != 0) {
      ip_entry->ip4dst = spec.loc_host[0];
      ip_mask->ip4dst = 4294967295U;
    } else {

    }
    if ((int )spec.match_flags & 1) {
      ip_entry->ip4src = spec.rem_host[0];
      ip_mask->ip4src = 4294967295U;
    } else {

    }
    if (((int )spec.match_flags & 32) != 0) {
      ip_entry->pdst = spec.loc_port;
      ip_mask->pdst = 65535U;
    } else {

    }
    if (((int )spec.match_flags & 8) != 0) {
      ip_entry->psrc = spec.rem_port;
      ip_mask->psrc = 65535U;
    } else {

    }
  } else
  if (((int )spec.match_flags & -1365) == 0) {
    rule->flow_type = 18U;
    if (((int )spec.match_flags & 1040) != 0) {
      ether_addr_copy((u8 *)(& mac_entry->h_dest), (u8 const   *)(& spec.loc_mac));
      if (((int )spec.match_flags & 16) != 0) {
        eth_broadcast_addr((u8 *)(& mac_mask->h_dest));
      } else {
        ether_addr_copy((u8 *)(& mac_mask->h_dest), (u8 const   *)(& mac_addr_ig_mask));
      }
    } else {

    }
    if (((int )spec.match_flags & 4) != 0) {
      ether_addr_copy((u8 *)(& mac_entry->h_source), (u8 const   *)(& spec.rem_mac));
      eth_broadcast_addr((u8 *)(& mac_mask->h_source));
    } else {

    }
    if (((int )spec.match_flags & 64) != 0) {
      mac_entry->h_proto = spec.ether_type;
      mac_mask->h_proto = 65535U;
    } else {

    }
  } else {
    __ret_warn_on = 1;
    tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp != 0L) {
      warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ethtool.c",
                         860);
    } else {

    }
    ldv__builtin_expect(__ret_warn_on != 0, 0L);
    return (-22);
  }
  if (((int )spec.match_flags & 256) != 0) {
    rule->flow_type = rule->flow_type | 2147483648U;
    rule->h_ext.vlan_tci = spec.outer_vid;
    rule->m_ext.vlan_tci = 65295U;
  } else {

  }
  return (rc);
}
}
static int efx_ethtool_get_rxnfc(struct net_device *net_dev , struct ethtool_rxnfc *info ,
                                 u32 *rule_locs ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  unsigned int min_revision ;
    klee_make_symbolic(&min_revision, sizeof(int), "min_revision");
  int tmp___0 ;
  u32 tmp___1 ;
  u32 tmp___2 ;
  int tmp___3 ;
  s32 rc ;
  u32 tmp___4 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  switch (info->cmd) {
  case 45U: 
  info->data = (__u64 )efx->n_rx_channels;
  return (0);
  case 41U: 
  min_revision = 0U;
  info->data = 0ULL;
  switch (info->flow_type) {
  case 1U: 
  info->data = info->data | 192ULL;
  case 2U: ;
  case 3U: ;
  case 4U: ;
  case 16U: 
  info->data = info->data | 48ULL;
  min_revision = 2U;
  goto ldv_55696;
  case 5U: 
  info->data = info->data | 192ULL;
  case 6U: ;
  case 7U: ;
  case 8U: ;
  case 17U: 
  info->data = info->data | 48ULL;
  min_revision = 3U;
  goto ldv_55696;
  default: ;
  goto ldv_55696;
  }
  ldv_55696: 
  tmp___0 = efx_nic_rev(efx);
  if ((unsigned int )tmp___0 < min_revision) {
    info->data = 0ULL;
  } else {

  }
  return (0);
  case 46U: 
  tmp___1 = efx_filter_get_rx_id_limit(efx);
  info->data = (__u64 )tmp___1;
  if (info->data == 0ULL) {
    return (-95);
  } else {

  }
  info->data = info->data | 2147483648ULL;
  info->rule_cnt = efx_filter_count_rx_used(efx, 2);
  return (0);
  case 47U: 
  tmp___2 = efx_filter_get_rx_id_limit(efx);
  if (tmp___2 == 0U) {
    return (-95);
  } else {

  }
  tmp___3 = efx_ethtool_get_class_rule(efx, & info->fs);
  return (tmp___3);
  case 48U: 
  tmp___4 = efx_filter_get_rx_id_limit(efx);
  info->data = (__u64 )tmp___4;
  if (info->data == 0ULL) {
    return (-95);
  } else {

  }
  rc = efx_filter_get_rx_ids(efx, 2, rule_locs, info->rule_cnt);
  if (rc < 0) {
    return (rc);
  } else {

  }
  info->rule_cnt = (__u32 )rc;
  return (0);
  default: ;
  return (-95);
  }
}
}
static int efx_ethtool_set_class_rule(struct efx_nic *efx , struct ethtool_rx_flow_spec *rule ) 
{ 
  struct ethtool_tcpip4_spec *ip_entry ;
  struct ethtool_tcpip4_spec *ip_mask ;
  struct ethhdr *mac_entry ;
  struct ethhdr *mac_mask ;
  struct efx_filter_spec spec ;
  int rc ;
  bool tmp ;
  bool tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  bool tmp___3 ;
  int tmp___4 ;
  bool tmp___5 ;
  int tmp___6 ;

  {
  ip_entry = & rule->h_u.tcp_ip4_spec;
  ip_mask = & rule->m_u.tcp_ip4_spec;
  mac_entry = & rule->h_u.ether_spec;
  mac_mask = & rule->m_u.ether_spec;
  if (rule->location != 4294967295U) {
    return (-22);
  } else {

  }
  if (rule->ring_cookie >= (__u64 )efx->n_rx_channels && rule->ring_cookie != 0xffffffffffffffffULL) {
    return (-22);
  } else {

  }
  if ((int )rule->flow_type < 0 && (((unsigned int )rule->m_ext.vlan_etype != 0U || rule->m_ext.data[0] != 0U) || rule->m_ext.data[1] != 0U)) {
    return (-22);
  } else {

  }
  efx_filter_init_rx(& spec, 2, (int )efx->rx_scatter ? 2 : 0, rule->ring_cookie != 0xffffffffffffffffULL ? (unsigned int )rule->ring_cookie : 4095U);
  switch (rule->flow_type & 2147483647U) {
  case 1U: ;
  case 2U: 
  spec.match_flags = 576U;
  spec.ether_type = 8U;
  spec.ip_proto = (rule->flow_type & 2147483647U) == 1U ? 6U : 17U;
  if (ip_mask->ip4dst != 0U) {
    if (ip_mask->ip4dst != 4294967295U) {
      return (-22);
    } else {

    }
    spec.match_flags = (unsigned short )((unsigned int )spec.match_flags | 2U);
    spec.loc_host[0] = ip_entry->ip4dst;
  } else {

  }
  if (ip_mask->ip4src != 0U) {
    if (ip_mask->ip4src != 4294967295U) {
      return (-22);
    } else {

    }
    spec.match_flags = (unsigned short )((unsigned int )spec.match_flags | 1U);
    spec.rem_host[0] = ip_entry->ip4src;
  } else {

  }
  if ((unsigned int )ip_mask->pdst != 0U) {
    if ((unsigned int )ip_mask->pdst != 65535U) {
      return (-22);
    } else {

    }
    spec.match_flags = (unsigned short )((unsigned int )spec.match_flags | 32U);
    spec.loc_port = ip_entry->pdst;
  } else {

  }
  if ((unsigned int )ip_mask->psrc != 0U) {
    if ((unsigned int )ip_mask->psrc != 65535U) {
      return (-22);
    } else {

    }
    spec.match_flags = (unsigned short )((unsigned int )spec.match_flags | 8U);
    spec.rem_port = ip_entry->psrc;
  } else {

  }
  if ((unsigned int )ip_mask->tos != 0U) {
    return (-22);
  } else {

  }
  goto ldv_55720;
  case 18U: 
  tmp___1 = is_zero_ether_addr((u8 const   *)(& mac_mask->h_dest));
  if (tmp___1) {
    tmp___2 = 0;
  } else {
    tmp___2 = 1;
  }
  if (tmp___2) {
    tmp___0 = ether_addr_equal((u8 const   *)(& mac_mask->h_dest), (u8 const   *)(& mac_addr_ig_mask));
    if ((int )tmp___0) {
      spec.match_flags = (unsigned short )((unsigned int )spec.match_flags | 1024U);
    } else {
      tmp = is_broadcast_ether_addr((u8 const   *)(& mac_mask->h_dest));
      if ((int )tmp) {
        spec.match_flags = (unsigned short )((unsigned int )spec.match_flags | 16U);
      } else {
        return (-22);
      }
    }
    ether_addr_copy((u8 *)(& spec.loc_mac), (u8 const   *)(& mac_entry->h_dest));
  } else {

  }
  tmp___5 = is_zero_ether_addr((u8 const   *)(& mac_mask->h_source));
  if (tmp___5) {
    tmp___6 = 0;
  } else {
    tmp___6 = 1;
  }
  if (tmp___6) {
    tmp___3 = is_broadcast_ether_addr((u8 const   *)(& mac_mask->h_source));
    if (tmp___3) {
      tmp___4 = 0;
    } else {
      tmp___4 = 1;
    }
    if (tmp___4) {
      return (-22);
    } else {

    }
    spec.match_flags = (unsigned short )((unsigned int )spec.match_flags | 4U);
    ether_addr_copy((u8 *)(& spec.rem_mac), (u8 const   *)(& mac_entry->h_source));
  } else {

  }
  if ((unsigned int )mac_mask->h_proto != 0U) {
    if ((unsigned int )mac_mask->h_proto != 65535U) {
      return (-22);
    } else {

    }
    spec.match_flags = (unsigned short )((unsigned int )spec.match_flags | 64U);
    spec.ether_type = mac_entry->h_proto;
  } else {

  }
  goto ldv_55720;
  default: ;
  return (-22);
  }
  ldv_55720: ;
  if ((int )rule->flow_type < 0 && (unsigned int )rule->m_ext.vlan_tci != 0U) {
    if ((unsigned int )rule->m_ext.vlan_tci != 65295U) {
      return (-22);
    } else {

    }
    spec.match_flags = (unsigned short )((unsigned int )spec.match_flags | 256U);
    spec.outer_vid = rule->h_ext.vlan_tci;
  } else {

  }
  rc = efx_filter_insert_filter(efx, & spec, 1);
  if (rc < 0) {
    return (rc);
  } else {

  }
  rule->location = (__u32 )rc;
  return (0);
}
}
static int efx_ethtool_set_rxnfc(struct net_device *net_dev , struct ethtool_rxnfc *info ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  u32 tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  tmp___0 = efx_filter_get_rx_id_limit(efx);
  if (tmp___0 == 0U) {
    return (-95);
  } else {

  }
  switch (info->cmd) {
  case 50U: 
  tmp___1 = efx_ethtool_set_class_rule(efx, & info->fs);
  return (tmp___1);
  case 49U: 
  tmp___2 = efx_filter_remove_id_safe(efx, 2, info->fs.location);
  return (tmp___2);
  default: ;
  return (-95);
  }
}
}
static u32 efx_ethtool_get_rxfh_indir_size(struct net_device *net_dev ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  tmp___0 = efx_nic_rev(efx);
  return (tmp___0 <= 1 || efx->n_rx_channels == 1U ? 0U : 128U);
}
}
static int efx_ethtool_get_rxfh(struct net_device *net_dev , u32 *indir , u8 *key ,
                                u8 *hfunc ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((unsigned long )hfunc != (unsigned long )((u8 *)0U)) {
    *hfunc = 1U;
  } else {

  }
  if ((unsigned long )indir != (unsigned long )((u32 *)0U)) {
    memcpy((void *)indir, (void const   *)(& efx->rx_indir_table), 512UL);
  } else {

  }
  return (0);
}
}
static int efx_ethtool_set_rxfh(struct net_device *net_dev , u32 const   *indir ,
                                u8 const   *key , u8 const   hfunc ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((unsigned long )key != (unsigned long )((u8 const   *)0U) || ((unsigned int )((unsigned char )hfunc) != 0U && (unsigned int )((unsigned char )hfunc) != 1U)) {
    return (-95);
  } else {

  }
  if ((unsigned long )indir == (unsigned long )((u32 const   *)0U)) {
    return (0);
  } else {

  }
  tmp___0 = (*((efx->type)->rx_push_rss_config))(efx, 1, indir);
  return (tmp___0);
}
}
static int efx_ethtool_get_ts_info(struct net_device *net_dev , struct ethtool_ts_info *ts_info ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  ts_info->so_timestamping = 24U;
  ts_info->phc_index = -1;
  efx_ptp_get_ts_info(efx, ts_info);
  return (0);
}
}
static int efx_ethtool_get_module_eeprom(struct net_device *net_dev , struct ethtool_eeprom *ee ,
                                         u8 *data ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int ret ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((unsigned long )efx->phy_op == (unsigned long )((struct efx_phy_operations  const  *)0) || (unsigned long )(efx->phy_op)->get_module_eeprom == (unsigned long )((int (*/* const  */)(struct efx_nic * ,
                                                                                                                                                                                           struct ethtool_eeprom * ,
                                                                                                                                                                                           u8 * ))0)) {
    return (-95);
  } else {

  }
  ldv_mutex_lock_417(& efx->mac_lock);
  ret = (*((efx->phy_op)->get_module_eeprom))(efx, ee, data);
  ldv_mutex_unlock_418(& efx->mac_lock);
  return (ret);
}
}
static int efx_ethtool_get_module_info(struct net_device *net_dev , struct ethtool_modinfo *modinfo ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int ret ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((unsigned long )efx->phy_op == (unsigned long )((struct efx_phy_operations  const  *)0) || (unsigned long )(efx->phy_op)->get_module_info == (unsigned long )((int (*/* const  */)(struct efx_nic * ,
                                                                                                                                                                                         struct ethtool_modinfo * ))0)) {
    return (-95);
  } else {

  }
  ldv_mutex_lock_419(& efx->mac_lock);
  ret = (*((efx->phy_op)->get_module_info))(efx, modinfo);
  ldv_mutex_unlock_420(& efx->mac_lock);
  return (ret);
}
}
struct ethtool_ops  const  efx_ethtool_ops  = 
     {& efx_ethtool_get_settings, & efx_ethtool_set_settings, & efx_ethtool_get_drvinfo,
    & efx_ethtool_get_regs_len, & efx_ethtool_get_regs, & efx_ethtool_get_wol, & efx_ethtool_set_wol,
    & efx_ethtool_get_msglevel, & efx_ethtool_set_msglevel, & efx_ethtool_nway_reset,
    & ethtool_op_get_link, 0, 0, 0, & efx_ethtool_get_coalesce, & efx_ethtool_set_coalesce,
    & efx_ethtool_get_ringparam, & efx_ethtool_set_ringparam, & efx_ethtool_get_pauseparam,
    & efx_ethtool_set_pauseparam, & efx_ethtool_self_test, & efx_ethtool_get_strings,
    & efx_ethtool_phys_id, & efx_ethtool_get_stats, 0, 0, 0, 0, & efx_ethtool_get_sset_count,
    & efx_ethtool_get_rxnfc, & efx_ethtool_set_rxnfc, 0, & efx_ethtool_reset, 0, & efx_ethtool_get_rxfh_indir_size,
    & efx_ethtool_get_rxfh, & efx_ethtool_set_rxfh, 0, 0, 0, 0, 0, & efx_ethtool_get_ts_info,
    & efx_ethtool_get_module_info, & efx_ethtool_get_module_eeprom, 0, 0, 0, 0};
void ldv_initialize_ethtool_ops_22(void) 
{ 
  void *tmp ;
  void *tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  void *tmp___4 ;
  void *tmp___5 ;

  {
  tmp = ldv_init_zalloc(92UL);
  efx_ethtool_ops_group3 = (struct ethtool_coalesce *)tmp;
  tmp___0 = ldv_init_zalloc(36UL);
  efx_ethtool_ops_group0 = (struct ethtool_ringparam *)tmp___0;
  tmp___1 = ldv_init_zalloc(3008UL);
  efx_ethtool_ops_group4 = (struct net_device *)tmp___1;
  tmp___2 = ldv_init_zalloc(44UL);
  efx_ethtool_ops_group1 = (struct ethtool_cmd *)tmp___2;
  tmp___3 = ldv_init_zalloc(192UL);
  efx_ethtool_ops_group5 = (struct ethtool_rxnfc *)tmp___3;
  tmp___4 = ldv_init_zalloc(20UL);
  efx_ethtool_ops_group6 = (struct ethtool_wolinfo *)tmp___4;
  tmp___5 = ldv_init_zalloc(16UL);
  efx_ethtool_ops_group2 = (struct ethtool_pauseparam *)tmp___5;
  return;
}
}
void ldv_main_exported_22(void) 
{ 
  int ldvarg201 ;
    klee_make_symbolic(&ldvarg201, sizeof(int), "ldvarg201");
  u32 *ldvarg206 ;
  void *tmp ;
  u32 *ldvarg199 ;
  void *tmp___0 ;
  struct ethtool_test *ldvarg198 ;
  void *tmp___1 ;
  u8 *ldvarg189 ;
  void *tmp___2 ;
  u32 *ldvarg205 ;
  void *tmp___3 ;
  u64 *ldvarg197 ;
  void *tmp___4 ;
  struct ethtool_modinfo *ldvarg196 ;
  void *tmp___5 ;
  void *ldvarg194 ;
  void *tmp___6 ;
  u64 *ldvarg183 ;
  void *tmp___7 ;
  u32 ldvarg200 ;
  u8 *ldvarg191 ;
  void *tmp___8 ;
  u8 *ldvarg192 ;
  void *tmp___9 ;
  struct ethtool_ts_info *ldvarg188 ;
  void *tmp___10 ;
  struct ethtool_drvinfo *ldvarg185 ;
  void *tmp___11 ;
  u32 *ldvarg193 ;
  void *tmp___12 ;
  struct ethtool_eeprom *ldvarg190 ;
  void *tmp___13 ;
  struct ethtool_stats *ldvarg184 ;
  void *tmp___14 ;
  u8 *ldvarg186 ;
  void *tmp___15 ;
  enum ethtool_phys_id_state ldvarg202 ;
  u32 ldvarg187 ;
  struct ethtool_regs *ldvarg195 ;
  void *tmp___16 ;
  u8 ldvarg203 ;
  u8 *ldvarg204 ;
  void *tmp___17 ;
  int tmp___18 ;

  {
  tmp = ldv_init_zalloc(4UL);
  ldvarg206 = (u32 *)tmp;
  tmp___0 = ldv_init_zalloc(4UL);
  ldvarg199 = (u32 *)tmp___0;
  tmp___1 = ldv_init_zalloc(16UL);
  ldvarg198 = (struct ethtool_test *)tmp___1;
  tmp___2 = ldv_init_zalloc(1UL);
  ldvarg189 = (u8 *)tmp___2;
  tmp___3 = ldv_init_zalloc(4UL);
  ldvarg205 = (u32 *)tmp___3;
  tmp___4 = ldv_init_zalloc(8UL);
  ldvarg197 = (u64 *)tmp___4;
  tmp___5 = ldv_init_zalloc(44UL);
  ldvarg196 = (struct ethtool_modinfo *)tmp___5;
  tmp___6 = ldv_init_zalloc(1UL);
  ldvarg194 = tmp___6;
  tmp___7 = ldv_init_zalloc(8UL);
  ldvarg183 = (u64 *)tmp___7;
  tmp___8 = ldv_init_zalloc(1UL);
  ldvarg191 = (u8 *)tmp___8;
  tmp___9 = ldv_init_zalloc(1UL);
  ldvarg192 = (u8 *)tmp___9;
  tmp___10 = ldv_init_zalloc(44UL);
  ldvarg188 = (struct ethtool_ts_info *)tmp___10;
  tmp___11 = ldv_init_zalloc(196UL);
  ldvarg185 = (struct ethtool_drvinfo *)tmp___11;
  tmp___12 = ldv_init_zalloc(4UL);
  ldvarg193 = (u32 *)tmp___12;
  tmp___13 = ldv_init_zalloc(16UL);
  ldvarg190 = (struct ethtool_eeprom *)tmp___13;
  tmp___14 = ldv_init_zalloc(8UL);
  ldvarg184 = (struct ethtool_stats *)tmp___14;
  tmp___15 = ldv_init_zalloc(1UL);
  ldvarg186 = (u8 *)tmp___15;
  tmp___16 = ldv_init_zalloc(12UL);
  ldvarg195 = (struct ethtool_regs *)tmp___16;
  tmp___17 = ldv_init_zalloc(1UL);
  ldvarg204 = (u8 *)tmp___17;
  ldv_memset((void *)(& ldvarg201), 0, 4UL);
  ldv_memset((void *)(& ldvarg200), 0, 4UL);
  ldv_memset((void *)(& ldvarg202), 0, 4UL);
  ldv_memset((void *)(& ldvarg187), 0, 4UL);
  ldv_memset((void *)(& ldvarg203), 0, 1UL);
  tmp___18 = __VERIFIER_nondet_int();
  switch (tmp___18) {
  case 0: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_rxnfc(efx_ethtool_ops_group4, efx_ethtool_ops_group5, ldvarg206);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 1: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_ringparam(efx_ethtool_ops_group4, efx_ethtool_ops_group0);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 2: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_set_rxfh(efx_ethtool_ops_group4, (u32 const   *)ldvarg205, (u8 const   *)ldvarg204,
                         (int )ldvarg203);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 3: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_phys_id(efx_ethtool_ops_group4, ldvarg202);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 4: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_pauseparam(efx_ethtool_ops_group4, efx_ethtool_ops_group2);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 5: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_sset_count(efx_ethtool_ops_group4, ldvarg201);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 6: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_set_coalesce(efx_ethtool_ops_group4, efx_ethtool_ops_group3);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 7: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_set_msglevel(efx_ethtool_ops_group4, ldvarg200);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 8: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_reset(efx_ethtool_ops_group4, ldvarg199);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 9: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_self_test(efx_ethtool_ops_group4, ldvarg198, ldvarg197);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 10: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_nway_reset(efx_ethtool_ops_group4);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 11: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_module_info(efx_ethtool_ops_group4, ldvarg196);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 12: ;
  if (ldv_state_variable_22 == 1) {
    ethtool_op_get_link(efx_ethtool_ops_group4);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 13: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_set_pauseparam(efx_ethtool_ops_group4, efx_ethtool_ops_group2);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 14: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_coalesce(efx_ethtool_ops_group4, efx_ethtool_ops_group3);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 15: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_regs(efx_ethtool_ops_group4, ldvarg195, ldvarg194);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 16: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_rxfh_indir_size(efx_ethtool_ops_group4);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 17: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_set_wol(efx_ethtool_ops_group4, efx_ethtool_ops_group6);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 18: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_set_settings(efx_ethtool_ops_group4, efx_ethtool_ops_group1);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 19: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_wol(efx_ethtool_ops_group4, efx_ethtool_ops_group6);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 20: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_regs_len(efx_ethtool_ops_group4);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 21: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_set_ringparam(efx_ethtool_ops_group4, efx_ethtool_ops_group0);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 22: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_set_rxnfc(efx_ethtool_ops_group4, efx_ethtool_ops_group5);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 23: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_rxfh(efx_ethtool_ops_group4, ldvarg193, ldvarg192, ldvarg191);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 24: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_settings(efx_ethtool_ops_group4, efx_ethtool_ops_group1);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 25: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_module_eeprom(efx_ethtool_ops_group4, ldvarg190, ldvarg189);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 26: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_ts_info(efx_ethtool_ops_group4, ldvarg188);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 27: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_strings(efx_ethtool_ops_group4, ldvarg187, ldvarg186);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 28: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_drvinfo(efx_ethtool_ops_group4, ldvarg185);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 29: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_stats(efx_ethtool_ops_group4, ldvarg184, ldvarg183);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  case 30: ;
  if (ldv_state_variable_22 == 1) {
    efx_ethtool_get_msglevel(efx_ethtool_ops_group4);
    ldv_state_variable_22 = 1;
  } else {

  }
  goto ldv_55801;
  default: 
  ldv_stop();
  }
  ldv_55801: ;
  return;
}
}
bool ldv_queue_work_on_399(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_400(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_401(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_402(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_403(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_404(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_405(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_406(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_407(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_408(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_409(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_410(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_411(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_412(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_413(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_414(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_415(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_416(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_417(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_418(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_419(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_420(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
int ldv_mutex_trylock_455(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_453(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_456(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_457(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_452(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_454(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_458(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_447(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_449(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_448(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_451(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_450(struct workqueue_struct *ldv_func_arg1 ) ;
extern int mdio_set_flag(struct mdio_if_info  const  * , int  , int  , u16  , int  ,
                         bool  ) ;
extern void mdio45_ethtool_gset_npage(struct mdio_if_info  const  * , struct ethtool_cmd * ,
                                      u32  , u32  ) ;
__inline static void mdio45_ethtool_gset(struct mdio_if_info  const  *mdio , struct ethtool_cmd *ecmd ) 
{ 


  {
  mdio45_ethtool_gset_npage(mdio, ecmd, 0U, 0U);
  return;
}
}
__inline static unsigned int efx_mdio_id_rev(u32 id ) 
{ 


  {
  return (id & 15U);
}
}
__inline static unsigned int efx_mdio_id_model(u32 id ) 
{ 


  {
  return ((id >> 4) & 63U);
}
}
unsigned int efx_mdio_id_oui(u32 id ) ;
__inline static void efx_mdio_write(struct efx_nic *efx , int devad , int addr , int value ) 
{ 


  {
  (*(efx->mdio.mdio_write))(efx->net_dev, efx->mdio.prtad, devad, (int )((u16 )addr),
                            (int )((u16 )value));
  return;
}
}
__inline static u32 efx_mdio_read_id(struct efx_nic *efx , int mmd ) 
{ 
  u16 id_low ;
  int tmp ;
  u16 id_hi ;
  int tmp___0 ;

  {
  tmp = efx_mdio_read(efx, mmd, 3);
  id_low = (u16 )tmp;
  tmp___0 = efx_mdio_read(efx, mmd, 2);
  id_hi = (u16 )tmp___0;
  return ((u32 )(((int )id_hi << 16) | (int )id_low));
}
}
int efx_mdio_reset_mmd(struct efx_nic *port , int mmd , int spins , int spintime ) ;
bool efx_mdio_links_ok(struct efx_nic *efx , unsigned int mmd_mask ) ;
void efx_mdio_transmit_disable(struct efx_nic *efx ) ;
void efx_mdio_phy_reconfigure(struct efx_nic *efx ) ;
int efx_mdio_set_settings(struct efx_nic *efx , struct ethtool_cmd *ecmd ) ;
__inline static void efx_mdio_set_flag(struct efx_nic *efx , int devad , int addr ,
                                       int mask , bool state ) 
{ 


  {
  mdio_set_flag((struct mdio_if_info  const  *)(& efx->mdio), efx->mdio.prtad, devad,
                (int )((u16 )addr), mask, (int )state);
  return;
}
}
int efx_mdio_test_alive(struct efx_nic *efx ) ;
void falcon_qt202x_set_led(struct efx_nic *p , int led , int mode ) ;
void falcon_qt202x_set_led(struct efx_nic *p , int led , int mode ) 
{ 
  int addr ;

  {
  addr = led + 53254;
  efx_mdio_write(p, 1, addr, mode);
  return;
}
}
static int qt2025c_wait_heartbeat(struct efx_nic *efx ) 
{ 
  unsigned long timeout ;
  int reg ;
    klee_make_symbolic(&reg, sizeof(int), "reg");
  int old_counter ;
    klee_make_symbolic(&old_counter, sizeof(int), "old_counter");
  int counter ;

  {
  timeout = (unsigned long )jiffies + 1250UL;
  old_counter = 0;
  ldv_55442: 
  reg = efx_mdio_read(efx, 3, 55278);
  if (reg < 0) {
    return (reg);
  } else {

  }
  counter = reg & 255;
  if (old_counter == 0) {
    old_counter = counter;
  } else
  if (counter != old_counter) {
    goto ldv_55435;
  } else {

  }
  if ((long )(timeout - (unsigned long )jiffies) < 0L) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "If an SFP+ direct attach cable is connected, please check that it complies with the SFP+ specification\n");
    } else {

    }
    return (-110);
  } else {

  }
  msleep(100U);
  goto ldv_55442;
  ldv_55435: ;
  return (0);
}
}
static int qt2025c_wait_fw_status_good(struct efx_nic *efx ) 
{ 
  unsigned long timeout ;
  int reg ;

  {
  timeout = (unsigned long )jiffies + 625UL;
  ldv_55455: 
  reg = efx_mdio_read(efx, 3, 55293);
  if (reg < 0) {
    return (reg);
  } else {

  }
  if ((reg & 255) > 31) {
    goto ldv_55448;
  } else {

  }
  if ((long )(timeout - (unsigned long )jiffies) < 0L) {
    return (-110);
  } else {

  }
  msleep(100U);
  goto ldv_55455;
  ldv_55448: ;
  return (0);
}
}
static void qt2025c_restart_firmware(struct efx_nic *efx ) 
{ 


  {
  efx_mdio_write(efx, 3, 59476, 192);
  efx_mdio_write(efx, 3, 59476, 64);
  msleep(50U);
  return;
}
}
static int qt2025c_wait_reset(struct efx_nic *efx ) 
{ 
  int rc ;
  struct _ddebug descriptor ;
  long tmp ;

  {
  rc = qt2025c_wait_heartbeat(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = qt2025c_wait_fw_status_good(efx);
  if (rc == -110) {
    if ((efx->msg_enable & 8192U) != 0U) {
      descriptor.modname = "sfc";
      descriptor.function = "qt2025c_wait_reset";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/qt202x_phy.c";
      descriptor.format = "bashing QT2025C microcontroller\n";
      descriptor.lineno = 152U;
      descriptor.flags = 0U;
      tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "bashing QT2025C microcontroller\n");
      } else {

      }
    } else {

    }
    qt2025c_restart_firmware(efx);
    rc = qt2025c_wait_heartbeat(efx);
    if (rc != 0) {
      return (rc);
    } else {

    }
    rc = qt2025c_wait_fw_status_good(efx);
  } else {

  }
  return (rc);
}
}
static void qt2025c_firmware_id(struct efx_nic *efx ) 
{ 
  struct qt202x_phy_data *phy_data ;
  u8 firmware_id[9U] ;
  size_t i ;
  int tmp ;

  {
  phy_data = (struct qt202x_phy_data *)efx->phy_data;
  i = 0UL;
  goto ldv_55472;
  ldv_55471: 
  tmp = efx_mdio_read(efx, 3, (int )((unsigned int )i + 55280U));
  firmware_id[i] = (u8 )tmp;
  i = i + 1UL;
  ldv_55472: ;
  if (i <= 8UL) {
    goto ldv_55471;
  } else {

  }

  if ((efx->msg_enable & 2U) != 0U) {
    netdev_info((struct net_device  const  *)efx->net_dev, "QT2025C firmware %xr%d v%d.%d.%d.%d [20%02d-%02d-%02d]\n",
                ((int )firmware_id[0] << 8) | (int )firmware_id[1], (int )firmware_id[2],
                (int )firmware_id[3] >> 4, (int )firmware_id[3] & 15, (int )firmware_id[4],
                (int )firmware_id[5], (int )firmware_id[6], (int )firmware_id[7],
                (int )firmware_id[8]);
  } else {

  }
  phy_data->firmware_ver = (u32 )((((((int )firmware_id[3] & 240) << 20) | (((int )firmware_id[3] & 15) << 16)) | ((int )firmware_id[4] << 8)) | (int )firmware_id[5]);
  return;
}
}
static void qt2025c_bug17190_workaround(struct efx_nic *efx ) 
{ 
  struct qt202x_phy_data *phy_data ;
  bool tmp ;
  int tmp___0 ;
  struct _ddebug descriptor ;
  long tmp___1 ;

  {
  phy_data = (struct qt202x_phy_data *)efx->phy_data;
  if ((int )efx->link_state.up) {
    phy_data->bug17190_in_bad_state = 0;
    return;
  } else {
    tmp = efx_mdio_links_ok(efx, 18U);
    if (tmp) {
      tmp___0 = 0;
    } else {
      tmp___0 = 1;
    }
    if (tmp___0) {
      phy_data->bug17190_in_bad_state = 0;
      return;
    } else {

    }
  }
  if (! phy_data->bug17190_in_bad_state) {
    phy_data->bug17190_in_bad_state = 1;
    phy_data->bug17190_timer = (unsigned long )jiffies + 500UL;
    return;
  } else {

  }
  if ((long )((unsigned long )jiffies - phy_data->bug17190_timer) >= 0L) {
    if ((efx->msg_enable & 8192U) != 0U) {
      descriptor.modname = "sfc";
      descriptor.function = "qt2025c_bug17190_workaround";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/qt202x_phy.c";
      descriptor.format = "bashing QT2025C PMA/PMD\n";
      descriptor.lineno = 206U;
      descriptor.flags = 0U;
      tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp___1 != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "bashing QT2025C PMA/PMD\n");
      } else {

      }
    } else {

    }
    efx_mdio_set_flag(efx, 1, 0, 1, 1);
    msleep(100U);
    efx_mdio_set_flag(efx, 1, 0, 1, 0);
    phy_data->bug17190_timer = (unsigned long )jiffies + 500UL;
  } else {

  }
  return;
}
}
static int qt2025c_select_phy_mode(struct efx_nic *efx ) 
{ 
  struct qt202x_phy_data *phy_data ;
  struct falcon_board *board ;
  struct falcon_board *tmp ;
  int reg ;
  int rc ;
  int i ;
  uint16_t phy_op_mode ;
  struct _ddebug descriptor ;
  long tmp___0 ;

  {
  phy_data = (struct qt202x_phy_data *)efx->phy_data;
  tmp = falcon_board(efx);
  board = tmp;
  if (phy_data->firmware_ver <= 33554687U) {
    return (0);
  } else {

  }
  phy_op_mode = (unsigned int )efx->loopback_mode == 0U ? 56U : 32U;
  reg = efx_mdio_read(efx, 1, 49945);
  if ((reg & 56) == (int )phy_op_mode) {
    return (0);
  } else {

  }
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "qt2025c_select_phy_mode";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/qt202x_phy.c";
    descriptor.format = "Switching PHY to mode 0x%04x\n";
    descriptor.lineno = 240U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "Switching PHY to mode 0x%04x\n", (int )phy_op_mode);
    } else {

    }
  } else {

  }
  efx_mdio_write(efx, 1, 49920, 0);
  if (board->major == 0 && board->minor <= 1) {
    efx_mdio_write(efx, 1, 49923, 17560);
    i = 0;
    goto ldv_55498;
    ldv_55497: 
    efx_mdio_write(efx, 1, 49923, 17544);
    efx_mdio_write(efx, 1, 49923, 17536);
    efx_mdio_write(efx, 1, 49923, 17552);
    efx_mdio_write(efx, 1, 49923, 17560);
    i = i + 1;
    ldv_55498: ;
    if (i <= 8) {
      goto ldv_55497;
    } else {

    }

  } else {
    efx_mdio_write(efx, 1, 49923, 2336);
    efx_mdio_write(efx, 1, 53256, 4);
    i = 0;
    goto ldv_55501;
    ldv_55500: 
    efx_mdio_write(efx, 1, 49923, 2304);
    efx_mdio_write(efx, 1, 53256, 5);
    efx_mdio_write(efx, 1, 49923, 2336);
    efx_mdio_write(efx, 1, 53256, 4);
    i = i + 1;
    ldv_55501: ;
    if (i <= 8) {
      goto ldv_55500;
    } else {

    }
    efx_mdio_write(efx, 1, 49923, 18688);
  }
  efx_mdio_write(efx, 1, 49923, 18688);
  efx_mdio_write(efx, 1, 49922, 4);
  efx_mdio_write(efx, 1, 49942, 19);
  efx_mdio_write(efx, 1, 49944, 84);
  efx_mdio_write(efx, 1, 49945, (int )phy_op_mode);
  efx_mdio_write(efx, 1, 49946, 152);
  efx_mdio_write(efx, 3, 38, 3584);
  efx_mdio_write(efx, 3, 39, 19);
  efx_mdio_write(efx, 3, 40, 42280);
  efx_mdio_write(efx, 1, 53254, 10);
  efx_mdio_write(efx, 1, 53255, 9);
  efx_mdio_write(efx, 1, 53256, 4);
  efx_mdio_write(efx, 1, 49943, 255);
  efx_mdio_set_flag(efx, 1, 49921, 64, 0);
  efx_mdio_write(efx, 1, 49920, 2);
  msleep(20U);
  qt2025c_restart_firmware(efx);
  rc = qt2025c_wait_reset(efx);
  if (rc < 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "PHY microcontroller reset during mode switch timed out\n");
    } else {

    }
    return (rc);
  } else {

  }
  return (0);
}
}
static int qt202x_reset_phy(struct efx_nic *efx ) 
{ 
  int rc ;
  struct falcon_board *tmp ;

  {
  if (efx->phy_type == 9U) {
    rc = qt2025c_wait_reset(efx);
    if (rc < 0) {
      goto fail;
    } else {

    }
  } else {
    rc = efx_mdio_reset_mmd(efx, 4, 50, 10);
    if (rc < 0) {
      goto fail;
    } else {

    }
  }
  msleep(250U);
  tmp = falcon_board(efx);
  (*((tmp->type)->init_phy))(efx);
  return (0);
  fail: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "PHY reset timed out\n");
  } else {

  }
  return (rc);
}
}
static int qt202x_phy_probe(struct efx_nic *efx ) 
{ 
  struct qt202x_phy_data *phy_data ;
  void *tmp ;

  {
  tmp = kzalloc(24UL, 208U);
  phy_data = (struct qt202x_phy_data *)tmp;
  if ((unsigned long )phy_data == (unsigned long )((struct qt202x_phy_data *)0)) {
    return (-12);
  } else {

  }
  efx->phy_data = (void *)phy_data;
  phy_data->phy_mode = efx->phy_mode;
  phy_data->bug17190_in_bad_state = 0;
  phy_data->bug17190_timer = 0UL;
  efx->mdio.mmds = 26U;
  efx->mdio.mode_support = 6U;
  efx->loopback_modes = 67305528ULL;
  return (0);
}
}
static int qt202x_phy_init(struct efx_nic *efx ) 
{ 
  u32 devid ;
  int rc ;
  unsigned int tmp ;
  unsigned int tmp___0 ;
  unsigned int tmp___1 ;

  {
  rc = qt202x_reset_phy(efx);
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "PHY init failed\n");
    } else {

    }
    return (rc);
  } else {

  }
  devid = efx_mdio_read_id(efx, 4);
  if ((efx->msg_enable & 2U) != 0U) {
    tmp = efx_mdio_id_rev(devid);
    tmp___0 = efx_mdio_id_model(devid);
    tmp___1 = efx_mdio_id_oui(devid);
    netdev_info((struct net_device  const  *)efx->net_dev, "PHY ID reg %x (OUI %06x model %02x revision %x)\n",
                devid, tmp___1, tmp___0, tmp);
  } else {

  }
  if (efx->phy_type == 9U) {
    qt2025c_firmware_id(efx);
  } else {

  }
  return (0);
}
}
static int qt202x_link_ok(struct efx_nic *efx ) 
{ 
  bool tmp ;

  {
  tmp = efx_mdio_links_ok(efx, 26U);
  return ((int )tmp);
}
}
static bool qt202x_phy_poll(struct efx_nic *efx ) 
{ 
  bool was_up ;
  int tmp ;

  {
  was_up = efx->link_state.up;
  tmp = qt202x_link_ok(efx);
  efx->link_state.up = tmp != 0;
  efx->link_state.speed = 10000U;
  efx->link_state.fd = 1;
  efx->link_state.fc = efx->wanted_fc;
  if (efx->phy_type == 9U) {
    qt2025c_bug17190_workaround(efx);
  } else {

  }
  return ((int )efx->link_state.up != (int )was_up);
}
}
static int qt202x_phy_reconfigure(struct efx_nic *efx ) 
{ 
  struct qt202x_phy_data *phy_data ;
  int rc ;
  int tmp ;

  {
  phy_data = (struct qt202x_phy_data *)efx->phy_data;
  if (efx->phy_type == 9U) {
    tmp = qt2025c_select_phy_mode(efx);
    rc = tmp;
    if (rc != 0) {
      return (rc);
    } else {

    }
    mdio_set_flag((struct mdio_if_info  const  *)(& efx->mdio), efx->mdio.prtad, 1,
                  49929, 8192, (int )((bool )((((int )efx->phy_mode & 1 || ((unsigned int )efx->phy_mode & 2U) != 0U) || (unsigned int )efx->loopback_mode == 16U) || (unsigned int )efx->loopback_mode == 17U)));
  } else {
    if (((unsigned int )efx->phy_mode & 1U) == 0U && (int )phy_data->phy_mode & 1) {
      qt202x_reset_phy(efx);
    } else {

    }
    efx_mdio_transmit_disable(efx);
  }
  efx_mdio_phy_reconfigure(efx);
  phy_data->phy_mode = efx->phy_mode;
  return (0);
}
}
static void qt202x_phy_get_settings(struct efx_nic *efx , struct ethtool_cmd *ecmd ) 
{ 


  {
  mdio45_ethtool_gset((struct mdio_if_info  const  *)(& efx->mdio), ecmd);
  return;
}
}
static void qt202x_phy_remove(struct efx_nic *efx ) 
{ 


  {
  kfree((void const   *)efx->phy_data);
  efx->phy_data = (void *)0;
  return;
}
}
static int qt202x_phy_get_module_info(struct efx_nic *efx , struct ethtool_modinfo *modinfo ) 
{ 


  {
  modinfo->type = 1U;
  modinfo->eeprom_len = 256U;
  return (0);
}
}
static int qt202x_phy_get_module_eeprom(struct efx_nic *efx , struct ethtool_eeprom *ee ,
                                        u8 *data ) 
{ 
  int mmd ;
    klee_make_symbolic(&mmd, sizeof(int), "mmd");
  int reg_base ;
    klee_make_symbolic(&reg_base, sizeof(int), "reg_base");
  int rc ;
  int i ;

  {
  if (efx->phy_type == 9U) {
    mmd = 3;
    reg_base = 53248;
  } else {
    mmd = 1;
    reg_base = 32775;
  }
  i = 0;
  goto ldv_55550;
  ldv_55549: 
  rc = efx_mdio_read(efx, mmd, (int )((ee->offset + (__u32 )reg_base) + (__u32 )i));
  if (rc < 0) {
    return (rc);
  } else {

  }
  *(data + (unsigned long )i) = (u8 )rc;
  i = i + 1;
  ldv_55550: ;
  if ((__u32 )i < ee->len) {
    goto ldv_55549;
  } else {

  }

  return (0);
}
}
struct efx_phy_operations  const  falcon_qt202x_phy_ops  = 
     {& qt202x_phy_probe, & qt202x_phy_init, & efx_port_dummy_op_void, & qt202x_phy_remove,
    & qt202x_phy_reconfigure, & qt202x_phy_poll, & qt202x_phy_get_settings, & efx_mdio_set_settings,
    0, & efx_mdio_test_alive, 0, 0, & qt202x_phy_get_module_eeprom, & qt202x_phy_get_module_info};
void ldv_initialize_efx_phy_operations_21(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
  tmp = ldv_init_zalloc(44UL);
  falcon_qt202x_phy_ops_group0 = (struct ethtool_cmd *)tmp;
  tmp___0 = ldv_init_zalloc(4032UL);
  falcon_qt202x_phy_ops_group1 = (struct efx_nic *)tmp___0;
  return;
}
}
void ldv_main_exported_21(void) 
{ 
  struct ethtool_eeprom *ldvarg2 ;
  void *tmp ;
  struct ethtool_modinfo *ldvarg3 ;
  void *tmp___0 ;
  u8 *ldvarg1 ;
  void *tmp___1 ;
  int tmp___2 ;

  {
  tmp = ldv_init_zalloc(16UL);
  ldvarg2 = (struct ethtool_eeprom *)tmp;
  tmp___0 = ldv_init_zalloc(44UL);
  ldvarg3 = (struct ethtool_modinfo *)tmp___0;
  tmp___1 = ldv_init_zalloc(1UL);
  ldvarg1 = (u8 *)tmp___1;
  tmp___2 = __VERIFIER_nondet_int();
  switch (tmp___2) {
  case 0: ;
  if (ldv_state_variable_21 == 1) {
    qt202x_phy_get_module_info(falcon_qt202x_phy_ops_group1, ldvarg3);
    ldv_state_variable_21 = 1;
  } else {

  }
  goto ldv_55563;
  case 1: ;
  if (ldv_state_variable_21 == 1) {
    qt202x_phy_reconfigure(falcon_qt202x_phy_ops_group1);
    ldv_state_variable_21 = 1;
  } else {

  }
  goto ldv_55563;
  case 2: ;
  if (ldv_state_variable_21 == 1) {
    efx_mdio_set_settings(falcon_qt202x_phy_ops_group1, falcon_qt202x_phy_ops_group0);
    ldv_state_variable_21 = 1;
  } else {

  }
  goto ldv_55563;
  case 3: ;
  if (ldv_state_variable_21 == 1) {
    efx_mdio_test_alive(falcon_qt202x_phy_ops_group1);
    ldv_state_variable_21 = 1;
  } else {

  }
  goto ldv_55563;
  case 4: ;
  if (ldv_state_variable_21 == 1) {
    qt202x_phy_remove(falcon_qt202x_phy_ops_group1);
    ldv_state_variable_21 = 1;
  } else {

  }
  goto ldv_55563;
  case 5: ;
  if (ldv_state_variable_21 == 1) {
    qt202x_phy_get_settings(falcon_qt202x_phy_ops_group1, falcon_qt202x_phy_ops_group0);
    ldv_state_variable_21 = 1;
  } else {

  }
  goto ldv_55563;
  case 6: ;
  if (ldv_state_variable_21 == 1) {
    qt202x_phy_get_module_eeprom(falcon_qt202x_phy_ops_group1, ldvarg2, ldvarg1);
    ldv_state_variable_21 = 1;
  } else {

  }
  goto ldv_55563;
  case 7: ;
  if (ldv_state_variable_21 == 1) {
    qt202x_phy_probe(falcon_qt202x_phy_ops_group1);
    ldv_state_variable_21 = 1;
  } else {

  }
  goto ldv_55563;
  case 8: ;
  if (ldv_state_variable_21 == 1) {
    efx_port_dummy_op_void(falcon_qt202x_phy_ops_group1);
    ldv_state_variable_21 = 1;
  } else {

  }
  goto ldv_55563;
  case 9: ;
  if (ldv_state_variable_21 == 1) {
    qt202x_phy_poll(falcon_qt202x_phy_ops_group1);
    ldv_state_variable_21 = 1;
  } else {

  }
  goto ldv_55563;
  case 10: ;
  if (ldv_state_variable_21 == 1) {
    qt202x_phy_init(falcon_qt202x_phy_ops_group1);
    ldv_state_variable_21 = 1;
  } else {

  }
  goto ldv_55563;
  default: 
  ldv_stop();
  }
  ldv_55563: ;
  return;
}
}
bool ldv_queue_work_on_447(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_448(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_449(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_450(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_451(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_452(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_453(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_454(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_455(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_456(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_457(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_458(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
int ldv_mutex_trylock_485(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_480(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_483(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_486(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_488(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_481(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_482(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_484(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_487(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_475(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_477(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_476(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_479(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_478(struct workqueue_struct *ldv_func_arg1 ) ;
__inline static u16 mii_advertise_flowctrl(int cap ) 
{ 
  u16 adv ;

  {
  adv = 0U;
  if ((cap & 2) != 0) {
    adv = 3072U;
  } else {

  }
  if (cap & 1) {
    adv = (u16 )((unsigned int )adv ^ 2048U);
  } else {

  }
  return (adv);
}
}
__inline static u8 mii_resolve_flowctrl_fdx(u16 lcladv , u16 rmtadv ) 
{ 
  u8 cap ;

  {
  cap = 0U;
  if ((((int )lcladv & (int )rmtadv) & 1024) != 0) {
    cap = 3U;
  } else
  if ((((int )lcladv & (int )rmtadv) & 2048) != 0) {
    if (((int )lcladv & 1024) != 0) {
      cap = 2U;
    } else
    if (((int )rmtadv & 1024) != 0) {
      cap = 1U;
    } else {

    }
  } else {

  }
  return (cap);
}
}
extern int mdio45_links_ok(struct mdio_if_info  const  * , u32  ) ;
int efx_mdio_check_mmds(struct efx_nic *efx , unsigned int mmd_mask ) ;
void efx_mdio_set_mmds_lpower(struct efx_nic *efx , int low_power , unsigned int mmd_mask ) ;
void efx_mdio_an_reconfigure(struct efx_nic *efx ) ;
u8 efx_mdio_get_pause(struct efx_nic *efx ) ;
int efx_mdio_wait_reset_mmds(struct efx_nic *efx , unsigned int mmd_mask ) ;
unsigned int efx_mdio_id_oui(u32 id ) 
{ 
  unsigned int oui ;
    klee_make_symbolic(&oui, sizeof(int), "oui");
  int i ;

  {
  oui = 0U;
  i = 0;
  goto ldv_54530;
  ldv_54529: ;
  if (((u32 )(1 << (i + 10)) & id) != 0U) {
    oui = (unsigned int )(1 << (i ^ 7)) | oui;
  } else {

  }
  i = i + 1;
  ldv_54530: ;
  if (i <= 21) {
    goto ldv_54529;
  } else {

  }

  return (oui);
}
}
int efx_mdio_reset_mmd(struct efx_nic *port , int mmd , int spins , int spintime ) 
{ 
  u32 ctrl ;
  int tmp ;

  {
  efx_mdio_write(port, mmd, 0, 32768);
  ldv_54539: 
  msleep((unsigned int )spintime);
  tmp = efx_mdio_read(port, mmd, 0);
  ctrl = (u32 )tmp;
  spins = spins - 1;
  if (spins != 0 && (ctrl & 32768U) != 0U) {
    goto ldv_54539;
  } else {

  }

  return (spins != 0 ? spins : -110);
}
}
static int efx_mdio_check_mmd(struct efx_nic *efx , int mmd ) 
{ 
  int status ;
    klee_make_symbolic(&status, sizeof(int), "status");

  {
  if (mmd != 7) {
    status = efx_mdio_read(efx, mmd, 8);
    if ((status & 49152) != 32768) {
      if ((efx->msg_enable & 8192U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "PHY MMD %d not responding.\n",
                   mmd);
      } else {

      }
      return (-5);
    } else {

    }
  } else {

  }
  return (0);
}
}
int efx_mdio_wait_reset_mmds(struct efx_nic *efx , unsigned int mmd_mask ) 
{ 
  int spintime ;
    klee_make_symbolic(&spintime, sizeof(int), "spintime");
  int tries ;
    klee_make_symbolic(&tries, sizeof(int), "tries");
  int rc ;
  int in_reset ;
    klee_make_symbolic(&in_reset, sizeof(int), "in_reset");
  int mask ;
  int mmd ;
  int stat ;
    klee_make_symbolic(&stat, sizeof(int), "stat");

  {
  spintime = 10;
  tries = 100;
  rc = 0;
  goto ldv_54562;
  ldv_54561: 
  mask = (int )mmd_mask;
  mmd = 0;
  in_reset = 0;
  goto ldv_54558;
  ldv_54557: ;
  if (mask & 1) {
    stat = efx_mdio_read(efx, mmd, 0);
    if (stat < 0) {
      if ((efx->msg_enable & 8192U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "failed to read status of MMD %d\n",
                   mmd);
      } else {

      }
      return (-5);
    } else {

    }
    if ((stat & 32768) != 0) {
      in_reset = (1 << mmd) | in_reset;
    } else {

    }
  } else {

  }
  mask = mask >> 1;
  mmd = mmd + 1;
  ldv_54558: ;
  if (mask != 0) {
    goto ldv_54557;
  } else {

  }

  if (in_reset == 0) {
    goto ldv_54560;
  } else {

  }
  tries = tries - 1;
  msleep((unsigned int )spintime);
  ldv_54562: ;
  if (tries != 0) {
    goto ldv_54561;
  } else {

  }
  ldv_54560: ;
  if (in_reset != 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "not all MMDs came out of reset in time. MMDs still in reset: %x\n",
                 in_reset);
    } else {

    }
    rc = -110;
  } else {

  }
  return (rc);
}
}
int efx_mdio_check_mmds(struct efx_nic *efx , unsigned int mmd_mask ) 
{ 
  int mmd ;
  int probe_mmd ;
    klee_make_symbolic(&probe_mmd, sizeof(int), "probe_mmd");
  int devs1 ;
    klee_make_symbolic(&devs1, sizeof(int), "devs1");
  int devs2 ;
    klee_make_symbolic(&devs2, sizeof(int), "devs2");
  u32 devices ;
  unsigned long tmp ;
  int tmp___0 ;

  {
  mmd = 0;
  if ((mmd_mask & 16U) == 0U) {
    tmp = __ffs((unsigned long )mmd_mask);
    probe_mmd = (int )tmp;
  } else {
    probe_mmd = 4;
  }
  devs1 = efx_mdio_read(efx, probe_mmd, 5);
  devs2 = efx_mdio_read(efx, probe_mmd, 6);
  if (devs1 < 0 || devs2 < 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "failed to read devices present\n");
    } else {

    }
    return (-5);
  } else {

  }
  devices = (u32 )((devs2 << 16) | devs1);
  if ((devices & mmd_mask) != mmd_mask) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "required MMDs not present: got %x, wanted %x\n",
                 devices, mmd_mask);
    } else {

    }
    return (-19);
  } else {

  }
  goto ldv_54574;
  ldv_54573: ;
  if ((int )mmd_mask & 1) {
    tmp___0 = efx_mdio_check_mmd(efx, mmd);
    if (tmp___0 != 0) {
      return (-5);
    } else {

    }
  } else {

  }
  mmd_mask = mmd_mask >> 1;
  mmd = mmd + 1;
  ldv_54574: ;
  if (mmd_mask != 0U) {
    goto ldv_54573;
  } else {

  }

  return (0);
}
}
bool efx_mdio_links_ok(struct efx_nic *efx , unsigned int mmd_mask ) 
{ 
  bool tmp ;
  int tmp___0 ;

  {
  if ((66600958 >> (int )efx->loopback_mode) & 1) {
    return (1);
  } else
  if ((133693440 >> (int )efx->loopback_mode) & 1) {
    return (0);
  } else {
    tmp = efx_phy_mode_disabled(efx->phy_mode);
    if ((int )tmp) {
      return (0);
    } else
    if ((unsigned int )efx->loopback_mode == 15U) {
      mmd_mask = mmd_mask & 4294967141U;
    } else
    if ((unsigned int )efx->loopback_mode == 16U) {
      mmd_mask = mmd_mask & 4294967157U;
    } else
    if ((unsigned int )efx->loopback_mode == 17U) {
      mmd_mask = mmd_mask & 4294967165U;
    } else {

    }
  }
  tmp___0 = mdio45_links_ok((struct mdio_if_info  const  *)(& efx->mdio), mmd_mask);
  return (tmp___0 != 0);
}
}
void efx_mdio_transmit_disable(struct efx_nic *efx ) 
{ 


  {
  efx_mdio_set_flag(efx, 1, 9, 1, (int )efx->phy_mode & 1);
  return;
}
}
void efx_mdio_phy_reconfigure(struct efx_nic *efx ) 
{ 


  {
  efx_mdio_set_flag(efx, 1, 0, 1, (unsigned int )efx->loopback_mode == 17U);
  efx_mdio_set_flag(efx, 3, 0, 16384, (unsigned int )efx->loopback_mode == 16U);
  efx_mdio_set_flag(efx, 4, 0, 16384, (unsigned int )efx->loopback_mode == 26U);
  return;
}
}
static void efx_mdio_set_mmd_lpower(struct efx_nic *efx , int lpower , int mmd ) 
{ 
  int stat ;
  int tmp ;

  {
  tmp = efx_mdio_read(efx, mmd, 1);
  stat = tmp;
  if ((stat & 2) != 0) {
    efx_mdio_set_flag(efx, mmd, 0, 2048, lpower != 0);
  } else {

  }
  return;
}
}
void efx_mdio_set_mmds_lpower(struct efx_nic *efx , int low_power , unsigned int mmd_mask ) 
{ 
  int mmd ;

  {
  mmd = 0;
  mmd_mask = mmd_mask & 4294967167U;
  goto ldv_54600;
  ldv_54599: ;
  if ((int )mmd_mask & 1) {
    efx_mdio_set_mmd_lpower(efx, low_power, mmd);
  } else {

  }
  mmd_mask = mmd_mask >> 1;
  mmd = mmd + 1;
  ldv_54600: ;
  if (mmd_mask != 0U) {
    goto ldv_54599;
  } else {

  }

  return;
}
}
int efx_mdio_set_settings(struct efx_nic *efx , struct ethtool_cmd *ecmd ) 
{ 
  struct ethtool_cmd prev ;
  __u32 tmp ;
  __u32 tmp___0 ;

  {
  prev.cmd = 1U;
  prev.supported = 0U;
  prev.advertising = 0U;
  prev.speed = (unsigned short)0;
  prev.duplex = (unsigned char)0;
  prev.port = (unsigned char)0;
  prev.phy_address = (unsigned char)0;
  prev.transceiver = (unsigned char)0;
  prev.autoneg = (unsigned char)0;
  prev.mdio_support = (unsigned char)0;
  prev.maxtxpkt = 0U;
  prev.maxrxpkt = 0U;
  prev.speed_hi = (unsigned short)0;
  prev.eth_tp_mdix = (unsigned char)0;
  prev.eth_tp_mdix_ctrl = (unsigned char)0;
  prev.lp_advertising = 0U;
  prev.reserved[0] = 0U;
  prev.reserved[1] = 0U;
  (*((efx->phy_op)->get_settings))(efx, & prev);
  if (ecmd->advertising == prev.advertising) {
    tmp = ethtool_cmd_speed((struct ethtool_cmd  const  *)ecmd);
    tmp___0 = ethtool_cmd_speed((struct ethtool_cmd  const  *)(& prev));
    if (tmp == tmp___0) {
      if ((int )ecmd->duplex == (int )prev.duplex) {
        if ((int )ecmd->port == (int )prev.port) {
          if ((int )ecmd->autoneg == (int )prev.autoneg) {
            return (0);
          } else {

          }
        } else {

        }
      } else {

      }
    } else {

    }
  } else {

  }
  if ((unsigned int )prev.port != 0U || (unsigned int )ecmd->port != 0U) {
    return (-22);
  } else {

  }
  if ((unsigned int )ecmd->autoneg == 0U || ((ecmd->advertising | 64U) & ~ prev.supported) != 0U) {
    return (-22);
  } else {

  }
  efx_link_set_advertising(efx, ecmd->advertising | 64U);
  efx_mdio_an_reconfigure(efx);
  return (0);
}
}
void efx_mdio_an_reconfigure(struct efx_nic *efx ) 
{ 
  int reg ;
  int __ret_warn_on ;
  long tmp ;

  {
  __ret_warn_on = (efx->mdio.mmds & 128U) == 0U;
  tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mdio_10g.c",
                       268);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  reg = 4097;
  if ((efx->link_advertising & 8192U) != 0U) {
    reg = reg | 1024;
  } else {

  }
  if ((efx->link_advertising & 16384U) != 0U) {
    reg = reg | 2048;
  } else {

  }
  efx_mdio_write(efx, 7, 16, reg);
  (*((efx->phy_op)->set_npage_adv))(efx, efx->link_advertising);
  reg = efx_mdio_read(efx, 7, 0);
  reg = reg | 12800;
  efx_mdio_write(efx, 7, 0, reg);
  return;
}
}
u8 efx_mdio_get_pause(struct efx_nic *efx ) 
{ 
  int __ret_warn_on ;
  long tmp ;
  int tmp___0 ;
  u16 tmp___1 ;
  u8 tmp___2 ;

  {
  if (((int )efx->wanted_fc & 4) == 0) {
    return (efx->wanted_fc);
  } else {

  }
  __ret_warn_on = (efx->mdio.mmds & 128U) == 0U;
  tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mdio_10g.c",
                       294);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  tmp___0 = efx_mdio_read(efx, 7, 19);
  tmp___1 = mii_advertise_flowctrl((int )efx->wanted_fc);
  tmp___2 = mii_resolve_flowctrl_fdx((int )tmp___1, (int )((u16 )tmp___0));
  return (tmp___2);
}
}
int efx_mdio_test_alive(struct efx_nic *efx ) 
{ 
  int rc ;
  int devad ;
    klee_make_symbolic(&devad, sizeof(int), "devad");
  unsigned long tmp ;
  u16 physid1 ;
  u16 physid2 ;
  int tmp___0 ;
  int tmp___1 ;

  {
  tmp = __ffs((unsigned long )efx->mdio.mmds);
  devad = (int )tmp;
  ldv_mutex_lock_487(& efx->mac_lock);
  tmp___0 = efx_mdio_read(efx, devad, 2);
  physid1 = (u16 )tmp___0;
  tmp___1 = efx_mdio_read(efx, devad, 3);
  physid2 = (u16 )tmp___1;
  if ((((unsigned int )physid1 == 0U || (unsigned int )physid1 == 65535U) || (unsigned int )physid2 == 0U) || (unsigned int )physid2 == 65535U) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "no MDIO PHY present with ID %d\n",
                 efx->mdio.prtad);
    } else {

    }
    rc = -22;
  } else {
    rc = efx_mdio_check_mmds(efx, efx->mdio.mmds);
  }
  ldv_mutex_unlock_488(& efx->mac_lock);
  return (rc);
}
}
bool ldv_queue_work_on_475(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_476(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_477(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_478(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_479(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_480(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_481(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_482(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_483(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_484(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_485(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_486(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_487(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_488(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_515(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_513(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_516(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_517(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_512(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_514(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_518(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_507(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_509(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_508(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_511(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_510(struct workqueue_struct *ldv_func_arg1 ) ;
void tenxpress_set_id_led(struct efx_nic *efx , enum efx_led_mode mode ) ;
static int tenxpress_init(struct efx_nic *efx ) 
{ 


  {
  efx_mdio_write(efx, 3, 55303, 8);
  efx_mdio_set_flag(efx, 1, 49159, 8, 1);
  efx_mdio_write(efx, 1, 49161, 128);
  return (0);
}
}
static int tenxpress_phy_probe(struct efx_nic *efx ) 
{ 
  struct tenxpress_phy_data *phy_data ;
  void *tmp ;

  {
  tmp = kzalloc(12UL, 208U);
  phy_data = (struct tenxpress_phy_data *)tmp;
  if ((unsigned long )phy_data == (unsigned long )((struct tenxpress_phy_data *)0)) {
    return (-12);
  } else {

  }
  efx->phy_data = (void *)phy_data;
  phy_data->phy_mode = efx->phy_mode;
  efx->mdio.mmds = 154U;
  efx->mdio.mode_support = 2U;
  efx->loopback_modes = 67338296ULL;
  efx->link_advertising = 4288U;
  return (0);
}
}
static int tenxpress_phy_init(struct efx_nic *efx ) 
{ 
  int rc ;
  struct falcon_board *tmp ;

  {
  tmp = falcon_board(efx);
  (*((tmp->type)->init_phy))(efx);
  if (((unsigned int )efx->phy_mode & 8U) == 0U) {
    rc = efx_mdio_wait_reset_mmds(efx, 154U);
    if (rc < 0) {
      return (rc);
    } else {

    }
    rc = efx_mdio_check_mmds(efx, 154U);
    if (rc < 0) {
      return (rc);
    } else {

    }
  } else {

  }
  rc = tenxpress_init(efx);
  if (rc < 0) {
    return (rc);
  } else {

  }
  efx_link_set_wanted_fc(efx, (int )efx->wanted_fc);
  efx_mdio_an_reconfigure(efx);
  schedule_timeout_uninterruptible(50L);
  falcon_reset_xaui(efx);
  return (0);
}
}
static int tenxpress_special_reset(struct efx_nic *efx ) 
{ 
  int rc ;
  int reg ;
  unsigned long __ms ;
    klee_make_symbolic(&__ms, sizeof(long), "__ms");
  unsigned long tmp ;
  unsigned long __ms___0 ;
    klee_make_symbolic(&__ms___0, sizeof(long), "__ms___0");
  unsigned long tmp___0 ;

  {
  falcon_stop_nic_stats(efx);
  reg = efx_mdio_read(efx, 1, 49152);
  reg = reg | 32768;
  efx_mdio_write(efx, 1, 49152, reg);
  __ms = 200UL;
  goto ldv_55439;
  ldv_55438: 
  __const_udelay(4295000UL);
  ldv_55439: 
  tmp = __ms;
  __ms = __ms - 1UL;
  if (tmp != 0UL) {
    goto ldv_55438;
  } else {

  }
  rc = efx_mdio_wait_reset_mmds(efx, 154U);
  if (rc < 0) {
    goto out;
  } else {

  }
  rc = tenxpress_init(efx);
  if (rc < 0) {
    goto out;
  } else {

  }
  __ms___0 = 10UL;
  goto ldv_55444;
  ldv_55443: 
  __const_udelay(4295000UL);
  ldv_55444: 
  tmp___0 = __ms___0;
  __ms___0 = __ms___0 - 1UL;
  if (tmp___0 != 0UL) {
    goto ldv_55443;
  } else {

  }

  out: 
  falcon_start_nic_stats(efx);
  return (rc);
}
}
static void sfx7101_check_bad_lp(struct efx_nic *efx , bool link_ok ) 
{ 
  struct tenxpress_phy_data *pd ;
  bool bad_lp ;
  int reg ;

  {
  pd = (struct tenxpress_phy_data *)efx->phy_data;
  if ((int )link_ok) {
    bad_lp = 0;
  } else {
    reg = efx_mdio_read(efx, 7, 1);
    if ((reg & 1) == 0) {
      return;
    } else {

    }
    bad_lp = (reg & 32) == 0;
    if ((int )bad_lp) {
      pd->bad_lp_tries = pd->bad_lp_tries + 1;
    } else {

    }
  }
  if (pd->bad_lp_tries == 0) {
    return;
  } else {

  }
  if (! bad_lp || pd->bad_lp_tries == 5) {
    reg = efx_mdio_read(efx, 1, 49161);
    reg = reg & -193;
    if (! bad_lp) {
      reg = reg | 128;
    } else {
      reg = reg | 192;
      if ((efx->msg_enable & 4U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "appears to be plugged into a port that is not 10GBASE-T capable. The PHY supports 10GBASE-T ONLY, so no link can be established\n");
      } else {

      }
    }
    efx_mdio_write(efx, 1, 49161, reg);
    pd->bad_lp_tries = (int )bad_lp;
  } else {

  }
  return;
}
}
static bool sfx7101_link_ok(struct efx_nic *efx ) 
{ 
  bool tmp ;

  {
  tmp = efx_mdio_links_ok(efx, 26U);
  return (tmp);
}
}
static void tenxpress_ext_loopback(struct efx_nic *efx ) 
{ 


  {
  efx_mdio_set_flag(efx, 4, 49162, 256, (unsigned int )efx->loopback_mode == 15U);
  return;
}
}
static void tenxpress_low_power(struct efx_nic *efx ) 
{ 


  {
  efx_mdio_set_mmds_lpower(efx, ((unsigned int )efx->phy_mode & 2U) != 0U, 154U);
  return;
}
}
static int tenxpress_phy_reconfigure(struct efx_nic *efx ) 
{ 
  struct tenxpress_phy_data *phy_data ;
  bool phy_mode_change ;
  bool loop_reset ;

  {
  phy_data = (struct tenxpress_phy_data *)efx->phy_data;
  if (((unsigned int )efx->phy_mode & 12U) != 0U) {
    phy_data->phy_mode = efx->phy_mode;
    return (0);
  } else {

  }
  phy_mode_change = (bool )((unsigned int )efx->phy_mode == 0U && (unsigned int )phy_data->phy_mode != 0U);
  loop_reset = (bool )(((((u64 )(1 << (int )phy_data->loopback_mode) & efx->loopback_modes) & 0xfffffffffc07c000ULL) != 0ULL && (((u64 )(1 << (int )efx->loopback_mode) & efx->loopback_modes) & 0xfffffffffc07c000ULL) == 0ULL) || (((1 << (int )phy_data->loopback_mode) ^ (1 << (int )efx->loopback_mode)) & 16384) != 0);
  if ((int )loop_reset || (int )phy_mode_change) {
    tenxpress_special_reset(efx);
    falcon_reset_xaui(efx);
  } else {

  }
  tenxpress_low_power(efx);
  efx_mdio_transmit_disable(efx);
  efx_mdio_phy_reconfigure(efx);
  tenxpress_ext_loopback(efx);
  efx_mdio_an_reconfigure(efx);
  phy_data->loopback_mode = efx->loopback_mode;
  phy_data->phy_mode = efx->phy_mode;
  return (0);
}
}
static void tenxpress_get_settings(struct efx_nic *efx , struct ethtool_cmd *ecmd ) ;
static bool tenxpress_phy_poll(struct efx_nic *efx ) 
{ 
  struct efx_link_state old_state ;
  bool tmp ;
  int tmp___0 ;

  {
  old_state = efx->link_state;
  efx->link_state.up = sfx7101_link_ok(efx);
  efx->link_state.speed = 10000U;
  efx->link_state.fd = 1;
  efx->link_state.fc = efx_mdio_get_pause(efx);
  sfx7101_check_bad_lp(efx, (int )efx->link_state.up);
  tmp = efx_link_state_equal((struct efx_link_state  const  *)(& efx->link_state),
                             (struct efx_link_state  const  *)(& old_state));
  if ((int )tmp != 0) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  return ((bool )tmp___0);
}
}
static void sfx7101_phy_fini(struct efx_nic *efx ) 
{ 
  int reg ;

  {
  reg = 256;
  efx_mdio_write(efx, 1, 49152, reg);
  schedule_timeout_uninterruptible(50L);
  return;
}
}
static void tenxpress_phy_remove(struct efx_nic *efx ) 
{ 


  {
  kfree((void const   *)efx->phy_data);
  efx->phy_data = (void *)0;
  return;
}
}
void tenxpress_set_id_led(struct efx_nic *efx , enum efx_led_mode mode ) 
{ 
  int reg ;

  {
  switch ((unsigned int )mode) {
  case 0U: 
  reg = 162;
  goto ldv_55488;
  case 1U: 
  reg = 81;
  goto ldv_55488;
  default: 
  reg = 128;
  goto ldv_55488;
  }
  ldv_55488: 
  efx_mdio_write(efx, 1, 49161, reg);
  return;
}
}
static char const   * const  sfx7101_test_names[1U]  = {      "bist"};
static char const   *sfx7101_test_name(struct efx_nic *efx , unsigned int index ) 
{ 


  {
  if (index == 0U) {
    return ((char const   *)sfx7101_test_names[index]);
  } else {

  }
  return ((char const   *)0);
}
}
static int sfx7101_run_tests(struct efx_nic *efx , int *results , unsigned int flags ) 
{ 
  int rc ;

  {
  if ((flags & 1U) == 0U) {
    return (0);
  } else {

  }
  rc = tenxpress_special_reset(efx);
  *results = rc != 0 ? -1 : 1;
  efx_mdio_an_reconfigure(efx);
  return (rc);
}
}
static void tenxpress_get_settings(struct efx_nic *efx , struct ethtool_cmd *ecmd ) 
{ 
  u32 adv ;
  u32 lpa ;
  int reg ;

  {
  adv = 0U;
  lpa = 0U;
  reg = efx_mdio_read(efx, 7, 32);
  if ((reg & 4096) != 0) {
    adv = adv | 4096U;
  } else {

  }
  reg = efx_mdio_read(efx, 7, 33);
  if ((reg & 2048) != 0) {
    lpa = lpa | 4096U;
  } else {

  }
  mdio45_ethtool_gset_npage((struct mdio_if_info  const  *)(& efx->mdio), ecmd, adv,
                            lpa);
  if ((((u64 )(1 << (int )efx->loopback_mode) & efx->loopback_modes) & 0xfffffffffc07c000ULL) != 0ULL) {
    ethtool_cmd_speed_set(ecmd, 10000U);
  } else {

  }
  return;
}
}
static int tenxpress_set_settings(struct efx_nic *efx , struct ethtool_cmd *ecmd ) 
{ 
  int tmp ;

  {
  if ((unsigned int )ecmd->autoneg == 0U) {
    return (-22);
  } else {

  }
  tmp = efx_mdio_set_settings(efx, ecmd);
  return (tmp);
}
}
static void sfx7101_set_npage_adv(struct efx_nic *efx , u32 advertising ) 
{ 


  {
  efx_mdio_set_flag(efx, 7, 32, 4096, (advertising & 4096U) != 0U);
  return;
}
}
struct efx_phy_operations  const  falcon_sfx7101_phy_ops  = 
     {& tenxpress_phy_probe, & tenxpress_phy_init, & sfx7101_phy_fini, & tenxpress_phy_remove,
    & tenxpress_phy_reconfigure, & tenxpress_phy_poll, & tenxpress_get_settings, & tenxpress_set_settings,
    & sfx7101_set_npage_adv, & efx_mdio_test_alive, & sfx7101_test_name, & sfx7101_run_tests,
    0, 0};
void ldv_initialize_efx_phy_operations_20(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
  tmp = ldv_init_zalloc(44UL);
  falcon_sfx7101_phy_ops_group0 = (struct ethtool_cmd *)tmp;
  tmp___0 = ldv_init_zalloc(4032UL);
  falcon_sfx7101_phy_ops_group1 = (struct efx_nic *)tmp___0;
  return;
}
}
void ldv_main_exported_20(void) 
{ 
  unsigned int ldvarg132 ;
    klee_make_symbolic(&ldvarg132, sizeof(int), "ldvarg132");
  int *ldvarg133 ;
  void *tmp ;
  u32 ldvarg135 ;
  unsigned int ldvarg134 ;
    klee_make_symbolic(&ldvarg134, sizeof(int), "ldvarg134");
  int tmp___0 ;

  {
  tmp = ldv_init_zalloc(4UL);
  ldvarg133 = (int *)tmp;
  ldv_memset((void *)(& ldvarg132), 0, 4UL);
  ldv_memset((void *)(& ldvarg135), 0, 4UL);
  ldv_memset((void *)(& ldvarg134), 0, 4UL);
  tmp___0 = __VERIFIER_nondet_int();
  switch (tmp___0) {
  case 0: ;
  if (ldv_state_variable_20 == 1) {
    tenxpress_phy_reconfigure(falcon_sfx7101_phy_ops_group1);
    ldv_state_variable_20 = 1;
  } else {

  }
  goto ldv_55531;
  case 1: ;
  if (ldv_state_variable_20 == 1) {
    sfx7101_set_npage_adv(falcon_sfx7101_phy_ops_group1, ldvarg135);
    ldv_state_variable_20 = 1;
  } else {

  }
  goto ldv_55531;
  case 2: ;
  if (ldv_state_variable_20 == 1) {
    tenxpress_set_settings(falcon_sfx7101_phy_ops_group1, falcon_sfx7101_phy_ops_group0);
    ldv_state_variable_20 = 1;
  } else {

  }
  goto ldv_55531;
  case 3: ;
  if (ldv_state_variable_20 == 1) {
    efx_mdio_test_alive(falcon_sfx7101_phy_ops_group1);
    ldv_state_variable_20 = 1;
  } else {

  }
  goto ldv_55531;
  case 4: ;
  if (ldv_state_variable_20 == 1) {
    sfx7101_test_name(falcon_sfx7101_phy_ops_group1, ldvarg134);
    ldv_state_variable_20 = 1;
  } else {

  }
  goto ldv_55531;
  case 5: ;
  if (ldv_state_variable_20 == 1) {
    tenxpress_phy_remove(falcon_sfx7101_phy_ops_group1);
    ldv_state_variable_20 = 1;
  } else {

  }
  goto ldv_55531;
  case 6: ;
  if (ldv_state_variable_20 == 1) {
    sfx7101_run_tests(falcon_sfx7101_phy_ops_group1, ldvarg133, ldvarg132);
    ldv_state_variable_20 = 1;
  } else {

  }
  goto ldv_55531;
  case 7: ;
  if (ldv_state_variable_20 == 1) {
    tenxpress_get_settings(falcon_sfx7101_phy_ops_group1, falcon_sfx7101_phy_ops_group0);
    ldv_state_variable_20 = 1;
  } else {

  }
  goto ldv_55531;
  case 8: ;
  if (ldv_state_variable_20 == 1) {
    tenxpress_phy_probe(falcon_sfx7101_phy_ops_group1);
    ldv_state_variable_20 = 1;
  } else {

  }
  goto ldv_55531;
  case 9: ;
  if (ldv_state_variable_20 == 1) {
    sfx7101_phy_fini(falcon_sfx7101_phy_ops_group1);
    ldv_state_variable_20 = 1;
  } else {

  }
  goto ldv_55531;
  case 10: ;
  if (ldv_state_variable_20 == 1) {
    tenxpress_phy_poll(falcon_sfx7101_phy_ops_group1);
    ldv_state_variable_20 = 1;
  } else {

  }
  goto ldv_55531;
  case 11: ;
  if (ldv_state_variable_20 == 1) {
    tenxpress_phy_init(falcon_sfx7101_phy_ops_group1);
    ldv_state_variable_20 = 1;
  } else {

  }
  goto ldv_55531;
  default: 
  ldv_stop();
  }
  ldv_55531: ;
  return;
}
}
bool ldv_queue_work_on_507(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_508(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_509(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_510(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_511(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_512(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_513(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_514(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_515(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_516(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_517(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_518(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_543(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_541(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_544(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_545(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_540(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_542(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_546(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_535(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_537(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_536(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_539(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_538(struct workqueue_struct *ldv_func_arg1 ) ;
void falcon_txc_set_gpio_dir(struct efx_nic *efx , int pin , int dir ) ;
void falcon_txc_set_gpio_val(struct efx_nic *efx , int pin , int on ) ;
static void txc_reset_logic(struct efx_nic *efx ) ;
void falcon_txc_set_gpio_val(struct efx_nic *efx , int pin , int on ) 
{ 


  {
  efx_mdio_set_flag(efx, 4, 49990, 1 << pin, on != 0);
  return;
}
}
void falcon_txc_set_gpio_dir(struct efx_nic *efx , int pin , int dir ) 
{ 


  {
  efx_mdio_set_flag(efx, 4, 49992, 1 << pin, dir != 0);
  return;
}
}
static int txc_reset_phy(struct efx_nic *efx ) 
{ 
  int rc ;
  int tmp ;

  {
  tmp = efx_mdio_reset_mmd(efx, 1, 50, 10);
  rc = tmp;
  if (rc < 0) {
    goto fail;
  } else {

  }
  rc = efx_mdio_check_mmds(efx, 26U);
  if (rc < 0) {
    goto fail;
  } else {

  }
  return (0);
  fail: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "TXC43128: reset timed out!\n");
  } else {

  }
  return (rc);
}
}
static int txc_bist_one(struct efx_nic *efx , int mmd , int test ) 
{ 
  int ctrl ;
    klee_make_symbolic(&ctrl, sizeof(int), "ctrl");
  int bctl ;
    klee_make_symbolic(&bctl, sizeof(int), "bctl");
  int lane ;
    klee_make_symbolic(&lane, sizeof(int), "lane");
  int rc ;
  int count ;
  int tmp ;

  {
  rc = 0;
  ctrl = efx_mdio_read(efx, 3, 49999);
  ctrl = ctrl | 1024;
  efx_mdio_write(efx, 3, 49999, ctrl);
  bctl = test << 10;
  efx_mdio_write(efx, mmd, 49792, bctl);
  bctl = bctl | 8192;
  efx_mdio_write(efx, mmd, 49792, bctl);
  efx_mdio_write(efx, mmd, 49792, bctl | 32768);
  __const_udelay(214750UL);
  bctl = bctl | 16384;
  efx_mdio_write(efx, mmd, 49792, bctl);
  goto ldv_55448;
  ldv_55447: 
  bctl = efx_mdio_read(efx, mmd, 49792);
  ldv_55448: ;
  if ((bctl & 16384) != 0) {
    goto ldv_55447;
  } else {

  }
  lane = 0;
  goto ldv_55452;
  ldv_55451: 
  tmp = efx_mdio_read(efx, mmd, lane + 49798);
  count = tmp;
  if (count != 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "TXC43128: BIST error. Lane %d had %d errs\n",
                 lane, count);
    } else {

    }
    rc = -5;
  } else {

  }
  count = efx_mdio_read(efx, mmd, lane + 49794);
  if (count == 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "TXC43128: BIST error. Lane %d got 0 frames\n",
                 lane);
    } else {

    }
    rc = -5;
  } else {

  }
  lane = lane + 1;
  ldv_55452: ;
  if (lane <= 3) {
    goto ldv_55451;
  } else {

  }

  if (rc == 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_info((struct net_device  const  *)efx->net_dev, "TXC43128: BIST pass\n");
    } else {

    }
  } else {

  }
  efx_mdio_write(efx, mmd, 49792, 0);
  ctrl = ctrl & -1025;
  efx_mdio_write(efx, 3, 49999, ctrl);
  return (rc);
}
}
static int txc_bist(struct efx_nic *efx ) 
{ 
  int tmp ;

  {
  tmp = txc_bist_one(efx, 3, 0);
  return (tmp);
}
}
static void txc_apply_defaults(struct efx_nic *efx ) 
{ 
  int mctrl ;
    klee_make_symbolic(&mctrl, sizeof(int), "mctrl");
  struct falcon_board *tmp ;

  {
  efx_mdio_write(efx, 4, 49219, 0);
  efx_mdio_write(efx, 4, 49220, 0);
  efx_mdio_write(efx, 4, 49217, 51400);
  efx_mdio_write(efx, 4, 49218, 51400);
  efx_mdio_write(efx, 1, 49219, 4112);
  efx_mdio_write(efx, 1, 49220, 4112);
  efx_mdio_write(efx, 1, 49217, 24672);
  efx_mdio_write(efx, 1, 49218, 24672);
  mctrl = efx_mdio_read(efx, 4, 49984);
  mctrl = mctrl & -24577;
  efx_mdio_write(efx, 4, 49984, mctrl);
  txc_reset_logic(efx);
  tmp = falcon_board(efx);
  (*((tmp->type)->init_phy))(efx);
  return;
}
}
static int txc43128_phy_probe(struct efx_nic *efx ) 
{ 
  struct txc43128_data *phy_data ;
  void *tmp ;

  {
  tmp = kzalloc(16UL, 208U);
  phy_data = (struct txc43128_data *)tmp;
  if ((unsigned long )phy_data == (unsigned long )((struct txc43128_data *)0)) {
    return (-12);
  } else {

  }
  efx->phy_data = (void *)phy_data;
  phy_data->phy_mode = efx->phy_mode;
  efx->mdio.mmds = 26U;
  efx->mdio.mode_support = 6U;
  efx->loopback_modes = 67305528ULL;
  return (0);
}
}
static int txc43128_phy_init(struct efx_nic *efx ) 
{ 
  int rc ;

  {
  rc = txc_reset_phy(efx);
  if (rc < 0) {
    return (rc);
  } else {

  }
  rc = txc_bist(efx);
  if (rc < 0) {
    return (rc);
  } else {

  }
  txc_apply_defaults(efx);
  return (0);
}
}
static void txc_glrgs_lane_power(struct efx_nic *efx , int mmd ) 
{ 
  int pd ;
    klee_make_symbolic(&pd, sizeof(int), "pd");
  int ctl ;
    klee_make_symbolic(&ctl, sizeof(int), "ctl");
  int tmp ;

  {
  pd = 96;
  tmp = efx_mdio_read(efx, mmd, 49156);
  ctl = tmp;
  if (((unsigned int )efx->phy_mode & 2U) == 0U) {
    ctl = ~ pd & ctl;
  } else {
    ctl = ctl | pd;
  }
  efx_mdio_write(efx, mmd, 49156, ctl);
  return;
}
}
static void txc_analog_lane_power(struct efx_nic *efx , int mmd ) 
{ 
  int txpd ;
    klee_make_symbolic(&txpd, sizeof(int), "txpd");
  int rxpd ;
    klee_make_symbolic(&rxpd, sizeof(int), "rxpd");
  int txctl ;
    klee_make_symbolic(&txctl, sizeof(int), "txctl");
  int tmp ;
  int rxctl ;
    klee_make_symbolic(&rxctl, sizeof(int), "rxctl");
  int tmp___0 ;

  {
  txpd = 61440;
  rxpd = 61440;
  tmp = efx_mdio_read(efx, mmd, 49216);
  txctl = tmp;
  tmp___0 = efx_mdio_read(efx, mmd, 49221);
  rxctl = tmp___0;
  if (((unsigned int )efx->phy_mode & 2U) == 0U) {
    txctl = ~ txpd & txctl;
    rxctl = ~ rxpd & rxctl;
  } else {
    txctl = txctl | txpd;
    rxctl = rxctl | rxpd;
  }
  efx_mdio_write(efx, mmd, 49216, txctl);
  efx_mdio_write(efx, mmd, 49221, rxctl);
  return;
}
}
static void txc_set_power(struct efx_nic *efx ) 
{ 


  {
  efx_mdio_set_mmds_lpower(efx, ((unsigned int )efx->phy_mode & 2U) != 0U, 26U);
  txc_glrgs_lane_power(efx, 3);
  txc_glrgs_lane_power(efx, 4);
  txc_analog_lane_power(efx, 1);
  txc_analog_lane_power(efx, 4);
  return;
}
}
static void txc_reset_logic_mmd(struct efx_nic *efx , int mmd ) 
{ 
  int val ;
    klee_make_symbolic(&val, sizeof(int), "val");
  int tmp ;
  int tries ;
  int tmp___0 ;

  {
  tmp = efx_mdio_read(efx, mmd, 49156);
  val = tmp;
  tries = 50;
  val = val | 16384;
  efx_mdio_write(efx, mmd, 49156, val);
  goto ldv_55494;
  ldv_55493: 
  val = efx_mdio_read(efx, mmd, 49156);
  if ((val & 16384) == 0) {
    goto ldv_55492;
  } else {

  }
  __const_udelay(4295UL);
  ldv_55494: 
  tmp___0 = tries;
  tries = tries - 1;
  if (tmp___0 != 0) {
    goto ldv_55493;
  } else {

  }
  ldv_55492: ;
  if (tries == 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_info((struct net_device  const  *)efx->net_dev, "TXC43128 Logic reset timed out!\n");
    } else {

    }
  } else {

  }
  return;
}
}
static void txc_reset_logic(struct efx_nic *efx ) 
{ 


  {
  txc_reset_logic_mmd(efx, 3);
  return;
}
}
static bool txc43128_phy_read_link(struct efx_nic *efx ) 
{ 
  bool tmp ;

  {
  tmp = efx_mdio_links_ok(efx, 26U);
  return (tmp);
}
}
static int txc43128_phy_reconfigure(struct efx_nic *efx ) 
{ 
  struct txc43128_data *phy_data ;
  enum efx_phy_mode mode_change ;
  bool loop_change ;

  {
  phy_data = (struct txc43128_data *)efx->phy_data;
  mode_change = (unsigned int )efx->phy_mode ^ (unsigned int )phy_data->phy_mode;
  loop_change = (((1 << (int )phy_data->loopback_mode) ^ (1 << (int )efx->loopback_mode)) & 67305472) != 0;
  if ((int )((unsigned int )efx->phy_mode & (unsigned int )mode_change) & 1) {
    txc_reset_phy(efx);
    txc_apply_defaults(efx);
    falcon_reset_xaui(efx);
    mode_change = (enum efx_phy_mode )((unsigned int )mode_change & 4294967294U);
  } else {

  }
  efx_mdio_transmit_disable(efx);
  efx_mdio_phy_reconfigure(efx);
  if (((unsigned int )mode_change & 2U) != 0U) {
    txc_set_power(efx);
  } else {

  }
  if ((int )loop_change || (unsigned int )mode_change != 0U) {
    txc_reset_logic(efx);
  } else {

  }
  phy_data->phy_mode = efx->phy_mode;
  phy_data->loopback_mode = efx->loopback_mode;
  return (0);
}
}
static void txc43128_phy_fini(struct efx_nic *efx ) 
{ 


  {
  efx_mdio_write(efx, 1, 36866, 0);
  return;
}
}
static void txc43128_phy_remove(struct efx_nic *efx ) 
{ 


  {
  kfree((void const   *)efx->phy_data);
  efx->phy_data = (void *)0;
  return;
}
}
static bool txc43128_phy_poll(struct efx_nic *efx ) 
{ 
  struct txc43128_data *data ;
  bool was_up ;

  {
  data = (struct txc43128_data *)efx->phy_data;
  was_up = efx->link_state.up;
  efx->link_state.up = txc43128_phy_read_link(efx);
  efx->link_state.speed = 10000U;
  efx->link_state.fd = 1;
  efx->link_state.fc = efx->wanted_fc;
  if ((int )efx->link_state.up || (unsigned int )efx->loopback_mode != 0U) {
    data->bug10934_timer = jiffies;
  } else
  if ((long )(((unsigned long )jiffies - data->bug10934_timer) - 1250UL) >= 0L) {
    data->bug10934_timer = jiffies;
    txc_reset_logic(efx);
  } else {

  }
  return ((int )efx->link_state.up != (int )was_up);
}
}
static char const   * const  txc43128_test_names[1U]  = {      "bist"};
static char const   *txc43128_test_name(struct efx_nic *efx , unsigned int index ) 
{ 


  {
  if (index == 0U) {
    return ((char const   *)txc43128_test_names[index]);
  } else {

  }
  return ((char const   *)0);
}
}
static int txc43128_run_tests(struct efx_nic *efx , int *results , unsigned int flags ) 
{ 
  int rc ;

  {
  if ((flags & 1U) == 0U) {
    return (0);
  } else {

  }
  rc = txc_reset_phy(efx);
  if (rc < 0) {
    return (rc);
  } else {

  }
  rc = txc_bist(efx);
  txc_apply_defaults(efx);
  *results = rc != 0 ? -1 : 1;
  return (rc);
}
}
static void txc43128_get_settings(struct efx_nic *efx , struct ethtool_cmd *ecmd ) 
{ 


  {
  mdio45_ethtool_gset((struct mdio_if_info  const  *)(& efx->mdio), ecmd);
  return;
}
}
struct efx_phy_operations  const  falcon_txc_phy_ops  = 
     {& txc43128_phy_probe, & txc43128_phy_init, & txc43128_phy_fini, & txc43128_phy_remove,
    & txc43128_phy_reconfigure, & txc43128_phy_poll, & txc43128_get_settings, & efx_mdio_set_settings,
    0, & efx_mdio_test_alive, & txc43128_test_name, & txc43128_run_tests, 0, 0};
void ldv_initialize_efx_phy_operations_19(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
  tmp = ldv_init_zalloc(44UL);
  falcon_txc_phy_ops_group0 = (struct ethtool_cmd *)tmp;
  tmp___0 = ldv_init_zalloc(4032UL);
  falcon_txc_phy_ops_group1 = (struct efx_nic *)tmp___0;
  return;
}
}
void ldv_main_exported_19(void) 
{ 
  unsigned int ldvarg347 ;
    klee_make_symbolic(&ldvarg347, sizeof(int), "ldvarg347");
  int *ldvarg348 ;
  void *tmp ;
  unsigned int ldvarg349 ;
    klee_make_symbolic(&ldvarg349, sizeof(int), "ldvarg349");
  int tmp___0 ;

  {
  tmp = ldv_init_zalloc(4UL);
  ldvarg348 = (int *)tmp;
  ldv_memset((void *)(& ldvarg347), 0, 4UL);
  ldv_memset((void *)(& ldvarg349), 0, 4UL);
  tmp___0 = __VERIFIER_nondet_int();
  switch (tmp___0) {
  case 0: ;
  if (ldv_state_variable_19 == 1) {
    txc43128_phy_reconfigure(falcon_txc_phy_ops_group1);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_55552;
  case 1: ;
  if (ldv_state_variable_19 == 1) {
    efx_mdio_set_settings(falcon_txc_phy_ops_group1, falcon_txc_phy_ops_group0);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_55552;
  case 2: ;
  if (ldv_state_variable_19 == 1) {
    efx_mdio_test_alive(falcon_txc_phy_ops_group1);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_55552;
  case 3: ;
  if (ldv_state_variable_19 == 1) {
    txc43128_test_name(falcon_txc_phy_ops_group1, ldvarg349);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_55552;
  case 4: ;
  if (ldv_state_variable_19 == 1) {
    txc43128_phy_remove(falcon_txc_phy_ops_group1);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_55552;
  case 5: ;
  if (ldv_state_variable_19 == 1) {
    txc43128_run_tests(falcon_txc_phy_ops_group1, ldvarg348, ldvarg347);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_55552;
  case 6: ;
  if (ldv_state_variable_19 == 1) {
    txc43128_get_settings(falcon_txc_phy_ops_group1, falcon_txc_phy_ops_group0);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_55552;
  case 7: ;
  if (ldv_state_variable_19 == 1) {
    txc43128_phy_probe(falcon_txc_phy_ops_group1);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_55552;
  case 8: ;
  if (ldv_state_variable_19 == 1) {
    txc43128_phy_fini(falcon_txc_phy_ops_group1);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_55552;
  case 9: ;
  if (ldv_state_variable_19 == 1) {
    txc43128_phy_poll(falcon_txc_phy_ops_group1);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_55552;
  case 10: ;
  if (ldv_state_variable_19 == 1) {
    txc43128_phy_init(falcon_txc_phy_ops_group1);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_55552;
  default: 
  ldv_stop();
  }
  ldv_55552: ;
  return;
}
}
bool ldv_queue_work_on_535(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_536(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_537(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_538(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_539(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_540(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_541(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_542(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_543(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_544(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_545(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_546(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_571(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_569(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_572(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_573(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_568(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_570(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_574(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_563(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_565(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_564(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_567(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_566(struct workqueue_struct *ldv_func_arg1 ) ;
extern s32 i2c_smbus_read_byte_data(struct i2c_client  const  * , u8  ) ;
extern s32 i2c_smbus_write_byte_data(struct i2c_client  const  * , u8  , u8  ) ;
extern struct i2c_client *i2c_new_device(struct i2c_adapter * , struct i2c_board_info  const  * ) ;
extern struct i2c_client *i2c_new_dummy(struct i2c_adapter * , u16  ) ;
extern void i2c_unregister_device(struct i2c_client * ) ;
static int efx_poke_lm87(struct i2c_client *client , u8 const   *reg_values ) 
{ 
  u8 reg ;
  u8 const   *tmp ;
  u8 value ;
  u8 const   *tmp___0 ;
  int rc ;
  s32 tmp___1 ;

  {
  goto ldv_55349;
  ldv_55348: 
  tmp = reg_values;
  reg_values = reg_values + 1;
  reg = *tmp;
  tmp___0 = reg_values;
  reg_values = reg_values + 1;
  value = *tmp___0;
  tmp___1 = i2c_smbus_write_byte_data((struct i2c_client  const  *)client, (int )reg,
                                      (int )value);
  rc = tmp___1;
  if (rc != 0) {
    return (rc);
  } else {

  }
  ldv_55349: ;
  if ((unsigned int )((unsigned char )*reg_values) != 0U) {
    goto ldv_55348;
  } else {

  }

  return (0);
}
}
static u8 const   falcon_lm87_common_regs[13U]  = 
  {      19U,      95U,      23U,      95U, 
        55U,      90U,      56U,      0U, 
        20U,      125U,      24U,      125U, 
        0U};
static int efx_init_lm87(struct efx_nic *efx , struct i2c_board_info  const  *info ,
                         u8 const   *reg_values ) 
{ 
  struct falcon_board *board ;
  struct falcon_board *tmp ;
  struct i2c_client *client ;
  struct i2c_client *tmp___0 ;
  int rc ;

  {
  tmp = falcon_board(efx);
  board = tmp;
  tmp___0 = i2c_new_device(& board->i2c_adap, info);
  client = tmp___0;
  if ((unsigned long )client == (unsigned long )((struct i2c_client *)0)) {
    return (-5);
  } else {

  }
  i2c_smbus_read_byte_data((struct i2c_client  const  *)client, 65);
  i2c_smbus_read_byte_data((struct i2c_client  const  *)client, 66);
  rc = efx_poke_lm87(client, reg_values);
  if (rc != 0) {
    goto err;
  } else {

  }
  rc = efx_poke_lm87(client, (u8 const   *)(& falcon_lm87_common_regs));
  if (rc != 0) {
    goto err;
  } else {

  }
  board->hwmon_client = client;
  return (0);
  err: 
  i2c_unregister_device(client);
  return (rc);
}
}
static void efx_fini_lm87(struct efx_nic *efx ) 
{ 
  struct falcon_board *tmp ;

  {
  tmp = falcon_board(efx);
  i2c_unregister_device(tmp->hwmon_client);
  return;
}
}
static int efx_check_lm87(struct efx_nic *efx , unsigned int mask ) 
{ 
  struct i2c_client *client ;
  struct falcon_board *tmp ;
  bool temp_crit ;
  bool elec_fault ;
  bool is_failure ;
  u16 alarms ;
  s32 reg ;

  {
  tmp = falcon_board(efx);
  client = tmp->hwmon_client;
  if ((int )efx->link_state.up) {
    return (0);
  } else {

  }
  reg = i2c_smbus_read_byte_data((struct i2c_client  const  *)client, 65);
  if (reg < 0) {
    return (reg);
  } else {

  }
  alarms = (u16 )reg;
  reg = i2c_smbus_read_byte_data((struct i2c_client  const  *)client, 66);
  if (reg < 0) {
    return (reg);
  } else {

  }
  alarms = (u16 )((int )((short )(reg << 8)) | (int )((short )alarms));
  alarms = (int )((u16 )mask) & (int )alarms;
  temp_crit = 0;
  if (((int )alarms & 16) != 0) {
    reg = i2c_smbus_read_byte_data((struct i2c_client  const  *)client, 39);
    if (reg < 0) {
      return (reg);
    } else {

    }
    if (reg > 95) {
      temp_crit = 1;
    } else {

    }
  } else {

  }
  if (((int )alarms & 32) != 0) {
    reg = i2c_smbus_read_byte_data((struct i2c_client  const  *)client, 38);
    if (reg < 0) {
      return (reg);
    } else {

    }
    if (reg > 125) {
      temp_crit = 1;
    } else {

    }
  } else {

  }
  elec_fault = ((int )alarms & -49) != 0;
  is_failure = (bool )((int )temp_crit || (int )elec_fault);
  if ((unsigned int )alarms != 0U) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "LM87 detected a hardware %s (status %02x:%02x)%s%s%s%s\n",
                 (int )is_failure ? (char *)"failure" : (char *)"problem", (int )alarms & 255,
                 (int )alarms >> 8, ((int )alarms & 16) != 0 ? (char *)"; board is overheating" : (char *)"",
                 ((int )alarms & 32) != 0 ? (char *)"; controller is overheating" : (char *)"",
                 (int )temp_crit ? (char *)"; reached critical temperature" : (char *)"",
                 (int )elec_fault ? (char *)"; electrical fault" : (char *)"");
    } else {

    }
  } else {

  }
  return ((int )is_failure ? -34 : 0);
}
}
static void sfe4001_poweroff(struct efx_nic *efx ) 
{ 
  struct i2c_client *ioexp_client ;
  struct falcon_board *tmp ;
  struct i2c_client *hwmon_client ;
  struct falcon_board *tmp___0 ;

  {
  tmp = falcon_board(efx);
  ioexp_client = tmp->ioexp_client;
  tmp___0 = falcon_board(efx);
  hwmon_client = tmp___0->hwmon_client;
  i2c_smbus_write_byte_data((struct i2c_client  const  *)ioexp_client, 2, 255);
  i2c_smbus_write_byte_data((struct i2c_client  const  *)ioexp_client, 7, 255);
  i2c_smbus_write_byte_data((struct i2c_client  const  *)ioexp_client, 6, 255);
  i2c_smbus_read_byte_data((struct i2c_client  const  *)hwmon_client, 2);
  return;
}
}
static int sfe4001_poweron(struct efx_nic *efx ) 
{ 
  struct i2c_client *ioexp_client ;
  struct falcon_board *tmp ;
  struct i2c_client *hwmon_client ;
  struct falcon_board *tmp___0 ;
  unsigned int i ;
  unsigned int j ;
  int rc ;
  u8 out ;

  {
  tmp = falcon_board(efx);
  ioexp_client = tmp->ioexp_client;
  tmp___0 = falcon_board(efx);
  hwmon_client = tmp___0->hwmon_client;
  rc = i2c_smbus_read_byte_data((struct i2c_client  const  *)hwmon_client, 2);
  if (rc < 0) {
    return (rc);
  } else {

  }
  rc = i2c_smbus_write_byte_data((struct i2c_client  const  *)ioexp_client, 6, 0);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = i2c_smbus_write_byte_data((struct i2c_client  const  *)ioexp_client, 7, 239);
  if (rc != 0) {
    goto fail_on;
  } else {

  }
  rc = i2c_smbus_read_byte_data((struct i2c_client  const  *)ioexp_client, 2);
  if (rc < 0) {
    goto fail_on;
  } else {

  }
  out = 255U;
  if ((int )out != rc) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_info((struct net_device  const  *)efx->net_dev, "power-cycling PHY\n");
    } else {

    }
    rc = i2c_smbus_write_byte_data((struct i2c_client  const  *)ioexp_client, 2, (int )out);
    if (rc != 0) {
      goto fail_on;
    } else {

    }
    schedule_timeout_uninterruptible(250L);
  } else {

  }
  i = 0U;
  goto ldv_55393;
  ldv_55392: 
  out = 161U;
  if (((unsigned int )efx->phy_mode & 8U) != 0U) {
    out = (u8 )((unsigned int )out | 8U);
  } else {

  }
  rc = i2c_smbus_write_byte_data((struct i2c_client  const  *)ioexp_client, 2, (int )out);
  if (rc != 0) {
    goto fail_on;
  } else {

  }
  msleep(10U);
  out = (unsigned int )out & 254U;
  rc = i2c_smbus_write_byte_data((struct i2c_client  const  *)ioexp_client, 2, (int )out);
  if (rc != 0) {
    goto fail_on;
  } else {

  }
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_info((struct net_device  const  *)efx->net_dev, "waiting for DSP boot (attempt %d)...\n",
                i);
  } else {

  }
  if (((unsigned int )efx->phy_mode & 8U) != 0U) {
    schedule_timeout_uninterruptible(250L);
    return (0);
  } else {

  }
  j = 0U;
  goto ldv_55390;
  ldv_55389: 
  msleep(100U);
  rc = i2c_smbus_read_byte_data((struct i2c_client  const  *)ioexp_client, 1);
  if (rc < 0) {
    goto fail_on;
  } else {

  }
  if (rc & 1) {
    return (0);
  } else {

  }
  j = j + 1U;
  ldv_55390: ;
  if (j <= 9U) {
    goto ldv_55389;
  } else {

  }
  i = i + 1U;
  ldv_55393: ;
  if (i <= 19U) {
    goto ldv_55392;
  } else {

  }

  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_info((struct net_device  const  *)efx->net_dev, "timed out waiting for DSP boot\n");
  } else {

  }
  rc = -110;
  fail_on: 
  sfe4001_poweroff(efx);
  return (rc);
}
}
static ssize_t show_phy_flash_cfg(struct device *dev , struct device_attribute *attr ,
                                  char *buf ) 
{ 
  struct efx_nic *efx ;
  struct device  const  *__mptr ;
  void *tmp ;
  int tmp___0 ;

  {
  __mptr = (struct device  const  *)dev;
  tmp = pci_get_drvdata((struct pci_dev *)__mptr + 0xffffffffffffff68UL);
  efx = (struct efx_nic *)tmp;
  tmp___0 = sprintf(buf, "%d\n", ((unsigned int )efx->phy_mode & 8U) != 0U);
  return ((ssize_t )tmp___0);
}
}
static ssize_t set_phy_flash_cfg(struct device *dev , struct device_attribute *attr ,
                                 char const   *buf , size_t count ) 
{ 
  struct efx_nic *efx ;
  struct device  const  *__mptr ;
  void *tmp ;
  enum efx_phy_mode old_mode ;
  enum efx_phy_mode new_mode ;
  int err ;
    klee_make_symbolic(&err, sizeof(int), "err");
  bool tmp___0 ;

  {
  __mptr = (struct device  const  *)dev;
  tmp = pci_get_drvdata((struct pci_dev *)__mptr + 0xffffffffffffff68UL);
  efx = (struct efx_nic *)tmp;
  rtnl_lock();
  old_mode = efx->phy_mode;
  if (count == 0UL || (int )((signed char )*buf) == 48) {
    new_mode = (enum efx_phy_mode )((unsigned int )old_mode & 4294967287U);
  } else {
    new_mode = 8;
  }
  if ((((unsigned int )old_mode ^ (unsigned int )new_mode) & 8U) == 0U) {
    err = 0;
  } else
  if ((unsigned int )efx->state != 1U) {
    err = -16;
  } else {
    tmp___0 = netif_running((struct net_device  const  *)efx->net_dev);
    if ((int )tmp___0) {
      err = -16;
    } else {
      efx->phy_mode = new_mode;
      if (((unsigned int )new_mode & 8U) != 0U) {
        falcon_stop_nic_stats(efx);
      } else {

      }
      err = sfe4001_poweron(efx);
      if (err == 0) {
        err = efx_reconfigure_port(efx);
      } else {

      }
      if (((unsigned int )new_mode & 8U) == 0U) {
        falcon_start_nic_stats(efx);
      } else {

      }
    }
  }
  rtnl_unlock();
  return ((ssize_t )(err != 0 ? (size_t )err : count));
}
}
static struct device_attribute dev_attr_phy_flash_cfg  =    {{"phy_flash_cfg", 420U, (_Bool)0, 0, {{{(char)0}, {(char)0}, {(char)0}, {(char)0},
                                           {(char)0}, {(char)0}, {(char)0}, {(char)0}}}},
    & show_phy_flash_cfg, & set_phy_flash_cfg};
static void sfe4001_fini(struct efx_nic *efx ) 
{ 
  struct falcon_board *board ;
  struct falcon_board *tmp ;

  {
  tmp = falcon_board(efx);
  board = tmp;
  if ((int )efx->msg_enable & 1) {
    netdev_info((struct net_device  const  *)efx->net_dev, "%s\n", "sfe4001_fini");
  } else {

  }
  device_remove_file(& (efx->pci_dev)->dev, (struct device_attribute  const  *)(& dev_attr_phy_flash_cfg));
  sfe4001_poweroff(efx);
  i2c_unregister_device(board->ioexp_client);
  i2c_unregister_device(board->hwmon_client);
  return;
}
}
static int sfe4001_check_hw(struct efx_nic *efx ) 
{ 
  struct falcon_nic_data *nic_data ;
  s32 status ;
  struct falcon_board *tmp ;

  {
  nic_data = (struct falcon_nic_data *)efx->nic_data;
  if (! nic_data->xmac_poll_required) {
    return (0);
  } else {

  }
  tmp = falcon_board(efx);
  status = i2c_smbus_read_byte_data((struct i2c_client  const  *)tmp->ioexp_client,
                                    1);
  if (status >= 0 && (status & 3) != 0) {
    return (0);
  } else {

  }
  sfe4001_poweroff(efx);
  efx->phy_mode = 4;
  return (status < 0 ? -5 : -34);
}
}
static struct i2c_board_info  const  sfe4001_hwmon_info  = 
     {{'m', 'a', 'x', '6', '6', '4', '7', '\000'}, (unsigned short)0, 78U, 0, 0, 0,
    0, 0};
static int sfe4001_init(struct efx_nic *efx ) 
{ 
  struct falcon_board *board ;
  struct falcon_board *tmp ;
  int rc ;

  {
  tmp = falcon_board(efx);
  board = tmp;
  board->hwmon_client = i2c_new_device(& board->i2c_adap, & sfe4001_hwmon_info);
  if ((unsigned long )board->hwmon_client == (unsigned long )((struct i2c_client *)0)) {
    return (-5);
  } else {

  }
  rc = i2c_smbus_write_byte_data((struct i2c_client  const  *)board->hwmon_client,
                                 11, 90);
  if (rc != 0) {
    goto fail_hwmon;
  } else {

  }
  board->ioexp_client = i2c_new_dummy(& board->i2c_adap, 116);
  if ((unsigned long )board->ioexp_client == (unsigned long )((struct i2c_client *)0)) {
    rc = -5;
    goto fail_hwmon;
  } else {

  }
  if (((unsigned int )efx->phy_mode & 8U) != 0U) {
    falcon_stop_nic_stats(efx);
  } else {

  }
  rc = sfe4001_poweron(efx);
  if (rc != 0) {
    goto fail_ioexp;
  } else {

  }
  rc = device_create_file(& (efx->pci_dev)->dev, (struct device_attribute  const  *)(& dev_attr_phy_flash_cfg));
  if (rc != 0) {
    goto fail_on;
  } else {

  }
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_info((struct net_device  const  *)efx->net_dev, "PHY is powered on\n");
  } else {

  }
  return (0);
  fail_on: 
  sfe4001_poweroff(efx);
  fail_ioexp: 
  i2c_unregister_device(board->ioexp_client);
  fail_hwmon: 
  i2c_unregister_device(board->hwmon_client);
  return (rc);
}
}
static u8 sfe4002_lm87_channel  =    3U;
static u8 const   sfe4002_lm87_regs[41U]  = 
  {      43U,      153U,      44U,      124U, 
        45U,      94U,      46U,      76U, 
        47U,      212U,      48U,      172U, 
        49U,      212U,      50U,      172U, 
        51U,      224U,      52U,      172U, 
        53U,      79U,      54U,      63U, 
        59U,      187U,      26U,      152U, 
        60U,      169U,      27U,      138U, 
        57U,      95U,      58U,      0U, 
        55U,      90U,      56U,      0U, 
        0U};
static struct i2c_board_info  const  sfe4002_hwmon_info  = 
     {{'l', 'm', '8', '7', '\000'}, (unsigned short)0, 46U, (void *)(& sfe4002_lm87_channel),
    0, 0, 0, 0};
static void sfe4002_init_phy(struct efx_nic *efx ) 
{ 


  {
  falcon_qt202x_set_led(efx, 1, 3);
  falcon_qt202x_set_led(efx, 0, 11);
  falcon_qt202x_set_led(efx, 2, 4);
  return;
}
}
static void sfe4002_set_id_led(struct efx_nic *efx , enum efx_led_mode mode ) 
{ 


  {
  falcon_qt202x_set_led(efx, 2, (unsigned int )mode == 1U ? 5 : 4);
  return;
}
}
static int sfe4002_check_hw(struct efx_nic *efx ) 
{ 
  struct falcon_board *board ;
  struct falcon_board *tmp ;
  unsigned int alarm_mask ;
    klee_make_symbolic(&alarm_mask, sizeof(int), "alarm_mask");
  int tmp___0 ;

  {
  tmp = falcon_board(efx);
  board = tmp;
  alarm_mask = board->major == 0 && board->minor == 0 ? 4294967263U : 4294967295U;
  tmp___0 = efx_check_lm87(efx, alarm_mask);
  return (tmp___0);
}
}
static int sfe4002_init(struct efx_nic *efx ) 
{ 
  int tmp ;

  {
  tmp = efx_init_lm87(efx, & sfe4002_hwmon_info, (u8 const   *)(& sfe4002_lm87_regs));
  return (tmp);
}
}
static u8 sfn4112f_lm87_channel  =    3U;
static u8 const   sfn4112f_lm87_regs[33U]  = 
  {      43U,      153U,      44U,      124U, 
        45U,      94U,      46U,      76U, 
        47U,      212U,      48U,      172U, 
        51U,      224U,      52U,      172U, 
        53U,      79U,      54U,      63U, 
        60U,      169U,      27U,      138U, 
        57U,      75U,      58U,      0U, 
        55U,      90U,      56U,      0U, 
        0U};
static struct i2c_board_info  const  sfn4112f_hwmon_info  = 
     {{'l', 'm', '8', '7', '\000'}, (unsigned short)0, 46U, (void *)(& sfn4112f_lm87_channel),
    0, 0, 0, 0};
static void sfn4112f_init_phy(struct efx_nic *efx ) 
{ 


  {
  falcon_qt202x_set_led(efx, 0, 10);
  falcon_qt202x_set_led(efx, 1, 9);
  return;
}
}
static void sfn4112f_set_id_led(struct efx_nic *efx , enum efx_led_mode mode ) 
{ 
  int reg ;

  {
  switch ((unsigned int )mode) {
  case 0U: 
  reg = 4;
  goto ldv_55477;
  case 1U: 
  reg = 5;
  goto ldv_55477;
  default: 
  reg = 9;
  goto ldv_55477;
  }
  ldv_55477: 
  falcon_qt202x_set_led(efx, 1, reg);
  return;
}
}
static int sfn4112f_check_hw(struct efx_nic *efx ) 
{ 
  int tmp ;

  {
  tmp = efx_check_lm87(efx, 4294967223U);
  return (tmp);
}
}
static int sfn4112f_init(struct efx_nic *efx ) 
{ 
  int tmp ;

  {
  tmp = efx_init_lm87(efx, & sfn4112f_hwmon_info, (u8 const   *)(& sfn4112f_lm87_regs));
  return (tmp);
}
}
static u8 sfe4003_lm87_channel  =    3U;
static u8 const   sfe4003_lm87_regs[25U]  = 
  {      43U,      127U,      44U,      103U, 
        45U,      94U,      46U,      76U, 
        47U,      212U,      48U,      172U, 
        51U,      224U,      52U,      172U, 
        53U,      79U,      54U,      63U, 
        57U,      85U,      58U,      0U, 
        0U};
static struct i2c_board_info  const  sfe4003_hwmon_info  = 
     {{'l', 'm', '8', '7', '\000'}, (unsigned short)0, 46U, (void *)(& sfe4003_lm87_channel),
    0, 0, 0, 0};
static void sfe4003_set_id_led(struct efx_nic *efx , enum efx_led_mode mode ) 
{ 
  struct falcon_board *board ;
  struct falcon_board *tmp ;

  {
  tmp = falcon_board(efx);
  board = tmp;
  if (board->minor <= 2 && board->major == 0) {
    return;
  } else {

  }
  falcon_txc_set_gpio_val(efx, 11, (unsigned int )mode == 1U);
  return;
}
}
static void sfe4003_init_phy(struct efx_nic *efx ) 
{ 
  struct falcon_board *board ;
  struct falcon_board *tmp ;

  {
  tmp = falcon_board(efx);
  board = tmp;
  if (board->minor <= 2 && board->major == 0) {
    return;
  } else {

  }
  falcon_txc_set_gpio_dir(efx, 11, 1);
  falcon_txc_set_gpio_val(efx, 11, 0);
  return;
}
}
static int sfe4003_check_hw(struct efx_nic *efx ) 
{ 
  struct falcon_board *board ;
  struct falcon_board *tmp ;
  unsigned int alarm_mask ;
  int tmp___0 ;

  {
  tmp = falcon_board(efx);
  board = tmp;
  alarm_mask = board->major == 0 && board->minor <= 2 ? 4294967263U : 4294967295U;
  tmp___0 = efx_check_lm87(efx, alarm_mask);
  return (tmp___0);
}
}
static int sfe4003_init(struct efx_nic *efx ) 
{ 
  int tmp ;

  {
  tmp = efx_init_lm87(efx, & sfe4003_hwmon_info, (u8 const   *)(& sfe4003_lm87_regs));
  return (tmp);
}
}
static struct falcon_board_type  const  board_types[4U]  = {      {1U, & sfe4001_init, & efx_port_dummy_op_void, & sfe4001_fini, & tenxpress_set_id_led,
      & sfe4001_check_hw}, 
        {2U, & sfe4002_init, & sfe4002_init_phy, & efx_fini_lm87, & sfe4002_set_id_led,
      & sfe4002_check_hw}, 
        {3U, & sfe4003_init, & sfe4003_init_phy, & efx_fini_lm87, & sfe4003_set_id_led,
      & sfe4003_check_hw}, 
        {82U, & sfn4112f_init, & sfn4112f_init_phy, & efx_fini_lm87, & sfn4112f_set_id_led,
      & sfn4112f_check_hw}};
int falcon_probe_board(struct efx_nic *efx , u16 revision_info ) 
{ 
  struct falcon_board *board ;
  struct falcon_board *tmp ;
  u8 type_id ;
  int i ;

  {
  tmp = falcon_board(efx);
  board = tmp;
  type_id = (u8 )((int )revision_info >> 8);
  board->major = ((int )revision_info >> 4) & 15;
  board->minor = (int )revision_info & 15;
  i = 0;
  goto ldv_55517;
  ldv_55516: ;
  if ((int )((unsigned char )board_types[i].id) == (int )type_id) {
    board->type = (struct falcon_board_type  const  *)(& board_types) + (unsigned long )i;
  } else {

  }
  i = i + 1;
  ldv_55517: ;
  if ((unsigned int )i <= 3U) {
    goto ldv_55516;
  } else {

  }

  if ((unsigned long )board->type != (unsigned long )((struct falcon_board_type  const  *)0)) {
    return (0);
  } else {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "unknown board type %d\n",
                 (int )type_id);
    } else {

    }
    return (-19);
  }
}
}
void ldv_initialize_device_attribute_18(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
  tmp = ldv_init_zalloc(48UL);
  dev_attr_phy_flash_cfg_group0 = (struct device_attribute *)tmp;
  tmp___0 = ldv_init_zalloc(1416UL);
  dev_attr_phy_flash_cfg_group1 = (struct device *)tmp___0;
  return;
}
}
void ldv_main_exported_18(void) 
{ 
  char *ldvarg15 ;
  void *tmp ;
  char *ldvarg13 ;
  void *tmp___0 ;
  size_t ldvarg14 ;
  int tmp___1 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg15 = (char *)tmp;
  tmp___0 = ldv_init_zalloc(1UL);
  ldvarg13 = (char *)tmp___0;
  ldv_memset((void *)(& ldvarg14), 0, 8UL);
  tmp___1 = __VERIFIER_nondet_int();
  switch (tmp___1) {
  case 0: ;
  if (ldv_state_variable_18 == 1) {
    set_phy_flash_cfg(dev_attr_phy_flash_cfg_group1, dev_attr_phy_flash_cfg_group0,
                      (char const   *)ldvarg15, ldvarg14);
    ldv_state_variable_18 = 1;
  } else {

  }
  goto ldv_55529;
  case 1: ;
  if (ldv_state_variable_18 == 1) {
    show_phy_flash_cfg(dev_attr_phy_flash_cfg_group1, dev_attr_phy_flash_cfg_group0,
                       ldvarg13);
    ldv_state_variable_18 = 1;
  } else {

  }
  goto ldv_55529;
  default: 
  ldv_stop();
  }
  ldv_55529: ;
  return;
}
}
bool ldv_queue_work_on_563(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_564(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_565(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_566(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_567(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_568(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_569(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_570(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_571(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_572(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_573(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_574(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
__inline static int list_empty(struct list_head  const  *head ) 
{ 


  {
  return ((unsigned long )((struct list_head  const  *)head->next) == (unsigned long )head);
}
}
extern void __xchg_wrong_size(void) ;
int ldv_mutex_trylock_599(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_597(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_600(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_601(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_596(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_598(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_602(struct mutex *ldv_func_arg1 ) ;
int ldv_mod_timer_603(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_605(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_del_timer_sync_604(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_606(struct timer_list *ldv_func_arg1 ) ;
bool ldv_queue_work_on_591(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_593(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_592(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_595(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_594(struct workqueue_struct *ldv_func_arg1 ) ;
extern unsigned long __get_free_pages(gfp_t  , unsigned int  ) ;
extern void free_pages(unsigned long  , unsigned int  ) ;
void choose_timer_13(void) ;
void activate_pending_timer_13(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void activate_suitable_timer_13(struct timer_list *timer , unsigned long data ) ;
void ldv_timer_13(int state , struct timer_list *timer ) ;
void disable_suitable_timer_13(struct timer_list *timer ) ;
int reg_timer_13(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) ;
extern int pci_reset_function(struct pci_dev * ) ;
int efx_mcdi_rpc_start(struct efx_nic *efx , unsigned int cmd , efx_dword_t const   *inbuf ,
                       size_t inlen ) ;
int efx_mcdi_rpc_finish(struct efx_nic *efx , unsigned int cmd , size_t inlen , efx_dword_t *outbuf ,
                        size_t outlen , size_t *outlen_actual ) ;
int efx_mcdi_rpc_finish_quiet(struct efx_nic *efx , unsigned int cmd , size_t inlen ,
                              efx_dword_t *outbuf , size_t outlen , size_t *outlen_actual ) ;
int efx_mcdi_rpc_async_quiet(struct efx_nic *efx , unsigned int cmd , efx_dword_t const   *inbuf ,
                             size_t inlen , size_t outlen , efx_mcdi_async_completer *complete___0 ,
                             unsigned long cookie ) ;
void efx_mcdi_sensor_event(struct efx_nic *efx , efx_qword_t *ev ) ;
void efx_mcdi_process_link_change(struct efx_nic *efx , efx_qword_t *ev ) ;
void efx_ptp_event(struct efx_nic *efx , efx_qword_t *ev ) ;
void efx_time_sync_event(struct efx_channel *channel , efx_qword_t *ev ) ;
static void efx_mcdi_timeout_async(unsigned long context ) ;
static int efx_mcdi_drv_attach(struct efx_nic *efx , bool driver_operating , bool *was_attached ) ;
static bool efx_mcdi_poll_once(struct efx_nic *efx ) ;
static void efx_mcdi_abandon(struct efx_nic *efx ) ;
static bool mcdi_logging_default  ;
int efx_mcdi_init(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_iface *mcdi ;
  bool already_attached ;
  int rc ;
  void *tmp ;
  unsigned long tmp___0 ;
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  struct lock_class_key __key___1 ;

  {
  rc = -12;
  tmp = kzalloc(712UL, 208U);
  efx->mcdi = (struct efx_mcdi_data *)tmp;
  if ((unsigned long )efx->mcdi == (unsigned long )((struct efx_mcdi_data *)0)) {
    goto fail;
  } else {

  }
  mcdi = efx_mcdi(efx);
  mcdi->efx = efx;
  tmp___0 = __get_free_pages(208U, 0U);
  mcdi->logging_buffer = (char *)tmp___0;
  if ((unsigned long )mcdi->logging_buffer == (unsigned long )((char *)0)) {
    goto fail1;
  } else {

  }
  mcdi->logging_enabled = mcdi_logging_default;
  __init_waitqueue_head(& mcdi->wq, "&mcdi->wq", & __key);
  spinlock_check(& mcdi->iface_lock);
  __raw_spin_lock_init(& mcdi->iface_lock.__annonCompField17.rlock, "&(&mcdi->iface_lock)->rlock",
                       & __key___0);
  mcdi->state = 0;
  mcdi->mode = 0;
  spinlock_check(& mcdi->async_lock);
  __raw_spin_lock_init(& mcdi->async_lock.__annonCompField17.rlock, "&(&mcdi->async_lock)->rlock",
                       & __key___1);
  INIT_LIST_HEAD(& mcdi->async_list);
  reg_timer_10(& mcdi->async_timer, & efx_mcdi_timeout_async, (unsigned long )mcdi);
  efx_mcdi_poll_reboot(efx);
  mcdi->new_epoch = 1;
  rc = efx_mcdi_handle_assertion(efx);
  if (rc != 0) {
    goto fail2;
  } else {

  }
  rc = efx_mcdi_drv_attach(efx, 1, & already_attached);
  if (rc != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Unable to register driver with MCPU\n");
    } else {

    }
    goto fail2;
  } else {

  }
  if ((int )already_attached) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Host already registered with MCPU\n");
    } else {

    }
  } else {

  }
  if ((int )(efx->mcdi)->fn_flags & 1) {
    efx->primary = efx;
  } else {

  }
  return (0);
  fail2: 
  free_pages((unsigned long )mcdi->logging_buffer, 0U);
  fail1: 
  kfree((void const   *)efx->mcdi);
  efx->mcdi = (struct efx_mcdi_data *)0;
  fail: ;
  return (rc);
}
}
void efx_mcdi_fini(struct efx_nic *efx ) 
{ 
  long tmp ;

  {
  if ((unsigned long )efx->mcdi == (unsigned long )((struct efx_mcdi_data *)0)) {
    return;
  } else {

  }
  tmp = ldv__builtin_expect((unsigned int )(efx->mcdi)->iface.state != 0U, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c"),
                         "i" (136), "i" (12UL));
    ldv_55691: ;
    goto ldv_55691;
  } else {

  }
  efx_mcdi_drv_attach(efx, 0, (bool *)0);
  free_pages((unsigned long )(efx->mcdi)->iface.logging_buffer, 0U);
  kfree((void const   *)efx->mcdi);
  return;
}
}
static void efx_mcdi_send_request(struct efx_nic *efx , unsigned int cmd , efx_dword_t const   *inbuf ,
                                  size_t inlen ) 
{ 
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp ;
  char *buf ;
  efx_dword_t hdr[2U] ;
  size_t hdr_len ;
  u32 xflags ;
  u32 seqno ;
  long tmp___0 ;
  long tmp___1 ;
  int bytes ;
    klee_make_symbolic(&bytes, sizeof(int), "bytes");
  int i ;
  bool __warned ;
  int __ret_warn_once ;
  int __ret_warn_on ;
  long tmp___2 ;
  long tmp___3 ;
  long tmp___4 ;
  bool __warned___0 ;
  int __ret_warn_once___0 ;
    klee_make_symbolic(&__ret_warn_once___0, sizeof(int), "__ret_warn_once___0");
  int __ret_warn_on___0 ;
  long tmp___5 ;
  long tmp___6 ;
  long tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;
  bool __warned___1 ;
  int __ret_warn_once___1 ;
    klee_make_symbolic(&__ret_warn_once___1, sizeof(int), "__ret_warn_once___1");
  int __ret_warn_on___1 ;
  long tmp___10 ;
  long tmp___11 ;
  long tmp___12 ;
  long tmp___13 ;

  {
  tmp = efx_mcdi(efx);
  mcdi = tmp;
  buf = mcdi->logging_buffer;
  tmp___0 = ldv__builtin_expect((unsigned int )mcdi->state == 0U, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c"),
                         "i" (159), "i" (12UL));
    ldv_55704: ;
    goto ldv_55704;
  } else {

  }
  spin_lock_bh(& mcdi->iface_lock);
  mcdi->seqno = mcdi->seqno + 1U;
  spin_unlock_bh(& mcdi->iface_lock);
  seqno = mcdi->seqno & 15U;
  xflags = 0U;
  if ((unsigned int )mcdi->mode == 1U) {
    xflags = xflags | 1U;
  } else {

  }
  if ((int )(efx->type)->mcdi_max_ver == 1) {
    hdr[0].u32[0] = ((((((unsigned int )inlen << 8) | cmd) | (seqno << 16)) | (xflags << 24)) | ((unsigned int )(! mcdi->new_epoch) << 21)) | 128U;
    hdr_len = 4UL;
  } else {
    tmp___1 = ldv__builtin_expect(inlen > 1024UL, 0L);
    if (tmp___1 != 0L) {
      __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c"),
                           "i" (184), "i" (12UL));
      ldv_55705: ;
      goto ldv_55705;
    } else {

    }
    hdr[0].u32[0] = (((seqno << 16) | (xflags << 24)) | ((unsigned int )(! mcdi->new_epoch) << 21)) | 255U;
    hdr[1].u32[0] = ((unsigned int )inlen << 16) | cmd;
    hdr_len = 8UL;
  }
  if ((int )mcdi->logging_enabled) {
    __ret_warn_once___1 = (unsigned long )buf == (unsigned long )((char *)0);
    tmp___12 = ldv__builtin_expect(__ret_warn_once___1 != 0, 0L);
    if (tmp___12 != 0L) {
      __ret_warn_on___1 = ! __warned___1;
      tmp___10 = ldv__builtin_expect(__ret_warn_on___1 != 0, 0L);
      if (tmp___10 != 0L) {
        warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c",
                           200);
      } else {

      }
      tmp___11 = ldv__builtin_expect(__ret_warn_on___1 != 0, 0L);
      if (tmp___11 != 0L) {
        __warned___1 = 1;
      } else {

      }
    } else {

    }
    tmp___13 = ldv__builtin_expect(__ret_warn_once___1 != 0, 0L);
    if (tmp___13 == 0L) {
      bytes = 0;
      __ret_warn_once = (hdr_len & 3UL) != 0UL;
      tmp___4 = ldv__builtin_expect(__ret_warn_once != 0, 0L);
      if (tmp___4 != 0L) {
        __ret_warn_on = ! __warned;
        tmp___2 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
        if (tmp___2 != 0L) {
          warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c",
                             206);
        } else {

        }
        tmp___3 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
        if (tmp___3 != 0L) {
          __warned = 1;
        } else {

        }
      } else {

      }
      ldv__builtin_expect(__ret_warn_once != 0, 0L);
      __ret_warn_once___0 = (inlen & 3UL) != 0UL;
      tmp___7 = ldv__builtin_expect(__ret_warn_once___0 != 0, 0L);
      if (tmp___7 != 0L) {
        __ret_warn_on___0 = ! __warned___0;
        tmp___5 = ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
        if (tmp___5 != 0L) {
          warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c",
                             207);
        } else {

        }
        tmp___6 = ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
        if (tmp___6 != 0L) {
          __warned___0 = 1;
        } else {

        }
      } else {

      }
      ldv__builtin_expect(__ret_warn_once___0 != 0, 0L);
      i = 0;
      goto ldv_55724;
      ldv_55723: 
      tmp___8 = snprintf(buf + (unsigned long )bytes, 4096UL - (unsigned long )bytes,
                         " %08x", hdr[i].u32[0]);
      bytes = tmp___8 + bytes;
      i = i + 1;
      ldv_55724: ;
      if ((size_t )i < hdr_len / 4UL && (unsigned int )bytes <= 4095U) {
        goto ldv_55723;
      } else {

      }
      i = 0;
      goto ldv_55727;
      ldv_55726: 
      tmp___9 = snprintf(buf + (unsigned long )bytes, 4096UL - (unsigned long )bytes,
                         " %08x", (inbuf + (unsigned long )i)->u32[0]);
      bytes = tmp___9 + bytes;
      i = i + 1;
      ldv_55727: ;
      if ((size_t )i < inlen / 4UL && (unsigned int )bytes <= 4095U) {
        goto ldv_55726;
      } else {

      }

      if ((efx->msg_enable & 8192U) != 0U) {
        netdev_info((struct net_device  const  *)efx->net_dev, "MCDI RPC REQ:%s\n",
                    buf);
      } else {

      }
    } else {

    }
  } else {

  }
  (*((efx->type)->mcdi_request))(efx, (efx_dword_t const   *)(& hdr), hdr_len, inbuf,
                                 inlen);
  mcdi->new_epoch = 0;
  return;
}
}
static int efx_mcdi_errno(unsigned int mcdi_err ) 
{ 


  {
  switch (mcdi_err) {
  case 0U: ;
  return (0);
  case 1U: ;
  return (-1);
  case 2U: ;
  return (-2);
  case 4U: ;
  return (-4);
  case 11U: ;
  return (-11);
  case 13U: ;
  return (-13);
  case 16U: ;
  return (-16);
  case 22U: ;
  return (-22);
  case 35U: ;
  return (-35);
  case 38U: ;
  return (-38);
  case 62U: ;
  return (-62);
  case 114U: ;
  return (-114);
  case 28U: ;
  return (-28);
  case 95U: ;
  return (-95);
  case 4096U: ;
  return (-105);
  case 4105U: ;
  return (-98);
  default: ;
  return (-71);
  }
}
}
static void efx_mcdi_read_response_header(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp ;
  unsigned int respseq ;
    klee_make_symbolic(&respseq, sizeof(int), "respseq");
  unsigned int respcmd ;
    klee_make_symbolic(&respcmd, sizeof(int), "respcmd");
  unsigned int error ;
  char *buf ;
  efx_dword_t hdr ;
  size_t hdr_len ;
  size_t data_len ;
  int bytes ;
  int i ;
  bool __warned ;
  int __ret_warn_once ;
  int __ret_warn_on ;
  long tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  bool __warned___0 ;
  int __ret_warn_once___0 ;
  int __ret_warn_on___0 ;
  long tmp___5 ;
  long tmp___6 ;
  long tmp___7 ;
  long tmp___8 ;

  {
  tmp = efx_mcdi(efx);
  mcdi = tmp;
  buf = mcdi->logging_buffer;
  (*((efx->type)->mcdi_read_response))(efx, & hdr, 0UL, 4UL);
  respseq = (hdr.u32[0] >> 16) & 15U;
  respcmd = hdr.u32[0] & 127U;
  error = (hdr.u32[0] >> 22) & 1U;
  if (respcmd != 127U) {
    mcdi->resp_hdr_len = 4UL;
    mcdi->resp_data_len = (size_t )(hdr.u32[0] >> 8) & 255UL;
  } else {
    (*((efx->type)->mcdi_read_response))(efx, & hdr, 4UL, 4UL);
    mcdi->resp_hdr_len = 8UL;
    mcdi->resp_data_len = (size_t )(hdr.u32[0] >> 16) & 1023UL;
  }
  if ((int )mcdi->logging_enabled) {
    __ret_warn_once___0 = (unsigned long )buf == (unsigned long )((char *)0);
    tmp___7 = ldv__builtin_expect(__ret_warn_once___0 != 0, 0L);
    if (tmp___7 != 0L) {
      __ret_warn_on___0 = ! __warned___0;
      tmp___5 = ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
      if (tmp___5 != 0L) {
        warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c",
                           286);
      } else {

      }
      tmp___6 = ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
      if (tmp___6 != 0L) {
        __warned___0 = 1;
      } else {

      }
    } else {

    }
    tmp___8 = ldv__builtin_expect(__ret_warn_once___0 != 0, 0L);
    if (tmp___8 == 0L) {
      bytes = 0;
      __ret_warn_once = (mcdi->resp_hdr_len & 3UL) != 0UL;
      tmp___2 = ldv__builtin_expect(__ret_warn_once != 0, 0L);
      if (tmp___2 != 0L) {
        __ret_warn_on = ! __warned;
        tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
        if (tmp___0 != 0L) {
          warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c",
                             291);
        } else {

        }
        tmp___1 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
        if (tmp___1 != 0L) {
          __warned = 1;
        } else {

        }
      } else {

      }
      ldv__builtin_expect(__ret_warn_once != 0, 0L);
      hdr_len = mcdi->resp_hdr_len / 4UL;
      data_len = (mcdi->resp_data_len + 3UL) / 4UL;
      i = 0;
      goto ldv_55773;
      ldv_55772: 
      (*((efx->type)->mcdi_read_response))(efx, & hdr, (size_t )(i * 4), 4UL);
      tmp___3 = snprintf(buf + (unsigned long )bytes, 4096UL - (unsigned long )bytes,
                         " %08x", hdr.u32[0]);
      bytes = tmp___3 + bytes;
      i = i + 1;
      ldv_55773: ;
      if ((size_t )i < hdr_len && (unsigned int )bytes <= 4095U) {
        goto ldv_55772;
      } else {

      }
      i = 0;
      goto ldv_55776;
      ldv_55775: 
      (*((efx->type)->mcdi_read_response))(efx, & hdr, mcdi->resp_hdr_len + (size_t )(i * 4),
                                           4UL);
      tmp___4 = snprintf(buf + (unsigned long )bytes, 4096UL - (unsigned long )bytes,
                         " %08x", hdr.u32[0]);
      bytes = tmp___4 + bytes;
      i = i + 1;
      ldv_55776: ;
      if ((size_t )i < data_len && (unsigned int )bytes <= 4095U) {
        goto ldv_55775;
      } else {

      }

      if ((efx->msg_enable & 8192U) != 0U) {
        netdev_info((struct net_device  const  *)efx->net_dev, "MCDI RPC RESP:%s\n",
                    buf);
      } else {

      }
    } else {

    }
  } else {

  }
  if (error != 0U && mcdi->resp_data_len == 0UL) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "MC rebooted\n");
    } else {

    }
    mcdi->resprc = -5;
  } else
  if (((mcdi->seqno ^ respseq) & 15U) != 0U) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "MC response mismatch tx seq 0x%x rx seq 0x%x\n",
                 respseq, mcdi->seqno);
    } else {

    }
    mcdi->resprc = -5;
  } else
  if (error != 0U) {
    (*((efx->type)->mcdi_read_response))(efx, & hdr, mcdi->resp_hdr_len, 4UL);
    mcdi->resprc = efx_mcdi_errno(hdr.u32[0]);
  } else {
    mcdi->resprc = 0;
  }
  return;
}
}
static bool efx_mcdi_poll_once(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  tmp = efx_mcdi(efx);
  mcdi = tmp;
  __asm__  volatile   ("lfence": : : "memory");
  tmp___0 = (*((efx->type)->mcdi_poll_response))(efx);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    return (0);
  } else {

  }
  spin_lock_bh(& mcdi->iface_lock);
  efx_mcdi_read_response_header(efx);
  spin_unlock_bh(& mcdi->iface_lock);
  return (1);
}
}
static int efx_mcdi_poll(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp ;
  unsigned long time ;
  unsigned long finish ;
    klee_make_symbolic(&finish, sizeof(long), "finish");
  unsigned int spins ;
    klee_make_symbolic(&spins, sizeof(int), "spins");
  int rc ;
  bool tmp___0 ;

  {
  tmp = efx_mcdi(efx);
  mcdi = tmp;
  rc = efx_mcdi_poll_reboot(efx);
  if (rc != 0) {
    spin_lock_bh(& mcdi->iface_lock);
    mcdi->resprc = rc;
    mcdi->resp_hdr_len = 0UL;
    mcdi->resp_data_len = 0UL;
    spin_unlock_bh(& mcdi->iface_lock);
    return (0);
  } else {

  }
  spins = 10000U;
  finish = (unsigned long )jiffies + 2500UL;
  ldv_55797: ;
  if (spins != 0U) {
    spins = spins - 1U;
    __const_udelay(4295UL);
  } else {
    schedule_timeout_uninterruptible(1L);
  }
  time = jiffies;
  tmp___0 = efx_mcdi_poll_once(efx);
  if ((int )tmp___0) {
    goto ldv_55790;
  } else {

  }
  if ((long )(finish - time) < 0L) {
    return (-110);
  } else {

  }
  goto ldv_55797;
  ldv_55790: ;
  return (0);
}
}
int efx_mcdi_poll_reboot(struct efx_nic *efx ) 
{ 
  int tmp ;

  {
  if ((unsigned long )efx->mcdi == (unsigned long )((struct efx_mcdi_data *)0)) {
    return (0);
  } else {

  }
  tmp = (*((efx->type)->mcdi_poll_reboot))(efx);
  return (tmp);
}
}
static bool efx_mcdi_acquire_async(struct efx_mcdi_iface *mcdi ) 
{ 
  enum efx_mcdi_state __ret ;
  enum efx_mcdi_state __old ;
  enum efx_mcdi_state __new ;
  u8 volatile   *__ptr ;
  u16 volatile   *__ptr___0 ;
  u32 volatile   *__ptr___1 ;
  u64 volatile   *__ptr___2 ;

  {
  __old = 0;
  __new = 2;
  switch (4UL) {
  case 1UL: 
  __ptr = (u8 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgb %2,%1": "=a" (__ret),
                       "+m" (*__ptr): "q" (__new), "0" (__old): "memory");
  goto ldv_55809;
  case 2UL: 
  __ptr___0 = (u16 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgw %2,%1": "=a" (__ret),
                       "+m" (*__ptr___0): "r" (__new), "0" (__old): "memory");
  goto ldv_55809;
  case 4UL: 
  __ptr___1 = (u32 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgl %2,%1": "=a" (__ret),
                       "+m" (*__ptr___1): "r" (__new), "0" (__old): "memory");
  goto ldv_55809;
  case 8UL: 
  __ptr___2 = (u64 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgq %2,%1": "=a" (__ret),
                       "+m" (*__ptr___2): "r" (__new), "0" (__old): "memory");
  goto ldv_55809;
  default: 
  __cmpxchg_wrong_size();
  }
  ldv_55809: ;
  return ((unsigned int )__ret == 0U);
}
}
static void efx_mcdi_acquire_sync(struct efx_mcdi_iface *mcdi ) 
{ 
  enum efx_mcdi_state __ret ;
  enum efx_mcdi_state __old ;
  enum efx_mcdi_state __new ;
  u8 volatile   *__ptr ;
  u16 volatile   *__ptr___0 ;
  u32 volatile   *__ptr___1 ;
  u64 volatile   *__ptr___2 ;
  wait_queue_t __wait ;
  long __ret___0 ;
  long __int ;
  long tmp ;
  enum efx_mcdi_state __ret___1 ;
  enum efx_mcdi_state __old___0 ;
  enum efx_mcdi_state __new___0 ;
  u8 volatile   *__ptr___3 ;
  u16 volatile   *__ptr___4 ;
  u32 volatile   *__ptr___5 ;
  u64 volatile   *__ptr___6 ;

  {
  __might_sleep("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c",
                422, 0);
  __old = 0;
  __new = 1;
  switch (4UL) {
  case 1UL: 
  __ptr = (u8 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgb %2,%1": "=a" (__ret),
                       "+m" (*__ptr): "q" (__new), "0" (__old): "memory");
  goto ldv_55826;
  case 2UL: 
  __ptr___0 = (u16 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgw %2,%1": "=a" (__ret),
                       "+m" (*__ptr___0): "r" (__new), "0" (__old): "memory");
  goto ldv_55826;
  case 4UL: 
  __ptr___1 = (u32 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgl %2,%1": "=a" (__ret),
                       "+m" (*__ptr___1): "r" (__new), "0" (__old): "memory");
  goto ldv_55826;
  case 8UL: 
  __ptr___2 = (u64 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgq %2,%1": "=a" (__ret),
                       "+m" (*__ptr___2): "r" (__new), "0" (__old): "memory");
  goto ldv_55826;
  default: 
  __cmpxchg_wrong_size();
  }
  ldv_55826: ;
  if ((unsigned int )__ret == 0U) {
    goto ldv_55835;
  } else {

  }
  __ret___0 = 0L;
  INIT_LIST_HEAD(& __wait.task_list);
  __wait.flags = 0U;
  ldv_55855: 
  tmp = prepare_to_wait_event(& mcdi->wq, & __wait, 2);
  __int = tmp;
  __old___0 = 0;
  __new___0 = 1;
  switch (4UL) {
  case 1UL: 
  __ptr___3 = (u8 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgb %2,%1": "=a" (__ret___1),
                       "+m" (*__ptr___3): "q" (__new___0), "0" (__old___0): "memory");
  goto ldv_55845;
  case 2UL: 
  __ptr___4 = (u16 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgw %2,%1": "=a" (__ret___1),
                       "+m" (*__ptr___4): "r" (__new___0), "0" (__old___0): "memory");
  goto ldv_55845;
  case 4UL: 
  __ptr___5 = (u32 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgl %2,%1": "=a" (__ret___1),
                       "+m" (*__ptr___5): "r" (__new___0), "0" (__old___0): "memory");
  goto ldv_55845;
  case 8UL: 
  __ptr___6 = (u64 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgq %2,%1": "=a" (__ret___1),
                       "+m" (*__ptr___6): "r" (__new___0), "0" (__old___0): "memory");
  goto ldv_55845;
  default: 
  __cmpxchg_wrong_size();
  }
  ldv_55845: ;
  if ((unsigned int )__ret___1 == 0U) {
    goto ldv_55854;
  } else {

  }
  schedule();
  goto ldv_55855;
  ldv_55854: 
  finish_wait(& mcdi->wq, & __wait);

  ldv_55835: ;
  return;
}
}
static int efx_mcdi_await_completion(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp ;
  long __ret ;
  wait_queue_t __wait ;
  long __ret___0 ;
  long __int ;
  long tmp___0 ;
  bool __cond ;
  bool __cond___0 ;
  int tmp___1 ;

  {
  tmp = efx_mcdi(efx);
  mcdi = tmp;
  __ret = 2500L;
  __might_sleep("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c",
                430, 0);
  __cond___0 = (unsigned int )mcdi->state == 3U;
  if ((int )__cond___0 && __ret == 0L) {
    __ret = 1L;
  } else {

  }
  if (((int )__cond___0 || __ret == 0L) == 0) {
    __ret___0 = 2500L;
    INIT_LIST_HEAD(& __wait.task_list);
    __wait.flags = 0U;
    ldv_55871: 
    tmp___0 = prepare_to_wait_event(& mcdi->wq, & __wait, 2);
    __int = tmp___0;
    __cond = (unsigned int )mcdi->state == 3U;
    if ((int )__cond && __ret___0 == 0L) {
      __ret___0 = 1L;
    } else {

    }
    if (((int )__cond || __ret___0 == 0L) != 0) {
      goto ldv_55870;
    } else {

    }
    __ret___0 = schedule_timeout(__ret___0);
    goto ldv_55871;
    ldv_55870: 
    finish_wait(& mcdi->wq, & __wait);
    __ret = __ret___0;
  } else {

  }
  if (__ret == 0L) {
    return (-110);
  } else {

  }
  if ((unsigned int )mcdi->mode == 0U) {
    tmp___1 = efx_mcdi_poll(efx);
    return (tmp___1);
  } else {

  }
  return (0);
}
}
static bool efx_mcdi_complete_sync(struct efx_mcdi_iface *mcdi ) 
{ 
  enum efx_mcdi_state __ret ;
  enum efx_mcdi_state __old ;
  enum efx_mcdi_state __new ;
  u8 volatile   *__ptr ;
  u16 volatile   *__ptr___0 ;
  u32 volatile   *__ptr___1 ;
  u64 volatile   *__ptr___2 ;

  {
  __old = 1;
  __new = 3;
  switch (4UL) {
  case 1UL: 
  __ptr = (u8 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgb %2,%1": "=a" (__ret),
                       "+m" (*__ptr): "q" (__new), "0" (__old): "memory");
  goto ldv_55882;
  case 2UL: 
  __ptr___0 = (u16 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgw %2,%1": "=a" (__ret),
                       "+m" (*__ptr___0): "r" (__new), "0" (__old): "memory");
  goto ldv_55882;
  case 4UL: 
  __ptr___1 = (u32 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgl %2,%1": "=a" (__ret),
                       "+m" (*__ptr___1): "r" (__new), "0" (__old): "memory");
  goto ldv_55882;
  case 8UL: 
  __ptr___2 = (u64 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgq %2,%1": "=a" (__ret),
                       "+m" (*__ptr___2): "r" (__new), "0" (__old): "memory");
  goto ldv_55882;
  default: 
  __cmpxchg_wrong_size();
  }
  ldv_55882: ;
  if ((unsigned int )__ret == 1U) {
    __wake_up(& mcdi->wq, 3U, 1, (void *)0);
    return (1);
  } else {

  }
  return (0);
}
}
static void efx_mcdi_release(struct efx_mcdi_iface *mcdi ) 
{ 
  struct efx_mcdi_async_param *async ;
  struct efx_nic *efx ;
  struct list_head  const  *__mptr ;
  int tmp___0 ;

  {
  if ((unsigned int )mcdi->mode == 1U) {
    efx = mcdi->efx;
    spin_lock_bh(& mcdi->async_lock);
    tmp___0 = list_empty((struct list_head  const  *)(& mcdi->async_list));
    if (tmp___0 == 0) {
      __mptr = (struct list_head  const  *)mcdi->async_list.next;
      async = (struct efx_mcdi_async_param *)__mptr;
    } else {
      async = (struct efx_mcdi_async_param *)0;
    }
    if ((unsigned long )async != (unsigned long )((struct efx_mcdi_async_param *)0)) {
      mcdi->state = 2;
      efx_mcdi_send_request(efx, async->cmd, (efx_dword_t const   *)async + 1U, async->inlen);
      ldv_mod_timer_603(& mcdi->async_timer, (unsigned long )jiffies + 2500UL);
    } else {

    }
    spin_unlock_bh(& mcdi->async_lock);
    if ((unsigned long )async != (unsigned long )((struct efx_mcdi_async_param *)0)) {
      return;
    } else {

    }
  } else {

  }
  mcdi->state = 0;
  __wake_up(& mcdi->wq, 3U, 1, (void *)0);
  return;
}
}
static bool efx_mcdi_complete_async(struct efx_mcdi_iface *mcdi , bool timeout ) 
{ 
  struct efx_nic *efx ;
  struct efx_mcdi_async_param *async ;
  size_t hdr_len ;
  size_t data_len ;
  size_t err_len ;
  efx_dword_t *outbuf ;
  efx_dword_t errbuf[2U] ;
  unsigned int tmp ;
  int rc ;
  enum efx_mcdi_state __ret ;
  enum efx_mcdi_state __old ;
  enum efx_mcdi_state __new ;
  u8 volatile   *__ptr ;
  u16 volatile   *__ptr___0 ;
  u32 volatile   *__ptr___1 ;
  u64 volatile   *__ptr___2 ;
  struct list_head  const  *__mptr ;
  size_t _min1 ;
  size_t _min2 ;
  unsigned long _min1___0 ;
    klee_make_symbolic(&_min1___0, sizeof(long), "_min1___0");
  size_t _min2___0 ;

  {
  efx = mcdi->efx;
  errbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    errbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  __old = 2;
  __new = 3;
  switch (4UL) {
  case 1UL: 
  __ptr = (u8 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgb %2,%1": "=a" (__ret),
                       "+m" (*__ptr): "q" (__new), "0" (__old): "memory");
  goto ldv_55915;
  case 2UL: 
  __ptr___0 = (u16 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgw %2,%1": "=a" (__ret),
                       "+m" (*__ptr___0): "r" (__new), "0" (__old): "memory");
  goto ldv_55915;
  case 4UL: 
  __ptr___1 = (u32 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgl %2,%1": "=a" (__ret),
                       "+m" (*__ptr___1): "r" (__new), "0" (__old): "memory");
  goto ldv_55915;
  case 8UL: 
  __ptr___2 = (u64 volatile   *)(& mcdi->state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgq %2,%1": "=a" (__ret),
                       "+m" (*__ptr___2): "r" (__new), "0" (__old): "memory");
  goto ldv_55915;
  default: 
  __cmpxchg_wrong_size();
  }
  ldv_55915: ;
  if ((unsigned int )__ret != 2U) {
    return (0);
  } else {

  }
  spin_lock(& mcdi->iface_lock);
  if ((int )timeout) {
    mcdi->seqno = mcdi->seqno + 1U;
    mcdi->credits = mcdi->credits + 1U;
    rc = -110;
    hdr_len = 0UL;
    data_len = 0UL;
  } else {
    rc = mcdi->resprc;
    hdr_len = mcdi->resp_hdr_len;
    data_len = mcdi->resp_data_len;
  }
  spin_unlock(& mcdi->iface_lock);
  if (! timeout) {
    ldv_del_timer_sync_604(& mcdi->async_timer);
  } else {

  }
  spin_lock(& mcdi->async_lock);
  __mptr = (struct list_head  const  *)mcdi->async_list.next;
  async = (struct efx_mcdi_async_param *)__mptr;
  list_del(& async->list);
  spin_unlock(& mcdi->async_lock);
  outbuf = (efx_dword_t *)async + 1U;
  _min1 = async->outlen;
  _min2 = data_len;
  (*((efx->type)->mcdi_read_response))(efx, outbuf, hdr_len, _min1 < _min2 ? _min1 : _min2);
  if ((! timeout && rc != 0) && ! async->quiet) {
    _min1___0 = 8UL;
    _min2___0 = data_len;
    err_len = _min1___0 < _min2___0 ? _min1___0 : _min2___0;
    (*((efx->type)->mcdi_read_response))(efx, (efx_dword_t *)(& errbuf), hdr_len,
                                         8UL);
    efx_mcdi_display_error(efx, async->cmd, async->inlen, (efx_dword_t *)(& errbuf),
                           err_len, rc);
  } else {

  }
  (*(async->complete))(efx, async->cookie, rc, outbuf, data_len);
  kfree((void const   *)async);
  efx_mcdi_release(mcdi);
  return (1);
}
}
static void efx_mcdi_ev_cpl(struct efx_nic *efx , unsigned int seqno , unsigned int datalen ,
                            unsigned int mcdi_err ) 
{ 
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp ;
  bool wake ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  tmp = efx_mcdi(efx);
  mcdi = tmp;
  wake = 0;
  spin_lock(& mcdi->iface_lock);
  if (((mcdi->seqno ^ seqno) & 15U) != 0U) {
    if (mcdi->credits != 0U) {
      mcdi->credits = mcdi->credits - 1U;
    } else
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "MC response mismatch tx seq 0x%x rx seq 0x%x\n",
                 seqno, mcdi->seqno);
    } else {

    }
  } else {
    if ((int )(efx->type)->mcdi_max_ver > 1) {
      efx_mcdi_read_response_header(efx);
    } else {
      mcdi->resprc = efx_mcdi_errno(mcdi_err);
      mcdi->resp_hdr_len = 4UL;
      mcdi->resp_data_len = (size_t )datalen;
    }
    wake = 1;
  }
  spin_unlock(& mcdi->iface_lock);
  if ((int )wake) {
    tmp___0 = efx_mcdi_complete_async(mcdi, 0);
    if (tmp___0) {
      tmp___1 = 0;
    } else {
      tmp___1 = 1;
    }
    if (tmp___1) {
      efx_mcdi_complete_sync(mcdi);
    } else {

    }
  } else {

  }
  return;
}
}
static void efx_mcdi_timeout_async(unsigned long context ) 
{ 
  struct efx_mcdi_iface *mcdi ;

  {
  mcdi = (struct efx_mcdi_iface *)context;
  efx_mcdi_complete_async(mcdi, 1);
  return;
}
}
static int efx_mcdi_check_supported(struct efx_nic *efx , unsigned int cmd , size_t inlen ) 
{ 


  {
  if ((int )(efx->type)->mcdi_max_ver < 0 || ((int )(efx->type)->mcdi_max_ver <= 1 && cmd > 127U)) {
    return (-22);
  } else {

  }
  if (inlen > 1024UL || ((int )(efx->type)->mcdi_max_ver <= 1 && inlen > 252UL)) {
    return (-90);
  } else {

  }
  return (0);
}
}
static int _efx_mcdi_rpc_finish(struct efx_nic *efx , unsigned int cmd , size_t inlen ,
                                efx_dword_t *outbuf , size_t outlen , size_t *outlen_actual ,
                                bool quiet ) 
{ 
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp ;
  efx_dword_t errbuf[2U] ;
  unsigned int tmp___0 ;
  int rc ;
  bool tmp___1 ;
  size_t hdr_len ;
  size_t data_len ;
  size_t err_len ;
  unsigned long _min1 ;
  size_t _min2 ;
  long tmp___2 ;
  size_t _min1___0 ;
  size_t _min2___0 ;

  {
  tmp = efx_mcdi(efx);
  mcdi = tmp;
  errbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 2U) {
      break;
    } else {

    }
    errbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  if ((unsigned int )mcdi->mode == 0U) {
    rc = efx_mcdi_poll(efx);
  } else {
    rc = efx_mcdi_await_completion(efx);
  }
  if (rc != 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "MC command 0x%x inlen %d mode %d timed out\n",
                 cmd, (int )inlen, (unsigned int )mcdi->mode);
    } else {

    }
    if ((unsigned int )mcdi->mode == 1U) {
      tmp___1 = efx_mcdi_poll_once(efx);
      if ((int )tmp___1) {
        if ((efx->msg_enable & 8192U) != 0U) {
          netdev_err((struct net_device  const  *)efx->net_dev, "MCDI request was completed without an event\n");
        } else {

        }
        rc = 0;
      } else {

      }
    } else {

    }
    efx_mcdi_abandon(efx);
    spin_lock_bh(& mcdi->iface_lock);
    mcdi->seqno = mcdi->seqno + 1U;
    mcdi->credits = mcdi->credits + 1U;
    spin_unlock_bh(& mcdi->iface_lock);
  } else {

  }
  if (rc != 0) {
    if ((unsigned long )outlen_actual != (unsigned long )((size_t *)0UL)) {
      *outlen_actual = 0UL;
    } else {

    }
  } else {
    spin_lock_bh(& mcdi->iface_lock);
    rc = mcdi->resprc;
    hdr_len = mcdi->resp_hdr_len;
    data_len = mcdi->resp_data_len;
    _min1 = 8UL;
    _min2 = data_len;
    err_len = _min1 < _min2 ? _min1 : _min2;
    spin_unlock_bh(& mcdi->iface_lock);
    tmp___2 = ldv__builtin_expect(rc > 0, 0L);
    if (tmp___2 != 0L) {
      __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c"),
                           "i" (677), "i" (12UL));
      ldv_55967: ;
      goto ldv_55967;
    } else {

    }
    _min1___0 = outlen;
    _min2___0 = data_len;
    (*((efx->type)->mcdi_read_response))(efx, outbuf, hdr_len, _min1___0 < _min2___0 ? _min1___0 : _min2___0);
    if ((unsigned long )outlen_actual != (unsigned long )((size_t *)0UL)) {
      *outlen_actual = data_len;
    } else {

    }
    (*((efx->type)->mcdi_read_response))(efx, (efx_dword_t *)(& errbuf), hdr_len,
                                         err_len);
    if (cmd == 61U && rc == -5) {

    } else
    if (rc == -5 || rc == -4) {
      if ((efx->msg_enable & 8192U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "MC fatal error %d\n",
                   - rc);
      } else {

      }
      efx_schedule_reset(efx, 14);
    } else
    if (rc != 0 && ! quiet) {
      efx_mcdi_display_error(efx, cmd, inlen, (efx_dword_t *)(& errbuf), err_len,
                             rc);
    } else {

    }
    if (rc == -5 || rc == -4) {
      msleep(250U);
      efx_mcdi_poll_reboot(efx);
      mcdi->new_epoch = 1;
    } else {

    }
  }
  efx_mcdi_release(mcdi);
  return (rc);
}
}
static int _efx_mcdi_rpc(struct efx_nic *efx , unsigned int cmd , efx_dword_t const   *inbuf ,
                         size_t inlen , efx_dword_t *outbuf , size_t outlen , size_t *outlen_actual ,
                         bool quiet ) 
{ 
  int rc ;
  int tmp ;

  {
  rc = efx_mcdi_rpc_start(efx, cmd, inbuf, inlen);
  if (rc != 0) {
    if ((unsigned long )outlen_actual != (unsigned long )((size_t *)0UL)) {
      *outlen_actual = 0UL;
    } else {

    }
    return (rc);
  } else {

  }
  tmp = _efx_mcdi_rpc_finish(efx, cmd, inlen, outbuf, outlen, outlen_actual, (int )quiet);
  return (tmp);
}
}
int efx_mcdi_rpc(struct efx_nic *efx , unsigned int cmd , efx_dword_t const   *inbuf ,
                 size_t inlen , efx_dword_t *outbuf , size_t outlen , size_t *outlen_actual ) 
{ 
  int tmp ;

  {
  tmp = _efx_mcdi_rpc(efx, cmd, inbuf, inlen, outbuf, outlen, outlen_actual, 0);
  return (tmp);
}
}
int efx_mcdi_rpc_quiet(struct efx_nic *efx , unsigned int cmd , efx_dword_t const   *inbuf ,
                       size_t inlen , efx_dword_t *outbuf , size_t outlen , size_t *outlen_actual ) 
{ 
  int tmp ;

  {
  tmp = _efx_mcdi_rpc(efx, cmd, inbuf, inlen, outbuf, outlen, outlen_actual, 1);
  return (tmp);
}
}
int efx_mcdi_rpc_start(struct efx_nic *efx , unsigned int cmd , efx_dword_t const   *inbuf ,
                       size_t inlen ) 
{ 
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp ;
  int rc ;

  {
  tmp = efx_mcdi(efx);
  mcdi = tmp;
  rc = efx_mcdi_check_supported(efx, cmd, inlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if ((int )efx->mc_bist_for_other_fn) {
    return (-100);
  } else {

  }
  if ((unsigned int )mcdi->mode == 2U) {
    return (-100);
  } else {

  }
  efx_mcdi_acquire_sync(mcdi);
  efx_mcdi_send_request(efx, cmd, inbuf, inlen);
  return (0);
}
}
static int _efx_mcdi_rpc_async(struct efx_nic *efx , unsigned int cmd , efx_dword_t const   *inbuf ,
                               size_t inlen , size_t outlen , efx_mcdi_async_completer *complete___0 ,
                               unsigned long cookie , bool quiet ) 
{ 
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp ;
  struct efx_mcdi_async_param *async ;
  int rc ;
  size_t _max1 ;
  size_t _max2 ;
  void *tmp___0 ;
  bool tmp___1 ;

  {
  tmp = efx_mcdi(efx);
  mcdi = tmp;
  rc = efx_mcdi_check_supported(efx, cmd, inlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if ((int )efx->mc_bist_for_other_fn) {
    return (-100);
  } else {

  }
  _max1 = inlen;
  _max2 = outlen;
  tmp___0 = kmalloc((((_max1 > _max2 ? _max1 : _max2) + 3UL) & 0xfffffffffffffffcUL) + 64UL,
                    32U);
  async = (struct efx_mcdi_async_param *)tmp___0;
  if ((unsigned long )async == (unsigned long )((struct efx_mcdi_async_param *)0)) {
    return (-12);
  } else {

  }
  async->cmd = cmd;
  async->inlen = inlen;
  async->outlen = outlen;
  async->quiet = quiet;
  async->complete = complete___0;
  async->cookie = cookie;
  memcpy((void *)async + 1U, (void const   *)inbuf, inlen);
  spin_lock_bh(& mcdi->async_lock);
  if ((unsigned int )mcdi->mode == 1U) {
    list_add_tail(& async->list, & mcdi->async_list);
    if ((unsigned long )mcdi->async_list.next == (unsigned long )(& async->list)) {
      tmp___1 = efx_mcdi_acquire_async(mcdi);
      if ((int )tmp___1) {
        efx_mcdi_send_request(efx, cmd, inbuf, inlen);
        ldv_mod_timer_605(& mcdi->async_timer, (unsigned long )jiffies + 2500UL);
      } else {

      }
    } else {

    }
  } else {
    kfree((void const   *)async);
    rc = -100;
  }
  spin_unlock_bh(& mcdi->async_lock);
  return (rc);
}
}
int efx_mcdi_rpc_async(struct efx_nic *efx , unsigned int cmd , efx_dword_t const   *inbuf ,
                       size_t inlen , size_t outlen , efx_mcdi_async_completer *complete___0 ,
                       unsigned long cookie ) 
{ 
  int tmp ;

  {
  tmp = _efx_mcdi_rpc_async(efx, cmd, inbuf, inlen, outlen, complete___0, cookie,
                            0);
  return (tmp);
}
}
int efx_mcdi_rpc_async_quiet(struct efx_nic *efx , unsigned int cmd , efx_dword_t const   *inbuf ,
                             size_t inlen , size_t outlen , efx_mcdi_async_completer *complete___0 ,
                             unsigned long cookie ) 
{ 
  int tmp ;

  {
  tmp = _efx_mcdi_rpc_async(efx, cmd, inbuf, inlen, outlen, complete___0, cookie,
                            1);
  return (tmp);
}
}
int efx_mcdi_rpc_finish(struct efx_nic *efx , unsigned int cmd , size_t inlen , efx_dword_t *outbuf ,
                        size_t outlen , size_t *outlen_actual ) 
{ 
  int tmp ;

  {
  tmp = _efx_mcdi_rpc_finish(efx, cmd, inlen, outbuf, outlen, outlen_actual, 0);
  return (tmp);
}
}
int efx_mcdi_rpc_finish_quiet(struct efx_nic *efx , unsigned int cmd , size_t inlen ,
                              efx_dword_t *outbuf , size_t outlen , size_t *outlen_actual ) 
{ 
  int tmp ;

  {
  tmp = _efx_mcdi_rpc_finish(efx, cmd, inlen, outbuf, outlen, outlen_actual, 1);
  return (tmp);
}
}
void efx_mcdi_display_error(struct efx_nic *efx , unsigned int cmd , size_t inlen ,
                            efx_dword_t *outbuf , size_t outlen , int rc ) 
{ 
  int code ;
  int err_arg ;
    klee_make_symbolic(&err_arg, sizeof(int), "err_arg");

  {
  code = 0;
  err_arg = 0;
  if (outlen > 3UL) {
    code = (int )outbuf->u32[0];
  } else {

  }
  if (outlen > 7UL) {
    err_arg = (int )(outbuf + 1UL)->u32[0];
  } else {

  }
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "MC command 0x%x inlen %d failed rc=%d (raw=%d) arg=%d\n",
               cmd, (int )inlen, rc, code, err_arg);
  } else {

  }
  return;
}
}
void efx_mcdi_mode_poll(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_iface *mcdi ;

  {
  if ((unsigned long )efx->mcdi == (unsigned long )((struct efx_mcdi_data *)0)) {
    return;
  } else {

  }
  mcdi = efx_mcdi(efx);
  if ((unsigned int )mcdi->mode == 0U || (unsigned int )mcdi->mode == 2U) {
    return;
  } else {

  }
  mcdi->mode = 0;
  efx_mcdi_complete_sync(mcdi);
  return;
}
}
void efx_mcdi_flush_async(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_async_param *async ;
  struct efx_mcdi_async_param *next ;
  struct efx_mcdi_iface *mcdi ;
  long tmp ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;

  {
  if ((unsigned long )efx->mcdi == (unsigned long )((struct efx_mcdi_data *)0)) {
    return;
  } else {

  }
  mcdi = efx_mcdi(efx);
  tmp = ldv__builtin_expect((unsigned int )mcdi->mode == 1U, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c"),
                         "i" (941), "i" (12UL));
    ldv_56092: ;
    goto ldv_56092;
  } else {

  }
  ldv_del_timer_sync_606(& mcdi->async_timer);
  if ((unsigned int )mcdi->state == 2U) {
    efx_mcdi_poll(efx);
    mcdi->state = 0;
  } else {

  }
  __mptr = (struct list_head  const  *)mcdi->async_list.next;
  async = (struct efx_mcdi_async_param *)__mptr;
  __mptr___0 = (struct list_head  const  *)async->list.next;
  next = (struct efx_mcdi_async_param *)__mptr___0;
  goto ldv_56100;
  ldv_56099: 
  (*(async->complete))(efx, async->cookie, -100, (efx_dword_t *)0, 0UL);
  list_del(& async->list);
  kfree((void const   *)async);
  async = next;
  __mptr___1 = (struct list_head  const  *)next->list.next;
  next = (struct efx_mcdi_async_param *)__mptr___1;
  ldv_56100: ;
  if ((unsigned long )(& async->list) != (unsigned long )(& mcdi->async_list)) {
    goto ldv_56099;
  } else {

  }

  return;
}
}
void efx_mcdi_mode_event(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_iface *mcdi ;

  {
  if ((unsigned long )efx->mcdi == (unsigned long )((struct efx_mcdi_data *)0)) {
    return;
  } else {

  }
  mcdi = efx_mcdi(efx);
  if ((unsigned int )mcdi->mode == 1U || (unsigned int )mcdi->mode == 2U) {
    return;
  } else {

  }
  efx_mcdi_acquire_sync(mcdi);
  mcdi->mode = 1;
  efx_mcdi_release(mcdi);
  return;
}
}
static void efx_mcdi_ev_death(struct efx_nic *efx , int rc ) 
{ 
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp ;
  int count ;
  int tmp___0 ;
  bool tmp___1 ;

  {
  tmp = efx_mcdi(efx);
  mcdi = tmp;
  spin_lock(& mcdi->iface_lock);
  tmp___1 = efx_mcdi_complete_sync(mcdi);
  if ((int )tmp___1) {
    if ((unsigned int )mcdi->mode == 1U) {
      mcdi->resprc = rc;
      mcdi->resp_hdr_len = 0UL;
      mcdi->resp_data_len = 0UL;
      mcdi->credits = mcdi->credits + 1U;
    } else {

    }
  } else {
    count = 0;
    goto ldv_56114;
    ldv_56113: 
    tmp___0 = efx_mcdi_poll_reboot(efx);
    if (tmp___0 != 0) {
      goto ldv_56112;
    } else {

    }
    __const_udelay(429500UL);
    count = count + 1;
    ldv_56114: ;
    if (count <= 2499) {
      goto ldv_56113;
    } else {

    }
    ldv_56112: 
    mcdi->new_epoch = 1;
    efx_schedule_reset(efx, 14);
  }
  spin_unlock(& mcdi->iface_lock);
  return;
}
}
static void efx_mcdi_ev_bist(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp ;
  bool tmp___0 ;

  {
  tmp = efx_mcdi(efx);
  mcdi = tmp;
  spin_lock(& mcdi->iface_lock);
  efx->mc_bist_for_other_fn = 1;
  tmp___0 = efx_mcdi_complete_sync(mcdi);
  if ((int )tmp___0) {
    if ((unsigned int )mcdi->mode == 1U) {
      mcdi->resprc = -5;
      mcdi->resp_hdr_len = 0UL;
      mcdi->resp_data_len = 0UL;
      mcdi->credits = mcdi->credits + 1U;
    } else {

    }
  } else {

  }
  mcdi->new_epoch = 1;
  efx_schedule_reset(efx, 6);
  spin_unlock(& mcdi->iface_lock);
  return;
}
}
static void efx_mcdi_abandon(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp ;
  enum efx_mcdi_mode __ret ;
  struct _ddebug descriptor ;
  long tmp___0 ;

  {
  tmp = efx_mcdi(efx);
  mcdi = tmp;
  __ret = 2;
  switch (4UL) {
  case 1UL: 
  __asm__  volatile   ("xchgb %b0, %1\n": "+q" (__ret), "+m" (mcdi->mode): : "memory",
                       "cc");
  goto ldv_56125;
  case 2UL: 
  __asm__  volatile   ("xchgw %w0, %1\n": "+r" (__ret), "+m" (mcdi->mode): : "memory",
                       "cc");
  goto ldv_56125;
  case 4UL: 
  __asm__  volatile   ("xchgl %0, %1\n": "+r" (__ret), "+m" (mcdi->mode): : "memory",
                       "cc");
  goto ldv_56125;
  case 8UL: 
  __asm__  volatile   ("xchgq %q0, %1\n": "+r" (__ret), "+m" (mcdi->mode): : "memory",
                       "cc");
  goto ldv_56125;
  default: 
  __xchg_wrong_size();
  }
  ldv_56125: ;
  if ((unsigned int )__ret == 2U) {
    return;
  } else {

  }
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_mcdi_abandon";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c";
    descriptor.format = "MCDI is timing out; trying to recover\n";
    descriptor.lineno = 1077U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "MCDI is timing out; trying to recover\n");
    } else {

    }
  } else {

  }
  efx_schedule_reset(efx, 15);
  return;
}
}
void efx_mcdi_process_event(struct efx_channel *channel , efx_qword_t *event ) 
{ 
  struct efx_nic *efx ;
  int code ;
  u32 data ;
  struct _ddebug descriptor ;
  long tmp ;

  {
  efx = channel->efx;
  code = (int )(event->u64[0] >> 44) & 255;
  data = (u32 )event->u64[0];
  switch (code) {
  case 1: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "MC watchdog or assertion failure at 0x%x\n",
               data);
  } else {

  }
  efx_mcdi_ev_death(efx, -4);
  goto ldv_56141;
  case 2: ;
  if ((efx->msg_enable & 16384U) != 0U) {
    netdev_info((struct net_device  const  *)efx->net_dev, "MCDI PM event.\n");
  } else {

  }
  goto ldv_56141;
  case 3: 
  efx_mcdi_ev_cpl(efx, (unsigned int )event->u64[0] & 255U, (unsigned int )(event->u64[0] >> 8) & 255U,
                  (unsigned int )(event->u64[0] >> 16) & 255U);
  goto ldv_56141;
  case 4: 
  efx_mcdi_process_link_change(efx, event);
  goto ldv_56141;
  case 5: 
  efx_mcdi_sensor_event(efx, event);
  goto ldv_56141;
  case 6: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_mcdi_process_event";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c";
    descriptor.format = "MC Scheduler alert (0x%x)\n";
    descriptor.lineno = 1115U;
    descriptor.flags = 0U;
    tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp != 0L) {
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "MC Scheduler alert (0x%x)\n", data);
    } else {

    }
  } else {

  }
  goto ldv_56141;
  case 7: ;
  case 21: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_info((struct net_device  const  *)efx->net_dev, "MC Reboot\n");
  } else {

  }
  efx_mcdi_ev_death(efx, -5);
  goto ldv_56141;
  case 25: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_info((struct net_device  const  *)efx->net_dev, "MC entered BIST mode\n");
  } else {

  }
  efx_mcdi_ev_bist(efx);
  goto ldv_56141;
  case 8: ;
  goto ldv_56141;
  case 10: ;
  if ((unsigned long )(efx->type)->sriov_flr != (unsigned long )((void (*/* const  */)(struct efx_nic * ,
                                                                                       unsigned int  ))0)) {
    (*((efx->type)->sriov_flr))(efx, (unsigned int )event->u64[0] & 255U);
  } else {

  }
  goto ldv_56141;
  case 13: ;
  case 14: ;
  case 15: 
  efx_ptp_event(efx, event);
  goto ldv_56141;
  case 26: 
  efx_time_sync_event(channel, event);
  goto ldv_56141;
  case 12: ;
  case 16: ;
  if (((event->u64[0] >> 12) & 1ULL) == 0ULL) {
    efx_ef10_handle_drain_event(efx);
  } else {

  }
  goto ldv_56141;
  case 11: ;
  case 17: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s DMA error (event: %08x:%08x)\n",
               code == 11 ? (char *)"TX" : (char *)"RX", event->u32[1], event->u32[0]);
  } else {

  }
  efx_schedule_reset(efx, 12);
  goto ldv_56141;
  default: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "Unknown MCDI event 0x%x\n",
               code);
  } else {

  }
  }
  ldv_56141: ;
  return;
}
}
void efx_mcdi_print_fwver(struct efx_nic *efx , char *buf , size_t len ) 
{ 
  efx_dword_t outbuf[8U] ;
  unsigned int tmp ;
  size_t outlength ;
  __le16 const   *ver_words ;
  size_t offset ;
  int rc ;
  int tmp___0 ;
  struct efx_ef10_nic_data *nic_data ;
  int tmp___1 ;
  int __ret_warn_on ;
  long tmp___2 ;
  long tmp___3 ;
  int tmp___4 ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 8U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  rc = efx_mcdi_rpc(efx, 8U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    32UL, & outlength);
  if (rc != 0) {
    goto fail;
  } else {

  }
  if (outlength <= 31UL) {
    rc = -5;
    goto fail;
  } else {

  }
  ver_words = (__le16 const   *)(& outbuf) + 24U;
  tmp___0 = snprintf(buf, len, "%u.%u.%u.%u", (int )*ver_words, (int )*(ver_words + 1UL),
                     (int )*(ver_words + 2UL), (int )*(ver_words + 3UL));
  offset = (size_t )tmp___0;
  tmp___4 = efx_nic_rev(efx);
  if (tmp___4 > 3) {
    nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
    tmp___1 = snprintf(buf + offset, len - offset, " rx%x tx%x", nic_data->rx_dpcpu_fw_id,
                       nic_data->tx_dpcpu_fw_id);
    offset = (size_t )tmp___1 + offset;
    __ret_warn_on = offset >= len;
    tmp___2 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___2 != 0L) {
      warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c",
                         1213);
    } else {

    }
    tmp___3 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___3 != 0L) {
      *buf = 0;
    } else {

    }
  } else {

  }
  return;
  fail: ;
  if ((efx->msg_enable & 2U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s: failed rc=%d\n", "efx_mcdi_print_fwver",
               rc);
  } else {

  }
  *buf = 0;
  return;
}
}
static int efx_mcdi_drv_attach(struct efx_nic *efx , bool driver_operating , bool *was_attached ) 
{ 
  efx_dword_t inbuf[3U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[2U] ;
  unsigned int tmp___0 ;
  size_t outlen ;
  int rc ;
  struct _ddebug descriptor ;
  long tmp___1 ;
  unsigned int tmp___2 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 3U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 2U) {
      break;
    } else {

    }
    outbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = (int )driver_operating ? 1U : 0U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = 1U;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = 1U;
  rc = efx_mcdi_rpc_quiet(efx, 28U, (efx_dword_t const   *)(& inbuf), 12UL, (efx_dword_t *)(& outbuf),
                          8UL, & outlen);
  if (rc == -1) {
    if ((efx->msg_enable & 2U) != 0U) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_mcdi_drv_attach";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c";
      descriptor.format = "efx_mcdi_drv_attach with fw-variant setting failed EPERM, trying without it\n";
      descriptor.lineno = 1245U;
      descriptor.flags = 0U;
      tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp___1 != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "efx_mcdi_drv_attach with fw-variant setting failed EPERM, trying without it\n");
      } else {

      }
    } else {

    }
    ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = 4294967295U;
    rc = efx_mcdi_rpc_quiet(efx, 28U, (efx_dword_t const   *)(& inbuf), 12UL, (efx_dword_t *)(& outbuf),
                            8UL, & outlen);
  } else {

  }
  if (rc != 0) {
    efx_mcdi_display_error(efx, 28U, 12UL, (efx_dword_t *)(& outbuf), outlen, rc);
    goto fail;
  } else {

  }
  if (outlen <= 3UL) {
    rc = -5;
    goto fail;
  } else {

  }
  if ((int )driver_operating) {
    if (outlen > 7UL) {
      (efx->mcdi)->fn_flags = ((efx_dword_t *)(& outbuf) + 1UL)->u32[0];
    } else {
      tmp___2 = efx_port_num(efx);
      (efx->mcdi)->fn_flags = tmp___2 == 0U ? 7U : 6U;
    }
  } else {

  }
  if ((unsigned long )was_attached != (unsigned long )((bool *)0)) {
    *was_attached = ((efx_dword_t *)(& outbuf))->u32[0] != 0U;
  } else {

  }
  return (0);
  fail: ;
  if ((efx->msg_enable & 2U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s: failed rc=%d\n", "efx_mcdi_drv_attach",
               rc);
  } else {

  }
  return (rc);
}
}
int efx_mcdi_get_board_cfg(struct efx_nic *efx , u8 *mac_address , u16 *fw_subtype_list ,
                           u32 *capabilities ) 
{ 
  efx_dword_t outbuf[34U] ;
  unsigned int tmp ;
  size_t outlen ;
  size_t i ;
  int port_num ;
  unsigned int tmp___0 ;
  int rc ;
  size_t __min1 ;
  size_t __min2 ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 34U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  tmp___0 = efx_port_num(efx);
  port_num = (int )tmp___0;
  rc = efx_mcdi_rpc(efx, 24U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    136UL, & outlen);
  if (rc != 0) {
    goto fail;
  } else {

  }
  if (outlen <= 95UL) {
    rc = -5;
    goto fail;
  } else {

  }
  if ((unsigned long )mac_address != (unsigned long )((u8 *)0U)) {
    ether_addr_copy(mac_address, port_num != 0 ? (u8 const   *)(& outbuf) + 50U : (u8 const   *)(& outbuf) + 44U);
  } else {

  }
  if ((unsigned long )fw_subtype_list != (unsigned long )((u16 *)0U)) {
    i = 0UL;
    goto ldv_56228;
    ldv_56227: 
    *(fw_subtype_list + i) = (u16 )*((__le16 const   *)(& outbuf) + (i + 36UL) * 2UL);
    i = i + 1UL;
    ldv_56228: 
    __min1 = 32UL;
    __min2 = (outlen - 72UL) / 2UL;
    if ((__min1 < __min2 ? __min1 : __min2) > i) {
      goto ldv_56227;
    } else {

    }

    goto ldv_56231;
    ldv_56230: 
    *(fw_subtype_list + i) = 0U;
    i = i + 1UL;
    ldv_56231: ;
    if (i <= 31UL) {
      goto ldv_56230;
    } else {

    }

  } else {

  }
  if ((unsigned long )capabilities != (unsigned long )((u32 *)0U)) {
    if (port_num != 0) {
      *capabilities = ((efx_dword_t *)(& outbuf) + 10UL)->u32[0];
    } else {
      *capabilities = ((efx_dword_t *)(& outbuf) + 9UL)->u32[0];
    }
  } else {

  }
  return (0);
  fail: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s: failed rc=%d len=%d\n",
               "efx_mcdi_get_board_cfg", rc, (int )outlen);
  } else {

  }
  return (rc);
}
}
int efx_mcdi_log_ctrl(struct efx_nic *efx , bool evq , bool uart , u32 dest_evq ) 
{ 
  efx_dword_t inbuf[2U] ;
  unsigned int tmp ;
  u32 dest ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  dest = 0U;
  if ((int )uart) {
    dest = dest | 1U;
  } else {

  }
  if ((int )evq) {
    dest = dest | 2U;
  } else {

  }
  ((efx_dword_t *)(& inbuf))->u32[0] = dest;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = dest_evq;
  rc = efx_mcdi_rpc(efx, 7U, (efx_dword_t const   *)(& inbuf), 8UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  return (rc);
}
}
int efx_mcdi_nvram_types(struct efx_nic *efx , u32 *nvram_types_out ) 
{ 
  efx_dword_t outbuf[1U] ;
  size_t outlen ;
  int rc ;

  {
  outbuf[0].u32[0] = 0U;
  rc = efx_mcdi_rpc(efx, 54U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    4UL, & outlen);
  if (rc != 0) {
    goto fail;
  } else {

  }
  if (outlen <= 3UL) {
    rc = -5;
    goto fail;
  } else {

  }
  *nvram_types_out = ((efx_dword_t *)(& outbuf))->u32[0];
  return (0);
  fail: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s: failed rc=%d\n", "efx_mcdi_nvram_types",
               rc);
  } else {

  }
  return (rc);
}
}
int efx_mcdi_nvram_info(struct efx_nic *efx , unsigned int type , size_t *size_out ,
                        size_t *erase_size_out , bool *protected_out ) 
{ 
  efx_dword_t inbuf[1U] ;
  efx_dword_t outbuf[6U] ;
  unsigned int tmp ;
  size_t outlen ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 6U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = type;
  rc = efx_mcdi_rpc(efx, 55U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)(& outbuf),
                    24UL, & outlen);
  if (rc != 0) {
    goto fail;
  } else {

  }
  if (outlen <= 23UL) {
    rc = -5;
    goto fail;
  } else {

  }
  *size_out = (size_t )((efx_dword_t *)(& outbuf) + 1UL)->u32[0];
  *erase_size_out = (size_t )((efx_dword_t *)(& outbuf) + 2UL)->u32[0];
  *protected_out = ((int )((efx_dword_t *)(& outbuf) + 3UL)->u32[0] & 1) != 0;
  return (0);
  fail: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s: failed rc=%d\n", "efx_mcdi_nvram_info",
               rc);
  } else {

  }
  return (rc);
}
}
static int efx_mcdi_nvram_test(struct efx_nic *efx , unsigned int type ) 
{ 
  efx_dword_t inbuf[1U] ;
  efx_dword_t outbuf[1U] ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  outbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = type;
  rc = efx_mcdi_rpc(efx, 76U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)(& outbuf),
                    4UL, (size_t *)0UL);
  if (rc != 0) {
    return (rc);
  } else {

  }
  switch (((efx_dword_t *)(& outbuf))->u32[0]) {
  case 0U: ;
  case 2U: ;
  return (0);
  default: ;
  return (-5);
  }
}
}
int efx_mcdi_nvram_test_all(struct efx_nic *efx ) 
{ 
  u32 nvram_types ;
  unsigned int type ;
  int rc ;

  {
  rc = efx_mcdi_nvram_types(efx, & nvram_types);
  if (rc != 0) {
    goto fail1;
  } else {

  }
  type = 0U;
  goto ldv_56320;
  ldv_56319: ;
  if ((int )nvram_types & 1) {
    rc = efx_mcdi_nvram_test(efx, type);
    if (rc != 0) {
      goto fail2;
    } else {

    }
  } else {

  }
  type = type + 1U;
  nvram_types = nvram_types >> 1;
  ldv_56320: ;
  if (nvram_types != 0U) {
    goto ldv_56319;
  } else {

  }

  return (0);
  fail2: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s: failed type=%u\n",
               "efx_mcdi_nvram_test_all", type);
  } else {

  }
  fail1: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s: failed rc=%d\n", "efx_mcdi_nvram_test_all",
               rc);
  } else {

  }
  return (rc);
}
}
static int efx_mcdi_read_assertion(struct efx_nic *efx ) 
{ 
  efx_dword_t inbuf[1U] ;
  efx_dword_t outbuf[35U] ;
  unsigned int tmp ;
  unsigned int flags ;
  unsigned int index ;
  char const   *reason ;
  size_t outlen ;
  int retry ;
  int rc ;
  int tmp___0 ;

  {
  inbuf[0].u32[0] = 0U;
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 35U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  retry = 2;
  ldv_56336: 
  ((efx_dword_t *)(& inbuf))->u32[0] = 1U;
  rc = efx_mcdi_rpc_quiet(efx, 6U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)(& outbuf),
                          140UL, & outlen);
  if (rc == -1) {
    return (0);
  } else {

  }
  if (rc == -4 || rc == -5) {
    tmp___0 = retry;
    retry = retry - 1;
    if (tmp___0 > 0) {
      goto ldv_56336;
    } else {
      goto ldv_56337;
    }
  } else {

  }
  ldv_56337: ;
  if (rc != 0) {
    efx_mcdi_display_error(efx, 6U, 4UL, (efx_dword_t *)(& outbuf), outlen, rc);
    return (rc);
  } else {

  }
  if (outlen <= 139UL) {
    return (-5);
  } else {

  }
  flags = ((efx_dword_t *)(& outbuf))->u32[0];
  if (flags == 1U) {
    return (0);
  } else {

  }
  reason = flags != 2U ? (flags != 3U ? (flags == 4U ? "watchdog reset" : "unknown assertion") : "thread-level assertion") : "system-level assertion";
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "MCPU %s at PC = 0x%.8x in thread 0x%.8x\n",
               reason, ((efx_dword_t *)(& outbuf) + 1UL)->u32[0], ((efx_dword_t *)(& outbuf) + 33UL)->u32[0]);
  } else {

  }
  index = 0U;
  goto ldv_56363;
  ldv_56362: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "R%.2d (?): 0x%.8x\n", index + 1U,
               ((efx_dword_t *)(& outbuf) + ((unsigned long )index + 2UL) * 4UL)->u32[0]);
  } else {

  }
  index = index + 1U;
  ldv_56363: ;
  if (index <= 30U) {
    goto ldv_56362;
  } else {

  }

  return (1);
}
}
static int efx_mcdi_exit_assertion(struct efx_nic *efx ) 
{ 
  efx_dword_t inbuf[1U] ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = 1U;
  rc = efx_mcdi_rpc_quiet(efx, 61U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
                          0UL, (size_t *)0UL);
  if (rc == -5) {
    rc = 0;
  } else {

  }
  if (rc != 0) {
    efx_mcdi_display_error(efx, 61U, 4UL, (efx_dword_t *)0, 0UL, rc);
  } else {

  }
  return (rc);
}
}
int efx_mcdi_handle_assertion(struct efx_nic *efx ) 
{ 
  int rc ;
  int tmp ;

  {
  rc = efx_mcdi_read_assertion(efx);
  if (rc <= 0) {
    return (rc);
  } else {

  }
  tmp = efx_mcdi_exit_assertion(efx);
  return (tmp);
}
}
void efx_mcdi_set_id_led(struct efx_nic *efx , enum efx_led_mode mode ) 
{ 
  efx_dword_t inbuf[1U] ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = (unsigned int )mode;
  rc = efx_mcdi_rpc(efx, 43U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  return;
}
}
static int efx_mcdi_reset_func(struct efx_nic *efx ) 
{ 
  efx_dword_t inbuf[1U] ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = 1U;
  rc = efx_mcdi_rpc(efx, 32U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  return (rc);
}
}
static int efx_mcdi_reset_mc(struct efx_nic *efx ) 
{ 
  efx_dword_t inbuf[1U] ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = 0U;
  rc = efx_mcdi_rpc(efx, 61U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  if (rc == -5) {
    return (0);
  } else {

  }
  if (rc == 0) {
    rc = -5;
  } else {

  }
  return (rc);
}
}
enum reset_type efx_mcdi_map_reset_reason(enum reset_type reason ) 
{ 


  {
  return (1);
}
}
int efx_mcdi_reset(struct efx_nic *efx , enum reset_type method ) 
{ 
  int rc ;
  struct efx_mcdi_iface *mcdi ;
  struct efx_mcdi_iface *tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
  if ((unsigned int )method == 15U) {
    rc = pci_reset_function(efx->pci_dev);
    if (rc != 0) {
      return (rc);
    } else {

    }
    if ((unsigned long )efx->mcdi != (unsigned long )((struct efx_mcdi_data *)0)) {
      tmp = efx_mcdi(efx);
      mcdi = tmp;
      mcdi->mode = 0;
    } else {

    }
    return (0);
  } else {

  }
  rc = efx_mcdi_handle_assertion(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if ((unsigned int )method == 5U) {
    return (0);
  } else
  if ((unsigned int )method == 3U) {
    tmp___0 = efx_mcdi_reset_mc(efx);
    return (tmp___0);
  } else {
    tmp___1 = efx_mcdi_reset_func(efx);
    return (tmp___1);
  }
}
}
static int efx_mcdi_wol_filter_set(struct efx_nic *efx , u32 type , u8 const   *mac ,
                                   int *id_out ) 
{ 
  efx_dword_t inbuf[48U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[1U] ;
  size_t outlen ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 48U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = type;
  ((efx_dword_t *)(& inbuf))->u32[0] = 0U;
  ether_addr_copy((u8 *)(& inbuf) + 8UL, mac);
  rc = efx_mcdi_rpc(efx, 50U, (efx_dword_t const   *)(& inbuf), 192UL, (efx_dword_t *)(& outbuf),
                    4UL, & outlen);
  if (rc != 0) {
    goto fail;
  } else {

  }
  if (outlen <= 3UL) {
    rc = -5;
    goto fail;
  } else {

  }
  *id_out = (int )((efx_dword_t *)(& outbuf))->u32[0];
  return (0);
  fail: 
  *id_out = -1;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s: failed rc=%d\n", "efx_mcdi_wol_filter_set",
               rc);
  } else {

  }
  return (rc);
}
}
int efx_mcdi_wol_filter_set_magic(struct efx_nic *efx , u8 const   *mac , int *id_out ) 
{ 
  int tmp ;

  {
  tmp = efx_mcdi_wol_filter_set(efx, 0U, mac, id_out);
  return (tmp);
}
}
int efx_mcdi_wol_filter_get_magic(struct efx_nic *efx , int *id_out ) 
{ 
  efx_dword_t outbuf[1U] ;
  size_t outlen ;
  int rc ;

  {
  outbuf[0].u32[0] = 0U;
  rc = efx_mcdi_rpc(efx, 69U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    4UL, & outlen);
  if (rc != 0) {
    goto fail;
  } else {

  }
  if (outlen <= 3UL) {
    rc = -5;
    goto fail;
  } else {

  }
  *id_out = (int )((efx_dword_t *)(& outbuf))->u32[0];
  return (0);
  fail: 
  *id_out = -1;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s: failed rc=%d\n", "efx_mcdi_wol_filter_get_magic",
               rc);
  } else {

  }
  return (rc);
}
}
int efx_mcdi_wol_filter_remove(struct efx_nic *efx , int id ) 
{ 
  efx_dword_t inbuf[1U] ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = (unsigned int )id;
  rc = efx_mcdi_rpc(efx, 51U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  return (rc);
}
}
int efx_mcdi_flush_rxqs(struct efx_nic *efx ) 
{ 
  struct efx_channel *channel ;
  struct efx_rx_queue *rx_queue ;
  efx_dword_t inbuf[32U] ;
  unsigned int tmp ;
  int rc ;
  int count ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int __ret_warn_on ;
  long tmp___3 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 32U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  count = 0;
  channel = efx->channel[0];
  goto ldv_56477;
  ldv_56476: 
  tmp___1 = efx_channel_has_rx_queue(channel);
  if (tmp___1) {
    tmp___2 = 0;
  } else {
    tmp___2 = 1;
  }
  if (tmp___2) {

  } else {
    rx_queue = & channel->rx_queue;
    goto ldv_56474;
    ldv_56473: ;
    if ((int )rx_queue->flush_pending) {
      rx_queue->flush_pending = 0;
      atomic_dec(& efx->rxq_flush_pending);
      tmp___0 = efx_rx_queue_index(rx_queue);
      ((efx_dword_t *)(& inbuf) + (unsigned long )count * 4UL)->u32[0] = (__le32 )tmp___0;
      count = count + 1;
    } else {

    }
    rx_queue = (struct efx_rx_queue *)0;
    ldv_56474: ;
    if ((unsigned long )rx_queue != (unsigned long )((struct efx_rx_queue *)0)) {
      goto ldv_56473;
    } else {

    }

  }
  channel = (unsigned int )(channel->channel + 1) < efx->n_channels ? efx->channel[channel->channel + 1] : (struct efx_channel *)0;
  ldv_56477: ;
  if ((unsigned long )channel != (unsigned long )((struct efx_channel *)0)) {
    goto ldv_56476;
  } else {

  }
  rc = efx_mcdi_rpc(efx, 39U, (efx_dword_t const   *)(& inbuf), (size_t )(count * 4),
                    (efx_dword_t *)0, 0UL, (size_t *)0UL);
  __ret_warn_on = rc < 0;
  tmp___3 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___3 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi.c",
                       1769);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  return (rc);
}
}
int efx_mcdi_wol_filter_reset(struct efx_nic *efx ) 
{ 
  int rc ;

  {
  rc = efx_mcdi_rpc(efx, 52U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)0, 0UL,
                    (size_t *)0UL);
  return (rc);
}
}
int efx_mcdi_set_workaround(struct efx_nic *efx , u32 type , bool enabled ) 
{ 
  efx_dword_t inbuf[2U] ;
  unsigned int tmp ;
  int tmp___0 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = type;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )enabled;
  tmp___0 = efx_mcdi_rpc(efx, 74U, (efx_dword_t const   *)(& inbuf), 8UL, (efx_dword_t *)0,
                         0UL, (size_t *)0UL);
  return (tmp___0);
}
}
int efx_mcdi_get_workarounds(struct efx_nic *efx , unsigned int *impl_out , unsigned int *enabled_out ) 
{ 
  efx_dword_t outbuf[2U] ;
  unsigned int tmp ;
  size_t outlen ;
  int rc ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  rc = efx_mcdi_rpc(efx, 89U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    8UL, & outlen);
  if (rc != 0) {
    goto fail;
  } else {

  }
  if (outlen <= 7UL) {
    rc = -5;
    goto fail;
  } else {

  }
  if ((unsigned long )impl_out != (unsigned long )((unsigned int *)0U)) {
    *impl_out = ((efx_dword_t *)(& outbuf))->u32[0];
  } else {

  }
  if ((unsigned long )enabled_out != (unsigned long )((unsigned int *)0U)) {
    *enabled_out = ((efx_dword_t *)(& outbuf) + 1UL)->u32[0];
  } else {

  }
  return (0);
  fail: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s: failed rc=%d\n", "efx_mcdi_get_workarounds",
               rc);
  } else {

  }
  return (rc);
}
}
static int efx_mcdi_nvram_update_start(struct efx_nic *efx , unsigned int type ) 
{ 
  efx_dword_t inbuf[1U] ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = type;
  rc = efx_mcdi_rpc(efx, 56U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  return (rc);
}
}
static int efx_mcdi_nvram_read(struct efx_nic *efx , unsigned int type , loff_t offset ,
                               u8 *buffer , size_t length ) 
{ 
  efx_dword_t inbuf[3U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[32U] ;
  unsigned int tmp___0 ;
  size_t outlen ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 3U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 32U) {
      break;
    } else {

    }
    outbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = type;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )offset;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = (unsigned int )length;
  rc = efx_mcdi_rpc(efx, 57U, (efx_dword_t const   *)(& inbuf), 12UL, (efx_dword_t *)(& outbuf),
                    128UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  memcpy((void *)buffer, (void const   *)(& outbuf), length);
  return (0);
}
}
static int efx_mcdi_nvram_write(struct efx_nic *efx , unsigned int type , loff_t offset ,
                                u8 const   *buffer , size_t length ) 
{ 
  efx_dword_t inbuf[35U] ;
  unsigned int tmp ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 35U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = type;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )offset;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = (unsigned int )length;
  memcpy((void *)(& inbuf) + 12U, (void const   *)buffer, length);
  rc = efx_mcdi_rpc(efx, 58U, (efx_dword_t const   *)(& inbuf), (length + 15UL) & 0xfffffffffffffffcUL,
                    (efx_dword_t *)0, 0UL, (size_t *)0UL);
  return (rc);
}
}
static int efx_mcdi_nvram_erase(struct efx_nic *efx , unsigned int type , loff_t offset ,
                                size_t length ) 
{ 
  efx_dword_t inbuf[3U] ;
  unsigned int tmp ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 3U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = type;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )offset;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = (unsigned int )length;
  rc = efx_mcdi_rpc(efx, 59U, (efx_dword_t const   *)(& inbuf), 12UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  return (rc);
}
}
static int efx_mcdi_nvram_update_finish(struct efx_nic *efx , unsigned int type ) 
{ 
  efx_dword_t inbuf[2U] ;
  unsigned int tmp ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = type;
  rc = efx_mcdi_rpc(efx, 60U, (efx_dword_t const   *)(& inbuf), 8UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  return (rc);
}
}
int efx_mcdi_mtd_read(struct mtd_info *mtd , loff_t start , size_t len , size_t *retlen ,
                      u8 *buffer ) 
{ 
  struct efx_mcdi_mtd_partition *part ;
  struct mtd_info  const  *__mptr ;
  struct efx_nic *efx ;
  loff_t offset ;
  loff_t end ;
  loff_t __min1 ;
  loff_t __min2 ;
  size_t chunk ;
  int rc ;
  size_t __min1___0 ;
  size_t __min2___0 ;

  {
  __mptr = (struct mtd_info  const  *)mtd;
  part = (struct efx_mcdi_mtd_partition *)__mptr + 0xfffffffffffffff0UL;
  efx = (struct efx_nic *)mtd->priv;
  offset = start;
  __min1 = (loff_t )((unsigned long long )start + (unsigned long long )len);
  __min2 = (loff_t )mtd->size;
  end = __min1 < __min2 ? __min1 : __min2;
  rc = 0;
  goto ldv_56598;
  ldv_56597: 
  __min1___0 = (size_t )(end - offset);
  __min2___0 = 128UL;
  chunk = __min1___0 < __min2___0 ? __min1___0 : __min2___0;
  rc = efx_mcdi_nvram_read(efx, (unsigned int )part->nvram_type, offset, buffer, chunk);
  if (rc != 0) {
    goto out;
  } else {

  }
  offset = (loff_t )((unsigned long long )offset + (unsigned long long )chunk);
  buffer = buffer + chunk;
  ldv_56598: ;
  if (offset < end) {
    goto ldv_56597;
  } else {

  }

  out: 
  *retlen = (size_t )(offset - start);
  return (rc);
}
}
int efx_mcdi_mtd_erase(struct mtd_info *mtd , loff_t start , size_t len ) 
{ 
  struct efx_mcdi_mtd_partition *part ;
  struct mtd_info  const  *__mptr ;
  struct efx_nic *efx ;
  loff_t offset ;
  loff_t end ;
  loff_t __min1 ;
  loff_t __min2 ;
  size_t chunk ;
  int rc ;

  {
  __mptr = (struct mtd_info  const  *)mtd;
  part = (struct efx_mcdi_mtd_partition *)__mptr + 0xfffffffffffffff0UL;
  efx = (struct efx_nic *)mtd->priv;
  offset = ~ ((long long )(mtd->erasesize - 1U)) & start;
  __min1 = (loff_t )((unsigned long long )start + (unsigned long long )len);
  __min2 = (loff_t )mtd->size;
  end = __min1 < __min2 ? __min1 : __min2;
  chunk = (size_t )part->common.mtd.erasesize;
  rc = 0;
  if (! part->updating) {
    rc = efx_mcdi_nvram_update_start(efx, (unsigned int )part->nvram_type);
    if (rc != 0) {
      goto out;
    } else {

    }
    part->updating = 1;
  } else {

  }
  goto ldv_56618;
  ldv_56617: 
  rc = efx_mcdi_nvram_erase(efx, (unsigned int )part->nvram_type, offset, chunk);
  if (rc != 0) {
    goto out;
  } else {

  }
  offset = (loff_t )((unsigned long long )offset + (unsigned long long )chunk);
  ldv_56618: ;
  if (offset < end) {
    goto ldv_56617;
  } else {

  }

  out: ;
  return (rc);
}
}
int efx_mcdi_mtd_write(struct mtd_info *mtd , loff_t start , size_t len , size_t *retlen ,
                       u8 const   *buffer ) 
{ 
  struct efx_mcdi_mtd_partition *part ;
  struct mtd_info  const  *__mptr ;
  struct efx_nic *efx ;
  loff_t offset ;
  loff_t end ;
  loff_t __min1 ;
  loff_t __min2 ;
  size_t chunk ;
  int rc ;
  size_t __min1___0 ;
  size_t __min2___0 ;

  {
  __mptr = (struct mtd_info  const  *)mtd;
  part = (struct efx_mcdi_mtd_partition *)__mptr + 0xfffffffffffffff0UL;
  efx = (struct efx_nic *)mtd->priv;
  offset = start;
  __min1 = (loff_t )((unsigned long long )start + (unsigned long long )len);
  __min2 = (loff_t )mtd->size;
  end = __min1 < __min2 ? __min1 : __min2;
  rc = 0;
  if (! part->updating) {
    rc = efx_mcdi_nvram_update_start(efx, (unsigned int )part->nvram_type);
    if (rc != 0) {
      goto out;
    } else {

    }
    part->updating = 1;
  } else {

  }
  goto ldv_56643;
  ldv_56642: 
  __min1___0 = (size_t )(end - offset);
  __min2___0 = 128UL;
  chunk = __min1___0 < __min2___0 ? __min1___0 : __min2___0;
  rc = efx_mcdi_nvram_write(efx, (unsigned int )part->nvram_type, offset, buffer,
                            chunk);
  if (rc != 0) {
    goto out;
  } else {

  }
  offset = (loff_t )((unsigned long long )offset + (unsigned long long )chunk);
  buffer = buffer + chunk;
  ldv_56643: ;
  if (offset < end) {
    goto ldv_56642;
  } else {

  }

  out: 
  *retlen = (size_t )(offset - start);
  return (rc);
}
}
int efx_mcdi_mtd_sync(struct mtd_info *mtd ) 
{ 
  struct efx_mcdi_mtd_partition *part ;
  struct mtd_info  const  *__mptr ;
  struct efx_nic *efx ;
  int rc ;

  {
  __mptr = (struct mtd_info  const  *)mtd;
  part = (struct efx_mcdi_mtd_partition *)__mptr + 0xfffffffffffffff0UL;
  efx = (struct efx_nic *)mtd->priv;
  rc = 0;
  if ((int )part->updating) {
    part->updating = 0;
    rc = efx_mcdi_nvram_update_finish(efx, (unsigned int )part->nvram_type);
  } else {

  }
  return (rc);
}
}
void efx_mcdi_mtd_rename(struct efx_mtd_partition *part ) 
{ 
  struct efx_mcdi_mtd_partition *mcdi_part ;
  struct efx_mtd_partition  const  *__mptr ;
  struct efx_nic *efx ;

  {
  __mptr = (struct efx_mtd_partition  const  *)part;
  mcdi_part = (struct efx_mcdi_mtd_partition *)__mptr;
  efx = (struct efx_nic *)part->mtd.priv;
  snprintf((char *)(& part->name), 36UL, "%s %s:%02x", (char *)(& efx->name), part->type_name,
           (int )mcdi_part->fw_subtype);
  return;
}
}
void choose_timer_13(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_13_0 == 1) {
    ldv_timer_13_0 = 2;
    ldv_timer_13(ldv_timer_13_0, ldv_timer_list_13_0);
  } else {

  }
  goto ldv_56664;
  case 1: ;
  if (ldv_timer_13_1 == 1) {
    ldv_timer_13_1 = 2;
    ldv_timer_13(ldv_timer_13_1, ldv_timer_list_13_1);
  } else {

  }
  goto ldv_56664;
  case 2: ;
  if (ldv_timer_13_2 == 1) {
    ldv_timer_13_2 = 2;
    ldv_timer_13(ldv_timer_13_2, ldv_timer_list_13_2);
  } else {

  }
  goto ldv_56664;
  case 3: ;
  if (ldv_timer_13_3 == 1) {
    ldv_timer_13_3 = 2;
    ldv_timer_13(ldv_timer_13_3, ldv_timer_list_13_3);
  } else {

  }
  goto ldv_56664;
  default: 
  ldv_stop();
  }
  ldv_56664: ;
  return;
}
}
void activate_pending_timer_13(struct timer_list *timer , unsigned long data , int pending_flag ) 
{ 


  {
  if ((unsigned long )ldv_timer_list_13_0 == (unsigned long )timer) {
    if (ldv_timer_13_0 == 2 || pending_flag != 0) {
      ldv_timer_list_13_0 = timer;
      ldv_timer_list_13_0->data = data;
      ldv_timer_13_0 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_13_1 == (unsigned long )timer) {
    if (ldv_timer_13_1 == 2 || pending_flag != 0) {
      ldv_timer_list_13_1 = timer;
      ldv_timer_list_13_1->data = data;
      ldv_timer_13_1 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_13_2 == (unsigned long )timer) {
    if (ldv_timer_13_2 == 2 || pending_flag != 0) {
      ldv_timer_list_13_2 = timer;
      ldv_timer_list_13_2->data = data;
      ldv_timer_13_2 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_13_3 == (unsigned long )timer) {
    if (ldv_timer_13_3 == 2 || pending_flag != 0) {
      ldv_timer_list_13_3 = timer;
      ldv_timer_list_13_3->data = data;
      ldv_timer_13_3 = 1;
    } else {

    }
    return;
  } else {

  }
  activate_suitable_timer_13(timer, data);
  return;
}
}
void activate_suitable_timer_13(struct timer_list *timer , unsigned long data ) 
{ 


  {
  if (ldv_timer_13_0 == 0 || ldv_timer_13_0 == 2) {
    ldv_timer_list_13_0 = timer;
    ldv_timer_list_13_0->data = data;
    ldv_timer_13_0 = 1;
    return;
  } else {

  }
  if (ldv_timer_13_1 == 0 || ldv_timer_13_1 == 2) {
    ldv_timer_list_13_1 = timer;
    ldv_timer_list_13_1->data = data;
    ldv_timer_13_1 = 1;
    return;
  } else {

  }
  if (ldv_timer_13_2 == 0 || ldv_timer_13_2 == 2) {
    ldv_timer_list_13_2 = timer;
    ldv_timer_list_13_2->data = data;
    ldv_timer_13_2 = 1;
    return;
  } else {

  }
  if (ldv_timer_13_3 == 0 || ldv_timer_13_3 == 2) {
    ldv_timer_list_13_3 = timer;
    ldv_timer_list_13_3->data = data;
    ldv_timer_13_3 = 1;
    return;
  } else {

  }
  return;
}
}
void ldv_timer_13(int state , struct timer_list *timer ) 
{ 


  {
  LDV_IN_INTERRUPT = 2;
  efx_mcdi_timeout_async(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void disable_suitable_timer_13(struct timer_list *timer ) 
{ 


  {
  if (ldv_timer_13_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_13_0) {
    ldv_timer_13_0 = 0;
    return;
  } else {

  }
  if (ldv_timer_13_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_13_1) {
    ldv_timer_13_1 = 0;
    return;
  } else {

  }
  if (ldv_timer_13_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_13_2) {
    ldv_timer_13_2 = 0;
    return;
  } else {

  }
  if (ldv_timer_13_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_13_3) {
    ldv_timer_13_3 = 0;
    return;
  } else {

  }
  return;
}
}
void timer_init_13(void) 
{ 


  {
  ldv_timer_13_0 = 0;
  ldv_timer_13_1 = 0;
  ldv_timer_13_2 = 0;
  ldv_timer_13_3 = 0;
  return;
}
}
int reg_timer_13(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) 
{ 


  {
  if ((unsigned long )function == (unsigned long )(& efx_mcdi_timeout_async)) {
    activate_suitable_timer_13(timer, data);
  } else {

  }
  return (0);
}
}
bool ldv_queue_work_on_591(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_592(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_593(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_594(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_595(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_596(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_597(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_598(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_599(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_600(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_601(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_602(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mod_timer_603(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_10(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_604(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_10(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_605(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___11 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_10(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_606(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___12 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_10(ldv_func_arg1);
  return (ldv_func_res);
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
__inline static int ldv_mutex_is_locked_241(struct mutex *lock ) ;
int ldv_mutex_trylock_635(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_633(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_636(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_637(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_632(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_634(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_638(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_627(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_629(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_628(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_631(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_630(struct workqueue_struct *ldv_func_arg1 ) ;
static int efx_mcdi_get_phy_cfg(struct efx_nic *efx , struct efx_mcdi_phy_data *cfg ) 
{ 
  efx_dword_t outbuf[18U] ;
  unsigned int tmp ;
  size_t outlen ;
  int rc ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 18U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  rc = efx_mcdi_rpc(efx, 36U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    72UL, & outlen);
  if (rc != 0) {
    goto fail;
  } else {

  }
  if (outlen <= 71UL) {
    rc = -5;
    goto fail;
  } else {

  }
  cfg->flags = ((efx_dword_t *)(& outbuf))->u32[0];
  cfg->type = ((efx_dword_t *)(& outbuf) + 1UL)->u32[0];
  cfg->supported_cap = ((efx_dword_t *)(& outbuf) + 2UL)->u32[0];
  cfg->channel = ((efx_dword_t *)(& outbuf) + 3UL)->u32[0];
  cfg->port = ((efx_dword_t *)(& outbuf) + 4UL)->u32[0];
  cfg->stats_mask = ((efx_dword_t *)(& outbuf) + 5UL)->u32[0];
  memcpy((void *)(& cfg->name), (void const   *)(& outbuf) + 24U, 20UL);
  cfg->media = ((efx_dword_t *)(& outbuf) + 11UL)->u32[0];
  cfg->mmd_mask = ((efx_dword_t *)(& outbuf) + 12UL)->u32[0];
  memcpy((void *)(& cfg->revision), (void const   *)(& outbuf) + 52U, 20UL);
  return (0);
  fail: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s: failed rc=%d\n", "efx_mcdi_get_phy_cfg",
               rc);
  } else {

  }
  return (rc);
}
}
static int efx_mcdi_set_link(struct efx_nic *efx , u32 capabilities , u32 flags ,
                             u32 loopback_mode , u32 loopback_speed ) 
{ 
  efx_dword_t inbuf[4U] ;
  unsigned int tmp ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 4U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = capabilities;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = flags;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = loopback_mode;
  ((efx_dword_t *)(& inbuf) + 3UL)->u32[0] = loopback_speed;
  rc = efx_mcdi_rpc(efx, 42U, (efx_dword_t const   *)(& inbuf), 16UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  return (rc);
}
}
static int efx_mcdi_loopback_modes(struct efx_nic *efx , u64 *loopback_modes ) 
{ 
  efx_dword_t outbuf[10U] ;
  unsigned int tmp ;
  size_t outlen ;
  int rc ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 10U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  rc = efx_mcdi_rpc(efx, 40U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    40UL, & outlen);
  if (rc != 0) {
    goto fail;
  } else {

  }
  if (outlen <= 31UL) {
    rc = -5;
    goto fail;
  } else {

  }
  *loopback_modes = (unsigned long long )((efx_dword_t *)(& outbuf) + 6UL)->u32[0] | ((unsigned long long )((efx_dword_t *)(& outbuf) + 7U)->u32[0] << 32);
  return (0);
  fail: ;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "%s: failed rc=%d\n", "efx_mcdi_loopback_modes",
               rc);
  } else {

  }
  return (rc);
}
}
static int efx_mcdi_mdio_read(struct net_device *net_dev , int prtad , int devad ,
                              u16 addr ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  efx_dword_t inbuf[4U] ;
  unsigned int tmp___0 ;
  efx_dword_t outbuf[2U] ;
  unsigned int tmp___1 ;
  size_t outlen ;
  int rc ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  inbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 4U) {
      break;
    } else {

    }
    inbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  outbuf[0].u32[0] = 0U;
  tmp___1 = 1U;
  while (1) {
    if (tmp___1 >= 2U) {
      break;
    } else {

    }
    outbuf[tmp___1].u32[0] = 0U;
    tmp___1 = tmp___1 + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = efx->mdio_bus;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )prtad;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = (unsigned int )devad;
  ((efx_dword_t *)(& inbuf) + 3UL)->u32[0] = (unsigned int )addr;
  rc = efx_mcdi_rpc(efx, 16U, (efx_dword_t const   *)(& inbuf), 16UL, (efx_dword_t *)(& outbuf),
                    8UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (((efx_dword_t *)(& outbuf) + 1UL)->u32[0] != 8U) {
    return (-5);
  } else {

  }
  return ((int )((unsigned short )((efx_dword_t *)(& outbuf))->u32[0]));
}
}
static int efx_mcdi_mdio_write(struct net_device *net_dev , int prtad , int devad ,
                               u16 addr , u16 value ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  efx_dword_t inbuf[5U] ;
  unsigned int tmp___0 ;
  efx_dword_t outbuf[1U] ;
  size_t outlen ;
  int rc ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  inbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 5U) {
      break;
    } else {

    }
    inbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  outbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = efx->mdio_bus;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )prtad;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = (unsigned int )devad;
  ((efx_dword_t *)(& inbuf) + 3UL)->u32[0] = (unsigned int )addr;
  ((efx_dword_t *)(& inbuf) + 4UL)->u32[0] = (unsigned int )value;
  rc = efx_mcdi_rpc(efx, 17U, (efx_dword_t const   *)(& inbuf), 20UL, (efx_dword_t *)(& outbuf),
                    4UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (((efx_dword_t *)(& outbuf))->u32[0] != 8U) {
    return (-5);
  } else {

  }
  return (0);
}
}
static u32 mcdi_to_ethtool_cap(u32 media , u32 cap ) 
{ 
  u32 result ;

  {
  result = 0U;
  switch (media) {
  case 3U: 
  result = result | 65536U;
  if ((cap & 64U) != 0U) {
    result = result | 131072U;
  } else {

  }
  if ((cap & 128U) != 0U) {
    result = result | 262144U;
  } else {

  }
  if ((cap & 2048U) != 0U) {
    result = result | 8388608U;
  } else {

  }
  goto ldv_55520;
  case 4U: ;
  case 5U: 
  result = result | 1024U;
  goto ldv_55520;
  case 7U: 
  result = result | 1024U;
  if ((cap & 2048U) != 0U) {
    result = result | 16777216U;
  } else {

  }
  goto ldv_55520;
  case 6U: 
  result = result | 128U;
  if ((cap & 2U) != 0U) {
    result = result | 1U;
  } else {

  }
  if ((cap & 4U) != 0U) {
    result = result | 2U;
  } else {

  }
  if ((cap & 8U) != 0U) {
    result = result | 4U;
  } else {

  }
  if ((cap & 16U) != 0U) {
    result = result | 8U;
  } else {

  }
  if ((cap & 32U) != 0U) {
    result = result | 16U;
  } else {

  }
  if ((cap & 64U) != 0U) {
    result = result | 32U;
  } else {

  }
  if ((cap & 128U) != 0U) {
    result = result | 4096U;
  } else {

  }
  goto ldv_55520;
  }
  ldv_55520: ;
  if ((cap & 256U) != 0U) {
    result = result | 8192U;
  } else {

  }
  if ((cap & 512U) != 0U) {
    result = result | 16384U;
  } else {

  }
  if ((cap & 1024U) != 0U) {
    result = result | 64U;
  } else {

  }
  return (result);
}
}
static u32 ethtool_to_mcdi_cap(u32 cap ) 
{ 
  u32 result ;

  {
  result = 0U;
  if ((int )cap & 1) {
    result = result | 2U;
  } else {

  }
  if ((cap & 2U) != 0U) {
    result = result | 4U;
  } else {

  }
  if ((cap & 4U) != 0U) {
    result = result | 8U;
  } else {

  }
  if ((cap & 8U) != 0U) {
    result = result | 16U;
  } else {

  }
  if ((cap & 16U) != 0U) {
    result = result | 32U;
  } else {

  }
  if ((cap & 131104U) != 0U) {
    result = result | 64U;
  } else {

  }
  if ((cap & 266240U) != 0U) {
    result = result | 128U;
  } else {

  }
  if ((cap & 25165824U) != 0U) {
    result = result | 2048U;
  } else {

  }
  if ((cap & 8192U) != 0U) {
    result = result | 256U;
  } else {

  }
  if ((cap & 16384U) != 0U) {
    result = result | 512U;
  } else {

  }
  if ((cap & 64U) != 0U) {
    result = result | 1024U;
  } else {

  }
  return (result);
}
}
static u32 efx_get_mcdi_phy_flags(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_phy_data *phy_cfg ;
  enum efx_phy_mode mode ;
  enum efx_phy_mode supported ;
  u32 flags ;

  {
  phy_cfg = (struct efx_mcdi_phy_data *)efx->phy_data;
  supported = 0;
  if ((phy_cfg->flags & 32U) != 0U) {
    supported = (enum efx_phy_mode )((unsigned int )supported | 1U);
  } else {

  }
  if ((phy_cfg->flags & 8U) != 0U) {
    supported = (enum efx_phy_mode )((unsigned int )supported | 2U);
  } else {

  }
  if ((phy_cfg->flags & 16U) != 0U) {
    supported = (enum efx_phy_mode )((unsigned int )supported | 4U);
  } else {

  }
  mode = (enum efx_phy_mode )((unsigned int )efx->phy_mode & (unsigned int )supported);
  flags = 0U;
  if ((int )mode & 1) {
    flags = flags | 4U;
  } else {

  }
  if (((unsigned int )mode & 2U) != 0U) {
    flags = flags | 1U;
  } else {

  }
  if (((unsigned int )mode & 4U) != 0U) {
    flags = flags | 2U;
  } else {

  }
  return (flags);
}
}
static u32 mcdi_to_ethtool_media(u32 media ) 
{ 


  {
  switch (media) {
  case 1U: ;
  case 2U: ;
  case 3U: ;
  return (255U);
  case 4U: ;
  case 5U: ;
  case 7U: ;
  return (3U);
  case 6U: ;
  return (0U);
  default: ;
  return (255U);
  }
}
}
static void efx_mcdi_phy_decode_link(struct efx_nic *efx , struct efx_link_state *link_state ,
                                     u32 speed , u32 flags , u32 fcntl ) 
{ 
  int __ret_warn_on ;
  long tmp ;
  int __ret_warn_on___0 ;
  long tmp___0 ;

  {
  switch (fcntl) {
  case 3U: 
  __ret_warn_on = 1;
  tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi_port.c",
                       315);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  link_state->fc = 7U;
  goto ldv_55557;
  case 2U: 
  link_state->fc = 3U;
  goto ldv_55557;
  case 1U: 
  link_state->fc = 2U;
  goto ldv_55557;
  default: 
  __ret_warn_on___0 = 1;
  tmp___0 = ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi_port.c",
                       325);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
  case 0U: 
  link_state->fc = 0U;
  goto ldv_55557;
  }
  ldv_55557: 
  link_state->up = ((int )flags & 1) != 0;
  link_state->fd = (flags & 2U) != 0U;
  link_state->speed = speed;
  return;
}
}
static int efx_mcdi_phy_probe(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_phy_data *phy_data ;
  efx_dword_t outbuf[7U] ;
  unsigned int tmp ;
  u32 caps ;
  int rc ;
  void *tmp___0 ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 7U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  tmp___0 = kzalloc(76UL, 208U);
  phy_data = (struct efx_mcdi_phy_data *)tmp___0;
  if ((unsigned long )phy_data == (unsigned long )((struct efx_mcdi_phy_data *)0)) {
    return (-12);
  } else {

  }
  rc = efx_mcdi_get_phy_cfg(efx, phy_data);
  if (rc != 0) {
    goto fail;
  } else {

  }
  rc = efx_mcdi_rpc(efx, 41U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    28UL, (size_t *)0UL);
  if (rc != 0) {
    goto fail;
  } else {

  }
  efx->phy_data = (void *)phy_data;
  efx->phy_type = phy_data->type;
  efx->mdio_bus = phy_data->channel;
  efx->mdio.prtad = (int )phy_data->port;
  efx->mdio.mmds = phy_data->mmd_mask & 4294967294U;
  efx->mdio.mode_support = 0U;
  if ((int )phy_data->mmd_mask & 1) {
    efx->mdio.mode_support = efx->mdio.mode_support | 1U;
  } else {

  }
  if ((phy_data->mmd_mask & 4294967294U) != 0U) {
    efx->mdio.mode_support = efx->mdio.mode_support | 6U;
  } else {

  }
  caps = ((efx_dword_t *)(& outbuf))->u32[0];
  if ((caps & 1024U) != 0U) {
    efx->link_advertising = mcdi_to_ethtool_cap(phy_data->media, caps);
  } else {
    phy_data->forced_cap = caps;
  }
  rc = efx_mcdi_loopback_modes(efx, & efx->loopback_modes);
  if (rc != 0) {
    goto fail;
  } else {

  }
  efx->loopback_modes = efx->loopback_modes & 0xfffffffffffffffeULL;
  efx_mcdi_phy_decode_link(efx, & efx->link_state, ((efx_dword_t *)(& outbuf) + 2UL)->u32[0],
                           ((efx_dword_t *)(& outbuf) + 4UL)->u32[0], ((efx_dword_t *)(& outbuf) + 5UL)->u32[0]);
  efx->wanted_fc = 3U;
  if ((phy_data->supported_cap & 1024U) != 0U) {
    efx->wanted_fc = (u8 )((unsigned int )efx->wanted_fc | 4U);
  } else {

  }
  efx_link_set_wanted_fc(efx, (int )efx->wanted_fc);
  return (0);
  fail: 
  kfree((void const   *)phy_data);
  return (rc);
}
}
int efx_mcdi_port_reconfigure(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_phy_data *phy_cfg ;
  u32 caps ;
  u32 tmp ;
  u32 tmp___0 ;
  u32 tmp___1 ;
  int tmp___2 ;

  {
  phy_cfg = (struct efx_mcdi_phy_data *)efx->phy_data;
  if (efx->link_advertising != 0U) {
    tmp = ethtool_to_mcdi_cap(efx->link_advertising);
    tmp___0 = tmp;
  } else {
    tmp___0 = phy_cfg->forced_cap;
  }
  caps = tmp___0;
  tmp___1 = efx_get_mcdi_phy_flags(efx);
  tmp___2 = efx_mcdi_set_link(efx, caps, tmp___1, (u32 )efx->loopback_mode, 0U);
  return (tmp___2);
}
}
static void efx_mcdi_phy_check_fcntl(struct efx_nic *efx , u32 lpa ) 
{ 
  struct efx_mcdi_phy_data *phy_cfg ;
  u32 rmtadv ;

  {
  phy_cfg = (struct efx_mcdi_phy_data *)efx->phy_data;
  if ((phy_cfg->supported_cap & 1024U) == 0U) {
    return;
  } else {

  }
  if (((int )efx->wanted_fc & 4) != 0) {
    return;
  } else {

  }
  rmtadv = 0U;
  if ((lpa & 256U) != 0U) {
    rmtadv = rmtadv | 8192U;
  } else {

  }
  if ((lpa & 512U) != 0U) {
    rmtadv = rmtadv | 16384U;
  } else {

  }
  if ((int )efx->wanted_fc & 1 && rmtadv == 16384U) {
    if ((efx->msg_enable & 4U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "warning: link partner doesn\'t support pause frames");
    } else {

    }
  } else {

  }
  return;
}
}
static bool efx_mcdi_phy_poll(struct efx_nic *efx ) 
{ 
  struct efx_link_state old_state ;
  efx_dword_t outbuf[7U] ;
  unsigned int tmp ;
  int rc ;
  int __ret_warn_on ;
  int tmp___0 ;
  long tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;

  {
  old_state = efx->link_state;
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 7U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  tmp___0 = ldv_mutex_is_locked_241(& efx->mac_lock);
  __ret_warn_on = tmp___0 == 0;
  tmp___1 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___1 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi_port.c",
                       480);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  rc = efx_mcdi_rpc(efx, 41U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    28UL, (size_t *)0UL);
  if (rc != 0) {
    efx->link_state.up = 0;
  } else {
    efx_mcdi_phy_decode_link(efx, & efx->link_state, ((efx_dword_t *)(& outbuf) + 2UL)->u32[0],
                             ((efx_dword_t *)(& outbuf) + 4UL)->u32[0], ((efx_dword_t *)(& outbuf) + 5UL)->u32[0]);
  }
  tmp___2 = efx_link_state_equal((struct efx_link_state  const  *)(& efx->link_state),
                                 (struct efx_link_state  const  *)(& old_state));
  if ((int )tmp___2 != 0) {
    tmp___3 = 0;
  } else {
    tmp___3 = 1;
  }
  return ((bool )tmp___3);
}
}
static void efx_mcdi_phy_remove(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_phy_data *phy_data ;

  {
  phy_data = (struct efx_mcdi_phy_data *)efx->phy_data;
  efx->phy_data = (void *)0;
  kfree((void const   *)phy_data);
  return;
}
}
static void efx_mcdi_phy_get_settings(struct efx_nic *efx , struct ethtool_cmd *ecmd ) 
{ 
  struct efx_mcdi_phy_data *phy_cfg ;
  efx_dword_t outbuf[7U] ;
  unsigned int tmp ;
  int rc ;
  u32 tmp___0 ;

  {
  phy_cfg = (struct efx_mcdi_phy_data *)efx->phy_data;
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 7U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ecmd->supported = mcdi_to_ethtool_cap(phy_cfg->media, phy_cfg->supported_cap);
  ecmd->advertising = efx->link_advertising;
  ethtool_cmd_speed_set(ecmd, efx->link_state.speed);
  ecmd->duplex = (__u8 )efx->link_state.fd;
  tmp___0 = mcdi_to_ethtool_media(phy_cfg->media);
  ecmd->port = (__u8 )tmp___0;
  ecmd->phy_address = (__u8 )phy_cfg->port;
  ecmd->transceiver = 0U;
  ecmd->autoneg = (efx->link_advertising & 64U) != 0U;
  ecmd->mdio_support = (unsigned int )((__u8 )efx->mdio.mode_support) & 3U;
  rc = efx_mcdi_rpc(efx, 41U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    28UL, (size_t *)0UL);
  if (rc != 0) {
    return;
  } else {

  }
  ecmd->lp_advertising = mcdi_to_ethtool_cap(phy_cfg->media, ((efx_dword_t *)(& outbuf) + 1UL)->u32[0]);
  return;
}
}
static int efx_mcdi_phy_set_settings(struct efx_nic *efx , struct ethtool_cmd *ecmd ) 
{ 
  struct efx_mcdi_phy_data *phy_cfg ;
  u32 caps ;
  int rc ;
  u32 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  u32 tmp___2 ;

  {
  phy_cfg = (struct efx_mcdi_phy_data *)efx->phy_data;
  if ((unsigned int )ecmd->autoneg != 0U) {
    tmp = ethtool_to_mcdi_cap(ecmd->advertising);
    caps = tmp | 1024U;
  } else
  if ((unsigned int )ecmd->duplex != 0U) {
    tmp___0 = ethtool_cmd_speed((struct ethtool_cmd  const  *)ecmd);
    switch (tmp___0) {
    case 10U: 
    caps = 4U;
    goto ldv_55642;
    case 100U: 
    caps = 16U;
    goto ldv_55642;
    case 1000U: 
    caps = 64U;
    goto ldv_55642;
    case 10000U: 
    caps = 128U;
    goto ldv_55642;
    case 40000U: 
    caps = 2048U;
    goto ldv_55642;
    default: ;
    return (-22);
    }
    ldv_55642: ;
  } else {
    tmp___1 = ethtool_cmd_speed((struct ethtool_cmd  const  *)ecmd);
    switch (tmp___1) {
    case 10U: 
    caps = 2U;
    goto ldv_55649;
    case 100U: 
    caps = 8U;
    goto ldv_55649;
    case 1000U: 
    caps = 32U;
    goto ldv_55649;
    default: ;
    return (-22);
    }
    ldv_55649: ;
  }
  tmp___2 = efx_get_mcdi_phy_flags(efx);
  rc = efx_mcdi_set_link(efx, caps, tmp___2, (u32 )efx->loopback_mode, 0U);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if ((unsigned int )ecmd->autoneg != 0U) {
    efx_link_set_advertising(efx, ecmd->advertising | 64U);
    phy_cfg->forced_cap = 0U;
  } else {
    efx_link_set_advertising(efx, 0U);
    phy_cfg->forced_cap = caps;
  }
  return (0);
}
}
static int efx_mcdi_phy_test_alive(struct efx_nic *efx ) 
{ 
  efx_dword_t outbuf[1U] ;
  size_t outlen ;
  int rc ;

  {
  outbuf[0].u32[0] = 0U;
  rc = efx_mcdi_rpc(efx, 67U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    4UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 3UL) {
    return (-5);
  } else {

  }
  if (((efx_dword_t *)(& outbuf))->u32[0] != 1U) {
    return (-22);
  } else {

  }
  return (0);
}
}
static char const   * const  mcdi_sft9001_cable_diag_names[8U]  = 
  {      "cable.pairA.length",      "cable.pairB.length",      "cable.pairC.length",      "cable.pairD.length", 
        "cable.pairA.status",      "cable.pairB.status",      "cable.pairC.status",      "cable.pairD.status"};
static int efx_mcdi_bist(struct efx_nic *efx , unsigned int bist_mode , int *results ) 
{ 
  unsigned int retry ;
  unsigned int i ;
  unsigned int count ;
  size_t outlen ;
  u32 status ;
  efx_dword_t inbuf[1U] ;
  efx_dword_t outbuf[9U] ;
  unsigned int tmp ;
  u8 *ptr ;
  int rc ;
  unsigned int tmp___0 ;

  {
  count = 0U;
  inbuf[0].u32[0] = 0U;
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 9U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = bist_mode;
  rc = efx_mcdi_rpc(efx, 37U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  if (rc != 0) {
    goto out;
  } else {

  }
  retry = 0U;
  goto ldv_55687;
  ldv_55686: 
  rc = efx_mcdi_rpc(efx, 38U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    36UL, & outlen);
  if (rc != 0) {
    goto out;
  } else {

  }
  status = ((efx_dword_t *)(& outbuf))->u32[0];
  if (status != 1U) {
    goto finished;
  } else {

  }
  msleep(100U);
  retry = retry + 1U;
  ldv_55687: ;
  if (retry <= 99U) {
    goto ldv_55686;
  } else {

  }
  rc = -110;
  goto out;
  finished: 
  tmp___0 = count;
  count = count + 1U;
  *(results + (unsigned long )tmp___0) = status == 2U ? 1 : -1;
  if (efx->phy_type == 10U && (bist_mode == 1U || bist_mode == 2U)) {
    ptr = (u8 *)(& outbuf) + 4UL;
    if (status == 2U && outlen > 35UL) {
      i = 0U;
      goto ldv_55690;
      ldv_55689: 
      *(results + (unsigned long )(count + i)) = (int )((efx_dword_t *)ptr + (unsigned long )i)->u32[0];
      i = i + 1U;
      ldv_55690: ;
      if (i <= 7U) {
        goto ldv_55689;
      } else {

      }

    } else {

    }
    count = count + 8U;
  } else {

  }
  rc = (int )count;
  out: ;
  return (rc);
}
}
static int efx_mcdi_phy_run_tests(struct efx_nic *efx , int *results , unsigned int flags ) 
{ 
  struct efx_mcdi_phy_data *phy_cfg ;
  u32 mode ;
  int rc ;

  {
  phy_cfg = (struct efx_mcdi_phy_data *)efx->phy_data;
  if ((phy_cfg->flags & 64U) != 0U) {
    rc = efx_mcdi_bist(efx, 5U, results);
    if (rc < 0) {
      return (rc);
    } else {

    }
    results = results + (unsigned long )rc;
  } else {

  }
  mode = 0U;
  if ((phy_cfg->flags & 2U) != 0U) {
    if ((int )flags & 1 && (phy_cfg->flags & 4U) != 0U) {
      mode = 2U;
    } else {
      mode = 1U;
    }
  } else
  if ((phy_cfg->flags & 4U) != 0U) {
    mode = 2U;
  } else {

  }
  if (mode != 0U) {
    rc = efx_mcdi_bist(efx, mode, results);
    if (rc < 0) {
      return (rc);
    } else {

    }
    results = results + (unsigned long )rc;
  } else {

  }
  return (0);
}
}
static char const   *efx_mcdi_phy_test_name(struct efx_nic *efx , unsigned int index ) 
{ 
  struct efx_mcdi_phy_data *phy_cfg ;

  {
  phy_cfg = (struct efx_mcdi_phy_data *)efx->phy_data;
  if ((phy_cfg->flags & 64U) != 0U) {
    if (index == 0U) {
      return ("bist");
    } else {

    }
    index = index - 1U;
  } else {

  }
  if ((phy_cfg->flags & 6U) != 0U) {
    if (index == 0U) {
      return ("cable");
    } else {

    }
    index = index - 1U;
    if (efx->phy_type == 10U) {
      if (index <= 7U) {
        return ((char const   *)mcdi_sft9001_cable_diag_names[index]);
      } else {

      }
      index = index - 8U;
    } else {

    }
  } else {

  }
  return ((char const   *)0);
}
}
static int efx_mcdi_phy_get_module_eeprom(struct efx_nic *efx , struct ethtool_eeprom *ee ,
                                          u8 *data ) 
{ 
  efx_dword_t outbuf[63U] ;
  unsigned int tmp ;
  efx_dword_t inbuf[1U] ;
  size_t outlen ;
  int rc ;
  unsigned int payload_len ;
    klee_make_symbolic(&payload_len, sizeof(int), "payload_len");
  unsigned int space_remaining ;
    klee_make_symbolic(&space_remaining, sizeof(int), "space_remaining");
  unsigned int page ;
    klee_make_symbolic(&page, sizeof(int), "page");
  unsigned int page_off ;
    klee_make_symbolic(&page_off, sizeof(int), "page_off");
  unsigned int to_copy ;
    klee_make_symbolic(&to_copy, sizeof(int), "to_copy");
  u8 *user_data ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 63U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  inbuf[0].u32[0] = 0U;
  space_remaining = ee->len;
  user_data = data;
  page_off = ee->offset & 127U;
  page = ee->offset / 128U;
  goto ldv_55731;
  ldv_55730: 
  ((efx_dword_t *)(& inbuf))->u32[0] = page;
  rc = efx_mcdi_rpc(efx, 75U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)(& outbuf),
                    252UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 131UL) {
    return (-5);
  } else {

  }
  payload_len = ((efx_dword_t *)(& outbuf))->u32[0];
  if (payload_len != 128U) {
    return (-5);
  } else {

  }
  payload_len = payload_len - page_off;
  to_copy = space_remaining < payload_len ? space_remaining : payload_len;
  memcpy((void *)user_data, (void const   *)(& outbuf) + ((unsigned long )page_off + 4UL),
           (size_t )to_copy);
  space_remaining = space_remaining - to_copy;
  user_data = user_data + (unsigned long )to_copy;
  page_off = 0U;
  page = page + 1U;
  ldv_55731: ;
  if (space_remaining != 0U && page <= 1U) {
    goto ldv_55730;
  } else {

  }

  return (0);
}
}
static int efx_mcdi_phy_get_module_info(struct efx_nic *efx , struct ethtool_modinfo *modinfo ) 
{ 
  struct efx_mcdi_phy_data *phy_cfg ;

  {
  phy_cfg = (struct efx_mcdi_phy_data *)efx->phy_data;
  switch (phy_cfg->media) {
  case 5U: 
  modinfo->type = 1U;
  modinfo->eeprom_len = 256U;
  return (0);
  default: ;
  return (-95);
  }
}
}
static struct efx_phy_operations  const  efx_mcdi_phy_ops  = 
     {& efx_mcdi_phy_probe, & efx_port_dummy_op_int, & efx_port_dummy_op_void, & efx_mcdi_phy_remove,
    & efx_mcdi_port_reconfigure, & efx_mcdi_phy_poll, & efx_mcdi_phy_get_settings,
    & efx_mcdi_phy_set_settings, 0, & efx_mcdi_phy_test_alive, & efx_mcdi_phy_test_name,
    & efx_mcdi_phy_run_tests, & efx_mcdi_phy_get_module_eeprom, & efx_mcdi_phy_get_module_info};
u32 efx_mcdi_phy_get_caps(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_phy_data *phy_data ;

  {
  phy_data = (struct efx_mcdi_phy_data *)efx->phy_data;
  return (phy_data->supported_cap);
}
}
static unsigned int efx_mcdi_event_link_speed[5U]  = {      0U,      100U,      1000U,      10000U, 
        40000U};
void efx_mcdi_process_link_change(struct efx_nic *efx , efx_qword_t *ev ) 
{ 
  u32 flags ;
  u32 fcntl ;
  u32 speed ;
  u32 lpa ;

  {
  speed = (u32 )(ev->u64[0] >> 16) & 15U;
  speed = efx_mcdi_event_link_speed[speed];
  flags = (u32 )(ev->u64[0] >> 24) & 255U;
  fcntl = (u32 )(ev->u64[0] >> 20) & 15U;
  lpa = (u32 )ev->u64[0] & 65535U;
  efx_mcdi_phy_decode_link(efx, & efx->link_state, speed, flags, fcntl);
  efx_mcdi_phy_check_fcntl(efx, lpa);
  efx_link_status_changed(efx);
  return;
}
}
int efx_mcdi_set_mac(struct efx_nic *efx ) 
{ 
  u32 fcntl ;
  efx_dword_t cmdbytes[6U] ;
  unsigned int tmp ;
  int tmp___0 ;

  {
  cmdbytes[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 6U) {
      break;
    } else {

    }
    cmdbytes[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ether_addr_copy((u8 *)(& cmdbytes) + 8UL, (u8 const   *)(efx->net_dev)->dev_addr);
  ((efx_dword_t *)(& cmdbytes))->u32[0] = (((efx->net_dev)->mtu + 29U) & 4294967288U) + 16U;
  ((efx_dword_t *)(& cmdbytes) + 1UL)->u32[0] = 0U;
  ((efx_dword_t *)(& cmdbytes) + 4UL)->u32[0] = (unsigned int )efx->unicast_filter;
  switch ((int )efx->wanted_fc) {
  case 3: 
  fcntl = 2U;
  goto ldv_55766;
  case 2: 
  fcntl = 1U;
  goto ldv_55766;
  default: 
  fcntl = 0U;
  goto ldv_55766;
  }
  ldv_55766: ;
  if (((int )efx->wanted_fc & 4) != 0) {
    fcntl = 3U;
  } else {

  }
  if (efx->fc_disable != 0U) {
    fcntl = 0U;
  } else {

  }
  ((efx_dword_t *)(& cmdbytes) + 5UL)->u32[0] = fcntl;
  tmp___0 = efx_mcdi_rpc(efx, 44U, (efx_dword_t const   *)(& cmdbytes), 24UL, (efx_dword_t *)0,
                         0UL, (size_t *)0UL);
  return (tmp___0);
}
}
bool efx_mcdi_mac_check_fault(struct efx_nic *efx ) 
{ 
  efx_dword_t outbuf[7U] ;
  unsigned int tmp ;
  size_t outlength ;
  int rc ;

  {
  outbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 7U) {
      break;
    } else {

    }
    outbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  rc = efx_mcdi_rpc(efx, 41U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    28UL, & outlength);
  if (rc != 0) {
    return (1);
  } else {

  }
  return (((efx_dword_t *)(& outbuf) + 6UL)->u32[0] != 0U);
}
}
static int efx_mcdi_mac_stats(struct efx_nic *efx , enum efx_stats_action action ,
                              int clear ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  efx_dword_t inbuf[5U] ;
  unsigned int tmp ;
  int rc ;
  int change ;
    klee_make_symbolic(&change, sizeof(int), "change");
  int enable ;
    klee_make_symbolic(&enable, sizeof(int), "enable");
  int period ;
    klee_make_symbolic(&period, sizeof(int), "period");
  dma_addr_t dma_addr ;
  u32 dma_len ;
  int tmp___0 ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 5U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  change = (unsigned int )action != 2U;
  enable = (unsigned int )action == 0U;
  period = (unsigned int )action == 0U ? 1000 : 0;
  dma_addr = efx->stats_buffer.dma_addr;
  dma_len = (unsigned int )action != 1U ? 776U : 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = (unsigned int )dma_addr;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )(dma_addr >> 32);
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = (((((unsigned int )(enable != 0) | ((unsigned int )clear << 1)) | ((unsigned int )change << 2)) | ((unsigned int )enable << 3)) | ((unsigned int )period << 16)) | 32U;
  ((efx_dword_t *)(& inbuf) + 3UL)->u32[0] = dma_len;
  ((efx_dword_t *)(& inbuf) + 4UL)->u32[0] = nic_data->vport_id;
  rc = efx_mcdi_rpc_quiet(efx, 46U, (efx_dword_t const   *)(& inbuf), 20UL, (efx_dword_t *)0,
                          0UL, (size_t *)0UL);
  if (rc != 0) {
    if (rc != -2) {
      efx_mcdi_display_error(efx, 46U, 20UL, (efx_dword_t *)0, 0UL, rc);
    } else {
      tmp___0 = atomic_read((atomic_t const   *)(& efx->active_queues));
      if (tmp___0 != 0) {
        efx_mcdi_display_error(efx, 46U, 20UL, (efx_dword_t *)0, 0UL, rc);
      } else {

      }
    }
  } else {

  }
  return (rc);
}
}
void efx_mcdi_mac_start_stats(struct efx_nic *efx ) 
{ 
  __le64 *dma_stats ;

  {
  dma_stats = (__le64 *)efx->stats_buffer.addr;
  *(dma_stats + 96UL) = 0xffffffffffffffffULL;
  efx_mcdi_mac_stats(efx, 0, 0);
  return;
}
}
void efx_mcdi_mac_stop_stats(struct efx_nic *efx ) 
{ 


  {
  efx_mcdi_mac_stats(efx, 1, 0);
  return;
}
}
void efx_mcdi_mac_pull_stats(struct efx_nic *efx ) 
{ 
  __le64 *dma_stats ;
  int attempts ;
    klee_make_symbolic(&attempts, sizeof(int), "attempts");
  int tmp ;

  {
  dma_stats = (__le64 *)efx->stats_buffer.addr;
  attempts = 10;
  *(dma_stats + 96UL) = 0xffffffffffffffffULL;
  efx_mcdi_mac_stats(efx, 2, 0);
  goto ldv_55821;
  ldv_55820: 
  __const_udelay(429500UL);
  ldv_55821: ;
  if (*(dma_stats + 96UL) == 0xffffffffffffffffULL) {
    tmp = attempts;
    attempts = attempts - 1;
    if (tmp != 0) {
      goto ldv_55820;
    } else {
      goto ldv_55822;
    }
  } else {

  }
  ldv_55822: ;
  return;
}
}
int efx_mcdi_port_probe(struct efx_nic *efx ) 
{ 
  int rc ;
  struct _ddebug descriptor ;
  phys_addr_t tmp ;
  long tmp___0 ;

  {
  efx->phy_op = & efx_mcdi_phy_ops;
  efx->mdio.mode_support = 6U;
  efx->mdio.mdio_read = & efx_mcdi_mdio_read;
  efx->mdio.mdio_write = & efx_mcdi_mdio_write;
  rc = (*((efx->phy_op)->probe))(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = efx_nic_alloc_buffer(efx, & efx->stats_buffer, 776U, 208U);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if ((efx->msg_enable & 2U) != 0U) {
    descriptor.modname = "sfc";
    descriptor.function = "efx_mcdi_port_probe";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mcdi_port.c";
    descriptor.format = "stats buffer at %llx (virt %p phys %llx)\n";
    descriptor.lineno = 1017U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      tmp = virt_to_phys((void volatile   *)efx->stats_buffer.addr);
      __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                           "stats buffer at %llx (virt %p phys %llx)\n", efx->stats_buffer.dma_addr,
                           efx->stats_buffer.addr, tmp);
    } else {

    }
  } else {

  }
  efx_mcdi_mac_stats(efx, 1, 1);
  return (0);
}
}
void efx_mcdi_port_remove(struct efx_nic *efx ) 
{ 


  {
  (*((efx->phy_op)->remove))(efx);
  efx_nic_free_buffer(efx, & efx->stats_buffer);
  return;
}
}
int efx_mcdi_port_get_number(struct efx_nic *efx ) 
{ 
  efx_dword_t outbuf[1U] ;
  int rc ;

  {
  outbuf[0].u32[0] = 0U;
  rc = efx_mcdi_rpc(efx, 184U, (efx_dword_t const   *)0, 0UL, (efx_dword_t *)(& outbuf),
                    4UL, (size_t *)0UL);
  if (rc != 0) {
    return (rc);
  } else {

  }
  return ((int )((efx_dword_t *)(& outbuf))->u32[0]);
}
}
void ldv_initialize_efx_phy_operations_17(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
  tmp = ldv_init_zalloc(44UL);
  efx_mcdi_phy_ops_group0 = (struct ethtool_cmd *)tmp;
  tmp___0 = ldv_init_zalloc(4032UL);
  efx_mcdi_phy_ops_group1 = (struct efx_nic *)tmp___0;
  return;
}
}
void ldv_main_exported_17(void) 
{ 
  unsigned int ldvarg9 ;
    klee_make_symbolic(&ldvarg9, sizeof(int), "ldvarg9");
  struct ethtool_modinfo *ldvarg12 ;
  void *tmp ;
  int *ldvarg10 ;
  void *tmp___0 ;
  u8 *ldvarg7 ;
  void *tmp___1 ;
  unsigned int ldvarg11 ;
    klee_make_symbolic(&ldvarg11, sizeof(int), "ldvarg11");
  struct ethtool_eeprom *ldvarg8 ;
  void *tmp___2 ;
  int tmp___3 ;

  {
  tmp = ldv_init_zalloc(44UL);
  ldvarg12 = (struct ethtool_modinfo *)tmp;
  tmp___0 = ldv_init_zalloc(4UL);
  ldvarg10 = (int *)tmp___0;
  tmp___1 = ldv_init_zalloc(1UL);
  ldvarg7 = (u8 *)tmp___1;
  tmp___2 = ldv_init_zalloc(16UL);
  ldvarg8 = (struct ethtool_eeprom *)tmp___2;
  ldv_memset((void *)(& ldvarg9), 0, 4UL);
  ldv_memset((void *)(& ldvarg11), 0, 4UL);
  tmp___3 = __VERIFIER_nondet_int();
  switch (tmp___3) {
  case 0: ;
  if (ldv_state_variable_17 == 1) {
    efx_mcdi_phy_get_module_info(efx_mcdi_phy_ops_group1, ldvarg12);
    ldv_state_variable_17 = 1;
  } else {

  }
  goto ldv_55854;
  case 1: ;
  if (ldv_state_variable_17 == 1) {
    efx_mcdi_port_reconfigure(efx_mcdi_phy_ops_group1);
    ldv_state_variable_17 = 1;
  } else {

  }
  goto ldv_55854;
  case 2: ;
  if (ldv_state_variable_17 == 1) {
    efx_mcdi_phy_set_settings(efx_mcdi_phy_ops_group1, efx_mcdi_phy_ops_group0);
    ldv_state_variable_17 = 1;
  } else {

  }
  goto ldv_55854;
  case 3: ;
  if (ldv_state_variable_17 == 1) {
    efx_mcdi_phy_test_alive(efx_mcdi_phy_ops_group1);
    ldv_state_variable_17 = 1;
  } else {

  }
  goto ldv_55854;
  case 4: ;
  if (ldv_state_variable_17 == 1) {
    efx_mcdi_phy_test_name(efx_mcdi_phy_ops_group1, ldvarg11);
    ldv_state_variable_17 = 1;
  } else {

  }
  goto ldv_55854;
  case 5: ;
  if (ldv_state_variable_17 == 1) {
    efx_mcdi_phy_remove(efx_mcdi_phy_ops_group1);
    ldv_state_variable_17 = 1;
  } else {

  }
  goto ldv_55854;
  case 6: ;
  if (ldv_state_variable_17 == 1) {
    efx_mcdi_phy_run_tests(efx_mcdi_phy_ops_group1, ldvarg10, ldvarg9);
    ldv_state_variable_17 = 1;
  } else {

  }
  goto ldv_55854;
  case 7: ;
  if (ldv_state_variable_17 == 1) {
    efx_mcdi_phy_get_settings(efx_mcdi_phy_ops_group1, efx_mcdi_phy_ops_group0);
    ldv_state_variable_17 = 1;
  } else {

  }
  goto ldv_55854;
  case 8: ;
  if (ldv_state_variable_17 == 1) {
    efx_mcdi_phy_get_module_eeprom(efx_mcdi_phy_ops_group1, ldvarg8, ldvarg7);
    ldv_state_variable_17 = 1;
  } else {

  }
  goto ldv_55854;
  case 9: ;
  if (ldv_state_variable_17 == 1) {
    efx_mcdi_phy_probe(efx_mcdi_phy_ops_group1);
    ldv_state_variable_17 = 1;
  } else {

  }
  goto ldv_55854;
  case 10: ;
  if (ldv_state_variable_17 == 1) {
    efx_port_dummy_op_void(efx_mcdi_phy_ops_group1);
    ldv_state_variable_17 = 1;
  } else {

  }
  goto ldv_55854;
  case 11: ;
  if (ldv_state_variable_17 == 1) {
    efx_mcdi_phy_poll(efx_mcdi_phy_ops_group1);
    ldv_state_variable_17 = 1;
  } else {

  }
  goto ldv_55854;
  case 12: ;
  if (ldv_state_variable_17 == 1) {
    efx_port_dummy_op_int(efx_mcdi_phy_ops_group1);
    ldv_state_variable_17 = 1;
  } else {

  }
  goto ldv_55854;
  default: 
  ldv_stop();
  }
  ldv_55854: ;
  return;
}
}
bool ldv_queue_work_on_627(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_628(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_629(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_630(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_631(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_632(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_633(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_634(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_635(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_636(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_637(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_638(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
bool ldv_is_err(void const   *ptr ) ;
long ldv_ptr_err(void const   *ptr ) ;
__inline static long PTR_ERR(void const   *ptr ) ;
__inline static bool IS_ERR(void const   *ptr ) ;
int ldv_mutex_trylock_665(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_663(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_666(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_667(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_670(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_662(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_664(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_668(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_669(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_update_lock_of_efx_mcdi_mon(struct mutex *lock ) ;
void ldv_mutex_unlock_update_lock_of_efx_mcdi_mon(struct mutex *lock ) ;
bool ldv_queue_work_on_657(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_659(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_658(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_661(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_660(struct workqueue_struct *ldv_func_arg1 ) ;
extern struct device *hwmon_device_register_with_groups(struct device * , char const   * ,
                                                        void * , struct attribute_group  const  ** ) ;
extern void hwmon_device_unregister(struct device * ) ;
__inline static struct efx_mcdi_mon *efx_mcdi_mon(struct efx_nic *efx ) 
{ 


  {
  return (& (efx->mcdi)->hwmon);
}
}
static char const   * const  efx_hwmon_unit[6U]  = {      0,      " degC",      " rpm",      " mV", 
        " mA",      " W"};
static struct __anonstruct_efx_mcdi_sensor_type_373  const  efx_mcdi_sensor_type[46U]  = 
  {      {"Controller board temp.", 1, -1}, 
        {"PHY temp.", 1, -1}, 
        {"Controller heat sink", 2, -1}, 
        {"PHY temp.", 1, 0}, 
        {"PHY heat sink", 2, 0}, 
        {"PHY temp.", 1, 1}, 
        {"PHY heat sink", 2, 1}, 
        {"1.0V supply", 3, -1}, 
        {"1.2V supply", 3, -1}, 
        {"1.8V supply", 3, -1}, 
        {"2.5V supply", 3, -1}, 
        {"3.3V supply", 3, -1}, 
        {"12.0V supply", 3, -1}, 
        {"1.2V analogue supply", 3, -1}, 
        {"Ref. voltage", 3, -1}, 
        {"AOE FPGA supply", 3, -1}, 
        {"AOE FPGA temp.", 1, -1}, 
        {"AOE regulator temp.", 1, -1}, 
        {"Controller regulator temp.", 1, -1}, 
        {"Fan 0", 2, -1}, 
        {"Fan 1", 2, -1}, 
        {"Fan 2", 2, -1}, 
        {"Fan 3", 2, -1}, 
        {"Fan 4", 2, -1}, 
        {"AOE input supply", 3, -1}, 
        {"AOE output current", 4, -1}, 
        {"AOE input current", 4, -1}, 
        {"Board power use", 5, -1}, 
        {"0.9V supply", 3, -1}, 
        {"0.9V supply current", 4, -1}, 
        {"1.2V supply current", 4, -1}, 
        {0, 0, 0}, 
        {"0.9V supply (ext. ADC)", 3, -1}, 
        {"Controller board temp. 2", 1, -1}, 
        {"Regulator die temp.", 1, -1}, 
        {"0.9V regulator temp.", 1, -1}, 
        {"1.2V regulator temp.", 1, -1}, 
        {"Controller PTAT voltage (int. ADC)", 3, -1}, 
        {"Controller die temp. (int. ADC)", 1, -1}, 
        {"Controller PTAT voltage (ext. ADC)", 3, -1}, 
        {"Controller die temp. (ext. ADC)", 1, -1}, 
        {"Ambient temp.", 1, -1}, 
        {"Air flow raw", 3, -1}, 
        {"0.9V die (int. ADC)", 3, -1}, 
        {"0.9V die (ext. ADC)", 3, -1}, 
        {"Controller board temp. (hotpoint)", 1, -1}};
static char const   * const  sensor_status_names[5U]  = {      "OK",      "Warning",      "Fatal",      "Device failure", 
        "No reading"};
void efx_mcdi_sensor_event(struct efx_nic *efx , efx_qword_t *ev ) 
{ 
  unsigned int type ;
  unsigned int state ;
  unsigned int value ;
  enum efx_hwmon_type hwmon_type ;
  char const   *name ;
  char const   *state_txt ;
  char const   *unit ;

  {
  hwmon_type = 0;
  name = (char const   *)0;
  type = (unsigned int )ev->u64[0] & 255U;
  state = (unsigned int )(ev->u64[0] >> 8) & 255U;
  value = (unsigned int )(ev->u64[0] >> 16) & 65535U;
  if (type <= 45U) {
    name = efx_mcdi_sensor_type[type].label;
    hwmon_type = efx_mcdi_sensor_type[type].hwmon_type;
  } else {

  }
  if ((unsigned long )name == (unsigned long )((char const   *)0)) {
    name = "No sensor name available";
  } else {

  }
  state_txt = sensor_status_names[state];
  unit = efx_hwmon_unit[(unsigned int )hwmon_type];
  if ((unsigned long )unit == (unsigned long )((char const   *)0)) {
    unit = "";
  } else {

  }
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "Sensor %d (%s) reports condition \'%s\' for value %d%s\n",
               type, name, state_txt, value, unit);
  } else {

  }
  return;
}
}
static int efx_mcdi_mon_update(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_mon *hwmon ;
  struct efx_mcdi_mon *tmp ;
  efx_dword_t inbuf[3U] ;
  unsigned int tmp___0 ;
  int rc ;

  {
  tmp = efx_mcdi_mon(efx);
  hwmon = tmp;
  inbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 3U) {
      break;
    } else {

    }
    inbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = (unsigned int )hwmon->dma_buf.dma_addr;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )(hwmon->dma_buf.dma_addr >> 32);
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = hwmon->dma_buf.len;
  rc = efx_mcdi_rpc(efx, 66U, (efx_dword_t const   *)(& inbuf), 12UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  if (rc == 0) {
    hwmon->last_update = jiffies;
  } else {

  }
  return (rc);
}
}
static int efx_mcdi_mon_get_entry(struct device *dev , unsigned int index , efx_dword_t *entry ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  struct efx_mcdi_mon *hwmon ;
  struct efx_mcdi_mon *tmp___0 ;
  int rc ;

  {
  tmp = dev_get_drvdata((struct device  const  *)dev->parent);
  efx = (struct efx_nic *)tmp;
  tmp___0 = efx_mcdi_mon(efx);
  hwmon = tmp___0;
  ldv_mutex_lock_669(& hwmon->update_lock);
  if ((long )(((unsigned long )jiffies - hwmon->last_update) - 250UL) < 0L) {
    rc = 0;
  } else {
    rc = efx_mcdi_mon_update(efx);
  }
  *entry = *((efx_dword_t *)hwmon->dma_buf.addr + (unsigned long )index);
  ldv_mutex_unlock_670(& hwmon->update_lock);
  return (rc);
}
}
static ssize_t efx_mcdi_mon_show_value(struct device *dev , struct device_attribute *attr ,
                                       char *buf ) 
{ 
  struct efx_mcdi_mon_attribute *mon_attr ;
  struct device_attribute  const  *__mptr ;
  efx_dword_t entry ;
  unsigned int value ;
  unsigned int state ;
  int rc ;
  int tmp ;

  {
  __mptr = (struct device_attribute  const  *)attr;
  mon_attr = (struct efx_mcdi_mon_attribute *)__mptr;
  rc = efx_mcdi_mon_get_entry(dev, mon_attr->index, & entry);
  if (rc != 0) {
    return ((ssize_t )rc);
  } else {

  }
  state = (entry.u32[0] >> 16) & 255U;
  if (state == 4U) {
    return (-16L);
  } else {

  }
  value = entry.u32[0] & 65535U;
  switch ((unsigned int )mon_attr->hwmon_type) {
  case 1U: 
  value = value * 1000U;
  goto ldv_55420;
  case 5U: 
  value = value * 1000000U;
  goto ldv_55420;
  default: ;
  goto ldv_55420;
  }
  ldv_55420: 
  tmp = sprintf(buf, "%u\n", value);
  return ((ssize_t )tmp);
}
}
static ssize_t efx_mcdi_mon_show_limit(struct device *dev , struct device_attribute *attr ,
                                       char *buf ) 
{ 
  struct efx_mcdi_mon_attribute *mon_attr ;
  struct device_attribute  const  *__mptr ;
  unsigned int value ;
  int tmp ;

  {
  __mptr = (struct device_attribute  const  *)attr;
  mon_attr = (struct efx_mcdi_mon_attribute *)__mptr;
  value = mon_attr->limit_value;
  switch ((unsigned int )mon_attr->hwmon_type) {
  case 1U: 
  value = value * 1000U;
  goto ldv_55433;
  case 5U: 
  value = value * 1000000U;
  goto ldv_55433;
  default: ;
  goto ldv_55433;
  }
  ldv_55433: 
  tmp = sprintf(buf, "%u\n", value);
  return ((ssize_t )tmp);
}
}
static ssize_t efx_mcdi_mon_show_alarm(struct device *dev , struct device_attribute *attr ,
                                       char *buf ) 
{ 
  struct efx_mcdi_mon_attribute *mon_attr ;
  struct device_attribute  const  *__mptr ;
  efx_dword_t entry ;
  int state ;
  int rc ;
  int tmp ;

  {
  __mptr = (struct device_attribute  const  *)attr;
  mon_attr = (struct efx_mcdi_mon_attribute *)__mptr;
  rc = efx_mcdi_mon_get_entry(dev, mon_attr->index, & entry);
  if (rc != 0) {
    return ((ssize_t )rc);
  } else {

  }
  state = (int )(entry.u32[0] >> 16) & 255;
  tmp = sprintf(buf, "%d\n", state != 0);
  return ((ssize_t )tmp);
}
}
static ssize_t efx_mcdi_mon_show_label(struct device *dev , struct device_attribute *attr ,
                                       char *buf ) 
{ 
  struct efx_mcdi_mon_attribute *mon_attr ;
  struct device_attribute  const  *__mptr ;
  int tmp ;

  {
  __mptr = (struct device_attribute  const  *)attr;
  mon_attr = (struct efx_mcdi_mon_attribute *)__mptr;
  tmp = sprintf(buf, "%s\n", efx_mcdi_sensor_type[mon_attr->type].label);
  return ((ssize_t )tmp);
}
}
static void efx_mcdi_mon_add_attr(struct efx_nic *efx , char const   *name , ssize_t (*reader)(struct device * ,
                                                                                               struct device_attribute * ,
                                                                                               char * ) ,
                                  unsigned int index , unsigned int type , unsigned int limit_value ) 
{ 
  struct efx_mcdi_mon *hwmon ;
  struct efx_mcdi_mon *tmp ;
  struct efx_mcdi_mon_attribute *attr ;
  struct lock_class_key __key ;
  unsigned int tmp___0 ;

  {
  tmp = efx_mcdi_mon(efx);
  hwmon = tmp;
  attr = hwmon->attrs + (unsigned long )hwmon->n_attrs;
  strlcpy((char *)(& attr->name), name, 12UL);
  attr->index = index;
  attr->type = type;
  if (type <= 45U) {
    attr->hwmon_type = efx_mcdi_sensor_type[type].hwmon_type;
  } else {
    attr->hwmon_type = 0;
  }
  attr->limit_value = limit_value;
  attr->dev_attr.attr.key = & __key;
  attr->dev_attr.attr.name = (char const   *)(& attr->name);
  attr->dev_attr.attr.mode = 292U;
  attr->dev_attr.show = reader;
  tmp___0 = hwmon->n_attrs;
  hwmon->n_attrs = hwmon->n_attrs + 1U;
  *(hwmon->group.attrs + (unsigned long )tmp___0) = & attr->dev_attr.attr;
  return;
}
}
int efx_mcdi_mon_probe(struct efx_nic *efx ) 
{ 
  unsigned int n_temp ;
    klee_make_symbolic(&n_temp, sizeof(int), "n_temp");
  unsigned int n_cool ;
    klee_make_symbolic(&n_cool, sizeof(int), "n_cool");
  unsigned int n_in ;
    klee_make_symbolic(&n_in, sizeof(int), "n_in");
  unsigned int n_curr ;
    klee_make_symbolic(&n_curr, sizeof(int), "n_curr");
  unsigned int n_power ;
    klee_make_symbolic(&n_power, sizeof(int), "n_power");
  struct efx_mcdi_mon *hwmon ;
  struct efx_mcdi_mon *tmp ;
  efx_dword_t inbuf[1U] ;
  efx_dword_t outbuf[63U] ;
  unsigned int tmp___0 ;
  unsigned int n_pages ;
    klee_make_symbolic(&n_pages, sizeof(int), "n_pages");
  unsigned int n_sensors ;
    klee_make_symbolic(&n_sensors, sizeof(int), "n_sensors");
  unsigned int n_attrs ;
  unsigned int page ;
  size_t outlen ;
  char name[12U] ;
  u32 mask ;
  int rc ;
  int i ;
  int j ;
  int type ;
  unsigned int tmp___1 ;
  struct lock_class_key __key ;
  void *tmp___2 ;
  void *tmp___3 ;
  enum efx_hwmon_type hwmon_type ;
  char const   *hwmon_prefix ;
  unsigned int hwmon_index ;
    klee_make_symbolic(&hwmon_index, sizeof(int), "hwmon_index");
  u16 min1 ;
  u16 max1 ;
  u16 min2 ;
  u16 max2 ;
  unsigned int tmp___4 ;
  unsigned int tmp___5 ;
  unsigned int tmp___6 ;
  long tmp___7 ;
  bool tmp___8 ;

  {
  n_temp = 0U;
  n_cool = 0U;
  n_in = 0U;
  n_curr = 0U;
  n_power = 0U;
  tmp = efx_mcdi_mon(efx);
  hwmon = tmp;
  inbuf[0].u32[0] = 0U;
  outbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 63U) {
      break;
    } else {

    }
    outbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  n_sensors = 0U;
  page = 0U;
  ldv_55499: 
  ((efx_dword_t *)(& inbuf))->u32[0] = page;
  rc = efx_mcdi_rpc(efx, 65U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)(& outbuf),
                    252UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 3UL) {
    return (-5);
  } else {

  }
  mask = ((efx_dword_t *)(& outbuf))->u32[0];
  tmp___1 = __arch_hweight32(mask & 2147483647U);
  n_sensors = tmp___1 + n_sensors;
  page = page + 1U;
  if ((int )mask < 0) {
    goto ldv_55499;
  } else {

  }
  n_pages = page;
  if (n_sensors == 0U) {
    return (0);
  } else {

  }
  rc = efx_nic_alloc_buffer(efx, & hwmon->dma_buf, n_sensors * 4U, 208U);
  if (rc != 0) {
    return (rc);
  } else {

  }
  __mutex_init(& hwmon->update_lock, "&hwmon->update_lock", & __key);
  efx_mcdi_mon_update(efx);
  n_attrs = n_sensors * 6U;
  tmp___2 = kcalloc((size_t )n_attrs, 80UL, 208U);
  hwmon->attrs = (struct efx_mcdi_mon_attribute *)tmp___2;
  if ((unsigned long )hwmon->attrs == (unsigned long )((struct efx_mcdi_mon_attribute *)0)) {
    rc = -12;
    goto fail;
  } else {

  }
  tmp___3 = kcalloc((size_t )(n_attrs + 1U), 8UL, 208U);
  hwmon->group.attrs = (struct attribute **)tmp___3;
  if ((unsigned long )hwmon->group.attrs == (unsigned long )((struct attribute **)0)) {
    rc = -12;
    goto fail;
  } else {

  }
  i = 0;
  j = -1;
  type = -1;
  ldv_55562: ;
  ldv_55517: 
  type = type + 1;
  if (((unsigned int )type & 31U) == 0U) {
    page = (unsigned int )(type / 32);
    j = -1;
    if (page == n_pages) {
      goto hwmon_register;
    } else {

    }
    ((efx_dword_t *)(& inbuf))->u32[0] = page;
    rc = efx_mcdi_rpc(efx, 65U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)(& outbuf),
                      252UL, & outlen);
    if (rc != 0) {
      goto fail;
    } else {

    }
    if (outlen <= 3UL) {
      rc = -5;
      goto fail;
    } else {

    }
    mask = ((efx_dword_t *)(& outbuf))->u32[0] & 2147483647U;
    tmp___4 = __arch_hweight32(mask);
    if ((size_t )(tmp___4 * 8U + 4U) > outlen) {
      rc = -5;
      goto fail;
    } else {

    }
  } else {

  }
  if (((u32 )(1 << type % 32) & mask) == 0U) {
    goto ldv_55517;
  } else {

  }
  j = j + 1;
  if ((unsigned int )type <= 45U) {
    hwmon_type = efx_mcdi_sensor_type[type].hwmon_type;
    if ((unsigned int )hwmon_type != 0U && (int )efx_mcdi_sensor_type[type].port >= 0) {
      tmp___5 = efx_port_num(efx);
      if ((unsigned int )efx_mcdi_sensor_type[type].port != tmp___5) {
        goto ldv_55521;
      } else {

      }
    } else {

    }
  } else {
    hwmon_type = 0;
  }
  switch ((unsigned int )hwmon_type) {
  case 1U: 
  hwmon_prefix = "temp";
  n_temp = n_temp + 1U;
  hwmon_index = n_temp;
  goto ldv_55523;
  case 2U: 
  hwmon_prefix = "fan";
  n_cool = n_cool + 1U;
  hwmon_index = n_cool;
  goto ldv_55523;
  default: 
  hwmon_prefix = "in";
  tmp___6 = n_in;
  n_in = n_in + 1U;
  hwmon_index = tmp___6;
  goto ldv_55523;
  case 4U: 
  hwmon_prefix = "curr";
  n_curr = n_curr + 1U;
  hwmon_index = n_curr;
  goto ldv_55523;
  case 5U: 
  hwmon_prefix = "power";
  n_power = n_power + 1U;
  hwmon_index = n_power;
  goto ldv_55523;
  }
  ldv_55523: 
  min1 = (u16 )((efx_dword_t *)(& outbuf) + ((unsigned long )j * 8UL + 4UL))->u32[0];
  max1 = (u16 )(((efx_dword_t *)(& outbuf) + ((unsigned long )j * 8UL + 4UL))->u32[0] >> 16);
  min2 = (u16 )((efx_dword_t *)(& outbuf) + ((unsigned long )j + 1UL) * 8UL)->u32[0];
  max2 = (u16 )(((efx_dword_t *)(& outbuf) + ((unsigned long )j + 1UL) * 8UL)->u32[0] >> 16);
  if ((int )min1 != (int )max1) {
    snprintf((char *)(& name), 12UL, "%s%u_input", hwmon_prefix, hwmon_index);
    efx_mcdi_mon_add_attr(efx, (char const   *)(& name), & efx_mcdi_mon_show_value,
                          (unsigned int )i, (unsigned int )type, 0U);
    if ((unsigned int )hwmon_type != 5U) {
      snprintf((char *)(& name), 12UL, "%s%u_min", hwmon_prefix, hwmon_index);
      efx_mcdi_mon_add_attr(efx, (char const   *)(& name), & efx_mcdi_mon_show_limit,
                            (unsigned int )i, (unsigned int )type, (unsigned int )min1);
    } else {

    }
    snprintf((char *)(& name), 12UL, "%s%u_max", hwmon_prefix, hwmon_index);
    efx_mcdi_mon_add_attr(efx, (char const   *)(& name), & efx_mcdi_mon_show_limit,
                          (unsigned int )i, (unsigned int )type, (unsigned int )max1);
    if ((int )min2 != (int )max2) {
      snprintf((char *)(& name), 12UL, "%s%u_crit", hwmon_prefix, hwmon_index);
      efx_mcdi_mon_add_attr(efx, (char const   *)(& name), & efx_mcdi_mon_show_limit,
                            (unsigned int )i, (unsigned int )type, (unsigned int )max2);
    } else {

    }
  } else {

  }
  snprintf((char *)(& name), 12UL, "%s%u_alarm", hwmon_prefix, hwmon_index);
  efx_mcdi_mon_add_attr(efx, (char const   *)(& name), & efx_mcdi_mon_show_alarm,
                        (unsigned int )i, (unsigned int )type, 0U);
  if ((unsigned int )type <= 45U && (unsigned long )efx_mcdi_sensor_type[type].label != (unsigned long )((char const   */* const  */)0)) {
    snprintf((char *)(& name), 12UL, "%s%u_label", hwmon_prefix, hwmon_index);
    efx_mcdi_mon_add_attr(efx, (char const   *)(& name), & efx_mcdi_mon_show_label,
                          (unsigned int )i, (unsigned int )type, 0U);
  } else {

  }
  ldv_55521: 
  i = i + 1;
  goto ldv_55562;
  hwmon_register: 
  hwmon->groups[0] = (struct attribute_group  const  *)(& hwmon->group);
  hwmon->device = hwmon_device_register_with_groups(& (efx->pci_dev)->dev, "sfc",
                                                    (void *)0, (struct attribute_group  const  **)(& hwmon->groups));
  tmp___8 = IS_ERR((void const   *)hwmon->device);
  if ((int )tmp___8) {
    tmp___7 = PTR_ERR((void const   *)hwmon->device);
    rc = (int )tmp___7;
    goto fail;
  } else {

  }
  return (0);
  fail: 
  efx_mcdi_mon_remove(efx);
  return (rc);
}
}
void efx_mcdi_mon_remove(struct efx_nic *efx ) 
{ 
  struct efx_mcdi_mon *hwmon ;
  struct efx_mcdi_mon *tmp ;

  {
  tmp = efx_mcdi_mon(efx);
  hwmon = tmp;
  if ((unsigned long )hwmon->device != (unsigned long )((struct device *)0)) {
    hwmon_device_unregister(hwmon->device);
  } else {

  }
  kfree((void const   *)hwmon->attrs);
  kfree((void const   *)hwmon->group.attrs);
  efx_nic_free_buffer(efx, & hwmon->dma_buf);
  return;
}
}
__inline static long PTR_ERR(void const   *ptr ) 
{ 
  long tmp ;

  {
  tmp = ldv_ptr_err(ptr);
  return (tmp);
}
}
__inline static bool IS_ERR(void const   *ptr ) 
{ 
  bool tmp ;

  {
  tmp = ldv_is_err(ptr);
  return (tmp);
}
}
bool ldv_queue_work_on_657(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_658(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_659(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_660(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_661(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_662(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_663(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_664(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_665(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_666(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_667(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_668(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_669(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_update_lock_of_efx_mcdi_mon(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_670(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_update_lock_of_efx_mcdi_mon(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
extern void __might_fault(char const   * , int  ) ;
__inline static void list_add(struct list_head *new , struct list_head *head ) 
{ 


  {
  __list_add(new, head, head->next);
  return;
}
}
extern void __list_del_entry(struct list_head * ) ;
__inline static void list_move(struct list_head *list , struct list_head *head ) 
{ 


  {
  __list_del_entry(list);
  list_add(list, head);
  return;
}
}
__inline static u32 __iter_div_u64_rem(u64 dividend , u32 divisor , u64 *remainder ) 
{ 
  u32 ret ;

  {
  ret = 0U;
  goto ldv_5138;
  ldv_5137: 
  __asm__  ("": "+rm" (dividend));
  dividend = dividend - (u64 )divisor;
  ret = ret + 1U;
  ldv_5138: ;
  if ((u64 )divisor <= dividend) {
    goto ldv_5137;
  } else {

  }
  *remainder = dividend;
  return (ret);
}
}
__inline static long PTR_ERR(void const   *ptr ) ;
__inline static bool IS_ERR(void const   *ptr ) ;
int ldv_mutex_trylock_697(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_695(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_698(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_699(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_694(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_696(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_700(struct mutex *ldv_func_arg1 ) ;
__inline static int timespec_compare(struct timespec  const  *lhs , struct timespec  const  *rhs ) 
{ 


  {
  if ((long )lhs->tv_sec < (long )rhs->tv_sec) {
    return (-1);
  } else {

  }
  if ((long )lhs->tv_sec > (long )rhs->tv_sec) {
    return (1);
  } else {

  }
  return ((int )((unsigned int )lhs->tv_nsec - (unsigned int )rhs->tv_nsec));
}
}
extern void set_normalized_timespec(struct timespec * , time_t  , s64  ) ;
__inline static struct timespec timespec_sub(struct timespec lhs , struct timespec rhs ) 
{ 
  struct timespec ts_delta ;

  {
  set_normalized_timespec(& ts_delta, lhs.tv_sec - rhs.tv_sec, (s64 )(lhs.tv_nsec - rhs.tv_nsec));
  return (ts_delta);
}
}
__inline static s64 timespec_to_ns(struct timespec  const  *ts ) 
{ 


  {
  return ((long long )ts->tv_sec * 1000000000LL + (long long )ts->tv_nsec);
}
}
extern struct timespec ns_to_timespec(s64 const    ) ;
__inline static void timespec_add_ns(struct timespec *a , u64 ns ) 
{ 
  u32 tmp ;

  {
  tmp = __iter_div_u64_rem((unsigned long long )a->tv_nsec + ns, 1000000000U, & ns);
  a->tv_sec = a->tv_sec + (__kernel_time_t )tmp;
  a->tv_nsec = (long )ns;
  return;
}
}
__inline static ktime_t ktime_set(s64 const   secs , unsigned long const   nsecs ) 
{ 
  ktime_t __constr_expr_0 ;
  long tmp ;
  ktime_t __constr_expr_1 ;

  {
  tmp = ldv__builtin_expect((long long )secs > 9223372035LL, 0L);
  if (tmp != 0L) {
    __constr_expr_0.tv64 = 9223372036854775807LL;
    return (__constr_expr_0);
  } else {

  }
  __constr_expr_1.tv64 = (long long )secs * 1000000000LL + (long long )nsecs;
  return (__constr_expr_1);
}
}
extern void getnstimeofday64(struct timespec * ) ;
__inline static void getnstimeofday(struct timespec *ts ) 
{ 


  {
  getnstimeofday64(ts);
  return;
}
}
void ldv_destroy_workqueue_701(struct workqueue_struct *ldv_func_arg1 ) ;
void ldv_destroy_workqueue_704(struct workqueue_struct *ldv_func_arg1 ) ;
void ldv_destroy_workqueue_705(struct workqueue_struct *ldv_func_arg1 ) ;
bool ldv_queue_work_on_689(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_691(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_690(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_693(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_692(struct workqueue_struct *ldv_func_arg1 ) ;
bool ldv_cancel_work_sync_702(struct work_struct *ldv_func_arg1 ) ;
bool ldv_cancel_work_sync_703(struct work_struct *ldv_func_arg1 ) ;
__inline static bool queue_work___0(struct workqueue_struct *wq , struct work_struct *work ) 
{ 
  bool tmp ;

  {
  tmp = ldv_queue_work_on_689(8192, wq, work);
  return (tmp);
}
}
void activate_work_5(struct work_struct *work , int state ) ;
void activate_work_6(struct work_struct *work , int state ) ;
void invoke_work_5(void) ;
void invoke_work_6(void) ;
void disable_work_5(struct work_struct *work ) ;
void call_and_disable_all_6(int state ) ;
void call_and_disable_work_5(struct work_struct *work ) ;
void call_and_disable_all_5(int state ) ;
void disable_work_6(struct work_struct *work ) ;
void call_and_disable_work_6(struct work_struct *work ) ;
extern unsigned long _copy_from_user(void * , void const   * , unsigned int  ) ;
extern unsigned long _copy_to_user(void * , void const   * , unsigned int  ) ;
extern void __copy_from_user_overflow(void) ;
extern void __copy_to_user_overflow(void) ;
__inline static unsigned long copy_from_user(void *to , void const   *from , unsigned long n ) 
{ 
  int sz ;
    klee_make_symbolic(&sz, sizeof(int), "sz");
  unsigned long tmp ;
  long tmp___0 ;

  {
  tmp = __builtin_object_size((void const   *)to, 0);
  sz = (int )tmp;
  __might_fault("./arch/x86/include/asm/uaccess.h", 697);
  tmp___0 = ldv__builtin_expect((long )(sz < 0 || (unsigned long )sz >= n), 1L);
  if (tmp___0 != 0L) {
    n = _copy_from_user(to, from, (unsigned int )n);
  } else {
    __copy_from_user_overflow();
  }
  return (n);
}
}
__inline static unsigned long copy_to_user(void *to , void const   *from , unsigned long n ) 
{ 
  int sz ;
  unsigned long tmp ;
  long tmp___0 ;

  {
  tmp = __builtin_object_size(from, 0);
  sz = (int )tmp;
  __might_fault("./arch/x86/include/asm/uaccess.h", 732);
  tmp___0 = ldv__builtin_expect((long )(sz < 0 || (unsigned long )sz >= n), 1L);
  if (tmp___0 != 0L) {
    n = _copy_to_user(to, from, (unsigned int )n);
  } else {
    __copy_to_user_overflow();
  }
  return (n);
}
}
__inline static struct skb_shared_hwtstamps *skb_hwtstamps(struct sk_buff *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  return (& ((struct skb_shared_info *)tmp)->hwtstamps);
}
}
__inline static struct sk_buff *skb_peek(struct sk_buff_head  const  *list_ ) 
{ 
  struct sk_buff *skb ;

  {
  skb = list_->next;
  if ((unsigned long )skb == (unsigned long )((struct sk_buff *)list_)) {
    skb = (struct sk_buff *)0;
  } else {

  }
  return (skb);
}
}
__inline static void __skb_queue_head_init(struct sk_buff_head *list ) 
{ 
  struct sk_buff *tmp ;

  {
  tmp = (struct sk_buff *)list;
  list->next = tmp;
  list->prev = tmp;
  list->qlen = 0U;
  return;
}
}
__inline static void skb_queue_head_init(struct sk_buff_head *list ) 
{ 
  struct lock_class_key __key ;

  {
  spinlock_check(& list->lock);
  __raw_spin_lock_init(& list->lock.__annonCompField17.rlock, "&(&list->lock)->rlock",
                       & __key);
  __skb_queue_head_init(list);
  return;
}
}
__inline static void __skb_insert(struct sk_buff *newsk , struct sk_buff *prev , struct sk_buff *next ,
                                  struct sk_buff_head *list ) 
{ 
  struct sk_buff *tmp ;

  {
  newsk->__annonCompField80.__annonCompField79.next = next;
  newsk->__annonCompField80.__annonCompField79.prev = prev;
  tmp = newsk;
  prev->__annonCompField80.__annonCompField79.next = tmp;
  next->__annonCompField80.__annonCompField79.prev = tmp;
  list->qlen = list->qlen + 1U;
  return;
}
}
__inline static void __skb_queue_before(struct sk_buff_head *list , struct sk_buff *next ,
                                        struct sk_buff *newsk ) 
{ 


  {
  __skb_insert(newsk, next->__annonCompField80.__annonCompField79.prev, next, list);
  return;
}
}
extern void skb_queue_head(struct sk_buff_head * , struct sk_buff * ) ;
extern void skb_queue_tail(struct sk_buff_head * , struct sk_buff * ) ;
__inline static void __skb_queue_tail(struct sk_buff_head *list , struct sk_buff *newsk ) 
{ 


  {
  __skb_queue_before(list, (struct sk_buff *)list, newsk);
  return;
}
}
__inline static void __skb_unlink(struct sk_buff *skb , struct sk_buff_head *list ) 
{ 
  struct sk_buff *next ;
  struct sk_buff *prev ;
  struct sk_buff *tmp ;

  {
  list->qlen = list->qlen - 1U;
  next = skb->__annonCompField80.__annonCompField79.next;
  prev = skb->__annonCompField80.__annonCompField79.prev;
  tmp = (struct sk_buff *)0;
  skb->__annonCompField80.__annonCompField79.prev = tmp;
  skb->__annonCompField80.__annonCompField79.next = tmp;
  next->__annonCompField80.__annonCompField79.prev = prev;
  prev->__annonCompField80.__annonCompField79.next = next;
  return;
}
}
extern struct sk_buff *skb_dequeue(struct sk_buff_head * ) ;
__inline static struct sk_buff *__skb_dequeue(struct sk_buff_head *list ) 
{ 
  struct sk_buff *skb ;
  struct sk_buff *tmp ;

  {
  tmp = skb_peek((struct sk_buff_head  const  *)list);
  skb = tmp;
  if ((unsigned long )skb != (unsigned long )((struct sk_buff *)0)) {
    __skb_unlink(skb, list);
  } else {

  }
  return (skb);
}
}
extern unsigned char *__pskb_pull_tail(struct sk_buff * , int  ) ;
__inline static int pskb_may_pull(struct sk_buff *skb , unsigned int len ) 
{ 
  unsigned int tmp ;
  long tmp___0 ;
  long tmp___1 ;
  unsigned int tmp___2 ;
  unsigned char *tmp___3 ;

  {
  tmp = skb_headlen((struct sk_buff  const  *)skb);
  tmp___0 = ldv__builtin_expect(tmp >= len, 1L);
  if (tmp___0 != 0L) {
    return (1);
  } else {

  }
  tmp___1 = ldv__builtin_expect(skb->len < len, 0L);
  if (tmp___1 != 0L) {
    return (0);
  } else {

  }
  tmp___2 = skb_headlen((struct sk_buff  const  *)skb);
  tmp___3 = __pskb_pull_tail(skb, (int )(len - tmp___2));
  return ((unsigned long )tmp___3 != (unsigned long )((unsigned char *)0U));
}
}
__inline static bool skb_transport_header_was_set(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned int )((unsigned short )skb->transport_header) != 65535U);
}
}
__inline static unsigned char *skb_mac_header(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->mac_header);
}
}
__inline static int skb_transport_offset(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_transport_header(skb);
  return ((int )((unsigned int )((long )tmp) - (unsigned int )((long )skb->data)));
}
}
__inline static u32 skb_network_header_len(struct sk_buff  const  *skb ) 
{ 


  {
  return ((u32 )((int )skb->transport_header - (int )skb->network_header));
}
}
extern void skb_queue_purge(struct sk_buff_head * ) ;
__inline static int __skb_linearize(struct sk_buff *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = __pskb_pull_tail(skb, (int )skb->data_len);
  return ((unsigned long )tmp != (unsigned long )((unsigned char *)0U) ? 0 : -12);
}
}
__inline static int skb_linearize(struct sk_buff *skb ) 
{ 
  int tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;

  {
  tmp___2 = skb_is_nonlinear((struct sk_buff  const  *)skb);
  if ((int )tmp___2) {
    tmp___0 = __skb_linearize(skb);
    tmp___1 = tmp___0;
  } else {
    tmp___1 = 0;
  }
  return (tmp___1);
}
}
__inline static void skb_copy_from_linear_data(struct sk_buff  const  *skb , void *to ,
                                               unsigned int const   len ) 
{ 


  {
  memcpy(to, (void const   *)skb->data, (size_t )len);
  return;
}
}
extern void skb_tstamp_tx(struct sk_buff * , struct skb_shared_hwtstamps * ) ;
extern int skb_checksum_help(struct sk_buff * ) ;
__inline static struct udphdr *udp_hdr(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_transport_header(skb);
  return ((struct udphdr *)tmp);
}
}
__inline static void pps_get_ts(struct pps_event_time *ts ) 
{ 


  {
  getnstimeofday(& ts->ts_real);
  return;
}
}
__inline static void pps_sub_ts(struct pps_event_time *ts , struct timespec delta ) 
{ 


  {
  ts->ts_real = timespec_sub(ts->ts_real, delta);
  return;
}
}
extern struct ptp_clock *ptp_clock_register(struct ptp_clock_info * , struct device * ) ;
extern int ptp_clock_unregister(struct ptp_clock * ) ;
extern void ptp_clock_event(struct ptp_clock * , struct ptp_clock_event * ) ;
extern int ptp_clock_index(struct ptp_clock * ) ;
__inline static int efx_filter_set_ipv4_local(struct efx_filter_spec *spec , u8 proto ,
                                              __be32 host , __be16 port ) 
{ 


  {
  spec->match_flags = (unsigned short )((unsigned int )spec->match_flags | 610U);
  spec->ether_type = 8U;
  spec->ip_proto = proto;
  spec->loc_host[0] = host;
  spec->loc_port = port;
  return (0);
}
}
__inline static void efx_xmit_hwtstamp_pending(struct sk_buff *skb ) 
{ 
  unsigned char *tmp ;
  unsigned char *tmp___0 ;

  {
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  tmp___0 = skb_end_pointer((struct sk_buff  const  *)skb);
  ((struct skb_shared_info *)tmp)->tx_flags = (__u8 )((unsigned int )((struct skb_shared_info *)tmp___0)->tx_flags | 4U);
  return;
}
}
static int efx_phc_adjfreq(struct ptp_clock_info *ptp , s32 delta ) ;
static int efx_phc_adjtime(struct ptp_clock_info *ptp , s64 delta ) ;
static int efx_phc_gettime(struct ptp_clock_info *ptp , struct timespec *ts ) ;
static int efx_phc_settime(struct ptp_clock_info *ptp , struct timespec  const  *e_ts ) ;
static int efx_phc_enable(struct ptp_clock_info *ptp , struct ptp_clock_request *request ,
                          int enable ) ;
static struct efx_hw_stat_desc  const  efx_ptp_stat_desc[14U]  = 
  {      {"ptp_good_syncs", 0U, 1344U}, 
        {"ptp_fast_syncs", 0U, 1348U}, 
        {"ptp_bad_syncs", 0U, 1352U}, 
        {"ptp_sync_timeouts", 0U, 1356U}, 
        {"ptp_no_time_syncs", 0U, 1360U}, 
        {"ptp_invalid_sync_windows", 0U, 1364U}, 
        {"ptp_undersize_sync_windows", 0U, 1368U}, 
        {"ptp_oversize_sync_windows", 0U, 1372U}, 
        {"ptp_rx_no_timestamp", 0U, 1376U}, 
        {"ptp_tx_timestamp_packets", 32U, 4U}, 
        {"ptp_rx_timestamp_packets", 32U, 8U}, 
        {"ptp_timestamp_packets", 32U, 12U}, 
        {"ptp_filter_matches", 32U, 16U}, 
        {"ptp_non_filter_matches", 32U, 20U}};
static unsigned long const   efx_ptp_stat_mask[1U]  = {      0xffffffffffffffffUL};
size_t efx_ptp_describe_stats(struct efx_nic *efx , u8 *strings ) 
{ 
  size_t tmp ;

  {
  if ((unsigned long )efx->ptp_data == (unsigned long )((struct efx_ptp_data *)0)) {
    return (0UL);
  } else {

  }
  tmp = efx_nic_describe_stats((struct efx_hw_stat_desc  const  *)(& efx_ptp_stat_desc),
                               14UL, (unsigned long const   *)(& efx_ptp_stat_mask),
                               strings);
  return (tmp);
}
}
size_t efx_ptp_update_stats(struct efx_nic *efx , u64 *stats ) 
{ 
  efx_dword_t inbuf[2U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[16U] ;
  unsigned int tmp___0 ;
  size_t i ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 16U) {
      break;
    } else {

    }
    outbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  if ((unsigned long )efx->ptp_data == (unsigned long )((struct efx_ptp_data *)0)) {
    return (0UL);
  } else {

  }
  i = 0UL;
  goto ldv_56671;
  ldv_56670: ;
  if ((unsigned int )((unsigned short )efx_ptp_stat_desc[i].dma_width) != 0U) {
    goto ldv_56669;
  } else {

  }
  *(stats + i) = (u64 )*((unsigned int *)efx->ptp_data + (unsigned long )efx_ptp_stat_desc[i].offset);
  ldv_56669: 
  i = i + 1UL;
  ldv_56671: ;
  if (i <= 13UL) {
    goto ldv_56670;
  } else {

  }
  ((efx_dword_t *)(& inbuf))->u32[0] = 5U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = 0U;
  rc = efx_mcdi_rpc(efx, 11U, (efx_dword_t const   *)(& inbuf), 8UL, (efx_dword_t *)(& outbuf),
                    64UL, (size_t *)0UL);
  if (rc != 0) {
    memset((void *)(& outbuf), 0, 64UL);
  } else {

  }
  efx_nic_update_stats((struct efx_hw_stat_desc  const  *)(& efx_ptp_stat_desc), 14UL,
                       (unsigned long const   *)(& efx_ptp_stat_mask), stats, (void const   *)(& outbuf),
                       0);
  return (14UL);
}
}
static void efx_ptp_ns_to_s_ns(s64 ns , u32 *nic_major , u32 *nic_minor ) 
{ 
  struct timespec ts ;
  struct timespec tmp ;

  {
  tmp = ns_to_timespec(ns);
  ts = tmp;
  *nic_major = (u32 )ts.tv_sec;
  *nic_minor = (u32 )ts.tv_nsec;
  return;
}
}
static ktime_t efx_ptp_s_ns_to_ktime_correction(u32 nic_major , u32 nic_minor , s32 correction ) 
{ 
  ktime_t kt ;
  ktime_t tmp ;
  ktime_t __constr_expr_0 ;
  ktime_t __constr_expr_1 ;

  {
  tmp = ktime_set((s64 const   )nic_major, (unsigned long const   )nic_minor);
  kt = tmp;
  if (correction >= 0) {
    __constr_expr_0.tv64 = (long long )((unsigned long long )kt.tv64 + (unsigned long long )correction);
    kt = __constr_expr_0;
  } else {
    __constr_expr_1.tv64 = (long long )((unsigned long long )kt.tv64 - (unsigned long long )(- correction));
    kt = __constr_expr_1;
  }
  return (kt);
}
}
static void efx_ptp_ns_to_s27(s64 ns , u32 *nic_major , u32 *nic_minor ) 
{ 
  struct timespec ts ;
  struct timespec tmp ;
  u32 maj ;
  u32 min ;

  {
  tmp = ns_to_timespec(ns);
  ts = tmp;
  maj = (u32 )ts.tv_sec;
  min = (unsigned int )(((unsigned long long )ts.tv_nsec * 9223372037ULL + 34359738368ULL) >> 36);
  if (min > 134217727U) {
    min = min - 134217728U;
    maj = maj + 1U;
  } else {

  }
  *nic_major = maj;
  *nic_minor = min;
  return;
}
}
__inline static ktime_t efx_ptp_s27_to_ktime(u32 nic_major , u32 nic_minor ) 
{ 
  u32 ns ;
  ktime_t tmp ;

  {
  ns = (unsigned int )(((unsigned long long )nic_minor * 1000000000ULL + 67108864ULL) >> 27);
  tmp = ktime_set((s64 const   )nic_major, (unsigned long const   )ns);
  return (tmp);
}
}
static ktime_t efx_ptp_s27_to_ktime_correction(u32 nic_major , u32 nic_minor , s32 correction ) 
{ 
  ktime_t tmp ;

  {
  nic_minor = nic_minor + (u32 )correction;
  if ((int )nic_minor < 0) {
    nic_minor = nic_minor + 134217728U;
    nic_major = nic_major - 1U;
  } else
  if (nic_minor > 134217727U) {
    nic_minor = nic_minor - 134217728U;
    nic_major = nic_major + 1U;
  } else {

  }
  tmp = efx_ptp_s27_to_ktime(nic_major, nic_minor);
  return (tmp);
}
}
static int efx_ptp_get_attributes(struct efx_nic *efx ) 
{ 
  efx_dword_t inbuf[2U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[2U] ;
  unsigned int tmp___0 ;
  struct efx_ptp_data *ptp ;
  int rc ;
  u32 fmt ;
  size_t out_len ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 2U) {
      break;
    } else {

    }
    outbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  ptp = efx->ptp_data;
  ((efx_dword_t *)(& inbuf))->u32[0] = 22U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = 0U;
  rc = efx_mcdi_rpc_quiet(efx, 11U, (efx_dword_t const   *)(& inbuf), 8UL, (efx_dword_t *)(& outbuf),
                          8UL, & out_len);
  if (rc == 0) {
    fmt = ((efx_dword_t *)(& outbuf))->u32[0];
  } else
  if (rc == -22) {
    fmt = 0U;
  } else
  if (rc == -1) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_info((struct net_device  const  *)efx->net_dev, "no PTP support\n");
    } else {

    }
    return (rc);
  } else {
    efx_mcdi_display_error(efx, 11U, 8UL, (efx_dword_t *)(& outbuf), 8UL, rc);
    return (rc);
  }
  if (fmt == 2U) {
    ptp->ns_to_nic_time = & efx_ptp_ns_to_s27;
    ptp->nic_to_kernel_time = & efx_ptp_s27_to_ktime_correction;
  } else
  if (fmt == 0U) {
    ptp->ns_to_nic_time = & efx_ptp_ns_to_s_ns;
    ptp->nic_to_kernel_time = & efx_ptp_s_ns_to_ktime_correction;
  } else {
    return (-34);
  }
  ptp->time_format = fmt;
  if (rc == 0 && out_len > 7UL) {
    ptp->min_synchronisation_ns = ((efx_dword_t *)(& outbuf) + 1UL)->u32[0];
  } else {
    ptp->min_synchronisation_ns = 120U;
  }
  return (0);
}
}
static int efx_ptp_get_timestamp_corrections(struct efx_nic *efx ) 
{ 
  efx_dword_t inbuf[2U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[4U] ;
  unsigned int tmp___0 ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 4U) {
      break;
    } else {

    }
    outbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = 23U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = 0U;
  rc = efx_mcdi_rpc_quiet(efx, 11U, (efx_dword_t const   *)(& inbuf), 8UL, (efx_dword_t *)(& outbuf),
                          16UL, (size_t *)0UL);
  if (rc == 0) {
    (efx->ptp_data)->ts_corrections.tx = (s32 )((efx_dword_t *)(& outbuf))->u32[0];
    (efx->ptp_data)->ts_corrections.rx = (s32 )((efx_dword_t *)(& outbuf) + 1UL)->u32[0];
    (efx->ptp_data)->ts_corrections.pps_out = (s32 )((efx_dword_t *)(& outbuf) + 2UL)->u32[0];
    (efx->ptp_data)->ts_corrections.pps_in = (s32 )((efx_dword_t *)(& outbuf) + 3UL)->u32[0];
  } else
  if (rc == -22) {
    (efx->ptp_data)->ts_corrections.tx = 0;
    (efx->ptp_data)->ts_corrections.rx = 0;
    (efx->ptp_data)->ts_corrections.pps_out = 0;
    (efx->ptp_data)->ts_corrections.pps_in = 0;
  } else {
    efx_mcdi_display_error(efx, 11U, 8UL, (efx_dword_t *)(& outbuf), 16UL, rc);
    return (rc);
  }
  return (0);
}
}
static int efx_ptp_enable(struct efx_nic *efx ) 
{ 
  efx_dword_t inbuf[4U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[2U] ;
  unsigned int tmp___0 ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 4U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 2U) {
      break;
    } else {

    }
    outbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = 1U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = 0U;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = (unsigned long )(efx->ptp_data)->channel != (unsigned long )((struct efx_channel *)0) ? (unsigned int )((efx->ptp_data)->channel)->channel : 0U;
  ((efx_dword_t *)(& inbuf) + 3UL)->u32[0] = (efx->ptp_data)->mode;
  rc = efx_mcdi_rpc_quiet(efx, 11U, (efx_dword_t const   *)(& inbuf), 16UL, (efx_dword_t *)(& outbuf),
                          8UL, (size_t *)0UL);
  rc = rc != -114 ? rc : 0;
  if (rc != 0) {
    efx_mcdi_display_error(efx, 11U, 16UL, (efx_dword_t *)(& outbuf), 8UL, rc);
  } else {

  }
  return (rc);
}
}
static int efx_ptp_disable(struct efx_nic *efx ) 
{ 
  efx_dword_t inbuf[2U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[2U] ;
  unsigned int tmp___0 ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 2U) {
      break;
    } else {

    }
    outbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = 2U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = 0U;
  rc = efx_mcdi_rpc_quiet(efx, 11U, (efx_dword_t const   *)(& inbuf), 8UL, (efx_dword_t *)(& outbuf),
                          8UL, (size_t *)0UL);
  rc = rc != -114 ? rc : 0;
  if (rc == -38 || rc == -1) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_info((struct net_device  const  *)efx->net_dev, "no PTP support\n");
    } else {

    }
  } else
  if (rc != 0) {
    efx_mcdi_display_error(efx, 11U, 8UL, (efx_dword_t *)(& outbuf), 8UL, rc);
  } else {

  }
  return (rc);
}
}
static void efx_ptp_deliver_rx_queue(struct sk_buff_head *q ) 
{ 
  struct sk_buff *skb ;

  {
  goto ldv_56789;
  ldv_56788: 
  local_bh_disable();
  netif_receive_skb(skb);
  local_bh_enable();
  ldv_56789: 
  skb = skb_dequeue(q);
  if ((unsigned long )skb != (unsigned long )((struct sk_buff *)0)) {
    goto ldv_56788;
  } else {

  }

  return;
}
}
static void efx_ptp_handle_no_channel(struct efx_nic *efx ) 
{ 


  {
  if ((int )efx->msg_enable & 1) {
    netdev_err((struct net_device  const  *)efx->net_dev, "OLD_ERROR: PTP requires MSI-X and 1 additional interruptvector. PTP disabled\n");
  } else {

  }
  return;
}
}
static void efx_ptp_send_times(struct efx_nic *efx , struct pps_event_time *last_time ) 
{ 
  struct pps_event_time now ;
  struct timespec limit ;
  struct efx_ptp_data *ptp ;
  struct timespec start ;
  int *mc_running ;
  struct timespec update_time ;
  unsigned int host_time ;
    klee_make_symbolic(&host_time, sizeof(int), "host_time");
  int tmp ;
  int __var ;
  int tmp___0 ;
  int __var___0 ;

  {
  ptp = efx->ptp_data;
  mc_running = (int *)ptp->start.addr;
  pps_get_ts(& now);
  start = now.ts_real;
  limit = now.ts_real;
  timespec_add_ns(& limit, 250000ULL);
  goto ldv_56812;
  ldv_56811: 
  update_time = now.ts_real;
  timespec_add_ns(& update_time, 200ULL);
  ldv_56809: 
  pps_get_ts(& now);
  tmp = timespec_compare((struct timespec  const  *)(& now.ts_real), (struct timespec  const  *)(& update_time));
  if (tmp < 0) {
    __var = 0;
    if ((int )*((int volatile   *)mc_running) != 0) {
      goto ldv_56809;
    } else {
      goto ldv_56810;
    }
  } else {

  }
  ldv_56810: 
  host_time = (unsigned int )((int )(now.ts_real.tv_sec << 30) | (int )now.ts_real.tv_nsec);
  (*((efx->type)->ptp_write_host_time))(efx, host_time);
  ldv_56812: 
  tmp___0 = timespec_compare((struct timespec  const  *)(& now.ts_real), (struct timespec  const  *)(& limit));
  if (tmp___0 < 0) {
    __var___0 = 0;
    if ((int )*((int volatile   *)mc_running) != 0) {
      goto ldv_56811;
    } else {
      goto ldv_56813;
    }
  } else {

  }
  ldv_56813: 
  *last_time = now;
  return;
}
}
static void efx_ptp_read_timeset(efx_dword_t *data , struct efx_ptp_timeset *timeset ) 
{ 
  unsigned int start_ns ;
    klee_make_symbolic(&start_ns, sizeof(int), "start_ns");
  unsigned int end_ns ;
    klee_make_symbolic(&end_ns, sizeof(int), "end_ns");

  {
  timeset->host_start = data->u32[0];
  timeset->major = (data + 1UL)->u32[0];
  timeset->minor = (data + 2UL)->u32[0];
  timeset->host_end = (data + 3UL)->u32[0];
  timeset->wait = (data + 4UL)->u32[0];
  start_ns = timeset->host_start & 1073741823U;
  end_ns = timeset->host_end & 1073741823U;
  if (end_ns < start_ns) {
    end_ns = end_ns + 1000000000U;
  } else {

  }
  timeset->window = end_ns - start_ns;
  return;
}
}
static int efx_ptp_process_times(struct efx_nic *efx , efx_dword_t *synch_buf , size_t response_length ,
                                 struct pps_event_time  const  *last_time ) 
{ 
  unsigned int number_readings ;
    klee_make_symbolic(&number_readings, sizeof(int), "number_readings");
  size_t __min1 ;
  size_t __min2 ;
  unsigned int i ;
  unsigned int ngood ;
    klee_make_symbolic(&ngood, sizeof(int), "ngood");
  unsigned int last_good ;
    klee_make_symbolic(&last_good, sizeof(int), "last_good");
  struct efx_ptp_data *ptp ;
  u32 last_sec ;
  u32 start_sec ;
  struct timespec delta ;
  ktime_t mc_time ;
  s32 window ;
  s32 corrected ;
  struct timespec wait ;
  ktime_t tmp ;
  struct timespec tmp___0 ;

  {
  __min1 = 12UL;
  __min2 = response_length / 20UL;
  number_readings = (unsigned int )(__min1 < __min2 ? __min1 : __min2);
  ngood = 0U;
  last_good = 0U;
  ptp = efx->ptp_data;
  if (number_readings == 0U) {
    return (-11);
  } else {

  }
  i = 0U;
  goto ldv_56866;
  ldv_56865: 
  efx_ptp_read_timeset(synch_buf + (unsigned long )i * 20UL, (struct efx_ptp_timeset *)(& ptp->timeset) + (unsigned long )i);
  tmp = (*(ptp->nic_to_kernel_time))(0U, ptp->timeset[i].wait, 0);
  wait = ns_to_timespec(tmp.tv64);
  window = (s32 )ptp->timeset[i].window;
  corrected = (s32 )((unsigned int )window - (unsigned int )wait.tv_nsec);
  if (window <= 199) {
    ptp->invalid_sync_windows = ptp->invalid_sync_windows + 1U;
  } else
  if (corrected > 999) {
    ptp->oversize_sync_windows = ptp->oversize_sync_windows + 1U;
  } else
  if ((unsigned int )corrected < ptp->min_synchronisation_ns) {
    ptp->undersize_sync_windows = ptp->undersize_sync_windows + 1U;
  } else {
    ngood = ngood + 1U;
    last_good = i;
  }
  i = i + 1U;
  ldv_56866: ;
  if (i < number_readings) {
    goto ldv_56865;
  } else {

  }

  if (ngood == 0U) {
    if ((int )efx->msg_enable & 1) {
      netdev_warn((struct net_device  const  *)efx->net_dev, "PTP no suitable synchronisations\n");
    } else {

    }
    return (-11);
  } else {

  }
  start_sec = ptp->timeset[last_good].host_start >> 30;
  last_sec = (u32 )last_time->ts_real.tv_sec & 3U;
  if (start_sec != last_sec && ((start_sec + 1U) & 3U) != last_sec) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_warn((struct net_device  const  *)efx->net_dev, "PTP bad synchronisation seconds\n");
    } else {

    }
    return (-11);
  } else {

  }
  delta.tv_sec = (__kernel_time_t )(last_sec - start_sec) & 1L;
  delta.tv_nsec = (long )last_time->ts_real.tv_nsec - ((long )ptp->timeset[last_good].host_start & 1073741823L);
  mc_time = (*(ptp->nic_to_kernel_time))(ptp->timeset[last_good].major, ptp->timeset[last_good].minor,
                                         0);
  tmp___0 = ns_to_timespec(mc_time.tv64);
  delta.tv_nsec = delta.tv_nsec + tmp___0.tv_nsec;
  ptp->host_time_pps = *last_time;
  pps_sub_ts(& ptp->host_time_pps, delta);
  return (0);
}
}
static int efx_ptp_synchronize(struct efx_nic *efx , unsigned int num_readings ) 
{ 
  struct efx_ptp_data *ptp ;
  efx_dword_t synch_buf[60U] ;
  unsigned int tmp ;
  size_t response_length ;
  int rc ;
  unsigned long timeout ;
  struct pps_event_time last_time ;
  unsigned int loops ;
    klee_make_symbolic(&loops, sizeof(int), "loops");
  int *start ;
  int __var ;
  unsigned long tmp___0 ;
  int __var___0 ;
  int __var___1 ;
    klee_make_symbolic(&__var___1, sizeof(int), "__var___1");

  {
  ptp = efx->ptp_data;
  synch_buf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 60U) {
      break;
    } else {

    }
    synch_buf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  last_time.ts_real.tv_sec = 0L;
  last_time.ts_real.tv_nsec = 0L;
  loops = 0U;
  start = (int *)ptp->start.addr;
  ((efx_dword_t *)(& synch_buf))->u32[0] = 7U;
  ((efx_dword_t *)(& synch_buf) + 1UL)->u32[0] = 0U;
  ((efx_dword_t *)(& synch_buf) + 2UL)->u32[0] = num_readings;
  ((efx_dword_t *)(& synch_buf) + 3UL)->u32[0] = (unsigned int )ptp->start.dma_addr;
  ((efx_dword_t *)(& synch_buf) + 4U)->u32[0] = (unsigned int )(ptp->start.dma_addr >> 32);
  __var = 0;
  *((int volatile   *)start) = 0;
  rc = efx_mcdi_rpc_start(efx, 11U, (efx_dword_t const   *)(& synch_buf), 20UL);
  tmp___0 = msecs_to_jiffies(2U);
  timeout = tmp___0 + (unsigned long )jiffies;
  goto ldv_56901;
  ldv_56900: 
  __const_udelay(85900UL);
  loops = loops + 1U;
  ldv_56901: 
  __var___0 = 0;
  if ((int )*((int volatile   *)start) == 0 && (long )((unsigned long )jiffies - timeout) < 0L) {
    goto ldv_56900;
  } else {

  }

  if (loops <= 1U) {
    ptp->fast_syncs = ptp->fast_syncs + 1U;
  } else {

  }
  if ((long )((unsigned long )jiffies - timeout) >= 0L) {
    ptp->sync_timeouts = ptp->sync_timeouts + 1U;
  } else {

  }
  __var___1 = 0;
  if ((int )*((int volatile   *)start) != 0) {
    efx_ptp_send_times(efx, & last_time);
  } else {

  }
  rc = efx_mcdi_rpc_finish(efx, 11U, 20UL, (efx_dword_t *)(& synch_buf), 240UL, & response_length);
  if (rc == 0) {
    rc = efx_ptp_process_times(efx, (efx_dword_t *)(& synch_buf), response_length,
                               (struct pps_event_time  const  *)(& last_time));
    if (rc == 0) {
      ptp->good_syncs = ptp->good_syncs + 1U;
    } else {
      ptp->no_time_syncs = ptp->no_time_syncs + 1U;
    }
  } else {

  }
  if (rc != 0) {
    ptp->bad_syncs = ptp->bad_syncs + 1U;
  } else {

  }
  return (rc);
}
}
static int efx_ptp_xmit_skb(struct efx_nic *efx , struct sk_buff *skb ) 
{ 
  struct efx_ptp_data *ptp_data ;
  struct skb_shared_hwtstamps timestamps ;
  int rc ;
  efx_dword_t txtime[2U] ;
  unsigned int tmp ;
  size_t len ;
  unsigned char *tmp___0 ;

  {
  ptp_data = efx->ptp_data;
  rc = -5;
  txtime[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    txtime[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ((efx_dword_t *)(& ptp_data->txbuf))->u32[0] = 3U;
  ((efx_dword_t *)(& ptp_data->txbuf) + 1UL)->u32[0] = 0U;
  ((efx_dword_t *)(& ptp_data->txbuf) + 2UL)->u32[0] = skb->len;
  tmp___0 = skb_end_pointer((struct sk_buff  const  *)skb);
  if ((unsigned int )((struct skb_shared_info *)tmp___0)->nr_frags != 0U) {
    rc = skb_linearize(skb);
    if (rc != 0) {
      goto fail;
    } else {

    }
  } else {

  }
  if ((unsigned int )*((unsigned char *)skb + 145UL) == 6U) {
    rc = skb_checksum_help(skb);
    if (rc != 0) {
      goto fail;
    } else {

    }
  } else {

  }
  skb_copy_from_linear_data((struct sk_buff  const  *)skb, (void *)(& ptp_data->txbuf) + 12U,
                            skb->len);
  rc = efx_mcdi_rpc(efx, 11U, (efx_dword_t const   *)(& ptp_data->txbuf), (size_t )(skb->len + 12U),
                    (efx_dword_t *)(& txtime), 8UL, & len);
  if (rc != 0) {
    goto fail;
  } else {

  }
  memset((void *)(& timestamps), 0, 8UL);
  timestamps.hwtstamp = (*(ptp_data->nic_to_kernel_time))(((efx_dword_t *)(& txtime))->u32[0],
                                                          ((efx_dword_t *)(& txtime) + 1UL)->u32[0],
                                                          ptp_data->ts_corrections.tx);
  skb_tstamp_tx(skb, & timestamps);
  rc = 0;
  fail: 
  consume_skb(skb);
  return (rc);
}
}
static void efx_ptp_drop_time_expired_events(struct efx_nic *efx ) 
{ 
  struct efx_ptp_data *ptp ;
  struct list_head *cursor ;
  struct list_head *next ;
  struct efx_ptp_event_rx *evt ;
  struct list_head  const  *__mptr ;
  int tmp ;

  {
  ptp = efx->ptp_data;
  if ((int )ptp->rx_ts_inline) {
    return;
  } else {

  }
  spin_lock_bh(& ptp->evt_lock);
  tmp = list_empty((struct list_head  const  *)(& ptp->evt_list));
  if (tmp == 0) {
    cursor = ptp->evt_list.next;
    next = cursor->next;
    goto ldv_56951;
    ldv_56950: 
    __mptr = (struct list_head  const  *)cursor;
    evt = (struct efx_ptp_event_rx *)__mptr;
    if ((long )(evt->expiry - (unsigned long )jiffies) < 0L) {
      list_move(& evt->link, & ptp->evt_free_list);
      if ((efx->msg_enable & 8192U) != 0U) {
        netdev_warn((struct net_device  const  *)efx->net_dev, "PTP rx event dropped\n");
      } else {

      }
    } else {

    }
    cursor = next;
    next = cursor->next;
    ldv_56951: ;
    if ((unsigned long )(& ptp->evt_list) != (unsigned long )cursor) {
      goto ldv_56950;
    } else {

    }

  } else {

  }
  spin_unlock_bh(& ptp->evt_lock);
  return;
}
}
static enum ptp_packet_state efx_ptp_match_rx(struct efx_nic *efx , struct sk_buff *skb ) 
{ 
  struct efx_ptp_data *ptp ;
  bool evts_waiting ;
  struct list_head *cursor ;
  struct list_head *next ;
  struct efx_ptp_match *match ;
  enum ptp_packet_state rc ;
  bool __warned ;
  int __ret_warn_once ;
  int __ret_warn_on ;
  long tmp ;
  long tmp___0 ;
  long tmp___1 ;
  int tmp___2 ;
  struct efx_ptp_event_rx *evt ;
  struct list_head  const  *__mptr ;
  struct skb_shared_hwtstamps *timestamps ;

  {
  ptp = efx->ptp_data;
  rc = 0;
  __ret_warn_once = (int )ptp->rx_ts_inline;
  tmp___1 = ldv__builtin_expect(__ret_warn_once != 0, 0L);
  if (tmp___1 != 0L) {
    __ret_warn_on = ! __warned;
    tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp != 0L) {
      warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ptp.c",
                         964);
    } else {

    }
    tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___0 != 0L) {
      __warned = 1;
    } else {

    }
  } else {

  }
  ldv__builtin_expect(__ret_warn_once != 0, 0L);
  spin_lock_bh(& ptp->evt_lock);
  tmp___2 = list_empty((struct list_head  const  *)(& ptp->evt_list));
  evts_waiting = tmp___2 == 0;
  spin_unlock_bh(& ptp->evt_lock);
  if (! evts_waiting) {
    return (0);
  } else {

  }
  match = (struct efx_ptp_match *)(& skb->cb);
  spin_lock_bh(& ptp->evt_lock);
  cursor = ptp->evt_list.next;
  next = cursor->next;
  goto ldv_56974;
  ldv_56973: 
  __mptr = (struct list_head  const  *)cursor;
  evt = (struct efx_ptp_event_rx *)__mptr;
  if (evt->seq0 == match->words[0] && evt->seq1 == match->words[1]) {
    timestamps = skb_hwtstamps(skb);
    timestamps->hwtstamp = evt->hwtimestamp;
    match->state = 1;
    rc = 1;
    list_move(& evt->link, & ptp->evt_free_list);
    goto ldv_56972;
  } else {

  }
  cursor = next;
  next = cursor->next;
  ldv_56974: ;
  if ((unsigned long )(& ptp->evt_list) != (unsigned long )cursor) {
    goto ldv_56973;
  } else {

  }
  ldv_56972: 
  spin_unlock_bh(& ptp->evt_lock);
  return (rc);
}
}
static void efx_ptp_process_events(struct efx_nic *efx , struct sk_buff_head *q ) 
{ 
  struct efx_ptp_data *ptp ;
  struct sk_buff *skb ;
  struct efx_ptp_match *match ;
  enum ptp_packet_state tmp ;

  {
  ptp = efx->ptp_data;
  goto ldv_56990;
  ldv_56989: 
  match = (struct efx_ptp_match *)(& skb->cb);
  if ((unsigned int )match->state == 3U) {
    __skb_queue_tail(q, skb);
  } else {
    tmp = efx_ptp_match_rx(efx, skb);
    if ((unsigned int )tmp == 1U) {
      __skb_queue_tail(q, skb);
    } else
    if ((long )(match->expiry - (unsigned long )jiffies) < 0L) {
      match->state = 2;
      ptp->rx_no_timestamp = ptp->rx_no_timestamp + 1U;
      __skb_queue_tail(q, skb);
    } else {
      skb_queue_head(& ptp->rxq, skb);
      goto ldv_56988;
    }
  }
  ldv_56990: 
  skb = skb_dequeue(& ptp->rxq);
  if ((unsigned long )skb != (unsigned long )((struct sk_buff *)0)) {
    goto ldv_56989;
  } else {

  }
  ldv_56988: ;
  return;
}
}
__inline static void efx_ptp_process_rx(struct efx_nic *efx , struct sk_buff *skb ) 
{ 


  {
  local_bh_disable();
  netif_receive_skb(skb);
  local_bh_enable();
  return;
}
}
static void efx_ptp_remove_multicast_filters(struct efx_nic *efx ) 
{ 
  struct efx_ptp_data *ptp ;

  {
  ptp = efx->ptp_data;
  if ((int )ptp->rxfilter_installed) {
    efx_filter_remove_id_safe(efx, 3, ptp->rxfilter_general);
    efx_filter_remove_id_safe(efx, 3, ptp->rxfilter_event);
    ptp->rxfilter_installed = 0;
  } else {

  }
  return;
}
}
static int efx_ptp_insert_multicast_filters(struct efx_nic *efx ) 
{ 
  struct efx_ptp_data *ptp ;
  struct efx_filter_spec rxfilter ;
  int rc ;
  struct efx_rx_queue *tmp ;
  int tmp___0 ;
  struct efx_rx_queue *tmp___1 ;
  int tmp___2 ;

  {
  ptp = efx->ptp_data;
  if ((unsigned long )ptp->channel == (unsigned long )((struct efx_channel *)0) || (int )ptp->rxfilter_installed) {
    return (0);
  } else {

  }
  tmp = efx_channel_get_rx_queue(ptp->channel);
  tmp___0 = efx_rx_queue_index(tmp);
  efx_filter_init_rx(& rxfilter, 3, 0, (unsigned int )tmp___0);
  rc = efx_filter_set_ipv4_local(& rxfilter, 17, 2164326624U, 16129);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = efx_filter_insert_filter(efx, & rxfilter, 1);
  if (rc < 0) {
    return (rc);
  } else {

  }
  ptp->rxfilter_event = (u32 )rc;
  tmp___1 = efx_channel_get_rx_queue(ptp->channel);
  tmp___2 = efx_rx_queue_index(tmp___1);
  efx_filter_init_rx(& rxfilter, 3, 0, (unsigned int )tmp___2);
  rc = efx_filter_set_ipv4_local(& rxfilter, 17, 2164326624U, 16385);
  if (rc != 0) {
    goto fail;
  } else {

  }
  rc = efx_filter_insert_filter(efx, & rxfilter, 1);
  if (rc < 0) {
    goto fail;
  } else {

  }
  ptp->rxfilter_general = (u32 )rc;
  ptp->rxfilter_installed = 1;
  return (0);
  fail: 
  efx_filter_remove_id_safe(efx, 3, ptp->rxfilter_event);
  return (rc);
}
}
static int efx_ptp_start(struct efx_nic *efx ) 
{ 
  struct efx_ptp_data *ptp ;
  int rc ;

  {
  ptp = efx->ptp_data;
  ptp->reset_required = 0;
  rc = efx_ptp_insert_multicast_filters(efx);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = efx_ptp_enable(efx);
  if (rc != 0) {
    goto fail;
  } else {

  }
  ptp->evt_frag_idx = 0;
  ptp->current_adjfreq = 0LL;
  return (0);
  fail: 
  efx_ptp_remove_multicast_filters(efx);
  return (rc);
}
}
static int efx_ptp_stop(struct efx_nic *efx ) 
{ 
  struct efx_ptp_data *ptp ;
  struct list_head *cursor ;
  struct list_head *next ;
  int rc ;

  {
  ptp = efx->ptp_data;
  if ((unsigned long )ptp == (unsigned long )((struct efx_ptp_data *)0)) {
    return (0);
  } else {

  }
  rc = efx_ptp_disable(efx);
  efx_ptp_remove_multicast_filters(efx);
  efx_ptp_deliver_rx_queue(& (efx->ptp_data)->rxq);
  skb_queue_purge(& (efx->ptp_data)->txq);
  spin_lock_bh(& (efx->ptp_data)->evt_lock);
  cursor = (efx->ptp_data)->evt_list.next;
  next = cursor->next;
  goto ldv_57020;
  ldv_57019: 
  list_move(cursor, & (efx->ptp_data)->evt_free_list);
  cursor = next;
  next = cursor->next;
  ldv_57020: ;
  if ((unsigned long )(& (efx->ptp_data)->evt_list) != (unsigned long )cursor) {
    goto ldv_57019;
  } else {

  }
  spin_unlock_bh(& (efx->ptp_data)->evt_lock);
  return (rc);
}
}
static int efx_ptp_restart(struct efx_nic *efx ) 
{ 
  int tmp ;

  {
  if ((unsigned long )efx->ptp_data != (unsigned long )((struct efx_ptp_data *)0) && (int )(efx->ptp_data)->enabled) {
    tmp = efx_ptp_start(efx);
    return (tmp);
  } else {

  }
  return (0);
}
}
static void efx_ptp_pps_worker(struct work_struct *work ) 
{ 
  struct efx_ptp_data *ptp ;
  struct work_struct  const  *__mptr ;
  struct efx_nic *efx ;
  struct ptp_clock_event ptp_evt ;
  int tmp ;

  {
  __mptr = (struct work_struct  const  *)work;
  ptp = (struct efx_ptp_data *)__mptr + 0xfffffffffffffc18UL;
  efx = ptp->efx;
  tmp = efx_ptp_synchronize(efx, 4U);
  if (tmp != 0) {
    return;
  } else {

  }
  ptp_evt.type = 3;
  ptp_evt.__annonCompField110.pps_times = ptp->host_time_pps;
  ptp_clock_event(ptp->phc_clock, & ptp_evt);
  return;
}
}
static void efx_ptp_worker(struct work_struct *work ) 
{ 
  struct efx_ptp_data *ptp_data ;
  struct work_struct  const  *__mptr ;
  struct efx_nic *efx ;
  struct sk_buff *skb ;
  struct sk_buff_head tempq ;

  {
  __mptr = (struct work_struct  const  *)work;
  ptp_data = (struct efx_ptp_data *)__mptr + 0xfffffffffffffd78UL;
  efx = ptp_data->efx;
  if ((int )ptp_data->reset_required) {
    efx_ptp_stop(efx);
    efx_ptp_start(efx);
    return;
  } else {

  }
  efx_ptp_drop_time_expired_events(efx);
  __skb_queue_head_init(& tempq);
  efx_ptp_process_events(efx, & tempq);
  goto ldv_57043;
  ldv_57042: 
  efx_ptp_xmit_skb(efx, skb);
  ldv_57043: 
  skb = skb_dequeue(& ptp_data->txq);
  if ((unsigned long )skb != (unsigned long )((struct sk_buff *)0)) {
    goto ldv_57042;
  } else {

  }

  goto ldv_57046;
  ldv_57045: 
  efx_ptp_process_rx(efx, skb);
  ldv_57046: 
  skb = __skb_dequeue(& tempq);
  if ((unsigned long )skb != (unsigned long )((struct sk_buff *)0)) {
    goto ldv_57045;
  } else {

  }

  return;
}
}
static struct ptp_clock_info  const  efx_phc_clock_info  = 
     {& __this_module, {'s', 'f', 'c', '\000'}, 1000000, 0, 0, 0, 0, 1, 0, & efx_phc_adjfreq,
    & efx_phc_adjtime, & efx_phc_gettime, & efx_phc_settime, & efx_phc_enable, 0};
int efx_ptp_probe(struct efx_nic *efx , struct efx_channel *channel ) 
{ 
  struct efx_ptp_data *ptp ;
  int rc ;
  unsigned int pos ;
  void *tmp ;
  int tmp___0 ;
  struct lock_class_key __key ;
  char const   *__lock_name ;
  struct workqueue_struct *tmp___1 ;
  struct lock_class_key __key___0 ;
  atomic_long_t __constr_expr_0 ;
  struct lock_class_key __key___1 ;
  long tmp___2 ;
  bool tmp___3 ;
  struct lock_class_key __key___2 ;
  atomic_long_t __constr_expr_1 ;
  struct lock_class_key __key___3 ;
  char const   *__lock_name___0 ;
  struct workqueue_struct *tmp___4 ;

  {
  rc = 0;
  tmp = kzalloc(1672UL, 208U);
  ptp = (struct efx_ptp_data *)tmp;
  efx->ptp_data = ptp;
  if ((unsigned long )efx->ptp_data == (unsigned long )((struct efx_ptp_data *)0)) {
    return (-12);
  } else {

  }
  ptp->efx = efx;
  ptp->channel = channel;
  tmp___0 = efx_nic_rev(efx);
  ptp->rx_ts_inline = tmp___0 > 3;
  rc = efx_nic_alloc_buffer(efx, & ptp->start, 4U, 208U);
  if (rc != 0) {
    goto fail1;
  } else {

  }
  skb_queue_head_init(& ptp->rxq);
  skb_queue_head_init(& ptp->txq);
  __lock_name = "\"%s\"\"sfc_ptp\"";
  tmp___1 = __alloc_workqueue_key("%s", 131082U, 1, & __key, __lock_name, (char *)"sfc_ptp");
  ptp->workwq = tmp___1;
  if ((unsigned long )ptp->workwq == (unsigned long )((struct workqueue_struct *)0)) {
    rc = -12;
    goto fail2;
  } else {

  }
  __init_work(& ptp->work, 0);
  __constr_expr_0.counter = 137438953408L;
  ptp->work.data = __constr_expr_0;
  lockdep_init_map(& ptp->work.lockdep_map, "(&ptp->work)", & __key___0, 0);
  INIT_LIST_HEAD(& ptp->work.entry);
  ptp->work.func = & efx_ptp_worker;
  ptp->config.flags = 0;
  ptp->config.tx_type = 0;
  ptp->config.rx_filter = 0;
  INIT_LIST_HEAD(& ptp->evt_list);
  INIT_LIST_HEAD(& ptp->evt_free_list);
  spinlock_check(& ptp->evt_lock);
  __raw_spin_lock_init(& ptp->evt_lock.__annonCompField17.rlock, "&(&ptp->evt_lock)->rlock",
                       & __key___1);
  pos = 0U;
  goto ldv_57065;
  ldv_57064: 
  list_add(& ptp->rx_evts[pos].link, & ptp->evt_free_list);
  pos = pos + 1U;
  ldv_57065: ;
  if (pos <= 7U) {
    goto ldv_57064;
  } else {

  }
  rc = efx_ptp_get_attributes(efx);
  if (rc < 0) {
    goto fail3;
  } else {

  }
  rc = efx_ptp_get_timestamp_corrections(efx);
  if (rc < 0) {
    goto fail3;
  } else {

  }
  if ((int )(efx->mcdi)->fn_flags & 1) {
    ptp->phc_clock_info = efx_phc_clock_info;
    ptp->phc_clock = ptp_clock_register(& ptp->phc_clock_info, & (efx->pci_dev)->dev);
    tmp___3 = IS_ERR((void const   *)ptp->phc_clock);
    if ((int )tmp___3) {
      tmp___2 = PTR_ERR((void const   *)ptp->phc_clock);
      rc = (int )tmp___2;
      goto fail3;
    } else {

    }
    __init_work(& ptp->pps_work, 0);
    __constr_expr_1.counter = 137438953408L;
    ptp->pps_work.data = __constr_expr_1;
    lockdep_init_map(& ptp->pps_work.lockdep_map, "(&ptp->pps_work)", & __key___2,
                     0);
    INIT_LIST_HEAD(& ptp->pps_work.entry);
    ptp->pps_work.func = & efx_ptp_pps_worker;
    __lock_name___0 = "\"%s\"\"sfc_pps\"";
    tmp___4 = __alloc_workqueue_key("%s", 131082U, 1, & __key___3, __lock_name___0,
                                    (char *)"sfc_pps");
    ptp->pps_workwq = tmp___4;
    if ((unsigned long )ptp->pps_workwq == (unsigned long )((struct workqueue_struct *)0)) {
      rc = -12;
      goto fail4;
    } else {

    }
  } else {

  }
  ptp->nic_ts_enabled = 0;
  return (0);
  fail4: 
  ptp_clock_unregister((efx->ptp_data)->phc_clock);
  fail3: 
  ldv_destroy_workqueue_701((efx->ptp_data)->workwq);
  fail2: 
  efx_nic_free_buffer(efx, & ptp->start);
  fail1: 
  kfree((void const   *)efx->ptp_data);
  efx->ptp_data = (struct efx_ptp_data *)0;
  return (rc);
}
}
static int efx_ptp_probe_channel(struct efx_channel *channel ) 
{ 
  struct efx_nic *efx ;
  int tmp ;

  {
  efx = channel->efx;
  channel->irq_moderation = 0U;
  channel->rx_queue.core_index = 0;
  tmp = efx_ptp_probe(efx, channel);
  return (tmp);
}
}
void efx_ptp_remove(struct efx_nic *efx ) 
{ 


  {
  if ((unsigned long )efx->ptp_data == (unsigned long )((struct efx_ptp_data *)0)) {
    return;
  } else {

  }
  efx_ptp_disable(efx);
  ldv_cancel_work_sync_702(& (efx->ptp_data)->work);
  ldv_cancel_work_sync_703(& (efx->ptp_data)->pps_work);
  skb_queue_purge(& (efx->ptp_data)->rxq);
  skb_queue_purge(& (efx->ptp_data)->txq);
  if ((unsigned long )(efx->ptp_data)->phc_clock != (unsigned long )((struct ptp_clock *)0)) {
    ldv_destroy_workqueue_704((efx->ptp_data)->pps_workwq);
    ptp_clock_unregister((efx->ptp_data)->phc_clock);
  } else {

  }
  ldv_destroy_workqueue_705((efx->ptp_data)->workwq);
  efx_nic_free_buffer(efx, & (efx->ptp_data)->start);
  kfree((void const   *)efx->ptp_data);
  return;
}
}
static void efx_ptp_remove_channel(struct efx_channel *channel ) 
{ 


  {
  efx_ptp_remove(channel->efx);
  return;
}
}
static void efx_ptp_get_channel_name(struct efx_channel *channel , char *buf , size_t len ) 
{ 


  {
  snprintf(buf, len, "%s-ptp", (char *)(& (channel->efx)->name));
  return;
}
}
bool efx_ptp_is_ptp_tx(struct efx_nic *efx , struct sk_buff *skb ) 
{ 
  long tmp ;
  bool tmp___0 ;
  u32 tmp___1 ;
  struct iphdr *tmp___2 ;
  unsigned int tmp___3 ;
  int tmp___4 ;
  struct udphdr *tmp___5 ;
  int tmp___6 ;

  {
  if ((((unsigned long )efx->ptp_data != (unsigned long )((struct efx_ptp_data *)0) && (int )(efx->ptp_data)->enabled) && skb->len > 62U) && skb->len <= 240U) {
    tmp = ldv__builtin_expect((unsigned int )skb->protocol == 8U, 1L);
    if (tmp != 0L) {
      tmp___0 = skb_transport_header_was_set((struct sk_buff  const  *)skb);
      if ((int )tmp___0) {
        tmp___1 = skb_network_header_len((struct sk_buff  const  *)skb);
        if (tmp___1 > 19U) {
          tmp___2 = ip_hdr((struct sk_buff  const  *)skb);
          if ((unsigned int )tmp___2->protocol == 17U) {
            tmp___3 = skb_headlen((struct sk_buff  const  *)skb);
            tmp___4 = skb_transport_offset((struct sk_buff  const  *)skb);
            if ((unsigned long )tmp___3 >= (unsigned long )tmp___4 + 8UL) {
              tmp___5 = udp_hdr((struct sk_buff  const  *)skb);
              if ((unsigned int )tmp___5->dest == 16129U) {
                tmp___6 = 1;
              } else {
                tmp___6 = 0;
              }
            } else {
              tmp___6 = 0;
            }
          } else {
            tmp___6 = 0;
          }
        } else {
          tmp___6 = 0;
        }
      } else {
        tmp___6 = 0;
      }
    } else {
      tmp___6 = 0;
    }
  } else {
    tmp___6 = 0;
  }
  return ((bool )tmp___6);
}
}
static bool efx_ptp_rx(struct efx_channel *channel , struct sk_buff *skb ) 
{ 
  struct efx_nic *efx ;
  struct efx_ptp_data *ptp ;
  struct efx_ptp_match *match ;
  u8 *match_data_012 ;
  u8 *match_data_345 ;
  unsigned int version ;
  u8 *data ;
  unsigned long tmp ;
  int tmp___0 ;
  __u16 tmp___1 ;
  int tmp___2 ;
  long tmp___3 ;
  __u16 tmp___4 ;

  {
  efx = channel->efx;
  ptp = efx->ptp_data;
  match = (struct efx_ptp_match *)(& skb->cb);
  tmp = msecs_to_jiffies(10U);
  match->expiry = tmp + (unsigned long )jiffies;
  if (ptp->mode == 0U) {
    tmp___0 = pskb_may_pull(skb, 64U);
    if (tmp___0 == 0) {
      return (0);
    } else {

    }
    data = skb->data;
    tmp___1 = __fswab16((int )*((__be16 *)data + 28U));
    version = (unsigned int )tmp___1;
    if (version != 1U) {
      return (0);
    } else {

    }
    match_data_012 = data + 50UL;
    match_data_345 = data + 53U;
  } else {
    tmp___2 = pskb_may_pull(skb, 63U);
    if (tmp___2 == 0) {
      return (0);
    } else {

    }
    data = skb->data;
    version = (unsigned int )*(data + 29UL);
    if ((version & 15U) != 2U) {
      return (0);
    } else {

    }
    match_data_345 = data + 53U;
    if (ptp->mode == 2U) {
      match_data_012 = data + 50U;
    } else {
      match_data_012 = data + 48UL;
      tmp___3 = ldv__builtin_expect(ptp->mode != 4U, 0L);
      if (tmp___3 != 0L) {
        __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ptp.c"),
                             "i" (1421), "i" (12UL));
        ldv_57104: ;
        goto ldv_57104;
      } else {

      }
    }
  }
  tmp___4 = __fswab16((int )*((__be16 *)data + 22U));
  if ((unsigned int )tmp___4 == 319U) {
    match->state = 0;
    match->words[0] = (u32 )((((int )*match_data_012 | ((int )*(match_data_012 + 1UL) << 8)) | ((int )*(match_data_012 + 2UL) << 16)) | ((int )*match_data_345 << 24));
    match->words[1] = (u32 )(((int )*(match_data_345 + 1UL) | ((int )*(match_data_345 + 2UL) << 8)) | ((int )*(data + 59UL) << 16));
  } else {
    match->state = 3;
  }
  skb_queue_tail(& ptp->rxq, skb);
  queue_work___0(ptp->workwq, & ptp->work);
  return (1);
}
}
int efx_ptp_tx(struct efx_nic *efx , struct sk_buff *skb ) 
{ 
  struct efx_ptp_data *ptp ;
  struct udphdr *tmp ;

  {
  ptp = efx->ptp_data;
  skb_queue_tail(& ptp->txq, skb);
  tmp = udp_hdr((struct sk_buff  const  *)skb);
  if ((unsigned int )tmp->dest == 16129U && skb->len <= 240U) {
    efx_xmit_hwtstamp_pending(skb);
  } else {

  }
  queue_work___0(ptp->workwq, & ptp->work);
  return (0);
}
}
int efx_ptp_get_mode(struct efx_nic *efx ) 
{ 


  {
  return ((int )(efx->ptp_data)->mode);
}
}
int efx_ptp_change_mode(struct efx_nic *efx , bool enable_wanted , unsigned int new_mode ) 
{ 
  int rc ;
  bool tmp ;

  {
  if ((int )(efx->ptp_data)->enabled != (int )enable_wanted || ((int )enable_wanted && (efx->ptp_data)->mode != new_mode)) {
    rc = 0;
    if ((int )enable_wanted) {
      if ((int )(efx->ptp_data)->enabled && (efx->ptp_data)->mode != new_mode) {
        (efx->ptp_data)->enabled = 0;
        rc = efx_ptp_stop(efx);
        if (rc != 0) {
          return (rc);
        } else {

        }
      } else {

      }
      (efx->ptp_data)->mode = new_mode;
      tmp = netif_running((struct net_device  const  *)efx->net_dev);
      if ((int )tmp) {
        rc = efx_ptp_start(efx);
      } else {

      }
      if (rc == 0) {
        rc = efx_ptp_synchronize(efx, 8U);
        if (rc != 0) {
          efx_ptp_stop(efx);
        } else {

        }
      } else {

      }
    } else {
      rc = efx_ptp_stop(efx);
    }
    if (rc != 0) {
      return (rc);
    } else {

    }
    (efx->ptp_data)->enabled = enable_wanted;
  } else {

  }
  return (0);
}
}
static int efx_ptp_ts_init(struct efx_nic *efx , struct hwtstamp_config *init ) 
{ 
  int rc ;

  {
  if (init->flags != 0) {
    return (-22);
  } else {

  }
  if (init->tx_type != 0 && init->tx_type != 1) {
    return (-34);
  } else {

  }
  rc = (*((efx->type)->ptp_set_ts_config))(efx, init);
  if (rc != 0) {
    return (rc);
  } else {

  }
  (efx->ptp_data)->config = *init;
  return (0);
}
}
void efx_ptp_get_ts_info(struct efx_nic *efx , struct ethtool_ts_info *ts_info ) 
{ 
  struct efx_ptp_data *ptp ;
  struct efx_nic *primary ;
  int tmp ;
  long tmp___0 ;

  {
  ptp = efx->ptp_data;
  primary = efx->primary;
  tmp = rtnl_is_locked();
  tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
  if (tmp___0 != 0L) {
    printk("\vRTNL: assertion failed at %s (%d)\n", (char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ptp.c",
           1545);
    dump_stack();
  } else {

  }
  if ((unsigned long )ptp == (unsigned long )((struct efx_ptp_data *)0)) {
    return;
  } else {

  }
  ts_info->so_timestamping = ts_info->so_timestamping | 69U;
  if (((unsigned long )primary != (unsigned long )((struct efx_nic *)0) && (unsigned long )primary->ptp_data != (unsigned long )((struct efx_ptp_data *)0)) && (unsigned long )(primary->ptp_data)->phc_clock != (unsigned long )((struct ptp_clock *)0)) {
    ts_info->phc_index = ptp_clock_index((primary->ptp_data)->phc_clock);
  } else {

  }
  ts_info->tx_types = 3U;
  ts_info->rx_filters = ((ptp->efx)->type)->hwtstamp_filters;
  return;
}
}
int efx_ptp_set_ts_config(struct efx_nic *efx , struct ifreq *ifr ) 
{ 
  struct hwtstamp_config config ;
  int rc ;
  unsigned long tmp ;
  unsigned long tmp___0 ;

  {
  if ((unsigned long )efx->ptp_data == (unsigned long )((struct efx_ptp_data *)0)) {
    return (-95);
  } else {

  }
  tmp = copy_from_user((void *)(& config), (void const   *)ifr->ifr_ifru.ifru_data,
                       12UL);
  if (tmp != 0UL) {
    return (-14);
  } else {

  }
  rc = efx_ptp_ts_init(efx, & config);
  if (rc != 0) {
    return (rc);
  } else {

  }
  tmp___0 = copy_to_user(ifr->ifr_ifru.ifru_data, (void const   *)(& config), 12UL);
  return (tmp___0 != 0UL ? -14 : 0);
}
}
int efx_ptp_get_ts_config(struct efx_nic *efx , struct ifreq *ifr ) 
{ 
  unsigned long tmp ;

  {
  if ((unsigned long )efx->ptp_data == (unsigned long )((struct efx_ptp_data *)0)) {
    return (-95);
  } else {

  }
  tmp = copy_to_user(ifr->ifr_ifru.ifru_data, (void const   *)(& (efx->ptp_data)->config),
                     12UL);
  return (tmp != 0UL ? -14 : 0);
}
}
static void ptp_event_failure(struct efx_nic *efx , int expected_frag_len ) 
{ 
  struct efx_ptp_data *ptp ;

  {
  ptp = efx->ptp_data;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "PTP unexpected event length: got %d expected %d\n",
               ptp->evt_frag_idx, expected_frag_len);
  } else {

  }
  ptp->reset_required = 1;
  queue_work___0(ptp->workwq, & ptp->work);
  return;
}
}
static void ptp_event_rx(struct efx_nic *efx , struct efx_ptp_data *ptp ) 
{ 
  struct efx_ptp_event_rx *evt ;
  bool __warned ;
  int __ret_warn_once ;
  int __ret_warn_on ;
  long tmp ;
  long tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;
  struct list_head  const  *__mptr ;
  unsigned long tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;

  {
  evt = (struct efx_ptp_event_rx *)0;
  __ret_warn_once = (int )ptp->rx_ts_inline;
  tmp___1 = ldv__builtin_expect(__ret_warn_once != 0, 0L);
  if (tmp___1 != 0L) {
    __ret_warn_on = ! __warned;
    tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp != 0L) {
      warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ptp.c",
                         1608);
    } else {

    }
    tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___0 != 0L) {
      __warned = 1;
    } else {

    }
  } else {

  }
  tmp___2 = ldv__builtin_expect(__ret_warn_once != 0, 0L);
  if (tmp___2 != 0L) {
    return;
  } else {

  }
  if (ptp->evt_frag_idx != 3) {
    ptp_event_failure(efx, 3);
    return;
  } else {

  }
  spin_lock_bh(& ptp->evt_lock);
  tmp___5 = list_empty((struct list_head  const  *)(& ptp->evt_free_list));
  if (tmp___5 == 0) {
    __mptr = (struct list_head  const  *)ptp->evt_free_list.next;
    evt = (struct efx_ptp_event_rx *)__mptr;
    list_del(& evt->link);
    evt->seq0 = (u32 )ptp->evt_frags[2].u64[0];
    evt->seq1 = (((u32 )(ptp->evt_frags[2].u64[0] >> 36) & 255U) | (((u32 )(ptp->evt_frags[1].u64[0] >> 36) << 8U) & 65535U)) | (((u32 )(ptp->evt_frags[0].u64[0] >> 36) & 255U) << 16U);
    evt->hwtimestamp = (*((efx->ptp_data)->nic_to_kernel_time))((u32 )ptp->evt_frags[0].u64[0],
                                                                (u32 )ptp->evt_frags[1].u64[0],
                                                                ptp->ts_corrections.rx);
    tmp___3 = msecs_to_jiffies(10U);
    evt->expiry = tmp___3 + (unsigned long )jiffies;
    list_add_tail(& evt->link, & ptp->evt_list);
    queue_work___0(ptp->workwq, & ptp->work);
  } else {
    tmp___4 = net_ratelimit();
    if (tmp___4 != 0) {
      if ((efx->msg_enable & 64U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "PTP event queue overflow\n");
      } else {

      }
    } else {

    }
  }
  spin_unlock_bh(& ptp->evt_lock);
  return;
}
}
static void ptp_event_fault(struct efx_nic *efx , struct efx_ptp_data *ptp ) 
{ 
  int code ;

  {
  code = (int )ptp->evt_frags[0].u64[0];
  if (ptp->evt_frag_idx != 1) {
    ptp_event_failure(efx, 1);
    return;
  } else {

  }
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "PTP error %d\n", code);
  } else {

  }
  return;
}
}
static void ptp_event_pps(struct efx_nic *efx , struct efx_ptp_data *ptp ) 
{ 


  {
  if ((int )ptp->nic_ts_enabled) {
    queue_work___0(ptp->pps_workwq, & ptp->pps_work);
  } else {

  }
  return;
}
}
void efx_ptp_event(struct efx_nic *efx , efx_qword_t *ev ) 
{ 
  struct efx_ptp_data *ptp ;
  int code ;
  int tmp ;
  int tmp___0 ;

  {
  ptp = efx->ptp_data;
  code = (int )(ev->u64[0] >> 44) & 255;
  if ((unsigned long )ptp == (unsigned long )((struct efx_ptp_data *)0)) {
    tmp = net_ratelimit();
    if (tmp != 0) {
      if ((int )efx->msg_enable & 1) {
        netdev_warn((struct net_device  const  *)efx->net_dev, "Received PTP event but PTP not set up\n");
      } else {

      }
    } else {

    }
    return;
  } else {

  }
  if (! ptp->enabled) {
    return;
  } else {

  }
  if (ptp->evt_frag_idx == 0) {
    ptp->evt_code = code;
  } else
  if (ptp->evt_code != code) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "PTP out of sequence event %d\n",
                 code);
    } else {

    }
    ptp->evt_frag_idx = 0;
  } else {

  }
  tmp___0 = ptp->evt_frag_idx;
  ptp->evt_frag_idx = ptp->evt_frag_idx + 1;
  ptp->evt_frags[tmp___0] = *ev;
  if (((ev->u64[0] >> 32) & 1ULL) == 0ULL) {
    switch (code) {
    case 13: 
    ptp_event_rx(efx, ptp);
    goto ldv_57173;
    case 14: 
    ptp_event_fault(efx, ptp);
    goto ldv_57173;
    case 15: 
    ptp_event_pps(efx, ptp);
    goto ldv_57173;
    default: ;
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "PTP unknown event %d\n",
                 code);
    } else {

    }
    goto ldv_57173;
    }
    ldv_57173: 
    ptp->evt_frag_idx = 0;
  } else
  if (ptp->evt_frag_idx == 3) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "PTP too many event fragments\n");
    } else {

    }
    ptp->evt_frag_idx = 0;
  } else {

  }
  return;
}
}
void efx_time_sync_event(struct efx_channel *channel , efx_qword_t *ev ) 
{ 
  enum efx_sync_events_state __ret ;
  enum efx_sync_events_state __old ;
  enum efx_sync_events_state __new ;
  u8 volatile   *__ptr ;
  u16 volatile   *__ptr___0 ;
  u32 volatile   *__ptr___1 ;
  u64 volatile   *__ptr___2 ;

  {
  channel->sync_timestamp_major = (u32 )ev->u64[0];
  channel->sync_timestamp_minor = ((u32 )(ev->u64[0] >> 36) & 255U) << 19U;
  __old = 2;
  __new = 3;
  switch (4UL) {
  case 1UL: 
  __ptr = (u8 volatile   *)(& channel->sync_events_state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgb %2,%1": "=a" (__ret),
                       "+m" (*__ptr): "q" (__new), "0" (__old): "memory");
  goto ldv_57186;
  case 2UL: 
  __ptr___0 = (u16 volatile   *)(& channel->sync_events_state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgw %2,%1": "=a" (__ret),
                       "+m" (*__ptr___0): "r" (__new), "0" (__old): "memory");
  goto ldv_57186;
  case 4UL: 
  __ptr___1 = (u32 volatile   *)(& channel->sync_events_state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgl %2,%1": "=a" (__ret),
                       "+m" (*__ptr___1): "r" (__new), "0" (__old): "memory");
  goto ldv_57186;
  case 8UL: 
  __ptr___2 = (u64 volatile   *)(& channel->sync_events_state);
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgq %2,%1": "=a" (__ret),
                       "+m" (*__ptr___2): "r" (__new), "0" (__old): "memory");
  goto ldv_57186;
  default: 
  __cmpxchg_wrong_size();
  }
  ldv_57186: ;
  return;
}
}
__inline static u32 efx_rx_buf_timestamp_minor(struct efx_nic *efx , u8 const   *eh ) 
{ 
  __u32 tmp ;

  {
  tmp = __le32_to_cpup((__le32 const   *)eh + (unsigned long )efx->rx_packet_ts_offset);
  return (tmp);
}
}
void __efx_rx_skb_attach_timestamp(struct efx_channel *channel , struct sk_buff *skb ) 
{ 
  struct efx_nic *efx ;
  u32 pkt_timestamp_major ;
  u32 pkt_timestamp_minor ;
  u32 diff ;
  u32 carry ;
  struct skb_shared_hwtstamps *timestamps ;
  unsigned char *tmp ;
  u32 tmp___0 ;

  {
  efx = channel->efx;
  tmp = skb_mac_header((struct sk_buff  const  *)skb);
  tmp___0 = efx_rx_buf_timestamp_minor(efx, (u8 const   *)tmp);
  pkt_timestamp_minor = (tmp___0 + (u32 )(efx->ptp_data)->ts_corrections.rx) & 134217727U;
  diff = (pkt_timestamp_minor - channel->sync_timestamp_minor) & 134217727U;
  carry = channel->sync_timestamp_minor + diff > 134217728U;
  if (diff <= 46976204U) {
    pkt_timestamp_major = channel->sync_timestamp_major + carry;
  } else
  if (diff > 120795955U) {
    pkt_timestamp_major = (channel->sync_timestamp_major + carry) - 1U;
  } else {
    return;
  }
  timestamps = skb_hwtstamps(skb);
  timestamps->hwtstamp = efx_ptp_s27_to_ktime(pkt_timestamp_major, pkt_timestamp_minor);
  return;
}
}
static int efx_phc_adjfreq(struct ptp_clock_info *ptp , s32 delta ) 
{ 
  struct efx_ptp_data *ptp_data ;
  struct ptp_clock_info  const  *__mptr ;
  struct efx_nic *efx ;
  efx_dword_t inadj[6U] ;
  unsigned int tmp ;
  s64 adjustment_ns ;
  int rc ;

  {
  __mptr = (struct ptp_clock_info  const  *)ptp;
  ptp_data = (struct efx_ptp_data *)__mptr + 0xfffffffffffffc80UL;
  efx = ptp_data->efx;
  inadj[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 6U) {
      break;
    } else {

    }
    inadj[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  if (delta > 1000000) {
    delta = 1000000;
  } else
  if (delta < -1000000) {
    delta = -1000000;
  } else {

  }
  adjustment_ns = (long long )delta * 4611686018LL >> 22;
  ((efx_dword_t *)(& inadj))->u32[0] = 6U;
  ((efx_dword_t *)(& inadj) + 1UL)->u32[0] = 0U;
  ((efx_dword_t *)(& inadj) + 2UL)->u32[0] = (unsigned int )adjustment_ns;
  ((efx_dword_t *)(& inadj) + 3U)->u32[0] = (unsigned int )((unsigned long long )adjustment_ns >> 32);
  ((efx_dword_t *)(& inadj) + 4UL)->u32[0] = 0U;
  ((efx_dword_t *)(& inadj) + 5UL)->u32[0] = 0U;
  rc = efx_mcdi_rpc(efx, 11U, (efx_dword_t const   *)(& inadj), 24UL, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  if (rc != 0) {
    return (rc);
  } else {

  }
  ptp_data->current_adjfreq = adjustment_ns;
  return (0);
}
}
static int efx_phc_adjtime(struct ptp_clock_info *ptp , s64 delta ) 
{ 
  u32 nic_major ;
  u32 nic_minor ;
  struct efx_ptp_data *ptp_data ;
  struct ptp_clock_info  const  *__mptr ;
  struct efx_nic *efx ;
  efx_dword_t inbuf[6U] ;
  unsigned int tmp ;
  int tmp___0 ;

  {
  __mptr = (struct ptp_clock_info  const  *)ptp;
  ptp_data = (struct efx_ptp_data *)__mptr + 0xfffffffffffffc80UL;
  efx = ptp_data->efx;
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 6U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  (*((efx->ptp_data)->ns_to_nic_time))(delta, & nic_major, & nic_minor);
  ((efx_dword_t *)(& inbuf))->u32[0] = 6U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = 0U;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = (unsigned int )ptp_data->current_adjfreq;
  ((efx_dword_t *)(& inbuf) + 3U)->u32[0] = (unsigned int )((unsigned long long )ptp_data->current_adjfreq >> 32);
  ((efx_dword_t *)(& inbuf) + 4UL)->u32[0] = nic_major;
  ((efx_dword_t *)(& inbuf) + 5UL)->u32[0] = nic_minor;
  tmp___0 = efx_mcdi_rpc(efx, 11U, (efx_dword_t const   *)(& inbuf), 24UL, (efx_dword_t *)0,
                         0UL, (size_t *)0UL);
  return (tmp___0);
}
}
static int efx_phc_gettime(struct ptp_clock_info *ptp , struct timespec *ts ) 
{ 
  struct efx_ptp_data *ptp_data ;
  struct ptp_clock_info  const  *__mptr ;
  struct efx_nic *efx ;
  efx_dword_t inbuf[2U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[2U] ;
  unsigned int tmp___0 ;
  int rc ;
  ktime_t kt ;

  {
  __mptr = (struct ptp_clock_info  const  *)ptp;
  ptp_data = (struct efx_ptp_data *)__mptr + 0xfffffffffffffc80UL;
  efx = ptp_data->efx;
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 2U) {
      break;
    } else {

    }
    outbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = 4U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = 0U;
  rc = efx_mcdi_rpc(efx, 11U, (efx_dword_t const   *)(& inbuf), 8UL, (efx_dword_t *)(& outbuf),
                    8UL, (size_t *)0UL);
  if (rc != 0) {
    return (rc);
  } else {

  }
  kt = (*(ptp_data->nic_to_kernel_time))(((efx_dword_t *)(& outbuf))->u32[0], ((efx_dword_t *)(& outbuf) + 1UL)->u32[0],
                                         0);
  *ts = ns_to_timespec(kt.tv64);
  return (0);
}
}
static int efx_phc_settime(struct ptp_clock_info *ptp , struct timespec  const  *e_ts ) 
{ 
  int rc ;
  struct timespec time_now ;
  struct timespec delta ;
  s64 tmp ;

  {
  rc = efx_phc_gettime(ptp, & time_now);
  if (rc != 0) {
    return (rc);
  } else {

  }
  delta = timespec_sub(*e_ts, time_now);
  tmp = timespec_to_ns((struct timespec  const  *)(& delta));
  rc = efx_phc_adjtime(ptp, tmp);
  if (rc != 0) {
    return (rc);
  } else {

  }
  return (0);
}
}
static int efx_phc_enable(struct ptp_clock_info *ptp , struct ptp_clock_request *request ,
                          int enable ) 
{ 
  struct efx_ptp_data *ptp_data ;
  struct ptp_clock_info  const  *__mptr ;

  {
  __mptr = (struct ptp_clock_info  const  *)ptp;
  ptp_data = (struct efx_ptp_data *)__mptr + 0xfffffffffffffc80UL;
  if ((unsigned int )request->type != 2U) {
    return (-95);
  } else {

  }
  ptp_data->nic_ts_enabled = enable != 0;
  return (0);
}
}
static struct efx_channel_type  const  efx_ptp_channel_type  =    {& efx_ptp_handle_no_channel, & efx_ptp_probe_channel, & efx_ptp_remove_channel,
    & efx_ptp_get_channel_name, 0, & efx_ptp_rx, 0};
void efx_ptp_defer_probe_with_channel(struct efx_nic *efx ) 
{ 
  int tmp ;

  {
  tmp = efx_ptp_disable(efx);
  if (tmp == 0) {
    efx->extra_channel_type[1] = & efx_ptp_channel_type;
  } else {

  }
  return;
}
}
void efx_ptp_start_datapath(struct efx_nic *efx ) 
{ 
  int tmp ;

  {
  tmp = efx_ptp_restart(efx);
  if (tmp != 0) {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Failed to restart PTP.\n");
    } else {

    }
  } else {

  }
  if ((unsigned long )(efx->type)->ptp_set_ts_sync_events != (unsigned long )((int (*/* const  */)(struct efx_nic * ,
                                                                                                   bool  ,
                                                                                                   bool  ))0)) {
    (*((efx->type)->ptp_set_ts_sync_events))(efx, 1, 1);
  } else {

  }
  return;
}
}
void efx_ptp_stop_datapath(struct efx_nic *efx ) 
{ 


  {
  if ((unsigned long )(efx->type)->ptp_set_ts_sync_events != (unsigned long )((int (*/* const  */)(struct efx_nic * ,
                                                                                                   bool  ,
                                                                                                   bool  ))0)) {
    (*((efx->type)->ptp_set_ts_sync_events))(efx, 0, 1);
  } else {

  }
  efx_ptp_stop(efx);
  return;
}
}
void activate_work_5(struct work_struct *work , int state ) 
{ 


  {
  if (ldv_work_5_0 == 0) {
    ldv_work_struct_5_0 = work;
    ldv_work_5_0 = state;
    return;
  } else {

  }
  if (ldv_work_5_1 == 0) {
    ldv_work_struct_5_1 = work;
    ldv_work_5_1 = state;
    return;
  } else {

  }
  if (ldv_work_5_2 == 0) {
    ldv_work_struct_5_2 = work;
    ldv_work_5_2 = state;
    return;
  } else {

  }
  if (ldv_work_5_3 == 0) {
    ldv_work_struct_5_3 = work;
    ldv_work_5_3 = state;
    return;
  } else {

  }
  return;
}
}
void work_init_5(void) 
{ 


  {
  ldv_work_5_0 = 0;
  ldv_work_5_1 = 0;
  ldv_work_5_2 = 0;
  ldv_work_5_3 = 0;
  return;
}
}
void ldv_initialize_ptp_clock_info_16(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(104UL);
  efx_phc_clock_info_group0 = (struct ptp_clock_info *)tmp;
  return;
}
}
void activate_work_6(struct work_struct *work , int state ) 
{ 


  {
  if (ldv_work_6_0 == 0) {
    ldv_work_struct_6_0 = work;
    ldv_work_6_0 = state;
    return;
  } else {

  }
  if (ldv_work_6_1 == 0) {
    ldv_work_struct_6_1 = work;
    ldv_work_6_1 = state;
    return;
  } else {

  }
  if (ldv_work_6_2 == 0) {
    ldv_work_struct_6_2 = work;
    ldv_work_6_2 = state;
    return;
  } else {

  }
  if (ldv_work_6_3 == 0) {
    ldv_work_struct_6_3 = work;
    ldv_work_6_3 = state;
    return;
  } else {

  }
  return;
}
}
void invoke_work_5(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_work_5_0 == 2 || ldv_work_5_0 == 3) {
    ldv_work_5_0 = 4;
    efx_ptp_worker(ldv_work_struct_5_0);
    ldv_work_5_0 = 1;
  } else {

  }
  goto ldv_57325;
  case 1: ;
  if (ldv_work_5_1 == 2 || ldv_work_5_1 == 3) {
    ldv_work_5_1 = 4;
    efx_ptp_worker(ldv_work_struct_5_0);
    ldv_work_5_1 = 1;
  } else {

  }
  goto ldv_57325;
  case 2: ;
  if (ldv_work_5_2 == 2 || ldv_work_5_2 == 3) {
    ldv_work_5_2 = 4;
    efx_ptp_worker(ldv_work_struct_5_0);
    ldv_work_5_2 = 1;
  } else {

  }
  goto ldv_57325;
  case 3: ;
  if (ldv_work_5_3 == 2 || ldv_work_5_3 == 3) {
    ldv_work_5_3 = 4;
    efx_ptp_worker(ldv_work_struct_5_0);
    ldv_work_5_3 = 1;
  } else {

  }
  goto ldv_57325;
  default: 
  ldv_stop();
  }
  ldv_57325: ;
  return;
}
}
void invoke_work_6(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_work_6_0 == 2 || ldv_work_6_0 == 3) {
    ldv_work_6_0 = 4;
    efx_ptp_pps_worker(ldv_work_struct_6_0);
    ldv_work_6_0 = 1;
  } else {

  }
  goto ldv_57336;
  case 1: ;
  if (ldv_work_6_1 == 2 || ldv_work_6_1 == 3) {
    ldv_work_6_1 = 4;
    efx_ptp_pps_worker(ldv_work_struct_6_0);
    ldv_work_6_1 = 1;
  } else {

  }
  goto ldv_57336;
  case 2: ;
  if (ldv_work_6_2 == 2 || ldv_work_6_2 == 3) {
    ldv_work_6_2 = 4;
    efx_ptp_pps_worker(ldv_work_struct_6_0);
    ldv_work_6_2 = 1;
  } else {

  }
  goto ldv_57336;
  case 3: ;
  if (ldv_work_6_3 == 2 || ldv_work_6_3 == 3) {
    ldv_work_6_3 = 4;
    efx_ptp_pps_worker(ldv_work_struct_6_0);
    ldv_work_6_3 = 1;
  } else {

  }
  goto ldv_57336;
  default: 
  ldv_stop();
  }
  ldv_57336: ;
  return;
}
}
void disable_work_5(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_5_0 == 3 || ldv_work_5_0 == 2) && (unsigned long )ldv_work_struct_5_0 == (unsigned long )work) {
    ldv_work_5_0 = 1;
  } else {

  }
  if ((ldv_work_5_1 == 3 || ldv_work_5_1 == 2) && (unsigned long )ldv_work_struct_5_1 == (unsigned long )work) {
    ldv_work_5_1 = 1;
  } else {

  }
  if ((ldv_work_5_2 == 3 || ldv_work_5_2 == 2) && (unsigned long )ldv_work_struct_5_2 == (unsigned long )work) {
    ldv_work_5_2 = 1;
  } else {

  }
  if ((ldv_work_5_3 == 3 || ldv_work_5_3 == 2) && (unsigned long )ldv_work_struct_5_3 == (unsigned long )work) {
    ldv_work_5_3 = 1;
  } else {

  }
  return;
}
}
void call_and_disable_all_6(int state ) 
{ 


  {
  if (ldv_work_6_0 == state) {
    call_and_disable_work_6(ldv_work_struct_6_0);
  } else {

  }
  if (ldv_work_6_1 == state) {
    call_and_disable_work_6(ldv_work_struct_6_1);
  } else {

  }
  if (ldv_work_6_2 == state) {
    call_and_disable_work_6(ldv_work_struct_6_2);
  } else {

  }
  if (ldv_work_6_3 == state) {
    call_and_disable_work_6(ldv_work_struct_6_3);
  } else {

  }
  return;
}
}
void call_and_disable_work_5(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_5_0 == 2 || ldv_work_5_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_5_0) {
    efx_ptp_worker(work);
    ldv_work_5_0 = 1;
    return;
  } else {

  }
  if ((ldv_work_5_1 == 2 || ldv_work_5_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_5_1) {
    efx_ptp_worker(work);
    ldv_work_5_1 = 1;
    return;
  } else {

  }
  if ((ldv_work_5_2 == 2 || ldv_work_5_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_5_2) {
    efx_ptp_worker(work);
    ldv_work_5_2 = 1;
    return;
  } else {

  }
  if ((ldv_work_5_3 == 2 || ldv_work_5_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_5_3) {
    efx_ptp_worker(work);
    ldv_work_5_3 = 1;
    return;
  } else {

  }
  return;
}
}
void call_and_disable_all_5(int state ) 
{ 


  {
  if (ldv_work_5_0 == state) {
    call_and_disable_work_5(ldv_work_struct_5_0);
  } else {

  }
  if (ldv_work_5_1 == state) {
    call_and_disable_work_5(ldv_work_struct_5_1);
  } else {

  }
  if (ldv_work_5_2 == state) {
    call_and_disable_work_5(ldv_work_struct_5_2);
  } else {

  }
  if (ldv_work_5_3 == state) {
    call_and_disable_work_5(ldv_work_struct_5_3);
  } else {

  }
  return;
}
}
void disable_work_6(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_6_0 == 3 || ldv_work_6_0 == 2) && (unsigned long )ldv_work_struct_6_0 == (unsigned long )work) {
    ldv_work_6_0 = 1;
  } else {

  }
  if ((ldv_work_6_1 == 3 || ldv_work_6_1 == 2) && (unsigned long )ldv_work_struct_6_1 == (unsigned long )work) {
    ldv_work_6_1 = 1;
  } else {

  }
  if ((ldv_work_6_2 == 3 || ldv_work_6_2 == 2) && (unsigned long )ldv_work_struct_6_2 == (unsigned long )work) {
    ldv_work_6_2 = 1;
  } else {

  }
  if ((ldv_work_6_3 == 3 || ldv_work_6_3 == 2) && (unsigned long )ldv_work_struct_6_3 == (unsigned long )work) {
    ldv_work_6_3 = 1;
  } else {

  }
  return;
}
}
void work_init_6(void) 
{ 


  {
  ldv_work_6_0 = 0;
  ldv_work_6_1 = 0;
  ldv_work_6_2 = 0;
  ldv_work_6_3 = 0;
  return;
}
}
void ldv_initialize_efx_channel_type_15(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(2176UL);
  efx_ptp_channel_type_group0 = (struct efx_channel *)tmp;
  return;
}
}
void call_and_disable_work_6(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_6_0 == 2 || ldv_work_6_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_6_0) {
    efx_ptp_pps_worker(work);
    ldv_work_6_0 = 1;
    return;
  } else {

  }
  if ((ldv_work_6_1 == 2 || ldv_work_6_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_6_1) {
    efx_ptp_pps_worker(work);
    ldv_work_6_1 = 1;
    return;
  } else {

  }
  if ((ldv_work_6_2 == 2 || ldv_work_6_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_6_2) {
    efx_ptp_pps_worker(work);
    ldv_work_6_2 = 1;
    return;
  } else {

  }
  if ((ldv_work_6_3 == 2 || ldv_work_6_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_6_3) {
    efx_ptp_pps_worker(work);
    ldv_work_6_3 = 1;
    return;
  } else {

  }
  return;
}
}
void ldv_main_exported_16(void) 
{ 
  s32 ldvarg22 ;
  int ldvarg23 ;
    klee_make_symbolic(&ldvarg23, sizeof(int), "ldvarg23");
  s64 ldvarg25 ;
  struct timespec *ldvarg26 ;
  void *tmp ;
  struct timespec *ldvarg27 ;
  void *tmp___0 ;
  struct ptp_clock_request *ldvarg24 ;
  void *tmp___1 ;
  int tmp___2 ;

  {
  tmp = ldv_init_zalloc(16UL);
  ldvarg26 = (struct timespec *)tmp;
  tmp___0 = ldv_init_zalloc(16UL);
  ldvarg27 = (struct timespec *)tmp___0;
  tmp___1 = ldv_init_zalloc(64UL);
  ldvarg24 = (struct ptp_clock_request *)tmp___1;
  ldv_memset((void *)(& ldvarg22), 0, 4UL);
  ldv_memset((void *)(& ldvarg23), 0, 4UL);
  ldv_memset((void *)(& ldvarg25), 0, 8UL);
  tmp___2 = __VERIFIER_nondet_int();
  switch (tmp___2) {
  case 0: ;
  if (ldv_state_variable_16 == 1) {
    efx_phc_settime(efx_phc_clock_info_group0, (struct timespec  const  *)ldvarg27);
    ldv_state_variable_16 = 1;
  } else {

  }
  goto ldv_57379;
  case 1: ;
  if (ldv_state_variable_16 == 1) {
    efx_phc_gettime(efx_phc_clock_info_group0, ldvarg26);
    ldv_state_variable_16 = 1;
  } else {

  }
  goto ldv_57379;
  case 2: ;
  if (ldv_state_variable_16 == 1) {
    efx_phc_adjtime(efx_phc_clock_info_group0, ldvarg25);
    ldv_state_variable_16 = 1;
  } else {

  }
  goto ldv_57379;
  case 3: ;
  if (ldv_state_variable_16 == 1) {
    efx_phc_enable(efx_phc_clock_info_group0, ldvarg24, ldvarg23);
    ldv_state_variable_16 = 1;
  } else {

  }
  goto ldv_57379;
  case 4: ;
  if (ldv_state_variable_16 == 1) {
    efx_phc_adjfreq(efx_phc_clock_info_group0, ldvarg22);
    ldv_state_variable_16 = 1;
  } else {

  }
  goto ldv_57379;
  default: 
  ldv_stop();
  }
  ldv_57379: ;
  return;
}
}
void ldv_main_exported_15(void) 
{ 
  struct efx_nic *ldvarg316 ;
  void *tmp ;
  size_t ldvarg318 ;
  struct sk_buff *ldvarg317 ;
  void *tmp___0 ;
  char *ldvarg319 ;
  void *tmp___1 ;
  int tmp___2 ;

  {
  tmp = ldv_init_zalloc(4032UL);
  ldvarg316 = (struct efx_nic *)tmp;
  tmp___0 = ldv_init_zalloc(232UL);
  ldvarg317 = (struct sk_buff *)tmp___0;
  tmp___1 = ldv_init_zalloc(1UL);
  ldvarg319 = (char *)tmp___1;
  ldv_memset((void *)(& ldvarg318), 0, 8UL);
  tmp___2 = __VERIFIER_nondet_int();
  switch (tmp___2) {
  case 0: ;
  if (ldv_state_variable_15 == 1) {
    efx_ptp_get_channel_name(efx_ptp_channel_type_group0, ldvarg319, ldvarg318);
    ldv_state_variable_15 = 1;
  } else {

  }
  goto ldv_57393;
  case 1: ;
  if (ldv_state_variable_15 == 1) {
    efx_ptp_probe_channel(efx_ptp_channel_type_group0);
    ldv_state_variable_15 = 1;
  } else {

  }
  goto ldv_57393;
  case 2: ;
  if (ldv_state_variable_15 == 1) {
    efx_ptp_remove_channel(efx_ptp_channel_type_group0);
    ldv_state_variable_15 = 1;
  } else {

  }
  goto ldv_57393;
  case 3: ;
  if (ldv_state_variable_15 == 1) {
    efx_ptp_rx(efx_ptp_channel_type_group0, ldvarg317);
    ldv_state_variable_15 = 1;
  } else {

  }
  goto ldv_57393;
  case 4: ;
  if (ldv_state_variable_15 == 1) {
    efx_ptp_handle_no_channel(ldvarg316);
    ldv_state_variable_15 = 1;
  } else {

  }
  goto ldv_57393;
  default: 
  ldv_stop();
  }
  ldv_57393: ;
  return;
}
}
bool ldv_queue_work_on_689(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_690(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_691(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_692(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_693(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_694(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_695(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_696(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_697(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_698(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_699(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_700(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_destroy_workqueue_701(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  destroy_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_cancel_work_sync_702(struct work_struct *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___14 ldv_func_res ;
  bool tmp ;

  {
  tmp = cancel_work_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_work_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
bool ldv_cancel_work_sync_703(struct work_struct *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___15 ldv_func_res ;
  bool tmp ;

  {
  tmp = cancel_work_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_work_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
void ldv_destroy_workqueue_704(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  destroy_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
void ldv_destroy_workqueue_705(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  destroy_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
int ldv_mutex_trylock_735(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_733(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_736(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_737(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_732(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_734(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_738(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_727(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_729(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_728(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_731(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_730(struct workqueue_struct *ldv_func_arg1 ) ;
extern int mtd_device_parse_register(struct mtd_info * , char const   * const  * ,
                                     struct mtd_part_parser_data * , struct mtd_partition  const  * ,
                                     int  ) ;
extern int mtd_device_unregister(struct mtd_info * ) ;
extern void mtd_erase_callback(struct erase_info * ) ;
static int efx_mtd_erase(struct mtd_info *mtd , struct erase_info *erase ) 
{ 
  struct efx_nic *efx ;
  int rc ;

  {
  efx = (struct efx_nic *)mtd->priv;
  rc = (*((efx->type)->mtd_erase))(mtd, (loff_t )erase->addr, (size_t )erase->len);
  if (rc == 0) {
    erase->state = 8U;
  } else {
    erase->state = 16U;
    erase->fail_addr = 0xffffffffffffffffULL;
  }
  mtd_erase_callback(erase);
  return (rc);
}
}
static void efx_mtd_sync(struct mtd_info *mtd ) 
{ 
  struct efx_mtd_partition *part ;
  struct mtd_info  const  *__mptr ;
  struct efx_nic *efx ;
  int rc ;

  {
  __mptr = (struct mtd_info  const  *)mtd;
  part = (struct efx_mtd_partition *)__mptr + 0xfffffffffffffff0UL;
  efx = (struct efx_nic *)mtd->priv;
  rc = (*((efx->type)->mtd_sync))(mtd);
  if (rc != 0) {
    printk("\v%s: %s sync failed (%d)\n", (char *)(& part->name), part->dev_type_name,
           rc);
  } else {

  }
  return;
}
}
static void efx_mtd_remove_partition(struct efx_mtd_partition *part ) 
{ 
  int rc ;
  int __ret_warn_on ;
  long tmp ;

  {
  ldv_55354: 
  rc = mtd_device_unregister(& part->mtd);
  if (rc != -16) {
    goto ldv_55353;
  } else {

  }
  ssleep(1U);
  goto ldv_55354;
  ldv_55353: 
  __ret_warn_on = rc != 0;
  tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mtd.c",
                       62);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  list_del(& part->node);
  return;
}
}
int efx_mtd_add(struct efx_nic *efx , struct efx_mtd_partition *parts , size_t n_parts ,
                size_t sizeof_part ) 
{ 
  struct efx_mtd_partition *part ;
  size_t i ;
  int tmp ;
  size_t tmp___0 ;

  {
  i = 0UL;
  goto ldv_55367;
  ldv_55366: 
  part = parts + i * sizeof_part;
  part->mtd.writesize = 1U;
  part->mtd.owner = & __this_module;
  part->mtd.priv = (void *)efx;
  part->mtd.name = (char const   *)(& part->name);
  part->mtd._erase = & efx_mtd_erase;
  part->mtd._read = (int (*)(struct mtd_info * , loff_t  , size_t  , size_t * , u_char * ))(efx->type)->mtd_read;
  part->mtd._write = (int (*)(struct mtd_info * , loff_t  , size_t  , size_t * , u_char const   * ))(efx->type)->mtd_write;
  part->mtd._sync = & efx_mtd_sync;
  (*((efx->type)->mtd_rename))(part);
  tmp = mtd_device_parse_register(& part->mtd, (char const   * const  *)0, (struct mtd_part_parser_data *)0,
                                  (struct mtd_partition  const  *)0, 0);
  if (tmp != 0) {
    goto fail;
  } else {

  }
  list_add_tail(& part->node, & efx->mtd_list);
  i = i + 1UL;
  ldv_55367: ;
  if (i < n_parts) {
    goto ldv_55366;
  } else {

  }

  return (0);
  fail: ;
  goto ldv_55370;
  ldv_55369: 
  part = parts + i * sizeof_part;
  efx_mtd_remove_partition(part);
  ldv_55370: 
  tmp___0 = i;
  i = i - 1UL;
  if (tmp___0 != 0UL) {
    goto ldv_55369;
  } else {

  }

  return (-12);
}
}
void efx_mtd_remove(struct efx_nic *efx ) 
{ 
  struct efx_mtd_partition *parts ;
  struct efx_mtd_partition *part ;
  struct efx_mtd_partition *next ;
  int __ret_warn_on ;
  int tmp ;
  long tmp___0 ;
  int tmp___1 ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;
  struct list_head  const  *__mptr___2 ;

  {
  tmp = efx_dev_registered(efx);
  __ret_warn_on = tmp != 0;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mtd.c",
                       111);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  tmp___1 = list_empty((struct list_head  const  *)(& efx->mtd_list));
  if (tmp___1 != 0) {
    return;
  } else {

  }
  __mptr = (struct list_head  const  *)efx->mtd_list.next;
  parts = (struct efx_mtd_partition *)__mptr;
  __mptr___0 = (struct list_head  const  *)efx->mtd_list.next;
  part = (struct efx_mtd_partition *)__mptr___0;
  __mptr___1 = (struct list_head  const  *)part->node.next;
  next = (struct efx_mtd_partition *)__mptr___1;
  goto ldv_55389;
  ldv_55388: 
  efx_mtd_remove_partition(part);
  part = next;
  __mptr___2 = (struct list_head  const  *)next->node.next;
  next = (struct efx_mtd_partition *)__mptr___2;
  ldv_55389: ;
  if ((unsigned long )(& part->node) != (unsigned long )(& efx->mtd_list)) {
    goto ldv_55388;
  } else {

  }
  kfree((void const   *)parts);
  return;
}
}
void efx_mtd_rename(struct efx_nic *efx ) 
{ 
  struct efx_mtd_partition *part ;
  int tmp ;
  long tmp___0 ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  tmp = rtnl_is_locked();
  tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
  if (tmp___0 != 0L) {
    printk("\vRTNL: assertion failed at %s (%d)\n", (char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/mtd.c",
           129);
    dump_stack();
  } else {

  }
  __mptr = (struct list_head  const  *)efx->mtd_list.next;
  part = (struct efx_mtd_partition *)__mptr;
  goto ldv_55400;
  ldv_55399: 
  (*((efx->type)->mtd_rename))(part);
  __mptr___0 = (struct list_head  const  *)part->node.next;
  part = (struct efx_mtd_partition *)__mptr___0;
  ldv_55400: ;
  if ((unsigned long )(& part->node) != (unsigned long )(& efx->mtd_list)) {
    goto ldv_55399;
  } else {

  }

  return;
}
}
bool ldv_queue_work_on_727(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_728(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_729(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_730(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_731(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_732(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_733(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_734(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_735(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_736(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_737(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_738(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_763(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_761(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_764(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_765(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_760(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_762(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_766(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_755(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_757(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_756(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_759(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_758(struct workqueue_struct *ldv_func_arg1 ) ;
int efx_sriov_set_vf_mac(struct net_device *net_dev , int vf_i , u8 *mac ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((unsigned long )(efx->type)->sriov_set_vf_mac != (unsigned long )((int (*/* const  */)(struct efx_nic * ,
                                                                                             int  ,
                                                                                             u8 * ))0)) {
    tmp___0 = (*((efx->type)->sriov_set_vf_mac))(efx, vf_i, mac);
    return (tmp___0);
  } else {
    return (-95);
  }
}
}
int efx_sriov_set_vf_vlan(struct net_device *net_dev , int vf_i , u16 vlan , u8 qos ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((unsigned long )(efx->type)->sriov_set_vf_vlan != (unsigned long )((int (*/* const  */)(struct efx_nic * ,
                                                                                              int  ,
                                                                                              u16  ,
                                                                                              u8  ))0)) {
    if (((int )vlan & -4096) != 0 || ((int )qos & -8) != 0) {
      return (-22);
    } else {

    }
    tmp___0 = (*((efx->type)->sriov_set_vf_vlan))(efx, vf_i, (int )vlan, (int )qos);
    return (tmp___0);
  } else {
    return (-95);
  }
}
}
int efx_sriov_set_vf_spoofchk(struct net_device *net_dev , int vf_i , bool spoofchk ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((unsigned long )(efx->type)->sriov_set_vf_spoofchk != (unsigned long )((int (*/* const  */)(struct efx_nic * ,
                                                                                                  int  ,
                                                                                                  bool  ))0)) {
    tmp___0 = (*((efx->type)->sriov_set_vf_spoofchk))(efx, vf_i, (int )spoofchk);
    return (tmp___0);
  } else {
    return (-95);
  }
}
}
int efx_sriov_get_vf_config(struct net_device *net_dev , int vf_i , struct ifla_vf_info *ivi ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((unsigned long )(efx->type)->sriov_get_vf_config != (unsigned long )((int (*/* const  */)(struct efx_nic * ,
                                                                                                int  ,
                                                                                                struct ifla_vf_info * ))0)) {
    tmp___0 = (*((efx->type)->sriov_get_vf_config))(efx, vf_i, ivi);
    return (tmp___0);
  } else {
    return (-95);
  }
}
}
int efx_sriov_set_vf_link_state(struct net_device *net_dev , int vf_i , int link_state ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((unsigned long )(efx->type)->sriov_set_vf_link_state != (unsigned long )((int (*/* const  */)(struct efx_nic * ,
                                                                                                    int  ,
                                                                                                    int  ))0)) {
    tmp___0 = (*((efx->type)->sriov_set_vf_link_state))(efx, vf_i, link_state);
    return (tmp___0);
  } else {
    return (-95);
  }
}
}
int efx_sriov_get_phys_port_id(struct net_device *net_dev , struct netdev_phys_item_id *ppid ) 
{ 
  struct efx_nic *efx ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)net_dev);
  efx = (struct efx_nic *)tmp;
  if ((unsigned long )(efx->type)->sriov_get_phys_port_id != (unsigned long )((int (*/* const  */)(struct efx_nic * ,
                                                                                                   struct netdev_phys_item_id * ))0)) {
    tmp___0 = (*((efx->type)->sriov_get_phys_port_id))(efx, ppid);
    return (tmp___0);
  } else {
    return (-95);
  }
}
}
bool ldv_queue_work_on_755(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_756(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_757(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_758(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_759(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_760(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_761(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_762(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_763(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_764(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_765(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_766(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
__inline static int __test_and_set_bit(long nr , unsigned long volatile   *addr ) 
{ 
  int oldbit ;

  {
  __asm__  ("bts %2,%1\n\tsbb %0,%0": "=r" (oldbit), "+m" (*((long volatile   *)addr)): "Ir" (nr));
  return (oldbit);
}
}
__inline static void __list_splice(struct list_head  const  *list , struct list_head *prev ,
                                   struct list_head *next ) 
{ 
  struct list_head *first ;
  struct list_head *last ;

  {
  first = list->next;
  last = list->prev;
  first->prev = prev;
  prev->next = first;
  last->next = next;
  next->prev = last;
  return;
}
}
__inline static void list_splice_tail_init(struct list_head *list , struct list_head *head ) 
{ 
  int tmp ;

  {
  tmp = list_empty((struct list_head  const  *)list);
  if (tmp == 0) {
    __list_splice((struct list_head  const  *)list, head->prev, head);
    INIT_LIST_HEAD(list);
  } else {

  }
  return;
}
}
__inline static int ldv_mutex_is_locked_795(struct mutex *lock ) ;
int ldv_mutex_trylock_791(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_789(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_792(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_793(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_797(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_800(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_801(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_803(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_805(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_808(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_809(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_811(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_818(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_820(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_822(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_788(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_790(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_794(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_796(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_798(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_799(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_802(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_804(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_806(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_807(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_810(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_817(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_819(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_821(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_local_lock_of_siena_nic_data(struct mutex *lock ) ;
void ldv_mutex_unlock_local_lock_of_siena_nic_data(struct mutex *lock ) ;
void ldv_mutex_lock_status_lock_of_siena_vf(struct mutex *lock ) ;
int ldv_mutex_is_locked_status_lock_of_siena_vf(struct mutex *lock ) ;
void ldv_mutex_unlock_status_lock_of_siena_vf(struct mutex *lock ) ;
void ldv_mutex_lock_txq_lock_of_siena_vf(struct mutex *lock ) ;
void ldv_mutex_unlock_txq_lock_of_siena_vf(struct mutex *lock ) ;
void ldv_destroy_workqueue_816(struct workqueue_struct *ldv_func_arg1 ) ;
bool ldv_queue_work_on_783(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_785(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_784(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_787(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_786(struct workqueue_struct *ldv_func_arg1 ) ;
bool ldv_cancel_work_sync_812(struct work_struct *ldv_func_arg1 ) ;
bool ldv_cancel_work_sync_813(struct work_struct *ldv_func_arg1 ) ;
bool ldv_cancel_work_sync_814(struct work_struct *ldv_func_arg1 ) ;
bool ldv_cancel_work_sync_815(struct work_struct *ldv_func_arg1 ) ;
__inline static bool queue_work___1(struct workqueue_struct *wq , struct work_struct *work ) 
{ 
  bool tmp ;

  {
  tmp = ldv_queue_work_on_783(8192, wq, work);
  return (tmp);
}
}
void invoke_work_8(void) ;
void call_and_disable_work_7(struct work_struct *work ) ;
void call_and_disable_all_9(int state ) ;
void call_and_disable_work_8(struct work_struct *work ) ;
void invoke_work_9(void) ;
void disable_work_8(struct work_struct *work ) ;
void activate_work_9(struct work_struct *work , int state ) ;
void invoke_work_7(void) ;
void call_and_disable_all_8(int state ) ;
void call_and_disable_work_9(struct work_struct *work ) ;
void activate_work_8(struct work_struct *work , int state ) ;
void disable_work_9(struct work_struct *work ) ;
extern int pci_find_ext_capability(struct pci_dev * , int  ) ;
extern int pci_bus_read_config_word(struct pci_bus * , unsigned int  , int  , u16 * ) ;
__inline static int pci_read_config_word(struct pci_dev  const  *dev , int where ,
                                         u16 *val ) 
{ 
  int tmp ;

  {
  tmp = pci_bus_read_config_word(dev->bus, dev->devfn, where, val);
  return (tmp);
}
}
__inline static int pci_domain_nr(struct pci_bus *bus ) 
{ 
  struct pci_sysdata *sd ;

  {
  sd = (struct pci_sysdata *)bus->sysdata;
  return (sd->domain);
}
}
extern int pci_enable_sriov(struct pci_dev * , int  ) ;
extern void pci_disable_sriov(struct pci_dev * ) ;
__inline static void efx_filter_init_tx(struct efx_filter_spec *spec , unsigned int txq_id ) 
{ 


  {
  memset((void *)spec, 0, 64UL);
  spec->priority = 3U;
  spec->flags = 16U;
  spec->dmaq_id = (unsigned short )txq_id;
  return;
}
}
static unsigned int vf_max_tx_channels  =    2U;
static int max_vfs  =    -1;
static struct workqueue_struct *vfdi_workqueue  ;
static unsigned int abs_index(struct siena_vf *vf , unsigned int index ) 
{ 
  unsigned int tmp ;

  {
  tmp = efx_vf_size(vf->efx);
  return ((vf->index * tmp + index) + 128U);
}
}
static int efx_siena_sriov_cmd(struct efx_nic *efx , bool enable , unsigned int *vi_scale_out ,
                               unsigned int *vf_total_out ) 
{ 
  efx_dword_t inbuf[3U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[2U] ;
  unsigned int tmp___0 ;
  unsigned int vi_scale ;
  unsigned int vf_total ;
    klee_make_symbolic(&vf_total, sizeof(int), "vf_total");
  size_t outlen ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 3U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 2U) {
      break;
    } else {

    }
    outbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = (int )enable ? 1U : 0U;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = 128U;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = efx->vf_count;
  rc = efx_mcdi_rpc_quiet(efx, 48U, (efx_dword_t const   *)(& inbuf), 12UL, (efx_dword_t *)(& outbuf),
                          8UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 7UL) {
    return (-5);
  } else {

  }
  vf_total = ((efx_dword_t *)(& outbuf) + 1UL)->u32[0];
  vi_scale = ((efx_dword_t *)(& outbuf))->u32[0];
  if (vi_scale > 6U) {
    return (-95);
  } else {

  }
  if ((unsigned long )vi_scale_out != (unsigned long )((unsigned int *)0U)) {
    *vi_scale_out = vi_scale;
  } else {

  }
  if ((unsigned long )vf_total_out != (unsigned long )((unsigned int *)0U)) {
    *vf_total_out = vf_total;
  } else {

  }
  return (0);
}
}
static void efx_siena_sriov_usrev(struct efx_nic *efx , bool enabled ) 
{ 
  struct siena_nic_data *nic_data ;
  efx_oword_t reg ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  reg.u64[0] = ((unsigned long long )(! enabled) << 16) | (unsigned long long )(nic_data->vfdi_channel)->channel;
  reg.u64[1] = 0ULL;
  efx_writeo(efx, (efx_oword_t const   *)(& reg), 256U);
  return;
}
}
static int efx_siena_sriov_memcpy(struct efx_nic *efx , struct efx_memcpy_req *req ,
                                  unsigned int count ) 
{ 
  efx_dword_t inbuf[63U] ;
  unsigned int tmp ;
  efx_dword_t *record ;
  unsigned int index ;
  unsigned int used ;
  u64 from_addr ;
  u32 from_rid ;
  int rc ;
  int __ret_warn_on ;
  long tmp___0 ;
  long tmp___1 ;
  int __ret_warn_on___0 ;
  long tmp___2 ;
  long tmp___3 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 63U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  __asm__  volatile   ("mfence": : : "memory");
  __ret_warn_on = count > 7U;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c",
                       255);
  } else {

  }
  tmp___1 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___1 != 0L) {
    return (-105);
  } else {

  }
  used = count * 32U;
  index = 0U;
  goto ldv_56723;
  ldv_56722: 
  record = (efx_dword_t *)(& inbuf) + (unsigned long )index * 32UL;
  record->u32[0] = count;
  (record + 1UL)->u32[0] = req->to_rid;
  (record + 2UL)->u32[0] = (unsigned int )req->to_addr;
  (record + 3U)->u32[0] = (unsigned int )(req->to_addr >> 32);
  if ((unsigned long )req->from_buf == (unsigned long )((void *)0)) {
    from_rid = req->from_rid;
    from_addr = req->from_addr;
  } else {
    __ret_warn_on___0 = req->length + used > 252U;
    tmp___2 = ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
    if (tmp___2 != 0L) {
      warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c",
                         272);
    } else {

    }
    tmp___3 = ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
    if (tmp___3 != 0L) {
      rc = -105;
      goto out;
    } else {

    }
    from_rid = 256U;
    from_addr = (u64 )used;
    memcpy((void *)(& inbuf) + (unsigned long )used, (void const   *)req->from_buf,
             (size_t )req->length);
    used = req->length + used;
  }
  (record + 4UL)->u32[0] = from_rid;
  (record + 5UL)->u32[0] = (unsigned int )from_addr;
  (record + 6U)->u32[0] = (unsigned int )(from_addr >> 32);
  (record + 7UL)->u32[0] = req->length;
  req = req + 1;
  index = index + 1U;
  ldv_56723: ;
  if (index < count) {
    goto ldv_56722;
  } else {

  }
  rc = efx_mcdi_rpc(efx, 49U, (efx_dword_t const   *)(& inbuf), (size_t )used, (efx_dword_t *)0,
                    0UL, (size_t *)0UL);
  out: 
  __asm__  volatile   ("mfence": : : "memory");
  return (rc);
}
}
static void efx_siena_sriov_reset_tx_filter(struct siena_vf *vf ) 
{ 
  struct efx_nic *efx ;
  struct efx_filter_spec filter ;
  u16 vlan ;
  int rc ;
  struct _ddebug descriptor ;
  long tmp ;
  bool tmp___0 ;
  __u16 tmp___1 ;
  unsigned int tmp___2 ;
  long tmp___3 ;
  struct _ddebug descriptor___0 ;
  long tmp___4 ;

  {
  efx = vf->efx;
  if (vf->tx_filter_id != -1) {
    efx_filter_remove_id_safe(efx, 3, (u32 )vf->tx_filter_id);
    if ((efx->msg_enable & 8192U) != 0U) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_siena_sriov_reset_tx_filter";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c";
      descriptor.format = "Removed vf %s tx filter %d\n";
      descriptor.lineno = 314U;
      descriptor.flags = 0U;
      tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "Removed vf %s tx filter %d\n", (char *)(& vf->pci_name),
                             vf->tx_filter_id);
      } else {

      }
    } else {

    }
    vf->tx_filter_id = -1;
  } else {

  }
  tmp___0 = is_zero_ether_addr((u8 const   *)(& vf->addr.mac_addr));
  if ((int )tmp___0) {
    return;
  } else {

  }
  if ((unsigned int )vf->tx_filter_mode == 1U && vf_max_tx_channels <= 2U) {
    vf->tx_filter_mode = 2;
  } else {

  }
  tmp___1 = __fswab16((int )vf->addr.tci);
  vlan = (unsigned int )tmp___1 & 4095U;
  tmp___2 = abs_index(vf, 0U);
  efx_filter_init_tx(& filter, tmp___2);
  rc = efx_filter_set_eth_local(& filter, (unsigned int )vlan != 0U ? (int )vlan : 65535,
                                (u8 const   *)(& vf->addr.mac_addr));
  tmp___3 = ldv__builtin_expect(rc != 0, 0L);
  if (tmp___3 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c"),
                         "i" (332), "i" (12UL));
    ldv_56734: ;
    goto ldv_56734;
  } else {

  }
  rc = efx_filter_insert_filter(efx, & filter, 1);
  if (rc < 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_warn((struct net_device  const  *)efx->net_dev, "Unable to migrate tx filter for vf %s\n",
                  (char *)(& vf->pci_name));
    } else {

    }
  } else {
    if ((efx->msg_enable & 8192U) != 0U) {
      descriptor___0.modname = "sfc";
      descriptor___0.function = "efx_siena_sriov_reset_tx_filter";
      descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c";
      descriptor___0.format = "Inserted vf %s tx filter %d\n";
      descriptor___0.lineno = 341U;
      descriptor___0.flags = 0U;
      tmp___4 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
      if (tmp___4 != 0L) {
        __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                             "Inserted vf %s tx filter %d\n", (char *)(& vf->pci_name),
                             rc);
      } else {

      }
    } else {

    }
    vf->tx_filter_id = rc;
  }
  return;
}
}
static void efx_siena_sriov_reset_rx_filter(struct siena_vf *vf ) 
{ 
  struct efx_nic *efx ;
  struct efx_filter_spec filter ;
  u16 vlan ;
  int rc ;
  struct _ddebug descriptor ;
  long tmp ;
  bool tmp___0 ;
  __u16 tmp___1 ;
  unsigned int tmp___2 ;
  long tmp___3 ;
  struct _ddebug descriptor___0 ;
  long tmp___4 ;

  {
  efx = vf->efx;
  if (vf->rx_filter_id != -1) {
    efx_filter_remove_id_safe(efx, 3, (u32 )vf->rx_filter_id);
    if ((efx->msg_enable & 8192U) != 0U) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_siena_sriov_reset_rx_filter";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c";
      descriptor.format = "Removed vf %s rx filter %d\n";
      descriptor.lineno = 358U;
      descriptor.flags = 0U;
      tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "Removed vf %s rx filter %d\n", (char *)(& vf->pci_name),
                             vf->rx_filter_id);
      } else {

      }
    } else {

    }
    vf->rx_filter_id = -1;
  } else {

  }
  if (! vf->rx_filtering) {
    return;
  } else {
    tmp___0 = is_zero_ether_addr((u8 const   *)(& vf->addr.mac_addr));
    if ((int )tmp___0) {
      return;
    } else {

    }
  }
  tmp___1 = __fswab16((int )vf->addr.tci);
  vlan = (unsigned int )tmp___1 & 4095U;
  tmp___2 = abs_index(vf, vf->rx_filter_qid);
  efx_filter_init_rx(& filter, 3, vf->rx_filter_flags, tmp___2);
  rc = efx_filter_set_eth_local(& filter, (unsigned int )vlan != 0U ? (int )vlan : 65535,
                                (u8 const   *)(& vf->addr.mac_addr));
  tmp___3 = ldv__builtin_expect(rc != 0, 0L);
  if (tmp___3 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c"),
                         "i" (372), "i" (12UL));
    ldv_56745: ;
    goto ldv_56745;
  } else {

  }
  rc = efx_filter_insert_filter(efx, & filter, 1);
  if (rc < 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_warn((struct net_device  const  *)efx->net_dev, "Unable to insert rx filter for vf %s\n",
                  (char *)(& vf->pci_name));
    } else {

    }
  } else {
    if ((efx->msg_enable & 8192U) != 0U) {
      descriptor___0.modname = "sfc";
      descriptor___0.function = "efx_siena_sriov_reset_rx_filter";
      descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c";
      descriptor___0.format = "Inserted vf %s rx filter %d\n";
      descriptor___0.lineno = 381U;
      descriptor___0.flags = 0U;
      tmp___4 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
      if (tmp___4 != 0L) {
        __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                             "Inserted vf %s rx filter %d\n", (char *)(& vf->pci_name),
                             rc);
      } else {

      }
    } else {

    }
    vf->rx_filter_id = rc;
  }
  return;
}
}
static void __efx_siena_sriov_update_vf_addr(struct siena_vf *vf ) 
{ 
  struct efx_nic *efx ;
  struct siena_nic_data *nic_data ;

  {
  efx = vf->efx;
  nic_data = (struct siena_nic_data *)efx->nic_data;
  efx_siena_sriov_reset_tx_filter(vf);
  efx_siena_sriov_reset_rx_filter(vf);
  queue_work___1(vfdi_workqueue, & nic_data->peer_work);
  return;
}
}
static void __efx_siena_sriov_push_vf_status(struct siena_vf *vf ) 
{ 
  struct efx_nic *efx ;
  struct siena_nic_data *nic_data ;
  struct vfdi_status *status ;
  struct efx_memcpy_req copy[4U] ;
  struct efx_endpoint_page *epp ;
  unsigned int pos ;
  unsigned int count ;
  unsigned int data_offset ;
    klee_make_symbolic(&data_offset, sizeof(int), "data_offset");
  efx_qword_t event ;
  int __ret_warn_on ;
  int tmp ;
  long tmp___0 ;
  int __ret_warn_on___0 ;
  long tmp___1 ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  unsigned int tmp___2 ;

  {
  efx = vf->efx;
  nic_data = (struct siena_nic_data *)efx->nic_data;
  status = (struct vfdi_status *)nic_data->vfdi_status.addr;
  tmp = ldv_mutex_is_locked_795(& vf->status_lock);
  __ret_warn_on = tmp == 0;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c",
                       412);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  __ret_warn_on___0 = vf->status_addr == 0ULL;
  tmp___1 = ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
  if (tmp___1 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c",
                       413);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
  status->local = vf->addr;
  status->generation_start = status->generation_start + 1U;
  status->generation_end = status->generation_start;
  memset((void *)(& copy), 0, 192UL);
  copy[0].from_buf = (void *)(& status->generation_start);
  copy[0].to_rid = vf->pci_rid;
  copy[0].to_addr = vf->status_addr;
  copy[0].length = 4U;
  data_offset = 8U;
  copy[1].from_rid = (efx->pci_dev)->devfn;
  copy[1].from_addr = nic_data->vfdi_status.dma_addr + (dma_addr_t )data_offset;
  copy[1].to_rid = vf->pci_rid;
  copy[1].to_addr = vf->status_addr + (u64 )data_offset;
  copy[1].length = status->length - data_offset;
  pos = 2U;
  count = 0U;
  __mptr = (struct list_head  const  *)nic_data->local_page_list.next;
  epp = (struct efx_endpoint_page *)__mptr;
  goto ldv_56778;
  ldv_56777: ;
  if (vf->peer_page_count == count) {
    goto ldv_56772;
  } else {

  }
  copy[pos].from_buf = (void *)0;
  copy[pos].from_rid = (efx->pci_dev)->devfn;
  copy[pos].from_addr = epp->addr;
  copy[pos].to_rid = vf->pci_rid;
  copy[pos].to_addr = *(vf->peer_page_addrs + (unsigned long )count);
  copy[pos].length = 4096U;
  pos = pos + 1U;
  if (pos == 4U) {
    efx_siena_sriov_memcpy(efx, (struct efx_memcpy_req *)(& copy), 4U);
    pos = 0U;
  } else {

  }
  count = count + 1U;
  __mptr___0 = (struct list_head  const  *)epp->link.next;
  epp = (struct efx_endpoint_page *)__mptr___0;
  ldv_56778: ;
  if ((unsigned long )(& epp->link) != (unsigned long )(& nic_data->local_page_list)) {
    goto ldv_56777;
  } else {

  }
  ldv_56772: 
  copy[pos].from_buf = (void *)(& status->generation_end);
  copy[pos].to_rid = vf->pci_rid;
  copy[pos].to_addr = vf->status_addr + 4ULL;
  copy[pos].length = 4U;
  efx_siena_sriov_memcpy(efx, (struct efx_memcpy_req *)(& copy), pos + 1U);
  event.u64[0] = (((unsigned long long )vf->msg_seqno << 24) & 4294967295ULL) | 0x8000000000040000ULL;
  vf->msg_seqno = vf->msg_seqno + 1U;
  tmp___2 = efx_vf_size(efx);
  efx_farch_generate_event(efx, vf->index * tmp___2 + 128U, & event);
  return;
}
}
static void efx_siena_sriov_bufs(struct efx_nic *efx , unsigned int offset , u64 *addr ,
                                 unsigned int count ) 
{ 
  efx_qword_t buf ;
  unsigned int pos ;

  {
  pos = 0U;
  goto ldv_56788;
  ldv_56787: 
  buf.u64[0] = (unsigned long )addr != (unsigned long )((u64 *)0ULL) ? (*(addr + (unsigned long )pos) >> 12) << 14 : 0ULL;
  efx_sram_writeq(efx, efx->membase + 8388608UL, (efx_qword_t const   *)(& buf), offset + pos);
  pos = pos + 1U;
  ldv_56788: ;
  if (pos < count) {
    goto ldv_56787;
  } else {

  }

  return;
}
}
static bool bad_vf_index(struct efx_nic *efx , unsigned int index ) 
{ 
  unsigned int tmp ;

  {
  tmp = efx_vf_size(efx);
  return (tmp <= index);
}
}
static bool bad_buf_count(unsigned int buf_count , unsigned int max_entry_count ) 
{ 
  unsigned int max_buf_count ;
    klee_make_symbolic(&max_buf_count, sizeof(int), "max_buf_count");

  {
  max_buf_count = (unsigned int )(((unsigned long )max_entry_count * 8UL) / 4096UL);
  return ((bool )(((buf_count - 1U) & buf_count) != 0U || buf_count > max_buf_count));
}
}
static bool map_vi_index(struct efx_nic *efx , unsigned int abs_index___0 , struct siena_vf **vf_out ,
                         unsigned int *rel_index_out ) 
{ 
  struct siena_nic_data *nic_data ;
  unsigned int vf_i ;
    klee_make_symbolic(&vf_i, sizeof(int), "vf_i");
  unsigned int tmp ;
  unsigned int tmp___0 ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  if (abs_index___0 <= 127U) {
    return (1);
  } else {

  }
  tmp = efx_vf_size(efx);
  vf_i = (abs_index___0 - 128U) / tmp;
  if (efx->vf_init_count <= vf_i) {
    return (1);
  } else {

  }
  if ((unsigned long )vf_out != (unsigned long )((struct siena_vf **)0)) {
    *vf_out = nic_data->vf + (unsigned long )vf_i;
  } else {

  }
  if ((unsigned long )rel_index_out != (unsigned long )((unsigned int *)0U)) {
    tmp___0 = efx_vf_size(efx);
    *rel_index_out = abs_index___0 % tmp___0;
  } else {

  }
  return (0);
}
}
static int efx_vfdi_init_evq(struct siena_vf *vf ) 
{ 
  struct efx_nic *efx ;
  struct vfdi_req *req ;
  unsigned int vf_evq ;
    klee_make_symbolic(&vf_evq, sizeof(int), "vf_evq");
  unsigned int buf_count ;
    klee_make_symbolic(&buf_count, sizeof(int), "buf_count");
  unsigned int abs_evq ;
    klee_make_symbolic(&abs_evq, sizeof(int), "abs_evq");
  unsigned int tmp ;
  unsigned int buftbl ;
    klee_make_symbolic(&buftbl, sizeof(int), "buftbl");
  efx_oword_t reg ;
  int tmp___0 ;
  bool tmp___1 ;
  bool tmp___2 ;
  unsigned long tmp___3 ;

  {
  efx = vf->efx;
  req = (struct vfdi_req *)vf->buf.addr;
  vf_evq = req->u.init_evq.index;
  buf_count = req->u.init_evq.buf_count;
  tmp = abs_index(vf, vf_evq);
  abs_evq = tmp;
  buftbl = (vf->buftbl_base + vf_evq * 32U) + 16U;
  tmp___1 = bad_vf_index(efx, vf_evq);
  if ((int )tmp___1) {
    goto _L;
  } else {
    tmp___2 = bad_buf_count(buf_count, 8192U);
    if ((int )tmp___2) {
      _L: /* CIL Label */ 
      tmp___0 = net_ratelimit();
      if (tmp___0 != 0) {
        if ((efx->msg_enable & 8192U) != 0U) {
          netdev_err((struct net_device  const  *)efx->net_dev, "OLD_ERROR: Invalid INIT_EVQ from %s: evq %d bufs %d\n",
                     (char *)(& vf->pci_name), vf_evq, buf_count);
        } else {

        }
      } else {

      }
      return (-22);
    } else {

    }
  }
  efx_siena_sriov_bufs(efx, buftbl, (u64 *)(& req->u.init_evq.addr), buf_count);
  reg.u64[0] = 8589934592ULL;
  reg.u64[1] = 0ULL;
  efx_writeo_table(efx, (efx_oword_t const   *)(& reg), 16187392U, abs_evq);
  tmp___3 = __ffs((unsigned long )buf_count);
  reg.u64[0] = (((unsigned long long )tmp___3 << 20) | (unsigned long long )buftbl) | 8388608ULL;
  reg.u64[1] = 0ULL;
  efx_writeo_table(efx, (efx_oword_t const   *)(& reg), 16121856U, abs_evq);
  if (vf_evq == 0U) {
    memcpy((void *)(& vf->evq0_addrs), (void const   *)(& req->u.init_evq.addr),
             (unsigned long )buf_count * 8UL);
    vf->evq0_count = buf_count;
  } else {

  }
  return (0);
}
}
static int efx_vfdi_init_rxq(struct siena_vf *vf ) 
{ 
  struct efx_nic *efx ;
  struct vfdi_req *req ;
  unsigned int vf_rxq ;
    klee_make_symbolic(&vf_rxq, sizeof(int), "vf_rxq");
  unsigned int vf_evq ;
  unsigned int buf_count ;
  unsigned int buftbl ;
  unsigned int label ;
    klee_make_symbolic(&label, sizeof(int), "label");
  efx_oword_t reg ;
  int tmp ;
  bool tmp___0 ;
  bool tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  unsigned int tmp___4 ;
  unsigned long tmp___5 ;
  unsigned int tmp___6 ;

  {
  efx = vf->efx;
  req = (struct vfdi_req *)vf->buf.addr;
  vf_rxq = req->u.init_rxq.index;
  vf_evq = req->u.init_rxq.evq;
  buf_count = req->u.init_rxq.buf_count;
  buftbl = (vf->buftbl_base + vf_rxq * 32U) + 8U;
  tmp___0 = bad_vf_index(efx, vf_evq);
  if ((int )tmp___0) {
    goto _L;
  } else {
    tmp___1 = bad_vf_index(efx, vf_rxq);
    if ((int )tmp___1) {
      goto _L;
    } else
    if (vf_rxq > 62U) {
      goto _L;
    } else {
      tmp___2 = bad_buf_count(buf_count, 4096U);
      if ((int )tmp___2) {
        _L: /* CIL Label */ 
        tmp = net_ratelimit();
        if (tmp != 0) {
          if ((efx->msg_enable & 8192U) != 0U) {
            netdev_err((struct net_device  const  *)efx->net_dev, "OLD_ERROR: Invalid INIT_RXQ from %s: rxq %d evq %d buf_count %d\n",
                       (char *)(& vf->pci_name), vf_rxq, vf_evq, buf_count);
          } else {

          }
        } else {

        }
        return (-22);
      } else {

      }
    }
  }
  tmp___3 = __test_and_set_bit((long )req->u.init_rxq.index, (unsigned long volatile   *)(& vf->rxq_mask));
  if (tmp___3 != 0) {
    vf->rxq_count = vf->rxq_count + 1U;
  } else {

  }
  efx_siena_sriov_bufs(efx, buftbl, (u64 *)(& req->u.init_rxq.addr), buf_count);
  label = req->u.init_rxq.label & 31U;
  tmp___4 = abs_index(vf, vf_evq);
  tmp___5 = __ffs((unsigned long )buf_count);
  reg.u64[0] = ((((((unsigned long long )buftbl << 36) | ((unsigned long long )tmp___4 << 24)) | ((unsigned long long )label << 5)) | ((unsigned long long )tmp___5 << 3)) | (((unsigned long long )req->u.init_rxq.flags & 1ULL) << 1)) | 1ULL;
  reg.u64[1] = 0ULL;
  tmp___6 = abs_index(vf, vf_rxq);
  efx_writeo_table(efx, (efx_oword_t const   *)(& reg), 15990784U, tmp___6);
  return (0);
}
}
static int efx_vfdi_init_txq(struct siena_vf *vf ) 
{ 
  struct efx_nic *efx ;
  struct vfdi_req *req ;
  unsigned int vf_txq ;
    klee_make_symbolic(&vf_txq, sizeof(int), "vf_txq");
  unsigned int vf_evq ;
  unsigned int buf_count ;
  unsigned int buftbl ;
  unsigned int label ;
  unsigned int eth_filt_en ;
    klee_make_symbolic(&eth_filt_en, sizeof(int), "eth_filt_en");
  efx_oword_t reg ;
  int tmp ;
  bool tmp___0 ;
  bool tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  unsigned int tmp___4 ;
  unsigned long tmp___5 ;
  unsigned int _min1 ;
  unsigned int _min2 ;
  unsigned int tmp___6 ;

  {
  efx = vf->efx;
  req = (struct vfdi_req *)vf->buf.addr;
  vf_txq = req->u.init_txq.index;
  vf_evq = req->u.init_txq.evq;
  buf_count = req->u.init_txq.buf_count;
  buftbl = vf->buftbl_base + vf_txq * 32U;
  tmp___0 = bad_vf_index(efx, vf_evq);
  if ((int )tmp___0) {
    goto _L;
  } else {
    tmp___1 = bad_vf_index(efx, vf_txq);
    if ((int )tmp___1) {
      goto _L;
    } else
    if (vf_txq >= vf_max_tx_channels) {
      goto _L;
    } else {
      tmp___2 = bad_buf_count(buf_count, 4096U);
      if ((int )tmp___2) {
        _L: /* CIL Label */ 
        tmp = net_ratelimit();
        if (tmp != 0) {
          if ((efx->msg_enable & 8192U) != 0U) {
            netdev_err((struct net_device  const  *)efx->net_dev, "OLD_ERROR: Invalid INIT_TXQ from %s: txq %d evq %d buf_count %d\n",
                       (char *)(& vf->pci_name), vf_txq, vf_evq, buf_count);
          } else {

          }
        } else {

        }
        return (-22);
      } else {

      }
    }
  }
  ldv_mutex_lock_796(& vf->txq_lock);
  tmp___3 = __test_and_set_bit((long )req->u.init_txq.index, (unsigned long volatile   *)(& vf->txq_mask));
  if (tmp___3 != 0) {
    vf->txq_count = vf->txq_count + 1U;
  } else {

  }
  ldv_mutex_unlock_797(& vf->txq_lock);
  efx_siena_sriov_bufs(efx, buftbl, (u64 *)(& req->u.init_txq.addr), buf_count);
  eth_filt_en = (unsigned int )vf->tx_filter_mode == 2U;
  label = req->u.init_txq.label & 31U;
  tmp___4 = abs_index(vf, vf_evq);
  tmp___5 = __ffs((unsigned long )buf_count);
  reg.u64[0] = ((((unsigned long long )buftbl << 36) | ((unsigned long long )tmp___4 << 24)) | ((unsigned long long )label << 5)) | ((unsigned long long )tmp___5 << 3);
  _min1 = efx->vi_scale;
  _min2 = 1U;
  reg.u64[1] = (((unsigned long long )(_min1 < _min2 ? _min1 : _min2) << 30) | ((unsigned long long )eth_filt_en << 29)) | 150994944ULL;
  tmp___6 = abs_index(vf, vf_txq);
  efx_writeo_table(efx, (efx_oword_t const   *)(& reg), 16056320U, tmp___6);
  return (0);
}
}
static bool efx_vfdi_flush_wake(struct siena_vf *vf ) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  __asm__  volatile   ("mfence": : : "memory");
  if (vf->txq_count == 0U && vf->rxq_count == 0U) {
    tmp___0 = 1;
  } else {
    tmp = atomic_read((atomic_t const   *)(& vf->rxq_retry_count));
    if (tmp != 0) {
      tmp___0 = 1;
    } else {
      tmp___0 = 0;
    }
  }
  return ((bool )tmp___0);
}
}
static void efx_vfdi_flush_clear(struct siena_vf *vf ) 
{ 


  {
  memset((void *)(& vf->txq_mask), 0, 8UL);
  vf->txq_count = 0U;
  memset((void *)(& vf->rxq_mask), 0, 8UL);
  vf->rxq_count = 0U;
  memset((void *)(& vf->rxq_retry_mask), 0, 8UL);
  atomic_set(& vf->rxq_retry_count, 0);
  return;
}
}
static int efx_vfdi_fini_all_queues(struct siena_vf *vf ) 
{ 
  struct efx_nic *efx ;
  efx_oword_t reg ;
  unsigned int count ;
  unsigned int tmp ;
  unsigned int vf_offset ;
    klee_make_symbolic(&vf_offset, sizeof(int), "vf_offset");
  unsigned int tmp___0 ;
  unsigned int timeout ;
  unsigned int index ;
  unsigned int rxqs_count ;
    klee_make_symbolic(&rxqs_count, sizeof(int), "rxqs_count");
  efx_dword_t inbuf[63U] ;
  unsigned int tmp___1 ;
  int rc ;
  int tmp___2 ;
  int tmp___3 ;
  int __ret_warn_on ;
  long tmp___4 ;
  long __ret ;
  wait_queue_t __wait ;
  long __ret___0 ;
  long __int ;
  long tmp___5 ;
  bool __cond ;
  bool tmp___6 ;
  bool __cond___0 ;
  bool tmp___7 ;
  int tmp___8 ;
  unsigned int tmp___9 ;

  {
  efx = vf->efx;
  tmp = efx_vf_size(efx);
  count = tmp;
  tmp___0 = efx_vf_size(efx);
  vf_offset = vf->index * tmp___0 + 128U;
  timeout = 250U;
  inbuf[0].u32[0] = 0U;
  tmp___1 = 1U;
  while (1) {
    if (tmp___1 >= 63U) {
      break;
    } else {

    }
    inbuf[tmp___1].u32[0] = 0U;
    tmp___1 = tmp___1 + 1U;
  }
  rtnl_lock();
  siena_prepare_flush(efx);
  rtnl_unlock();
  rxqs_count = 0U;
  index = 0U;
  goto ldv_56895;
  ldv_56894: 
  tmp___2 = variable_test_bit((long )index, (unsigned long const volatile   *)(& vf->txq_mask));
  if (tmp___2 != 0) {
    reg.u64[0] = (unsigned long long )(vf_offset + index) | 4096ULL;
    reg.u64[1] = 0ULL;
    efx_writeo(efx, (efx_oword_t const   *)(& reg), 2560U);
  } else {

  }
  tmp___3 = variable_test_bit((long )index, (unsigned long const volatile   *)(& vf->rxq_mask));
  if (tmp___3 != 0) {
    ((efx_dword_t *)(& inbuf) + (unsigned long )rxqs_count * 4UL)->u32[0] = vf_offset + index;
    rxqs_count = rxqs_count + 1U;
  } else {

  }
  index = index + 1U;
  ldv_56895: ;
  if (index < count) {
    goto ldv_56894;
  } else {

  }
  atomic_set(& vf->rxq_retry_count, 0);
  goto ldv_56928;
  ldv_56927: 
  rc = efx_mcdi_rpc(efx, 39U, (efx_dword_t const   *)(& inbuf), (size_t )(rxqs_count * 4U),
                    (efx_dword_t *)0, 0UL, (size_t *)0UL);
  __ret_warn_on = rc < 0;
  tmp___4 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___4 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c",
                       720);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  __ret = (long )timeout;
  __might_sleep("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c",
                724, 0);
  tmp___7 = efx_vfdi_flush_wake(vf);
  __cond___0 = tmp___7;
  if ((int )__cond___0 && __ret == 0L) {
    __ret = 1L;
  } else {

  }
  if (((int )__cond___0 || __ret == 0L) == 0) {
    __ret___0 = (long )timeout;
    INIT_LIST_HEAD(& __wait.task_list);
    __wait.flags = 0U;
    ldv_56909: 
    tmp___5 = prepare_to_wait_event(& vf->flush_waitq, & __wait, 2);
    __int = tmp___5;
    tmp___6 = efx_vfdi_flush_wake(vf);
    __cond = tmp___6;
    if ((int )__cond && __ret___0 == 0L) {
      __ret___0 = 1L;
    } else {

    }
    if (((int )__cond || __ret___0 == 0L) != 0) {
      goto ldv_56908;
    } else {

    }
    __ret___0 = schedule_timeout(__ret___0);
    goto ldv_56909;
    ldv_56908: 
    finish_wait(& vf->flush_waitq, & __wait);
    __ret = __ret___0;
  } else {

  }
  timeout = (unsigned int )__ret;
  rxqs_count = 0U;
  index = 0U;
  goto ldv_56925;
  ldv_56924: 
  tmp___8 = test_and_clear_bit((long )index, (unsigned long volatile   *)(& vf->rxq_retry_mask));
  if (tmp___8 != 0) {
    atomic_dec(& vf->rxq_retry_count);
    ((efx_dword_t *)(& inbuf) + (unsigned long )rxqs_count * 4UL)->u32[0] = vf_offset + index;
    rxqs_count = rxqs_count + 1U;
  } else {

  }
  index = index + 1U;
  ldv_56925: ;
  if (index < count) {
    goto ldv_56924;
  } else {

  }

  ldv_56928: ;
  if (timeout != 0U && (vf->rxq_count != 0U || vf->txq_count != 0U)) {
    goto ldv_56927;
  } else {

  }
  rtnl_lock();
  siena_finish_flush(efx);
  rtnl_unlock();
  reg.u64[0] = 0ULL;
  reg.u64[1] = 0ULL;
  index = 0U;
  goto ldv_56931;
  ldv_56930: 
  efx_writeo_table(efx, (efx_oword_t const   *)(& reg), 15990784U, vf_offset + index);
  efx_writeo_table(efx, (efx_oword_t const   *)(& reg), 16056320U, vf_offset + index);
  efx_writeo_table(efx, (efx_oword_t const   *)(& reg), 16121856U, vf_offset + index);
  efx_writeo_table(efx, (efx_oword_t const   *)(& reg), 16187392U, vf_offset + index);
  index = index + 1U;
  ldv_56931: ;
  if (index < count) {
    goto ldv_56930;
  } else {

  }
  tmp___9 = efx_vf_size(efx);
  efx_siena_sriov_bufs(efx, vf->buftbl_base, (u64 *)0ULL, tmp___9 * 32U);
  efx_vfdi_flush_clear(vf);
  vf->evq0_count = 0U;
  return (timeout != 0U ? 0 : -110);
}
}
static int efx_vfdi_insert_filter(struct siena_vf *vf ) 
{ 
  struct efx_nic *efx ;
  struct siena_nic_data *nic_data ;
  struct vfdi_req *req ;
  unsigned int vf_rxq ;
  unsigned int flags ;
  int tmp ;
  bool tmp___0 ;

  {
  efx = vf->efx;
  nic_data = (struct siena_nic_data *)efx->nic_data;
  req = (struct vfdi_req *)vf->buf.addr;
  vf_rxq = req->u.mac_filter.rxq;
  tmp___0 = bad_vf_index(efx, vf_rxq);
  if ((int )tmp___0 || (int )vf->rx_filtering) {
    tmp = net_ratelimit();
    if (tmp != 0) {
      if ((efx->msg_enable & 8192U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "OLD_ERROR: Invalid INSERT_FILTER from %s: rxq %d flags 0x%x\n",
                   (char *)(& vf->pci_name), vf_rxq, req->u.mac_filter.flags);
      } else {

      }
    } else {

    }
    return (-22);
  } else {

  }
  flags = 0U;
  if ((int )req->u.mac_filter.flags & 1) {
    flags = flags | 1U;
  } else {

  }
  if ((req->u.mac_filter.flags & 2U) != 0U) {
    flags = flags | 2U;
  } else {

  }
  vf->rx_filter_flags = (enum efx_filter_flags )flags;
  vf->rx_filter_qid = vf_rxq;
  vf->rx_filtering = 1;
  efx_siena_sriov_reset_rx_filter(vf);
  queue_work___1(vfdi_workqueue, & nic_data->peer_work);
  return (0);
}
}
static int efx_vfdi_remove_all_filters(struct siena_vf *vf ) 
{ 
  struct efx_nic *efx ;
  struct siena_nic_data *nic_data ;

  {
  efx = vf->efx;
  nic_data = (struct siena_nic_data *)efx->nic_data;
  vf->rx_filtering = 0;
  efx_siena_sriov_reset_rx_filter(vf);
  queue_work___1(vfdi_workqueue, & nic_data->peer_work);
  return (0);
}
}
static int efx_vfdi_set_status_page(struct siena_vf *vf ) 
{ 
  struct efx_nic *efx ;
  struct siena_nic_data *nic_data ;
  struct vfdi_req *req ;
  u64 page_count___0 ;
  u64 max_page_count ;
  int tmp ;
  void *tmp___0 ;

  {
  efx = vf->efx;
  nic_data = (struct siena_nic_data *)efx->nic_data;
  req = (struct vfdi_req *)vf->buf.addr;
  page_count___0 = req->u.set_status_page.peer_page_count;
  max_page_count = 508ULL;
  if (req->u.set_status_page.dma_addr == 0ULL || page_count___0 > max_page_count) {
    tmp = net_ratelimit();
    if (tmp != 0) {
      if ((efx->msg_enable & 8192U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "OLD_ERROR: Invalid SET_STATUS_PAGE from %s\n",
                   (char *)(& vf->pci_name));
      } else {

      }
    } else {

    }
    return (-22);
  } else {

  }
  ldv_mutex_lock_798(& nic_data->local_lock);
  ldv_mutex_lock_799(& vf->status_lock);
  vf->status_addr = req->u.set_status_page.dma_addr;
  kfree((void const   *)vf->peer_page_addrs);
  vf->peer_page_addrs = (u64 *)0ULL;
  vf->peer_page_count = 0U;
  if (page_count___0 != 0ULL) {
    tmp___0 = kcalloc((size_t )page_count___0, 8UL, 208U);
    vf->peer_page_addrs = (u64 *)tmp___0;
    if ((unsigned long )vf->peer_page_addrs != (unsigned long )((u64 *)0ULL)) {
      memcpy((void *)vf->peer_page_addrs, (void const   *)(& req->u.set_status_page.peer_page_addr),
               (size_t )(page_count___0 * 8ULL));
      vf->peer_page_count = (unsigned int )page_count___0;
    } else {

    }
  } else {

  }
  __efx_siena_sriov_push_vf_status(vf);
  ldv_mutex_unlock_800(& vf->status_lock);
  ldv_mutex_unlock_801(& nic_data->local_lock);
  return (0);
}
}
static int efx_vfdi_clear_status_page(struct siena_vf *vf ) 
{ 


  {
  ldv_mutex_lock_802(& vf->status_lock);
  vf->status_addr = 0ULL;
  ldv_mutex_unlock_803(& vf->status_lock);
  return (0);
}
}
static efx_vfdi_op_t vfdi_ops[9U]  = 
  {      0,      & efx_vfdi_init_evq,      & efx_vfdi_init_rxq,      & efx_vfdi_init_txq, 
        & efx_vfdi_fini_all_queues,      & efx_vfdi_insert_filter,      & efx_vfdi_remove_all_filters,      & efx_vfdi_set_status_page, 
        & efx_vfdi_clear_status_page};
static void efx_siena_sriov_vfdi(struct work_struct *work ) 
{ 
  struct siena_vf *vf ;
  struct work_struct  const  *__mptr ;
  struct efx_nic *efx ;
  struct vfdi_req *req ;
  struct efx_memcpy_req copy[2U] ;
  int rc ;
  int tmp ;
  struct _ddebug descriptor ;
  long tmp___0 ;
  struct _ddebug descriptor___0 ;
  long tmp___1 ;

  {
  __mptr = (struct work_struct  const  *)work;
  vf = (struct siena_vf *)__mptr + 0xffffffffffffffe0UL;
  efx = vf->efx;
  req = (struct vfdi_req *)vf->buf.addr;
  memset((void *)(& copy), 0, 96UL);
  copy[0].from_rid = vf->pci_rid;
  copy[0].from_addr = vf->req_addr;
  copy[0].to_rid = (efx->pci_dev)->devfn;
  copy[0].to_addr = vf->buf.dma_addr;
  copy[0].length = 4096U;
  rc = efx_siena_sriov_memcpy(efx, (struct efx_memcpy_req *)(& copy), 1U);
  if (rc != 0) {
    tmp = net_ratelimit();
    if (tmp != 0) {
      if ((efx->msg_enable & 8192U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "OLD_ERROR: Unable to fetch VFDI request from %s rc %d\n",
                   (char *)(& vf->pci_name), - rc);
      } else {

      }
    } else {

    }
    vf->busy = 0;
    return;
  } else {

  }
  if (req->op <= 8U && (unsigned long )vfdi_ops[req->op] != (unsigned long )((int (*)(struct siena_vf * ))0)) {
    rc = (*(vfdi_ops[req->op]))(vf);
    if (rc == 0) {
      if ((efx->msg_enable & 8192U) != 0U) {
        descriptor.modname = "sfc";
        descriptor.function = "efx_siena_sriov_vfdi";
        descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c";
        descriptor.format = "vfdi request %d from %s ok\n";
        descriptor.lineno = 904U;
        descriptor.flags = 0U;
        tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
        if (tmp___0 != 0L) {
          __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                               "vfdi request %d from %s ok\n", req->op, (char *)(& vf->pci_name));
        } else {

        }
      } else {

      }
    } else {

    }
  } else {
    if ((efx->msg_enable & 8192U) != 0U) {
      descriptor___0.modname = "sfc";
      descriptor___0.function = "efx_siena_sriov_vfdi";
      descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c";
      descriptor___0.format = "OLD_ERROR: Unrecognised request %d from VF %s addr %llx\n";
      descriptor___0.lineno = 910U;
      descriptor___0.flags = 0U;
      tmp___1 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
      if (tmp___1 != 0L) {
        __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                             "OLD_ERROR: Unrecognised request %d from VF %s addr %llx\n",
                             req->op, (char *)(& vf->pci_name), vf->req_addr);
      } else {

      }
    } else {

    }
    rc = -95;
  }
  vf->busy = 0;
  __asm__  volatile   ("": : : "memory");
  req->rc = rc;
  req->op = 0U;
  memset((void *)(& copy), 0, 96UL);
  copy[0].from_buf = (void *)(& req->rc);
  copy[0].to_rid = vf->pci_rid;
  copy[0].to_addr = vf->req_addr + 8ULL;
  copy[0].length = 4U;
  copy[1].from_buf = (void *)(& req->op);
  copy[1].to_rid = vf->pci_rid;
  copy[1].to_addr = vf->req_addr;
  copy[1].length = 4U;
  efx_siena_sriov_memcpy(efx, (struct efx_memcpy_req *)(& copy), 2U);
  return;
}
}
static void efx_siena_sriov_reset_vf(struct siena_vf *vf , struct efx_buffer *buffer ) 
{ 
  struct efx_nic *efx ;
  struct efx_memcpy_req copy_req[4U] ;
  efx_qword_t event ;
  unsigned int pos ;
  unsigned int count ;
  unsigned int k ;
    klee_make_symbolic(&k, sizeof(int), "k");
  unsigned int buftbl ;
  unsigned int abs_evq ;
  efx_oword_t reg ;
  efx_dword_t ptr ;
  int rc ;
  long tmp ;
  long tmp___0 ;
  unsigned int __min1 ;
  unsigned int __min2 ;
  int tmp___1 ;
  unsigned long tmp___2 ;

  {
  efx = vf->efx;
  tmp = ldv__builtin_expect(buffer->len != 4096U, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c"),
                         "i" (953), "i" (12UL));
    ldv_56990: ;
    goto ldv_56990;
  } else {

  }
  if (vf->evq0_count == 0U) {
    return;
  } else {

  }
  tmp___0 = ldv__builtin_expect((vf->evq0_count & (vf->evq0_count - 1U)) != 0U, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c"),
                         "i" (957), "i" (12UL));
    ldv_56991: ;
    goto ldv_56991;
  } else {

  }
  ldv_mutex_lock_804(& vf->status_lock);
  event.u64[0] = ((unsigned long long )vf->msg_seqno << 24) | 0x8000000000050000ULL;
  vf->msg_seqno = vf->msg_seqno + 1U;
  pos = 0U;
  goto ldv_56993;
  ldv_56992: 
  memcpy(buffer->addr + (unsigned long )pos, (void const   *)(& event), 8UL);
  pos = pos + 8U;
  ldv_56993: ;
  if (pos <= 4095U) {
    goto ldv_56992;
  } else {

  }
  pos = 0U;
  goto ldv_57005;
  ldv_57004: 
  __min1 = vf->evq0_count - pos;
  __min2 = 4U;
  count = __min1 < __min2 ? __min1 : __min2;
  k = 0U;
  goto ldv_57001;
  ldv_57000: 
  copy_req[k].from_buf = (void *)0;
  copy_req[k].from_rid = (efx->pci_dev)->devfn;
  copy_req[k].from_addr = buffer->dma_addr;
  copy_req[k].to_rid = vf->pci_rid;
  copy_req[k].to_addr = vf->evq0_addrs[pos + k];
  copy_req[k].length = 4096U;
  k = k + 1U;
  ldv_57001: ;
  if (k < count) {
    goto ldv_57000;
  } else {

  }
  rc = efx_siena_sriov_memcpy(efx, (struct efx_memcpy_req *)(& copy_req), count);
  if (rc != 0) {
    tmp___1 = net_ratelimit();
    if (tmp___1 != 0) {
      if ((efx->msg_enable & 8192U) != 0U) {
        netdev_err((struct net_device  const  *)efx->net_dev, "OLD_ERROR: Unable to notify %s of reset: %d\n",
                   (char *)(& vf->pci_name), - rc);
      } else {

      }
    } else {

    }
    goto ldv_57003;
  } else {

  }
  pos = pos + count;
  ldv_57005: ;
  if (vf->evq0_count > pos) {
    goto ldv_57004;
  } else {

  }
  ldv_57003: 
  abs_evq = abs_index(vf, 0U);
  buftbl = vf->buftbl_base + 16U;
  efx_siena_sriov_bufs(efx, buftbl, (u64 *)(& vf->evq0_addrs), vf->evq0_count);
  reg.u64[0] = 8589934592ULL;
  reg.u64[1] = 0ULL;
  efx_writeo_table(efx, (efx_oword_t const   *)(& reg), 16187392U, abs_evq);
  tmp___2 = __ffs((unsigned long )vf->evq0_count);
  reg.u64[0] = (((unsigned long long )tmp___2 << 20) | (unsigned long long )buftbl) | 8388608ULL;
  reg.u64[1] = 0ULL;
  efx_writeo_table(efx, (efx_oword_t const   *)(& reg), 16121856U, abs_evq);
  ptr.u32[0] = 0U;
  efx_writed(efx, (efx_dword_t const   *)(& ptr), (abs_evq + 1024000U) * 16U);
  ldv_mutex_unlock_805(& vf->status_lock);
  return;
}
}
static void efx_siena_sriov_reset_vf_work(struct work_struct *work ) 
{ 
  struct siena_vf *vf ;
  struct work_struct  const  *__mptr ;
  struct efx_nic *efx ;
  struct efx_buffer buf ;
  int tmp ;

  {
  __mptr = (struct work_struct  const  *)work;
  vf = (struct siena_vf *)__mptr + 0xffffffffffffffe0UL;
  efx = vf->efx;
  tmp = efx_nic_alloc_buffer(efx, & buf, 4096U, 16U);
  if (tmp == 0) {
    efx_siena_sriov_reset_vf(vf, & buf);
    efx_nic_free_buffer(efx, & buf);
  } else {

  }
  return;
}
}
static void efx_siena_sriov_handle_no_channel(struct efx_nic *efx ) 
{ 


  {
  if ((int )efx->msg_enable & 1) {
    netdev_err((struct net_device  const  *)efx->net_dev, "OLD_ERROR: IOV requires MSI-X and 1 additional interruptvector. IOV disabled\n");
  } else {

  }
  efx->vf_count = 0U;
  return;
}
}
static int efx_siena_sriov_probe_channel(struct efx_channel *channel ) 
{ 
  struct siena_nic_data *nic_data ;

  {
  nic_data = (struct siena_nic_data *)(channel->efx)->nic_data;
  nic_data->vfdi_channel = channel;
  return (0);
}
}
static void efx_siena_sriov_get_channel_name(struct efx_channel *channel , char *buf ,
                                             size_t len ) 
{ 


  {
  snprintf(buf, len, "%s-iov", (char *)(& (channel->efx)->name));
  return;
}
}
static struct efx_channel_type  const  efx_siena_sriov_channel_type  =    {& efx_siena_sriov_handle_no_channel, & efx_siena_sriov_probe_channel, & efx_channel_dummy_op_void,
    & efx_siena_sriov_get_channel_name, 0, 0, 1};
void efx_siena_sriov_probe(struct efx_nic *efx ) 
{ 
  unsigned int count ;
  int tmp ;

  {
  if (max_vfs == 0) {
    return;
  } else {

  }
  tmp = efx_siena_sriov_cmd(efx, 0, & efx->vi_scale, & count);
  if (tmp != 0) {
    if ((efx->msg_enable & 2U) != 0U) {
      netdev_info((struct net_device  const  *)efx->net_dev, "no SR-IOV VFs probed\n");
    } else {

    }
    return;
  } else {

  }
  if (count != 0U && (unsigned int )max_vfs < count) {
    count = (unsigned int )max_vfs;
  } else {

  }
  efx->vf_count = count;
  efx->extra_channel_type[0] = & efx_siena_sriov_channel_type;
  return;
}
}
static void efx_siena_sriov_peer_work(struct work_struct *data ) 
{ 
  struct siena_nic_data *nic_data ;
  struct work_struct  const  *__mptr ;
  struct efx_nic *efx ;
  struct vfdi_status *vfdi_status ;
  struct siena_vf *vf ;
  struct efx_local_addr *local_addr ;
  struct vfdi_endpoint *peer ;
  struct efx_endpoint_page *epp ;
  struct list_head pages ;
  unsigned int peer_space ;
    klee_make_symbolic(&peer_space, sizeof(int), "peer_space");
  unsigned int peer_count ;
    klee_make_symbolic(&peer_count, sizeof(int), "peer_count");
  unsigned int pos ;
  struct vfdi_endpoint *tmp ;
  long tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  struct list_head  const  *__mptr___0 ;
  void *tmp___3 ;
  struct list_head  const  *__mptr___1 ;
  int tmp___4 ;
  struct list_head  const  *__mptr___2 ;
  struct list_head  const  *__mptr___3 ;
  int tmp___5 ;

  {
  __mptr = (struct work_struct  const  *)data;
  nic_data = (struct siena_nic_data *)__mptr + 0xfffffffffffffd28UL;
  efx = nic_data->efx;
  vfdi_status = (struct vfdi_status *)nic_data->vfdi_status.addr;
  ldv_mutex_lock_806(& nic_data->local_lock);
  INIT_LIST_HEAD(& pages);
  list_splice_tail_init(& nic_data->local_page_list, & pages);
  peer = (struct vfdi_endpoint *)(& vfdi_status->peers) + 1UL;
  peer_space = 255U;
  peer_count = 1U;
  pos = 0U;
  goto ldv_57051;
  ldv_57050: 
  vf = nic_data->vf + (unsigned long )pos;
  ldv_mutex_lock_807(& vf->status_lock);
  if ((int )vf->rx_filtering) {
    tmp___1 = is_zero_ether_addr((u8 const   *)(& vf->addr.mac_addr));
    if (tmp___1) {
      tmp___2 = 0;
    } else {
      tmp___2 = 1;
    }
    if (tmp___2) {
      tmp = peer;
      peer = peer + 1;
      *tmp = vf->addr;
      peer_count = peer_count + 1U;
      peer_space = peer_space - 1U;
      tmp___0 = ldv__builtin_expect(peer_space == 0U, 0L);
      if (tmp___0 != 0L) {
        __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c"),
                             "i" (1114), "i" (12UL));
        ldv_57049: ;
        goto ldv_57049;
      } else {

      }
    } else {

    }
  } else {

  }
  ldv_mutex_unlock_808(& vf->status_lock);
  pos = pos + 1U;
  ldv_57051: ;
  if (efx->vf_count > pos) {
    goto ldv_57050;
  } else {

  }
  __mptr___0 = (struct list_head  const  *)nic_data->local_addr_list.next;
  local_addr = (struct efx_local_addr *)__mptr___0;
  goto ldv_57061;
  ldv_57060: 
  ether_addr_copy((u8 *)(& peer->mac_addr), (u8 const   *)(& local_addr->addr));
  peer->tci = 0U;
  peer = peer + 1;
  peer_count = peer_count + 1U;
  peer_space = peer_space - 1U;
  if (peer_space == 0U) {
    tmp___4 = list_empty((struct list_head  const  *)(& pages));
    if (tmp___4 != 0) {
      tmp___3 = kmalloc(32UL, 208U);
      epp = (struct efx_endpoint_page *)tmp___3;
      if ((unsigned long )epp == (unsigned long )((struct efx_endpoint_page *)0)) {
        goto ldv_57057;
      } else {

      }
      epp->ptr = dma_alloc_attrs(& (efx->pci_dev)->dev, 4096UL, & epp->addr, 208U,
                                 (struct dma_attrs *)0);
      if ((unsigned long )epp->ptr == (unsigned long )((void *)0)) {
        kfree((void const   *)epp);
        goto ldv_57057;
      } else {

      }
    } else {
      __mptr___1 = (struct list_head  const  *)pages.next;
      epp = (struct efx_endpoint_page *)__mptr___1;
      list_del(& epp->link);
    }
    list_add_tail(& epp->link, & nic_data->local_page_list);
    peer = (struct vfdi_endpoint *)epp->ptr;
    peer_space = 512U;
  } else {

  }
  __mptr___2 = (struct list_head  const  *)local_addr->link.next;
  local_addr = (struct efx_local_addr *)__mptr___2;
  ldv_57061: ;
  if ((unsigned long )(& local_addr->link) != (unsigned long )(& nic_data->local_addr_list)) {
    goto ldv_57060;
  } else {

  }
  ldv_57057: 
  vfdi_status->peer_count = (u16 )peer_count;
  ldv_mutex_unlock_809(& nic_data->local_lock);
  goto ldv_57065;
  ldv_57064: 
  __mptr___3 = (struct list_head  const  *)pages.next;
  epp = (struct efx_endpoint_page *)__mptr___3;
  list_del(& epp->link);
  dma_free_attrs(& (efx->pci_dev)->dev, 4096UL, epp->ptr, epp->addr, (struct dma_attrs *)0);
  kfree((void const   *)epp);
  ldv_57065: 
  tmp___5 = list_empty((struct list_head  const  *)(& pages));
  if (tmp___5 == 0) {
    goto ldv_57064;
  } else {

  }
  pos = 0U;
  goto ldv_57068;
  ldv_57067: 
  vf = nic_data->vf + (unsigned long )pos;
  ldv_mutex_lock_810(& vf->status_lock);
  if (vf->status_addr != 0ULL) {
    __efx_siena_sriov_push_vf_status(vf);
  } else {

  }
  ldv_mutex_unlock_811(& vf->status_lock);
  pos = pos + 1U;
  ldv_57068: ;
  if (efx->vf_count > pos) {
    goto ldv_57067;
  } else {

  }

  return;
}
}
static void efx_siena_sriov_free_local(struct efx_nic *efx ) 
{ 
  struct siena_nic_data *nic_data ;
  struct efx_local_addr *local_addr ;
  struct efx_endpoint_page *epp ;
  struct list_head  const  *__mptr ;
  int tmp ;
  struct list_head  const  *__mptr___0 ;
  int tmp___0 ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  goto ldv_57079;
  ldv_57078: 
  __mptr = (struct list_head  const  *)nic_data->local_addr_list.next;
  local_addr = (struct efx_local_addr *)__mptr;
  list_del(& local_addr->link);
  kfree((void const   *)local_addr);
  ldv_57079: 
  tmp = list_empty((struct list_head  const  *)(& nic_data->local_addr_list));
  if (tmp == 0) {
    goto ldv_57078;
  } else {

  }

  goto ldv_57084;
  ldv_57083: 
  __mptr___0 = (struct list_head  const  *)nic_data->local_page_list.next;
  epp = (struct efx_endpoint_page *)__mptr___0;
  list_del(& epp->link);
  dma_free_attrs(& (efx->pci_dev)->dev, 4096UL, epp->ptr, epp->addr, (struct dma_attrs *)0);
  kfree((void const   *)epp);
  ldv_57084: 
  tmp___0 = list_empty((struct list_head  const  *)(& nic_data->local_page_list));
  if (tmp___0 == 0) {
    goto ldv_57083;
  } else {

  }

  return;
}
}
static int efx_siena_sriov_vf_alloc(struct efx_nic *efx ) 
{ 
  unsigned int index ;
  struct siena_vf *vf ;
  struct siena_nic_data *nic_data ;
  void *tmp ;
  struct lock_class_key __key ;
  atomic_long_t __constr_expr_0 ;
  struct lock_class_key __key___0 ;
  atomic_long_t __constr_expr_1 ;
  struct lock_class_key __key___1 ;
  struct lock_class_key __key___2 ;
  struct lock_class_key __key___3 ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  tmp = kcalloc((size_t )efx->vf_count, 896UL, 208U);
  nic_data->vf = (struct siena_vf *)tmp;
  if ((unsigned long )nic_data->vf == (unsigned long )((struct siena_vf *)0)) {
    return (-12);
  } else {

  }
  index = 0U;
  goto ldv_57100;
  ldv_57099: 
  vf = nic_data->vf + (unsigned long )index;
  vf->efx = efx;
  vf->index = index;
  vf->rx_filter_id = -1;
  vf->tx_filter_mode = 1;
  vf->tx_filter_id = -1;
  __init_work(& vf->req, 0);
  __constr_expr_0.counter = 137438953408L;
  vf->req.data = __constr_expr_0;
  lockdep_init_map(& vf->req.lockdep_map, "(&vf->req)", & __key, 0);
  INIT_LIST_HEAD(& vf->req.entry);
  vf->req.func = & efx_siena_sriov_vfdi;
  __init_work(& vf->reset_work, 0);
  __constr_expr_1.counter = 137438953408L;
  vf->reset_work.data = __constr_expr_1;
  lockdep_init_map(& vf->reset_work.lockdep_map, "(&vf->reset_work)", & __key___0,
                   0);
  INIT_LIST_HEAD(& vf->reset_work.entry);
  vf->reset_work.func = & efx_siena_sriov_reset_vf_work;
  __init_waitqueue_head(& vf->flush_waitq, "&vf->flush_waitq", & __key___1);
  __mutex_init(& vf->status_lock, "&vf->status_lock", & __key___2);
  __mutex_init(& vf->txq_lock, "&vf->txq_lock", & __key___3);
  index = index + 1U;
  ldv_57100: ;
  if (efx->vf_count > index) {
    goto ldv_57099;
  } else {

  }

  return (0);
}
}
static void efx_siena_sriov_vfs_fini(struct efx_nic *efx ) 
{ 
  struct siena_nic_data *nic_data ;
  struct siena_vf *vf ;
  unsigned int pos ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  pos = 0U;
  goto ldv_57109;
  ldv_57108: 
  vf = nic_data->vf + (unsigned long )pos;
  efx_nic_free_buffer(efx, & vf->buf);
  kfree((void const   *)vf->peer_page_addrs);
  vf->peer_page_addrs = (u64 *)0ULL;
  vf->peer_page_count = 0U;
  vf->evq0_count = 0U;
  pos = pos + 1U;
  ldv_57109: ;
  if (efx->vf_count > pos) {
    goto ldv_57108;
  } else {

  }

  return;
}
}
static int efx_siena_sriov_vfs_init(struct efx_nic *efx ) 
{ 
  struct pci_dev *pci_dev ;
  struct siena_nic_data *nic_data ;
  unsigned int index ;
  unsigned int devfn ;
  unsigned int sriov ;
    klee_make_symbolic(&sriov, sizeof(int), "sriov");
  unsigned int buftbl_base ;
  u16 offset ;
  u16 stride ;
  struct siena_vf *vf ;
  int rc ;
  int tmp ;
  unsigned int tmp___0 ;
  int tmp___1 ;

  {
  pci_dev = efx->pci_dev;
  nic_data = (struct siena_nic_data *)efx->nic_data;
  tmp = pci_find_ext_capability(pci_dev, 16);
  sriov = (unsigned int )tmp;
  if (sriov == 0U) {
    return (-2);
  } else {

  }
  pci_read_config_word((struct pci_dev  const  *)pci_dev, (int )(sriov + 20U), & offset);
  pci_read_config_word((struct pci_dev  const  *)pci_dev, (int )(sriov + 22U), & stride);
  buftbl_base = nic_data->vf_buftbl_base;
  devfn = pci_dev->devfn + (unsigned int )offset;
  index = 0U;
  goto ldv_57126;
  ldv_57125: 
  vf = nic_data->vf + (unsigned long )index;
  vf->buftbl_base = buftbl_base;
  tmp___0 = efx_vf_size(efx);
  buftbl_base = tmp___0 * 32U + buftbl_base;
  vf->pci_rid = devfn;
  tmp___1 = pci_domain_nr(pci_dev->bus);
  snprintf((char *)(& vf->pci_name), 13UL, "%04x:%02x:%02x.%d", tmp___1, (int )(pci_dev->bus)->number,
           (devfn >> 3) & 31U, devfn & 7U);
  rc = efx_nic_alloc_buffer(efx, & vf->buf, 4096U, 208U);
  if (rc != 0) {
    goto fail;
  } else {

  }
  devfn = (unsigned int )stride + devfn;
  index = index + 1U;
  ldv_57126: ;
  if (efx->vf_count > index) {
    goto ldv_57125;
  } else {

  }

  return (0);
  fail: 
  efx_siena_sriov_vfs_fini(efx);
  return (rc);
}
}
int efx_siena_sriov_init(struct efx_nic *efx ) 
{ 
  struct net_device *net_dev ;
  struct siena_nic_data *nic_data ;
  struct vfdi_status *vfdi_status ;
  int rc ;
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  atomic_long_t __constr_expr_0 ;
  unsigned int tmp ;

  {
  net_dev = efx->net_dev;
  nic_data = (struct siena_nic_data *)efx->nic_data;
  if (efx->vf_count == 0U) {
    return (0);
  } else {

  }
  rc = efx_siena_sriov_cmd(efx, 1, (unsigned int *)0U, (unsigned int *)0U);
  if (rc != 0) {
    goto fail_cmd;
  } else {

  }
  rc = efx_nic_alloc_buffer(efx, & nic_data->vfdi_status, 2084U, 208U);
  if (rc != 0) {
    goto fail_status;
  } else {

  }
  vfdi_status = (struct vfdi_status *)nic_data->vfdi_status.addr;
  memset((void *)vfdi_status, 0, 2084UL);
  vfdi_status->version = 1U;
  vfdi_status->length = 2084U;
  vfdi_status->max_tx_channels = (u8 )vf_max_tx_channels;
  vfdi_status->vi_scale = (u8 )efx->vi_scale;
  vfdi_status->rss_rxq_count = (u8 )efx->rss_spread;
  vfdi_status->peer_count = (unsigned int )((u16 )efx->vf_count) + 1U;
  vfdi_status->timer_quantum_ns = efx->timer_quantum_ns;
  rc = efx_siena_sriov_vf_alloc(efx);
  if (rc != 0) {
    goto fail_alloc;
  } else {

  }
  __mutex_init(& nic_data->local_lock, "&nic_data->local_lock", & __key);
  __init_work(& nic_data->peer_work, 0);
  __constr_expr_0.counter = 137438953408L;
  nic_data->peer_work.data = __constr_expr_0;
  lockdep_init_map(& nic_data->peer_work.lockdep_map, "(&nic_data->peer_work)", & __key___0,
                   0);
  INIT_LIST_HEAD(& nic_data->peer_work.entry);
  nic_data->peer_work.func = & efx_siena_sriov_peer_work;
  INIT_LIST_HEAD(& nic_data->local_addr_list);
  INIT_LIST_HEAD(& nic_data->local_page_list);
  rc = efx_siena_sriov_vfs_init(efx);
  if (rc != 0) {
    goto fail_vfs;
  } else {

  }
  rtnl_lock();
  ether_addr_copy((u8 *)(& vfdi_status->peers[0].mac_addr), (u8 const   *)net_dev->dev_addr);
  efx->vf_init_count = efx->vf_count;
  rtnl_unlock();
  efx_siena_sriov_usrev(efx, 1);
  rc = pci_enable_sriov(efx->pci_dev, (int )efx->vf_count);
  if (rc != 0) {
    goto fail_pci;
  } else {

  }
  if ((efx->msg_enable & 2U) != 0U) {
    tmp = efx_vf_size(efx);
    netdev_info((struct net_device  const  *)net_dev, "enabled SR-IOV for %d VFs, %d VI per VF\n",
                efx->vf_count, tmp);
  } else {

  }
  return (0);
  fail_pci: 
  efx_siena_sriov_usrev(efx, 0);
  rtnl_lock();
  efx->vf_init_count = 0U;
  rtnl_unlock();
  efx_siena_sriov_vfs_fini(efx);
  fail_vfs: 
  ldv_cancel_work_sync_812(& nic_data->peer_work);
  efx_siena_sriov_free_local(efx);
  kfree((void const   *)nic_data->vf);
  fail_alloc: 
  efx_nic_free_buffer(efx, & nic_data->vfdi_status);
  fail_status: 
  efx_siena_sriov_cmd(efx, 0, (unsigned int *)0U, (unsigned int *)0U);
  fail_cmd: ;
  return (rc);
}
}
void efx_siena_sriov_fini(struct efx_nic *efx ) 
{ 
  struct siena_vf *vf ;
  unsigned int pos ;
  struct siena_nic_data *nic_data ;
  long tmp ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  if (efx->vf_init_count == 0U) {
    return;
  } else {

  }
  tmp = ldv__builtin_expect((long )(nic_data->vfdi_channel)->enabled, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c"),
                         "i" (1380), "i" (12UL));
    ldv_57149: ;
    goto ldv_57149;
  } else {

  }
  efx_siena_sriov_usrev(efx, 0);
  rtnl_lock();
  efx->vf_init_count = 0U;
  rtnl_unlock();
  pos = 0U;
  goto ldv_57151;
  ldv_57150: 
  vf = nic_data->vf + (unsigned long )pos;
  ldv_cancel_work_sync_813(& vf->req);
  ldv_cancel_work_sync_814(& vf->reset_work);
  pos = pos + 1U;
  ldv_57151: ;
  if (efx->vf_count > pos) {
    goto ldv_57150;
  } else {

  }
  ldv_cancel_work_sync_815(& nic_data->peer_work);
  pci_disable_sriov(efx->pci_dev);
  efx_siena_sriov_vfs_fini(efx);
  efx_siena_sriov_free_local(efx);
  kfree((void const   *)nic_data->vf);
  efx_nic_free_buffer(efx, & nic_data->vfdi_status);
  efx_siena_sriov_cmd(efx, 0, (unsigned int *)0U, (unsigned int *)0U);
  return;
}
}
void efx_siena_sriov_event(struct efx_channel *channel , efx_qword_t *event ) 
{ 
  struct efx_nic *efx ;
  struct siena_vf *vf ;
  unsigned int qid ;
  unsigned int seq ;
  unsigned int type ;
  unsigned int data ;
  bool tmp ;
  unsigned int tmp___0 ;
  int tmp___1 ;

  {
  efx = channel->efx;
  qid = (unsigned int )(event->u64[0] >> 32) & 1023U;
  seq = (unsigned int )(event->u64[0] >> 24) & 255U;
  type = (unsigned int )(event->u64[0] >> 16) & 255U;
  data = (unsigned int )event->u64[0] & 65535U;
  tmp = map_vi_index(efx, qid, & vf, (unsigned int *)0U);
  if ((int )tmp) {
    return;
  } else {

  }
  if ((int )vf->busy) {
    goto error;
  } else {

  }
  if (type == 0U) {
    vf->req_type = 0;
    vf->req_seqno = seq + 1U;
    vf->req_addr = 0ULL;
  } else {
    tmp___0 = vf->req_seqno;
    vf->req_seqno = vf->req_seqno + 1U;
    if ((tmp___0 & 255U) != seq || (unsigned int )vf->req_type != type) {
      goto error;
    } else {

    }
  }
  switch (vf->req_type) {
  case 0: ;
  case 1: ;
  case 2: 
  vf->req_addr = vf->req_addr | ((unsigned long long )data << (vf->req_type << 4));
  vf->req_type = vf->req_type + 1;
  return;
  case 3: 
  vf->req_addr = vf->req_addr | ((unsigned long long )data << 48);
  vf->req_type = 0;
  vf->busy = 1;
  queue_work___1(vfdi_workqueue, & vf->req);
  return;
  }
  error: 
  tmp___1 = net_ratelimit();
  if (tmp___1 != 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "OLD_ERROR: Screaming VFDI request from %s\n",
                 (char *)(& vf->pci_name));
    } else {

    }
  } else {

  }
  vf->req_type = 0;
  vf->req_seqno = seq + 1U;
  return;
}
}
void efx_siena_sriov_flr(struct efx_nic *efx , unsigned int vf_i ) 
{ 
  struct siena_nic_data *nic_data ;
  struct siena_vf *vf ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  if (efx->vf_init_count < vf_i) {
    return;
  } else {

  }
  vf = nic_data->vf + (unsigned long )vf_i;
  if ((efx->msg_enable & 8192U) != 0U) {
    netdev_info((struct net_device  const  *)efx->net_dev, "FLR on VF %s\n", (char *)(& vf->pci_name));
  } else {

  }
  vf->status_addr = 0ULL;
  efx_vfdi_remove_all_filters(vf);
  efx_vfdi_flush_clear(vf);
  vf->evq0_count = 0U;
  return;
}
}
int efx_siena_sriov_mac_address_changed(struct efx_nic *efx ) 
{ 
  struct siena_nic_data *nic_data ;
  struct vfdi_status *vfdi_status ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  vfdi_status = (struct vfdi_status *)nic_data->vfdi_status.addr;
  if (efx->vf_init_count == 0U) {
    return (0);
  } else {

  }
  ether_addr_copy((u8 *)(& vfdi_status->peers[0].mac_addr), (u8 const   *)(efx->net_dev)->dev_addr);
  queue_work___1(vfdi_workqueue, & nic_data->peer_work);
  return (0);
}
}
void efx_siena_sriov_tx_flush_done(struct efx_nic *efx , efx_qword_t *event ) 
{ 
  struct siena_vf *vf ;
  unsigned int queue ;
  unsigned int qid ;
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;

  {
  queue = (unsigned int )event->u64[0] & 16383U;
  tmp = map_vi_index(efx, queue, & vf, & qid);
  if ((int )tmp) {
    return;
  } else {

  }
  tmp___0 = variable_test_bit((long )qid, (unsigned long const volatile   *)(& vf->txq_mask));
  if (tmp___0 == 0) {
    return;
  } else {

  }
  __clear_bit((long )qid, (unsigned long volatile   *)(& vf->txq_mask));
  vf->txq_count = vf->txq_count - 1U;
  tmp___1 = efx_vfdi_flush_wake(vf);
  if ((int )tmp___1) {
    __wake_up(& vf->flush_waitq, 3U, 1, (void *)0);
  } else {

  }
  return;
}
}
void efx_siena_sriov_rx_flush_done(struct efx_nic *efx , efx_qword_t *event ) 
{ 
  struct siena_vf *vf ;
  unsigned int ev_failed ;
    klee_make_symbolic(&ev_failed, sizeof(int), "ev_failed");
  unsigned int queue ;
  unsigned int qid ;
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;

  {
  queue = (unsigned int )event->u64[0] & 4095U;
  ev_failed = (unsigned int )(event->u64[0] >> 12) & 1U;
  tmp = map_vi_index(efx, queue, & vf, & qid);
  if ((int )tmp) {
    return;
  } else {

  }
  tmp___0 = variable_test_bit((long )qid, (unsigned long const volatile   *)(& vf->rxq_mask));
  if (tmp___0 == 0) {
    return;
  } else {

  }
  if (ev_failed != 0U) {
    set_bit((long )qid, (unsigned long volatile   *)(& vf->rxq_retry_mask));
    atomic_inc(& vf->rxq_retry_count);
  } else {
    __clear_bit((long )qid, (unsigned long volatile   *)(& vf->rxq_mask));
    vf->rxq_count = vf->rxq_count - 1U;
  }
  tmp___1 = efx_vfdi_flush_wake(vf);
  if ((int )tmp___1) {
    __wake_up(& vf->flush_waitq, 3U, 1, (void *)0);
  } else {

  }
  return;
}
}
void efx_siena_sriov_desc_fetch_err(struct efx_nic *efx , unsigned int dmaq ) 
{ 
  struct siena_vf *vf ;
  unsigned int rel ;
    klee_make_symbolic(&rel, sizeof(int), "rel");
  bool tmp ;
  int tmp___0 ;

  {
  tmp = map_vi_index(efx, dmaq, & vf, & rel);
  if ((int )tmp) {
    return;
  } else {

  }
  tmp___0 = net_ratelimit();
  if (tmp___0 != 0) {
    if ((efx->msg_enable & 8192U) != 0U) {
      netdev_err((struct net_device  const  *)efx->net_dev, "VF %d DMA Q %d reports descriptor fetch error.\n",
                 vf->index, rel);
    } else {

    }
  } else {

  }
  queue_work___1(vfdi_workqueue, & vf->reset_work);
  return;
}
}
void efx_siena_sriov_reset(struct efx_nic *efx ) 
{ 
  struct siena_nic_data *nic_data ;
  unsigned int vf_i ;
  struct efx_buffer buf ;
  struct siena_vf *vf ;
  int tmp ;
  long tmp___0 ;
  int tmp___1 ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  tmp = rtnl_is_locked();
  tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
  if (tmp___0 != 0L) {
    printk("\vRTNL: assertion failed at %s (%d)\n", (char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/siena_sriov.c",
           1560);
    dump_stack();
  } else {

  }
  if (efx->vf_init_count == 0U) {
    return;
  } else {

  }
  efx_siena_sriov_usrev(efx, 1);
  efx_siena_sriov_cmd(efx, 1, (unsigned int *)0U, (unsigned int *)0U);
  tmp___1 = efx_nic_alloc_buffer(efx, & buf, 4096U, 16U);
  if (tmp___1 != 0) {
    return;
  } else {

  }
  vf_i = 0U;
  goto ldv_57209;
  ldv_57208: 
  vf = nic_data->vf + (unsigned long )vf_i;
  efx_siena_sriov_reset_vf(vf, & buf);
  vf_i = vf_i + 1U;
  ldv_57209: ;
  if (efx->vf_init_count > vf_i) {
    goto ldv_57208;
  } else {

  }
  efx_nic_free_buffer(efx, & buf);
  return;
}
}
int efx_init_sriov(void) 
{ 
  struct lock_class_key __key ;
  char const   *__lock_name ;
  struct workqueue_struct *tmp ;

  {
  __lock_name = "\"%s\"\"sfc_vfdi\"";
  tmp = __alloc_workqueue_key("%s", 131082U, 1, & __key, __lock_name, (char *)"sfc_vfdi");
  vfdi_workqueue = tmp;
  if ((unsigned long )vfdi_workqueue == (unsigned long )((struct workqueue_struct *)0)) {
    return (-12);
  } else {

  }
  return (0);
}
}
void efx_fini_sriov(void) 
{ 


  {
  ldv_destroy_workqueue_816(vfdi_workqueue);
  return;
}
}
int efx_siena_sriov_set_vf_mac(struct efx_nic *efx , int vf_i , u8 *mac ) 
{ 
  struct siena_nic_data *nic_data ;
  struct siena_vf *vf ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  if ((unsigned int )vf_i >= efx->vf_init_count) {
    return (-22);
  } else {

  }
  vf = nic_data->vf + (unsigned long )vf_i;
  ldv_mutex_lock_817(& vf->status_lock);
  ether_addr_copy((u8 *)(& vf->addr.mac_addr), (u8 const   *)mac);
  __efx_siena_sriov_update_vf_addr(vf);
  ldv_mutex_unlock_818(& vf->status_lock);
  return (0);
}
}
int efx_siena_sriov_set_vf_vlan(struct efx_nic *efx , int vf_i , u16 vlan , u8 qos ) 
{ 
  struct siena_nic_data *nic_data ;
  struct siena_vf *vf ;
  u16 tci ;
  __u16 tmp ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  if ((unsigned int )vf_i >= efx->vf_init_count) {
    return (-22);
  } else {

  }
  vf = nic_data->vf + (unsigned long )vf_i;
  ldv_mutex_lock_819(& vf->status_lock);
  tci = (u16 )(((int )((short )vlan) & 4095) | (int )((short )((int )qos << 13)));
  tmp = __fswab16((int )tci);
  vf->addr.tci = tmp;
  __efx_siena_sriov_update_vf_addr(vf);
  ldv_mutex_unlock_820(& vf->status_lock);
  return (0);
}
}
int efx_siena_sriov_set_vf_spoofchk(struct efx_nic *efx , int vf_i , bool spoofchk ) 
{ 
  struct siena_nic_data *nic_data ;
  struct siena_vf *vf ;
  int rc ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  if ((unsigned int )vf_i >= efx->vf_init_count) {
    return (-22);
  } else {

  }
  vf = nic_data->vf + (unsigned long )vf_i;
  ldv_mutex_lock_821(& vf->txq_lock);
  if (vf->txq_count == 0U) {
    vf->tx_filter_mode = (int )spoofchk ? 2 : 0;
    rc = 0;
  } else {
    rc = -16;
  }
  ldv_mutex_unlock_822(& vf->txq_lock);
  return (rc);
}
}
int efx_siena_sriov_get_vf_config(struct efx_nic *efx , int vf_i , struct ifla_vf_info *ivi ) 
{ 
  struct siena_nic_data *nic_data ;
  struct siena_vf *vf ;
  u16 tci ;
  __u16 tmp ;

  {
  nic_data = (struct siena_nic_data *)efx->nic_data;
  if ((unsigned int )vf_i >= efx->vf_init_count) {
    return (-22);
  } else {

  }
  vf = nic_data->vf + (unsigned long )vf_i;
  ivi->vf = (__u32 )vf_i;
  ether_addr_copy((u8 *)(& ivi->mac), (u8 const   *)(& vf->addr.mac_addr));
  ivi->max_tx_rate = 0U;
  ivi->min_tx_rate = 0U;
  tmp = __fswab16((int )vf->addr.tci);
  tci = tmp;
  ivi->vlan = (__u32 )tci & 4095U;
  ivi->qos = (__u32 )((int )tci >> 13) & 7U;
  ivi->spoofchk = (unsigned int )vf->tx_filter_mode == 2U;
  return (0);
}
}
bool efx_siena_sriov_wanted(struct efx_nic *efx ) 
{ 


  {
  return (efx->vf_count != 0U);
}
}
int efx_siena_sriov_configure(struct efx_nic *efx , int num_vfs ) 
{ 


  {
  return (0);
}
}
void work_init_9(void) 
{ 


  {
  ldv_work_9_0 = 0;
  ldv_work_9_1 = 0;
  ldv_work_9_2 = 0;
  ldv_work_9_3 = 0;
  return;
}
}
void invoke_work_8(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_work_8_0 == 2 || ldv_work_8_0 == 3) {
    ldv_work_8_0 = 4;
    efx_siena_sriov_reset_vf_work(ldv_work_struct_8_0);
    ldv_work_8_0 = 1;
  } else {

  }
  goto ldv_57268;
  case 1: ;
  if (ldv_work_8_1 == 2 || ldv_work_8_1 == 3) {
    ldv_work_8_1 = 4;
    efx_siena_sriov_reset_vf_work(ldv_work_struct_8_0);
    ldv_work_8_1 = 1;
  } else {

  }
  goto ldv_57268;
  case 2: ;
  if (ldv_work_8_2 == 2 || ldv_work_8_2 == 3) {
    ldv_work_8_2 = 4;
    efx_siena_sriov_reset_vf_work(ldv_work_struct_8_0);
    ldv_work_8_2 = 1;
  } else {

  }
  goto ldv_57268;
  case 3: ;
  if (ldv_work_8_3 == 2 || ldv_work_8_3 == 3) {
    ldv_work_8_3 = 4;
    efx_siena_sriov_reset_vf_work(ldv_work_struct_8_0);
    ldv_work_8_3 = 1;
  } else {

  }
  goto ldv_57268;
  default: 
  ldv_stop();
  }
  ldv_57268: ;
  return;
}
}
void ldv_initialize_efx_channel_type_14(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(2176UL);
  efx_siena_sriov_channel_type_group0 = (struct efx_channel *)tmp;
  return;
}
}
void disable_work_7(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_7_0 == 3 || ldv_work_7_0 == 2) && (unsigned long )ldv_work_struct_7_0 == (unsigned long )work) {
    ldv_work_7_0 = 1;
  } else {

  }
  if ((ldv_work_7_1 == 3 || ldv_work_7_1 == 2) && (unsigned long )ldv_work_struct_7_1 == (unsigned long )work) {
    ldv_work_7_1 = 1;
  } else {

  }
  if ((ldv_work_7_2 == 3 || ldv_work_7_2 == 2) && (unsigned long )ldv_work_struct_7_2 == (unsigned long )work) {
    ldv_work_7_2 = 1;
  } else {

  }
  if ((ldv_work_7_3 == 3 || ldv_work_7_3 == 2) && (unsigned long )ldv_work_struct_7_3 == (unsigned long )work) {
    ldv_work_7_3 = 1;
  } else {

  }
  return;
}
}
void call_and_disable_work_7(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_7_0 == 2 || ldv_work_7_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_7_0) {
    efx_siena_sriov_vfdi(work);
    ldv_work_7_0 = 1;
    return;
  } else {

  }
  if ((ldv_work_7_1 == 2 || ldv_work_7_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_7_1) {
    efx_siena_sriov_vfdi(work);
    ldv_work_7_1 = 1;
    return;
  } else {

  }
  if ((ldv_work_7_2 == 2 || ldv_work_7_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_7_2) {
    efx_siena_sriov_vfdi(work);
    ldv_work_7_2 = 1;
    return;
  } else {

  }
  if ((ldv_work_7_3 == 2 || ldv_work_7_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_7_3) {
    efx_siena_sriov_vfdi(work);
    ldv_work_7_3 = 1;
    return;
  } else {

  }
  return;
}
}
void work_init_8(void) 
{ 


  {
  ldv_work_8_0 = 0;
  ldv_work_8_1 = 0;
  ldv_work_8_2 = 0;
  ldv_work_8_3 = 0;
  return;
}
}
void call_and_disable_all_9(int state ) 
{ 


  {
  if (ldv_work_9_0 == state) {
    call_and_disable_work_9(ldv_work_struct_9_0);
  } else {

  }
  if (ldv_work_9_1 == state) {
    call_and_disable_work_9(ldv_work_struct_9_1);
  } else {

  }
  if (ldv_work_9_2 == state) {
    call_and_disable_work_9(ldv_work_struct_9_2);
  } else {

  }
  if (ldv_work_9_3 == state) {
    call_and_disable_work_9(ldv_work_struct_9_3);
  } else {

  }
  return;
}
}
void call_and_disable_work_8(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_8_0 == 2 || ldv_work_8_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_8_0) {
    efx_siena_sriov_reset_vf_work(work);
    ldv_work_8_0 = 1;
    return;
  } else {

  }
  if ((ldv_work_8_1 == 2 || ldv_work_8_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_8_1) {
    efx_siena_sriov_reset_vf_work(work);
    ldv_work_8_1 = 1;
    return;
  } else {

  }
  if ((ldv_work_8_2 == 2 || ldv_work_8_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_8_2) {
    efx_siena_sriov_reset_vf_work(work);
    ldv_work_8_2 = 1;
    return;
  } else {

  }
  if ((ldv_work_8_3 == 2 || ldv_work_8_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_8_3) {
    efx_siena_sriov_reset_vf_work(work);
    ldv_work_8_3 = 1;
    return;
  } else {

  }
  return;
}
}
void invoke_work_9(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_work_9_0 == 2 || ldv_work_9_0 == 3) {
    ldv_work_9_0 = 4;
    efx_siena_sriov_peer_work(ldv_work_struct_9_0);
    ldv_work_9_0 = 1;
  } else {

  }
  goto ldv_57301;
  case 1: ;
  if (ldv_work_9_1 == 2 || ldv_work_9_1 == 3) {
    ldv_work_9_1 = 4;
    efx_siena_sriov_peer_work(ldv_work_struct_9_0);
    ldv_work_9_1 = 1;
  } else {

  }
  goto ldv_57301;
  case 2: ;
  if (ldv_work_9_2 == 2 || ldv_work_9_2 == 3) {
    ldv_work_9_2 = 4;
    efx_siena_sriov_peer_work(ldv_work_struct_9_0);
    ldv_work_9_2 = 1;
  } else {

  }
  goto ldv_57301;
  case 3: ;
  if (ldv_work_9_3 == 2 || ldv_work_9_3 == 3) {
    ldv_work_9_3 = 4;
    efx_siena_sriov_peer_work(ldv_work_struct_9_0);
    ldv_work_9_3 = 1;
  } else {

  }
  goto ldv_57301;
  default: 
  ldv_stop();
  }
  ldv_57301: ;
  return;
}
}
void disable_work_8(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_8_0 == 3 || ldv_work_8_0 == 2) && (unsigned long )ldv_work_struct_8_0 == (unsigned long )work) {
    ldv_work_8_0 = 1;
  } else {

  }
  if ((ldv_work_8_1 == 3 || ldv_work_8_1 == 2) && (unsigned long )ldv_work_struct_8_1 == (unsigned long )work) {
    ldv_work_8_1 = 1;
  } else {

  }
  if ((ldv_work_8_2 == 3 || ldv_work_8_2 == 2) && (unsigned long )ldv_work_struct_8_2 == (unsigned long )work) {
    ldv_work_8_2 = 1;
  } else {

  }
  if ((ldv_work_8_3 == 3 || ldv_work_8_3 == 2) && (unsigned long )ldv_work_struct_8_3 == (unsigned long )work) {
    ldv_work_8_3 = 1;
  } else {

  }
  return;
}
}
void activate_work_9(struct work_struct *work , int state ) 
{ 


  {
  if (ldv_work_9_0 == 0) {
    ldv_work_struct_9_0 = work;
    ldv_work_9_0 = state;
    return;
  } else {

  }
  if (ldv_work_9_1 == 0) {
    ldv_work_struct_9_1 = work;
    ldv_work_9_1 = state;
    return;
  } else {

  }
  if (ldv_work_9_2 == 0) {
    ldv_work_struct_9_2 = work;
    ldv_work_9_2 = state;
    return;
  } else {

  }
  if (ldv_work_9_3 == 0) {
    ldv_work_struct_9_3 = work;
    ldv_work_9_3 = state;
    return;
  } else {

  }
  return;
}
}
void call_and_disable_all_7(int state ) 
{ 


  {
  if (ldv_work_7_0 == state) {
    call_and_disable_work_7(ldv_work_struct_7_0);
  } else {

  }
  if (ldv_work_7_1 == state) {
    call_and_disable_work_7(ldv_work_struct_7_1);
  } else {

  }
  if (ldv_work_7_2 == state) {
    call_and_disable_work_7(ldv_work_struct_7_2);
  } else {

  }
  if (ldv_work_7_3 == state) {
    call_and_disable_work_7(ldv_work_struct_7_3);
  } else {

  }
  return;
}
}
void work_init_7(void) 
{ 


  {
  ldv_work_7_0 = 0;
  ldv_work_7_1 = 0;
  ldv_work_7_2 = 0;
  ldv_work_7_3 = 0;
  return;
}
}
void invoke_work_7(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_work_7_0 == 2 || ldv_work_7_0 == 3) {
    ldv_work_7_0 = 4;
    efx_siena_sriov_vfdi(ldv_work_struct_7_0);
    ldv_work_7_0 = 1;
  } else {

  }
  goto ldv_57325;
  case 1: ;
  if (ldv_work_7_1 == 2 || ldv_work_7_1 == 3) {
    ldv_work_7_1 = 4;
    efx_siena_sriov_vfdi(ldv_work_struct_7_0);
    ldv_work_7_1 = 1;
  } else {

  }
  goto ldv_57325;
  case 2: ;
  if (ldv_work_7_2 == 2 || ldv_work_7_2 == 3) {
    ldv_work_7_2 = 4;
    efx_siena_sriov_vfdi(ldv_work_struct_7_0);
    ldv_work_7_2 = 1;
  } else {

  }
  goto ldv_57325;
  case 3: ;
  if (ldv_work_7_3 == 2 || ldv_work_7_3 == 3) {
    ldv_work_7_3 = 4;
    efx_siena_sriov_vfdi(ldv_work_struct_7_0);
    ldv_work_7_3 = 1;
  } else {

  }
  goto ldv_57325;
  default: 
  ldv_stop();
  }
  ldv_57325: ;
  return;
}
}
void call_and_disable_all_8(int state ) 
{ 


  {
  if (ldv_work_8_0 == state) {
    call_and_disable_work_8(ldv_work_struct_8_0);
  } else {

  }
  if (ldv_work_8_1 == state) {
    call_and_disable_work_8(ldv_work_struct_8_1);
  } else {

  }
  if (ldv_work_8_2 == state) {
    call_and_disable_work_8(ldv_work_struct_8_2);
  } else {

  }
  if (ldv_work_8_3 == state) {
    call_and_disable_work_8(ldv_work_struct_8_3);
  } else {

  }
  return;
}
}
void call_and_disable_work_9(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_9_0 == 2 || ldv_work_9_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_9_0) {
    efx_siena_sriov_peer_work(work);
    ldv_work_9_0 = 1;
    return;
  } else {

  }
  if ((ldv_work_9_1 == 2 || ldv_work_9_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_9_1) {
    efx_siena_sriov_peer_work(work);
    ldv_work_9_1 = 1;
    return;
  } else {

  }
  if ((ldv_work_9_2 == 2 || ldv_work_9_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_9_2) {
    efx_siena_sriov_peer_work(work);
    ldv_work_9_2 = 1;
    return;
  } else {

  }
  if ((ldv_work_9_3 == 2 || ldv_work_9_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_9_3) {
    efx_siena_sriov_peer_work(work);
    ldv_work_9_3 = 1;
    return;
  } else {

  }
  return;
}
}
void activate_work_8(struct work_struct *work , int state ) 
{ 


  {
  if (ldv_work_8_0 == 0) {
    ldv_work_struct_8_0 = work;
    ldv_work_8_0 = state;
    return;
  } else {

  }
  if (ldv_work_8_1 == 0) {
    ldv_work_struct_8_1 = work;
    ldv_work_8_1 = state;
    return;
  } else {

  }
  if (ldv_work_8_2 == 0) {
    ldv_work_struct_8_2 = work;
    ldv_work_8_2 = state;
    return;
  } else {

  }
  if (ldv_work_8_3 == 0) {
    ldv_work_struct_8_3 = work;
    ldv_work_8_3 = state;
    return;
  } else {

  }
  return;
}
}
void disable_work_9(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_9_0 == 3 || ldv_work_9_0 == 2) && (unsigned long )ldv_work_struct_9_0 == (unsigned long )work) {
    ldv_work_9_0 = 1;
  } else {

  }
  if ((ldv_work_9_1 == 3 || ldv_work_9_1 == 2) && (unsigned long )ldv_work_struct_9_1 == (unsigned long )work) {
    ldv_work_9_1 = 1;
  } else {

  }
  if ((ldv_work_9_2 == 3 || ldv_work_9_2 == 2) && (unsigned long )ldv_work_struct_9_2 == (unsigned long )work) {
    ldv_work_9_2 = 1;
  } else {

  }
  if ((ldv_work_9_3 == 3 || ldv_work_9_3 == 2) && (unsigned long )ldv_work_struct_9_3 == (unsigned long )work) {
    ldv_work_9_3 = 1;
  } else {

  }
  return;
}
}
void activate_work_7(struct work_struct *work , int state ) 
{ 


  {
  if (ldv_work_7_0 == 0) {
    ldv_work_struct_7_0 = work;
    ldv_work_7_0 = state;
    return;
  } else {

  }
  if (ldv_work_7_1 == 0) {
    ldv_work_struct_7_1 = work;
    ldv_work_7_1 = state;
    return;
  } else {

  }
  if (ldv_work_7_2 == 0) {
    ldv_work_struct_7_2 = work;
    ldv_work_7_2 = state;
    return;
  } else {

  }
  if (ldv_work_7_3 == 0) {
    ldv_work_struct_7_3 = work;
    ldv_work_7_3 = state;
    return;
  } else {

  }
  return;
}
}
void ldv_main_exported_14(void) 
{ 
  size_t ldvarg137 ;
  char *ldvarg138 ;
  void *tmp ;
  struct efx_nic *ldvarg136 ;
  void *tmp___0 ;
  int tmp___1 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg138 = (char *)tmp;
  tmp___0 = ldv_init_zalloc(4032UL);
  ldvarg136 = (struct efx_nic *)tmp___0;
  ldv_memset((void *)(& ldvarg137), 0, 8UL);
  tmp___1 = __VERIFIER_nondet_int();
  switch (tmp___1) {
  case 0: ;
  if (ldv_state_variable_14 == 1) {
    efx_siena_sriov_get_channel_name(efx_siena_sriov_channel_type_group0, ldvarg138,
                                     ldvarg137);
    ldv_state_variable_14 = 1;
  } else {

  }
  goto ldv_57356;
  case 1: ;
  if (ldv_state_variable_14 == 1) {
    efx_siena_sriov_probe_channel(efx_siena_sriov_channel_type_group0);
    ldv_state_variable_14 = 1;
  } else {

  }
  goto ldv_57356;
  case 2: ;
  if (ldv_state_variable_14 == 1) {
    efx_channel_dummy_op_void(efx_siena_sriov_channel_type_group0);
    ldv_state_variable_14 = 1;
  } else {

  }
  goto ldv_57356;
  case 3: ;
  if (ldv_state_variable_14 == 1) {
    efx_siena_sriov_handle_no_channel(ldvarg136);
    ldv_state_variable_14 = 1;
  } else {

  }
  goto ldv_57356;
  default: 
  ldv_stop();
  }
  ldv_57356: ;
  return;
}
}
bool ldv_queue_work_on_783(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_784(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_785(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_786(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_787(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_788(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_789(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_790(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_791(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_792(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_793(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_794(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
__inline static int ldv_mutex_is_locked_795(struct mutex *lock ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_is_locked(lock);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_is_locked_status_lock_of_siena_vf(lock);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_796(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_txq_lock_of_siena_vf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_797(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_txq_lock_of_siena_vf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_798(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_local_lock_of_siena_nic_data(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_799(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_status_lock_of_siena_vf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_800(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_status_lock_of_siena_vf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_801(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_local_lock_of_siena_nic_data(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_802(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_status_lock_of_siena_vf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_803(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_status_lock_of_siena_vf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_804(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_status_lock_of_siena_vf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_805(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_status_lock_of_siena_vf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_806(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_local_lock_of_siena_nic_data(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_807(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_status_lock_of_siena_vf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_808(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_status_lock_of_siena_vf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_809(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_local_lock_of_siena_nic_data(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_810(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_status_lock_of_siena_vf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_811(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_status_lock_of_siena_vf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
bool ldv_cancel_work_sync_812(struct work_struct *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___15 ldv_func_res ;
  bool tmp ;

  {
  tmp = cancel_work_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_work_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
bool ldv_cancel_work_sync_813(struct work_struct *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___6 ldv_func_res ;
  bool tmp ;

  {
  tmp = cancel_work_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_work_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
bool ldv_cancel_work_sync_814(struct work_struct *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___7 ldv_func_res ;
  bool tmp ;

  {
  tmp = cancel_work_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_work_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
bool ldv_cancel_work_sync_815(struct work_struct *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___16 ldv_func_res ;
  bool tmp ;

  {
  tmp = cancel_work_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_work_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
void ldv_destroy_workqueue_816(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  destroy_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
void ldv_mutex_lock_817(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_status_lock_of_siena_vf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_818(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_status_lock_of_siena_vf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_819(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_status_lock_of_siena_vf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_820(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_status_lock_of_siena_vf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_821(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_txq_lock_of_siena_vf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_822(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_txq_lock_of_siena_vf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
int ldv_mutex_trylock_875(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_873(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_876(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_877(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_872(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_874(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_878(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_867(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_869(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_868(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_871(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_870(struct workqueue_struct *ldv_func_arg1 ) ;
extern int pci_num_vf(struct pci_dev * ) ;
extern int pci_sriov_get_totalvfs(struct pci_dev * ) ;
extern void get_random_bytes(void * , int  ) ;
__inline static void netif_tx_lock___3(struct net_device *dev ) 
{ 
  unsigned int i ;
  int cpu ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  spin_lock(& dev->tx_global_lock);
  __vpp_verify = (void const   *)0;
  switch (4UL) {
  case 1UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
  goto ldv_45270;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_45270;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_45270;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_45270;
  default: 
  __bad_percpu_size();
  }
  ldv_45270: 
  pscr_ret__ = pfo_ret__;
  goto ldv_45276;
  case 2UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45280;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45280;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45280;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_45280;
  default: 
  __bad_percpu_size();
  }
  ldv_45280: 
  pscr_ret__ = pfo_ret_____0;
  goto ldv_45276;
  case 4UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45289;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45289;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45289;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_45289;
  default: 
  __bad_percpu_size();
  }
  ldv_45289: 
  pscr_ret__ = pfo_ret_____1;
  goto ldv_45276;
  case 8UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45298;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45298;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45298;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_45298;
  default: 
  __bad_percpu_size();
  }
  ldv_45298: 
  pscr_ret__ = pfo_ret_____2;
  goto ldv_45276;
  default: 
  __bad_size_call_parameter();
  goto ldv_45276;
  }
  ldv_45276: 
  cpu = pscr_ret__;
  i = 0U;
  goto ldv_45308;
  ldv_45307: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  __netif_tx_lock(txq, cpu);
  set_bit(2L, (unsigned long volatile   *)(& txq->state));
  __netif_tx_unlock(txq);
  i = i + 1U;
  ldv_45308: ;
  if (dev->num_tx_queues > i) {
    goto ldv_45307;
  } else {

  }

  return;
}
}
__inline static void netif_tx_lock_bh___2(struct net_device *dev ) 
{ 


  {
  local_bh_disable();
  netif_tx_lock___3(dev);
  return;
}
}
__inline static void netif_tx_unlock___3(struct net_device *dev ) 
{ 
  unsigned int i ;
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  i = 0U;
  goto ldv_45319;
  ldv_45318: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  clear_bit(2L, (unsigned long volatile   *)(& txq->state));
  netif_schedule_queue(txq);
  i = i + 1U;
  ldv_45319: ;
  if (dev->num_tx_queues > i) {
    goto ldv_45318;
  } else {

  }
  spin_unlock(& dev->tx_global_lock);
  return;
}
}
__inline static void netif_tx_unlock_bh___2(struct net_device *dev ) 
{ 


  {
  netif_tx_unlock___3(dev);
  local_bh_enable();
  return;
}
}
__inline static void eth_random_addr(u8 *addr ) 
{ 


  {
  get_random_bytes((void *)addr, 6);
  *addr = (unsigned int )*addr & 254U;
  *addr = (u8 )((unsigned int )*addr | 2U);
  return;
}
}
__inline static void eth_zero_addr(u8 *addr ) 
{ 


  {
  memset((void *)addr, 0, 6UL);
  return;
}
}
__inline static void efx_device_detach_sync___2(struct efx_nic *efx ) 
{ 
  struct net_device *dev ;

  {
  dev = efx->net_dev;
  netif_tx_lock_bh___2(dev);
  netif_device_detach(dev);
  netif_tx_unlock_bh___2(dev);
  return;
}
}
static int efx_ef10_evb_port_assign(struct efx_nic *efx , unsigned int port_id , unsigned int vf_fn ) 
{ 
  efx_dword_t inbuf[2U] ;
  unsigned int tmp ;
  struct efx_ef10_nic_data *nic_data ;
  int tmp___0 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  ((efx_dword_t *)(& inbuf))->u32[0] = port_id;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = nic_data->pf_index | (vf_fn << 16);
  tmp___0 = efx_mcdi_rpc(efx, 154U, (efx_dword_t const   *)(& inbuf), 8UL, (efx_dword_t *)0,
                         0UL, (size_t *)0UL);
  return (tmp___0);
}
}
static int efx_ef10_vport_add_mac(struct efx_nic *efx , unsigned int port_id , u8 *mac ) 
{ 
  efx_dword_t inbuf[3U] ;
  unsigned int tmp ;
  int tmp___0 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 3U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = port_id;
  ether_addr_copy((u8 *)(& inbuf) + 4UL, (u8 const   *)mac);
  tmp___0 = efx_mcdi_rpc(efx, 168U, (efx_dword_t const   *)(& inbuf), 12UL, (efx_dword_t *)0,
                         0UL, (size_t *)0UL);
  return (tmp___0);
}
}
static int efx_ef10_vport_del_mac(struct efx_nic *efx , unsigned int port_id , u8 *mac ) 
{ 
  efx_dword_t inbuf[3U] ;
  unsigned int tmp ;
  int tmp___0 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 3U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = port_id;
  ether_addr_copy((u8 *)(& inbuf) + 4UL, (u8 const   *)mac);
  tmp___0 = efx_mcdi_rpc(efx, 169U, (efx_dword_t const   *)(& inbuf), 12UL, (efx_dword_t *)0,
                         0UL, (size_t *)0UL);
  return (tmp___0);
}
}
static int efx_ef10_vswitch_alloc(struct efx_nic *efx , unsigned int port_id , unsigned int vswitch_type ) 
{ 
  efx_dword_t inbuf[4U] ;
  unsigned int tmp ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 4U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = port_id;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = vswitch_type;
  ((efx_dword_t *)(& inbuf) + 3UL)->u32[0] = 2U;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = 0U;
  rc = efx_mcdi_rpc_quiet(efx, 148U, (efx_dword_t const   *)(& inbuf), 16UL, (efx_dword_t *)0,
                          0UL, (size_t *)0UL);
  if (rc == -71) {
    ((efx_dword_t *)(& inbuf) + 3UL)->u32[0] = 1U;
    rc = efx_mcdi_rpc(efx, 148U, (efx_dword_t const   *)(& inbuf), 16UL, (efx_dword_t *)0,
                      0UL, (size_t *)0UL);
  } else
  if (rc != 0) {
    efx_mcdi_display_error(efx, 148U, 16UL, (efx_dword_t *)0, 0UL, rc);
  } else {

  }
  return (rc);
}
}
static int efx_ef10_vswitch_free(struct efx_nic *efx , unsigned int port_id ) 
{ 
  efx_dword_t inbuf[1U] ;
  int tmp ;

  {
  inbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = port_id;
  tmp = efx_mcdi_rpc(efx, 149U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
                     0UL, (size_t *)0UL);
  return (tmp);
}
}
static int efx_ef10_vport_alloc(struct efx_nic *efx , unsigned int port_id_in , unsigned int vport_type ,
                                u16 vlan , unsigned int *port_id_out ) 
{ 
  efx_dword_t inbuf[5U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[1U] ;
  size_t outlen ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 5U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = port_id_in;
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = vport_type;
  ((efx_dword_t *)(& inbuf) + 3UL)->u32[0] = (unsigned int )vlan != 0U;
  ((efx_dword_t *)(& inbuf) + 2UL)->u32[0] = 0U;
  if ((unsigned int )vlan != 0U) {
    ((efx_dword_t *)(& inbuf) + 4UL)->u32[0] = (unsigned int )vlan;
  } else {

  }
  rc = efx_mcdi_rpc(efx, 150U, (efx_dword_t const   *)(& inbuf), 20UL, (efx_dword_t *)(& outbuf),
                    4UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 3UL) {
    return (-5);
  } else {

  }
  *port_id_out = ((efx_dword_t *)(& outbuf))->u32[0];
  return (0);
}
}
static int efx_ef10_vport_free(struct efx_nic *efx , unsigned int port_id ) 
{ 
  efx_dword_t inbuf[1U] ;
  int tmp ;

  {
  inbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = port_id;
  tmp = efx_mcdi_rpc(efx, 151U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
                     0UL, (size_t *)0UL);
  return (tmp);
}
}
static int efx_ef10_vadaptor_alloc(struct efx_nic *efx , unsigned int port_id ) 
{ 
  efx_dword_t inbuf[8U] ;
  unsigned int tmp ;
  int tmp___0 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 8U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = port_id;
  tmp___0 = efx_mcdi_rpc(efx, 152U, (efx_dword_t const   *)(& inbuf), 32UL, (efx_dword_t *)0,
                         0UL, (size_t *)0UL);
  return (tmp___0);
}
}
static int efx_ef10_vadaptor_free(struct efx_nic *efx , unsigned int port_id ) 
{ 
  efx_dword_t inbuf[1U] ;
  int tmp ;

  {
  inbuf[0].u32[0] = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = port_id;
  tmp = efx_mcdi_rpc(efx, 153U, (efx_dword_t const   *)(& inbuf), 4UL, (efx_dword_t *)0,
                     0UL, (size_t *)0UL);
  return (tmp);
}
}
static void efx_ef10_sriov_free_vf_vports(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  int i ;
  struct ef10_vf *vf ;
  bool tmp ;
  int tmp___0 ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  if ((unsigned long )nic_data->vf == (unsigned long )((struct ef10_vf *)0)) {
    return;
  } else {

  }
  i = 0;
  goto ldv_56382;
  ldv_56381: 
  vf = nic_data->vf + (unsigned long )i;
  if ((unsigned long )vf->pci_dev != (unsigned long )((struct pci_dev *)0) && ((int )(vf->pci_dev)->dev_flags & 4) != 0) {
    goto ldv_56380;
  } else {

  }
  if (vf->vport_assigned != 0U) {
    efx_ef10_evb_port_assign(efx, 0U, (unsigned int )i);
    vf->vport_assigned = 0U;
  } else {

  }
  tmp = is_zero_ether_addr((u8 const   *)(& vf->mac));
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    efx_ef10_vport_del_mac(efx, vf->vport_id, (u8 *)(& vf->mac));
    eth_zero_addr((u8 *)(& vf->mac));
  } else {

  }
  if (vf->vport_id != 0U) {
    efx_ef10_vport_free(efx, vf->vport_id);
    vf->vport_id = 0U;
  } else {

  }
  vf->efx = (struct efx_nic *)0;
  ldv_56380: 
  i = i + 1;
  ldv_56382: ;
  if ((unsigned int )i < efx->vf_count) {
    goto ldv_56381;
  } else {

  }

  return;
}
}
static void efx_ef10_sriov_free_vf_vswitching(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  efx_ef10_sriov_free_vf_vports(efx);
  kfree((void const   *)nic_data->vf);
  nic_data->vf = (struct ef10_vf *)0;
  return;
}
}
static int efx_ef10_sriov_assign_vf_vport(struct efx_nic *efx , unsigned int vf_i ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  struct ef10_vf *vf ;
  int rc ;
  bool __warned ;
  int __ret_warn_once ;
  int __ret_warn_on ;
  long tmp ;
  long tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  vf = nic_data->vf + (unsigned long )vf_i;
  __ret_warn_once = (unsigned long )nic_data->vf == (unsigned long )((struct ef10_vf *)0);
  tmp___1 = ldv__builtin_expect(__ret_warn_once != 0, 0L);
  if (tmp___1 != 0L) {
    __ret_warn_on = ! __warned;
    tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp != 0L) {
      warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10_sriov.c",
                         208);
    } else {

    }
    tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___0 != 0L) {
      __warned = 1;
    } else {

    }
  } else {

  }
  tmp___2 = ldv__builtin_expect(__ret_warn_once != 0, 0L);
  if (tmp___2 != 0L) {
    return (-95);
  } else {

  }
  rc = efx_ef10_vport_alloc(efx, 16777216U, 4U, (int )vf->vlan, & vf->vport_id);
  if (rc != 0) {
    return (rc);
  } else {

  }
  rc = efx_ef10_vport_add_mac(efx, vf->vport_id, (u8 *)(& vf->mac));
  if (rc != 0) {
    eth_zero_addr((u8 *)(& vf->mac));
    return (rc);
  } else {

  }
  rc = efx_ef10_evb_port_assign(efx, vf->vport_id, vf_i);
  if (rc != 0) {
    return (rc);
  } else {

  }
  vf->vport_assigned = 1U;
  return (0);
}
}
static int efx_ef10_sriov_alloc_vf_vswitching(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  unsigned int i ;
  int rc ;
  void *tmp ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  tmp = kcalloc((size_t )efx->vf_count, 32UL, 208U);
  nic_data->vf = (struct ef10_vf *)tmp;
  if ((unsigned long )nic_data->vf == (unsigned long )((struct ef10_vf *)0)) {
    return (-12);
  } else {

  }
  i = 0U;
  goto ldv_56408;
  ldv_56407: 
  eth_random_addr((u8 *)(& (nic_data->vf + (unsigned long )i)->mac));
  (nic_data->vf + (unsigned long )i)->efx = (struct efx_nic *)0;
  (nic_data->vf + (unsigned long )i)->vlan = 0U;
  rc = efx_ef10_sriov_assign_vf_vport(efx, i);
  if (rc != 0) {
    goto fail;
  } else {

  }
  i = i + 1U;
  ldv_56408: ;
  if (efx->vf_count > i) {
    goto ldv_56407;
  } else {

  }

  return (0);
  fail: 
  efx_ef10_sriov_free_vf_vports(efx);
  kfree((void const   *)nic_data->vf);
  nic_data->vf = (struct ef10_vf *)0;
  return (rc);
}
}
static int efx_ef10_sriov_restore_vf_vswitching(struct efx_nic *efx ) 
{ 
  unsigned int i ;
  int rc ;

  {
  i = 0U;
  goto ldv_56417;
  ldv_56416: 
  rc = efx_ef10_sriov_assign_vf_vport(efx, i);
  if (rc != 0) {
    goto fail;
  } else {

  }
  i = i + 1U;
  ldv_56417: ;
  if (efx->vf_count > i) {
    goto ldv_56416;
  } else {

  }

  return (0);
  fail: 
  efx_ef10_sriov_free_vf_vswitching(efx);
  return (rc);
}
}
int efx_ef10_vswitching_probe_pf(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  struct net_device *net_dev ;
  int rc ;
  int tmp ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  net_dev = efx->net_dev;
  tmp = pci_sriov_get_totalvfs(efx->pci_dev);
  if (tmp <= 0) {
    efx_ef10_vadaptor_alloc(efx, nic_data->vport_id);
    return (0);
  } else {

  }
  rc = efx_ef10_vswitch_alloc(efx, 16777216U, 2U);
  if (rc != 0) {
    goto fail1;
  } else {

  }
  rc = efx_ef10_vport_alloc(efx, 16777216U, 4U, 0, & nic_data->vport_id);
  if (rc != 0) {
    goto fail2;
  } else {

  }
  rc = efx_ef10_vport_add_mac(efx, nic_data->vport_id, net_dev->dev_addr);
  if (rc != 0) {
    goto fail3;
  } else {

  }
  ether_addr_copy((u8 *)(& nic_data->vport_mac), (u8 const   *)net_dev->dev_addr);
  rc = efx_ef10_vadaptor_alloc(efx, nic_data->vport_id);
  if (rc != 0) {
    goto fail4;
  } else {

  }
  return (0);
  fail4: 
  efx_ef10_vport_del_mac(efx, nic_data->vport_id, (u8 *)(& nic_data->vport_mac));
  eth_zero_addr((u8 *)(& nic_data->vport_mac));
  fail3: 
  efx_ef10_vport_free(efx, nic_data->vport_id);
  nic_data->vport_id = 16777216U;
  fail2: 
  efx_ef10_vswitch_free(efx, 16777216U);
  fail1: ;
  return (rc);
}
}
int efx_ef10_vswitching_probe_vf(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  int tmp ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  tmp = efx_ef10_vadaptor_alloc(efx, nic_data->vport_id);
  return (tmp);
}
}
int efx_ef10_vswitching_restore_pf(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  int rc ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  if (! nic_data->must_probe_vswitching) {
    return (0);
  } else {

  }
  rc = efx_ef10_vswitching_probe_pf(efx);
  if (rc != 0) {
    goto fail;
  } else {

  }
  rc = efx_ef10_sriov_restore_vf_vswitching(efx);
  if (rc != 0) {
    goto fail;
  } else {

  }
  nic_data->must_probe_vswitching = 0;
  fail: ;
  return (rc);
}
}
int efx_ef10_vswitching_restore_vf(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  int rc ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  if (! nic_data->must_probe_vswitching) {
    return (0);
  } else {

  }
  rc = efx_ef10_vadaptor_free(efx, 16777216U);
  if (rc != 0) {
    return (rc);
  } else {

  }
  nic_data->must_probe_vswitching = 0;
  return (0);
}
}
void efx_ef10_vswitching_remove_pf(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  bool tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  efx_ef10_sriov_free_vf_vswitching(efx);
  efx_ef10_vadaptor_free(efx, nic_data->vport_id);
  if (nic_data->vport_id == 16777216U) {
    return;
  } else {

  }
  tmp = is_zero_ether_addr((u8 const   *)(& nic_data->vport_mac));
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    efx_ef10_vport_del_mac(efx, nic_data->vport_id, (efx->net_dev)->dev_addr);
    eth_zero_addr((u8 *)(& nic_data->vport_mac));
  } else {

  }
  efx_ef10_vport_free(efx, nic_data->vport_id);
  nic_data->vport_id = 16777216U;
  tmp___1 = pci_vfs_assigned(efx->pci_dev);
  if (tmp___1 == 0) {
    efx_ef10_vswitch_free(efx, nic_data->vport_id);
  } else {

  }
  return;
}
}
void efx_ef10_vswitching_remove_vf(struct efx_nic *efx ) 
{ 


  {
  efx_ef10_vadaptor_free(efx, 16777216U);
  return;
}
}
static int efx_ef10_pci_sriov_enable(struct efx_nic *efx , int num_vfs ) 
{ 
  int rc ;
  struct pci_dev *dev ;

  {
  rc = 0;
  dev = efx->pci_dev;
  efx->vf_count = (unsigned int )num_vfs;
  rc = efx_ef10_sriov_alloc_vf_vswitching(efx);
  if (rc != 0) {
    goto fail1;
  } else {

  }
  rc = pci_enable_sriov(dev, num_vfs);
  if (rc != 0) {
    goto fail2;
  } else {

  }
  return (0);
  fail2: 
  efx_ef10_sriov_free_vf_vswitching(efx);
  fail1: 
  efx->vf_count = 0U;
  if ((efx->msg_enable & 2U) != 0U) {
    netdev_err((struct net_device  const  *)efx->net_dev, "Failed to enable SRIOV VFs\n");
  } else {

  }
  return (rc);
}
}
static int efx_ef10_pci_sriov_disable(struct efx_nic *efx , bool force ) 
{ 
  struct pci_dev *dev ;
  unsigned int vfs_assigned ;
    klee_make_symbolic(&vfs_assigned, sizeof(int), "vfs_assigned");
  int tmp ;

  {
  dev = efx->pci_dev;
  vfs_assigned = 0U;
  tmp = pci_vfs_assigned(dev);
  vfs_assigned = (unsigned int )tmp;
  if (vfs_assigned != 0U && ! force) {
    if ((int )efx->msg_enable & 1) {
      netdev_info((struct net_device  const  *)efx->net_dev, "VFs are assigned to guests; please detach them before disabling SR-IOV\n");
    } else {

    }
    return (-16);
  } else {

  }
  if (vfs_assigned == 0U) {
    pci_disable_sriov(dev);
  } else {

  }
  efx_ef10_sriov_free_vf_vswitching(efx);
  efx->vf_count = 0U;
  return (0);
}
}
int efx_ef10_sriov_configure(struct efx_nic *efx , int num_vfs ) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  if (num_vfs == 0) {
    tmp = efx_ef10_pci_sriov_disable(efx, 0);
    return (tmp);
  } else {
    tmp___0 = efx_ef10_pci_sriov_enable(efx, num_vfs);
    return (tmp___0);
  }
}
}
int efx_ef10_sriov_init(struct efx_nic *efx ) 
{ 


  {
  return (0);
}
}
void efx_ef10_sriov_fini(struct efx_nic *efx ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  unsigned int i ;
  int rc ;
  int tmp ;
  int tmp___0 ;
  struct efx_nic *vf_efx ;
  struct _ddebug descriptor ;
  long tmp___1 ;
  struct _ddebug descriptor___0 ;
  long tmp___2 ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  if ((unsigned long )nic_data->vf == (unsigned long )((struct ef10_vf *)0)) {
    tmp = pci_num_vf(efx->pci_dev);
    if (tmp != 0) {
      tmp___0 = pci_vfs_assigned(efx->pci_dev);
      if (tmp___0 == 0) {
        pci_disable_sriov(efx->pci_dev);
      } else {

      }
    } else {

    }
    return;
  } else {

  }
  i = 0U;
  goto ldv_56480;
  ldv_56479: 
  vf_efx = (nic_data->vf + (unsigned long )i)->efx;
  if ((unsigned long )vf_efx != (unsigned long )((struct efx_nic *)0)) {
    (*(((vf_efx->pci_dev)->driver)->remove))(vf_efx->pci_dev);
  } else {

  }
  i = i + 1U;
  ldv_56480: ;
  if (efx->vf_count > i) {
    goto ldv_56479;
  } else {

  }
  rc = efx_ef10_pci_sriov_disable(efx, 1);
  if (rc != 0) {
    if ((int )efx->msg_enable & 1) {
      descriptor.modname = "sfc";
      descriptor.function = "efx_ef10_sriov_fini";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10_sriov.c";
      descriptor.format = "Disabling SRIOV was not successful rc=%d\n";
      descriptor.lineno = 481U;
      descriptor.flags = 0U;
      tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp___1 != 0L) {
        __dynamic_netdev_dbg(& descriptor, (struct net_device  const  *)efx->net_dev,
                             "Disabling SRIOV was not successful rc=%d\n", rc);
      } else {

      }
    } else {

    }
  } else
  if ((int )efx->msg_enable & 1) {
    descriptor___0.modname = "sfc";
    descriptor___0.function = "efx_ef10_sriov_fini";
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11285/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/sfc/ef10_sriov.c";
    descriptor___0.format = "SRIOV disabled\n";
    descriptor___0.lineno = 483U;
    descriptor___0.flags = 0U;
    tmp___2 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
    if (tmp___2 != 0L) {
      __dynamic_netdev_dbg(& descriptor___0, (struct net_device  const  *)efx->net_dev,
                           "SRIOV disabled\n");
    } else {

    }
  } else {

  }
  return;
}
}
static int efx_ef10_vport_del_vf_mac(struct efx_nic *efx , unsigned int port_id ,
                                     u8 *mac ) 
{ 
  efx_dword_t inbuf[3U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[2U] ;
  unsigned int tmp___0 ;
  size_t outlen ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 3U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  tmp___0 = 1U;
  while (1) {
    if (tmp___0 >= 2U) {
      break;
    } else {

    }
    outbuf[tmp___0].u32[0] = 0U;
    tmp___0 = tmp___0 + 1U;
  }
  ((efx_dword_t *)(& inbuf))->u32[0] = port_id;
  ether_addr_copy((u8 *)(& inbuf) + 4UL, (u8 const   *)mac);
  rc = efx_mcdi_rpc(efx, 169U, (efx_dword_t const   *)(& inbuf), 12UL, (efx_dword_t *)(& outbuf),
                    8UL, & outlen);
  return (rc);
}
}
int efx_ef10_sriov_set_vf_mac(struct efx_nic *efx , int vf_i , u8 *mac ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  struct ef10_vf *vf ;
  int rc ;
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  if ((unsigned long )nic_data->vf == (unsigned long )((struct ef10_vf *)0)) {
    return (-95);
  } else {

  }
  if ((unsigned int )vf_i >= efx->vf_count) {
    return (-22);
  } else {

  }
  vf = nic_data->vf + (unsigned long )vf_i;
  if ((unsigned long )vf->efx != (unsigned long )((struct efx_nic *)0)) {
    efx_device_detach_sync___2(vf->efx);
    efx_net_stop((vf->efx)->net_dev);
    down_write(& (vf->efx)->filter_sem);
    (*(((vf->efx)->type)->filter_table_remove))(vf->efx);
    rc = efx_ef10_vadaptor_free(vf->efx, 16777216U);
    if (rc != 0) {
      up_write(& (vf->efx)->filter_sem);
      return (rc);
    } else {

    }
  } else {

  }
  rc = efx_ef10_evb_port_assign(efx, 0U, (unsigned int )vf_i);
  if (rc != 0) {
    return (rc);
  } else {

  }
  tmp = is_zero_ether_addr((u8 const   *)(& vf->mac));
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    rc = efx_ef10_vport_del_vf_mac(efx, vf->vport_id, (u8 *)(& vf->mac));
    if (rc != 0) {
      return (rc);
    } else {

    }
  } else {

  }
  tmp___1 = is_zero_ether_addr((u8 const   *)mac);
  if (tmp___1) {
    tmp___2 = 0;
  } else {
    tmp___2 = 1;
  }
  if (tmp___2) {
    rc = efx_ef10_vport_add_mac(efx, vf->vport_id, mac);
    if (rc != 0) {
      eth_zero_addr((u8 *)(& vf->mac));
      goto fail;
    } else {

    }
    if ((unsigned long )vf->efx != (unsigned long )((struct efx_nic *)0)) {
      ether_addr_copy(((vf->efx)->net_dev)->dev_addr, (u8 const   *)mac);
    } else {

    }
  } else {

  }
  ether_addr_copy((u8 *)(& vf->mac), (u8 const   *)mac);
  rc = efx_ef10_evb_port_assign(efx, vf->vport_id, (unsigned int )vf_i);
  if (rc != 0) {
    goto fail;
  } else {

  }
  if ((unsigned long )vf->efx != (unsigned long )((struct efx_nic *)0)) {
    rc = efx_ef10_vadaptor_alloc(vf->efx, 16777216U);
    if (rc != 0) {
      up_write(& (vf->efx)->filter_sem);
      return (rc);
    } else {

    }
    (*(((vf->efx)->type)->filter_table_probe))(vf->efx);
    up_write(& (vf->efx)->filter_sem);
    efx_net_open((vf->efx)->net_dev);
    netif_device_attach((vf->efx)->net_dev);
  } else {

  }
  return (0);
  fail: 
  memset((void *)(& vf->mac), 0, 6UL);
  return (rc);
}
}
int efx_ef10_sriov_set_vf_vlan(struct efx_nic *efx , int vf_i , u16 vlan , u8 qos ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  struct ef10_vf *vf ;
  u16 old_vlan ;
  u16 new_vlan ;
  int rc ;
  int rc2 ;
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  rc = 0;
  rc2 = 0;
  if ((unsigned int )vf_i >= efx->vf_count) {
    return (-22);
  } else {

  }
  if ((unsigned int )qos != 0U) {
    return (-22);
  } else {

  }
  vf = nic_data->vf + (unsigned long )vf_i;
  new_vlan = vlan;
  if ((int )vf->vlan == (int )new_vlan) {
    return (0);
  } else {

  }
  if ((unsigned long )vf->efx != (unsigned long )((struct efx_nic *)0)) {
    efx_device_detach_sync___2(vf->efx);
    efx_net_stop((vf->efx)->net_dev);
    down_write(& (vf->efx)->filter_sem);
    (*(((vf->efx)->type)->filter_table_remove))(vf->efx);
    rc = efx_ef10_vadaptor_free(vf->efx, 16777216U);
    if (rc != 0) {
      goto restore_filters;
    } else {

    }
  } else {

  }
  if (vf->vport_assigned != 0U) {
    rc = efx_ef10_evb_port_assign(efx, 0U, (unsigned int )vf_i);
    if (rc != 0) {
      if ((int )efx->msg_enable & 1) {
        netdev_warn((struct net_device  const  *)efx->net_dev, "Failed to change vlan on VF %d.\n",
                    vf_i);
      } else {

      }
      if ((int )efx->msg_enable & 1) {
        netdev_warn((struct net_device  const  *)efx->net_dev, "This is likely because the VF is bound to a driver in a VM.\n");
      } else {

      }
      if ((int )efx->msg_enable & 1) {
        netdev_warn((struct net_device  const  *)efx->net_dev, "Please unload the driver in the VM.\n");
      } else {

      }
      goto restore_vadaptor;
    } else {

    }
    vf->vport_assigned = 0U;
  } else {

  }
  tmp = is_zero_ether_addr((u8 const   *)(& vf->mac));
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    rc = efx_ef10_vport_del_mac(efx, vf->vport_id, (u8 *)(& vf->mac));
    if (rc != 0) {
      goto restore_evb_port;
    } else {

    }
  } else {

  }
  if (vf->vport_id != 0U) {
    rc = efx_ef10_vport_free(efx, vf->vport_id);
    if (rc != 0) {
      goto restore_mac;
    } else {

    }
    vf->vport_id = 0U;
  } else {

  }
  old_vlan = vf->vlan;
  vf->vlan = new_vlan;
  rc = efx_ef10_vport_alloc(efx, 16777216U, 4U, (int )vf->vlan, & vf->vport_id);
  if (rc != 0) {
    goto reset_nic;
  } else {

  }
  restore_mac: 
  tmp___1 = is_zero_ether_addr((u8 const   *)(& vf->mac));
  if (tmp___1) {
    tmp___2 = 0;
  } else {
    tmp___2 = 1;
  }
  if (tmp___2) {
    rc2 = efx_ef10_vport_add_mac(efx, vf->vport_id, (u8 *)(& vf->mac));
    if (rc2 != 0) {
      eth_zero_addr((u8 *)(& vf->mac));
      goto reset_nic;
    } else {

    }
  } else {

  }
  restore_evb_port: 
  rc2 = efx_ef10_evb_port_assign(efx, vf->vport_id, (unsigned int )vf_i);
  if (rc2 != 0) {
    goto reset_nic;
  } else {
    vf->vport_assigned = 1U;
  }
  restore_vadaptor: ;
  if ((unsigned long )vf->efx != (unsigned long )((struct efx_nic *)0)) {
    rc2 = efx_ef10_vadaptor_alloc(vf->efx, 16777216U);
    if (rc2 != 0) {
      goto reset_nic;
    } else {

    }
  } else {

  }
  restore_filters: ;
  if ((unsigned long )vf->efx != (unsigned long )((struct efx_nic *)0)) {
    rc2 = (*(((vf->efx)->type)->filter_table_probe))(vf->efx);
    if (rc2 != 0) {
      goto reset_nic;
    } else {

    }
    up_write(& (vf->efx)->filter_sem);
    rc2 = efx_net_open((vf->efx)->net_dev);
    if (rc2 != 0) {
      goto reset_nic;
    } else {

    }
    netif_device_attach((vf->efx)->net_dev);
  } else {

  }
  return (rc);
  reset_nic: ;
  if ((unsigned long )vf->efx != (unsigned long )((struct efx_nic *)0)) {
    up_write(& (vf->efx)->filter_sem);
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Failed to restore VF - scheduling reset.\n");
    } else {

    }
    efx_schedule_reset(vf->efx, 5);
  } else {
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Failed to restore the VF and cannot reset the VF - VF is not functional.\n");
    } else {

    }
    if ((int )efx->msg_enable & 1) {
      netdev_err((struct net_device  const  *)efx->net_dev, "Please reload the driver attached to the VF.\n");
    } else {

    }
  }
  return (rc != 0 ? rc : rc2);
}
}
int efx_ef10_sriov_set_vf_spoofchk(struct efx_nic *efx , int vf_i , bool spoofchk ) 
{ 


  {
  return ((int )spoofchk ? -95 : 0);
}
}
int efx_ef10_sriov_set_vf_link_state(struct efx_nic *efx , int vf_i , int link_state ) 
{ 
  efx_dword_t inbuf[2U] ;
  unsigned int tmp ;
  struct efx_ef10_nic_data *nic_data ;
  int tmp___0 ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  ((efx_dword_t *)(& inbuf))->u32[0] = nic_data->pf_index | ((unsigned int )vf_i << 16);
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = (unsigned int )link_state;
  tmp___0 = efx_mcdi_rpc(efx, 92U, (efx_dword_t const   *)(& inbuf), 8UL, (efx_dword_t *)0,
                         0UL, (size_t *)0UL);
  return (tmp___0);
}
}
int efx_ef10_sriov_get_vf_config(struct efx_nic *efx , int vf_i , struct ifla_vf_info *ivf ) 
{ 
  efx_dword_t inbuf[2U] ;
  unsigned int tmp ;
  efx_dword_t outbuf[1U] ;
  struct efx_ef10_nic_data *nic_data ;
  struct ef10_vf *vf ;
  size_t outlen ;
  int rc ;

  {
  inbuf[0].u32[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 2U) {
      break;
    } else {

    }
    inbuf[tmp].u32[0] = 0U;
    tmp = tmp + 1U;
  }
  outbuf[0].u32[0] = 0U;
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  if ((unsigned int )vf_i >= efx->vf_count) {
    return (-22);
  } else {

  }
  if ((unsigned long )nic_data->vf == (unsigned long )((struct ef10_vf *)0)) {
    return (-95);
  } else {

  }
  vf = nic_data->vf + (unsigned long )vf_i;
  ivf->vf = (__u32 )vf_i;
  ivf->min_tx_rate = 0U;
  ivf->max_tx_rate = 0U;
  ether_addr_copy((u8 *)(& ivf->mac), (u8 const   *)(& vf->mac));
  ivf->vlan = (unsigned int )vf->vlan != 0U ? (__u32 )vf->vlan : 0U;
  ivf->qos = 0U;
  ((efx_dword_t *)(& inbuf))->u32[0] = nic_data->pf_index | ((unsigned int )vf_i << 16);
  ((efx_dword_t *)(& inbuf) + 1UL)->u32[0] = 4294967295U;
  rc = efx_mcdi_rpc(efx, 92U, (efx_dword_t const   *)(& inbuf), 8UL, (efx_dword_t *)(& outbuf),
                    4UL, & outlen);
  if (rc != 0) {
    return (rc);
  } else {

  }
  if (outlen <= 3UL) {
    return (-5);
  } else {

  }
  ivf->linkstate = ((efx_dword_t *)(& outbuf))->u32[0];
  return (0);
}
}
int efx_ef10_sriov_get_phys_port_id(struct efx_nic *efx , struct netdev_phys_item_id *ppid ) 
{ 
  struct efx_ef10_nic_data *nic_data ;
  bool tmp ;
  int tmp___0 ;

  {
  nic_data = (struct efx_ef10_nic_data *)efx->nic_data;
  tmp = is_valid_ether_addr((u8 const   *)(& nic_data->port_id));
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (-95);
  } else {

  }
  ppid->id_len = 6U;
  memcpy((void *)(& ppid->id), (void const   *)(& nic_data->port_id), (size_t )ppid->id_len);
  return (0);
}
}
bool ldv_queue_work_on_867(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_868(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_869(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_7(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_870(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_7(2);
  return;
}
}
bool ldv_queue_delayed_work_on_871(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_7(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_872(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_873(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_874(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_875(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_876(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_877(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_878(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
__inline static void ldv_error(void) 
{ 


  {
  ERROR: ;
  {reach_error();}
}
}
__inline static int ldv_undef_int_negative(void) 
{ 
  int ret ;
  int tmp ;

  {
  tmp = ldv_undef_int();
  ret = tmp;
  if (ret >= 0) {
    ldv_stop();
  } else {

  }
  return (ret);
}
}
bool ldv_is_err(void const   *ptr ) 
{ 


  {
  return ((unsigned long )ptr > 2012UL);
}
}
void *ldv_err_ptr(long error ) 
{ 


  {
  return ((void *)(2012L - error));
}
}
long ldv_ptr_err(void const   *ptr ) 
{ 


  {
  return ((long )(2012UL - (unsigned long )ptr));
}
}
bool ldv_is_err_or_null(void const   *ptr ) 
{ 
  bool tmp ;
  int tmp___0 ;

  {
  if ((unsigned long )ptr == (unsigned long )((void const   *)0)) {
    tmp___0 = 1;
  } else {
    tmp = ldv_is_err(ptr);
    if ((int )tmp) {
      tmp___0 = 1;
    } else {
      tmp___0 = 0;
    }
  }
  return ((bool )tmp___0);
}
}
static int ldv_mutex_i_mutex_of_inode  =    1;
int ldv_mutex_lock_interruptible_i_mutex_of_inode(struct mutex *lock ) 
{ 
  int nondetermined ;
    klee_make_symbolic(&nondetermined, sizeof(int), "nondetermined");

  {
  if (ldv_mutex_i_mutex_of_inode != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_i_mutex_of_inode = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_i_mutex_of_inode(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_i_mutex_of_inode != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_i_mutex_of_inode = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_i_mutex_of_inode(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_i_mutex_of_inode != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_i_mutex_of_inode = 2;
  return;
}
}
int ldv_mutex_trylock_i_mutex_of_inode(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;
    klee_make_symbolic(&is_mutex_held_by_another_thread, sizeof(int), "is_mutex_held_by_another_thread");

  {
  if (ldv_mutex_i_mutex_of_inode != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_i_mutex_of_inode = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_i_mutex_of_inode(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;
    klee_make_symbolic(&atomic_value_after_dec, sizeof(int), "atomic_value_after_dec");

  {
  if (ldv_mutex_i_mutex_of_inode != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_i_mutex_of_inode = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_i_mutex_of_inode(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_i_mutex_of_inode == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_i_mutex_of_inode(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_i_mutex_of_inode != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_i_mutex_of_inode = 1;
  return;
}
}
void ldv_usb_lock_device_i_mutex_of_inode(void) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_i_mutex_of_inode(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_i_mutex_of_inode((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_i_mutex_of_inode(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_i_mutex_of_inode((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_i_mutex_of_inode(void) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode((struct mutex *)0);
  return;
}
}
static int ldv_mutex_local_lock_of_siena_nic_data  =    1;
int ldv_mutex_lock_interruptible_local_lock_of_siena_nic_data(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_local_lock_of_siena_nic_data != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_local_lock_of_siena_nic_data = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_local_lock_of_siena_nic_data(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_local_lock_of_siena_nic_data != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_local_lock_of_siena_nic_data = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_local_lock_of_siena_nic_data(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_local_lock_of_siena_nic_data != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_local_lock_of_siena_nic_data = 2;
  return;
}
}
int ldv_mutex_trylock_local_lock_of_siena_nic_data(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
  if (ldv_mutex_local_lock_of_siena_nic_data != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_local_lock_of_siena_nic_data = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_local_lock_of_siena_nic_data(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
  if (ldv_mutex_local_lock_of_siena_nic_data != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_local_lock_of_siena_nic_data = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_local_lock_of_siena_nic_data(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_local_lock_of_siena_nic_data == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_local_lock_of_siena_nic_data(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_local_lock_of_siena_nic_data != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_local_lock_of_siena_nic_data = 1;
  return;
}
}
void ldv_usb_lock_device_local_lock_of_siena_nic_data(void) 
{ 


  {
  ldv_mutex_lock_local_lock_of_siena_nic_data((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_local_lock_of_siena_nic_data(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_local_lock_of_siena_nic_data((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_local_lock_of_siena_nic_data(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_local_lock_of_siena_nic_data((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_local_lock_of_siena_nic_data(void) 
{ 


  {
  ldv_mutex_unlock_local_lock_of_siena_nic_data((struct mutex *)0);
  return;
}
}
static int ldv_mutex_lock  =    1;
int ldv_mutex_lock_interruptible_lock(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_lock != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_lock = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_lock(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_lock != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_lock = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_lock(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_lock != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_lock = 2;
  return;
}
}
int ldv_mutex_trylock_lock(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
  if (ldv_mutex_lock != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_lock = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_lock(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
  if (ldv_mutex_lock != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_lock = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_lock(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_lock == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_lock(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_lock != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_lock = 1;
  return;
}
}
void ldv_usb_lock_device_lock(void) 
{ 


  {
  ldv_mutex_lock_lock((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_lock(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_lock((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_lock(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_lock((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_lock(void) 
{ 


  {
  ldv_mutex_unlock_lock((struct mutex *)0);
  return;
}
}
static int ldv_mutex_mac_lock_of_efx_nic  =    1;
int ldv_mutex_lock_interruptible_mac_lock_of_efx_nic(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_mac_lock_of_efx_nic != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_mac_lock_of_efx_nic = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_mac_lock_of_efx_nic(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_mac_lock_of_efx_nic != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_mac_lock_of_efx_nic = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_mac_lock_of_efx_nic(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_mac_lock_of_efx_nic != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_mac_lock_of_efx_nic = 2;
  return;
}
}
int ldv_mutex_trylock_mac_lock_of_efx_nic(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
  if (ldv_mutex_mac_lock_of_efx_nic != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_mac_lock_of_efx_nic = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_mac_lock_of_efx_nic(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
  if (ldv_mutex_mac_lock_of_efx_nic != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_mac_lock_of_efx_nic = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_mac_lock_of_efx_nic(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_mac_lock_of_efx_nic == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_mac_lock_of_efx_nic(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_mac_lock_of_efx_nic != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_mac_lock_of_efx_nic = 1;
  return;
}
}
void ldv_usb_lock_device_mac_lock_of_efx_nic(void) 
{ 


  {
  ldv_mutex_lock_mac_lock_of_efx_nic((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_mac_lock_of_efx_nic(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_mac_lock_of_efx_nic((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_mac_lock_of_efx_nic(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_mac_lock_of_efx_nic((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_mac_lock_of_efx_nic(void) 
{ 


  {
  ldv_mutex_unlock_mac_lock_of_efx_nic((struct mutex *)0);
  return;
}
}
static int ldv_mutex_mdio_lock_of_falcon_nic_data  =    1;
int ldv_mutex_lock_interruptible_mdio_lock_of_falcon_nic_data(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_mdio_lock_of_falcon_nic_data != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_mdio_lock_of_falcon_nic_data = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_mdio_lock_of_falcon_nic_data(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_mdio_lock_of_falcon_nic_data != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_mdio_lock_of_falcon_nic_data = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_mdio_lock_of_falcon_nic_data(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_mdio_lock_of_falcon_nic_data != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_mdio_lock_of_falcon_nic_data = 2;
  return;
}
}
int ldv_mutex_trylock_mdio_lock_of_falcon_nic_data(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
  if (ldv_mutex_mdio_lock_of_falcon_nic_data != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_mdio_lock_of_falcon_nic_data = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_mdio_lock_of_falcon_nic_data(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
  if (ldv_mutex_mdio_lock_of_falcon_nic_data != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_mdio_lock_of_falcon_nic_data = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_mdio_lock_of_falcon_nic_data(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_mdio_lock_of_falcon_nic_data == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_mdio_lock_of_falcon_nic_data(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_mdio_lock_of_falcon_nic_data != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_mdio_lock_of_falcon_nic_data = 1;
  return;
}
}
void ldv_usb_lock_device_mdio_lock_of_falcon_nic_data(void) 
{ 


  {
  ldv_mutex_lock_mdio_lock_of_falcon_nic_data((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_mdio_lock_of_falcon_nic_data(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_mdio_lock_of_falcon_nic_data((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_mdio_lock_of_falcon_nic_data(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_mdio_lock_of_falcon_nic_data((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_mdio_lock_of_falcon_nic_data(void) 
{ 


  {
  ldv_mutex_unlock_mdio_lock_of_falcon_nic_data((struct mutex *)0);
  return;
}
}
static int ldv_mutex_mutex_of_device  =    1;
int ldv_mutex_lock_interruptible_mutex_of_device(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_mutex_of_device != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_mutex_of_device = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_mutex_of_device(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_mutex_of_device != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_mutex_of_device = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_mutex_of_device(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_mutex_of_device != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_mutex_of_device = 2;
  return;
}
}
int ldv_mutex_trylock_mutex_of_device(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
  if (ldv_mutex_mutex_of_device != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_mutex_of_device = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_mutex_of_device(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
  if (ldv_mutex_mutex_of_device != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_mutex_of_device = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_mutex_of_device(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_mutex_of_device == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_mutex_of_device(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_mutex_of_device != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_mutex_of_device = 1;
  return;
}
}
void ldv_usb_lock_device_mutex_of_device(void) 
{ 


  {
  ldv_mutex_lock_mutex_of_device((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_mutex_of_device(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_mutex_of_device((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_mutex_of_device(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_mutex_of_device((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_mutex_of_device(void) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device((struct mutex *)0);
  return;
}
}
static int ldv_mutex_spi_lock_of_falcon_nic_data  =    1;
int ldv_mutex_lock_interruptible_spi_lock_of_falcon_nic_data(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_spi_lock_of_falcon_nic_data != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_spi_lock_of_falcon_nic_data = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_spi_lock_of_falcon_nic_data(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_spi_lock_of_falcon_nic_data != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_spi_lock_of_falcon_nic_data = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_spi_lock_of_falcon_nic_data(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_spi_lock_of_falcon_nic_data != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_spi_lock_of_falcon_nic_data = 2;
  return;
}
}
int ldv_mutex_trylock_spi_lock_of_falcon_nic_data(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
  if (ldv_mutex_spi_lock_of_falcon_nic_data != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_spi_lock_of_falcon_nic_data = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_spi_lock_of_falcon_nic_data(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
  if (ldv_mutex_spi_lock_of_falcon_nic_data != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_spi_lock_of_falcon_nic_data = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_spi_lock_of_falcon_nic_data(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_spi_lock_of_falcon_nic_data == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_spi_lock_of_falcon_nic_data(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_spi_lock_of_falcon_nic_data != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_spi_lock_of_falcon_nic_data = 1;
  return;
}
}
void ldv_usb_lock_device_spi_lock_of_falcon_nic_data(void) 
{ 


  {
  ldv_mutex_lock_spi_lock_of_falcon_nic_data((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_spi_lock_of_falcon_nic_data(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_spi_lock_of_falcon_nic_data((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_spi_lock_of_falcon_nic_data(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_spi_lock_of_falcon_nic_data((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_spi_lock_of_falcon_nic_data(void) 
{ 


  {
  ldv_mutex_unlock_spi_lock_of_falcon_nic_data((struct mutex *)0);
  return;
}
}
static int ldv_mutex_status_lock_of_siena_vf  =    1;
int ldv_mutex_lock_interruptible_status_lock_of_siena_vf(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_status_lock_of_siena_vf != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_status_lock_of_siena_vf = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_status_lock_of_siena_vf(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_status_lock_of_siena_vf != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_status_lock_of_siena_vf = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_status_lock_of_siena_vf(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_status_lock_of_siena_vf != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_status_lock_of_siena_vf = 2;
  return;
}
}
int ldv_mutex_trylock_status_lock_of_siena_vf(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
  if (ldv_mutex_status_lock_of_siena_vf != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_status_lock_of_siena_vf = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_status_lock_of_siena_vf(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
  if (ldv_mutex_status_lock_of_siena_vf != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_status_lock_of_siena_vf = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_status_lock_of_siena_vf(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_status_lock_of_siena_vf == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_status_lock_of_siena_vf(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_status_lock_of_siena_vf != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_status_lock_of_siena_vf = 1;
  return;
}
}
void ldv_usb_lock_device_status_lock_of_siena_vf(void) 
{ 


  {
  ldv_mutex_lock_status_lock_of_siena_vf((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_status_lock_of_siena_vf(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_status_lock_of_siena_vf((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_status_lock_of_siena_vf(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_status_lock_of_siena_vf((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_status_lock_of_siena_vf(void) 
{ 


  {
  ldv_mutex_unlock_status_lock_of_siena_vf((struct mutex *)0);
  return;
}
}
static int ldv_mutex_txq_lock_of_siena_vf  =    1;
int ldv_mutex_lock_interruptible_txq_lock_of_siena_vf(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_txq_lock_of_siena_vf != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_txq_lock_of_siena_vf = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_txq_lock_of_siena_vf(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_txq_lock_of_siena_vf != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_txq_lock_of_siena_vf = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_txq_lock_of_siena_vf(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_txq_lock_of_siena_vf != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_txq_lock_of_siena_vf = 2;
  return;
}
}
int ldv_mutex_trylock_txq_lock_of_siena_vf(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
  if (ldv_mutex_txq_lock_of_siena_vf != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_txq_lock_of_siena_vf = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_txq_lock_of_siena_vf(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
  if (ldv_mutex_txq_lock_of_siena_vf != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_txq_lock_of_siena_vf = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_txq_lock_of_siena_vf(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_txq_lock_of_siena_vf == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_txq_lock_of_siena_vf(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_txq_lock_of_siena_vf != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_txq_lock_of_siena_vf = 1;
  return;
}
}
void ldv_usb_lock_device_txq_lock_of_siena_vf(void) 
{ 


  {
  ldv_mutex_lock_txq_lock_of_siena_vf((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_txq_lock_of_siena_vf(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_txq_lock_of_siena_vf((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_txq_lock_of_siena_vf(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_txq_lock_of_siena_vf((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_txq_lock_of_siena_vf(void) 
{ 


  {
  ldv_mutex_unlock_txq_lock_of_siena_vf((struct mutex *)0);
  return;
}
}
static int ldv_mutex_update_lock_of_efx_mcdi_mon  =    1;
int ldv_mutex_lock_interruptible_update_lock_of_efx_mcdi_mon(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_update_lock_of_efx_mcdi_mon != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_update_lock_of_efx_mcdi_mon = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_update_lock_of_efx_mcdi_mon(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_update_lock_of_efx_mcdi_mon != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_update_lock_of_efx_mcdi_mon = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_update_lock_of_efx_mcdi_mon(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_update_lock_of_efx_mcdi_mon != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_update_lock_of_efx_mcdi_mon = 2;
  return;
}
}
int ldv_mutex_trylock_update_lock_of_efx_mcdi_mon(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
  if (ldv_mutex_update_lock_of_efx_mcdi_mon != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_update_lock_of_efx_mcdi_mon = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_update_lock_of_efx_mcdi_mon(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
  if (ldv_mutex_update_lock_of_efx_mcdi_mon != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_update_lock_of_efx_mcdi_mon = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_update_lock_of_efx_mcdi_mon(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_update_lock_of_efx_mcdi_mon == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_update_lock_of_efx_mcdi_mon(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_update_lock_of_efx_mcdi_mon != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_update_lock_of_efx_mcdi_mon = 1;
  return;
}
}
void ldv_usb_lock_device_update_lock_of_efx_mcdi_mon(void) 
{ 


  {
  ldv_mutex_lock_update_lock_of_efx_mcdi_mon((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_update_lock_of_efx_mcdi_mon(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_update_lock_of_efx_mcdi_mon((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_update_lock_of_efx_mcdi_mon(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_update_lock_of_efx_mcdi_mon((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_update_lock_of_efx_mcdi_mon(void) 
{ 


  {
  ldv_mutex_unlock_update_lock_of_efx_mcdi_mon((struct mutex *)0);
  return;
}
}
void ldv_check_final_state(void) 
{ 


  {
  if (ldv_mutex_i_mutex_of_inode != 1) {
    ldv_error();
  } else {

  }
  if (ldv_mutex_local_lock_of_siena_nic_data != 1) {
    ldv_error();
  } else {

  }
  if (ldv_mutex_lock != 1) {
    ldv_error();
  } else {

  }
  if (ldv_mutex_mac_lock_of_efx_nic != 1) {
    ldv_error();
  } else {

  }
  if (ldv_mutex_mdio_lock_of_falcon_nic_data != 1) {
    ldv_error();
  } else {

  }
  if (ldv_mutex_mutex_of_device != 1) {
    ldv_error();
  } else {

  }
  if (ldv_mutex_spi_lock_of_falcon_nic_data != 1) {
    ldv_error();
  } else {

  }
  if (ldv_mutex_status_lock_of_siena_vf != 1) {
    ldv_error();
  } else {

  }
  if (ldv_mutex_txq_lock_of_siena_vf != 1) {
    ldv_error();
  } else {

  }
  if (ldv_mutex_update_lock_of_efx_mcdi_mon != 1) {
    ldv_error();
  } else {

  }
  return;
}
}
#include "model/linux-4.2-rc1.tar.xz-32_7a-drivers--net--ethernet--sfc--sfc.ko-entry_point_true-unreach-call.cil.out.env.c"
#include <klee/klee.h>
#include "model/common.env.c"
