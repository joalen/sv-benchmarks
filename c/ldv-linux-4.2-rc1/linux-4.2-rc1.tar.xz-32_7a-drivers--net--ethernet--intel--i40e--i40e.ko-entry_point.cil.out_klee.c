extern void abort(void);
#include <assert.h>
void reach_error() { assert(0); }
/* Generated by CIL v. 1.5.1 */
/* print_CIL_Input is false */

typedef unsigned char __u8;
    klee_make_symbolic(&__u8, sizeof(char), "__u8");
typedef short __s16;
    klee_make_symbolic(&__s16, sizeof(short), "__s16");
typedef unsigned short __u16;
    klee_make_symbolic(&__u16, sizeof(short), "__u16");
typedef int __s32;
    klee_make_symbolic(&__s32, sizeof(int), "__s32");
typedef unsigned int __u32;
    klee_make_symbolic(&__u32, sizeof(int), "__u32");
typedef long long __s64;
    klee_make_symbolic(&__s64, sizeof(long), "__s64");
typedef unsigned long long __u64;
    klee_make_symbolic(&__u64, sizeof(long), "__u64");
typedef signed char s8;
    klee_make_symbolic(&s8, sizeof(char), "s8");
typedef unsigned char u8;
    klee_make_symbolic(&u8, sizeof(char), "u8");
typedef short s16;
    klee_make_symbolic(&s16, sizeof(short), "s16");
typedef unsigned short u16;
    klee_make_symbolic(&u16, sizeof(short), "u16");
typedef int s32;
    klee_make_symbolic(&s32, sizeof(int), "s32");
typedef unsigned int u32;
    klee_make_symbolic(&u32, sizeof(int), "u32");
typedef long long s64;
    klee_make_symbolic(&s64, sizeof(long), "s64");
typedef unsigned long long u64;
    klee_make_symbolic(&u64, sizeof(long), "u64");
typedef long __kernel_long_t;
    klee_make_symbolic(&__kernel_long_t, sizeof(long), "__kernel_long_t");
typedef unsigned long __kernel_ulong_t;
    klee_make_symbolic(&__kernel_ulong_t, sizeof(long), "__kernel_ulong_t");
typedef int __kernel_pid_t;
    klee_make_symbolic(&__kernel_pid_t, sizeof(int), "__kernel_pid_t");
typedef unsigned int __kernel_uid32_t;
    klee_make_symbolic(&__kernel_uid32_t, sizeof(int), "__kernel_uid32_t");
typedef unsigned int __kernel_gid32_t;
    klee_make_symbolic(&__kernel_gid32_t, sizeof(int), "__kernel_gid32_t");
typedef __kernel_ulong_t __kernel_size_t;
typedef __kernel_long_t __kernel_ssize_t;
typedef long long __kernel_loff_t;
    klee_make_symbolic(&__kernel_loff_t, sizeof(long), "__kernel_loff_t");
typedef __kernel_long_t __kernel_time_t;
typedef __kernel_long_t __kernel_clock_t;
typedef int __kernel_timer_t;
    klee_make_symbolic(&__kernel_timer_t, sizeof(int), "__kernel_timer_t");
typedef int __kernel_clockid_t;
    klee_make_symbolic(&__kernel_clockid_t, sizeof(int), "__kernel_clockid_t");
typedef __u16 __le16;
typedef __u16 __be16;
typedef __u32 __le32;
typedef __u32 __be32;
typedef __u64 __le64;
typedef __u32 __wsum;
struct kernel_symbol {
   unsigned long value ;
    klee_make_symbolic(&value, sizeof(long), "value");
   char const   *name ;
};
struct module;
typedef __u32 __kernel_dev_t;
typedef __kernel_dev_t dev_t;
typedef unsigned short umode_t;
    klee_make_symbolic(&umode_t, sizeof(short), "umode_t");
typedef __kernel_pid_t pid_t;
typedef __kernel_clockid_t clockid_t;
typedef _Bool bool;
typedef __kernel_uid32_t uid_t;
typedef __kernel_gid32_t gid_t;
typedef __kernel_loff_t loff_t;
typedef __kernel_size_t size_t;
typedef __kernel_ssize_t ssize_t;
typedef __kernel_time_t time_t;
typedef __s32 int32_t;
typedef __u8 uint8_t;
typedef __u32 uint32_t;
typedef __u64 uint64_t;
typedef unsigned long sector_t;
    klee_make_symbolic(&sector_t, sizeof(long), "sector_t");
typedef unsigned long blkcnt_t;
    klee_make_symbolic(&blkcnt_t, sizeof(long), "blkcnt_t");
typedef u64 dma_addr_t;
typedef unsigned int gfp_t;
    klee_make_symbolic(&gfp_t, sizeof(int), "gfp_t");
typedef unsigned int fmode_t;
    klee_make_symbolic(&fmode_t, sizeof(int), "fmode_t");
typedef unsigned int oom_flags_t;
    klee_make_symbolic(&oom_flags_t, sizeof(int), "oom_flags_t");
typedef u64 phys_addr_t;
typedef phys_addr_t resource_size_t;
struct __anonstruct_atomic_t_6 {
   int counter ;
    klee_make_symbolic(&counter, sizeof(int), "counter");
};
typedef struct __anonstruct_atomic_t_6 atomic_t;
struct __anonstruct_atomic64_t_7 {
   long counter ;
};
typedef struct __anonstruct_atomic64_t_7 atomic64_t;
struct list_head {
   struct list_head *next ;
   struct list_head *prev ;
};
struct hlist_node;
struct hlist_head {
   struct hlist_node *first ;
};
struct hlist_node {
   struct hlist_node *next ;
   struct hlist_node **pprev ;
};
struct callback_head {
   struct callback_head *next ;
   void (*func)(struct callback_head * ) ;
};
struct pt_regs {
   unsigned long r15 ;
    klee_make_symbolic(&r15, sizeof(long), "r15");
   unsigned long r14 ;
    klee_make_symbolic(&r14, sizeof(long), "r14");
   unsigned long r13 ;
    klee_make_symbolic(&r13, sizeof(long), "r13");
   unsigned long r12 ;
    klee_make_symbolic(&r12, sizeof(long), "r12");
   unsigned long bp ;
    klee_make_symbolic(&bp, sizeof(long), "bp");
   unsigned long bx ;
    klee_make_symbolic(&bx, sizeof(long), "bx");
   unsigned long r11 ;
    klee_make_symbolic(&r11, sizeof(long), "r11");
   unsigned long r10 ;
    klee_make_symbolic(&r10, sizeof(long), "r10");
   unsigned long r9 ;
    klee_make_symbolic(&r9, sizeof(long), "r9");
   unsigned long r8 ;
    klee_make_symbolic(&r8, sizeof(long), "r8");
   unsigned long ax ;
    klee_make_symbolic(&ax, sizeof(long), "ax");
   unsigned long cx ;
    klee_make_symbolic(&cx, sizeof(long), "cx");
   unsigned long dx ;
    klee_make_symbolic(&dx, sizeof(long), "dx");
   unsigned long si ;
    klee_make_symbolic(&si, sizeof(long), "si");
   unsigned long di ;
    klee_make_symbolic(&di, sizeof(long), "di");
   unsigned long orig_ax ;
    klee_make_symbolic(&orig_ax, sizeof(long), "orig_ax");
   unsigned long ip ;
    klee_make_symbolic(&ip, sizeof(long), "ip");
   unsigned long cs ;
    klee_make_symbolic(&cs, sizeof(long), "cs");
   unsigned long flags ;
    klee_make_symbolic(&flags, sizeof(long), "flags");
   unsigned long sp ;
    klee_make_symbolic(&sp, sizeof(long), "sp");
   unsigned long ss ;
    klee_make_symbolic(&ss, sizeof(long), "ss");
};
struct __anonstruct____missing_field_name_9 {
   unsigned int a ;
    klee_make_symbolic(&a, sizeof(int), "a");
   unsigned int b ;
    klee_make_symbolic(&b, sizeof(int), "b");
};
struct __anonstruct____missing_field_name_10 {
   u16 limit0 ;
   u16 base0 ;
   unsigned char base1 ;
    klee_make_symbolic(&base1, sizeof(char), "base1");
   unsigned char type : 4 ;
   unsigned char s : 1 ;
   unsigned char dpl : 2 ;
   unsigned char p : 1 ;
   unsigned char limit : 4 ;
   unsigned char avl : 1 ;
   unsigned char l : 1 ;
   unsigned char d : 1 ;
   unsigned char g : 1 ;
   unsigned char base2 ;
    klee_make_symbolic(&base2, sizeof(char), "base2");
};
union __anonunion____missing_field_name_8 {
   struct __anonstruct____missing_field_name_9 __annonCompField4 ;
   struct __anonstruct____missing_field_name_10 __annonCompField5 ;
};
struct desc_struct {
   union __anonunion____missing_field_name_8 __annonCompField6 ;
};
typedef unsigned long pteval_t;
    klee_make_symbolic(&pteval_t, sizeof(long), "pteval_t");
typedef unsigned long pgdval_t;
    klee_make_symbolic(&pgdval_t, sizeof(long), "pgdval_t");
typedef unsigned long pgprotval_t;
    klee_make_symbolic(&pgprotval_t, sizeof(long), "pgprotval_t");
struct __anonstruct_pte_t_11 {
   pteval_t pte ;
};
typedef struct __anonstruct_pte_t_11 pte_t;
struct pgprot {
   pgprotval_t pgprot ;
};
typedef struct pgprot pgprot_t;
struct __anonstruct_pgd_t_12 {
   pgdval_t pgd ;
};
typedef struct __anonstruct_pgd_t_12 pgd_t;
struct page;
typedef struct page *pgtable_t;
struct file;
struct seq_file;
struct thread_struct;
struct mm_struct;
struct task_struct;
struct cpumask;
struct qspinlock {
   atomic_t val ;
};
typedef struct qspinlock arch_spinlock_t;
struct qrwlock {
   atomic_t cnts ;
   arch_spinlock_t lock ;
};
typedef struct qrwlock arch_rwlock_t;
typedef void (*ctor_fn_t)(void);
struct _ddebug {
   char const   *modname ;
   char const   *function ;
   char const   *filename ;
   char const   *format ;
   unsigned int lineno : 18 ;
   unsigned char flags ;
};
struct device;
struct net_device;
struct file_operations;
struct completion;
enum system_states {
    SYSTEM_BOOTING = 0,
    SYSTEM_RUNNING = 1,
    SYSTEM_HALT = 2,
    SYSTEM_POWER_OFF = 3,
    SYSTEM_RESTART = 4
} ;
struct lockdep_map;
struct kernel_vm86_regs {
   struct pt_regs pt ;
   unsigned short es ;
    klee_make_symbolic(&es, sizeof(short), "es");
   unsigned short __esh ;
    klee_make_symbolic(&__esh, sizeof(short), "__esh");
   unsigned short ds ;
    klee_make_symbolic(&ds, sizeof(short), "ds");
   unsigned short __dsh ;
    klee_make_symbolic(&__dsh, sizeof(short), "__dsh");
   unsigned short fs ;
    klee_make_symbolic(&fs, sizeof(short), "fs");
   unsigned short __fsh ;
    klee_make_symbolic(&__fsh, sizeof(short), "__fsh");
   unsigned short gs ;
    klee_make_symbolic(&gs, sizeof(short), "gs");
   unsigned short __gsh ;
    klee_make_symbolic(&__gsh, sizeof(short), "__gsh");
};
union __anonunion____missing_field_name_15 {
   struct pt_regs *regs ;
   struct kernel_vm86_regs *vm86 ;
};
struct math_emu_info {
   long ___orig_eip ;
    klee_make_symbolic(&___orig_eip, sizeof(long), "___orig_eip");
   union __anonunion____missing_field_name_15 __annonCompField7 ;
};
struct bug_entry {
   int bug_addr_disp ;
    klee_make_symbolic(&bug_addr_disp, sizeof(int), "bug_addr_disp");
   int file_disp ;
    klee_make_symbolic(&file_disp, sizeof(int), "file_disp");
   unsigned short line ;
    klee_make_symbolic(&line, sizeof(short), "line");
   unsigned short flags ;
};
struct cpumask {
   unsigned long bits[128U] ;
};
typedef struct cpumask cpumask_t;
typedef struct cpumask *cpumask_var_t;
struct static_key;
struct fregs_state {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u32 status ;
};
struct __anonstruct____missing_field_name_25 {
   u64 rip ;
   u64 rdp ;
};
struct __anonstruct____missing_field_name_26 {
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
};
union __anonunion____missing_field_name_24 {
   struct __anonstruct____missing_field_name_25 __annonCompField11 ;
   struct __anonstruct____missing_field_name_26 __annonCompField12 ;
};
union __anonunion____missing_field_name_27 {
   u32 padding1[12U] ;
   u32 sw_reserved[12U] ;
};
struct fxregs_state {
   u16 cwd ;
   u16 swd ;
   u16 twd ;
   u16 fop ;
   union __anonunion____missing_field_name_24 __annonCompField13 ;
   u32 mxcsr ;
   u32 mxcsr_mask ;
   u32 st_space[32U] ;
   u32 xmm_space[64U] ;
   u32 padding[12U] ;
   union __anonunion____missing_field_name_27 __annonCompField14 ;
};
struct swregs_state {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u8 ftop ;
   u8 changed ;
   u8 lookahead ;
   u8 no_update ;
   u8 rm ;
   u8 alimit ;
   struct math_emu_info *info ;
   u32 entry_eip ;
};
struct xstate_header {
   u64 xfeatures ;
   u64 xcomp_bv ;
   u64 reserved[6U] ;
};
struct xregs_state {
   struct fxregs_state i387 ;
   struct xstate_header header ;
   u8 __reserved[464U] ;
};
union fpregs_state {
   struct fregs_state fsave ;
   struct fxregs_state fxsave ;
   struct swregs_state soft ;
   struct xregs_state xsave ;
};
struct fpu {
   union fpregs_state state ;
   unsigned int last_cpu ;
    klee_make_symbolic(&last_cpu, sizeof(int), "last_cpu");
   unsigned char fpstate_active ;
    klee_make_symbolic(&fpstate_active, sizeof(char), "fpstate_active");
   unsigned char fpregs_active ;
    klee_make_symbolic(&fpregs_active, sizeof(char), "fpregs_active");
   unsigned char counter ;
};
struct seq_operations;
struct perf_event;
struct thread_struct {
   struct desc_struct tls_array[3U] ;
   unsigned long sp0 ;
    klee_make_symbolic(&sp0, sizeof(long), "sp0");
   unsigned long sp ;
   unsigned short es ;
   unsigned short ds ;
   unsigned short fsindex ;
    klee_make_symbolic(&fsindex, sizeof(short), "fsindex");
   unsigned short gsindex ;
    klee_make_symbolic(&gsindex, sizeof(short), "gsindex");
   unsigned long fs ;
   unsigned long gs ;
   struct fpu fpu ;
   struct perf_event *ptrace_bps[4U] ;
   unsigned long debugreg6 ;
    klee_make_symbolic(&debugreg6, sizeof(long), "debugreg6");
   unsigned long ptrace_dr7 ;
    klee_make_symbolic(&ptrace_dr7, sizeof(long), "ptrace_dr7");
   unsigned long cr2 ;
    klee_make_symbolic(&cr2, sizeof(long), "cr2");
   unsigned long trap_nr ;
    klee_make_symbolic(&trap_nr, sizeof(long), "trap_nr");
   unsigned long error_code ;
    klee_make_symbolic(&error_code, sizeof(long), "error_code");
   unsigned long *io_bitmap_ptr ;
   unsigned long iopl ;
    klee_make_symbolic(&iopl, sizeof(long), "iopl");
   unsigned int io_bitmap_max ;
    klee_make_symbolic(&io_bitmap_max, sizeof(int), "io_bitmap_max");
};
typedef atomic64_t atomic_long_t;
struct stack_trace {
   unsigned int nr_entries ;
    klee_make_symbolic(&nr_entries, sizeof(int), "nr_entries");
   unsigned int max_entries ;
    klee_make_symbolic(&max_entries, sizeof(int), "max_entries");
   unsigned long *entries ;
   int skip ;
    klee_make_symbolic(&skip, sizeof(int), "skip");
};
struct lockdep_subclass_key {
   char __one_byte ;
    klee_make_symbolic(&__one_byte, sizeof(char), "__one_byte");
};
struct lock_class_key {
   struct lockdep_subclass_key subkeys[8U] ;
};
struct lock_class {
   struct list_head hash_entry ;
   struct list_head lock_entry ;
   struct lockdep_subclass_key *key ;
   unsigned int subclass ;
    klee_make_symbolic(&subclass, sizeof(int), "subclass");
   unsigned int dep_gen_id ;
    klee_make_symbolic(&dep_gen_id, sizeof(int), "dep_gen_id");
   unsigned long usage_mask ;
    klee_make_symbolic(&usage_mask, sizeof(long), "usage_mask");
   struct stack_trace usage_traces[13U] ;
   struct list_head locks_after ;
   struct list_head locks_before ;
   unsigned int version ;
    klee_make_symbolic(&version, sizeof(int), "version");
   unsigned long ops ;
    klee_make_symbolic(&ops, sizeof(long), "ops");
   char const   *name ;
   int name_version ;
    klee_make_symbolic(&name_version, sizeof(int), "name_version");
   unsigned long contention_point[4U] ;
   unsigned long contending_point[4U] ;
};
struct lockdep_map {
   struct lock_class_key *key ;
   struct lock_class *class_cache[2U] ;
   char const   *name ;
   int cpu ;
    klee_make_symbolic(&cpu, sizeof(int), "cpu");
   unsigned long ip ;
};
struct held_lock {
   u64 prev_chain_key ;
   unsigned long acquire_ip ;
    klee_make_symbolic(&acquire_ip, sizeof(long), "acquire_ip");
   struct lockdep_map *instance ;
   struct lockdep_map *nest_lock ;
   u64 waittime_stamp ;
   u64 holdtime_stamp ;
   unsigned short class_idx : 13 ;
   unsigned char irq_context : 2 ;
   unsigned char trylock : 1 ;
   unsigned char read : 2 ;
   unsigned char check : 1 ;
   unsigned char hardirqs_off : 1 ;
   unsigned short references : 12 ;
   unsigned int pin_count ;
    klee_make_symbolic(&pin_count, sizeof(int), "pin_count");
};
struct raw_spinlock {
   arch_spinlock_t raw_lock ;
   unsigned int magic ;
    klee_make_symbolic(&magic, sizeof(int), "magic");
   unsigned int owner_cpu ;
    klee_make_symbolic(&owner_cpu, sizeof(int), "owner_cpu");
   void *owner ;
   struct lockdep_map dep_map ;
};
typedef struct raw_spinlock raw_spinlock_t;
struct __anonstruct____missing_field_name_31 {
   u8 __padding[24U] ;
   struct lockdep_map dep_map ;
};
union __anonunion____missing_field_name_30 {
   struct raw_spinlock rlock ;
   struct __anonstruct____missing_field_name_31 __annonCompField16 ;
};
struct spinlock {
   union __anonunion____missing_field_name_30 __annonCompField17 ;
};
typedef struct spinlock spinlock_t;
struct __anonstruct_rwlock_t_32 {
   arch_rwlock_t raw_lock ;
   unsigned int magic ;
   unsigned int owner_cpu ;
   void *owner ;
   struct lockdep_map dep_map ;
};
typedef struct __anonstruct_rwlock_t_32 rwlock_t;
struct optimistic_spin_queue {
   atomic_t tail ;
};
struct mutex {
   atomic_t count ;
   spinlock_t wait_lock ;
   struct list_head wait_list ;
   struct task_struct *owner ;
   void *magic ;
   struct lockdep_map dep_map ;
};
struct mutex_waiter {
   struct list_head list ;
   struct task_struct *task ;
   void *magic ;
};
struct timespec;
struct compat_timespec;
struct __anonstruct_futex_34 {
   u32 *uaddr ;
   u32 val ;
   u32 flags ;
   u32 bitset ;
   u64 time ;
   u32 *uaddr2 ;
};
struct __anonstruct_nanosleep_35 {
   clockid_t clockid ;
   struct timespec *rmtp ;
   struct compat_timespec *compat_rmtp ;
   u64 expires ;
};
struct pollfd;
struct __anonstruct_poll_36 {
   struct pollfd *ufds ;
   int nfds ;
    klee_make_symbolic(&nfds, sizeof(int), "nfds");
   int has_timeout ;
    klee_make_symbolic(&has_timeout, sizeof(int), "has_timeout");
   unsigned long tv_sec ;
    klee_make_symbolic(&tv_sec, sizeof(long), "tv_sec");
   unsigned long tv_nsec ;
    klee_make_symbolic(&tv_nsec, sizeof(long), "tv_nsec");
};
union __anonunion____missing_field_name_33 {
   struct __anonstruct_futex_34 futex ;
   struct __anonstruct_nanosleep_35 nanosleep ;
   struct __anonstruct_poll_36 poll ;
};
struct restart_block {
   long (*fn)(struct restart_block * ) ;
   union __anonunion____missing_field_name_33 __annonCompField18 ;
};
typedef int pao_T__;
    klee_make_symbolic(&pao_T__, sizeof(int), "pao_T__");
typedef int pao_T_____0;
    klee_make_symbolic(&pao_T_____0, sizeof(int), "pao_T_____0");
struct static_key {
   atomic_t enabled ;
};
struct seqcount {
   unsigned int sequence ;
    klee_make_symbolic(&sequence, sizeof(int), "sequence");
   struct lockdep_map dep_map ;
};
typedef struct seqcount seqcount_t;
struct __anonstruct_seqlock_t_45 {
   struct seqcount seqcount ;
   spinlock_t lock ;
};
typedef struct __anonstruct_seqlock_t_45 seqlock_t;
struct timespec {
   __kernel_time_t tv_sec ;
   long tv_nsec ;
};
union ktime {
   s64 tv64 ;
};
typedef union ktime ktime_t;
struct timer_list {
   struct hlist_node entry ;
   unsigned long expires ;
    klee_make_symbolic(&expires, sizeof(long), "expires");
   void (*function)(unsigned long  ) ;
   unsigned long data ;
    klee_make_symbolic(&data, sizeof(long), "data");
   u32 flags ;
   int slack ;
    klee_make_symbolic(&slack, sizeof(int), "slack");
   int start_pid ;
    klee_make_symbolic(&start_pid, sizeof(int), "start_pid");
   void *start_site ;
   char start_comm[16U] ;
   struct lockdep_map lockdep_map ;
};
struct hrtimer;
enum hrtimer_restart;
struct __wait_queue_head {
   spinlock_t lock ;
   struct list_head task_list ;
};
typedef struct __wait_queue_head wait_queue_head_t;
struct completion {
   unsigned int done ;
    klee_make_symbolic(&done, sizeof(int), "done");
   wait_queue_head_t wait ;
};
struct notifier_block;
struct rb_node {
   unsigned long __rb_parent_color ;
    klee_make_symbolic(&__rb_parent_color, sizeof(long), "__rb_parent_color");
   struct rb_node *rb_right ;
   struct rb_node *rb_left ;
};
struct rb_root {
   struct rb_node *rb_node ;
};
struct ctl_table;
struct nsproxy;
struct ctl_table_root;
struct ctl_table_header;
struct ctl_dir;
typedef int proc_handler(struct ctl_table * , int  , void * , size_t * , loff_t * );
struct ctl_table_poll {
   atomic_t event ;
   wait_queue_head_t wait ;
};
struct ctl_table {
   char const   *procname ;
   void *data ;
   int maxlen ;
    klee_make_symbolic(&maxlen, sizeof(int), "maxlen");
   umode_t mode ;
   struct ctl_table *child ;
   proc_handler *proc_handler ;
   struct ctl_table_poll *poll ;
   void *extra1 ;
   void *extra2 ;
};
struct ctl_node {
   struct rb_node node ;
   struct ctl_table_header *header ;
};
struct __anonstruct____missing_field_name_47 {
   struct ctl_table *ctl_table ;
   int used ;
    klee_make_symbolic(&used, sizeof(int), "used");
   int count ;
    klee_make_symbolic(&count, sizeof(int), "count");
   int nreg ;
    klee_make_symbolic(&nreg, sizeof(int), "nreg");
};
union __anonunion____missing_field_name_46 {
   struct __anonstruct____missing_field_name_47 __annonCompField19 ;
   struct callback_head rcu ;
};
struct ctl_table_set;
struct ctl_table_header {
   union __anonunion____missing_field_name_46 __annonCompField20 ;
   struct completion *unregistering ;
   struct ctl_table *ctl_table_arg ;
   struct ctl_table_root *root ;
   struct ctl_table_set *set ;
   struct ctl_dir *parent ;
   struct ctl_node *node ;
};
struct ctl_dir {
   struct ctl_table_header header ;
   struct rb_root root ;
};
struct ctl_table_set {
   int (*is_seen)(struct ctl_table_set * ) ;
   struct ctl_dir dir ;
};
struct ctl_table_root {
   struct ctl_table_set default_set ;
   struct ctl_table_set *(*lookup)(struct ctl_table_root * , struct nsproxy * ) ;
   int (*permissions)(struct ctl_table_header * , struct ctl_table * ) ;
};
struct workqueue_struct;
struct work_struct;
struct work_struct {
   atomic_long_t data ;
   struct list_head entry ;
   void (*func)(struct work_struct * ) ;
   struct lockdep_map lockdep_map ;
};
struct delayed_work {
   struct work_struct work ;
   struct timer_list timer ;
   struct workqueue_struct *wq ;
   int cpu ;
};
struct vm_area_struct;
struct __anonstruct_nodemask_t_48 {
   unsigned long bits[16U] ;
};
typedef struct __anonstruct_nodemask_t_48 nodemask_t;
struct rw_semaphore;
struct rw_semaphore {
   long count ;
   struct list_head wait_list ;
   raw_spinlock_t wait_lock ;
   struct optimistic_spin_queue osq ;
   struct task_struct *owner ;
   struct lockdep_map dep_map ;
};
struct notifier_block {
   int (*notifier_call)(struct notifier_block * , unsigned long  , void * ) ;
   struct notifier_block *next ;
   int priority ;
    klee_make_symbolic(&priority, sizeof(int), "priority");
};
struct resource {
   resource_size_t start ;
   resource_size_t end ;
   char const   *name ;
   unsigned long flags ;
   struct resource *parent ;
   struct resource *sibling ;
   struct resource *child ;
};
struct pci_dev;
struct pm_message {
   int event ;
    klee_make_symbolic(&event, sizeof(int), "event");
};
typedef struct pm_message pm_message_t;
struct dev_pm_ops {
   int (*prepare)(struct device * ) ;
   void (*complete)(struct device * ) ;
   int (*suspend)(struct device * ) ;
   int (*resume)(struct device * ) ;
   int (*freeze)(struct device * ) ;
   int (*thaw)(struct device * ) ;
   int (*poweroff)(struct device * ) ;
   int (*restore)(struct device * ) ;
   int (*suspend_late)(struct device * ) ;
   int (*resume_early)(struct device * ) ;
   int (*freeze_late)(struct device * ) ;
   int (*thaw_early)(struct device * ) ;
   int (*poweroff_late)(struct device * ) ;
   int (*restore_early)(struct device * ) ;
   int (*suspend_noirq)(struct device * ) ;
   int (*resume_noirq)(struct device * ) ;
   int (*freeze_noirq)(struct device * ) ;
   int (*thaw_noirq)(struct device * ) ;
   int (*poweroff_noirq)(struct device * ) ;
   int (*restore_noirq)(struct device * ) ;
   int (*runtime_suspend)(struct device * ) ;
   int (*runtime_resume)(struct device * ) ;
   int (*runtime_idle)(struct device * ) ;
};
enum rpm_status {
    RPM_ACTIVE = 0,
    RPM_RESUMING = 1,
    RPM_SUSPENDED = 2,
    RPM_SUSPENDING = 3
} ;
enum rpm_request {
    RPM_REQ_NONE = 0,
    RPM_REQ_IDLE = 1,
    RPM_REQ_SUSPEND = 2,
    RPM_REQ_AUTOSUSPEND = 3,
    RPM_REQ_RESUME = 4
} ;
struct wakeup_source;
struct wake_irq;
struct pm_subsys_data {
   spinlock_t lock ;
   unsigned int refcount ;
    klee_make_symbolic(&refcount, sizeof(int), "refcount");
   struct list_head clock_list ;
};
struct dev_pm_qos;
struct dev_pm_info {
   pm_message_t power_state ;
   unsigned char can_wakeup : 1 ;
   unsigned char async_suspend : 1 ;
   bool is_prepared ;
   bool is_suspended ;
   bool is_noirq_suspended ;
   bool is_late_suspended ;
   bool ignore_children ;
   bool early_init ;
   bool direct_complete ;
   spinlock_t lock ;
   struct list_head entry ;
   struct completion completion ;
   struct wakeup_source *wakeup ;
   bool wakeup_path ;
   bool syscore ;
   struct timer_list suspend_timer ;
   unsigned long timer_expires ;
    klee_make_symbolic(&timer_expires, sizeof(long), "timer_expires");
   struct work_struct work ;
   wait_queue_head_t wait_queue ;
   struct wake_irq *wakeirq ;
   atomic_t usage_count ;
   atomic_t child_count ;
   unsigned char disable_depth : 3 ;
   unsigned char idle_notification : 1 ;
   unsigned char request_pending : 1 ;
   unsigned char deferred_resume : 1 ;
   unsigned char run_wake : 1 ;
   unsigned char runtime_auto : 1 ;
   unsigned char no_callbacks : 1 ;
   unsigned char irq_safe : 1 ;
   unsigned char use_autosuspend : 1 ;
   unsigned char timer_autosuspends : 1 ;
   unsigned char memalloc_noio : 1 ;
   enum rpm_request request ;
   enum rpm_status runtime_status ;
   int runtime_error ;
    klee_make_symbolic(&runtime_error, sizeof(int), "runtime_error");
   int autosuspend_delay ;
    klee_make_symbolic(&autosuspend_delay, sizeof(int), "autosuspend_delay");
   unsigned long last_busy ;
    klee_make_symbolic(&last_busy, sizeof(long), "last_busy");
   unsigned long active_jiffies ;
    klee_make_symbolic(&active_jiffies, sizeof(long), "active_jiffies");
   unsigned long suspended_jiffies ;
    klee_make_symbolic(&suspended_jiffies, sizeof(long), "suspended_jiffies");
   unsigned long accounting_timestamp ;
    klee_make_symbolic(&accounting_timestamp, sizeof(long), "accounting_timestamp");
   struct pm_subsys_data *subsys_data ;
   void (*set_latency_tolerance)(struct device * , s32  ) ;
   struct dev_pm_qos *qos ;
};
struct dev_pm_domain {
   struct dev_pm_ops ops ;
   void (*detach)(struct device * , bool  ) ;
   int (*activate)(struct device * ) ;
   void (*sync)(struct device * ) ;
   void (*dismiss)(struct device * ) ;
};
struct pci_bus;
struct __anonstruct_mm_context_t_113 {
   void *ldt ;
   int size ;
    klee_make_symbolic(&size, sizeof(int), "size");
   unsigned short ia32_compat ;
    klee_make_symbolic(&ia32_compat, sizeof(short), "ia32_compat");
   struct mutex lock ;
   void *vdso ;
   atomic_t perf_rdpmc_allowed ;
};
typedef struct __anonstruct_mm_context_t_113 mm_context_t;
struct bio_vec;
struct llist_node;
struct llist_node {
   struct llist_node *next ;
};
struct kmem_cache;
struct kernel_cap_struct {
   __u32 cap[2U] ;
};
typedef struct kernel_cap_struct kernel_cap_t;
struct inode;
struct dentry;
struct user_namespace;
struct plist_node {
   int prio ;
    klee_make_symbolic(&prio, sizeof(int), "prio");
   struct list_head prio_list ;
   struct list_head node_list ;
};
struct arch_uprobe_task {
   unsigned long saved_scratch_register ;
    klee_make_symbolic(&saved_scratch_register, sizeof(long), "saved_scratch_register");
   unsigned int saved_trap_nr ;
    klee_make_symbolic(&saved_trap_nr, sizeof(int), "saved_trap_nr");
   unsigned int saved_tf ;
    klee_make_symbolic(&saved_tf, sizeof(int), "saved_tf");
};
enum uprobe_task_state {
    UTASK_RUNNING = 0,
    UTASK_SSTEP = 1,
    UTASK_SSTEP_ACK = 2,
    UTASK_SSTEP_TRAPPED = 3
} ;
struct __anonstruct____missing_field_name_146 {
   struct arch_uprobe_task autask ;
   unsigned long vaddr ;
    klee_make_symbolic(&vaddr, sizeof(long), "vaddr");
};
struct __anonstruct____missing_field_name_147 {
   struct callback_head dup_xol_work ;
   unsigned long dup_xol_addr ;
    klee_make_symbolic(&dup_xol_addr, sizeof(long), "dup_xol_addr");
};
union __anonunion____missing_field_name_145 {
   struct __anonstruct____missing_field_name_146 __annonCompField33 ;
   struct __anonstruct____missing_field_name_147 __annonCompField34 ;
};
struct uprobe;
struct return_instance;
struct uprobe_task {
   enum uprobe_task_state state ;
   union __anonunion____missing_field_name_145 __annonCompField35 ;
   struct uprobe *active_uprobe ;
   unsigned long xol_vaddr ;
    klee_make_symbolic(&xol_vaddr, sizeof(long), "xol_vaddr");
   struct return_instance *return_instances ;
   unsigned int depth ;
    klee_make_symbolic(&depth, sizeof(int), "depth");
};
struct xol_area;
struct uprobes_state {
   struct xol_area *xol_area ;
};
struct address_space;
struct mem_cgroup;
typedef void compound_page_dtor(struct page * );
union __anonunion____missing_field_name_148 {
   struct address_space *mapping ;
   void *s_mem ;
};
union __anonunion____missing_field_name_150 {
   unsigned long index ;
    klee_make_symbolic(&index, sizeof(long), "index");
   void *freelist ;
   bool pfmemalloc ;
};
struct __anonstruct____missing_field_name_154 {
   unsigned short inuse ;
    klee_make_symbolic(&inuse, sizeof(short), "inuse");
   unsigned short objects : 15 ;
   unsigned char frozen : 1 ;
};
union __anonunion____missing_field_name_153 {
   atomic_t _mapcount ;
   struct __anonstruct____missing_field_name_154 __annonCompField38 ;
   int units ;
    klee_make_symbolic(&units, sizeof(int), "units");
};
struct __anonstruct____missing_field_name_152 {
   union __anonunion____missing_field_name_153 __annonCompField39 ;
   atomic_t _count ;
};
union __anonunion____missing_field_name_151 {
   unsigned long counters ;
    klee_make_symbolic(&counters, sizeof(long), "counters");
   struct __anonstruct____missing_field_name_152 __annonCompField40 ;
   unsigned int active ;
    klee_make_symbolic(&active, sizeof(int), "active");
};
struct __anonstruct____missing_field_name_149 {
   union __anonunion____missing_field_name_150 __annonCompField37 ;
   union __anonunion____missing_field_name_151 __annonCompField41 ;
};
struct __anonstruct____missing_field_name_156 {
   struct page *next ;
   int pages ;
    klee_make_symbolic(&pages, sizeof(int), "pages");
   int pobjects ;
    klee_make_symbolic(&pobjects, sizeof(int), "pobjects");
};
struct slab;
struct __anonstruct____missing_field_name_157 {
   compound_page_dtor *compound_dtor ;
   unsigned long compound_order ;
    klee_make_symbolic(&compound_order, sizeof(long), "compound_order");
};
union __anonunion____missing_field_name_155 {
   struct list_head lru ;
   struct __anonstruct____missing_field_name_156 __annonCompField43 ;
   struct slab *slab_page ;
   struct callback_head callback_head ;
   struct __anonstruct____missing_field_name_157 __annonCompField44 ;
   pgtable_t pmd_huge_pte ;
};
union __anonunion____missing_field_name_158 {
   unsigned long private ;
    klee_make_symbolic(&private, sizeof(long), "private");
   spinlock_t *ptl ;
   struct kmem_cache *slab_cache ;
   struct page *first_page ;
};
struct page {
   unsigned long flags ;
   union __anonunion____missing_field_name_148 __annonCompField36 ;
   struct __anonstruct____missing_field_name_149 __annonCompField42 ;
   union __anonunion____missing_field_name_155 __annonCompField45 ;
   union __anonunion____missing_field_name_158 __annonCompField46 ;
   struct mem_cgroup *mem_cgroup ;
};
struct page_frag {
   struct page *page ;
   __u32 offset ;
   __u32 size ;
};
struct __anonstruct_shared_159 {
   struct rb_node rb ;
   unsigned long rb_subtree_last ;
    klee_make_symbolic(&rb_subtree_last, sizeof(long), "rb_subtree_last");
};
struct anon_vma;
struct vm_operations_struct;
struct mempolicy;
struct vm_area_struct {
   unsigned long vm_start ;
    klee_make_symbolic(&vm_start, sizeof(long), "vm_start");
   unsigned long vm_end ;
    klee_make_symbolic(&vm_end, sizeof(long), "vm_end");
   struct vm_area_struct *vm_next ;
   struct vm_area_struct *vm_prev ;
   struct rb_node vm_rb ;
   unsigned long rb_subtree_gap ;
    klee_make_symbolic(&rb_subtree_gap, sizeof(long), "rb_subtree_gap");
   struct mm_struct *vm_mm ;
   pgprot_t vm_page_prot ;
   unsigned long vm_flags ;
    klee_make_symbolic(&vm_flags, sizeof(long), "vm_flags");
   struct __anonstruct_shared_159 shared ;
   struct list_head anon_vma_chain ;
   struct anon_vma *anon_vma ;
   struct vm_operations_struct  const  *vm_ops ;
   unsigned long vm_pgoff ;
    klee_make_symbolic(&vm_pgoff, sizeof(long), "vm_pgoff");
   struct file *vm_file ;
   void *vm_private_data ;
   struct mempolicy *vm_policy ;
};
struct core_thread {
   struct task_struct *task ;
   struct core_thread *next ;
};
struct core_state {
   atomic_t nr_threads ;
   struct core_thread dumper ;
   struct completion startup ;
};
struct task_rss_stat {
   int events ;
    klee_make_symbolic(&events, sizeof(int), "events");
   int count[3U] ;
};
struct mm_rss_stat {
   atomic_long_t count[3U] ;
};
struct kioctx_table;
struct linux_binfmt;
struct mmu_notifier_mm;
struct mm_struct {
   struct vm_area_struct *mmap ;
   struct rb_root mm_rb ;
   u32 vmacache_seqnum ;
   unsigned long (*get_unmapped_area)(struct file * , unsigned long  , unsigned long  ,
                                      unsigned long  , unsigned long  ) ;
   unsigned long mmap_base ;
    klee_make_symbolic(&mmap_base, sizeof(long), "mmap_base");
   unsigned long mmap_legacy_base ;
    klee_make_symbolic(&mmap_legacy_base, sizeof(long), "mmap_legacy_base");
   unsigned long task_size ;
    klee_make_symbolic(&task_size, sizeof(long), "task_size");
   unsigned long highest_vm_end ;
    klee_make_symbolic(&highest_vm_end, sizeof(long), "highest_vm_end");
   pgd_t *pgd ;
   atomic_t mm_users ;
   atomic_t mm_count ;
   atomic_long_t nr_ptes ;
   atomic_long_t nr_pmds ;
   int map_count ;
    klee_make_symbolic(&map_count, sizeof(int), "map_count");
   spinlock_t page_table_lock ;
   struct rw_semaphore mmap_sem ;
   struct list_head mmlist ;
   unsigned long hiwater_rss ;
    klee_make_symbolic(&hiwater_rss, sizeof(long), "hiwater_rss");
   unsigned long hiwater_vm ;
    klee_make_symbolic(&hiwater_vm, sizeof(long), "hiwater_vm");
   unsigned long total_vm ;
    klee_make_symbolic(&total_vm, sizeof(long), "total_vm");
   unsigned long locked_vm ;
    klee_make_symbolic(&locked_vm, sizeof(long), "locked_vm");
   unsigned long pinned_vm ;
    klee_make_symbolic(&pinned_vm, sizeof(long), "pinned_vm");
   unsigned long shared_vm ;
    klee_make_symbolic(&shared_vm, sizeof(long), "shared_vm");
   unsigned long exec_vm ;
    klee_make_symbolic(&exec_vm, sizeof(long), "exec_vm");
   unsigned long stack_vm ;
    klee_make_symbolic(&stack_vm, sizeof(long), "stack_vm");
   unsigned long def_flags ;
    klee_make_symbolic(&def_flags, sizeof(long), "def_flags");
   unsigned long start_code ;
    klee_make_symbolic(&start_code, sizeof(long), "start_code");
   unsigned long end_code ;
    klee_make_symbolic(&end_code, sizeof(long), "end_code");
   unsigned long start_data ;
    klee_make_symbolic(&start_data, sizeof(long), "start_data");
   unsigned long end_data ;
    klee_make_symbolic(&end_data, sizeof(long), "end_data");
   unsigned long start_brk ;
    klee_make_symbolic(&start_brk, sizeof(long), "start_brk");
   unsigned long brk ;
    klee_make_symbolic(&brk, sizeof(long), "brk");
   unsigned long start_stack ;
    klee_make_symbolic(&start_stack, sizeof(long), "start_stack");
   unsigned long arg_start ;
    klee_make_symbolic(&arg_start, sizeof(long), "arg_start");
   unsigned long arg_end ;
    klee_make_symbolic(&arg_end, sizeof(long), "arg_end");
   unsigned long env_start ;
    klee_make_symbolic(&env_start, sizeof(long), "env_start");
   unsigned long env_end ;
    klee_make_symbolic(&env_end, sizeof(long), "env_end");
   unsigned long saved_auxv[46U] ;
   struct mm_rss_stat rss_stat ;
   struct linux_binfmt *binfmt ;
   cpumask_var_t cpu_vm_mask_var ;
   mm_context_t context ;
   unsigned long flags ;
   struct core_state *core_state ;
   spinlock_t ioctx_lock ;
   struct kioctx_table *ioctx_table ;
   struct task_struct *owner ;
   struct file *exe_file ;
   struct mmu_notifier_mm *mmu_notifier_mm ;
   struct cpumask cpumask_allocation ;
   unsigned long numa_next_scan ;
    klee_make_symbolic(&numa_next_scan, sizeof(long), "numa_next_scan");
   unsigned long numa_scan_offset ;
    klee_make_symbolic(&numa_scan_offset, sizeof(long), "numa_scan_offset");
   int numa_scan_seq ;
    klee_make_symbolic(&numa_scan_seq, sizeof(int), "numa_scan_seq");
   bool tlb_flush_pending ;
   struct uprobes_state uprobes_state ;
   void *bd_addr ;
};
typedef unsigned long cputime_t;
    klee_make_symbolic(&cputime_t, sizeof(long), "cputime_t");
struct __anonstruct_kuid_t_161 {
   uid_t val ;
};
typedef struct __anonstruct_kuid_t_161 kuid_t;
struct __anonstruct_kgid_t_162 {
   gid_t val ;
};
typedef struct __anonstruct_kgid_t_162 kgid_t;
struct sem_undo_list;
struct sysv_sem {
   struct sem_undo_list *undo_list ;
};
struct user_struct;
struct sysv_shm {
   struct list_head shm_clist ;
};
struct __anonstruct_sigset_t_163 {
   unsigned long sig[1U] ;
};
typedef struct __anonstruct_sigset_t_163 sigset_t;
struct siginfo;
typedef void __signalfn_t(int  );
typedef __signalfn_t *__sighandler_t;
typedef void __restorefn_t(void);
typedef __restorefn_t *__sigrestore_t;
union sigval {
   int sival_int ;
    klee_make_symbolic(&sival_int, sizeof(int), "sival_int");
   void *sival_ptr ;
};
typedef union sigval sigval_t;
struct __anonstruct__kill_165 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
};
struct __anonstruct__timer_166 {
   __kernel_timer_t _tid ;
   int _overrun ;
    klee_make_symbolic(&_overrun, sizeof(int), "_overrun");
   char _pad[0U] ;
   sigval_t _sigval ;
   int _sys_private ;
    klee_make_symbolic(&_sys_private, sizeof(int), "_sys_private");
};
struct __anonstruct__rt_167 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
   sigval_t _sigval ;
};
struct __anonstruct__sigchld_168 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
   int _status ;
    klee_make_symbolic(&_status, sizeof(int), "_status");
   __kernel_clock_t _utime ;
   __kernel_clock_t _stime ;
};
struct __anonstruct__addr_bnd_170 {
   void *_lower ;
   void *_upper ;
};
struct __anonstruct__sigfault_169 {
   void *_addr ;
   short _addr_lsb ;
    klee_make_symbolic(&_addr_lsb, sizeof(short), "_addr_lsb");
   struct __anonstruct__addr_bnd_170 _addr_bnd ;
};
struct __anonstruct__sigpoll_171 {
   long _band ;
    klee_make_symbolic(&_band, sizeof(long), "_band");
   int _fd ;
    klee_make_symbolic(&_fd, sizeof(int), "_fd");
};
struct __anonstruct__sigsys_172 {
   void *_call_addr ;
   int _syscall ;
    klee_make_symbolic(&_syscall, sizeof(int), "_syscall");
   unsigned int _arch ;
    klee_make_symbolic(&_arch, sizeof(int), "_arch");
};
union __anonunion__sifields_164 {
   int _pad[28U] ;
   struct __anonstruct__kill_165 _kill ;
   struct __anonstruct__timer_166 _timer ;
   struct __anonstruct__rt_167 _rt ;
   struct __anonstruct__sigchld_168 _sigchld ;
   struct __anonstruct__sigfault_169 _sigfault ;
   struct __anonstruct__sigpoll_171 _sigpoll ;
   struct __anonstruct__sigsys_172 _sigsys ;
};
struct siginfo {
   int si_signo ;
    klee_make_symbolic(&si_signo, sizeof(int), "si_signo");
   int si_errno ;
    klee_make_symbolic(&si_errno, sizeof(int), "si_errno");
   int si_code ;
    klee_make_symbolic(&si_code, sizeof(int), "si_code");
   union __anonunion__sifields_164 _sifields ;
};
typedef struct siginfo siginfo_t;
struct sigpending {
   struct list_head list ;
   sigset_t signal ;
};
struct sigaction {
   __sighandler_t sa_handler ;
   unsigned long sa_flags ;
    klee_make_symbolic(&sa_flags, sizeof(long), "sa_flags");
   __sigrestore_t sa_restorer ;
   sigset_t sa_mask ;
};
struct k_sigaction {
   struct sigaction sa ;
};
enum pid_type {
    PIDTYPE_PID = 0,
    PIDTYPE_PGID = 1,
    PIDTYPE_SID = 2,
    PIDTYPE_MAX = 3
} ;
struct pid_namespace;
struct upid {
   int nr ;
    klee_make_symbolic(&nr, sizeof(int), "nr");
   struct pid_namespace *ns ;
   struct hlist_node pid_chain ;
};
struct pid {
   atomic_t count ;
   unsigned int level ;
    klee_make_symbolic(&level, sizeof(int), "level");
   struct hlist_head tasks[3U] ;
   struct callback_head rcu ;
   struct upid numbers[1U] ;
};
struct pid_link {
   struct hlist_node node ;
   struct pid *pid ;
};
struct percpu_counter {
   raw_spinlock_t lock ;
   s64 count ;
   struct list_head list ;
   s32 *counters ;
};
struct seccomp_filter;
struct seccomp {
   int mode ;
    klee_make_symbolic(&mode, sizeof(int), "mode");
   struct seccomp_filter *filter ;
};
struct rt_mutex_waiter;
struct rlimit {
   __kernel_ulong_t rlim_cur ;
   __kernel_ulong_t rlim_max ;
};
struct timerqueue_node {
   struct rb_node node ;
   ktime_t expires ;
};
struct timerqueue_head {
   struct rb_root head ;
   struct timerqueue_node *next ;
};
struct hrtimer_clock_base;
struct hrtimer_cpu_base;
enum hrtimer_restart {
    HRTIMER_NORESTART = 0,
    HRTIMER_RESTART = 1
} ;
struct hrtimer {
   struct timerqueue_node node ;
   ktime_t _softexpires ;
   enum hrtimer_restart (*function)(struct hrtimer * ) ;
   struct hrtimer_clock_base *base ;
   unsigned long state ;
    klee_make_symbolic(&state, sizeof(long), "state");
   int start_pid ;
   void *start_site ;
   char start_comm[16U] ;
};
struct hrtimer_clock_base {
   struct hrtimer_cpu_base *cpu_base ;
   int index ;
   clockid_t clockid ;
   struct timerqueue_head active ;
   ktime_t (*get_time)(void) ;
   ktime_t offset ;
};
struct hrtimer_cpu_base {
   raw_spinlock_t lock ;
   seqcount_t seq ;
   struct hrtimer *running ;
   unsigned int cpu ;
   unsigned int active_bases ;
    klee_make_symbolic(&active_bases, sizeof(int), "active_bases");
   unsigned int clock_was_set_seq ;
    klee_make_symbolic(&clock_was_set_seq, sizeof(int), "clock_was_set_seq");
   bool migration_enabled ;
   bool nohz_active ;
   unsigned char in_hrtirq : 1 ;
   unsigned char hres_active : 1 ;
   unsigned char hang_detected : 1 ;
   ktime_t expires_next ;
   struct hrtimer *next_timer ;
   unsigned int nr_events ;
    klee_make_symbolic(&nr_events, sizeof(int), "nr_events");
   unsigned int nr_retries ;
    klee_make_symbolic(&nr_retries, sizeof(int), "nr_retries");
   unsigned int nr_hangs ;
    klee_make_symbolic(&nr_hangs, sizeof(int), "nr_hangs");
   unsigned int max_hang_time ;
    klee_make_symbolic(&max_hang_time, sizeof(int), "max_hang_time");
   struct hrtimer_clock_base clock_base[4U] ;
};
struct task_io_accounting {
   u64 rchar ;
   u64 wchar ;
   u64 syscr ;
   u64 syscw ;
   u64 read_bytes ;
   u64 write_bytes ;
   u64 cancelled_write_bytes ;
};
struct latency_record {
   unsigned long backtrace[12U] ;
   unsigned int count ;
   unsigned long time ;
    klee_make_symbolic(&time, sizeof(long), "time");
   unsigned long max ;
    klee_make_symbolic(&max, sizeof(long), "max");
};
struct assoc_array_ptr;
struct assoc_array {
   struct assoc_array_ptr *root ;
   unsigned long nr_leaves_on_tree ;
    klee_make_symbolic(&nr_leaves_on_tree, sizeof(long), "nr_leaves_on_tree");
};
typedef int32_t key_serial_t;
typedef uint32_t key_perm_t;
struct key;
struct signal_struct;
struct cred;
struct key_type;
struct keyring_index_key {
   struct key_type *type ;
   char const   *description ;
   size_t desc_len ;
};
union __anonunion____missing_field_name_179 {
   struct list_head graveyard_link ;
   struct rb_node serial_node ;
};
struct key_user;
union __anonunion____missing_field_name_180 {
   time_t expiry ;
   time_t revoked_at ;
};
struct __anonstruct____missing_field_name_182 {
   struct key_type *type ;
   char *description ;
};
union __anonunion____missing_field_name_181 {
   struct keyring_index_key index_key ;
   struct __anonstruct____missing_field_name_182 __annonCompField49 ;
};
union __anonunion_type_data_183 {
   struct list_head link ;
   unsigned long x[2U] ;
   void *p[2U] ;
   int reject_error ;
    klee_make_symbolic(&reject_error, sizeof(int), "reject_error");
};
union __anonunion_payload_185 {
   unsigned long value ;
   void *rcudata ;
   void *data ;
   void *data2[2U] ;
};
union __anonunion____missing_field_name_184 {
   union __anonunion_payload_185 payload ;
   struct assoc_array keys ;
};
struct key {
   atomic_t usage ;
   key_serial_t serial ;
   union __anonunion____missing_field_name_179 __annonCompField47 ;
   struct rw_semaphore sem ;
   struct key_user *user ;
   void *security ;
   union __anonunion____missing_field_name_180 __annonCompField48 ;
   time_t last_used_at ;
   kuid_t uid ;
   kgid_t gid ;
   key_perm_t perm ;
   unsigned short quotalen ;
    klee_make_symbolic(&quotalen, sizeof(short), "quotalen");
   unsigned short datalen ;
    klee_make_symbolic(&datalen, sizeof(short), "datalen");
   unsigned long flags ;
   union __anonunion____missing_field_name_181 __annonCompField50 ;
   union __anonunion_type_data_183 type_data ;
   union __anonunion____missing_field_name_184 __annonCompField51 ;
};
struct audit_context;
struct group_info {
   atomic_t usage ;
   int ngroups ;
    klee_make_symbolic(&ngroups, sizeof(int), "ngroups");
   int nblocks ;
    klee_make_symbolic(&nblocks, sizeof(int), "nblocks");
   kgid_t small_block[32U] ;
   kgid_t *blocks[0U] ;
};
struct cred {
   atomic_t usage ;
   atomic_t subscribers ;
   void *put_addr ;
   unsigned int magic ;
   kuid_t uid ;
   kgid_t gid ;
   kuid_t suid ;
   kgid_t sgid ;
   kuid_t euid ;
   kgid_t egid ;
   kuid_t fsuid ;
   kgid_t fsgid ;
   unsigned int securebits ;
    klee_make_symbolic(&securebits, sizeof(int), "securebits");
   kernel_cap_t cap_inheritable ;
   kernel_cap_t cap_permitted ;
   kernel_cap_t cap_effective ;
   kernel_cap_t cap_bset ;
   unsigned char jit_keyring ;
    klee_make_symbolic(&jit_keyring, sizeof(char), "jit_keyring");
   struct key *session_keyring ;
   struct key *process_keyring ;
   struct key *thread_keyring ;
   struct key *request_key_auth ;
   void *security ;
   struct user_struct *user ;
   struct user_namespace *user_ns ;
   struct group_info *group_info ;
   struct callback_head rcu ;
};
union __anonunion____missing_field_name_186 {
   unsigned long bitmap[4U] ;
   struct callback_head callback_head ;
};
struct idr_layer {
   int prefix ;
    klee_make_symbolic(&prefix, sizeof(int), "prefix");
   int layer ;
    klee_make_symbolic(&layer, sizeof(int), "layer");
   struct idr_layer *ary[256U] ;
   int count ;
   union __anonunion____missing_field_name_186 __annonCompField52 ;
};
struct idr {
   struct idr_layer *hint ;
   struct idr_layer *top ;
   int layers ;
    klee_make_symbolic(&layers, sizeof(int), "layers");
   int cur ;
    klee_make_symbolic(&cur, sizeof(int), "cur");
   spinlock_t lock ;
   int id_free_cnt ;
    klee_make_symbolic(&id_free_cnt, sizeof(int), "id_free_cnt");
   struct idr_layer *id_free ;
};
struct ida_bitmap {
   long nr_busy ;
    klee_make_symbolic(&nr_busy, sizeof(long), "nr_busy");
   unsigned long bitmap[15U] ;
};
struct ida {
   struct idr idr ;
   struct ida_bitmap *free_bitmap ;
};
struct percpu_ref;
typedef void percpu_ref_func_t(struct percpu_ref * );
struct percpu_ref {
   atomic_long_t count ;
   unsigned long percpu_count_ptr ;
    klee_make_symbolic(&percpu_count_ptr, sizeof(long), "percpu_count_ptr");
   percpu_ref_func_t *release ;
   percpu_ref_func_t *confirm_switch ;
   bool force_atomic ;
   struct callback_head rcu ;
};
struct cgroup;
struct cgroup_root;
struct cgroup_subsys;
struct cgroup_taskset;
struct kernfs_node;
struct kernfs_ops;
struct kernfs_open_file;
struct cgroup_subsys_state {
   struct cgroup *cgroup ;
   struct cgroup_subsys *ss ;
   struct percpu_ref refcnt ;
   struct cgroup_subsys_state *parent ;
   struct list_head sibling ;
   struct list_head children ;
   int id ;
    klee_make_symbolic(&id, sizeof(int), "id");
   unsigned int flags ;
   u64 serial_nr ;
   struct callback_head callback_head ;
   struct work_struct destroy_work ;
};
struct css_set {
   atomic_t refcount ;
   struct hlist_node hlist ;
   struct list_head tasks ;
   struct list_head mg_tasks ;
   struct list_head cgrp_links ;
   struct cgroup *dfl_cgrp ;
   struct cgroup_subsys_state *subsys[12U] ;
   struct list_head mg_preload_node ;
   struct list_head mg_node ;
   struct cgroup *mg_src_cgrp ;
   struct css_set *mg_dst_cset ;
   struct list_head e_cset_node[12U] ;
   struct callback_head callback_head ;
};
struct cgroup {
   struct cgroup_subsys_state self ;
   unsigned long flags ;
   int id ;
   int populated_cnt ;
    klee_make_symbolic(&populated_cnt, sizeof(int), "populated_cnt");
   struct kernfs_node *kn ;
   struct kernfs_node *procs_kn ;
   struct kernfs_node *populated_kn ;
   unsigned int subtree_control ;
    klee_make_symbolic(&subtree_control, sizeof(int), "subtree_control");
   unsigned int child_subsys_mask ;
    klee_make_symbolic(&child_subsys_mask, sizeof(int), "child_subsys_mask");
   struct cgroup_subsys_state *subsys[12U] ;
   struct cgroup_root *root ;
   struct list_head cset_links ;
   struct list_head e_csets[12U] ;
   struct list_head pidlists ;
   struct mutex pidlist_mutex ;
   wait_queue_head_t offline_waitq ;
   struct work_struct release_agent_work ;
};
struct kernfs_root;
struct cgroup_root {
   struct kernfs_root *kf_root ;
   unsigned int subsys_mask ;
    klee_make_symbolic(&subsys_mask, sizeof(int), "subsys_mask");
   int hierarchy_id ;
    klee_make_symbolic(&hierarchy_id, sizeof(int), "hierarchy_id");
   struct cgroup cgrp ;
   atomic_t nr_cgrps ;
   struct list_head root_list ;
   unsigned int flags ;
   struct idr cgroup_idr ;
   char release_agent_path[4096U] ;
   char name[64U] ;
};
struct cftype {
   char name[64U] ;
   int private ;
   umode_t mode ;
   size_t max_write_len ;
   unsigned int flags ;
   struct cgroup_subsys *ss ;
   struct list_head node ;
   struct kernfs_ops *kf_ops ;
   u64 (*read_u64)(struct cgroup_subsys_state * , struct cftype * ) ;
   s64 (*read_s64)(struct cgroup_subsys_state * , struct cftype * ) ;
   int (*seq_show)(struct seq_file * , void * ) ;
   void *(*seq_start)(struct seq_file * , loff_t * ) ;
   void *(*seq_next)(struct seq_file * , void * , loff_t * ) ;
   void (*seq_stop)(struct seq_file * , void * ) ;
   int (*write_u64)(struct cgroup_subsys_state * , struct cftype * , u64  ) ;
   int (*write_s64)(struct cgroup_subsys_state * , struct cftype * , s64  ) ;
   ssize_t (*write)(struct kernfs_open_file * , char * , size_t  , loff_t  ) ;
   struct lock_class_key lockdep_key ;
};
struct cgroup_subsys {
   struct cgroup_subsys_state *(*css_alloc)(struct cgroup_subsys_state * ) ;
   int (*css_online)(struct cgroup_subsys_state * ) ;
   void (*css_offline)(struct cgroup_subsys_state * ) ;
   void (*css_released)(struct cgroup_subsys_state * ) ;
   void (*css_free)(struct cgroup_subsys_state * ) ;
   void (*css_reset)(struct cgroup_subsys_state * ) ;
   void (*css_e_css_changed)(struct cgroup_subsys_state * ) ;
   int (*can_attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*cancel_attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*fork)(struct task_struct * ) ;
   void (*exit)(struct cgroup_subsys_state * , struct cgroup_subsys_state * , struct task_struct * ) ;
   void (*bind)(struct cgroup_subsys_state * ) ;
   int disabled ;
    klee_make_symbolic(&disabled, sizeof(int), "disabled");
   int early_init ;
    klee_make_symbolic(&early_init, sizeof(int), "early_init");
   bool broken_hierarchy ;
   bool warned_broken_hierarchy ;
   int id ;
   char const   *name ;
   struct cgroup_root *root ;
   struct idr css_idr ;
   struct list_head cfts ;
   struct cftype *dfl_cftypes ;
   struct cftype *legacy_cftypes ;
   unsigned int depends_on ;
    klee_make_symbolic(&depends_on, sizeof(int), "depends_on");
};
struct futex_pi_state;
struct robust_list_head;
struct bio_list;
struct fs_struct;
struct perf_event_context;
struct blk_plug;
struct nameidata;
struct cfs_rq;
struct task_group;
struct sighand_struct {
   atomic_t count ;
   struct k_sigaction action[64U] ;
   spinlock_t siglock ;
   wait_queue_head_t signalfd_wqh ;
};
struct pacct_struct {
   int ac_flag ;
    klee_make_symbolic(&ac_flag, sizeof(int), "ac_flag");
   long ac_exitcode ;
    klee_make_symbolic(&ac_exitcode, sizeof(long), "ac_exitcode");
   unsigned long ac_mem ;
    klee_make_symbolic(&ac_mem, sizeof(long), "ac_mem");
   cputime_t ac_utime ;
   cputime_t ac_stime ;
   unsigned long ac_minflt ;
    klee_make_symbolic(&ac_minflt, sizeof(long), "ac_minflt");
   unsigned long ac_majflt ;
    klee_make_symbolic(&ac_majflt, sizeof(long), "ac_majflt");
};
struct cpu_itimer {
   cputime_t expires ;
   cputime_t incr ;
   u32 error ;
   u32 incr_error ;
};
struct cputime {
   cputime_t utime ;
   cputime_t stime ;
};
struct task_cputime {
   cputime_t utime ;
   cputime_t stime ;
   unsigned long long sum_exec_runtime ;
    klee_make_symbolic(&sum_exec_runtime, sizeof(long), "sum_exec_runtime");
};
struct task_cputime_atomic {
   atomic64_t utime ;
   atomic64_t stime ;
   atomic64_t sum_exec_runtime ;
};
struct thread_group_cputimer {
   struct task_cputime_atomic cputime_atomic ;
   int running ;
    klee_make_symbolic(&running, sizeof(int), "running");
};
struct autogroup;
struct tty_struct;
struct taskstats;
struct tty_audit_buf;
struct signal_struct {
   atomic_t sigcnt ;
   atomic_t live ;
   int nr_threads ;
    klee_make_symbolic(&nr_threads, sizeof(int), "nr_threads");
   struct list_head thread_head ;
   wait_queue_head_t wait_chldexit ;
   struct task_struct *curr_target ;
   struct sigpending shared_pending ;
   int group_exit_code ;
    klee_make_symbolic(&group_exit_code, sizeof(int), "group_exit_code");
   int notify_count ;
    klee_make_symbolic(&notify_count, sizeof(int), "notify_count");
   struct task_struct *group_exit_task ;
   int group_stop_count ;
    klee_make_symbolic(&group_stop_count, sizeof(int), "group_stop_count");
   unsigned int flags ;
   unsigned char is_child_subreaper : 1 ;
   unsigned char has_child_subreaper : 1 ;
   int posix_timer_id ;
    klee_make_symbolic(&posix_timer_id, sizeof(int), "posix_timer_id");
   struct list_head posix_timers ;
   struct hrtimer real_timer ;
   struct pid *leader_pid ;
   ktime_t it_real_incr ;
   struct cpu_itimer it[2U] ;
   struct thread_group_cputimer cputimer ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   struct pid *tty_old_pgrp ;
   int leader ;
    klee_make_symbolic(&leader, sizeof(int), "leader");
   struct tty_struct *tty ;
   struct autogroup *autogroup ;
   seqlock_t stats_lock ;
   cputime_t utime ;
   cputime_t stime ;
   cputime_t cutime ;
   cputime_t cstime ;
   cputime_t gtime ;
   cputime_t cgtime ;
   struct cputime prev_cputime ;
   unsigned long nvcsw ;
    klee_make_symbolic(&nvcsw, sizeof(long), "nvcsw");
   unsigned long nivcsw ;
    klee_make_symbolic(&nivcsw, sizeof(long), "nivcsw");
   unsigned long cnvcsw ;
    klee_make_symbolic(&cnvcsw, sizeof(long), "cnvcsw");
   unsigned long cnivcsw ;
    klee_make_symbolic(&cnivcsw, sizeof(long), "cnivcsw");
   unsigned long min_flt ;
    klee_make_symbolic(&min_flt, sizeof(long), "min_flt");
   unsigned long maj_flt ;
    klee_make_symbolic(&maj_flt, sizeof(long), "maj_flt");
   unsigned long cmin_flt ;
    klee_make_symbolic(&cmin_flt, sizeof(long), "cmin_flt");
   unsigned long cmaj_flt ;
    klee_make_symbolic(&cmaj_flt, sizeof(long), "cmaj_flt");
   unsigned long inblock ;
    klee_make_symbolic(&inblock, sizeof(long), "inblock");
   unsigned long oublock ;
    klee_make_symbolic(&oublock, sizeof(long), "oublock");
   unsigned long cinblock ;
    klee_make_symbolic(&cinblock, sizeof(long), "cinblock");
   unsigned long coublock ;
    klee_make_symbolic(&coublock, sizeof(long), "coublock");
   unsigned long maxrss ;
    klee_make_symbolic(&maxrss, sizeof(long), "maxrss");
   unsigned long cmaxrss ;
    klee_make_symbolic(&cmaxrss, sizeof(long), "cmaxrss");
   struct task_io_accounting ioac ;
   unsigned long long sum_sched_runtime ;
    klee_make_symbolic(&sum_sched_runtime, sizeof(long), "sum_sched_runtime");
   struct rlimit rlim[16U] ;
   struct pacct_struct pacct ;
   struct taskstats *stats ;
   unsigned int audit_tty ;
    klee_make_symbolic(&audit_tty, sizeof(int), "audit_tty");
   unsigned int audit_tty_log_passwd ;
    klee_make_symbolic(&audit_tty_log_passwd, sizeof(int), "audit_tty_log_passwd");
   struct tty_audit_buf *tty_audit_buf ;
   oom_flags_t oom_flags ;
   short oom_score_adj ;
    klee_make_symbolic(&oom_score_adj, sizeof(short), "oom_score_adj");
   short oom_score_adj_min ;
    klee_make_symbolic(&oom_score_adj_min, sizeof(short), "oom_score_adj_min");
   struct mutex cred_guard_mutex ;
};
struct user_struct {
   atomic_t __count ;
   atomic_t processes ;
   atomic_t sigpending ;
   atomic_t inotify_watches ;
   atomic_t inotify_devs ;
   atomic_t fanotify_listeners ;
   atomic_long_t epoll_watches ;
   unsigned long mq_bytes ;
    klee_make_symbolic(&mq_bytes, sizeof(long), "mq_bytes");
   unsigned long locked_shm ;
    klee_make_symbolic(&locked_shm, sizeof(long), "locked_shm");
   struct key *uid_keyring ;
   struct key *session_keyring ;
   struct hlist_node uidhash_node ;
   kuid_t uid ;
   atomic_long_t locked_vm ;
};
struct backing_dev_info;
struct reclaim_state;
struct sched_info {
   unsigned long pcount ;
    klee_make_symbolic(&pcount, sizeof(long), "pcount");
   unsigned long long run_delay ;
    klee_make_symbolic(&run_delay, sizeof(long), "run_delay");
   unsigned long long last_arrival ;
    klee_make_symbolic(&last_arrival, sizeof(long), "last_arrival");
   unsigned long long last_queued ;
    klee_make_symbolic(&last_queued, sizeof(long), "last_queued");
};
struct task_delay_info {
   spinlock_t lock ;
   unsigned int flags ;
   u64 blkio_start ;
   u64 blkio_delay ;
   u64 swapin_delay ;
   u32 blkio_count ;
   u32 swapin_count ;
   u64 freepages_start ;
   u64 freepages_delay ;
   u32 freepages_count ;
};
struct wake_q_node {
   struct wake_q_node *next ;
};
struct io_context;
struct pipe_inode_info;
struct uts_namespace;
struct load_weight {
   unsigned long weight ;
    klee_make_symbolic(&weight, sizeof(long), "weight");
   u32 inv_weight ;
};
struct sched_avg {
   u64 last_runnable_update ;
   s64 decay_count ;
   unsigned long load_avg_contrib ;
    klee_make_symbolic(&load_avg_contrib, sizeof(long), "load_avg_contrib");
   unsigned long utilization_avg_contrib ;
    klee_make_symbolic(&utilization_avg_contrib, sizeof(long), "utilization_avg_contrib");
   u32 runnable_avg_sum ;
   u32 avg_period ;
   u32 running_avg_sum ;
};
struct sched_statistics {
   u64 wait_start ;
   u64 wait_max ;
   u64 wait_count ;
   u64 wait_sum ;
   u64 iowait_count ;
   u64 iowait_sum ;
   u64 sleep_start ;
   u64 sleep_max ;
   s64 sum_sleep_runtime ;
   u64 block_start ;
   u64 block_max ;
   u64 exec_max ;
   u64 slice_max ;
   u64 nr_migrations_cold ;
   u64 nr_failed_migrations_affine ;
   u64 nr_failed_migrations_running ;
   u64 nr_failed_migrations_hot ;
   u64 nr_forced_migrations ;
   u64 nr_wakeups ;
   u64 nr_wakeups_sync ;
   u64 nr_wakeups_migrate ;
   u64 nr_wakeups_local ;
   u64 nr_wakeups_remote ;
   u64 nr_wakeups_affine ;
   u64 nr_wakeups_affine_attempts ;
   u64 nr_wakeups_passive ;
   u64 nr_wakeups_idle ;
};
struct sched_entity {
   struct load_weight load ;
   struct rb_node run_node ;
   struct list_head group_node ;
   unsigned int on_rq ;
    klee_make_symbolic(&on_rq, sizeof(int), "on_rq");
   u64 exec_start ;
   u64 sum_exec_runtime ;
   u64 vruntime ;
   u64 prev_sum_exec_runtime ;
   u64 nr_migrations ;
   struct sched_statistics statistics ;
   int depth ;
   struct sched_entity *parent ;
   struct cfs_rq *cfs_rq ;
   struct cfs_rq *my_q ;
   struct sched_avg avg ;
};
struct rt_rq;
struct sched_rt_entity {
   struct list_head run_list ;
   unsigned long timeout ;
    klee_make_symbolic(&timeout, sizeof(long), "timeout");
   unsigned long watchdog_stamp ;
    klee_make_symbolic(&watchdog_stamp, sizeof(long), "watchdog_stamp");
   unsigned int time_slice ;
    klee_make_symbolic(&time_slice, sizeof(int), "time_slice");
   struct sched_rt_entity *back ;
   struct sched_rt_entity *parent ;
   struct rt_rq *rt_rq ;
   struct rt_rq *my_q ;
};
struct sched_dl_entity {
   struct rb_node rb_node ;
   u64 dl_runtime ;
   u64 dl_deadline ;
   u64 dl_period ;
   u64 dl_bw ;
   s64 runtime ;
   u64 deadline ;
   unsigned int flags ;
   int dl_throttled ;
    klee_make_symbolic(&dl_throttled, sizeof(int), "dl_throttled");
   int dl_new ;
    klee_make_symbolic(&dl_new, sizeof(int), "dl_new");
   int dl_boosted ;
    klee_make_symbolic(&dl_boosted, sizeof(int), "dl_boosted");
   int dl_yielded ;
    klee_make_symbolic(&dl_yielded, sizeof(int), "dl_yielded");
   struct hrtimer dl_timer ;
};
struct memcg_oom_info {
   struct mem_cgroup *memcg ;
   gfp_t gfp_mask ;
   int order ;
    klee_make_symbolic(&order, sizeof(int), "order");
   unsigned char may_oom : 1 ;
};
struct sched_class;
struct files_struct;
struct compat_robust_list_head;
struct numa_group;
struct task_struct {
   long volatile   state ;
   void *stack ;
   atomic_t usage ;
   unsigned int flags ;
   unsigned int ptrace ;
    klee_make_symbolic(&ptrace, sizeof(int), "ptrace");
   struct llist_node wake_entry ;
   int on_cpu ;
    klee_make_symbolic(&on_cpu, sizeof(int), "on_cpu");
   struct task_struct *last_wakee ;
   unsigned long wakee_flips ;
    klee_make_symbolic(&wakee_flips, sizeof(long), "wakee_flips");
   unsigned long wakee_flip_decay_ts ;
    klee_make_symbolic(&wakee_flip_decay_ts, sizeof(long), "wakee_flip_decay_ts");
   int wake_cpu ;
    klee_make_symbolic(&wake_cpu, sizeof(int), "wake_cpu");
   int on_rq ;
   int prio ;
   int static_prio ;
    klee_make_symbolic(&static_prio, sizeof(int), "static_prio");
   int normal_prio ;
    klee_make_symbolic(&normal_prio, sizeof(int), "normal_prio");
   unsigned int rt_priority ;
    klee_make_symbolic(&rt_priority, sizeof(int), "rt_priority");
   struct sched_class  const  *sched_class ;
   struct sched_entity se ;
   struct sched_rt_entity rt ;
   struct task_group *sched_task_group ;
   struct sched_dl_entity dl ;
   struct hlist_head preempt_notifiers ;
   unsigned int policy ;
    klee_make_symbolic(&policy, sizeof(int), "policy");
   int nr_cpus_allowed ;
    klee_make_symbolic(&nr_cpus_allowed, sizeof(int), "nr_cpus_allowed");
   cpumask_t cpus_allowed ;
   unsigned long rcu_tasks_nvcsw ;
    klee_make_symbolic(&rcu_tasks_nvcsw, sizeof(long), "rcu_tasks_nvcsw");
   bool rcu_tasks_holdout ;
   struct list_head rcu_tasks_holdout_list ;
   int rcu_tasks_idle_cpu ;
    klee_make_symbolic(&rcu_tasks_idle_cpu, sizeof(int), "rcu_tasks_idle_cpu");
   struct sched_info sched_info ;
   struct list_head tasks ;
   struct plist_node pushable_tasks ;
   struct rb_node pushable_dl_tasks ;
   struct mm_struct *mm ;
   struct mm_struct *active_mm ;
   u32 vmacache_seqnum ;
   struct vm_area_struct *vmacache[4U] ;
   struct task_rss_stat rss_stat ;
   int exit_state ;
    klee_make_symbolic(&exit_state, sizeof(int), "exit_state");
   int exit_code ;
    klee_make_symbolic(&exit_code, sizeof(int), "exit_code");
   int exit_signal ;
    klee_make_symbolic(&exit_signal, sizeof(int), "exit_signal");
   int pdeath_signal ;
    klee_make_symbolic(&pdeath_signal, sizeof(int), "pdeath_signal");
   unsigned long jobctl ;
    klee_make_symbolic(&jobctl, sizeof(long), "jobctl");
   unsigned int personality ;
    klee_make_symbolic(&personality, sizeof(int), "personality");
   unsigned char in_execve : 1 ;
   unsigned char in_iowait : 1 ;
   unsigned char sched_reset_on_fork : 1 ;
   unsigned char sched_contributes_to_load : 1 ;
   unsigned char sched_migrated : 1 ;
   unsigned char memcg_kmem_skip_account : 1 ;
   unsigned char brk_randomized : 1 ;
   unsigned long atomic_flags ;
    klee_make_symbolic(&atomic_flags, sizeof(long), "atomic_flags");
   struct restart_block restart_block ;
   pid_t pid ;
   pid_t tgid ;
   struct task_struct *real_parent ;
   struct task_struct *parent ;
   struct list_head children ;
   struct list_head sibling ;
   struct task_struct *group_leader ;
   struct list_head ptraced ;
   struct list_head ptrace_entry ;
   struct pid_link pids[3U] ;
   struct list_head thread_group ;
   struct list_head thread_node ;
   struct completion *vfork_done ;
   int *set_child_tid ;
   int *clear_child_tid ;
   cputime_t utime ;
   cputime_t stime ;
   cputime_t utimescaled ;
   cputime_t stimescaled ;
   cputime_t gtime ;
   struct cputime prev_cputime ;
   unsigned long nvcsw ;
   unsigned long nivcsw ;
   u64 start_time ;
   u64 real_start_time ;
   unsigned long min_flt ;
   unsigned long maj_flt ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   struct cred  const  *real_cred ;
   struct cred  const  *cred ;
   char comm[16U] ;
   struct nameidata *nameidata ;
   struct sysv_sem sysvsem ;
   struct sysv_shm sysvshm ;
   unsigned long last_switch_count ;
    klee_make_symbolic(&last_switch_count, sizeof(long), "last_switch_count");
   struct thread_struct thread ;
   struct fs_struct *fs ;
   struct files_struct *files ;
   struct nsproxy *nsproxy ;
   struct signal_struct *signal ;
   struct sighand_struct *sighand ;
   sigset_t blocked ;
   sigset_t real_blocked ;
   sigset_t saved_sigmask ;
   struct sigpending pending ;
   unsigned long sas_ss_sp ;
    klee_make_symbolic(&sas_ss_sp, sizeof(long), "sas_ss_sp");
   size_t sas_ss_size ;
   int (*notifier)(void * ) ;
   void *notifier_data ;
   sigset_t *notifier_mask ;
   struct callback_head *task_works ;
   struct audit_context *audit_context ;
   kuid_t loginuid ;
   unsigned int sessionid ;
    klee_make_symbolic(&sessionid, sizeof(int), "sessionid");
   struct seccomp seccomp ;
   u32 parent_exec_id ;
   u32 self_exec_id ;
   spinlock_t alloc_lock ;
   raw_spinlock_t pi_lock ;
   struct wake_q_node wake_q ;
   struct rb_root pi_waiters ;
   struct rb_node *pi_waiters_leftmost ;
   struct rt_mutex_waiter *pi_blocked_on ;
   struct mutex_waiter *blocked_on ;
   unsigned int irq_events ;
    klee_make_symbolic(&irq_events, sizeof(int), "irq_events");
   unsigned long hardirq_enable_ip ;
    klee_make_symbolic(&hardirq_enable_ip, sizeof(long), "hardirq_enable_ip");
   unsigned long hardirq_disable_ip ;
    klee_make_symbolic(&hardirq_disable_ip, sizeof(long), "hardirq_disable_ip");
   unsigned int hardirq_enable_event ;
    klee_make_symbolic(&hardirq_enable_event, sizeof(int), "hardirq_enable_event");
   unsigned int hardirq_disable_event ;
    klee_make_symbolic(&hardirq_disable_event, sizeof(int), "hardirq_disable_event");
   int hardirqs_enabled ;
    klee_make_symbolic(&hardirqs_enabled, sizeof(int), "hardirqs_enabled");
   int hardirq_context ;
    klee_make_symbolic(&hardirq_context, sizeof(int), "hardirq_context");
   unsigned long softirq_disable_ip ;
    klee_make_symbolic(&softirq_disable_ip, sizeof(long), "softirq_disable_ip");
   unsigned long softirq_enable_ip ;
    klee_make_symbolic(&softirq_enable_ip, sizeof(long), "softirq_enable_ip");
   unsigned int softirq_disable_event ;
    klee_make_symbolic(&softirq_disable_event, sizeof(int), "softirq_disable_event");
   unsigned int softirq_enable_event ;
    klee_make_symbolic(&softirq_enable_event, sizeof(int), "softirq_enable_event");
   int softirqs_enabled ;
    klee_make_symbolic(&softirqs_enabled, sizeof(int), "softirqs_enabled");
   int softirq_context ;
    klee_make_symbolic(&softirq_context, sizeof(int), "softirq_context");
   u64 curr_chain_key ;
   int lockdep_depth ;
    klee_make_symbolic(&lockdep_depth, sizeof(int), "lockdep_depth");
   unsigned int lockdep_recursion ;
    klee_make_symbolic(&lockdep_recursion, sizeof(int), "lockdep_recursion");
   struct held_lock held_locks[48U] ;
   gfp_t lockdep_reclaim_gfp ;
   void *journal_info ;
   struct bio_list *bio_list ;
   struct blk_plug *plug ;
   struct reclaim_state *reclaim_state ;
   struct backing_dev_info *backing_dev_info ;
   struct io_context *io_context ;
   unsigned long ptrace_message ;
    klee_make_symbolic(&ptrace_message, sizeof(long), "ptrace_message");
   siginfo_t *last_siginfo ;
   struct task_io_accounting ioac ;
   u64 acct_rss_mem1 ;
   u64 acct_vm_mem1 ;
   cputime_t acct_timexpd ;
   nodemask_t mems_allowed ;
   seqcount_t mems_allowed_seq ;
   int cpuset_mem_spread_rotor ;
    klee_make_symbolic(&cpuset_mem_spread_rotor, sizeof(int), "cpuset_mem_spread_rotor");
   int cpuset_slab_spread_rotor ;
    klee_make_symbolic(&cpuset_slab_spread_rotor, sizeof(int), "cpuset_slab_spread_rotor");
   struct css_set *cgroups ;
   struct list_head cg_list ;
   struct robust_list_head *robust_list ;
   struct compat_robust_list_head *compat_robust_list ;
   struct list_head pi_state_list ;
   struct futex_pi_state *pi_state_cache ;
   struct perf_event_context *perf_event_ctxp[2U] ;
   struct mutex perf_event_mutex ;
   struct list_head perf_event_list ;
   struct mempolicy *mempolicy ;
   short il_next ;
    klee_make_symbolic(&il_next, sizeof(short), "il_next");
   short pref_node_fork ;
    klee_make_symbolic(&pref_node_fork, sizeof(short), "pref_node_fork");
   int numa_scan_seq ;
   unsigned int numa_scan_period ;
    klee_make_symbolic(&numa_scan_period, sizeof(int), "numa_scan_period");
   unsigned int numa_scan_period_max ;
    klee_make_symbolic(&numa_scan_period_max, sizeof(int), "numa_scan_period_max");
   int numa_preferred_nid ;
    klee_make_symbolic(&numa_preferred_nid, sizeof(int), "numa_preferred_nid");
   unsigned long numa_migrate_retry ;
    klee_make_symbolic(&numa_migrate_retry, sizeof(long), "numa_migrate_retry");
   u64 node_stamp ;
   u64 last_task_numa_placement ;
   u64 last_sum_exec_runtime ;
   struct callback_head numa_work ;
   struct list_head numa_entry ;
   struct numa_group *numa_group ;
   unsigned long *numa_faults ;
   unsigned long total_numa_faults ;
    klee_make_symbolic(&total_numa_faults, sizeof(long), "total_numa_faults");
   unsigned long numa_faults_locality[3U] ;
   unsigned long numa_pages_migrated ;
    klee_make_symbolic(&numa_pages_migrated, sizeof(long), "numa_pages_migrated");
   struct callback_head rcu ;
   struct pipe_inode_info *splice_pipe ;
   struct page_frag task_frag ;
   struct task_delay_info *delays ;
   int make_it_fail ;
    klee_make_symbolic(&make_it_fail, sizeof(int), "make_it_fail");
   int nr_dirtied ;
    klee_make_symbolic(&nr_dirtied, sizeof(int), "nr_dirtied");
   int nr_dirtied_pause ;
    klee_make_symbolic(&nr_dirtied_pause, sizeof(int), "nr_dirtied_pause");
   unsigned long dirty_paused_when ;
    klee_make_symbolic(&dirty_paused_when, sizeof(long), "dirty_paused_when");
   int latency_record_count ;
    klee_make_symbolic(&latency_record_count, sizeof(int), "latency_record_count");
   struct latency_record latency_record[32U] ;
   unsigned long timer_slack_ns ;
    klee_make_symbolic(&timer_slack_ns, sizeof(long), "timer_slack_ns");
   unsigned long default_timer_slack_ns ;
    klee_make_symbolic(&default_timer_slack_ns, sizeof(long), "default_timer_slack_ns");
   unsigned int kasan_depth ;
    klee_make_symbolic(&kasan_depth, sizeof(int), "kasan_depth");
   unsigned long trace ;
    klee_make_symbolic(&trace, sizeof(long), "trace");
   unsigned long trace_recursion ;
    klee_make_symbolic(&trace_recursion, sizeof(long), "trace_recursion");
   struct memcg_oom_info memcg_oom ;
   struct uprobe_task *utask ;
   unsigned int sequential_io ;
    klee_make_symbolic(&sequential_io, sizeof(int), "sequential_io");
   unsigned int sequential_io_avg ;
    klee_make_symbolic(&sequential_io_avg, sizeof(int), "sequential_io_avg");
   unsigned long task_state_change ;
    klee_make_symbolic(&task_state_change, sizeof(long), "task_state_change");
   int pagefault_disabled ;
    klee_make_symbolic(&pagefault_disabled, sizeof(int), "pagefault_disabled");
};
enum irqreturn {
    IRQ_NONE = 0,
    IRQ_HANDLED = 1,
    IRQ_WAKE_THREAD = 2
} ;
typedef enum irqreturn irqreturn_t;
struct ethtool_rxnfc;
struct ethtool_pauseparam;
struct ethtool_eeprom;
struct ethtool_wolinfo;
struct ethtool_coalesce;
struct ethtool_cmd;
struct ethtool_ringparam;
struct ethtool_channels;
struct iovec {
   void *iov_base ;
   __kernel_size_t iov_len ;
};
struct kvec {
   void *iov_base ;
   size_t iov_len ;
};
union __anonunion____missing_field_name_205 {
   struct iovec  const  *iov ;
   struct kvec  const  *kvec ;
   struct bio_vec  const  *bvec ;
};
struct iov_iter {
   int type ;
    klee_make_symbolic(&type, sizeof(int), "type");
   size_t iov_offset ;
   size_t count ;
   union __anonunion____missing_field_name_205 __annonCompField56 ;
   unsigned long nr_segs ;
    klee_make_symbolic(&nr_segs, sizeof(long), "nr_segs");
};
typedef unsigned short __kernel_sa_family_t;
    klee_make_symbolic(&__kernel_sa_family_t, sizeof(short), "__kernel_sa_family_t");
typedef __kernel_sa_family_t sa_family_t;
struct sockaddr {
   sa_family_t sa_family ;
   char sa_data[14U] ;
};
struct kiocb;
struct msghdr {
   void *msg_name ;
   int msg_namelen ;
    klee_make_symbolic(&msg_namelen, sizeof(int), "msg_namelen");
   struct iov_iter msg_iter ;
   void *msg_control ;
   __kernel_size_t msg_controllen ;
   unsigned int msg_flags ;
    klee_make_symbolic(&msg_flags, sizeof(int), "msg_flags");
   struct kiocb *msg_iocb ;
};
enum ldv_16982 {
    SS_FREE = 0,
    SS_UNCONNECTED = 1,
    SS_CONNECTING = 2,
    SS_CONNECTED = 3,
    SS_DISCONNECTING = 4
} ;
typedef enum ldv_16982 socket_state;
struct poll_table_struct;
struct net;
struct fasync_struct;
struct socket_wq {
   wait_queue_head_t wait ;
   struct fasync_struct *fasync_list ;
   struct callback_head rcu ;
};
struct sock;
struct proto_ops;
struct socket {
   socket_state state ;
   short type ;
   unsigned long flags ;
   struct socket_wq *wq ;
   struct file *file ;
   struct sock *sk ;
   struct proto_ops  const  *ops ;
};
struct proto_ops {
   int family ;
    klee_make_symbolic(&family, sizeof(int), "family");
   struct module *owner ;
   int (*release)(struct socket * ) ;
   int (*bind)(struct socket * , struct sockaddr * , int  ) ;
   int (*connect)(struct socket * , struct sockaddr * , int  , int  ) ;
   int (*socketpair)(struct socket * , struct socket * ) ;
   int (*accept)(struct socket * , struct socket * , int  ) ;
   int (*getname)(struct socket * , struct sockaddr * , int * , int  ) ;
   unsigned int (*poll)(struct file * , struct socket * , struct poll_table_struct * ) ;
   int (*ioctl)(struct socket * , unsigned int  , unsigned long  ) ;
   int (*compat_ioctl)(struct socket * , unsigned int  , unsigned long  ) ;
   int (*listen)(struct socket * , int  ) ;
   int (*shutdown)(struct socket * , int  ) ;
   int (*setsockopt)(struct socket * , int  , int  , char * , unsigned int  ) ;
   int (*getsockopt)(struct socket * , int  , int  , char * , int * ) ;
   int (*compat_setsockopt)(struct socket * , int  , int  , char * , unsigned int  ) ;
   int (*compat_getsockopt)(struct socket * , int  , int  , char * , int * ) ;
   int (*sendmsg)(struct socket * , struct msghdr * , size_t  ) ;
   int (*recvmsg)(struct socket * , struct msghdr * , size_t  , int  ) ;
   int (*mmap)(struct file * , struct socket * , struct vm_area_struct * ) ;
   ssize_t (*sendpage)(struct socket * , struct page * , int  , size_t  , int  ) ;
   ssize_t (*splice_read)(struct socket * , loff_t * , struct pipe_inode_info * ,
                          size_t  , unsigned int  ) ;
   int (*set_peek_off)(struct sock * , int  ) ;
};
struct exception_table_entry {
   int insn ;
    klee_make_symbolic(&insn, sizeof(int), "insn");
   int fixup ;
    klee_make_symbolic(&fixup, sizeof(int), "fixup");
};
struct in6_addr;
struct sk_buff;
struct iattr;
struct super_block;
struct file_system_type;
struct kernfs_open_node;
struct kernfs_iattrs;
struct kernfs_elem_dir {
   unsigned long subdirs ;
    klee_make_symbolic(&subdirs, sizeof(long), "subdirs");
   struct rb_root children ;
   struct kernfs_root *root ;
};
struct kernfs_elem_symlink {
   struct kernfs_node *target_kn ;
};
struct kernfs_elem_attr {
   struct kernfs_ops  const  *ops ;
   struct kernfs_open_node *open ;
   loff_t size ;
   struct kernfs_node *notify_next ;
};
union __anonunion____missing_field_name_206 {
   struct kernfs_elem_dir dir ;
   struct kernfs_elem_symlink symlink ;
   struct kernfs_elem_attr attr ;
};
struct kernfs_node {
   atomic_t count ;
   atomic_t active ;
   struct lockdep_map dep_map ;
   struct kernfs_node *parent ;
   char const   *name ;
   struct rb_node rb ;
   void const   *ns ;
   unsigned int hash ;
    klee_make_symbolic(&hash, sizeof(int), "hash");
   union __anonunion____missing_field_name_206 __annonCompField57 ;
   void *priv ;
   unsigned short flags ;
   umode_t mode ;
   unsigned int ino ;
    klee_make_symbolic(&ino, sizeof(int), "ino");
   struct kernfs_iattrs *iattr ;
};
struct kernfs_syscall_ops {
   int (*remount_fs)(struct kernfs_root * , int * , char * ) ;
   int (*show_options)(struct seq_file * , struct kernfs_root * ) ;
   int (*mkdir)(struct kernfs_node * , char const   * , umode_t  ) ;
   int (*rmdir)(struct kernfs_node * ) ;
   int (*rename)(struct kernfs_node * , struct kernfs_node * , char const   * ) ;
};
struct kernfs_root {
   struct kernfs_node *kn ;
   unsigned int flags ;
   struct ida ino_ida ;
   struct kernfs_syscall_ops *syscall_ops ;
   struct list_head supers ;
   wait_queue_head_t deactivate_waitq ;
};
struct kernfs_open_file {
   struct kernfs_node *kn ;
   struct file *file ;
   void *priv ;
   struct mutex mutex ;
   int event ;
   struct list_head list ;
   char *prealloc_buf ;
   size_t atomic_write_len ;
   bool mmapped ;
   struct vm_operations_struct  const  *vm_ops ;
};
struct kernfs_ops {
   int (*seq_show)(struct seq_file * , void * ) ;
   void *(*seq_start)(struct seq_file * , loff_t * ) ;
   void *(*seq_next)(struct seq_file * , void * , loff_t * ) ;
   void (*seq_stop)(struct seq_file * , void * ) ;
   ssize_t (*read)(struct kernfs_open_file * , char * , size_t  , loff_t  ) ;
   size_t atomic_write_len ;
   bool prealloc ;
   ssize_t (*write)(struct kernfs_open_file * , char * , size_t  , loff_t  ) ;
   int (*mmap)(struct kernfs_open_file * , struct vm_area_struct * ) ;
   struct lock_class_key lockdep_key ;
};
struct kobject;
enum kobj_ns_type {
    KOBJ_NS_TYPE_NONE = 0,
    KOBJ_NS_TYPE_NET = 1,
    KOBJ_NS_TYPES = 2
} ;
struct kobj_ns_type_operations {
   enum kobj_ns_type type ;
   bool (*current_may_mount)(void) ;
   void *(*grab_current_ns)(void) ;
   void const   *(*netlink_ns)(struct sock * ) ;
   void const   *(*initial_ns)(void) ;
   void (*drop_ns)(void * ) ;
};
struct kstat {
   u64 ino ;
   dev_t dev ;
   umode_t mode ;
   unsigned int nlink ;
    klee_make_symbolic(&nlink, sizeof(int), "nlink");
   kuid_t uid ;
   kgid_t gid ;
   dev_t rdev ;
   loff_t size ;
   struct timespec atime ;
   struct timespec mtime ;
   struct timespec ctime ;
   unsigned long blksize ;
    klee_make_symbolic(&blksize, sizeof(long), "blksize");
   unsigned long long blocks ;
    klee_make_symbolic(&blocks, sizeof(long), "blocks");
};
struct bin_attribute;
struct attribute {
   char const   *name ;
   umode_t mode ;
   bool ignore_lockdep ;
   struct lock_class_key *key ;
   struct lock_class_key skey ;
};
struct attribute_group {
   char const   *name ;
   umode_t (*is_visible)(struct kobject * , struct attribute * , int  ) ;
   struct attribute **attrs ;
   struct bin_attribute **bin_attrs ;
};
struct bin_attribute {
   struct attribute attr ;
   size_t size ;
   void *private ;
   ssize_t (*read)(struct file * , struct kobject * , struct bin_attribute * , char * ,
                   loff_t  , size_t  ) ;
   ssize_t (*write)(struct file * , struct kobject * , struct bin_attribute * , char * ,
                    loff_t  , size_t  ) ;
   int (*mmap)(struct file * , struct kobject * , struct bin_attribute * , struct vm_area_struct * ) ;
};
struct sysfs_ops {
   ssize_t (*show)(struct kobject * , struct attribute * , char * ) ;
   ssize_t (*store)(struct kobject * , struct attribute * , char const   * , size_t  ) ;
};
struct kref {
   atomic_t refcount ;
};
struct kset;
struct kobj_type;
struct kobject {
   char const   *name ;
   struct list_head entry ;
   struct kobject *parent ;
   struct kset *kset ;
   struct kobj_type *ktype ;
   struct kernfs_node *sd ;
   struct kref kref ;
   struct delayed_work release ;
   unsigned char state_initialized : 1 ;
   unsigned char state_in_sysfs : 1 ;
   unsigned char state_add_uevent_sent : 1 ;
   unsigned char state_remove_uevent_sent : 1 ;
   unsigned char uevent_suppress : 1 ;
};
struct kobj_type {
   void (*release)(struct kobject * ) ;
   struct sysfs_ops  const  *sysfs_ops ;
   struct attribute **default_attrs ;
   struct kobj_ns_type_operations  const  *(*child_ns_type)(struct kobject * ) ;
   void const   *(*namespace)(struct kobject * ) ;
};
struct kobj_uevent_env {
   char *argv[3U] ;
   char *envp[32U] ;
   int envp_idx ;
    klee_make_symbolic(&envp_idx, sizeof(int), "envp_idx");
   char buf[2048U] ;
   int buflen ;
    klee_make_symbolic(&buflen, sizeof(int), "buflen");
};
struct kset_uevent_ops {
   int (* const  filter)(struct kset * , struct kobject * ) ;
   char const   *(* const  name)(struct kset * , struct kobject * ) ;
   int (* const  uevent)(struct kset * , struct kobject * , struct kobj_uevent_env * ) ;
};
struct kset {
   struct list_head list ;
   spinlock_t list_lock ;
   struct kobject kobj ;
   struct kset_uevent_ops  const  *uevent_ops ;
};
struct klist_node;
struct klist_node {
   void *n_klist ;
   struct list_head n_node ;
   struct kref n_ref ;
};
struct path;
struct seq_file {
   char *buf ;
   size_t size ;
   size_t from ;
   size_t count ;
   size_t pad_until ;
   loff_t index ;
   loff_t read_pos ;
   u64 version ;
   struct mutex lock ;
   struct seq_operations  const  *op ;
   int poll_event ;
    klee_make_symbolic(&poll_event, sizeof(int), "poll_event");
   struct user_namespace *user_ns ;
   void *private ;
};
struct seq_operations {
   void *(*start)(struct seq_file * , loff_t * ) ;
   void (*stop)(struct seq_file * , void * ) ;
   void *(*next)(struct seq_file * , void * , loff_t * ) ;
   int (*show)(struct seq_file * , void * ) ;
};
struct pinctrl;
struct pinctrl_state;
struct dev_pin_info {
   struct pinctrl *p ;
   struct pinctrl_state *default_state ;
   struct pinctrl_state *sleep_state ;
   struct pinctrl_state *idle_state ;
};
struct dma_map_ops;
struct dev_archdata {
   struct dma_map_ops *dma_ops ;
   void *iommu ;
};
struct device_private;
struct device_driver;
struct driver_private;
struct class;
struct subsys_private;
struct bus_type;
struct device_node;
struct fwnode_handle;
struct iommu_ops;
struct iommu_group;
struct device_attribute;
struct bus_type {
   char const   *name ;
   char const   *dev_name ;
   struct device *dev_root ;
   struct device_attribute *dev_attrs ;
   struct attribute_group  const  **bus_groups ;
   struct attribute_group  const  **dev_groups ;
   struct attribute_group  const  **drv_groups ;
   int (*match)(struct device * , struct device_driver * ) ;
   int (*uevent)(struct device * , struct kobj_uevent_env * ) ;
   int (*probe)(struct device * ) ;
   int (*remove)(struct device * ) ;
   void (*shutdown)(struct device * ) ;
   int (*online)(struct device * ) ;
   int (*offline)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
   struct iommu_ops  const  *iommu_ops ;
   struct subsys_private *p ;
   struct lock_class_key lock_key ;
};
struct device_type;
enum probe_type {
    PROBE_DEFAULT_STRATEGY = 0,
    PROBE_PREFER_ASYNCHRONOUS = 1,
    PROBE_FORCE_SYNCHRONOUS = 2
} ;
struct of_device_id;
struct acpi_device_id;
struct device_driver {
   char const   *name ;
   struct bus_type *bus ;
   struct module *owner ;
   char const   *mod_name ;
   bool suppress_bind_attrs ;
   enum probe_type probe_type ;
   struct of_device_id  const  *of_match_table ;
   struct acpi_device_id  const  *acpi_match_table ;
   int (*probe)(struct device * ) ;
   int (*remove)(struct device * ) ;
   void (*shutdown)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct attribute_group  const  **groups ;
   struct dev_pm_ops  const  *pm ;
   struct driver_private *p ;
};
struct class_attribute;
struct class {
   char const   *name ;
   struct module *owner ;
   struct class_attribute *class_attrs ;
   struct attribute_group  const  **dev_groups ;
   struct kobject *dev_kobj ;
   int (*dev_uevent)(struct device * , struct kobj_uevent_env * ) ;
   char *(*devnode)(struct device * , umode_t * ) ;
   void (*class_release)(struct class * ) ;
   void (*dev_release)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct kobj_ns_type_operations  const  *ns_type ;
   void const   *(*namespace)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
   struct subsys_private *p ;
};
struct class_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct class * , struct class_attribute * , char * ) ;
   ssize_t (*store)(struct class * , struct class_attribute * , char const   * , size_t  ) ;
};
struct device_type {
   char const   *name ;
   struct attribute_group  const  **groups ;
   int (*uevent)(struct device * , struct kobj_uevent_env * ) ;
   char *(*devnode)(struct device * , umode_t * , kuid_t * , kgid_t * ) ;
   void (*release)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
};
struct device_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct device * , struct device_attribute * , char * ) ;
   ssize_t (*store)(struct device * , struct device_attribute * , char const   * ,
                    size_t  ) ;
};
struct device_dma_parameters {
   unsigned int max_segment_size ;
    klee_make_symbolic(&max_segment_size, sizeof(int), "max_segment_size");
   unsigned long segment_boundary_mask ;
    klee_make_symbolic(&segment_boundary_mask, sizeof(long), "segment_boundary_mask");
};
struct dma_coherent_mem;
struct cma;
struct device {
   struct device *parent ;
   struct device_private *p ;
   struct kobject kobj ;
   char const   *init_name ;
   struct device_type  const  *type ;
   struct mutex mutex ;
   struct bus_type *bus ;
   struct device_driver *driver ;
   void *platform_data ;
   void *driver_data ;
   struct dev_pm_info power ;
   struct dev_pm_domain *pm_domain ;
   struct dev_pin_info *pins ;
   int numa_node ;
    klee_make_symbolic(&numa_node, sizeof(int), "numa_node");
   u64 *dma_mask ;
   u64 coherent_dma_mask ;
   unsigned long dma_pfn_offset ;
    klee_make_symbolic(&dma_pfn_offset, sizeof(long), "dma_pfn_offset");
   struct device_dma_parameters *dma_parms ;
   struct list_head dma_pools ;
   struct dma_coherent_mem *dma_mem ;
   struct cma *cma_area ;
   struct dev_archdata archdata ;
   struct device_node *of_node ;
   struct fwnode_handle *fwnode ;
   dev_t devt ;
   u32 id ;
   spinlock_t devres_lock ;
   struct list_head devres_head ;
   struct klist_node knode_class ;
   struct class *class ;
   struct attribute_group  const  **groups ;
   void (*release)(struct device * ) ;
   struct iommu_group *iommu_group ;
   bool offline_disabled ;
   bool offline ;
};
struct wakeup_source {
   char const   *name ;
   struct list_head entry ;
   spinlock_t lock ;
   struct wake_irq *wakeirq ;
   struct timer_list timer ;
   unsigned long timer_expires ;
   ktime_t total_time ;
   ktime_t max_time ;
   ktime_t last_time ;
   ktime_t start_prevent_time ;
   ktime_t prevent_sleep_time ;
   unsigned long event_count ;
    klee_make_symbolic(&event_count, sizeof(long), "event_count");
   unsigned long active_count ;
    klee_make_symbolic(&active_count, sizeof(long), "active_count");
   unsigned long relax_count ;
    klee_make_symbolic(&relax_count, sizeof(long), "relax_count");
   unsigned long expire_count ;
    klee_make_symbolic(&expire_count, sizeof(long), "expire_count");
   unsigned long wakeup_count ;
    klee_make_symbolic(&wakeup_count, sizeof(long), "wakeup_count");
   bool active ;
   bool autosleep_enabled ;
};
struct dma_attrs {
   unsigned long flags[1U] ;
};
enum dma_data_direction {
    DMA_BIDIRECTIONAL = 0,
    DMA_TO_DEVICE = 1,
    DMA_FROM_DEVICE = 2,
    DMA_NONE = 3
} ;
struct shrink_control {
   gfp_t gfp_mask ;
   unsigned long nr_to_scan ;
    klee_make_symbolic(&nr_to_scan, sizeof(long), "nr_to_scan");
   int nid ;
    klee_make_symbolic(&nid, sizeof(int), "nid");
   struct mem_cgroup *memcg ;
};
struct shrinker {
   unsigned long (*count_objects)(struct shrinker * , struct shrink_control * ) ;
   unsigned long (*scan_objects)(struct shrinker * , struct shrink_control * ) ;
   int seeks ;
    klee_make_symbolic(&seeks, sizeof(int), "seeks");
   long batch ;
    klee_make_symbolic(&batch, sizeof(long), "batch");
   unsigned long flags ;
   struct list_head list ;
   atomic_long_t *nr_deferred ;
};
struct file_ra_state;
struct writeback_control;
struct bdi_writeback;
struct vm_fault {
   unsigned int flags ;
   unsigned long pgoff ;
    klee_make_symbolic(&pgoff, sizeof(long), "pgoff");
   void *virtual_address ;
   struct page *cow_page ;
   struct page *page ;
   unsigned long max_pgoff ;
    klee_make_symbolic(&max_pgoff, sizeof(long), "max_pgoff");
   pte_t *pte ;
};
struct vm_operations_struct {
   void (*open)(struct vm_area_struct * ) ;
   void (*close)(struct vm_area_struct * ) ;
   int (*fault)(struct vm_area_struct * , struct vm_fault * ) ;
   void (*map_pages)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*page_mkwrite)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*pfn_mkwrite)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*access)(struct vm_area_struct * , unsigned long  , void * , int  , int  ) ;
   char const   *(*name)(struct vm_area_struct * ) ;
   int (*set_policy)(struct vm_area_struct * , struct mempolicy * ) ;
   struct mempolicy *(*get_policy)(struct vm_area_struct * , unsigned long  ) ;
   struct page *(*find_special_page)(struct vm_area_struct * , unsigned long  ) ;
};
struct scatterlist {
   unsigned long sg_magic ;
    klee_make_symbolic(&sg_magic, sizeof(long), "sg_magic");
   unsigned long page_link ;
    klee_make_symbolic(&page_link, sizeof(long), "page_link");
   unsigned int offset ;
    klee_make_symbolic(&offset, sizeof(int), "offset");
   unsigned int length ;
    klee_make_symbolic(&length, sizeof(int), "length");
   dma_addr_t dma_address ;
   unsigned int dma_length ;
    klee_make_symbolic(&dma_length, sizeof(int), "dma_length");
};
struct sg_table {
   struct scatterlist *sgl ;
   unsigned int nents ;
    klee_make_symbolic(&nents, sizeof(int), "nents");
   unsigned int orig_nents ;
    klee_make_symbolic(&orig_nents, sizeof(int), "orig_nents");
};
struct dma_map_ops {
   void *(*alloc)(struct device * , size_t  , dma_addr_t * , gfp_t  , struct dma_attrs * ) ;
   void (*free)(struct device * , size_t  , void * , dma_addr_t  , struct dma_attrs * ) ;
   int (*mmap)(struct device * , struct vm_area_struct * , void * , dma_addr_t  ,
               size_t  , struct dma_attrs * ) ;
   int (*get_sgtable)(struct device * , struct sg_table * , void * , dma_addr_t  ,
                      size_t  , struct dma_attrs * ) ;
   dma_addr_t (*map_page)(struct device * , struct page * , unsigned long  , size_t  ,
                          enum dma_data_direction  , struct dma_attrs * ) ;
   void (*unmap_page)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ,
                      struct dma_attrs * ) ;
   int (*map_sg)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ,
                 struct dma_attrs * ) ;
   void (*unmap_sg)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ,
                    struct dma_attrs * ) ;
   void (*sync_single_for_cpu)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ) ;
   void (*sync_single_for_device)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ) ;
   void (*sync_sg_for_cpu)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ) ;
   void (*sync_sg_for_device)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ) ;
   int (*mapping_error)(struct device * , dma_addr_t  ) ;
   int (*dma_supported)(struct device * , u64  ) ;
   int (*set_dma_mask)(struct device * , u64  ) ;
   int is_phys ;
    klee_make_symbolic(&is_phys, sizeof(int), "is_phys");
};
typedef u64 netdev_features_t;
union __anonunion_in6_u_207 {
   __u8 u6_addr8[16U] ;
   __be16 u6_addr16[8U] ;
   __be32 u6_addr32[4U] ;
};
struct in6_addr {
   union __anonunion_in6_u_207 in6_u ;
};
struct ethhdr {
   unsigned char h_dest[6U] ;
   unsigned char h_source[6U] ;
   __be16 h_proto ;
};
struct pipe_buf_operations;
struct pipe_buffer {
   struct page *page ;
   unsigned int offset ;
   unsigned int len ;
    klee_make_symbolic(&len, sizeof(int), "len");
   struct pipe_buf_operations  const  *ops ;
   unsigned int flags ;
   unsigned long private ;
};
struct pipe_inode_info {
   struct mutex mutex ;
   wait_queue_head_t wait ;
   unsigned int nrbufs ;
    klee_make_symbolic(&nrbufs, sizeof(int), "nrbufs");
   unsigned int curbuf ;
    klee_make_symbolic(&curbuf, sizeof(int), "curbuf");
   unsigned int buffers ;
    klee_make_symbolic(&buffers, sizeof(int), "buffers");
   unsigned int readers ;
    klee_make_symbolic(&readers, sizeof(int), "readers");
   unsigned int writers ;
    klee_make_symbolic(&writers, sizeof(int), "writers");
   unsigned int files ;
    klee_make_symbolic(&files, sizeof(int), "files");
   unsigned int waiting_writers ;
    klee_make_symbolic(&waiting_writers, sizeof(int), "waiting_writers");
   unsigned int r_counter ;
    klee_make_symbolic(&r_counter, sizeof(int), "r_counter");
   unsigned int w_counter ;
    klee_make_symbolic(&w_counter, sizeof(int), "w_counter");
   struct page *tmp_page ;
   struct fasync_struct *fasync_readers ;
   struct fasync_struct *fasync_writers ;
   struct pipe_buffer *bufs ;
};
struct pipe_buf_operations {
   int can_merge ;
    klee_make_symbolic(&can_merge, sizeof(int), "can_merge");
   int (*confirm)(struct pipe_inode_info * , struct pipe_buffer * ) ;
   void (*release)(struct pipe_inode_info * , struct pipe_buffer * ) ;
   int (*steal)(struct pipe_inode_info * , struct pipe_buffer * ) ;
   void (*get)(struct pipe_inode_info * , struct pipe_buffer * ) ;
};
struct napi_struct;
struct nf_conntrack {
   atomic_t use ;
};
union __anonunion____missing_field_name_212 {
   struct net_device *physoutdev ;
   char neigh_header[8U] ;
};
union __anonunion____missing_field_name_213 {
   __be32 ipv4_daddr ;
   struct in6_addr ipv6_daddr ;
};
struct nf_bridge_info {
   atomic_t use ;
   unsigned char orig_proto ;
    klee_make_symbolic(&orig_proto, sizeof(char), "orig_proto");
   bool pkt_otherhost ;
   __u16 frag_max_size ;
   unsigned int mask ;
    klee_make_symbolic(&mask, sizeof(int), "mask");
   struct net_device *physindev ;
   union __anonunion____missing_field_name_212 __annonCompField61 ;
   union __anonunion____missing_field_name_213 __annonCompField62 ;
};
struct sk_buff_head {
   struct sk_buff *next ;
   struct sk_buff *prev ;
   __u32 qlen ;
   spinlock_t lock ;
};
typedef unsigned int sk_buff_data_t;
    klee_make_symbolic(&sk_buff_data_t, sizeof(int), "sk_buff_data_t");
struct __anonstruct____missing_field_name_216 {
   u32 stamp_us ;
   u32 stamp_jiffies ;
};
union __anonunion____missing_field_name_215 {
   u64 v64 ;
   struct __anonstruct____missing_field_name_216 __annonCompField63 ;
};
struct skb_mstamp {
   union __anonunion____missing_field_name_215 __annonCompField64 ;
};
union __anonunion____missing_field_name_219 {
   ktime_t tstamp ;
   struct skb_mstamp skb_mstamp ;
};
struct __anonstruct____missing_field_name_218 {
   struct sk_buff *next ;
   struct sk_buff *prev ;
   union __anonunion____missing_field_name_219 __annonCompField65 ;
};
union __anonunion____missing_field_name_217 {
   struct __anonstruct____missing_field_name_218 __annonCompField66 ;
   struct rb_node rbnode ;
};
struct sec_path;
struct __anonstruct____missing_field_name_221 {
   __u16 csum_start ;
   __u16 csum_offset ;
};
union __anonunion____missing_field_name_220 {
   __wsum csum ;
   struct __anonstruct____missing_field_name_221 __annonCompField68 ;
};
union __anonunion____missing_field_name_222 {
   unsigned int napi_id ;
    klee_make_symbolic(&napi_id, sizeof(int), "napi_id");
   unsigned int sender_cpu ;
    klee_make_symbolic(&sender_cpu, sizeof(int), "sender_cpu");
};
union __anonunion____missing_field_name_223 {
   __u32 mark ;
   __u32 reserved_tailroom ;
};
union __anonunion____missing_field_name_224 {
   __be16 inner_protocol ;
   __u8 inner_ipproto ;
};
struct sk_buff {
   union __anonunion____missing_field_name_217 __annonCompField67 ;
   struct sock *sk ;
   struct net_device *dev ;
   char cb[48U] ;
   unsigned long _skb_refdst ;
    klee_make_symbolic(&_skb_refdst, sizeof(long), "_skb_refdst");
   void (*destructor)(struct sk_buff * ) ;
   struct sec_path *sp ;
   struct nf_conntrack *nfct ;
   struct nf_bridge_info *nf_bridge ;
   unsigned int len ;
   unsigned int data_len ;
    klee_make_symbolic(&data_len, sizeof(int), "data_len");
   __u16 mac_len ;
   __u16 hdr_len ;
   __u16 queue_mapping ;
   unsigned char cloned : 1 ;
   unsigned char nohdr : 1 ;
   unsigned char fclone : 2 ;
   unsigned char peeked : 1 ;
   unsigned char head_frag : 1 ;
   unsigned char xmit_more : 1 ;
   __u32 headers_start[0U] ;
   __u8 __pkt_type_offset[0U] ;
   unsigned char pkt_type : 3 ;
   unsigned char pfmemalloc : 1 ;
   unsigned char ignore_df : 1 ;
   unsigned char nfctinfo : 3 ;
   unsigned char nf_trace : 1 ;
   unsigned char ip_summed : 2 ;
   unsigned char ooo_okay : 1 ;
   unsigned char l4_hash : 1 ;
   unsigned char sw_hash : 1 ;
   unsigned char wifi_acked_valid : 1 ;
   unsigned char wifi_acked : 1 ;
   unsigned char no_fcs : 1 ;
   unsigned char encapsulation : 1 ;
   unsigned char encap_hdr_csum : 1 ;
   unsigned char csum_valid : 1 ;
   unsigned char csum_complete_sw : 1 ;
   unsigned char csum_level : 2 ;
   unsigned char csum_bad : 1 ;
   unsigned char ndisc_nodetype : 2 ;
   unsigned char ipvs_property : 1 ;
   unsigned char inner_protocol_type : 1 ;
   unsigned char remcsum_offload : 1 ;
   __u16 tc_index ;
   __u16 tc_verd ;
   union __anonunion____missing_field_name_220 __annonCompField69 ;
   __u32 priority ;
   int skb_iif ;
    klee_make_symbolic(&skb_iif, sizeof(int), "skb_iif");
   __u32 hash ;
   __be16 vlan_proto ;
   __u16 vlan_tci ;
   union __anonunion____missing_field_name_222 __annonCompField70 ;
   __u32 secmark ;
   union __anonunion____missing_field_name_223 __annonCompField71 ;
   union __anonunion____missing_field_name_224 __annonCompField72 ;
   __u16 inner_transport_header ;
   __u16 inner_network_header ;
   __u16 inner_mac_header ;
   __be16 protocol ;
   __u16 transport_header ;
   __u16 network_header ;
   __u16 mac_header ;
   __u32 headers_end[0U] ;
   sk_buff_data_t tail ;
   sk_buff_data_t end ;
   unsigned char *head ;
   unsigned char *data ;
   unsigned int truesize ;
    klee_make_symbolic(&truesize, sizeof(int), "truesize");
   atomic_t users ;
};
struct dst_entry;
struct rtable;
struct proc_dir_entry;
struct hlist_nulls_node;
struct hlist_nulls_head {
   struct hlist_nulls_node *first ;
};
struct hlist_nulls_node {
   struct hlist_nulls_node *next ;
   struct hlist_nulls_node **pprev ;
};
struct dql {
   unsigned int num_queued ;
    klee_make_symbolic(&num_queued, sizeof(int), "num_queued");
   unsigned int adj_limit ;
    klee_make_symbolic(&adj_limit, sizeof(int), "adj_limit");
   unsigned int last_obj_cnt ;
    klee_make_symbolic(&last_obj_cnt, sizeof(int), "last_obj_cnt");
   unsigned int limit ;
    klee_make_symbolic(&limit, sizeof(int), "limit");
   unsigned int num_completed ;
    klee_make_symbolic(&num_completed, sizeof(int), "num_completed");
   unsigned int prev_ovlimit ;
    klee_make_symbolic(&prev_ovlimit, sizeof(int), "prev_ovlimit");
   unsigned int prev_num_queued ;
    klee_make_symbolic(&prev_num_queued, sizeof(int), "prev_num_queued");
   unsigned int prev_last_obj_cnt ;
    klee_make_symbolic(&prev_last_obj_cnt, sizeof(int), "prev_last_obj_cnt");
   unsigned int lowest_slack ;
    klee_make_symbolic(&lowest_slack, sizeof(int), "lowest_slack");
   unsigned long slack_start_time ;
    klee_make_symbolic(&slack_start_time, sizeof(long), "slack_start_time");
   unsigned int max_limit ;
    klee_make_symbolic(&max_limit, sizeof(int), "max_limit");
   unsigned int min_limit ;
    klee_make_symbolic(&min_limit, sizeof(int), "min_limit");
   unsigned int slack_hold_time ;
    klee_make_symbolic(&slack_hold_time, sizeof(int), "slack_hold_time");
};
struct __anonstruct_sync_serial_settings_234 {
   unsigned int clock_rate ;
    klee_make_symbolic(&clock_rate, sizeof(int), "clock_rate");
   unsigned int clock_type ;
    klee_make_symbolic(&clock_type, sizeof(int), "clock_type");
   unsigned short loopback ;
    klee_make_symbolic(&loopback, sizeof(short), "loopback");
};
typedef struct __anonstruct_sync_serial_settings_234 sync_serial_settings;
struct __anonstruct_te1_settings_235 {
   unsigned int clock_rate ;
   unsigned int clock_type ;
   unsigned short loopback ;
   unsigned int slot_map ;
    klee_make_symbolic(&slot_map, sizeof(int), "slot_map");
};
typedef struct __anonstruct_te1_settings_235 te1_settings;
struct __anonstruct_raw_hdlc_proto_236 {
   unsigned short encoding ;
    klee_make_symbolic(&encoding, sizeof(short), "encoding");
   unsigned short parity ;
    klee_make_symbolic(&parity, sizeof(short), "parity");
};
typedef struct __anonstruct_raw_hdlc_proto_236 raw_hdlc_proto;
struct __anonstruct_fr_proto_237 {
   unsigned int t391 ;
    klee_make_symbolic(&t391, sizeof(int), "t391");
   unsigned int t392 ;
    klee_make_symbolic(&t392, sizeof(int), "t392");
   unsigned int n391 ;
    klee_make_symbolic(&n391, sizeof(int), "n391");
   unsigned int n392 ;
    klee_make_symbolic(&n392, sizeof(int), "n392");
   unsigned int n393 ;
    klee_make_symbolic(&n393, sizeof(int), "n393");
   unsigned short lmi ;
    klee_make_symbolic(&lmi, sizeof(short), "lmi");
   unsigned short dce ;
    klee_make_symbolic(&dce, sizeof(short), "dce");
};
typedef struct __anonstruct_fr_proto_237 fr_proto;
struct __anonstruct_fr_proto_pvc_238 {
   unsigned int dlci ;
    klee_make_symbolic(&dlci, sizeof(int), "dlci");
};
typedef struct __anonstruct_fr_proto_pvc_238 fr_proto_pvc;
struct __anonstruct_fr_proto_pvc_info_239 {
   unsigned int dlci ;
   char master[16U] ;
};
typedef struct __anonstruct_fr_proto_pvc_info_239 fr_proto_pvc_info;
struct __anonstruct_cisco_proto_240 {
   unsigned int interval ;
    klee_make_symbolic(&interval, sizeof(int), "interval");
   unsigned int timeout ;
};
typedef struct __anonstruct_cisco_proto_240 cisco_proto;
struct ifmap {
   unsigned long mem_start ;
    klee_make_symbolic(&mem_start, sizeof(long), "mem_start");
   unsigned long mem_end ;
    klee_make_symbolic(&mem_end, sizeof(long), "mem_end");
   unsigned short base_addr ;
    klee_make_symbolic(&base_addr, sizeof(short), "base_addr");
   unsigned char irq ;
    klee_make_symbolic(&irq, sizeof(char), "irq");
   unsigned char dma ;
    klee_make_symbolic(&dma, sizeof(char), "dma");
   unsigned char port ;
    klee_make_symbolic(&port, sizeof(char), "port");
};
union __anonunion_ifs_ifsu_241 {
   raw_hdlc_proto *raw_hdlc ;
   cisco_proto *cisco ;
   fr_proto *fr ;
   fr_proto_pvc *fr_pvc ;
   fr_proto_pvc_info *fr_pvc_info ;
   sync_serial_settings *sync ;
   te1_settings *te1 ;
};
struct if_settings {
   unsigned int type ;
   unsigned int size ;
   union __anonunion_ifs_ifsu_241 ifs_ifsu ;
};
union __anonunion_ifr_ifrn_242 {
   char ifrn_name[16U] ;
};
union __anonunion_ifr_ifru_243 {
   struct sockaddr ifru_addr ;
   struct sockaddr ifru_dstaddr ;
   struct sockaddr ifru_broadaddr ;
   struct sockaddr ifru_netmask ;
   struct sockaddr ifru_hwaddr ;
   short ifru_flags ;
    klee_make_symbolic(&ifru_flags, sizeof(short), "ifru_flags");
   int ifru_ivalue ;
    klee_make_symbolic(&ifru_ivalue, sizeof(int), "ifru_ivalue");
   int ifru_mtu ;
    klee_make_symbolic(&ifru_mtu, sizeof(int), "ifru_mtu");
   struct ifmap ifru_map ;
   char ifru_slave[16U] ;
   char ifru_newname[16U] ;
   void *ifru_data ;
   struct if_settings ifru_settings ;
};
struct ifreq {
   union __anonunion_ifr_ifrn_242 ifr_ifrn ;
   union __anonunion_ifr_ifru_243 ifr_ifru ;
};
struct hlist_bl_node;
struct hlist_bl_head {
   struct hlist_bl_node *first ;
};
struct hlist_bl_node {
   struct hlist_bl_node *next ;
   struct hlist_bl_node **pprev ;
};
struct __anonstruct____missing_field_name_248 {
   spinlock_t lock ;
   int count ;
};
union __anonunion____missing_field_name_247 {
   struct __anonstruct____missing_field_name_248 __annonCompField80 ;
};
struct lockref {
   union __anonunion____missing_field_name_247 __annonCompField81 ;
};
struct vfsmount;
struct __anonstruct____missing_field_name_250 {
   u32 hash ;
   u32 len ;
};
union __anonunion____missing_field_name_249 {
   struct __anonstruct____missing_field_name_250 __annonCompField82 ;
   u64 hash_len ;
};
struct qstr {
   union __anonunion____missing_field_name_249 __annonCompField83 ;
   unsigned char const   *name ;
};
struct dentry_operations;
union __anonunion_d_u_251 {
   struct hlist_node d_alias ;
   struct callback_head d_rcu ;
};
struct dentry {
   unsigned int d_flags ;
    klee_make_symbolic(&d_flags, sizeof(int), "d_flags");
   seqcount_t d_seq ;
   struct hlist_bl_node d_hash ;
   struct dentry *d_parent ;
   struct qstr d_name ;
   struct inode *d_inode ;
   unsigned char d_iname[32U] ;
   struct lockref d_lockref ;
   struct dentry_operations  const  *d_op ;
   struct super_block *d_sb ;
   unsigned long d_time ;
    klee_make_symbolic(&d_time, sizeof(long), "d_time");
   void *d_fsdata ;
   struct list_head d_lru ;
   struct list_head d_child ;
   struct list_head d_subdirs ;
   union __anonunion_d_u_251 d_u ;
};
struct dentry_operations {
   int (*d_revalidate)(struct dentry * , unsigned int  ) ;
   int (*d_weak_revalidate)(struct dentry * , unsigned int  ) ;
   int (*d_hash)(struct dentry  const  * , struct qstr * ) ;
   int (*d_compare)(struct dentry  const  * , struct dentry  const  * , unsigned int  ,
                    char const   * , struct qstr  const  * ) ;
   int (*d_delete)(struct dentry  const  * ) ;
   void (*d_release)(struct dentry * ) ;
   void (*d_prune)(struct dentry * ) ;
   void (*d_iput)(struct dentry * , struct inode * ) ;
   char *(*d_dname)(struct dentry * , char * , int  ) ;
   struct vfsmount *(*d_automount)(struct path * ) ;
   int (*d_manage)(struct dentry * , bool  ) ;
   struct inode *(*d_select_inode)(struct dentry * , unsigned int  ) ;
};
struct path {
   struct vfsmount *mnt ;
   struct dentry *dentry ;
};
struct list_lru_one {
   struct list_head list ;
   long nr_items ;
    klee_make_symbolic(&nr_items, sizeof(long), "nr_items");
};
struct list_lru_memcg {
   struct list_lru_one *lru[0U] ;
};
struct list_lru_node {
   spinlock_t lock ;
   struct list_lru_one lru ;
   struct list_lru_memcg *memcg_lrus ;
};
struct list_lru {
   struct list_lru_node *node ;
   struct list_head list ;
};
struct __anonstruct____missing_field_name_255 {
   struct radix_tree_node *parent ;
   void *private_data ;
};
union __anonunion____missing_field_name_254 {
   struct __anonstruct____missing_field_name_255 __annonCompField84 ;
   struct callback_head callback_head ;
};
struct radix_tree_node {
   unsigned int path ;
    klee_make_symbolic(&path, sizeof(int), "path");
   unsigned int count ;
   union __anonunion____missing_field_name_254 __annonCompField85 ;
   struct list_head private_list ;
   void *slots[64U] ;
   unsigned long tags[3U][1U] ;
};
struct radix_tree_root {
   unsigned int height ;
    klee_make_symbolic(&height, sizeof(int), "height");
   gfp_t gfp_mask ;
   struct radix_tree_node *rnode ;
};
struct fiemap_extent {
   __u64 fe_logical ;
   __u64 fe_physical ;
   __u64 fe_length ;
   __u64 fe_reserved64[2U] ;
   __u32 fe_flags ;
   __u32 fe_reserved[3U] ;
};
enum migrate_mode {
    MIGRATE_ASYNC = 0,
    MIGRATE_SYNC_LIGHT = 1,
    MIGRATE_SYNC = 2
} ;
struct block_device;
struct bio_vec {
   struct page *bv_page ;
   unsigned int bv_len ;
    klee_make_symbolic(&bv_len, sizeof(int), "bv_len");
   unsigned int bv_offset ;
    klee_make_symbolic(&bv_offset, sizeof(int), "bv_offset");
};
struct export_operations;
struct kstatfs;
struct swap_info_struct;
struct iattr {
   unsigned int ia_valid ;
    klee_make_symbolic(&ia_valid, sizeof(int), "ia_valid");
   umode_t ia_mode ;
   kuid_t ia_uid ;
   kgid_t ia_gid ;
   loff_t ia_size ;
   struct timespec ia_atime ;
   struct timespec ia_mtime ;
   struct timespec ia_ctime ;
   struct file *ia_file ;
};
struct dquot;
typedef __kernel_uid32_t projid_t;
struct __anonstruct_kprojid_t_259 {
   projid_t val ;
};
typedef struct __anonstruct_kprojid_t_259 kprojid_t;
enum quota_type {
    USRQUOTA = 0,
    GRPQUOTA = 1,
    PRJQUOTA = 2
} ;
typedef long long qsize_t;
    klee_make_symbolic(&qsize_t, sizeof(long), "qsize_t");
union __anonunion____missing_field_name_260 {
   kuid_t uid ;
   kgid_t gid ;
   kprojid_t projid ;
};
struct kqid {
   union __anonunion____missing_field_name_260 __annonCompField87 ;
   enum quota_type type ;
};
struct mem_dqblk {
   qsize_t dqb_bhardlimit ;
   qsize_t dqb_bsoftlimit ;
   qsize_t dqb_curspace ;
   qsize_t dqb_rsvspace ;
   qsize_t dqb_ihardlimit ;
   qsize_t dqb_isoftlimit ;
   qsize_t dqb_curinodes ;
   time_t dqb_btime ;
   time_t dqb_itime ;
};
struct quota_format_type;
struct mem_dqinfo {
   struct quota_format_type *dqi_format ;
   int dqi_fmt_id ;
    klee_make_symbolic(&dqi_fmt_id, sizeof(int), "dqi_fmt_id");
   struct list_head dqi_dirty_list ;
   unsigned long dqi_flags ;
    klee_make_symbolic(&dqi_flags, sizeof(long), "dqi_flags");
   unsigned int dqi_bgrace ;
    klee_make_symbolic(&dqi_bgrace, sizeof(int), "dqi_bgrace");
   unsigned int dqi_igrace ;
    klee_make_symbolic(&dqi_igrace, sizeof(int), "dqi_igrace");
   qsize_t dqi_max_spc_limit ;
   qsize_t dqi_max_ino_limit ;
   void *dqi_priv ;
};
struct dquot {
   struct hlist_node dq_hash ;
   struct list_head dq_inuse ;
   struct list_head dq_free ;
   struct list_head dq_dirty ;
   struct mutex dq_lock ;
   atomic_t dq_count ;
   wait_queue_head_t dq_wait_unused ;
   struct super_block *dq_sb ;
   struct kqid dq_id ;
   loff_t dq_off ;
   unsigned long dq_flags ;
    klee_make_symbolic(&dq_flags, sizeof(long), "dq_flags");
   struct mem_dqblk dq_dqb ;
};
struct quota_format_ops {
   int (*check_quota_file)(struct super_block * , int  ) ;
   int (*read_file_info)(struct super_block * , int  ) ;
   int (*write_file_info)(struct super_block * , int  ) ;
   int (*free_file_info)(struct super_block * , int  ) ;
   int (*read_dqblk)(struct dquot * ) ;
   int (*commit_dqblk)(struct dquot * ) ;
   int (*release_dqblk)(struct dquot * ) ;
};
struct dquot_operations {
   int (*write_dquot)(struct dquot * ) ;
   struct dquot *(*alloc_dquot)(struct super_block * , int  ) ;
   void (*destroy_dquot)(struct dquot * ) ;
   int (*acquire_dquot)(struct dquot * ) ;
   int (*release_dquot)(struct dquot * ) ;
   int (*mark_dirty)(struct dquot * ) ;
   int (*write_info)(struct super_block * , int  ) ;
   qsize_t *(*get_reserved_space)(struct inode * ) ;
   int (*get_projid)(struct inode * , kprojid_t * ) ;
};
struct qc_dqblk {
   int d_fieldmask ;
    klee_make_symbolic(&d_fieldmask, sizeof(int), "d_fieldmask");
   u64 d_spc_hardlimit ;
   u64 d_spc_softlimit ;
   u64 d_ino_hardlimit ;
   u64 d_ino_softlimit ;
   u64 d_space ;
   u64 d_ino_count ;
   s64 d_ino_timer ;
   s64 d_spc_timer ;
   int d_ino_warns ;
    klee_make_symbolic(&d_ino_warns, sizeof(int), "d_ino_warns");
   int d_spc_warns ;
    klee_make_symbolic(&d_spc_warns, sizeof(int), "d_spc_warns");
   u64 d_rt_spc_hardlimit ;
   u64 d_rt_spc_softlimit ;
   u64 d_rt_space ;
   s64 d_rt_spc_timer ;
   int d_rt_spc_warns ;
    klee_make_symbolic(&d_rt_spc_warns, sizeof(int), "d_rt_spc_warns");
};
struct qc_type_state {
   unsigned int flags ;
   unsigned int spc_timelimit ;
    klee_make_symbolic(&spc_timelimit, sizeof(int), "spc_timelimit");
   unsigned int ino_timelimit ;
    klee_make_symbolic(&ino_timelimit, sizeof(int), "ino_timelimit");
   unsigned int rt_spc_timelimit ;
    klee_make_symbolic(&rt_spc_timelimit, sizeof(int), "rt_spc_timelimit");
   unsigned int spc_warnlimit ;
    klee_make_symbolic(&spc_warnlimit, sizeof(int), "spc_warnlimit");
   unsigned int ino_warnlimit ;
    klee_make_symbolic(&ino_warnlimit, sizeof(int), "ino_warnlimit");
   unsigned int rt_spc_warnlimit ;
    klee_make_symbolic(&rt_spc_warnlimit, sizeof(int), "rt_spc_warnlimit");
   unsigned long long ino ;
   blkcnt_t blocks ;
   blkcnt_t nextents ;
};
struct qc_state {
   unsigned int s_incoredqs ;
    klee_make_symbolic(&s_incoredqs, sizeof(int), "s_incoredqs");
   struct qc_type_state s_state[3U] ;
};
struct qc_info {
   int i_fieldmask ;
    klee_make_symbolic(&i_fieldmask, sizeof(int), "i_fieldmask");
   unsigned int i_flags ;
    klee_make_symbolic(&i_flags, sizeof(int), "i_flags");
   unsigned int i_spc_timelimit ;
    klee_make_symbolic(&i_spc_timelimit, sizeof(int), "i_spc_timelimit");
   unsigned int i_ino_timelimit ;
    klee_make_symbolic(&i_ino_timelimit, sizeof(int), "i_ino_timelimit");
   unsigned int i_rt_spc_timelimit ;
    klee_make_symbolic(&i_rt_spc_timelimit, sizeof(int), "i_rt_spc_timelimit");
   unsigned int i_spc_warnlimit ;
    klee_make_symbolic(&i_spc_warnlimit, sizeof(int), "i_spc_warnlimit");
   unsigned int i_ino_warnlimit ;
    klee_make_symbolic(&i_ino_warnlimit, sizeof(int), "i_ino_warnlimit");
   unsigned int i_rt_spc_warnlimit ;
    klee_make_symbolic(&i_rt_spc_warnlimit, sizeof(int), "i_rt_spc_warnlimit");
};
struct quotactl_ops {
   int (*quota_on)(struct super_block * , int  , int  , struct path * ) ;
   int (*quota_off)(struct super_block * , int  ) ;
   int (*quota_enable)(struct super_block * , unsigned int  ) ;
   int (*quota_disable)(struct super_block * , unsigned int  ) ;
   int (*quota_sync)(struct super_block * , int  ) ;
   int (*set_info)(struct super_block * , int  , struct qc_info * ) ;
   int (*get_dqblk)(struct super_block * , struct kqid  , struct qc_dqblk * ) ;
   int (*set_dqblk)(struct super_block * , struct kqid  , struct qc_dqblk * ) ;
   int (*get_state)(struct super_block * , struct qc_state * ) ;
   int (*rm_xquota)(struct super_block * , unsigned int  ) ;
};
struct quota_format_type {
   int qf_fmt_id ;
    klee_make_symbolic(&qf_fmt_id, sizeof(int), "qf_fmt_id");
   struct quota_format_ops  const  *qf_ops ;
   struct module *qf_owner ;
   struct quota_format_type *qf_next ;
};
struct quota_info {
   unsigned int flags ;
   struct mutex dqio_mutex ;
   struct mutex dqonoff_mutex ;
   struct inode *files[3U] ;
   struct mem_dqinfo info[3U] ;
   struct quota_format_ops  const  *ops[3U] ;
};
struct kiocb {
   struct file *ki_filp ;
   loff_t ki_pos ;
   void (*ki_complete)(struct kiocb * , long  , long  ) ;
   void *private ;
   int ki_flags ;
    klee_make_symbolic(&ki_flags, sizeof(int), "ki_flags");
};
struct address_space_operations {
   int (*writepage)(struct page * , struct writeback_control * ) ;
   int (*readpage)(struct file * , struct page * ) ;
   int (*writepages)(struct address_space * , struct writeback_control * ) ;
   int (*set_page_dirty)(struct page * ) ;
   int (*readpages)(struct file * , struct address_space * , struct list_head * ,
                    unsigned int  ) ;
   int (*write_begin)(struct file * , struct address_space * , loff_t  , unsigned int  ,
                      unsigned int  , struct page ** , void ** ) ;
   int (*write_end)(struct file * , struct address_space * , loff_t  , unsigned int  ,
                    unsigned int  , struct page * , void * ) ;
   sector_t (*bmap)(struct address_space * , sector_t  ) ;
   void (*invalidatepage)(struct page * , unsigned int  , unsigned int  ) ;
   int (*releasepage)(struct page * , gfp_t  ) ;
   void (*freepage)(struct page * ) ;
   ssize_t (*direct_IO)(struct kiocb * , struct iov_iter * , loff_t  ) ;
   int (*migratepage)(struct address_space * , struct page * , struct page * , enum migrate_mode  ) ;
   int (*launder_page)(struct page * ) ;
   int (*is_partially_uptodate)(struct page * , unsigned long  , unsigned long  ) ;
   void (*is_dirty_writeback)(struct page * , bool * , bool * ) ;
   int (*error_remove_page)(struct address_space * , struct page * ) ;
   int (*swap_activate)(struct swap_info_struct * , struct file * , sector_t * ) ;
   void (*swap_deactivate)(struct file * ) ;
};
struct address_space {
   struct inode *host ;
   struct radix_tree_root page_tree ;
   spinlock_t tree_lock ;
   atomic_t i_mmap_writable ;
   struct rb_root i_mmap ;
   struct rw_semaphore i_mmap_rwsem ;
   unsigned long nrpages ;
    klee_make_symbolic(&nrpages, sizeof(long), "nrpages");
   unsigned long nrshadows ;
    klee_make_symbolic(&nrshadows, sizeof(long), "nrshadows");
   unsigned long writeback_index ;
    klee_make_symbolic(&writeback_index, sizeof(long), "writeback_index");
   struct address_space_operations  const  *a_ops ;
   unsigned long flags ;
   spinlock_t private_lock ;
   struct list_head private_list ;
   void *private_data ;
};
struct request_queue;
struct hd_struct;
struct gendisk;
struct block_device {
   dev_t bd_dev ;
   int bd_openers ;
    klee_make_symbolic(&bd_openers, sizeof(int), "bd_openers");
   struct inode *bd_inode ;
   struct super_block *bd_super ;
   struct mutex bd_mutex ;
   struct list_head bd_inodes ;
   void *bd_claiming ;
   void *bd_holder ;
   int bd_holders ;
    klee_make_symbolic(&bd_holders, sizeof(int), "bd_holders");
   bool bd_write_holder ;
   struct list_head bd_holder_disks ;
   struct block_device *bd_contains ;
   unsigned int bd_block_size ;
    klee_make_symbolic(&bd_block_size, sizeof(int), "bd_block_size");
   struct hd_struct *bd_part ;
   unsigned int bd_part_count ;
    klee_make_symbolic(&bd_part_count, sizeof(int), "bd_part_count");
   int bd_invalidated ;
    klee_make_symbolic(&bd_invalidated, sizeof(int), "bd_invalidated");
   struct gendisk *bd_disk ;
   struct request_queue *bd_queue ;
   struct list_head bd_list ;
   unsigned long bd_private ;
    klee_make_symbolic(&bd_private, sizeof(long), "bd_private");
   int bd_fsfreeze_count ;
    klee_make_symbolic(&bd_fsfreeze_count, sizeof(int), "bd_fsfreeze_count");
   struct mutex bd_fsfreeze_mutex ;
};
struct posix_acl;
struct inode_operations;
union __anonunion____missing_field_name_263 {
   unsigned int const   i_nlink ;
   unsigned int __i_nlink ;
    klee_make_symbolic(&__i_nlink, sizeof(int), "__i_nlink");
};
union __anonunion____missing_field_name_264 {
   struct hlist_head i_dentry ;
   struct callback_head i_rcu ;
};
struct file_lock_context;
struct cdev;
union __anonunion____missing_field_name_265 {
   struct pipe_inode_info *i_pipe ;
   struct block_device *i_bdev ;
   struct cdev *i_cdev ;
   char *i_link ;
};
struct inode {
   umode_t i_mode ;
   unsigned short i_opflags ;
    klee_make_symbolic(&i_opflags, sizeof(short), "i_opflags");
   kuid_t i_uid ;
   kgid_t i_gid ;
   unsigned int i_flags ;
   struct posix_acl *i_acl ;
   struct posix_acl *i_default_acl ;
   struct inode_operations  const  *i_op ;
   struct super_block *i_sb ;
   struct address_space *i_mapping ;
   void *i_security ;
   unsigned long i_ino ;
    klee_make_symbolic(&i_ino, sizeof(long), "i_ino");
   union __anonunion____missing_field_name_263 __annonCompField88 ;
   dev_t i_rdev ;
   loff_t i_size ;
   struct timespec i_atime ;
   struct timespec i_mtime ;
   struct timespec i_ctime ;
   spinlock_t i_lock ;
   unsigned short i_bytes ;
    klee_make_symbolic(&i_bytes, sizeof(short), "i_bytes");
   unsigned int i_blkbits ;
    klee_make_symbolic(&i_blkbits, sizeof(int), "i_blkbits");
   blkcnt_t i_blocks ;
   unsigned long i_state ;
    klee_make_symbolic(&i_state, sizeof(long), "i_state");
   struct mutex i_mutex ;
   unsigned long dirtied_when ;
    klee_make_symbolic(&dirtied_when, sizeof(long), "dirtied_when");
   unsigned long dirtied_time_when ;
    klee_make_symbolic(&dirtied_time_when, sizeof(long), "dirtied_time_when");
   struct hlist_node i_hash ;
   struct list_head i_wb_list ;
   struct bdi_writeback *i_wb ;
   int i_wb_frn_winner ;
    klee_make_symbolic(&i_wb_frn_winner, sizeof(int), "i_wb_frn_winner");
   u16 i_wb_frn_avg_time ;
   u16 i_wb_frn_history ;
   struct list_head i_lru ;
   struct list_head i_sb_list ;
   union __anonunion____missing_field_name_264 __annonCompField89 ;
   u64 i_version ;
   atomic_t i_count ;
   atomic_t i_dio_count ;
   atomic_t i_writecount ;
   atomic_t i_readcount ;
   struct file_operations  const  *i_fop ;
   struct file_lock_context *i_flctx ;
   struct address_space i_data ;
   struct list_head i_devices ;
   union __anonunion____missing_field_name_265 __annonCompField90 ;
   __u32 i_generation ;
   __u32 i_fsnotify_mask ;
   struct hlist_head i_fsnotify_marks ;
   void *i_private ;
};
struct fown_struct {
   rwlock_t lock ;
   struct pid *pid ;
   enum pid_type pid_type ;
   kuid_t uid ;
   kuid_t euid ;
   int signum ;
    klee_make_symbolic(&signum, sizeof(int), "signum");
};
struct file_ra_state {
   unsigned long start ;
    klee_make_symbolic(&start, sizeof(long), "start");
   unsigned int size ;
   unsigned int async_size ;
    klee_make_symbolic(&async_size, sizeof(int), "async_size");
   unsigned int ra_pages ;
    klee_make_symbolic(&ra_pages, sizeof(int), "ra_pages");
   unsigned int mmap_miss ;
    klee_make_symbolic(&mmap_miss, sizeof(int), "mmap_miss");
   loff_t prev_pos ;
};
union __anonunion_f_u_266 {
   struct llist_node fu_llist ;
   struct callback_head fu_rcuhead ;
};
struct file {
   union __anonunion_f_u_266 f_u ;
   struct path f_path ;
   struct inode *f_inode ;
   struct file_operations  const  *f_op ;
   spinlock_t f_lock ;
   atomic_long_t f_count ;
   unsigned int f_flags ;
    klee_make_symbolic(&f_flags, sizeof(int), "f_flags");
   fmode_t f_mode ;
   struct mutex f_pos_lock ;
   loff_t f_pos ;
   struct fown_struct f_owner ;
   struct cred  const  *f_cred ;
   struct file_ra_state f_ra ;
   u64 f_version ;
   void *f_security ;
   void *private_data ;
   struct list_head f_ep_links ;
   struct list_head f_tfile_llink ;
   struct address_space *f_mapping ;
};
typedef void *fl_owner_t;
struct file_lock;
struct file_lock_operations {
   void (*fl_copy_lock)(struct file_lock * , struct file_lock * ) ;
   void (*fl_release_private)(struct file_lock * ) ;
};
struct lock_manager_operations {
   int (*lm_compare_owner)(struct file_lock * , struct file_lock * ) ;
   unsigned long (*lm_owner_key)(struct file_lock * ) ;
   fl_owner_t (*lm_get_owner)(fl_owner_t  ) ;
   void (*lm_put_owner)(fl_owner_t  ) ;
   void (*lm_notify)(struct file_lock * ) ;
   int (*lm_grant)(struct file_lock * , int  ) ;
   bool (*lm_break)(struct file_lock * ) ;
   int (*lm_change)(struct file_lock * , int  , struct list_head * ) ;
   void (*lm_setup)(struct file_lock * , void ** ) ;
};
struct nlm_lockowner;
struct nfs_lock_info {
   u32 state ;
   struct nlm_lockowner *owner ;
   struct list_head list ;
};
struct nfs4_lock_state;
struct nfs4_lock_info {
   struct nfs4_lock_state *owner ;
};
struct __anonstruct_afs_268 {
   struct list_head link ;
   int state ;
};
union __anonunion_fl_u_267 {
   struct nfs_lock_info nfs_fl ;
   struct nfs4_lock_info nfs4_fl ;
   struct __anonstruct_afs_268 afs ;
};
struct file_lock {
   struct file_lock *fl_next ;
   struct list_head fl_list ;
   struct hlist_node fl_link ;
   struct list_head fl_block ;
   fl_owner_t fl_owner ;
   unsigned int fl_flags ;
    klee_make_symbolic(&fl_flags, sizeof(int), "fl_flags");
   unsigned char fl_type ;
    klee_make_symbolic(&fl_type, sizeof(char), "fl_type");
   unsigned int fl_pid ;
    klee_make_symbolic(&fl_pid, sizeof(int), "fl_pid");
   int fl_link_cpu ;
    klee_make_symbolic(&fl_link_cpu, sizeof(int), "fl_link_cpu");
   struct pid *fl_nspid ;
   wait_queue_head_t fl_wait ;
   struct file *fl_file ;
   loff_t fl_start ;
   loff_t fl_end ;
   struct fasync_struct *fl_fasync ;
   unsigned long fl_break_time ;
    klee_make_symbolic(&fl_break_time, sizeof(long), "fl_break_time");
   unsigned long fl_downgrade_time ;
    klee_make_symbolic(&fl_downgrade_time, sizeof(long), "fl_downgrade_time");
   struct file_lock_operations  const  *fl_ops ;
   struct lock_manager_operations  const  *fl_lmops ;
   union __anonunion_fl_u_267 fl_u ;
};
struct file_lock_context {
   spinlock_t flc_lock ;
   struct list_head flc_flock ;
   struct list_head flc_posix ;
   struct list_head flc_lease ;
};
struct fasync_struct {
   spinlock_t fa_lock ;
   int magic ;
   int fa_fd ;
    klee_make_symbolic(&fa_fd, sizeof(int), "fa_fd");
   struct fasync_struct *fa_next ;
   struct file *fa_file ;
   struct callback_head fa_rcu ;
};
struct sb_writers {
   struct percpu_counter counter[3U] ;
   wait_queue_head_t wait ;
   int frozen ;
    klee_make_symbolic(&frozen, sizeof(int), "frozen");
   wait_queue_head_t wait_unfrozen ;
   struct lockdep_map lock_map[3U] ;
};
struct super_operations;
struct xattr_handler;
struct mtd_info;
struct super_block {
   struct list_head s_list ;
   dev_t s_dev ;
   unsigned char s_blocksize_bits ;
    klee_make_symbolic(&s_blocksize_bits, sizeof(char), "s_blocksize_bits");
   unsigned long s_blocksize ;
    klee_make_symbolic(&s_blocksize, sizeof(long), "s_blocksize");
   loff_t s_maxbytes ;
   struct file_system_type *s_type ;
   struct super_operations  const  *s_op ;
   struct dquot_operations  const  *dq_op ;
   struct quotactl_ops  const  *s_qcop ;
   struct export_operations  const  *s_export_op ;
   unsigned long s_flags ;
    klee_make_symbolic(&s_flags, sizeof(long), "s_flags");
   unsigned long s_iflags ;
    klee_make_symbolic(&s_iflags, sizeof(long), "s_iflags");
   unsigned long s_magic ;
    klee_make_symbolic(&s_magic, sizeof(long), "s_magic");
   struct dentry *s_root ;
   struct rw_semaphore s_umount ;
   int s_count ;
    klee_make_symbolic(&s_count, sizeof(int), "s_count");
   atomic_t s_active ;
   void *s_security ;
   struct xattr_handler  const  **s_xattr ;
   struct list_head s_inodes ;
   struct hlist_bl_head s_anon ;
   struct list_head s_mounts ;
   struct block_device *s_bdev ;
   struct backing_dev_info *s_bdi ;
   struct mtd_info *s_mtd ;
   struct hlist_node s_instances ;
   unsigned int s_quota_types ;
    klee_make_symbolic(&s_quota_types, sizeof(int), "s_quota_types");
   struct quota_info s_dquot ;
   struct sb_writers s_writers ;
   char s_id[32U] ;
   u8 s_uuid[16U] ;
   void *s_fs_info ;
   unsigned int s_max_links ;
    klee_make_symbolic(&s_max_links, sizeof(int), "s_max_links");
   fmode_t s_mode ;
   u32 s_time_gran ;
   struct mutex s_vfs_rename_mutex ;
   char *s_subtype ;
   char *s_options ;
   struct dentry_operations  const  *s_d_op ;
   int cleancache_poolid ;
    klee_make_symbolic(&cleancache_poolid, sizeof(int), "cleancache_poolid");
   struct shrinker s_shrink ;
   atomic_long_t s_remove_count ;
   int s_readonly_remount ;
    klee_make_symbolic(&s_readonly_remount, sizeof(int), "s_readonly_remount");
   struct workqueue_struct *s_dio_done_wq ;
   struct hlist_head s_pins ;
   struct list_lru s_dentry_lru ;
   struct list_lru s_inode_lru ;
   struct callback_head rcu ;
   int s_stack_depth ;
    klee_make_symbolic(&s_stack_depth, sizeof(int), "s_stack_depth");
};
struct fiemap_extent_info {
   unsigned int fi_flags ;
    klee_make_symbolic(&fi_flags, sizeof(int), "fi_flags");
   unsigned int fi_extents_mapped ;
    klee_make_symbolic(&fi_extents_mapped, sizeof(int), "fi_extents_mapped");
   unsigned int fi_extents_max ;
    klee_make_symbolic(&fi_extents_max, sizeof(int), "fi_extents_max");
   struct fiemap_extent *fi_extents_start ;
};
struct dir_context;
struct dir_context {
   int (*actor)(struct dir_context * , char const   * , int  , loff_t  , u64  , unsigned int  ) ;
   loff_t pos ;
};
struct file_operations {
   struct module *owner ;
   loff_t (*llseek)(struct file * , loff_t  , int  ) ;
   ssize_t (*read)(struct file * , char * , size_t  , loff_t * ) ;
   ssize_t (*write)(struct file * , char const   * , size_t  , loff_t * ) ;
   ssize_t (*read_iter)(struct kiocb * , struct iov_iter * ) ;
   ssize_t (*write_iter)(struct kiocb * , struct iov_iter * ) ;
   int (*iterate)(struct file * , struct dir_context * ) ;
   unsigned int (*poll)(struct file * , struct poll_table_struct * ) ;
   long (*unlocked_ioctl)(struct file * , unsigned int  , unsigned long  ) ;
   long (*compat_ioctl)(struct file * , unsigned int  , unsigned long  ) ;
   int (*mmap)(struct file * , struct vm_area_struct * ) ;
   int (*mremap)(struct file * , struct vm_area_struct * ) ;
   int (*open)(struct inode * , struct file * ) ;
   int (*flush)(struct file * , fl_owner_t  ) ;
   int (*release)(struct inode * , struct file * ) ;
   int (*fsync)(struct file * , loff_t  , loff_t  , int  ) ;
   int (*aio_fsync)(struct kiocb * , int  ) ;
   int (*fasync)(int  , struct file * , int  ) ;
   int (*lock)(struct file * , int  , struct file_lock * ) ;
   ssize_t (*sendpage)(struct file * , struct page * , int  , size_t  , loff_t * ,
                       int  ) ;
   unsigned long (*get_unmapped_area)(struct file * , unsigned long  , unsigned long  ,
                                      unsigned long  , unsigned long  ) ;
   int (*check_flags)(int  ) ;
   int (*flock)(struct file * , int  , struct file_lock * ) ;
   ssize_t (*splice_write)(struct pipe_inode_info * , struct file * , loff_t * , size_t  ,
                           unsigned int  ) ;
   ssize_t (*splice_read)(struct file * , loff_t * , struct pipe_inode_info * , size_t  ,
                          unsigned int  ) ;
   int (*setlease)(struct file * , long  , struct file_lock ** , void ** ) ;
   long (*fallocate)(struct file * , int  , loff_t  , loff_t  ) ;
   void (*show_fdinfo)(struct seq_file * , struct file * ) ;
};
struct inode_operations {
   struct dentry *(*lookup)(struct inode * , struct dentry * , unsigned int  ) ;
   char const   *(*follow_link)(struct dentry * , void ** ) ;
   int (*permission)(struct inode * , int  ) ;
   struct posix_acl *(*get_acl)(struct inode * , int  ) ;
   int (*readlink)(struct dentry * , char * , int  ) ;
   void (*put_link)(struct inode * , void * ) ;
   int (*create)(struct inode * , struct dentry * , umode_t  , bool  ) ;
   int (*link)(struct dentry * , struct inode * , struct dentry * ) ;
   int (*unlink)(struct inode * , struct dentry * ) ;
   int (*symlink)(struct inode * , struct dentry * , char const   * ) ;
   int (*mkdir)(struct inode * , struct dentry * , umode_t  ) ;
   int (*rmdir)(struct inode * , struct dentry * ) ;
   int (*mknod)(struct inode * , struct dentry * , umode_t  , dev_t  ) ;
   int (*rename)(struct inode * , struct dentry * , struct inode * , struct dentry * ) ;
   int (*rename2)(struct inode * , struct dentry * , struct inode * , struct dentry * ,
                  unsigned int  ) ;
   int (*setattr)(struct dentry * , struct iattr * ) ;
   int (*getattr)(struct vfsmount * , struct dentry * , struct kstat * ) ;
   int (*setxattr)(struct dentry * , char const   * , void const   * , size_t  , int  ) ;
   ssize_t (*getxattr)(struct dentry * , char const   * , void * , size_t  ) ;
   ssize_t (*listxattr)(struct dentry * , char * , size_t  ) ;
   int (*removexattr)(struct dentry * , char const   * ) ;
   int (*fiemap)(struct inode * , struct fiemap_extent_info * , u64  , u64  ) ;
   int (*update_time)(struct inode * , struct timespec * , int  ) ;
   int (*atomic_open)(struct inode * , struct dentry * , struct file * , unsigned int  ,
                      umode_t  , int * ) ;
   int (*tmpfile)(struct inode * , struct dentry * , umode_t  ) ;
   int (*set_acl)(struct inode * , struct posix_acl * , int  ) ;
};
struct super_operations {
   struct inode *(*alloc_inode)(struct super_block * ) ;
   void (*destroy_inode)(struct inode * ) ;
   void (*dirty_inode)(struct inode * , int  ) ;
   int (*write_inode)(struct inode * , struct writeback_control * ) ;
   int (*drop_inode)(struct inode * ) ;
   void (*evict_inode)(struct inode * ) ;
   void (*put_super)(struct super_block * ) ;
   int (*sync_fs)(struct super_block * , int  ) ;
   int (*freeze_super)(struct super_block * ) ;
   int (*freeze_fs)(struct super_block * ) ;
   int (*thaw_super)(struct super_block * ) ;
   int (*unfreeze_fs)(struct super_block * ) ;
   int (*statfs)(struct dentry * , struct kstatfs * ) ;
   int (*remount_fs)(struct super_block * , int * , char * ) ;
   void (*umount_begin)(struct super_block * ) ;
   int (*show_options)(struct seq_file * , struct dentry * ) ;
   int (*show_devname)(struct seq_file * , struct dentry * ) ;
   int (*show_path)(struct seq_file * , struct dentry * ) ;
   int (*show_stats)(struct seq_file * , struct dentry * ) ;
   ssize_t (*quota_read)(struct super_block * , int  , char * , size_t  , loff_t  ) ;
   ssize_t (*quota_write)(struct super_block * , int  , char const   * , size_t  ,
                          loff_t  ) ;
   struct dquot **(*get_dquots)(struct inode * ) ;
   int (*bdev_try_to_free_page)(struct super_block * , struct page * , gfp_t  ) ;
   long (*nr_cached_objects)(struct super_block * , struct shrink_control * ) ;
   long (*free_cached_objects)(struct super_block * , struct shrink_control * ) ;
};
struct file_system_type {
   char const   *name ;
   int fs_flags ;
    klee_make_symbolic(&fs_flags, sizeof(int), "fs_flags");
   struct dentry *(*mount)(struct file_system_type * , int  , char const   * , void * ) ;
   void (*kill_sb)(struct super_block * ) ;
   struct module *owner ;
   struct file_system_type *next ;
   struct hlist_head fs_supers ;
   struct lock_class_key s_lock_key ;
   struct lock_class_key s_umount_key ;
   struct lock_class_key s_vfs_rename_key ;
   struct lock_class_key s_writers_key[3U] ;
   struct lock_class_key i_lock_key ;
   struct lock_class_key i_mutex_key ;
   struct lock_class_key i_mutex_dir_key ;
};
typedef s32 compat_time_t;
typedef s32 compat_long_t;
typedef u32 compat_uptr_t;
struct compat_timespec {
   compat_time_t tv_sec ;
   s32 tv_nsec ;
};
struct compat_robust_list {
   compat_uptr_t next ;
};
struct compat_robust_list_head {
   struct compat_robust_list list ;
   compat_long_t futex_offset ;
   compat_uptr_t list_op_pending ;
};
struct ethtool_cmd {
   __u32 cmd ;
   __u32 supported ;
   __u32 advertising ;
   __u16 speed ;
   __u8 duplex ;
   __u8 port ;
   __u8 phy_address ;
   __u8 transceiver ;
   __u8 autoneg ;
   __u8 mdio_support ;
   __u32 maxtxpkt ;
   __u32 maxrxpkt ;
   __u16 speed_hi ;
   __u8 eth_tp_mdix ;
   __u8 eth_tp_mdix_ctrl ;
   __u32 lp_advertising ;
   __u32 reserved[2U] ;
};
struct ethtool_drvinfo {
   __u32 cmd ;
   char driver[32U] ;
   char version[32U] ;
   char fw_version[32U] ;
   char bus_info[32U] ;
   char erom_version[32U] ;
   char reserved2[12U] ;
   __u32 n_priv_flags ;
   __u32 n_stats ;
   __u32 testinfo_len ;
   __u32 eedump_len ;
   __u32 regdump_len ;
};
struct ethtool_wolinfo {
   __u32 cmd ;
   __u32 supported ;
   __u32 wolopts ;
   __u8 sopass[6U] ;
};
struct ethtool_tunable {
   __u32 cmd ;
   __u32 id ;
   __u32 type_id ;
   __u32 len ;
   void *data[0U] ;
};
struct ethtool_regs {
   __u32 cmd ;
   __u32 version ;
   __u32 len ;
   __u8 data[0U] ;
};
struct ethtool_eeprom {
   __u32 cmd ;
   __u32 magic ;
   __u32 offset ;
   __u32 len ;
   __u8 data[0U] ;
};
struct ethtool_eee {
   __u32 cmd ;
   __u32 supported ;
   __u32 advertised ;
   __u32 lp_advertised ;
   __u32 eee_active ;
   __u32 eee_enabled ;
   __u32 tx_lpi_enabled ;
   __u32 tx_lpi_timer ;
   __u32 reserved[2U] ;
};
struct ethtool_modinfo {
   __u32 cmd ;
   __u32 type ;
   __u32 eeprom_len ;
   __u32 reserved[8U] ;
};
struct ethtool_coalesce {
   __u32 cmd ;
   __u32 rx_coalesce_usecs ;
   __u32 rx_max_coalesced_frames ;
   __u32 rx_coalesce_usecs_irq ;
   __u32 rx_max_coalesced_frames_irq ;
   __u32 tx_coalesce_usecs ;
   __u32 tx_max_coalesced_frames ;
   __u32 tx_coalesce_usecs_irq ;
   __u32 tx_max_coalesced_frames_irq ;
   __u32 stats_block_coalesce_usecs ;
   __u32 use_adaptive_rx_coalesce ;
   __u32 use_adaptive_tx_coalesce ;
   __u32 pkt_rate_low ;
   __u32 rx_coalesce_usecs_low ;
   __u32 rx_max_coalesced_frames_low ;
   __u32 tx_coalesce_usecs_low ;
   __u32 tx_max_coalesced_frames_low ;
   __u32 pkt_rate_high ;
   __u32 rx_coalesce_usecs_high ;
   __u32 rx_max_coalesced_frames_high ;
   __u32 tx_coalesce_usecs_high ;
   __u32 tx_max_coalesced_frames_high ;
   __u32 rate_sample_interval ;
};
struct ethtool_ringparam {
   __u32 cmd ;
   __u32 rx_max_pending ;
   __u32 rx_mini_max_pending ;
   __u32 rx_jumbo_max_pending ;
   __u32 tx_max_pending ;
   __u32 rx_pending ;
   __u32 rx_mini_pending ;
   __u32 rx_jumbo_pending ;
   __u32 tx_pending ;
};
struct ethtool_channels {
   __u32 cmd ;
   __u32 max_rx ;
   __u32 max_tx ;
   __u32 max_other ;
   __u32 max_combined ;
   __u32 rx_count ;
   __u32 tx_count ;
   __u32 other_count ;
   __u32 combined_count ;
};
struct ethtool_pauseparam {
   __u32 cmd ;
   __u32 autoneg ;
   __u32 rx_pause ;
   __u32 tx_pause ;
};
struct ethtool_test {
   __u32 cmd ;
   __u32 flags ;
   __u32 reserved ;
   __u32 len ;
   __u64 data[0U] ;
};
struct ethtool_stats {
   __u32 cmd ;
   __u32 n_stats ;
   __u64 data[0U] ;
};
struct ethtool_tcpip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be16 psrc ;
   __be16 pdst ;
   __u8 tos ;
};
struct ethtool_ah_espip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be32 spi ;
   __u8 tos ;
};
struct ethtool_usrip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be32 l4_4_bytes ;
   __u8 tos ;
   __u8 ip_ver ;
   __u8 proto ;
};
union ethtool_flow_union {
   struct ethtool_tcpip4_spec tcp_ip4_spec ;
   struct ethtool_tcpip4_spec udp_ip4_spec ;
   struct ethtool_tcpip4_spec sctp_ip4_spec ;
   struct ethtool_ah_espip4_spec ah_ip4_spec ;
   struct ethtool_ah_espip4_spec esp_ip4_spec ;
   struct ethtool_usrip4_spec usr_ip4_spec ;
   struct ethhdr ether_spec ;
   __u8 hdata[52U] ;
};
struct ethtool_flow_ext {
   __u8 padding[2U] ;
   unsigned char h_dest[6U] ;
   __be16 vlan_etype ;
   __be16 vlan_tci ;
   __be32 data[2U] ;
};
struct ethtool_rx_flow_spec {
   __u32 flow_type ;
   union ethtool_flow_union h_u ;
   struct ethtool_flow_ext h_ext ;
   union ethtool_flow_union m_u ;
   struct ethtool_flow_ext m_ext ;
   __u64 ring_cookie ;
   __u32 location ;
};
struct ethtool_rxnfc {
   __u32 cmd ;
   __u32 flow_type ;
   __u64 data ;
   struct ethtool_rx_flow_spec fs ;
   __u32 rule_cnt ;
   __u32 rule_locs[0U] ;
};
struct ethtool_flash {
   __u32 cmd ;
   __u32 region ;
   char data[128U] ;
};
struct ethtool_dump {
   __u32 cmd ;
   __u32 version ;
   __u32 flag ;
   __u32 len ;
   __u8 data[0U] ;
};
struct ethtool_ts_info {
   __u32 cmd ;
   __u32 so_timestamping ;
   __s32 phc_index ;
   __u32 tx_types ;
   __u32 tx_reserved[3U] ;
   __u32 rx_filters ;
   __u32 rx_reserved[3U] ;
};
enum ethtool_phys_id_state {
    ETHTOOL_ID_INACTIVE = 0,
    ETHTOOL_ID_ACTIVE = 1,
    ETHTOOL_ID_ON = 2,
    ETHTOOL_ID_OFF = 3
} ;
struct ethtool_ops {
   int (*get_settings)(struct net_device * , struct ethtool_cmd * ) ;
   int (*set_settings)(struct net_device * , struct ethtool_cmd * ) ;
   void (*get_drvinfo)(struct net_device * , struct ethtool_drvinfo * ) ;
   int (*get_regs_len)(struct net_device * ) ;
   void (*get_regs)(struct net_device * , struct ethtool_regs * , void * ) ;
   void (*get_wol)(struct net_device * , struct ethtool_wolinfo * ) ;
   int (*set_wol)(struct net_device * , struct ethtool_wolinfo * ) ;
   u32 (*get_msglevel)(struct net_device * ) ;
   void (*set_msglevel)(struct net_device * , u32  ) ;
   int (*nway_reset)(struct net_device * ) ;
   u32 (*get_link)(struct net_device * ) ;
   int (*get_eeprom_len)(struct net_device * ) ;
   int (*get_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*set_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_coalesce)(struct net_device * , struct ethtool_coalesce * ) ;
   int (*set_coalesce)(struct net_device * , struct ethtool_coalesce * ) ;
   void (*get_ringparam)(struct net_device * , struct ethtool_ringparam * ) ;
   int (*set_ringparam)(struct net_device * , struct ethtool_ringparam * ) ;
   void (*get_pauseparam)(struct net_device * , struct ethtool_pauseparam * ) ;
   int (*set_pauseparam)(struct net_device * , struct ethtool_pauseparam * ) ;
   void (*self_test)(struct net_device * , struct ethtool_test * , u64 * ) ;
   void (*get_strings)(struct net_device * , u32  , u8 * ) ;
   int (*set_phys_id)(struct net_device * , enum ethtool_phys_id_state  ) ;
   void (*get_ethtool_stats)(struct net_device * , struct ethtool_stats * , u64 * ) ;
   int (*begin)(struct net_device * ) ;
   void (*complete)(struct net_device * ) ;
   u32 (*get_priv_flags)(struct net_device * ) ;
   int (*set_priv_flags)(struct net_device * , u32  ) ;
   int (*get_sset_count)(struct net_device * , int  ) ;
   int (*get_rxnfc)(struct net_device * , struct ethtool_rxnfc * , u32 * ) ;
   int (*set_rxnfc)(struct net_device * , struct ethtool_rxnfc * ) ;
   int (*flash_device)(struct net_device * , struct ethtool_flash * ) ;
   int (*reset)(struct net_device * , u32 * ) ;
   u32 (*get_rxfh_key_size)(struct net_device * ) ;
   u32 (*get_rxfh_indir_size)(struct net_device * ) ;
   int (*get_rxfh)(struct net_device * , u32 * , u8 * , u8 * ) ;
   int (*set_rxfh)(struct net_device * , u32 const   * , u8 const   * , u8 const    ) ;
   void (*get_channels)(struct net_device * , struct ethtool_channels * ) ;
   int (*set_channels)(struct net_device * , struct ethtool_channels * ) ;
   int (*get_dump_flag)(struct net_device * , struct ethtool_dump * ) ;
   int (*get_dump_data)(struct net_device * , struct ethtool_dump * , void * ) ;
   int (*set_dump)(struct net_device * , struct ethtool_dump * ) ;
   int (*get_ts_info)(struct net_device * , struct ethtool_ts_info * ) ;
   int (*get_module_info)(struct net_device * , struct ethtool_modinfo * ) ;
   int (*get_module_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_eee)(struct net_device * , struct ethtool_eee * ) ;
   int (*set_eee)(struct net_device * , struct ethtool_eee * ) ;
   int (*get_tunable)(struct net_device * , struct ethtool_tunable  const  * , void * ) ;
   int (*set_tunable)(struct net_device * , struct ethtool_tunable  const  * , void const   * ) ;
};
struct prot_inuse;
struct netns_core {
   struct ctl_table_header *sysctl_hdr ;
   int sysctl_somaxconn ;
    klee_make_symbolic(&sysctl_somaxconn, sizeof(int), "sysctl_somaxconn");
   struct prot_inuse *inuse ;
};
struct u64_stats_sync {

};
struct ipstats_mib {
   u64 mibs[36U] ;
   struct u64_stats_sync syncp ;
};
struct icmp_mib {
   unsigned long mibs[28U] ;
};
struct icmpmsg_mib {
   atomic_long_t mibs[512U] ;
};
struct icmpv6_mib {
   unsigned long mibs[6U] ;
};
struct icmpv6_mib_device {
   atomic_long_t mibs[6U] ;
};
struct icmpv6msg_mib {
   atomic_long_t mibs[512U] ;
};
struct icmpv6msg_mib_device {
   atomic_long_t mibs[512U] ;
};
struct tcp_mib {
   unsigned long mibs[16U] ;
};
struct udp_mib {
   unsigned long mibs[9U] ;
};
struct linux_mib {
   unsigned long mibs[115U] ;
};
struct linux_xfrm_mib {
   unsigned long mibs[29U] ;
};
struct netns_mib {
   struct tcp_mib *tcp_statistics ;
   struct ipstats_mib *ip_statistics ;
   struct linux_mib *net_statistics ;
   struct udp_mib *udp_statistics ;
   struct udp_mib *udplite_statistics ;
   struct icmp_mib *icmp_statistics ;
   struct icmpmsg_mib *icmpmsg_statistics ;
   struct proc_dir_entry *proc_net_devsnmp6 ;
   struct udp_mib *udp_stats_in6 ;
   struct udp_mib *udplite_stats_in6 ;
   struct ipstats_mib *ipv6_statistics ;
   struct icmpv6_mib *icmpv6_statistics ;
   struct icmpv6msg_mib *icmpv6msg_statistics ;
   struct linux_xfrm_mib *xfrm_statistics ;
};
struct netns_unix {
   int sysctl_max_dgram_qlen ;
    klee_make_symbolic(&sysctl_max_dgram_qlen, sizeof(int), "sysctl_max_dgram_qlen");
   struct ctl_table_header *ctl ;
};
struct netns_packet {
   struct mutex sklist_lock ;
   struct hlist_head sklist ;
};
struct netns_frags {
   struct percpu_counter mem ;
   int timeout ;
   int high_thresh ;
    klee_make_symbolic(&high_thresh, sizeof(int), "high_thresh");
   int low_thresh ;
    klee_make_symbolic(&low_thresh, sizeof(int), "low_thresh");
};
struct ipv4_devconf;
struct fib_rules_ops;
struct fib_table;
struct local_ports {
   seqlock_t lock ;
   int range[2U] ;
   bool warned ;
};
struct ping_group_range {
   seqlock_t lock ;
   kgid_t range[2U] ;
};
struct inet_peer_base;
struct xt_table;
struct netns_ipv4 {
   struct ctl_table_header *forw_hdr ;
   struct ctl_table_header *frags_hdr ;
   struct ctl_table_header *ipv4_hdr ;
   struct ctl_table_header *route_hdr ;
   struct ctl_table_header *xfrm4_hdr ;
   struct ipv4_devconf *devconf_all ;
   struct ipv4_devconf *devconf_dflt ;
   struct fib_rules_ops *rules_ops ;
   bool fib_has_custom_rules ;
   struct fib_table *fib_local ;
   struct fib_table *fib_main ;
   struct fib_table *fib_default ;
   int fib_num_tclassid_users ;
    klee_make_symbolic(&fib_num_tclassid_users, sizeof(int), "fib_num_tclassid_users");
   struct hlist_head *fib_table_hash ;
   bool fib_offload_disabled ;
   struct sock *fibnl ;
   struct sock **icmp_sk ;
   struct sock *mc_autojoin_sk ;
   struct inet_peer_base *peers ;
   struct sock **tcp_sk ;
   struct netns_frags frags ;
   struct xt_table *iptable_filter ;
   struct xt_table *iptable_mangle ;
   struct xt_table *iptable_raw ;
   struct xt_table *arptable_filter ;
   struct xt_table *iptable_security ;
   struct xt_table *nat_table ;
   int sysctl_icmp_echo_ignore_all ;
    klee_make_symbolic(&sysctl_icmp_echo_ignore_all, sizeof(int), "sysctl_icmp_echo_ignore_all");
   int sysctl_icmp_echo_ignore_broadcasts ;
    klee_make_symbolic(&sysctl_icmp_echo_ignore_broadcasts, sizeof(int), "sysctl_icmp_echo_ignore_broadcasts");
   int sysctl_icmp_ignore_bogus_error_responses ;
    klee_make_symbolic(&sysctl_icmp_ignore_bogus_error_responses, sizeof(int), "sysctl_icmp_ignore_bogus_error_responses");
   int sysctl_icmp_ratelimit ;
    klee_make_symbolic(&sysctl_icmp_ratelimit, sizeof(int), "sysctl_icmp_ratelimit");
   int sysctl_icmp_ratemask ;
    klee_make_symbolic(&sysctl_icmp_ratemask, sizeof(int), "sysctl_icmp_ratemask");
   int sysctl_icmp_errors_use_inbound_ifaddr ;
    klee_make_symbolic(&sysctl_icmp_errors_use_inbound_ifaddr, sizeof(int), "sysctl_icmp_errors_use_inbound_ifaddr");
   struct local_ports ip_local_ports ;
   int sysctl_tcp_ecn ;
    klee_make_symbolic(&sysctl_tcp_ecn, sizeof(int), "sysctl_tcp_ecn");
   int sysctl_tcp_ecn_fallback ;
    klee_make_symbolic(&sysctl_tcp_ecn_fallback, sizeof(int), "sysctl_tcp_ecn_fallback");
   int sysctl_ip_no_pmtu_disc ;
    klee_make_symbolic(&sysctl_ip_no_pmtu_disc, sizeof(int), "sysctl_ip_no_pmtu_disc");
   int sysctl_ip_fwd_use_pmtu ;
    klee_make_symbolic(&sysctl_ip_fwd_use_pmtu, sizeof(int), "sysctl_ip_fwd_use_pmtu");
   int sysctl_ip_nonlocal_bind ;
    klee_make_symbolic(&sysctl_ip_nonlocal_bind, sizeof(int), "sysctl_ip_nonlocal_bind");
   int sysctl_fwmark_reflect ;
    klee_make_symbolic(&sysctl_fwmark_reflect, sizeof(int), "sysctl_fwmark_reflect");
   int sysctl_tcp_fwmark_accept ;
    klee_make_symbolic(&sysctl_tcp_fwmark_accept, sizeof(int), "sysctl_tcp_fwmark_accept");
   int sysctl_tcp_mtu_probing ;
    klee_make_symbolic(&sysctl_tcp_mtu_probing, sizeof(int), "sysctl_tcp_mtu_probing");
   int sysctl_tcp_base_mss ;
    klee_make_symbolic(&sysctl_tcp_base_mss, sizeof(int), "sysctl_tcp_base_mss");
   int sysctl_tcp_probe_threshold ;
    klee_make_symbolic(&sysctl_tcp_probe_threshold, sizeof(int), "sysctl_tcp_probe_threshold");
   u32 sysctl_tcp_probe_interval ;
   struct ping_group_range ping_group_range ;
   atomic_t dev_addr_genid ;
   unsigned long *sysctl_local_reserved_ports ;
   struct list_head mr_tables ;
   struct fib_rules_ops *mr_rules_ops ;
   atomic_t rt_genid ;
};
struct neighbour;
struct dst_ops {
   unsigned short family ;
   unsigned int gc_thresh ;
    klee_make_symbolic(&gc_thresh, sizeof(int), "gc_thresh");
   int (*gc)(struct dst_ops * ) ;
   struct dst_entry *(*check)(struct dst_entry * , __u32  ) ;
   unsigned int (*default_advmss)(struct dst_entry  const  * ) ;
   unsigned int (*mtu)(struct dst_entry  const  * ) ;
   u32 *(*cow_metrics)(struct dst_entry * , unsigned long  ) ;
   void (*destroy)(struct dst_entry * ) ;
   void (*ifdown)(struct dst_entry * , struct net_device * , int  ) ;
   struct dst_entry *(*negative_advice)(struct dst_entry * ) ;
   void (*link_failure)(struct sk_buff * ) ;
   void (*update_pmtu)(struct dst_entry * , struct sock * , struct sk_buff * , u32  ) ;
   void (*redirect)(struct dst_entry * , struct sock * , struct sk_buff * ) ;
   int (*local_out)(struct sk_buff * ) ;
   struct neighbour *(*neigh_lookup)(struct dst_entry  const  * , struct sk_buff * ,
                                     void const   * ) ;
   struct kmem_cache *kmem_cachep ;
   struct percpu_counter pcpuc_entries ;
};
struct netns_sysctl_ipv6 {
   struct ctl_table_header *hdr ;
   struct ctl_table_header *route_hdr ;
   struct ctl_table_header *icmp_hdr ;
   struct ctl_table_header *frags_hdr ;
   struct ctl_table_header *xfrm6_hdr ;
   int bindv6only ;
    klee_make_symbolic(&bindv6only, sizeof(int), "bindv6only");
   int flush_delay ;
    klee_make_symbolic(&flush_delay, sizeof(int), "flush_delay");
   int ip6_rt_max_size ;
    klee_make_symbolic(&ip6_rt_max_size, sizeof(int), "ip6_rt_max_size");
   int ip6_rt_gc_min_interval ;
    klee_make_symbolic(&ip6_rt_gc_min_interval, sizeof(int), "ip6_rt_gc_min_interval");
   int ip6_rt_gc_timeout ;
    klee_make_symbolic(&ip6_rt_gc_timeout, sizeof(int), "ip6_rt_gc_timeout");
   int ip6_rt_gc_interval ;
    klee_make_symbolic(&ip6_rt_gc_interval, sizeof(int), "ip6_rt_gc_interval");
   int ip6_rt_gc_elasticity ;
    klee_make_symbolic(&ip6_rt_gc_elasticity, sizeof(int), "ip6_rt_gc_elasticity");
   int ip6_rt_mtu_expires ;
    klee_make_symbolic(&ip6_rt_mtu_expires, sizeof(int), "ip6_rt_mtu_expires");
   int ip6_rt_min_advmss ;
    klee_make_symbolic(&ip6_rt_min_advmss, sizeof(int), "ip6_rt_min_advmss");
   int flowlabel_consistency ;
    klee_make_symbolic(&flowlabel_consistency, sizeof(int), "flowlabel_consistency");
   int auto_flowlabels ;
    klee_make_symbolic(&auto_flowlabels, sizeof(int), "auto_flowlabels");
   int icmpv6_time ;
    klee_make_symbolic(&icmpv6_time, sizeof(int), "icmpv6_time");
   int anycast_src_echo_reply ;
    klee_make_symbolic(&anycast_src_echo_reply, sizeof(int), "anycast_src_echo_reply");
   int fwmark_reflect ;
    klee_make_symbolic(&fwmark_reflect, sizeof(int), "fwmark_reflect");
   int idgen_retries ;
    klee_make_symbolic(&idgen_retries, sizeof(int), "idgen_retries");
   int idgen_delay ;
    klee_make_symbolic(&idgen_delay, sizeof(int), "idgen_delay");
   int flowlabel_state_ranges ;
    klee_make_symbolic(&flowlabel_state_ranges, sizeof(int), "flowlabel_state_ranges");
};
struct ipv6_devconf;
struct rt6_info;
struct rt6_statistics;
struct fib6_table;
struct netns_ipv6 {
   struct netns_sysctl_ipv6 sysctl ;
   struct ipv6_devconf *devconf_all ;
   struct ipv6_devconf *devconf_dflt ;
   struct inet_peer_base *peers ;
   struct netns_frags frags ;
   struct xt_table *ip6table_filter ;
   struct xt_table *ip6table_mangle ;
   struct xt_table *ip6table_raw ;
   struct xt_table *ip6table_security ;
   struct xt_table *ip6table_nat ;
   struct rt6_info *ip6_null_entry ;
   struct rt6_statistics *rt6_stats ;
   struct timer_list ip6_fib_timer ;
   struct hlist_head *fib_table_hash ;
   struct fib6_table *fib6_main_tbl ;
   struct dst_ops ip6_dst_ops ;
   unsigned int ip6_rt_gc_expire ;
    klee_make_symbolic(&ip6_rt_gc_expire, sizeof(int), "ip6_rt_gc_expire");
   unsigned long ip6_rt_last_gc ;
    klee_make_symbolic(&ip6_rt_last_gc, sizeof(long), "ip6_rt_last_gc");
   struct rt6_info *ip6_prohibit_entry ;
   struct rt6_info *ip6_blk_hole_entry ;
   struct fib6_table *fib6_local_tbl ;
   struct fib_rules_ops *fib6_rules_ops ;
   struct sock **icmp_sk ;
   struct sock *ndisc_sk ;
   struct sock *tcp_sk ;
   struct sock *igmp_sk ;
   struct sock *mc_autojoin_sk ;
   struct list_head mr6_tables ;
   struct fib_rules_ops *mr6_rules_ops ;
   atomic_t dev_addr_genid ;
   atomic_t fib6_sernum ;
};
struct netns_nf_frag {
   struct netns_sysctl_ipv6 sysctl ;
   struct netns_frags frags ;
};
struct netns_sysctl_lowpan {
   struct ctl_table_header *frags_hdr ;
};
struct netns_ieee802154_lowpan {
   struct netns_sysctl_lowpan sysctl ;
   struct netns_frags frags ;
};
struct sctp_mib;
struct netns_sctp {
   struct sctp_mib *sctp_statistics ;
   struct proc_dir_entry *proc_net_sctp ;
   struct ctl_table_header *sysctl_header ;
   struct sock *ctl_sock ;
   struct list_head local_addr_list ;
   struct list_head addr_waitq ;
   struct timer_list addr_wq_timer ;
   struct list_head auto_asconf_splist ;
   spinlock_t addr_wq_lock ;
   spinlock_t local_addr_lock ;
   unsigned int rto_initial ;
    klee_make_symbolic(&rto_initial, sizeof(int), "rto_initial");
   unsigned int rto_min ;
    klee_make_symbolic(&rto_min, sizeof(int), "rto_min");
   unsigned int rto_max ;
    klee_make_symbolic(&rto_max, sizeof(int), "rto_max");
   int rto_alpha ;
    klee_make_symbolic(&rto_alpha, sizeof(int), "rto_alpha");
   int rto_beta ;
    klee_make_symbolic(&rto_beta, sizeof(int), "rto_beta");
   int max_burst ;
    klee_make_symbolic(&max_burst, sizeof(int), "max_burst");
   int cookie_preserve_enable ;
    klee_make_symbolic(&cookie_preserve_enable, sizeof(int), "cookie_preserve_enable");
   char *sctp_hmac_alg ;
   unsigned int valid_cookie_life ;
    klee_make_symbolic(&valid_cookie_life, sizeof(int), "valid_cookie_life");
   unsigned int sack_timeout ;
    klee_make_symbolic(&sack_timeout, sizeof(int), "sack_timeout");
   unsigned int hb_interval ;
    klee_make_symbolic(&hb_interval, sizeof(int), "hb_interval");
   int max_retrans_association ;
    klee_make_symbolic(&max_retrans_association, sizeof(int), "max_retrans_association");
   int max_retrans_path ;
    klee_make_symbolic(&max_retrans_path, sizeof(int), "max_retrans_path");
   int max_retrans_init ;
    klee_make_symbolic(&max_retrans_init, sizeof(int), "max_retrans_init");
   int pf_retrans ;
    klee_make_symbolic(&pf_retrans, sizeof(int), "pf_retrans");
   int sndbuf_policy ;
    klee_make_symbolic(&sndbuf_policy, sizeof(int), "sndbuf_policy");
   int rcvbuf_policy ;
    klee_make_symbolic(&rcvbuf_policy, sizeof(int), "rcvbuf_policy");
   int default_auto_asconf ;
    klee_make_symbolic(&default_auto_asconf, sizeof(int), "default_auto_asconf");
   int addip_enable ;
    klee_make_symbolic(&addip_enable, sizeof(int), "addip_enable");
   int addip_noauth ;
    klee_make_symbolic(&addip_noauth, sizeof(int), "addip_noauth");
   int prsctp_enable ;
    klee_make_symbolic(&prsctp_enable, sizeof(int), "prsctp_enable");
   int auth_enable ;
    klee_make_symbolic(&auth_enable, sizeof(int), "auth_enable");
   int scope_policy ;
    klee_make_symbolic(&scope_policy, sizeof(int), "scope_policy");
   int rwnd_upd_shift ;
    klee_make_symbolic(&rwnd_upd_shift, sizeof(int), "rwnd_upd_shift");
   unsigned long max_autoclose ;
    klee_make_symbolic(&max_autoclose, sizeof(long), "max_autoclose");
};
struct netns_dccp {
   struct sock *v4_ctl_sk ;
   struct sock *v6_ctl_sk ;
};
struct nf_logger;
struct netns_nf {
   struct proc_dir_entry *proc_netfilter ;
   struct nf_logger  const  *nf_loggers[13U] ;
   struct ctl_table_header *nf_log_dir_header ;
};
struct ebt_table;
struct netns_xt {
   struct list_head tables[13U] ;
   bool notrack_deprecated_warning ;
   bool clusterip_deprecated_warning ;
   struct ebt_table *broute_table ;
   struct ebt_table *frame_filter ;
   struct ebt_table *frame_nat ;
};
struct nf_proto_net {
   struct ctl_table_header *ctl_table_header ;
   struct ctl_table *ctl_table ;
   struct ctl_table_header *ctl_compat_header ;
   struct ctl_table *ctl_compat_table ;
   unsigned int users ;
    klee_make_symbolic(&users, sizeof(int), "users");
};
struct nf_generic_net {
   struct nf_proto_net pn ;
   unsigned int timeout ;
};
struct nf_tcp_net {
   struct nf_proto_net pn ;
   unsigned int timeouts[14U] ;
   unsigned int tcp_loose ;
    klee_make_symbolic(&tcp_loose, sizeof(int), "tcp_loose");
   unsigned int tcp_be_liberal ;
    klee_make_symbolic(&tcp_be_liberal, sizeof(int), "tcp_be_liberal");
   unsigned int tcp_max_retrans ;
    klee_make_symbolic(&tcp_max_retrans, sizeof(int), "tcp_max_retrans");
};
struct nf_udp_net {
   struct nf_proto_net pn ;
   unsigned int timeouts[2U] ;
};
struct nf_icmp_net {
   struct nf_proto_net pn ;
   unsigned int timeout ;
};
struct nf_ip_net {
   struct nf_generic_net generic ;
   struct nf_tcp_net tcp ;
   struct nf_udp_net udp ;
   struct nf_icmp_net icmp ;
   struct nf_icmp_net icmpv6 ;
   struct ctl_table_header *ctl_table_header ;
   struct ctl_table *ctl_table ;
};
struct ct_pcpu {
   spinlock_t lock ;
   struct hlist_nulls_head unconfirmed ;
   struct hlist_nulls_head dying ;
   struct hlist_nulls_head tmpl ;
};
struct ip_conntrack_stat;
struct nf_ct_event_notifier;
struct nf_exp_event_notifier;
struct netns_ct {
   atomic_t count ;
   unsigned int expect_count ;
    klee_make_symbolic(&expect_count, sizeof(int), "expect_count");
   struct delayed_work ecache_dwork ;
   bool ecache_dwork_pending ;
   struct ctl_table_header *sysctl_header ;
   struct ctl_table_header *acct_sysctl_header ;
   struct ctl_table_header *tstamp_sysctl_header ;
   struct ctl_table_header *event_sysctl_header ;
   struct ctl_table_header *helper_sysctl_header ;
   char *slabname ;
   unsigned int sysctl_log_invalid ;
    klee_make_symbolic(&sysctl_log_invalid, sizeof(int), "sysctl_log_invalid");
   int sysctl_events ;
    klee_make_symbolic(&sysctl_events, sizeof(int), "sysctl_events");
   int sysctl_acct ;
    klee_make_symbolic(&sysctl_acct, sizeof(int), "sysctl_acct");
   int sysctl_auto_assign_helper ;
    klee_make_symbolic(&sysctl_auto_assign_helper, sizeof(int), "sysctl_auto_assign_helper");
   bool auto_assign_helper_warned ;
   int sysctl_tstamp ;
    klee_make_symbolic(&sysctl_tstamp, sizeof(int), "sysctl_tstamp");
   int sysctl_checksum ;
    klee_make_symbolic(&sysctl_checksum, sizeof(int), "sysctl_checksum");
   unsigned int htable_size ;
    klee_make_symbolic(&htable_size, sizeof(int), "htable_size");
   seqcount_t generation ;
   struct kmem_cache *nf_conntrack_cachep ;
   struct hlist_nulls_head *hash ;
   struct hlist_head *expect_hash ;
   struct ct_pcpu *pcpu_lists ;
   struct ip_conntrack_stat *stat ;
   struct nf_ct_event_notifier *nf_conntrack_event_cb ;
   struct nf_exp_event_notifier *nf_expect_event_cb ;
   struct nf_ip_net nf_ct_proto ;
   unsigned int labels_used ;
    klee_make_symbolic(&labels_used, sizeof(int), "labels_used");
   u8 label_words ;
   struct hlist_head *nat_bysource ;
   unsigned int nat_htable_size ;
    klee_make_symbolic(&nat_htable_size, sizeof(int), "nat_htable_size");
};
struct nft_af_info;
struct netns_nftables {
   struct list_head af_info ;
   struct list_head commit_list ;
   struct nft_af_info *ipv4 ;
   struct nft_af_info *ipv6 ;
   struct nft_af_info *inet ;
   struct nft_af_info *arp ;
   struct nft_af_info *bridge ;
   struct nft_af_info *netdev ;
   unsigned int base_seq ;
    klee_make_symbolic(&base_seq, sizeof(int), "base_seq");
   u8 gencursor ;
};
struct tasklet_struct {
   struct tasklet_struct *next ;
   unsigned long state ;
   atomic_t count ;
   void (*func)(unsigned long  ) ;
   unsigned long data ;
};
struct flow_cache_percpu {
   struct hlist_head *hash_table ;
   int hash_count ;
    klee_make_symbolic(&hash_count, sizeof(int), "hash_count");
   u32 hash_rnd ;
   int hash_rnd_recalc ;
    klee_make_symbolic(&hash_rnd_recalc, sizeof(int), "hash_rnd_recalc");
   struct tasklet_struct flush_tasklet ;
};
struct flow_cache {
   u32 hash_shift ;
   struct flow_cache_percpu *percpu ;
   struct notifier_block hotcpu_notifier ;
   int low_watermark ;
    klee_make_symbolic(&low_watermark, sizeof(int), "low_watermark");
   int high_watermark ;
    klee_make_symbolic(&high_watermark, sizeof(int), "high_watermark");
   struct timer_list rnd_timer ;
};
struct xfrm_policy_hash {
   struct hlist_head *table ;
   unsigned int hmask ;
    klee_make_symbolic(&hmask, sizeof(int), "hmask");
   u8 dbits4 ;
   u8 sbits4 ;
   u8 dbits6 ;
   u8 sbits6 ;
};
struct xfrm_policy_hthresh {
   struct work_struct work ;
   seqlock_t lock ;
   u8 lbits4 ;
   u8 rbits4 ;
   u8 lbits6 ;
   u8 rbits6 ;
};
struct netns_xfrm {
   struct list_head state_all ;
   struct hlist_head *state_bydst ;
   struct hlist_head *state_bysrc ;
   struct hlist_head *state_byspi ;
   unsigned int state_hmask ;
    klee_make_symbolic(&state_hmask, sizeof(int), "state_hmask");
   unsigned int state_num ;
    klee_make_symbolic(&state_num, sizeof(int), "state_num");
   struct work_struct state_hash_work ;
   struct hlist_head state_gc_list ;
   struct work_struct state_gc_work ;
   struct list_head policy_all ;
   struct hlist_head *policy_byidx ;
   unsigned int policy_idx_hmask ;
    klee_make_symbolic(&policy_idx_hmask, sizeof(int), "policy_idx_hmask");
   struct hlist_head policy_inexact[3U] ;
   struct xfrm_policy_hash policy_bydst[3U] ;
   unsigned int policy_count[6U] ;
   struct work_struct policy_hash_work ;
   struct xfrm_policy_hthresh policy_hthresh ;
   struct sock *nlsk ;
   struct sock *nlsk_stash ;
   u32 sysctl_aevent_etime ;
   u32 sysctl_aevent_rseqth ;
   int sysctl_larval_drop ;
    klee_make_symbolic(&sysctl_larval_drop, sizeof(int), "sysctl_larval_drop");
   u32 sysctl_acq_expires ;
   struct ctl_table_header *sysctl_hdr ;
   struct dst_ops xfrm4_dst_ops ;
   struct dst_ops xfrm6_dst_ops ;
   spinlock_t xfrm_state_lock ;
   rwlock_t xfrm_policy_lock ;
   struct mutex xfrm_cfg_mutex ;
   struct flow_cache flow_cache_global ;
   atomic_t flow_cache_genid ;
   struct list_head flow_cache_gc_list ;
   spinlock_t flow_cache_gc_lock ;
   struct work_struct flow_cache_gc_work ;
   struct work_struct flow_cache_flush_work ;
   struct mutex flow_flush_sem ;
};
struct mpls_route;
struct netns_mpls {
   size_t platform_labels ;
   struct mpls_route **platform_label ;
   struct ctl_table_header *ctl ;
};
struct proc_ns_operations;
struct ns_common {
   atomic_long_t stashed ;
   struct proc_ns_operations  const  *ops ;
   unsigned int inum ;
    klee_make_symbolic(&inum, sizeof(int), "inum");
};
struct net_generic;
struct netns_ipvs;
struct net {
   atomic_t passive ;
   atomic_t count ;
   spinlock_t rules_mod_lock ;
   atomic64_t cookie_gen ;
   struct list_head list ;
   struct list_head cleanup_list ;
   struct list_head exit_list ;
   struct user_namespace *user_ns ;
   spinlock_t nsid_lock ;
   struct idr netns_ids ;
   struct ns_common ns ;
   struct proc_dir_entry *proc_net ;
   struct proc_dir_entry *proc_net_stat ;
   struct ctl_table_set sysctls ;
   struct sock *rtnl ;
   struct sock *genl_sock ;
   struct list_head dev_base_head ;
   struct hlist_head *dev_name_head ;
   struct hlist_head *dev_index_head ;
   unsigned int dev_base_seq ;
    klee_make_symbolic(&dev_base_seq, sizeof(int), "dev_base_seq");
   int ifindex ;
    klee_make_symbolic(&ifindex, sizeof(int), "ifindex");
   unsigned int dev_unreg_count ;
    klee_make_symbolic(&dev_unreg_count, sizeof(int), "dev_unreg_count");
   struct list_head rules_ops ;
   struct net_device *loopback_dev ;
   struct netns_core core ;
   struct netns_mib mib ;
   struct netns_packet packet ;
   struct netns_unix unx ;
   struct netns_ipv4 ipv4 ;
   struct netns_ipv6 ipv6 ;
   struct netns_ieee802154_lowpan ieee802154_lowpan ;
   struct netns_sctp sctp ;
   struct netns_dccp dccp ;
   struct netns_nf nf ;
   struct netns_xt xt ;
   struct netns_ct ct ;
   struct netns_nftables nft ;
   struct netns_nf_frag nf_frag ;
   struct sock *nfnl ;
   struct sock *nfnl_stash ;
   struct sk_buff_head wext_nlevents ;
   struct net_generic *gen ;
   struct netns_xfrm xfrm ;
   struct netns_ipvs *ipvs ;
   struct netns_mpls mpls ;
   struct sock *diag_nlsk ;
   atomic_t fnhe_genid ;
};
struct __anonstruct_possible_net_t_291 {
   struct net *net ;
};
typedef struct __anonstruct_possible_net_t_291 possible_net_t;
typedef unsigned long kernel_ulong_t;
    klee_make_symbolic(&kernel_ulong_t, sizeof(long), "kernel_ulong_t");
struct pci_device_id {
   __u32 vendor ;
   __u32 device ;
   __u32 subvendor ;
   __u32 subdevice ;
   __u32 class ;
   __u32 class_mask ;
   kernel_ulong_t driver_data ;
};
struct acpi_device_id {
   __u8 id[9U] ;
   kernel_ulong_t driver_data ;
};
struct of_device_id {
   char name[32U] ;
   char type[32U] ;
   char compatible[128U] ;
   void const   *data ;
};
enum fwnode_type {
    FWNODE_INVALID = 0,
    FWNODE_OF = 1,
    FWNODE_ACPI = 2,
    FWNODE_PDATA = 3
} ;
struct fwnode_handle {
   enum fwnode_type type ;
   struct fwnode_handle *secondary ;
};
typedef u32 phandle;
struct property {
   char *name ;
   int length ;
   void *value ;
   struct property *next ;
   unsigned long _flags ;
    klee_make_symbolic(&_flags, sizeof(long), "_flags");
   unsigned int unique_id ;
    klee_make_symbolic(&unique_id, sizeof(int), "unique_id");
   struct bin_attribute attr ;
};
struct device_node {
   char const   *name ;
   char const   *type ;
   phandle phandle ;
   char const   *full_name ;
   struct fwnode_handle fwnode ;
   struct property *properties ;
   struct property *deadprops ;
   struct device_node *parent ;
   struct device_node *child ;
   struct device_node *sibling ;
   struct kobject kobj ;
   unsigned long _flags ;
   void *data ;
};
struct of_phandle_args {
   struct device_node *np ;
   int args_count ;
    klee_make_symbolic(&args_count, sizeof(int), "args_count");
   uint32_t args[16U] ;
};
enum ldv_27513 {
    PHY_INTERFACE_MODE_NA = 0,
    PHY_INTERFACE_MODE_MII = 1,
    PHY_INTERFACE_MODE_GMII = 2,
    PHY_INTERFACE_MODE_SGMII = 3,
    PHY_INTERFACE_MODE_TBI = 4,
    PHY_INTERFACE_MODE_REVMII = 5,
    PHY_INTERFACE_MODE_RMII = 6,
    PHY_INTERFACE_MODE_RGMII = 7,
    PHY_INTERFACE_MODE_RGMII_ID = 8,
    PHY_INTERFACE_MODE_RGMII_RXID = 9,
    PHY_INTERFACE_MODE_RGMII_TXID = 10,
    PHY_INTERFACE_MODE_RTBI = 11,
    PHY_INTERFACE_MODE_SMII = 12,
    PHY_INTERFACE_MODE_XGMII = 13,
    PHY_INTERFACE_MODE_MOCA = 14,
    PHY_INTERFACE_MODE_QSGMII = 15,
    PHY_INTERFACE_MODE_MAX = 16
} ;
typedef enum ldv_27513 phy_interface_t;
enum ldv_27567 {
    MDIOBUS_ALLOCATED = 1,
    MDIOBUS_REGISTERED = 2,
    MDIOBUS_UNREGISTERED = 3,
    MDIOBUS_RELEASED = 4
} ;
struct phy_device;
struct mii_bus {
   char const   *name ;
   char id[17U] ;
   void *priv ;
   int (*read)(struct mii_bus * , int  , int  ) ;
   int (*write)(struct mii_bus * , int  , int  , u16  ) ;
   int (*reset)(struct mii_bus * ) ;
   struct mutex mdio_lock ;
   struct device *parent ;
   enum ldv_27567 state ;
   struct device dev ;
   struct phy_device *phy_map[32U] ;
   u32 phy_mask ;
   u32 phy_ignore_ta_mask ;
   int *irq ;
};
enum phy_state {
    PHY_DOWN = 0,
    PHY_STARTING = 1,
    PHY_READY = 2,
    PHY_PENDING = 3,
    PHY_UP = 4,
    PHY_AN = 5,
    PHY_RUNNING = 6,
    PHY_NOLINK = 7,
    PHY_FORCING = 8,
    PHY_CHANGELINK = 9,
    PHY_HALTED = 10,
    PHY_RESUMING = 11
} ;
struct phy_c45_device_ids {
   u32 devices_in_package ;
   u32 device_ids[8U] ;
};
struct phy_driver;
struct phy_device {
   struct phy_driver *drv ;
   struct mii_bus *bus ;
   struct device dev ;
   u32 phy_id ;
   struct phy_c45_device_ids c45_ids ;
   bool is_c45 ;
   bool is_internal ;
   bool has_fixups ;
   bool suspended ;
   enum phy_state state ;
   u32 dev_flags ;
   phy_interface_t interface ;
   int addr ;
    klee_make_symbolic(&addr, sizeof(int), "addr");
   int speed ;
    klee_make_symbolic(&speed, sizeof(int), "speed");
   int duplex ;
    klee_make_symbolic(&duplex, sizeof(int), "duplex");
   int pause ;
    klee_make_symbolic(&pause, sizeof(int), "pause");
   int asym_pause ;
    klee_make_symbolic(&asym_pause, sizeof(int), "asym_pause");
   int link ;
    klee_make_symbolic(&link, sizeof(int), "link");
   u32 interrupts ;
   u32 supported ;
   u32 advertising ;
   u32 lp_advertising ;
   int autoneg ;
    klee_make_symbolic(&autoneg, sizeof(int), "autoneg");
   int link_timeout ;
    klee_make_symbolic(&link_timeout, sizeof(int), "link_timeout");
   int irq ;
   void *priv ;
   struct work_struct phy_queue ;
   struct delayed_work state_queue ;
   atomic_t irq_disable ;
   struct mutex lock ;
   struct net_device *attached_dev ;
   void (*adjust_link)(struct net_device * ) ;
};
struct phy_driver {
   u32 phy_id ;
   char *name ;
   unsigned int phy_id_mask ;
    klee_make_symbolic(&phy_id_mask, sizeof(int), "phy_id_mask");
   u32 features ;
   u32 flags ;
   void const   *driver_data ;
   int (*soft_reset)(struct phy_device * ) ;
   int (*config_init)(struct phy_device * ) ;
   int (*probe)(struct phy_device * ) ;
   int (*suspend)(struct phy_device * ) ;
   int (*resume)(struct phy_device * ) ;
   int (*config_aneg)(struct phy_device * ) ;
   int (*aneg_done)(struct phy_device * ) ;
   int (*read_status)(struct phy_device * ) ;
   int (*ack_interrupt)(struct phy_device * ) ;
   int (*config_intr)(struct phy_device * ) ;
   int (*did_interrupt)(struct phy_device * ) ;
   void (*remove)(struct phy_device * ) ;
   int (*match_phy_device)(struct phy_device * ) ;
   int (*ts_info)(struct phy_device * , struct ethtool_ts_info * ) ;
   int (*hwtstamp)(struct phy_device * , struct ifreq * ) ;
   bool (*rxtstamp)(struct phy_device * , struct sk_buff * , int  ) ;
   void (*txtstamp)(struct phy_device * , struct sk_buff * , int  ) ;
   int (*set_wol)(struct phy_device * , struct ethtool_wolinfo * ) ;
   void (*get_wol)(struct phy_device * , struct ethtool_wolinfo * ) ;
   void (*link_change_notify)(struct phy_device * ) ;
   int (*read_mmd_indirect)(struct phy_device * , int  , int  , int  ) ;
   void (*write_mmd_indirect)(struct phy_device * , int  , int  , int  , u32  ) ;
   int (*module_info)(struct phy_device * , struct ethtool_modinfo * ) ;
   int (*module_eeprom)(struct phy_device * , struct ethtool_eeprom * , u8 * ) ;
   struct device_driver driver ;
};
struct fixed_phy_status {
   int link ;
   int speed ;
   int duplex ;
   int pause ;
   int asym_pause ;
};
enum dsa_tag_protocol {
    DSA_TAG_PROTO_NONE = 0,
    DSA_TAG_PROTO_DSA = 1,
    DSA_TAG_PROTO_TRAILER = 2,
    DSA_TAG_PROTO_EDSA = 3,
    DSA_TAG_PROTO_BRCM = 4
} ;
struct dsa_chip_data {
   struct device *host_dev ;
   int sw_addr ;
    klee_make_symbolic(&sw_addr, sizeof(int), "sw_addr");
   int eeprom_len ;
    klee_make_symbolic(&eeprom_len, sizeof(int), "eeprom_len");
   struct device_node *of_node ;
   char *port_names[12U] ;
   struct device_node *port_dn[12U] ;
   s8 *rtable ;
};
struct dsa_platform_data {
   struct device *netdev ;
   struct net_device *of_netdev ;
   int nr_chips ;
    klee_make_symbolic(&nr_chips, sizeof(int), "nr_chips");
   struct dsa_chip_data *chip ;
};
struct packet_type;
struct dsa_switch;
struct dsa_switch_tree {
   struct dsa_platform_data *pd ;
   struct net_device *master_netdev ;
   int (*rcv)(struct sk_buff * , struct net_device * , struct packet_type * , struct net_device * ) ;
   enum dsa_tag_protocol tag_protocol ;
   s8 cpu_switch ;
   s8 cpu_port ;
   int link_poll_needed ;
    klee_make_symbolic(&link_poll_needed, sizeof(int), "link_poll_needed");
   struct work_struct link_poll_work ;
   struct timer_list link_poll_timer ;
   struct dsa_switch *ds[4U] ;
};
struct dsa_switch_driver;
struct dsa_switch {
   struct dsa_switch_tree *dst ;
   int index ;
   enum dsa_tag_protocol tag_protocol ;
   struct dsa_chip_data *pd ;
   struct dsa_switch_driver *drv ;
   struct device *master_dev ;
   char hwmon_name[24U] ;
   struct device *hwmon_dev ;
   u32 dsa_port_mask ;
   u32 phys_port_mask ;
   u32 phys_mii_mask ;
   struct mii_bus *slave_mii_bus ;
   struct net_device *ports[12U] ;
};
struct dsa_switch_driver {
   struct list_head list ;
   enum dsa_tag_protocol tag_protocol ;
   int priv_size ;
    klee_make_symbolic(&priv_size, sizeof(int), "priv_size");
   char *(*probe)(struct device * , int  ) ;
   int (*setup)(struct dsa_switch * ) ;
   int (*set_addr)(struct dsa_switch * , u8 * ) ;
   u32 (*get_phy_flags)(struct dsa_switch * , int  ) ;
   int (*phy_read)(struct dsa_switch * , int  , int  ) ;
   int (*phy_write)(struct dsa_switch * , int  , int  , u16  ) ;
   void (*poll_link)(struct dsa_switch * ) ;
   void (*adjust_link)(struct dsa_switch * , int  , struct phy_device * ) ;
   void (*fixed_link_update)(struct dsa_switch * , int  , struct fixed_phy_status * ) ;
   void (*get_strings)(struct dsa_switch * , int  , uint8_t * ) ;
   void (*get_ethtool_stats)(struct dsa_switch * , int  , uint64_t * ) ;
   int (*get_sset_count)(struct dsa_switch * ) ;
   void (*get_wol)(struct dsa_switch * , int  , struct ethtool_wolinfo * ) ;
   int (*set_wol)(struct dsa_switch * , int  , struct ethtool_wolinfo * ) ;
   int (*suspend)(struct dsa_switch * ) ;
   int (*resume)(struct dsa_switch * ) ;
   int (*port_enable)(struct dsa_switch * , int  , struct phy_device * ) ;
   void (*port_disable)(struct dsa_switch * , int  , struct phy_device * ) ;
   int (*set_eee)(struct dsa_switch * , int  , struct phy_device * , struct ethtool_eee * ) ;
   int (*get_eee)(struct dsa_switch * , int  , struct ethtool_eee * ) ;
   int (*get_temp)(struct dsa_switch * , int * ) ;
   int (*get_temp_limit)(struct dsa_switch * , int * ) ;
   int (*set_temp_limit)(struct dsa_switch * , int  ) ;
   int (*get_temp_alarm)(struct dsa_switch * , bool * ) ;
   int (*get_eeprom_len)(struct dsa_switch * ) ;
   int (*get_eeprom)(struct dsa_switch * , struct ethtool_eeprom * , u8 * ) ;
   int (*set_eeprom)(struct dsa_switch * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_regs_len)(struct dsa_switch * , int  ) ;
   void (*get_regs)(struct dsa_switch * , int  , struct ethtool_regs * , void * ) ;
   int (*port_join_bridge)(struct dsa_switch * , int  , u32  ) ;
   int (*port_leave_bridge)(struct dsa_switch * , int  , u32  ) ;
   int (*port_stp_update)(struct dsa_switch * , int  , u8  ) ;
   int (*fdb_add)(struct dsa_switch * , int  , unsigned char const   * , u16  ) ;
   int (*fdb_del)(struct dsa_switch * , int  , unsigned char const   * , u16  ) ;
   int (*fdb_getnext)(struct dsa_switch * , int  , unsigned char * , bool * ) ;
};
struct ieee_ets {
   __u8 willing ;
   __u8 ets_cap ;
   __u8 cbs ;
   __u8 tc_tx_bw[8U] ;
   __u8 tc_rx_bw[8U] ;
   __u8 tc_tsa[8U] ;
   __u8 prio_tc[8U] ;
   __u8 tc_reco_bw[8U] ;
   __u8 tc_reco_tsa[8U] ;
   __u8 reco_prio_tc[8U] ;
};
struct ieee_maxrate {
   __u64 tc_maxrate[8U] ;
};
struct ieee_qcn {
   __u8 rpg_enable[8U] ;
   __u32 rppp_max_rps[8U] ;
   __u32 rpg_time_reset[8U] ;
   __u32 rpg_byte_reset[8U] ;
   __u32 rpg_threshold[8U] ;
   __u32 rpg_max_rate[8U] ;
   __u32 rpg_ai_rate[8U] ;
   __u32 rpg_hai_rate[8U] ;
   __u32 rpg_gd[8U] ;
   __u32 rpg_min_dec_fac[8U] ;
   __u32 rpg_min_rate[8U] ;
   __u32 cndd_state_machine[8U] ;
};
struct ieee_qcn_stats {
   __u64 rppp_rp_centiseconds[8U] ;
   __u32 rppp_created_rps[8U] ;
};
struct ieee_pfc {
   __u8 pfc_cap ;
   __u8 pfc_en ;
   __u8 mbc ;
   __u16 delay ;
   __u64 requests[8U] ;
   __u64 indications[8U] ;
};
struct cee_pg {
   __u8 willing ;
   __u8 error ;
   __u8 pg_en ;
   __u8 tcs_supported ;
   __u8 pg_bw[8U] ;
   __u8 prio_pg[8U] ;
};
struct cee_pfc {
   __u8 willing ;
   __u8 error ;
   __u8 pfc_en ;
   __u8 tcs_supported ;
};
struct dcb_app {
   __u8 selector ;
   __u8 priority ;
   __u16 protocol ;
};
struct dcb_peer_app_info {
   __u8 willing ;
   __u8 error ;
};
struct dcbnl_rtnl_ops {
   int (*ieee_getets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_setets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_getmaxrate)(struct net_device * , struct ieee_maxrate * ) ;
   int (*ieee_setmaxrate)(struct net_device * , struct ieee_maxrate * ) ;
   int (*ieee_getqcn)(struct net_device * , struct ieee_qcn * ) ;
   int (*ieee_setqcn)(struct net_device * , struct ieee_qcn * ) ;
   int (*ieee_getqcnstats)(struct net_device * , struct ieee_qcn_stats * ) ;
   int (*ieee_getpfc)(struct net_device * , struct ieee_pfc * ) ;
   int (*ieee_setpfc)(struct net_device * , struct ieee_pfc * ) ;
   int (*ieee_getapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_setapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_delapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_peer_getets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_peer_getpfc)(struct net_device * , struct ieee_pfc * ) ;
   u8 (*getstate)(struct net_device * ) ;
   u8 (*setstate)(struct net_device * , u8  ) ;
   void (*getpermhwaddr)(struct net_device * , u8 * ) ;
   void (*setpgtccfgtx)(struct net_device * , int  , u8  , u8  , u8  , u8  ) ;
   void (*setpgbwgcfgtx)(struct net_device * , int  , u8  ) ;
   void (*setpgtccfgrx)(struct net_device * , int  , u8  , u8  , u8  , u8  ) ;
   void (*setpgbwgcfgrx)(struct net_device * , int  , u8  ) ;
   void (*getpgtccfgtx)(struct net_device * , int  , u8 * , u8 * , u8 * , u8 * ) ;
   void (*getpgbwgcfgtx)(struct net_device * , int  , u8 * ) ;
   void (*getpgtccfgrx)(struct net_device * , int  , u8 * , u8 * , u8 * , u8 * ) ;
   void (*getpgbwgcfgrx)(struct net_device * , int  , u8 * ) ;
   void (*setpfccfg)(struct net_device * , int  , u8  ) ;
   void (*getpfccfg)(struct net_device * , int  , u8 * ) ;
   u8 (*setall)(struct net_device * ) ;
   u8 (*getcap)(struct net_device * , int  , u8 * ) ;
   int (*getnumtcs)(struct net_device * , int  , u8 * ) ;
   int (*setnumtcs)(struct net_device * , int  , u8  ) ;
   u8 (*getpfcstate)(struct net_device * ) ;
   void (*setpfcstate)(struct net_device * , u8  ) ;
   void (*getbcncfg)(struct net_device * , int  , u32 * ) ;
   void (*setbcncfg)(struct net_device * , int  , u32  ) ;
   void (*getbcnrp)(struct net_device * , int  , u8 * ) ;
   void (*setbcnrp)(struct net_device * , int  , u8  ) ;
   int (*setapp)(struct net_device * , u8  , u16  , u8  ) ;
   int (*getapp)(struct net_device * , u8  , u16  ) ;
   u8 (*getfeatcfg)(struct net_device * , int  , u8 * ) ;
   u8 (*setfeatcfg)(struct net_device * , int  , u8  ) ;
   u8 (*getdcbx)(struct net_device * ) ;
   u8 (*setdcbx)(struct net_device * , u8  ) ;
   int (*peer_getappinfo)(struct net_device * , struct dcb_peer_app_info * , u16 * ) ;
   int (*peer_getapptable)(struct net_device * , struct dcb_app * ) ;
   int (*cee_peer_getpg)(struct net_device * , struct cee_pg * ) ;
   int (*cee_peer_getpfc)(struct net_device * , struct cee_pfc * ) ;
};
struct taskstats {
   __u16 version ;
   __u32 ac_exitcode ;
   __u8 ac_flag ;
   __u8 ac_nice ;
   __u64 cpu_count ;
   __u64 cpu_delay_total ;
   __u64 blkio_count ;
   __u64 blkio_delay_total ;
   __u64 swapin_count ;
   __u64 swapin_delay_total ;
   __u64 cpu_run_real_total ;
   __u64 cpu_run_virtual_total ;
   char ac_comm[32U] ;
   __u8 ac_sched ;
   __u8 ac_pad[3U] ;
   __u32 ac_uid ;
   __u32 ac_gid ;
   __u32 ac_pid ;
   __u32 ac_ppid ;
   __u32 ac_btime ;
   __u64 ac_etime ;
   __u64 ac_utime ;
   __u64 ac_stime ;
   __u64 ac_minflt ;
   __u64 ac_majflt ;
   __u64 coremem ;
   __u64 virtmem ;
   __u64 hiwater_rss ;
   __u64 hiwater_vm ;
   __u64 read_char ;
   __u64 write_char ;
   __u64 read_syscalls ;
   __u64 write_syscalls ;
   __u64 read_bytes ;
   __u64 write_bytes ;
   __u64 cancelled_write_bytes ;
   __u64 nvcsw ;
   __u64 nivcsw ;
   __u64 ac_utimescaled ;
   __u64 ac_stimescaled ;
   __u64 cpu_scaled_run_real_total ;
   __u64 freepages_count ;
   __u64 freepages_delay_total ;
};
struct netprio_map {
   struct callback_head rcu ;
   u32 priomap_len ;
   u32 priomap[] ;
};
struct xfrm_policy;
struct xfrm_state;
struct request_sock;
struct mnt_namespace;
struct ipc_namespace;
struct nsproxy {
   atomic_t count ;
   struct uts_namespace *uts_ns ;
   struct ipc_namespace *ipc_ns ;
   struct mnt_namespace *mnt_ns ;
   struct pid_namespace *pid_ns_for_children ;
   struct net *net_ns ;
};
struct nlmsghdr {
   __u32 nlmsg_len ;
   __u16 nlmsg_type ;
   __u16 nlmsg_flags ;
   __u32 nlmsg_seq ;
   __u32 nlmsg_pid ;
};
struct nlattr {
   __u16 nla_len ;
   __u16 nla_type ;
};
struct netlink_callback {
   struct sk_buff *skb ;
   struct nlmsghdr  const  *nlh ;
   int (*dump)(struct sk_buff * , struct netlink_callback * ) ;
   int (*done)(struct netlink_callback * ) ;
   void *data ;
   struct module *module ;
   u16 family ;
   u16 min_dump_alloc ;
   unsigned int prev_seq ;
    klee_make_symbolic(&prev_seq, sizeof(int), "prev_seq");
   unsigned int seq ;
    klee_make_symbolic(&seq, sizeof(int), "seq");
   long args[6U] ;
};
struct ndmsg {
   __u8 ndm_family ;
   __u8 ndm_pad1 ;
   __u16 ndm_pad2 ;
   __s32 ndm_ifindex ;
   __u16 ndm_state ;
   __u8 ndm_flags ;
   __u8 ndm_type ;
};
struct rtnl_link_stats64 {
   __u64 rx_packets ;
   __u64 tx_packets ;
   __u64 rx_bytes ;
   __u64 tx_bytes ;
   __u64 rx_errors ;
   __u64 tx_errors ;
   __u64 rx_dropped ;
   __u64 tx_dropped ;
   __u64 multicast ;
   __u64 collisions ;
   __u64 rx_length_errors ;
   __u64 rx_over_errors ;
   __u64 rx_crc_errors ;
   __u64 rx_frame_errors ;
   __u64 rx_fifo_errors ;
   __u64 rx_missed_errors ;
   __u64 tx_aborted_errors ;
   __u64 tx_carrier_errors ;
   __u64 tx_fifo_errors ;
   __u64 tx_heartbeat_errors ;
   __u64 tx_window_errors ;
   __u64 rx_compressed ;
   __u64 tx_compressed ;
};
struct ifla_vf_stats {
   __u64 rx_packets ;
   __u64 tx_packets ;
   __u64 rx_bytes ;
   __u64 tx_bytes ;
   __u64 broadcast ;
   __u64 multicast ;
};
struct ifla_vf_info {
   __u32 vf ;
   __u8 mac[32U] ;
   __u32 vlan ;
   __u32 qos ;
   __u32 spoofchk ;
   __u32 linkstate ;
   __u32 min_tx_rate ;
   __u32 max_tx_rate ;
   __u32 rss_query_en ;
};
struct netpoll_info;
struct wireless_dev;
struct wpan_dev;
struct mpls_dev;
enum netdev_tx {
    __NETDEV_TX_MIN = (-0x7FFFFFFF-1),
    NETDEV_TX_OK = 0,
    NETDEV_TX_BUSY = 16,
    NETDEV_TX_LOCKED = 32
} ;
typedef enum netdev_tx netdev_tx_t;
struct net_device_stats {
   unsigned long rx_packets ;
    klee_make_symbolic(&rx_packets, sizeof(long), "rx_packets");
   unsigned long tx_packets ;
    klee_make_symbolic(&tx_packets, sizeof(long), "tx_packets");
   unsigned long rx_bytes ;
    klee_make_symbolic(&rx_bytes, sizeof(long), "rx_bytes");
   unsigned long tx_bytes ;
    klee_make_symbolic(&tx_bytes, sizeof(long), "tx_bytes");
   unsigned long rx_errors ;
    klee_make_symbolic(&rx_errors, sizeof(long), "rx_errors");
   unsigned long tx_errors ;
    klee_make_symbolic(&tx_errors, sizeof(long), "tx_errors");
   unsigned long rx_dropped ;
    klee_make_symbolic(&rx_dropped, sizeof(long), "rx_dropped");
   unsigned long tx_dropped ;
    klee_make_symbolic(&tx_dropped, sizeof(long), "tx_dropped");
   unsigned long multicast ;
    klee_make_symbolic(&multicast, sizeof(long), "multicast");
   unsigned long collisions ;
    klee_make_symbolic(&collisions, sizeof(long), "collisions");
   unsigned long rx_length_errors ;
    klee_make_symbolic(&rx_length_errors, sizeof(long), "rx_length_errors");
   unsigned long rx_over_errors ;
    klee_make_symbolic(&rx_over_errors, sizeof(long), "rx_over_errors");
   unsigned long rx_crc_errors ;
    klee_make_symbolic(&rx_crc_errors, sizeof(long), "rx_crc_errors");
   unsigned long rx_frame_errors ;
    klee_make_symbolic(&rx_frame_errors, sizeof(long), "rx_frame_errors");
   unsigned long rx_fifo_errors ;
    klee_make_symbolic(&rx_fifo_errors, sizeof(long), "rx_fifo_errors");
   unsigned long rx_missed_errors ;
    klee_make_symbolic(&rx_missed_errors, sizeof(long), "rx_missed_errors");
   unsigned long tx_aborted_errors ;
    klee_make_symbolic(&tx_aborted_errors, sizeof(long), "tx_aborted_errors");
   unsigned long tx_carrier_errors ;
    klee_make_symbolic(&tx_carrier_errors, sizeof(long), "tx_carrier_errors");
   unsigned long tx_fifo_errors ;
    klee_make_symbolic(&tx_fifo_errors, sizeof(long), "tx_fifo_errors");
   unsigned long tx_heartbeat_errors ;
    klee_make_symbolic(&tx_heartbeat_errors, sizeof(long), "tx_heartbeat_errors");
   unsigned long tx_window_errors ;
    klee_make_symbolic(&tx_window_errors, sizeof(long), "tx_window_errors");
   unsigned long rx_compressed ;
    klee_make_symbolic(&rx_compressed, sizeof(long), "rx_compressed");
   unsigned long tx_compressed ;
    klee_make_symbolic(&tx_compressed, sizeof(long), "tx_compressed");
};
struct neigh_parms;
struct netdev_hw_addr {
   struct list_head list ;
   unsigned char addr[32U] ;
   unsigned char type ;
   bool global_use ;
   int sync_cnt ;
    klee_make_symbolic(&sync_cnt, sizeof(int), "sync_cnt");
   int refcount ;
   int synced ;
    klee_make_symbolic(&synced, sizeof(int), "synced");
   struct callback_head callback_head ;
};
struct netdev_hw_addr_list {
   struct list_head list ;
   int count ;
};
struct hh_cache {
   u16 hh_len ;
   u16 __pad ;
   seqlock_t hh_lock ;
   unsigned long hh_data[16U] ;
};
struct header_ops {
   int (*create)(struct sk_buff * , struct net_device * , unsigned short  , void const   * ,
                 void const   * , unsigned int  ) ;
   int (*parse)(struct sk_buff  const  * , unsigned char * ) ;
   int (*cache)(struct neighbour  const  * , struct hh_cache * , __be16  ) ;
   void (*cache_update)(struct hh_cache * , struct net_device  const  * , unsigned char const   * ) ;
};
struct napi_struct {
   struct list_head poll_list ;
   unsigned long state ;
   int weight ;
   unsigned int gro_count ;
    klee_make_symbolic(&gro_count, sizeof(int), "gro_count");
   int (*poll)(struct napi_struct * , int  ) ;
   spinlock_t poll_lock ;
   int poll_owner ;
    klee_make_symbolic(&poll_owner, sizeof(int), "poll_owner");
   struct net_device *dev ;
   struct sk_buff *gro_list ;
   struct sk_buff *skb ;
   struct hrtimer timer ;
   struct list_head dev_list ;
   struct hlist_node napi_hash_node ;
   unsigned int napi_id ;
};
enum rx_handler_result {
    RX_HANDLER_CONSUMED = 0,
    RX_HANDLER_ANOTHER = 1,
    RX_HANDLER_EXACT = 2,
    RX_HANDLER_PASS = 3
} ;
typedef enum rx_handler_result rx_handler_result_t;
typedef rx_handler_result_t rx_handler_func_t(struct sk_buff ** );
struct Qdisc;
struct netdev_queue {
   struct net_device *dev ;
   struct Qdisc *qdisc ;
   struct Qdisc *qdisc_sleeping ;
   struct kobject kobj ;
   int numa_node ;
   spinlock_t _xmit_lock ;
   int xmit_lock_owner ;
    klee_make_symbolic(&xmit_lock_owner, sizeof(int), "xmit_lock_owner");
   unsigned long trans_start ;
    klee_make_symbolic(&trans_start, sizeof(long), "trans_start");
   unsigned long trans_timeout ;
    klee_make_symbolic(&trans_timeout, sizeof(long), "trans_timeout");
   unsigned long state ;
   struct dql dql ;
   unsigned long tx_maxrate ;
    klee_make_symbolic(&tx_maxrate, sizeof(long), "tx_maxrate");
};
struct rps_map {
   unsigned int len ;
   struct callback_head rcu ;
   u16 cpus[0U] ;
};
struct rps_dev_flow {
   u16 cpu ;
   u16 filter ;
   unsigned int last_qtail ;
    klee_make_symbolic(&last_qtail, sizeof(int), "last_qtail");
};
struct rps_dev_flow_table {
   unsigned int mask ;
   struct callback_head rcu ;
   struct rps_dev_flow flows[0U] ;
};
struct netdev_rx_queue {
   struct rps_map *rps_map ;
   struct rps_dev_flow_table *rps_flow_table ;
   struct kobject kobj ;
   struct net_device *dev ;
};
struct xps_map {
   unsigned int len ;
   unsigned int alloc_len ;
    klee_make_symbolic(&alloc_len, sizeof(int), "alloc_len");
   struct callback_head rcu ;
   u16 queues[0U] ;
};
struct xps_dev_maps {
   struct callback_head rcu ;
   struct xps_map *cpu_map[0U] ;
};
struct netdev_tc_txq {
   u16 count ;
   u16 offset ;
};
struct netdev_fcoe_hbainfo {
   char manufacturer[64U] ;
   char serial_number[64U] ;
   char hardware_version[64U] ;
   char driver_version[64U] ;
   char optionrom_version[64U] ;
   char firmware_version[64U] ;
   char model[256U] ;
   char model_description[256U] ;
};
struct netdev_phys_item_id {
   unsigned char id[32U] ;
   unsigned char id_len ;
    klee_make_symbolic(&id_len, sizeof(char), "id_len");
};
struct net_device_ops {
   int (*ndo_init)(struct net_device * ) ;
   void (*ndo_uninit)(struct net_device * ) ;
   int (*ndo_open)(struct net_device * ) ;
   int (*ndo_stop)(struct net_device * ) ;
   netdev_tx_t (*ndo_start_xmit)(struct sk_buff * , struct net_device * ) ;
   u16 (*ndo_select_queue)(struct net_device * , struct sk_buff * , void * , u16 (*)(struct net_device * ,
                                                                                     struct sk_buff * ) ) ;
   void (*ndo_change_rx_flags)(struct net_device * , int  ) ;
   void (*ndo_set_rx_mode)(struct net_device * ) ;
   int (*ndo_set_mac_address)(struct net_device * , void * ) ;
   int (*ndo_validate_addr)(struct net_device * ) ;
   int (*ndo_do_ioctl)(struct net_device * , struct ifreq * , int  ) ;
   int (*ndo_set_config)(struct net_device * , struct ifmap * ) ;
   int (*ndo_change_mtu)(struct net_device * , int  ) ;
   int (*ndo_neigh_setup)(struct net_device * , struct neigh_parms * ) ;
   void (*ndo_tx_timeout)(struct net_device * ) ;
   struct rtnl_link_stats64 *(*ndo_get_stats64)(struct net_device * , struct rtnl_link_stats64 * ) ;
   struct net_device_stats *(*ndo_get_stats)(struct net_device * ) ;
   int (*ndo_vlan_rx_add_vid)(struct net_device * , __be16  , u16  ) ;
   int (*ndo_vlan_rx_kill_vid)(struct net_device * , __be16  , u16  ) ;
   void (*ndo_poll_controller)(struct net_device * ) ;
   int (*ndo_netpoll_setup)(struct net_device * , struct netpoll_info * ) ;
   void (*ndo_netpoll_cleanup)(struct net_device * ) ;
   int (*ndo_busy_poll)(struct napi_struct * ) ;
   int (*ndo_set_vf_mac)(struct net_device * , int  , u8 * ) ;
   int (*ndo_set_vf_vlan)(struct net_device * , int  , u16  , u8  ) ;
   int (*ndo_set_vf_rate)(struct net_device * , int  , int  , int  ) ;
   int (*ndo_set_vf_spoofchk)(struct net_device * , int  , bool  ) ;
   int (*ndo_get_vf_config)(struct net_device * , int  , struct ifla_vf_info * ) ;
   int (*ndo_set_vf_link_state)(struct net_device * , int  , int  ) ;
   int (*ndo_get_vf_stats)(struct net_device * , int  , struct ifla_vf_stats * ) ;
   int (*ndo_set_vf_port)(struct net_device * , int  , struct nlattr ** ) ;
   int (*ndo_get_vf_port)(struct net_device * , int  , struct sk_buff * ) ;
   int (*ndo_set_vf_rss_query_en)(struct net_device * , int  , bool  ) ;
   int (*ndo_setup_tc)(struct net_device * , u8  ) ;
   int (*ndo_fcoe_enable)(struct net_device * ) ;
   int (*ndo_fcoe_disable)(struct net_device * ) ;
   int (*ndo_fcoe_ddp_setup)(struct net_device * , u16  , struct scatterlist * , unsigned int  ) ;
   int (*ndo_fcoe_ddp_done)(struct net_device * , u16  ) ;
   int (*ndo_fcoe_ddp_target)(struct net_device * , u16  , struct scatterlist * ,
                              unsigned int  ) ;
   int (*ndo_fcoe_get_hbainfo)(struct net_device * , struct netdev_fcoe_hbainfo * ) ;
   int (*ndo_fcoe_get_wwn)(struct net_device * , u64 * , int  ) ;
   int (*ndo_rx_flow_steer)(struct net_device * , struct sk_buff  const  * , u16  ,
                            u32  ) ;
   int (*ndo_add_slave)(struct net_device * , struct net_device * ) ;
   int (*ndo_del_slave)(struct net_device * , struct net_device * ) ;
   netdev_features_t (*ndo_fix_features)(struct net_device * , netdev_features_t  ) ;
   int (*ndo_set_features)(struct net_device * , netdev_features_t  ) ;
   int (*ndo_neigh_construct)(struct neighbour * ) ;
   void (*ndo_neigh_destroy)(struct neighbour * ) ;
   int (*ndo_fdb_add)(struct ndmsg * , struct nlattr ** , struct net_device * , unsigned char const   * ,
                      u16  , u16  ) ;
   int (*ndo_fdb_del)(struct ndmsg * , struct nlattr ** , struct net_device * , unsigned char const   * ,
                      u16  ) ;
   int (*ndo_fdb_dump)(struct sk_buff * , struct netlink_callback * , struct net_device * ,
                       struct net_device * , int  ) ;
   int (*ndo_bridge_setlink)(struct net_device * , struct nlmsghdr * , u16  ) ;
   int (*ndo_bridge_getlink)(struct sk_buff * , u32  , u32  , struct net_device * ,
                             u32  , int  ) ;
   int (*ndo_bridge_dellink)(struct net_device * , struct nlmsghdr * , u16  ) ;
   int (*ndo_change_carrier)(struct net_device * , bool  ) ;
   int (*ndo_get_phys_port_id)(struct net_device * , struct netdev_phys_item_id * ) ;
   int (*ndo_get_phys_port_name)(struct net_device * , char * , size_t  ) ;
   void (*ndo_add_vxlan_port)(struct net_device * , sa_family_t  , __be16  ) ;
   void (*ndo_del_vxlan_port)(struct net_device * , sa_family_t  , __be16  ) ;
   void *(*ndo_dfwd_add_station)(struct net_device * , struct net_device * ) ;
   void (*ndo_dfwd_del_station)(struct net_device * , void * ) ;
   netdev_tx_t (*ndo_dfwd_start_xmit)(struct sk_buff * , struct net_device * , void * ) ;
   int (*ndo_get_lock_subclass)(struct net_device * ) ;
   netdev_features_t (*ndo_features_check)(struct sk_buff * , struct net_device * ,
                                           netdev_features_t  ) ;
   int (*ndo_set_tx_maxrate)(struct net_device * , int  , u32  ) ;
   int (*ndo_get_iflink)(struct net_device  const  * ) ;
};
struct __anonstruct_adj_list_304 {
   struct list_head upper ;
   struct list_head lower ;
};
struct __anonstruct_all_adj_list_305 {
   struct list_head upper ;
   struct list_head lower ;
};
struct iw_handler_def;
struct iw_public_data;
struct switchdev_ops;
struct vlan_info;
struct tipc_bearer;
struct in_device;
struct dn_dev;
struct inet6_dev;
struct tcf_proto;
struct cpu_rmap;
struct pcpu_lstats;
struct pcpu_sw_netstats;
struct pcpu_dstats;
struct pcpu_vstats;
union __anonunion____missing_field_name_306 {
   void *ml_priv ;
   struct pcpu_lstats *lstats ;
   struct pcpu_sw_netstats *tstats ;
   struct pcpu_dstats *dstats ;
   struct pcpu_vstats *vstats ;
};
struct garp_port;
struct mrp_port;
struct rtnl_link_ops;
struct net_device {
   char name[16U] ;
   struct hlist_node name_hlist ;
   char *ifalias ;
   unsigned long mem_end ;
   unsigned long mem_start ;
   unsigned long base_addr ;
   int irq ;
   atomic_t carrier_changes ;
   unsigned long state ;
   struct list_head dev_list ;
   struct list_head napi_list ;
   struct list_head unreg_list ;
   struct list_head close_list ;
   struct list_head ptype_all ;
   struct list_head ptype_specific ;
   struct __anonstruct_adj_list_304 adj_list ;
   struct __anonstruct_all_adj_list_305 all_adj_list ;
   netdev_features_t features ;
   netdev_features_t hw_features ;
   netdev_features_t wanted_features ;
   netdev_features_t vlan_features ;
   netdev_features_t hw_enc_features ;
   netdev_features_t mpls_features ;
   int ifindex ;
   int group ;
    klee_make_symbolic(&group, sizeof(int), "group");
   struct net_device_stats stats ;
   atomic_long_t rx_dropped ;
   atomic_long_t tx_dropped ;
   struct iw_handler_def  const  *wireless_handlers ;
   struct iw_public_data *wireless_data ;
   struct net_device_ops  const  *netdev_ops ;
   struct ethtool_ops  const  *ethtool_ops ;
   struct switchdev_ops  const  *switchdev_ops ;
   struct header_ops  const  *header_ops ;
   unsigned int flags ;
   unsigned int priv_flags ;
    klee_make_symbolic(&priv_flags, sizeof(int), "priv_flags");
   unsigned short gflags ;
    klee_make_symbolic(&gflags, sizeof(short), "gflags");
   unsigned short padded ;
    klee_make_symbolic(&padded, sizeof(short), "padded");
   unsigned char operstate ;
    klee_make_symbolic(&operstate, sizeof(char), "operstate");
   unsigned char link_mode ;
    klee_make_symbolic(&link_mode, sizeof(char), "link_mode");
   unsigned char if_port ;
    klee_make_symbolic(&if_port, sizeof(char), "if_port");
   unsigned char dma ;
   unsigned int mtu ;
    klee_make_symbolic(&mtu, sizeof(int), "mtu");
   unsigned short type ;
   unsigned short hard_header_len ;
    klee_make_symbolic(&hard_header_len, sizeof(short), "hard_header_len");
   unsigned short needed_headroom ;
    klee_make_symbolic(&needed_headroom, sizeof(short), "needed_headroom");
   unsigned short needed_tailroom ;
    klee_make_symbolic(&needed_tailroom, sizeof(short), "needed_tailroom");
   unsigned char perm_addr[32U] ;
   unsigned char addr_assign_type ;
    klee_make_symbolic(&addr_assign_type, sizeof(char), "addr_assign_type");
   unsigned char addr_len ;
    klee_make_symbolic(&addr_len, sizeof(char), "addr_len");
   unsigned short neigh_priv_len ;
    klee_make_symbolic(&neigh_priv_len, sizeof(short), "neigh_priv_len");
   unsigned short dev_id ;
    klee_make_symbolic(&dev_id, sizeof(short), "dev_id");
   unsigned short dev_port ;
    klee_make_symbolic(&dev_port, sizeof(short), "dev_port");
   spinlock_t addr_list_lock ;
   unsigned char name_assign_type ;
    klee_make_symbolic(&name_assign_type, sizeof(char), "name_assign_type");
   bool uc_promisc ;
   struct netdev_hw_addr_list uc ;
   struct netdev_hw_addr_list mc ;
   struct netdev_hw_addr_list dev_addrs ;
   struct kset *queues_kset ;
   unsigned int promiscuity ;
    klee_make_symbolic(&promiscuity, sizeof(int), "promiscuity");
   unsigned int allmulti ;
    klee_make_symbolic(&allmulti, sizeof(int), "allmulti");
   struct vlan_info *vlan_info ;
   struct dsa_switch_tree *dsa_ptr ;
   struct tipc_bearer *tipc_ptr ;
   void *atalk_ptr ;
   struct in_device *ip_ptr ;
   struct dn_dev *dn_ptr ;
   struct inet6_dev *ip6_ptr ;
   void *ax25_ptr ;
   struct wireless_dev *ieee80211_ptr ;
   struct wpan_dev *ieee802154_ptr ;
   struct mpls_dev *mpls_ptr ;
   unsigned long last_rx ;
    klee_make_symbolic(&last_rx, sizeof(long), "last_rx");
   unsigned char *dev_addr ;
   struct netdev_rx_queue *_rx ;
   unsigned int num_rx_queues ;
    klee_make_symbolic(&num_rx_queues, sizeof(int), "num_rx_queues");
   unsigned int real_num_rx_queues ;
    klee_make_symbolic(&real_num_rx_queues, sizeof(int), "real_num_rx_queues");
   unsigned long gro_flush_timeout ;
    klee_make_symbolic(&gro_flush_timeout, sizeof(long), "gro_flush_timeout");
   rx_handler_func_t *rx_handler ;
   void *rx_handler_data ;
   struct tcf_proto *ingress_cl_list ;
   struct netdev_queue *ingress_queue ;
   struct list_head nf_hooks_ingress ;
   unsigned char broadcast[32U] ;
   struct cpu_rmap *rx_cpu_rmap ;
   struct hlist_node index_hlist ;
   struct netdev_queue *_tx ;
   unsigned int num_tx_queues ;
    klee_make_symbolic(&num_tx_queues, sizeof(int), "num_tx_queues");
   unsigned int real_num_tx_queues ;
    klee_make_symbolic(&real_num_tx_queues, sizeof(int), "real_num_tx_queues");
   struct Qdisc *qdisc ;
   unsigned long tx_queue_len ;
    klee_make_symbolic(&tx_queue_len, sizeof(long), "tx_queue_len");
   spinlock_t tx_global_lock ;
   int watchdog_timeo ;
    klee_make_symbolic(&watchdog_timeo, sizeof(int), "watchdog_timeo");
   struct xps_dev_maps *xps_maps ;
   unsigned long trans_start ;
   struct timer_list watchdog_timer ;
   int *pcpu_refcnt ;
   struct list_head todo_list ;
   struct list_head link_watch_list ;
   unsigned char reg_state ;
    klee_make_symbolic(&reg_state, sizeof(char), "reg_state");
   bool dismantle ;
   unsigned short rtnl_link_state ;
    klee_make_symbolic(&rtnl_link_state, sizeof(short), "rtnl_link_state");
   void (*destructor)(struct net_device * ) ;
   struct netpoll_info *npinfo ;
   possible_net_t nd_net ;
   union __anonunion____missing_field_name_306 __annonCompField93 ;
   struct garp_port *garp_port ;
   struct mrp_port *mrp_port ;
   struct device dev ;
   struct attribute_group  const  *sysfs_groups[4U] ;
   struct attribute_group  const  *sysfs_rx_queue_group ;
   struct rtnl_link_ops  const  *rtnl_link_ops ;
   unsigned int gso_max_size ;
    klee_make_symbolic(&gso_max_size, sizeof(int), "gso_max_size");
   u16 gso_max_segs ;
   u16 gso_min_segs ;
   struct dcbnl_rtnl_ops  const  *dcbnl_ops ;
   u8 num_tc ;
   struct netdev_tc_txq tc_to_txq[16U] ;
   u8 prio_tc_map[16U] ;
   unsigned int fcoe_ddp_xid ;
    klee_make_symbolic(&fcoe_ddp_xid, sizeof(int), "fcoe_ddp_xid");
   struct netprio_map *priomap ;
   struct phy_device *phydev ;
   struct lock_class_key *qdisc_tx_busylock ;
};
struct packet_type {
   __be16 type ;
   struct net_device *dev ;
   int (*func)(struct sk_buff * , struct net_device * , struct packet_type * , struct net_device * ) ;
   bool (*id_match)(struct packet_type * , struct sock * ) ;
   void *af_packet_priv ;
   struct list_head list ;
};
struct pcpu_sw_netstats {
   u64 rx_packets ;
   u64 rx_bytes ;
   u64 tx_packets ;
   u64 tx_bytes ;
   struct u64_stats_sync syncp ;
};
struct page_counter {
   atomic_long_t count ;
   unsigned long limit ;
   struct page_counter *parent ;
   unsigned long watermark ;
    klee_make_symbolic(&watermark, sizeof(long), "watermark");
   unsigned long failcnt ;
    klee_make_symbolic(&failcnt, sizeof(long), "failcnt");
};
struct sock_filter {
   __u16 code ;
   __u8 jt ;
   __u8 jf ;
   __u32 k ;
};
struct bpf_insn {
   __u8 code ;
   unsigned char dst_reg : 4 ;
   unsigned char src_reg : 4 ;
   __s16 off ;
   __s32 imm ;
};
enum bpf_prog_type {
    BPF_PROG_TYPE_UNSPEC = 0,
    BPF_PROG_TYPE_SOCKET_FILTER = 1,
    BPF_PROG_TYPE_KPROBE = 2,
    BPF_PROG_TYPE_SCHED_CLS = 3,
    BPF_PROG_TYPE_SCHED_ACT = 4
} ;
struct bpf_prog_aux;
struct sock_fprog_kern {
   u16 len ;
   struct sock_filter *filter ;
};
union __anonunion____missing_field_name_317 {
   struct sock_filter insns[0U] ;
   struct bpf_insn insnsi[0U] ;
};
struct bpf_prog {
   u16 pages ;
   bool jited ;
   bool gpl_compatible ;
   u32 len ;
   enum bpf_prog_type type ;
   struct bpf_prog_aux *aux ;
   struct sock_fprog_kern *orig_prog ;
   unsigned int (*bpf_func)(struct sk_buff  const  * , struct bpf_insn  const  * ) ;
   union __anonunion____missing_field_name_317 __annonCompField98 ;
};
struct sk_filter {
   atomic_t refcnt ;
   struct callback_head rcu ;
   struct bpf_prog *prog ;
};
struct pollfd {
   int fd ;
    klee_make_symbolic(&fd, sizeof(int), "fd");
   short events ;
   short revents ;
    klee_make_symbolic(&revents, sizeof(short), "revents");
};
struct poll_table_struct {
   void (*_qproc)(struct file * , wait_queue_head_t * , struct poll_table_struct * ) ;
   unsigned long _key ;
    klee_make_symbolic(&_key, sizeof(long), "_key");
};
struct nla_policy {
   u16 type ;
   u16 len ;
};
struct rtnl_link_ops {
   struct list_head list ;
   char const   *kind ;
   size_t priv_size ;
   void (*setup)(struct net_device * ) ;
   int maxtype ;
    klee_make_symbolic(&maxtype, sizeof(int), "maxtype");
   struct nla_policy  const  *policy ;
   int (*validate)(struct nlattr ** , struct nlattr ** ) ;
   int (*newlink)(struct net * , struct net_device * , struct nlattr ** , struct nlattr ** ) ;
   int (*changelink)(struct net_device * , struct nlattr ** , struct nlattr ** ) ;
   void (*dellink)(struct net_device * , struct list_head * ) ;
   size_t (*get_size)(struct net_device  const  * ) ;
   int (*fill_info)(struct sk_buff * , struct net_device  const  * ) ;
   size_t (*get_xstats_size)(struct net_device  const  * ) ;
   int (*fill_xstats)(struct sk_buff * , struct net_device  const  * ) ;
   unsigned int (*get_num_tx_queues)(void) ;
   unsigned int (*get_num_rx_queues)(void) ;
   int slave_maxtype ;
    klee_make_symbolic(&slave_maxtype, sizeof(int), "slave_maxtype");
   struct nla_policy  const  *slave_policy ;
   int (*slave_validate)(struct nlattr ** , struct nlattr ** ) ;
   int (*slave_changelink)(struct net_device * , struct net_device * , struct nlattr ** ,
                           struct nlattr ** ) ;
   size_t (*get_slave_size)(struct net_device  const  * , struct net_device  const  * ) ;
   int (*fill_slave_info)(struct sk_buff * , struct net_device  const  * , struct net_device  const  * ) ;
   struct net *(*get_link_net)(struct net_device  const  * ) ;
};
struct neigh_table;
struct neigh_parms {
   possible_net_t net ;
   struct net_device *dev ;
   struct list_head list ;
   int (*neigh_setup)(struct neighbour * ) ;
   void (*neigh_cleanup)(struct neighbour * ) ;
   struct neigh_table *tbl ;
   void *sysctl_table ;
   int dead ;
    klee_make_symbolic(&dead, sizeof(int), "dead");
   atomic_t refcnt ;
   struct callback_head callback_head ;
   int reachable_time ;
    klee_make_symbolic(&reachable_time, sizeof(int), "reachable_time");
   int data[13U] ;
   unsigned long data_state[1U] ;
};
struct neigh_statistics {
   unsigned long allocs ;
    klee_make_symbolic(&allocs, sizeof(long), "allocs");
   unsigned long destroys ;
    klee_make_symbolic(&destroys, sizeof(long), "destroys");
   unsigned long hash_grows ;
    klee_make_symbolic(&hash_grows, sizeof(long), "hash_grows");
   unsigned long res_failed ;
    klee_make_symbolic(&res_failed, sizeof(long), "res_failed");
   unsigned long lookups ;
    klee_make_symbolic(&lookups, sizeof(long), "lookups");
   unsigned long hits ;
    klee_make_symbolic(&hits, sizeof(long), "hits");
   unsigned long rcv_probes_mcast ;
    klee_make_symbolic(&rcv_probes_mcast, sizeof(long), "rcv_probes_mcast");
   unsigned long rcv_probes_ucast ;
    klee_make_symbolic(&rcv_probes_ucast, sizeof(long), "rcv_probes_ucast");
   unsigned long periodic_gc_runs ;
    klee_make_symbolic(&periodic_gc_runs, sizeof(long), "periodic_gc_runs");
   unsigned long forced_gc_runs ;
    klee_make_symbolic(&forced_gc_runs, sizeof(long), "forced_gc_runs");
   unsigned long unres_discards ;
    klee_make_symbolic(&unres_discards, sizeof(long), "unres_discards");
};
struct neigh_ops;
struct neighbour {
   struct neighbour *next ;
   struct neigh_table *tbl ;
   struct neigh_parms *parms ;
   unsigned long confirmed ;
    klee_make_symbolic(&confirmed, sizeof(long), "confirmed");
   unsigned long updated ;
    klee_make_symbolic(&updated, sizeof(long), "updated");
   rwlock_t lock ;
   atomic_t refcnt ;
   struct sk_buff_head arp_queue ;
   unsigned int arp_queue_len_bytes ;
    klee_make_symbolic(&arp_queue_len_bytes, sizeof(int), "arp_queue_len_bytes");
   struct timer_list timer ;
   unsigned long used ;
   atomic_t probes ;
   __u8 flags ;
   __u8 nud_state ;
   __u8 type ;
   __u8 dead ;
   seqlock_t ha_lock ;
   unsigned char ha[32U] ;
   struct hh_cache hh ;
   int (*output)(struct neighbour * , struct sk_buff * ) ;
   struct neigh_ops  const  *ops ;
   struct callback_head rcu ;
   struct net_device *dev ;
   u8 primary_key[0U] ;
};
struct neigh_ops {
   int family ;
   void (*solicit)(struct neighbour * , struct sk_buff * ) ;
   void (*error_report)(struct neighbour * , struct sk_buff * ) ;
   int (*output)(struct neighbour * , struct sk_buff * ) ;
   int (*connected_output)(struct neighbour * , struct sk_buff * ) ;
};
struct pneigh_entry {
   struct pneigh_entry *next ;
   possible_net_t net ;
   struct net_device *dev ;
   u8 flags ;
   u8 key[0U] ;
};
struct neigh_hash_table {
   struct neighbour **hash_buckets ;
   unsigned int hash_shift ;
    klee_make_symbolic(&hash_shift, sizeof(int), "hash_shift");
   __u32 hash_rnd[4U] ;
   struct callback_head rcu ;
};
struct neigh_table {
   int family ;
   int entry_size ;
    klee_make_symbolic(&entry_size, sizeof(int), "entry_size");
   int key_len ;
    klee_make_symbolic(&key_len, sizeof(int), "key_len");
   __be16 protocol ;
   __u32 (*hash)(void const   * , struct net_device  const  * , __u32 * ) ;
   bool (*key_eq)(struct neighbour  const  * , void const   * ) ;
   int (*constructor)(struct neighbour * ) ;
   int (*pconstructor)(struct pneigh_entry * ) ;
   void (*pdestructor)(struct pneigh_entry * ) ;
   void (*proxy_redo)(struct sk_buff * ) ;
   char *id ;
   struct neigh_parms parms ;
   struct list_head parms_list ;
   int gc_interval ;
    klee_make_symbolic(&gc_interval, sizeof(int), "gc_interval");
   int gc_thresh1 ;
    klee_make_symbolic(&gc_thresh1, sizeof(int), "gc_thresh1");
   int gc_thresh2 ;
    klee_make_symbolic(&gc_thresh2, sizeof(int), "gc_thresh2");
   int gc_thresh3 ;
    klee_make_symbolic(&gc_thresh3, sizeof(int), "gc_thresh3");
   unsigned long last_flush ;
    klee_make_symbolic(&last_flush, sizeof(long), "last_flush");
   struct delayed_work gc_work ;
   struct timer_list proxy_timer ;
   struct sk_buff_head proxy_queue ;
   atomic_t entries ;
   rwlock_t lock ;
   unsigned long last_rand ;
    klee_make_symbolic(&last_rand, sizeof(long), "last_rand");
   struct neigh_statistics *stats ;
   struct neigh_hash_table *nht ;
   struct pneigh_entry **phash_buckets ;
};
struct dn_route;
union __anonunion____missing_field_name_328 {
   struct dst_entry *next ;
   struct rtable *rt_next ;
   struct rt6_info *rt6_next ;
   struct dn_route *dn_next ;
};
struct dst_entry {
   struct callback_head callback_head ;
   struct dst_entry *child ;
   struct net_device *dev ;
   struct dst_ops *ops ;
   unsigned long _metrics ;
    klee_make_symbolic(&_metrics, sizeof(long), "_metrics");
   unsigned long expires ;
   struct dst_entry *path ;
   struct dst_entry *from ;
   struct xfrm_state *xfrm ;
   int (*input)(struct sk_buff * ) ;
   int (*output)(struct sock * , struct sk_buff * ) ;
   unsigned short flags ;
   unsigned short pending_confirm ;
    klee_make_symbolic(&pending_confirm, sizeof(short), "pending_confirm");
   short error ;
    klee_make_symbolic(&error, sizeof(short), "error");
   short obsolete ;
    klee_make_symbolic(&obsolete, sizeof(short), "obsolete");
   unsigned short header_len ;
    klee_make_symbolic(&header_len, sizeof(short), "header_len");
   unsigned short trailer_len ;
    klee_make_symbolic(&trailer_len, sizeof(short), "trailer_len");
   __u32 tclassid ;
   long __pad_to_align_refcnt[2U] ;
   atomic_t __refcnt ;
   int __use ;
    klee_make_symbolic(&__use, sizeof(int), "__use");
   unsigned long lastuse ;
    klee_make_symbolic(&lastuse, sizeof(long), "lastuse");
   union __anonunion____missing_field_name_328 __annonCompField99 ;
};
struct hwtstamp_config {
   int flags ;
   int tx_type ;
    klee_make_symbolic(&tx_type, sizeof(int), "tx_type");
   int rx_filter ;
    klee_make_symbolic(&rx_filter, sizeof(int), "rx_filter");
};
struct __anonstruct_socket_lock_t_329 {
   spinlock_t slock ;
   int owned ;
    klee_make_symbolic(&owned, sizeof(int), "owned");
   wait_queue_head_t wq ;
   struct lockdep_map dep_map ;
};
typedef struct __anonstruct_socket_lock_t_329 socket_lock_t;
struct proto;
typedef __u32 __portpair;
typedef __u64 __addrpair;
struct __anonstruct____missing_field_name_331 {
   __be32 skc_daddr ;
   __be32 skc_rcv_saddr ;
};
union __anonunion____missing_field_name_330 {
   __addrpair skc_addrpair ;
   struct __anonstruct____missing_field_name_331 __annonCompField100 ;
};
union __anonunion____missing_field_name_332 {
   unsigned int skc_hash ;
    klee_make_symbolic(&skc_hash, sizeof(int), "skc_hash");
   __u16 skc_u16hashes[2U] ;
};
struct __anonstruct____missing_field_name_334 {
   __be16 skc_dport ;
   __u16 skc_num ;
};
union __anonunion____missing_field_name_333 {
   __portpair skc_portpair ;
   struct __anonstruct____missing_field_name_334 __annonCompField103 ;
};
union __anonunion____missing_field_name_335 {
   struct hlist_node skc_bind_node ;
   struct hlist_nulls_node skc_portaddr_node ;
};
union __anonunion____missing_field_name_336 {
   struct hlist_node skc_node ;
   struct hlist_nulls_node skc_nulls_node ;
};
struct sock_common {
   union __anonunion____missing_field_name_330 __annonCompField101 ;
   union __anonunion____missing_field_name_332 __annonCompField102 ;
   union __anonunion____missing_field_name_333 __annonCompField104 ;
   unsigned short skc_family ;
    klee_make_symbolic(&skc_family, sizeof(short), "skc_family");
   unsigned char volatile   skc_state ;
   unsigned char skc_reuse : 4 ;
   unsigned char skc_reuseport : 1 ;
   unsigned char skc_ipv6only : 1 ;
   unsigned char skc_net_refcnt : 1 ;
   int skc_bound_dev_if ;
    klee_make_symbolic(&skc_bound_dev_if, sizeof(int), "skc_bound_dev_if");
   union __anonunion____missing_field_name_335 __annonCompField105 ;
   struct proto *skc_prot ;
   possible_net_t skc_net ;
   struct in6_addr skc_v6_daddr ;
   struct in6_addr skc_v6_rcv_saddr ;
   atomic64_t skc_cookie ;
   int skc_dontcopy_begin[0U] ;
   union __anonunion____missing_field_name_336 __annonCompField106 ;
   int skc_tx_queue_mapping ;
    klee_make_symbolic(&skc_tx_queue_mapping, sizeof(int), "skc_tx_queue_mapping");
   atomic_t skc_refcnt ;
   int skc_dontcopy_end[0U] ;
};
struct cg_proto;
struct __anonstruct_sk_backlog_337 {
   atomic_t rmem_alloc ;
   int len ;
   struct sk_buff *head ;
   struct sk_buff *tail ;
};
struct sock {
   struct sock_common __sk_common ;
   socket_lock_t sk_lock ;
   struct sk_buff_head sk_receive_queue ;
   struct __anonstruct_sk_backlog_337 sk_backlog ;
   int sk_forward_alloc ;
    klee_make_symbolic(&sk_forward_alloc, sizeof(int), "sk_forward_alloc");
   __u32 sk_rxhash ;
   u16 sk_incoming_cpu ;
   __u32 sk_txhash ;
   unsigned int sk_napi_id ;
    klee_make_symbolic(&sk_napi_id, sizeof(int), "sk_napi_id");
   unsigned int sk_ll_usec ;
    klee_make_symbolic(&sk_ll_usec, sizeof(int), "sk_ll_usec");
   atomic_t sk_drops ;
   int sk_rcvbuf ;
    klee_make_symbolic(&sk_rcvbuf, sizeof(int), "sk_rcvbuf");
   struct sk_filter *sk_filter ;
   struct socket_wq *sk_wq ;
   struct xfrm_policy *sk_policy[2U] ;
   unsigned long sk_flags ;
    klee_make_symbolic(&sk_flags, sizeof(long), "sk_flags");
   struct dst_entry *sk_rx_dst ;
   struct dst_entry *sk_dst_cache ;
   spinlock_t sk_dst_lock ;
   atomic_t sk_wmem_alloc ;
   atomic_t sk_omem_alloc ;
   int sk_sndbuf ;
    klee_make_symbolic(&sk_sndbuf, sizeof(int), "sk_sndbuf");
   struct sk_buff_head sk_write_queue ;
   unsigned char sk_shutdown : 2 ;
   unsigned char sk_no_check_tx : 1 ;
   unsigned char sk_no_check_rx : 1 ;
   unsigned char sk_userlocks : 4 ;
   unsigned char sk_protocol ;
    klee_make_symbolic(&sk_protocol, sizeof(char), "sk_protocol");
   unsigned short sk_type ;
    klee_make_symbolic(&sk_type, sizeof(short), "sk_type");
   int sk_wmem_queued ;
    klee_make_symbolic(&sk_wmem_queued, sizeof(int), "sk_wmem_queued");
   gfp_t sk_allocation ;
   u32 sk_pacing_rate ;
   u32 sk_max_pacing_rate ;
   netdev_features_t sk_route_caps ;
   netdev_features_t sk_route_nocaps ;
   int sk_gso_type ;
    klee_make_symbolic(&sk_gso_type, sizeof(int), "sk_gso_type");
   unsigned int sk_gso_max_size ;
    klee_make_symbolic(&sk_gso_max_size, sizeof(int), "sk_gso_max_size");
   u16 sk_gso_max_segs ;
   int sk_rcvlowat ;
    klee_make_symbolic(&sk_rcvlowat, sizeof(int), "sk_rcvlowat");
   unsigned long sk_lingertime ;
    klee_make_symbolic(&sk_lingertime, sizeof(long), "sk_lingertime");
   struct sk_buff_head sk_error_queue ;
   struct proto *sk_prot_creator ;
   rwlock_t sk_callback_lock ;
   int sk_err ;
    klee_make_symbolic(&sk_err, sizeof(int), "sk_err");
   int sk_err_soft ;
    klee_make_symbolic(&sk_err_soft, sizeof(int), "sk_err_soft");
   u32 sk_ack_backlog ;
   u32 sk_max_ack_backlog ;
   __u32 sk_priority ;
   __u32 sk_cgrp_prioidx ;
   struct pid *sk_peer_pid ;
   struct cred  const  *sk_peer_cred ;
   long sk_rcvtimeo ;
    klee_make_symbolic(&sk_rcvtimeo, sizeof(long), "sk_rcvtimeo");
   long sk_sndtimeo ;
    klee_make_symbolic(&sk_sndtimeo, sizeof(long), "sk_sndtimeo");
   struct timer_list sk_timer ;
   ktime_t sk_stamp ;
   u16 sk_tsflags ;
   u32 sk_tskey ;
   struct socket *sk_socket ;
   void *sk_user_data ;
   struct page_frag sk_frag ;
   struct sk_buff *sk_send_head ;
   __s32 sk_peek_off ;
   int sk_write_pending ;
    klee_make_symbolic(&sk_write_pending, sizeof(int), "sk_write_pending");
   void *sk_security ;
   __u32 sk_mark ;
   u32 sk_classid ;
   struct cg_proto *sk_cgrp ;
   void (*sk_state_change)(struct sock * ) ;
   void (*sk_data_ready)(struct sock * ) ;
   void (*sk_write_space)(struct sock * ) ;
   void (*sk_error_report)(struct sock * ) ;
   int (*sk_backlog_rcv)(struct sock * , struct sk_buff * ) ;
   void (*sk_destruct)(struct sock * ) ;
};
struct request_sock_ops;
struct timewait_sock_ops;
struct inet_hashinfo;
struct raw_hashinfo;
struct udp_table;
union __anonunion_h_340 {
   struct inet_hashinfo *hashinfo ;
   struct udp_table *udp_table ;
   struct raw_hashinfo *raw_hash ;
};
struct proto {
   void (*close)(struct sock * , long  ) ;
   int (*connect)(struct sock * , struct sockaddr * , int  ) ;
   int (*disconnect)(struct sock * , int  ) ;
   struct sock *(*accept)(struct sock * , int  , int * ) ;
   int (*ioctl)(struct sock * , int  , unsigned long  ) ;
   int (*init)(struct sock * ) ;
   void (*destroy)(struct sock * ) ;
   void (*shutdown)(struct sock * , int  ) ;
   int (*setsockopt)(struct sock * , int  , int  , char * , unsigned int  ) ;
   int (*getsockopt)(struct sock * , int  , int  , char * , int * ) ;
   int (*compat_setsockopt)(struct sock * , int  , int  , char * , unsigned int  ) ;
   int (*compat_getsockopt)(struct sock * , int  , int  , char * , int * ) ;
   int (*compat_ioctl)(struct sock * , unsigned int  , unsigned long  ) ;
   int (*sendmsg)(struct sock * , struct msghdr * , size_t  ) ;
   int (*recvmsg)(struct sock * , struct msghdr * , size_t  , int  , int  , int * ) ;
   int (*sendpage)(struct sock * , struct page * , int  , size_t  , int  ) ;
   int (*bind)(struct sock * , struct sockaddr * , int  ) ;
   int (*backlog_rcv)(struct sock * , struct sk_buff * ) ;
   void (*release_cb)(struct sock * ) ;
   void (*hash)(struct sock * ) ;
   void (*unhash)(struct sock * ) ;
   void (*rehash)(struct sock * ) ;
   int (*get_port)(struct sock * , unsigned short  ) ;
   void (*clear_sk)(struct sock * , int  ) ;
   unsigned int inuse_idx ;
    klee_make_symbolic(&inuse_idx, sizeof(int), "inuse_idx");
   bool (*stream_memory_free)(struct sock  const  * ) ;
   void (*enter_memory_pressure)(struct sock * ) ;
   atomic_long_t *memory_allocated ;
   struct percpu_counter *sockets_allocated ;
   int *memory_pressure ;
   long *sysctl_mem ;
   int *sysctl_wmem ;
   int *sysctl_rmem ;
   int max_header ;
    klee_make_symbolic(&max_header, sizeof(int), "max_header");
   bool no_autobind ;
   struct kmem_cache *slab ;
   unsigned int obj_size ;
    klee_make_symbolic(&obj_size, sizeof(int), "obj_size");
   int slab_flags ;
    klee_make_symbolic(&slab_flags, sizeof(int), "slab_flags");
   struct percpu_counter *orphan_count ;
   struct request_sock_ops *rsk_prot ;
   struct timewait_sock_ops *twsk_prot ;
   union __anonunion_h_340 h ;
   struct module *owner ;
   char name[32U] ;
   struct list_head node ;
   int (*init_cgroup)(struct mem_cgroup * , struct cgroup_subsys * ) ;
   void (*destroy_cgroup)(struct mem_cgroup * ) ;
   struct cg_proto *(*proto_cgroup)(struct mem_cgroup * ) ;
};
struct cg_proto {
   struct page_counter memory_allocated ;
   struct percpu_counter sockets_allocated ;
   int memory_pressure ;
    klee_make_symbolic(&memory_pressure, sizeof(int), "memory_pressure");
   long sysctl_mem[3U] ;
   unsigned long flags ;
   struct mem_cgroup *memcg ;
};
struct request_sock_ops {
   int family ;
   int obj_size ;
   struct kmem_cache *slab ;
   char *slab_name ;
   int (*rtx_syn_ack)(struct sock * , struct request_sock * ) ;
   void (*send_ack)(struct sock * , struct sk_buff * , struct request_sock * ) ;
   void (*send_reset)(struct sock * , struct sk_buff * ) ;
   void (*destructor)(struct request_sock * ) ;
   void (*syn_ack_timeout)(struct request_sock  const  * ) ;
};
struct request_sock {
   struct sock_common __req_common ;
   struct request_sock *dl_next ;
   struct sock *rsk_listener ;
   u16 mss ;
   u8 num_retrans ;
   unsigned char cookie_ts : 1 ;
   unsigned char num_timeout : 7 ;
   u32 window_clamp ;
   u32 rcv_wnd ;
   u32 ts_recent ;
   struct timer_list rsk_timer ;
   struct request_sock_ops  const  *rsk_ops ;
   struct sock *sk ;
   u32 *saved_syn ;
   u32 secid ;
   u32 peer_secid ;
};
struct timewait_sock_ops {
   struct kmem_cache *twsk_slab ;
   char *twsk_slab_name ;
   unsigned int twsk_obj_size ;
    klee_make_symbolic(&twsk_obj_size, sizeof(int), "twsk_obj_size");
   int (*twsk_unique)(struct sock * , struct sock * , void * ) ;
   void (*twsk_destructor)(struct sock * ) ;
};
struct ipv6_stable_secret {
   bool initialized ;
   struct in6_addr secret ;
};
struct ipv6_devconf {
   __s32 forwarding ;
   __s32 hop_limit ;
   __s32 mtu6 ;
   __s32 accept_ra ;
   __s32 accept_redirects ;
   __s32 autoconf ;
   __s32 dad_transmits ;
   __s32 rtr_solicits ;
   __s32 rtr_solicit_interval ;
   __s32 rtr_solicit_delay ;
   __s32 force_mld_version ;
   __s32 mldv1_unsolicited_report_interval ;
   __s32 mldv2_unsolicited_report_interval ;
   __s32 use_tempaddr ;
   __s32 temp_valid_lft ;
   __s32 temp_prefered_lft ;
   __s32 regen_max_retry ;
   __s32 max_desync_factor ;
   __s32 max_addresses ;
   __s32 accept_ra_defrtr ;
   __s32 accept_ra_pinfo ;
   __s32 accept_ra_rtr_pref ;
   __s32 rtr_probe_interval ;
   __s32 accept_ra_rt_info_max_plen ;
   __s32 proxy_ndp ;
   __s32 accept_source_route ;
   __s32 accept_ra_from_local ;
   __s32 optimistic_dad ;
   __s32 use_optimistic ;
   __s32 mc_forwarding ;
   __s32 disable_ipv6 ;
   __s32 accept_dad ;
   __s32 force_tllao ;
   __s32 ndisc_notify ;
   __s32 suppress_frag_ndisc ;
   __s32 accept_ra_mtu ;
   struct ipv6_stable_secret stable_secret ;
   void *sysctl ;
};
struct ip6_sf_list {
   struct ip6_sf_list *sf_next ;
   struct in6_addr sf_addr ;
   unsigned long sf_count[2U] ;
   unsigned char sf_gsresp ;
    klee_make_symbolic(&sf_gsresp, sizeof(char), "sf_gsresp");
   unsigned char sf_oldin ;
    klee_make_symbolic(&sf_oldin, sizeof(char), "sf_oldin");
   unsigned char sf_crcount ;
    klee_make_symbolic(&sf_crcount, sizeof(char), "sf_crcount");
};
struct ifmcaddr6 {
   struct in6_addr mca_addr ;
   struct inet6_dev *idev ;
   struct ifmcaddr6 *next ;
   struct ip6_sf_list *mca_sources ;
   struct ip6_sf_list *mca_tomb ;
   unsigned int mca_sfmode ;
    klee_make_symbolic(&mca_sfmode, sizeof(int), "mca_sfmode");
   unsigned char mca_crcount ;
    klee_make_symbolic(&mca_crcount, sizeof(char), "mca_crcount");
   unsigned long mca_sfcount[2U] ;
   struct timer_list mca_timer ;
   unsigned int mca_flags ;
    klee_make_symbolic(&mca_flags, sizeof(int), "mca_flags");
   int mca_users ;
    klee_make_symbolic(&mca_users, sizeof(int), "mca_users");
   atomic_t mca_refcnt ;
   spinlock_t mca_lock ;
   unsigned long mca_cstamp ;
    klee_make_symbolic(&mca_cstamp, sizeof(long), "mca_cstamp");
   unsigned long mca_tstamp ;
    klee_make_symbolic(&mca_tstamp, sizeof(long), "mca_tstamp");
};
struct ifacaddr6 {
   struct in6_addr aca_addr ;
   struct inet6_dev *aca_idev ;
   struct rt6_info *aca_rt ;
   struct ifacaddr6 *aca_next ;
   int aca_users ;
    klee_make_symbolic(&aca_users, sizeof(int), "aca_users");
   atomic_t aca_refcnt ;
   unsigned long aca_cstamp ;
    klee_make_symbolic(&aca_cstamp, sizeof(long), "aca_cstamp");
   unsigned long aca_tstamp ;
    klee_make_symbolic(&aca_tstamp, sizeof(long), "aca_tstamp");
};
struct ipv6_devstat {
   struct proc_dir_entry *proc_dir_entry ;
   struct ipstats_mib *ipv6 ;
   struct icmpv6_mib_device *icmpv6dev ;
   struct icmpv6msg_mib_device *icmpv6msgdev ;
};
struct inet6_dev {
   struct net_device *dev ;
   struct list_head addr_list ;
   struct ifmcaddr6 *mc_list ;
   struct ifmcaddr6 *mc_tomb ;
   spinlock_t mc_lock ;
   unsigned char mc_qrv ;
    klee_make_symbolic(&mc_qrv, sizeof(char), "mc_qrv");
   unsigned char mc_gq_running ;
    klee_make_symbolic(&mc_gq_running, sizeof(char), "mc_gq_running");
   unsigned char mc_ifc_count ;
    klee_make_symbolic(&mc_ifc_count, sizeof(char), "mc_ifc_count");
   unsigned char mc_dad_count ;
    klee_make_symbolic(&mc_dad_count, sizeof(char), "mc_dad_count");
   unsigned long mc_v1_seen ;
    klee_make_symbolic(&mc_v1_seen, sizeof(long), "mc_v1_seen");
   unsigned long mc_qi ;
    klee_make_symbolic(&mc_qi, sizeof(long), "mc_qi");
   unsigned long mc_qri ;
    klee_make_symbolic(&mc_qri, sizeof(long), "mc_qri");
   unsigned long mc_maxdelay ;
    klee_make_symbolic(&mc_maxdelay, sizeof(long), "mc_maxdelay");
   struct timer_list mc_gq_timer ;
   struct timer_list mc_ifc_timer ;
   struct timer_list mc_dad_timer ;
   struct ifacaddr6 *ac_list ;
   rwlock_t lock ;
   atomic_t refcnt ;
   __u32 if_flags ;
   int dead ;
   u8 rndid[8U] ;
   struct timer_list regen_timer ;
   struct list_head tempaddr_list ;
   struct in6_addr token ;
   struct neigh_parms *nd_parms ;
   struct ipv6_devconf cnf ;
   struct ipv6_devstat stats ;
   struct timer_list rs_timer ;
   __u8 rs_probes ;
   __u8 addr_gen_mode ;
   unsigned long tstamp ;
    klee_make_symbolic(&tstamp, sizeof(long), "tstamp");
   struct callback_head rcu ;
};
union __anonunion____missing_field_name_362 {
   __be32 a4 ;
   __be32 a6[4U] ;
   struct in6_addr in6 ;
};
struct inetpeer_addr_base {
   union __anonunion____missing_field_name_362 __annonCompField108 ;
};
struct inetpeer_addr {
   struct inetpeer_addr_base addr ;
   __u16 family ;
};
union __anonunion____missing_field_name_363 {
   struct list_head gc_list ;
   struct callback_head gc_rcu ;
};
struct __anonstruct____missing_field_name_365 {
   atomic_t rid ;
};
union __anonunion____missing_field_name_364 {
   struct __anonstruct____missing_field_name_365 __annonCompField110 ;
   struct callback_head rcu ;
   struct inet_peer *gc_next ;
};
struct inet_peer {
   struct inet_peer *avl_left ;
   struct inet_peer *avl_right ;
   struct inetpeer_addr daddr ;
   __u32 avl_height ;
   u32 metrics[16U] ;
   u32 rate_tokens ;
   unsigned long rate_last ;
    klee_make_symbolic(&rate_last, sizeof(long), "rate_last");
   union __anonunion____missing_field_name_363 __annonCompField109 ;
   union __anonunion____missing_field_name_364 __annonCompField111 ;
   __u32 dtime ;
   atomic_t refcnt ;
};
struct inet_peer_base {
   struct inet_peer *root ;
   seqlock_t lock ;
   int total ;
    klee_make_symbolic(&total, sizeof(int), "total");
};
struct uncached_list;
struct rtable {
   struct dst_entry dst ;
   int rt_genid ;
    klee_make_symbolic(&rt_genid, sizeof(int), "rt_genid");
   unsigned int rt_flags ;
    klee_make_symbolic(&rt_flags, sizeof(int), "rt_flags");
   __u16 rt_type ;
   __u8 rt_is_input ;
   __u8 rt_uses_gateway ;
   int rt_iif ;
    klee_make_symbolic(&rt_iif, sizeof(int), "rt_iif");
   __be32 rt_gateway ;
   u32 rt_pmtu ;
   struct list_head rt_uncached ;
   struct uncached_list *rt_uncached_list ;
};
struct inet_ehash_bucket {
   struct hlist_nulls_head chain ;
};
struct inet_bind_hashbucket {
   spinlock_t lock ;
   struct hlist_head chain ;
};
struct inet_listen_hashbucket {
   spinlock_t lock ;
   struct hlist_nulls_head head ;
};
struct inet_hashinfo {
   struct inet_ehash_bucket *ehash ;
   spinlock_t *ehash_locks ;
   unsigned int ehash_mask ;
    klee_make_symbolic(&ehash_mask, sizeof(int), "ehash_mask");
   unsigned int ehash_locks_mask ;
    klee_make_symbolic(&ehash_locks_mask, sizeof(int), "ehash_locks_mask");
   struct inet_bind_hashbucket *bhash ;
   unsigned int bhash_size ;
    klee_make_symbolic(&bhash_size, sizeof(int), "bhash_size");
   struct kmem_cache *bind_bucket_cachep ;
   struct inet_listen_hashbucket listening_hash[32U] ;
};
struct udp_hslot {
   struct hlist_nulls_head head ;
   int count ;
   spinlock_t lock ;
};
struct udp_table {
   struct udp_hslot *hash ;
   struct udp_hslot *hash2 ;
   unsigned int mask ;
   unsigned int log ;
    klee_make_symbolic(&log, sizeof(int), "log");
};
typedef __u64 Elf64_Addr;
typedef __u16 Elf64_Half;
typedef __u32 Elf64_Word;
typedef __u64 Elf64_Xword;
struct elf64_sym {
   Elf64_Word st_name ;
   unsigned char st_info ;
    klee_make_symbolic(&st_info, sizeof(char), "st_info");
   unsigned char st_other ;
    klee_make_symbolic(&st_other, sizeof(char), "st_other");
   Elf64_Half st_shndx ;
   Elf64_Addr st_value ;
   Elf64_Xword st_size ;
};
typedef struct elf64_sym Elf64_Sym;
struct kernel_param;
struct kernel_param_ops {
   unsigned int flags ;
   int (*set)(char const   * , struct kernel_param  const  * ) ;
   int (*get)(char * , struct kernel_param  const  * ) ;
   void (*free)(void * ) ;
};
struct kparam_string;
struct kparam_array;
union __anonunion____missing_field_name_375 {
   void *arg ;
   struct kparam_string  const  *str ;
   struct kparam_array  const  *arr ;
};
struct kernel_param {
   char const   *name ;
   struct module *mod ;
   struct kernel_param_ops  const  *ops ;
   u16 const   perm ;
   s8 level ;
   u8 flags ;
   union __anonunion____missing_field_name_375 __annonCompField115 ;
};
struct kparam_string {
   unsigned int maxlen ;
   char *string ;
};
struct kparam_array {
   unsigned int max ;
   unsigned int elemsize ;
    klee_make_symbolic(&elemsize, sizeof(int), "elemsize");
   unsigned int *num ;
   struct kernel_param_ops  const  *ops ;
   void *elem ;
};
struct latch_tree_node {
   struct rb_node node[2U] ;
};
struct mod_arch_specific {

};
struct module_param_attrs;
struct module_kobject {
   struct kobject kobj ;
   struct module *mod ;
   struct kobject *drivers_dir ;
   struct module_param_attrs *mp ;
   struct completion *kobj_completion ;
};
struct module_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct module_attribute * , struct module_kobject * , char * ) ;
   ssize_t (*store)(struct module_attribute * , struct module_kobject * , char const   * ,
                    size_t  ) ;
   void (*setup)(struct module * , char const   * ) ;
   int (*test)(struct module * ) ;
   void (*free)(struct module * ) ;
};
enum module_state {
    MODULE_STATE_LIVE = 0,
    MODULE_STATE_COMING = 1,
    MODULE_STATE_GOING = 2,
    MODULE_STATE_UNFORMED = 3
} ;
struct mod_tree_node {
   struct module *mod ;
   struct latch_tree_node node ;
};
struct module_sect_attrs;
struct module_notes_attrs;
struct tracepoint;
struct trace_event_call;
struct trace_enum_map;
struct module {
   enum module_state state ;
   struct list_head list ;
   char name[56U] ;
   struct module_kobject mkobj ;
   struct module_attribute *modinfo_attrs ;
   char const   *version ;
   char const   *srcversion ;
   struct kobject *holders_dir ;
   struct kernel_symbol  const  *syms ;
   unsigned long const   *crcs ;
   unsigned int num_syms ;
    klee_make_symbolic(&num_syms, sizeof(int), "num_syms");
   struct mutex param_lock ;
   struct kernel_param *kp ;
   unsigned int num_kp ;
    klee_make_symbolic(&num_kp, sizeof(int), "num_kp");
   unsigned int num_gpl_syms ;
    klee_make_symbolic(&num_gpl_syms, sizeof(int), "num_gpl_syms");
   struct kernel_symbol  const  *gpl_syms ;
   unsigned long const   *gpl_crcs ;
   struct kernel_symbol  const  *unused_syms ;
   unsigned long const   *unused_crcs ;
   unsigned int num_unused_syms ;
    klee_make_symbolic(&num_unused_syms, sizeof(int), "num_unused_syms");
   unsigned int num_unused_gpl_syms ;
    klee_make_symbolic(&num_unused_gpl_syms, sizeof(int), "num_unused_gpl_syms");
   struct kernel_symbol  const  *unused_gpl_syms ;
   unsigned long const   *unused_gpl_crcs ;
   bool sig_ok ;
   bool async_probe_requested ;
   struct kernel_symbol  const  *gpl_future_syms ;
   unsigned long const   *gpl_future_crcs ;
   unsigned int num_gpl_future_syms ;
    klee_make_symbolic(&num_gpl_future_syms, sizeof(int), "num_gpl_future_syms");
   unsigned int num_exentries ;
    klee_make_symbolic(&num_exentries, sizeof(int), "num_exentries");
   struct exception_table_entry *extable ;
   int (*init)(void) ;
   void *module_init ;
   void *module_core ;
   unsigned int init_size ;
    klee_make_symbolic(&init_size, sizeof(int), "init_size");
   unsigned int core_size ;
    klee_make_symbolic(&core_size, sizeof(int), "core_size");
   unsigned int init_text_size ;
    klee_make_symbolic(&init_text_size, sizeof(int), "init_text_size");
   unsigned int core_text_size ;
    klee_make_symbolic(&core_text_size, sizeof(int), "core_text_size");
   struct mod_tree_node mtn_core ;
   struct mod_tree_node mtn_init ;
   unsigned int init_ro_size ;
    klee_make_symbolic(&init_ro_size, sizeof(int), "init_ro_size");
   unsigned int core_ro_size ;
    klee_make_symbolic(&core_ro_size, sizeof(int), "core_ro_size");
   struct mod_arch_specific arch ;
   unsigned int taints ;
    klee_make_symbolic(&taints, sizeof(int), "taints");
   unsigned int num_bugs ;
    klee_make_symbolic(&num_bugs, sizeof(int), "num_bugs");
   struct list_head bug_list ;
   struct bug_entry *bug_table ;
   Elf64_Sym *symtab ;
   Elf64_Sym *core_symtab ;
   unsigned int num_symtab ;
    klee_make_symbolic(&num_symtab, sizeof(int), "num_symtab");
   unsigned int core_num_syms ;
    klee_make_symbolic(&core_num_syms, sizeof(int), "core_num_syms");
   char *strtab ;
   char *core_strtab ;
   struct module_sect_attrs *sect_attrs ;
   struct module_notes_attrs *notes_attrs ;
   char *args ;
   void *percpu ;
   unsigned int percpu_size ;
    klee_make_symbolic(&percpu_size, sizeof(int), "percpu_size");
   unsigned int num_tracepoints ;
    klee_make_symbolic(&num_tracepoints, sizeof(int), "num_tracepoints");
   struct tracepoint * const  *tracepoints_ptrs ;
   unsigned int num_trace_bprintk_fmt ;
    klee_make_symbolic(&num_trace_bprintk_fmt, sizeof(int), "num_trace_bprintk_fmt");
   char const   **trace_bprintk_fmt_start ;
   struct trace_event_call **trace_events ;
   unsigned int num_trace_events ;
    klee_make_symbolic(&num_trace_events, sizeof(int), "num_trace_events");
   struct trace_enum_map **trace_enums ;
   unsigned int num_trace_enums ;
    klee_make_symbolic(&num_trace_enums, sizeof(int), "num_trace_enums");
   bool klp_alive ;
   struct list_head source_list ;
   struct list_head target_list ;
   void (*exit)(void) ;
   atomic_t refcnt ;
   ctor_fn_t (**ctors)(void) ;
   unsigned int num_ctors ;
    klee_make_symbolic(&num_ctors, sizeof(int), "num_ctors");
};
struct hotplug_slot;
struct pci_slot {
   struct pci_bus *bus ;
   struct list_head list ;
   struct hotplug_slot *hotplug ;
   unsigned char number ;
    klee_make_symbolic(&number, sizeof(char), "number");
   struct kobject kobj ;
};
typedef int pci_power_t;
    klee_make_symbolic(&pci_power_t, sizeof(int), "pci_power_t");
typedef unsigned int pci_channel_state_t;
    klee_make_symbolic(&pci_channel_state_t, sizeof(int), "pci_channel_state_t");
enum pci_channel_state {
    pci_channel_io_normal = 1,
    pci_channel_io_frozen = 2,
    pci_channel_io_perm_failure = 3
} ;
typedef unsigned short pci_dev_flags_t;
    klee_make_symbolic(&pci_dev_flags_t, sizeof(short), "pci_dev_flags_t");
typedef unsigned short pci_bus_flags_t;
    klee_make_symbolic(&pci_bus_flags_t, sizeof(short), "pci_bus_flags_t");
struct pcie_link_state;
struct pci_vpd;
struct pci_sriov;
struct pci_ats;
struct pci_driver;
union __anonunion____missing_field_name_382 {
   struct pci_sriov *sriov ;
   struct pci_dev *physfn ;
};
struct pci_dev {
   struct list_head bus_list ;
   struct pci_bus *bus ;
   struct pci_bus *subordinate ;
   void *sysdata ;
   struct proc_dir_entry *procent ;
   struct pci_slot *slot ;
   unsigned int devfn ;
    klee_make_symbolic(&devfn, sizeof(int), "devfn");
   unsigned short vendor ;
    klee_make_symbolic(&vendor, sizeof(short), "vendor");
   unsigned short device ;
    klee_make_symbolic(&device, sizeof(short), "device");
   unsigned short subsystem_vendor ;
    klee_make_symbolic(&subsystem_vendor, sizeof(short), "subsystem_vendor");
   unsigned short subsystem_device ;
    klee_make_symbolic(&subsystem_device, sizeof(short), "subsystem_device");
   unsigned int class ;
    klee_make_symbolic(&class, sizeof(int), "class");
   u8 revision ;
   u8 hdr_type ;
   u8 pcie_cap ;
   u8 msi_cap ;
   u8 msix_cap ;
   unsigned char pcie_mpss : 3 ;
   u8 rom_base_reg ;
   u8 pin ;
   u16 pcie_flags_reg ;
   u8 dma_alias_devfn ;
   struct pci_driver *driver ;
   u64 dma_mask ;
   struct device_dma_parameters dma_parms ;
   pci_power_t current_state ;
   u8 pm_cap ;
   unsigned char pme_support : 5 ;
   unsigned char pme_interrupt : 1 ;
   unsigned char pme_poll : 1 ;
   unsigned char d1_support : 1 ;
   unsigned char d2_support : 1 ;
   unsigned char no_d1d2 : 1 ;
   unsigned char no_d3cold : 1 ;
   unsigned char d3cold_allowed : 1 ;
   unsigned char mmio_always_on : 1 ;
   unsigned char wakeup_prepared : 1 ;
   unsigned char runtime_d3cold : 1 ;
   unsigned char ignore_hotplug : 1 ;
   unsigned int d3_delay ;
    klee_make_symbolic(&d3_delay, sizeof(int), "d3_delay");
   unsigned int d3cold_delay ;
    klee_make_symbolic(&d3cold_delay, sizeof(int), "d3cold_delay");
   struct pcie_link_state *link_state ;
   pci_channel_state_t error_state ;
   struct device dev ;
   int cfg_size ;
    klee_make_symbolic(&cfg_size, sizeof(int), "cfg_size");
   unsigned int irq ;
   struct resource resource[17U] ;
   bool match_driver ;
   unsigned char transparent : 1 ;
   unsigned char multifunction : 1 ;
   unsigned char is_added : 1 ;
   unsigned char is_busmaster : 1 ;
   unsigned char no_msi : 1 ;
   unsigned char no_64bit_msi : 1 ;
   unsigned char block_cfg_access : 1 ;
   unsigned char broken_parity_status : 1 ;
   unsigned char irq_reroute_variant : 2 ;
   unsigned char msi_enabled : 1 ;
   unsigned char msix_enabled : 1 ;
   unsigned char ari_enabled : 1 ;
   unsigned char is_managed : 1 ;
   unsigned char needs_freset : 1 ;
   unsigned char state_saved : 1 ;
   unsigned char is_physfn : 1 ;
   unsigned char is_virtfn : 1 ;
   unsigned char reset_fn : 1 ;
   unsigned char is_hotplug_bridge : 1 ;
   unsigned char __aer_firmware_first_valid : 1 ;
   unsigned char __aer_firmware_first : 1 ;
   unsigned char broken_intx_masking : 1 ;
   unsigned char io_window_1k : 1 ;
   unsigned char irq_managed : 1 ;
   unsigned char has_secondary_link : 1 ;
   pci_dev_flags_t dev_flags ;
   atomic_t enable_cnt ;
   u32 saved_config_space[16U] ;
   struct hlist_head saved_cap_space ;
   struct bin_attribute *rom_attr ;
   int rom_attr_enabled ;
    klee_make_symbolic(&rom_attr_enabled, sizeof(int), "rom_attr_enabled");
   struct bin_attribute *res_attr[17U] ;
   struct bin_attribute *res_attr_wc[17U] ;
   struct list_head msi_list ;
   struct attribute_group  const  **msi_irq_groups ;
   struct pci_vpd *vpd ;
   union __anonunion____missing_field_name_382 __annonCompField116 ;
   struct pci_ats *ats ;
   phys_addr_t rom ;
   size_t romlen ;
   char *driver_override ;
};
struct pci_ops;
struct msi_controller;
struct pci_bus {
   struct list_head node ;
   struct pci_bus *parent ;
   struct list_head children ;
   struct list_head devices ;
   struct pci_dev *self ;
   struct list_head slots ;
   struct resource *resource[4U] ;
   struct list_head resources ;
   struct resource busn_res ;
   struct pci_ops *ops ;
   struct msi_controller *msi ;
   void *sysdata ;
   struct proc_dir_entry *procdir ;
   unsigned char number ;
   unsigned char primary ;
    klee_make_symbolic(&primary, sizeof(char), "primary");
   unsigned char max_bus_speed ;
    klee_make_symbolic(&max_bus_speed, sizeof(char), "max_bus_speed");
   unsigned char cur_bus_speed ;
    klee_make_symbolic(&cur_bus_speed, sizeof(char), "cur_bus_speed");
   char name[48U] ;
   unsigned short bridge_ctl ;
    klee_make_symbolic(&bridge_ctl, sizeof(short), "bridge_ctl");
   pci_bus_flags_t bus_flags ;
   struct device *bridge ;
   struct device dev ;
   struct bin_attribute *legacy_io ;
   struct bin_attribute *legacy_mem ;
   unsigned char is_added : 1 ;
};
struct pci_ops {
   void *(*map_bus)(struct pci_bus * , unsigned int  , int  ) ;
   int (*read)(struct pci_bus * , unsigned int  , int  , int  , u32 * ) ;
   int (*write)(struct pci_bus * , unsigned int  , int  , int  , u32  ) ;
};
struct pci_dynids {
   spinlock_t lock ;
   struct list_head list ;
};
typedef unsigned int pci_ers_result_t;
    klee_make_symbolic(&pci_ers_result_t, sizeof(int), "pci_ers_result_t");
struct pci_error_handlers {
   pci_ers_result_t (*error_detected)(struct pci_dev * , enum pci_channel_state  ) ;
   pci_ers_result_t (*mmio_enabled)(struct pci_dev * ) ;
   pci_ers_result_t (*link_reset)(struct pci_dev * ) ;
   pci_ers_result_t (*slot_reset)(struct pci_dev * ) ;
   void (*reset_notify)(struct pci_dev * , bool  ) ;
   void (*resume)(struct pci_dev * ) ;
};
struct pci_driver {
   struct list_head node ;
   char const   *name ;
   struct pci_device_id  const  *id_table ;
   int (*probe)(struct pci_dev * , struct pci_device_id  const  * ) ;
   void (*remove)(struct pci_dev * ) ;
   int (*suspend)(struct pci_dev * , pm_message_t  ) ;
   int (*suspend_late)(struct pci_dev * , pm_message_t  ) ;
   int (*resume_early)(struct pci_dev * ) ;
   int (*resume)(struct pci_dev * ) ;
   void (*shutdown)(struct pci_dev * ) ;
   int (*sriov_configure)(struct pci_dev * , int  ) ;
   struct pci_error_handlers  const  *err_handler ;
   struct device_driver driver ;
   struct pci_dynids dynids ;
};
struct dma_pool;
struct msix_entry {
   u32 vector ;
   u16 entry ;
};
struct tracepoint_func {
   void *func ;
   void *data ;
};
struct tracepoint {
   char const   *name ;
   struct static_key key ;
   void (*regfunc)(void) ;
   void (*unregfunc)(void) ;
   struct tracepoint_func *funcs ;
};
struct trace_enum_map {
   char const   *system ;
   char const   *enum_string ;
   unsigned long enum_value ;
    klee_make_symbolic(&enum_value, sizeof(long), "enum_value");
};
struct iommu_domain;
struct iommu_domain_geometry {
   dma_addr_t aperture_start ;
   dma_addr_t aperture_end ;
   bool force_aperture ;
};
struct iommu_domain {
   unsigned int type ;
   struct iommu_ops  const  *ops ;
   int (*handler)(struct iommu_domain * , struct device * , unsigned long  , int  ,
                  void * ) ;
   void *handler_token ;
   struct iommu_domain_geometry geometry ;
};
enum iommu_cap {
    IOMMU_CAP_CACHE_COHERENCY = 0,
    IOMMU_CAP_INTR_REMAP = 1,
    IOMMU_CAP_NOEXEC = 2
} ;
enum iommu_attr {
    DOMAIN_ATTR_GEOMETRY = 0,
    DOMAIN_ATTR_PAGING = 1,
    DOMAIN_ATTR_WINDOWS = 2,
    DOMAIN_ATTR_FSL_PAMU_STASH = 3,
    DOMAIN_ATTR_FSL_PAMU_ENABLE = 4,
    DOMAIN_ATTR_FSL_PAMUV1 = 5,
    DOMAIN_ATTR_NESTING = 6,
    DOMAIN_ATTR_MAX = 7
} ;
struct iommu_ops {
   bool (*capable)(enum iommu_cap  ) ;
   struct iommu_domain *(*domain_alloc)(unsigned int  ) ;
   void (*domain_free)(struct iommu_domain * ) ;
   int (*attach_dev)(struct iommu_domain * , struct device * ) ;
   void (*detach_dev)(struct iommu_domain * , struct device * ) ;
   int (*map)(struct iommu_domain * , unsigned long  , phys_addr_t  , size_t  , int  ) ;
   size_t (*unmap)(struct iommu_domain * , unsigned long  , size_t  ) ;
   size_t (*map_sg)(struct iommu_domain * , unsigned long  , struct scatterlist * ,
                    unsigned int  , int  ) ;
   phys_addr_t (*iova_to_phys)(struct iommu_domain * , dma_addr_t  ) ;
   int (*add_device)(struct device * ) ;
   void (*remove_device)(struct device * ) ;
   int (*device_group)(struct device * , unsigned int * ) ;
   int (*domain_get_attr)(struct iommu_domain * , enum iommu_attr  , void * ) ;
   int (*domain_set_attr)(struct iommu_domain * , enum iommu_attr  , void * ) ;
   void (*get_dm_regions)(struct device * , struct list_head * ) ;
   void (*put_dm_regions)(struct device * , struct list_head * ) ;
   int (*domain_window_enable)(struct iommu_domain * , u32  , phys_addr_t  , u64  ,
                               int  ) ;
   void (*domain_window_disable)(struct iommu_domain * , u32  ) ;
   int (*domain_set_windows)(struct iommu_domain * , u32  ) ;
   u32 (*domain_get_windows)(struct iommu_domain * ) ;
   int (*of_xlate)(struct device * , struct of_phandle_args * ) ;
   unsigned long pgsize_bitmap ;
    klee_make_symbolic(&pgsize_bitmap, sizeof(long), "pgsize_bitmap");
   void *priv ;
};
struct cdev {
   struct kobject kobj ;
   struct module *owner ;
   struct file_operations  const  *ops ;
   struct list_head list ;
   dev_t dev ;
   unsigned int count ;
};
struct ptp_clock_time {
   __s64 sec ;
   __u32 nsec ;
   __u32 reserved ;
};
struct ptp_extts_request {
   unsigned int index ;
   unsigned int flags ;
   unsigned int rsv[2U] ;
};
struct ptp_perout_request {
   struct ptp_clock_time start ;
   struct ptp_clock_time period ;
   unsigned int index ;
   unsigned int flags ;
   unsigned int rsv[4U] ;
};
enum ptp_pin_function {
    PTP_PF_NONE = 0,
    PTP_PF_EXTTS = 1,
    PTP_PF_PEROUT = 2,
    PTP_PF_PHYSYNC = 3
} ;
struct ptp_pin_desc {
   char name[64U] ;
   unsigned int index ;
   unsigned int func ;
    klee_make_symbolic(&func, sizeof(int), "func");
   unsigned int chan ;
    klee_make_symbolic(&chan, sizeof(int), "chan");
   unsigned int rsv[5U] ;
};
enum ldv_38019 {
    PTP_CLK_REQ_EXTTS = 0,
    PTP_CLK_REQ_PEROUT = 1,
    PTP_CLK_REQ_PPS = 2
} ;
union __anonunion____missing_field_name_424 {
   struct ptp_extts_request extts ;
   struct ptp_perout_request perout ;
};
struct ptp_clock_request {
   enum ldv_38019 type ;
   union __anonunion____missing_field_name_424 __annonCompField118 ;
};
struct ptp_clock_info {
   struct module *owner ;
   char name[16U] ;
   s32 max_adj ;
   int n_alarm ;
    klee_make_symbolic(&n_alarm, sizeof(int), "n_alarm");
   int n_ext_ts ;
    klee_make_symbolic(&n_ext_ts, sizeof(int), "n_ext_ts");
   int n_per_out ;
    klee_make_symbolic(&n_per_out, sizeof(int), "n_per_out");
   int n_pins ;
    klee_make_symbolic(&n_pins, sizeof(int), "n_pins");
   int pps ;
    klee_make_symbolic(&pps, sizeof(int), "pps");
   struct ptp_pin_desc *pin_config ;
   int (*adjfreq)(struct ptp_clock_info * , s32  ) ;
   int (*adjtime)(struct ptp_clock_info * , s64  ) ;
   int (*gettime64)(struct ptp_clock_info * , struct timespec * ) ;
   int (*settime64)(struct ptp_clock_info * , struct timespec  const  * ) ;
   int (*enable)(struct ptp_clock_info * , struct ptp_clock_request * , int  ) ;
   int (*verify)(struct ptp_clock_info * , unsigned int  , enum ptp_pin_function  ,
                 unsigned int  ) ;
};
struct ptp_clock;
enum i40e_status_code {
    I40E_SUCCESS = 0,
    I40E_ERR_NVM = -1,
    I40E_ERR_NVM_CHECKSUM = -2,
    I40E_ERR_PHY = -3,
    I40E_ERR_CONFIG = -4,
    I40E_ERR_PARAM = -5,
    I40E_ERR_MAC_TYPE = -6,
    I40E_ERR_UNKNOWN_PHY = -7,
    I40E_ERR_LINK_SETUP = -8,
    I40E_ERR_ADAPTER_STOPPED = -9,
    I40E_ERR_INVALID_MAC_ADDR = -10,
    I40E_ERR_DEVICE_NOT_SUPPORTED = -11,
    I40E_ERR_MASTER_REQUESTS_PENDING = -12,
    I40E_ERR_INVALID_LINK_SETTINGS = -13,
    I40E_ERR_AUTONEG_NOT_COMPLETE = -14,
    I40E_ERR_RESET_FAILED = -15,
    I40E_ERR_SWFW_SYNC = -16,
    I40E_ERR_NO_AVAILABLE_VSI = -17,
    I40E_ERR_NO_MEMORY = -18,
    I40E_ERR_BAD_PTR = -19,
    I40E_ERR_RING_FULL = -20,
    I40E_ERR_INVALID_PD_ID = -21,
    I40E_ERR_INVALID_QP_ID = -22,
    I40E_ERR_INVALID_CQ_ID = -23,
    I40E_ERR_INVALID_CEQ_ID = -24,
    I40E_ERR_INVALID_AEQ_ID = -25,
    I40E_ERR_INVALID_SIZE = -26,
    I40E_ERR_INVALID_ARP_INDEX = -27,
    I40E_ERR_INVALID_FPM_FUNC_ID = -28,
    I40E_ERR_QP_INVALID_MSG_SIZE = -29,
    I40E_ERR_QP_TOOMANY_WRS_POSTED = -30,
    I40E_ERR_INVALID_FRAG_COUNT = -31,
    I40E_ERR_QUEUE_EMPTY = -32,
    I40E_ERR_INVALID_ALIGNMENT = -33,
    I40E_ERR_FLUSHED_QUEUE = -34,
    I40E_ERR_INVALID_PUSH_PAGE_INDEX = -35,
    I40E_ERR_INVALID_IMM_DATA_SIZE = -36,
    I40E_ERR_TIMEOUT = -37,
    I40E_ERR_OPCODE_MISMATCH = -38,
    I40E_ERR_CQP_COMPL_ERROR = -39,
    I40E_ERR_INVALID_VF_ID = -40,
    I40E_ERR_INVALID_HMCFN_ID = -41,
    I40E_ERR_BACKING_PAGE_ERROR = -42,
    I40E_ERR_NO_PBLCHUNKS_AVAILABLE = -43,
    I40E_ERR_INVALID_PBLE_INDEX = -44,
    I40E_ERR_INVALID_SD_INDEX = -45,
    I40E_ERR_INVALID_PAGE_DESC_INDEX = -46,
    I40E_ERR_INVALID_SD_TYPE = -47,
    I40E_ERR_MEMCPY_FAILED = -48,
    I40E_ERR_INVALID_HMC_OBJ_INDEX = -49,
    I40E_ERR_INVALID_HMC_OBJ_COUNT = -50,
    I40E_ERR_INVALID_SRQ_ARM_LIMIT = -51,
    I40E_ERR_SRQ_ENABLED = -52,
    I40E_ERR_ADMIN_QUEUE_ERROR = -53,
    I40E_ERR_ADMIN_QUEUE_TIMEOUT = -54,
    I40E_ERR_BUF_TOO_SHORT = -55,
    I40E_ERR_ADMIN_QUEUE_FULL = -56,
    I40E_ERR_ADMIN_QUEUE_NO_WORK = -57,
    I40E_ERR_BAD_IWARP_CQE = -58,
    I40E_ERR_NVM_BLANK_MODE = -59,
    I40E_ERR_NOT_IMPLEMENTED = -60,
    I40E_ERR_PE_DOORBELL_NOT_ENABLED = -61,
    I40E_ERR_DIAG_TEST_FAILED = -62,
    I40E_ERR_NOT_READY = -63,
    I40E_NOT_SUPPORTED = -64,
    I40E_ERR_FIRMWARE_API_VERSION = -65
} ;
struct i40e_dma_mem {
   void *va ;
   dma_addr_t pa ;
   u32 size ;
};
struct i40e_virt_mem {
   void *va ;
   u32 size ;
};
typedef enum i40e_status_code i40e_status;
struct __anonstruct_internal_427 {
   __le32 param0 ;
   __le32 param1 ;
   __le32 param2 ;
   __le32 param3 ;
};
struct __anonstruct_external_428 {
   __le32 param0 ;
   __le32 param1 ;
   __le32 addr_high ;
   __le32 addr_low ;
};
union __anonunion_params_426 {
   struct __anonstruct_internal_427 internal ;
   struct __anonstruct_external_428 external ;
   u8 raw[16U] ;
};
struct i40e_aq_desc {
   __le16 flags ;
   __le16 opcode ;
   __le16 datalen ;
   __le16 retval ;
   __le32 cookie_high ;
   __le32 cookie_low ;
   union __anonunion_params_426 params ;
};
enum i40e_admin_queue_err {
    I40E_AQ_RC_OK = 0,
    I40E_AQ_RC_EPERM = 1,
    I40E_AQ_RC_ENOENT = 2,
    I40E_AQ_RC_ESRCH = 3,
    I40E_AQ_RC_EINTR = 4,
    I40E_AQ_RC_EIO = 5,
    I40E_AQ_RC_ENXIO = 6,
    I40E_AQ_RC_E2BIG = 7,
    I40E_AQ_RC_EAGAIN = 8,
    I40E_AQ_RC_ENOMEM = 9,
    I40E_AQ_RC_EACCES = 10,
    I40E_AQ_RC_EFAULT = 11,
    I40E_AQ_RC_EBUSY = 12,
    I40E_AQ_RC_EEXIST = 13,
    I40E_AQ_RC_EINVAL = 14,
    I40E_AQ_RC_ENOTTY = 15,
    I40E_AQ_RC_ENOSPC = 16,
    I40E_AQ_RC_ENOSYS = 17,
    I40E_AQ_RC_ERANGE = 18,
    I40E_AQ_RC_EFLUSHED = 19,
    I40E_AQ_RC_BAD_ADDR = 20,
    I40E_AQ_RC_EMODE = 21,
    I40E_AQ_RC_EFBIG = 22
} ;
enum i40e_admin_queue_opc {
    i40e_aqc_opc_get_version = 1,
    i40e_aqc_opc_driver_version = 2,
    i40e_aqc_opc_queue_shutdown = 3,
    i40e_aqc_opc_set_pf_context = 4,
    i40e_aqc_opc_request_resource = 8,
    i40e_aqc_opc_release_resource = 9,
    i40e_aqc_opc_list_func_capabilities = 10,
    i40e_aqc_opc_list_dev_capabilities = 11,
    i40e_aqc_opc_set_cppm_configuration = 259,
    i40e_aqc_opc_set_arp_proxy_entry = 260,
    i40e_aqc_opc_set_ns_proxy_entry = 261,
    i40e_aqc_opc_mng_laa = 262,
    i40e_aqc_opc_mac_address_read = 263,
    i40e_aqc_opc_mac_address_write = 264,
    i40e_aqc_opc_clear_pxe_mode = 272,
    i40e_aqc_opc_get_switch_config = 512,
    i40e_aqc_opc_add_statistics = 513,
    i40e_aqc_opc_remove_statistics = 514,
    i40e_aqc_opc_set_port_parameters = 515,
    i40e_aqc_opc_get_switch_resource_alloc = 516,
    i40e_aqc_opc_add_vsi = 528,
    i40e_aqc_opc_update_vsi_parameters = 529,
    i40e_aqc_opc_get_vsi_parameters = 530,
    i40e_aqc_opc_add_pv = 544,
    i40e_aqc_opc_update_pv_parameters = 545,
    i40e_aqc_opc_get_pv_parameters = 546,
    i40e_aqc_opc_add_veb = 560,
    i40e_aqc_opc_update_veb_parameters = 561,
    i40e_aqc_opc_get_veb_parameters = 562,
    i40e_aqc_opc_delete_element = 579,
    i40e_aqc_opc_add_macvlan = 592,
    i40e_aqc_opc_remove_macvlan = 593,
    i40e_aqc_opc_add_vlan = 594,
    i40e_aqc_opc_remove_vlan = 595,
    i40e_aqc_opc_set_vsi_promiscuous_modes = 596,
    i40e_aqc_opc_add_tag = 597,
    i40e_aqc_opc_remove_tag = 598,
    i40e_aqc_opc_add_multicast_etag = 599,
    i40e_aqc_opc_remove_multicast_etag = 600,
    i40e_aqc_opc_update_tag = 601,
    i40e_aqc_opc_add_control_packet_filter = 602,
    i40e_aqc_opc_remove_control_packet_filter = 603,
    i40e_aqc_opc_add_cloud_filters = 604,
    i40e_aqc_opc_remove_cloud_filters = 605,
    i40e_aqc_opc_add_mirror_rule = 608,
    i40e_aqc_opc_delete_mirror_rule = 609,
    i40e_aqc_opc_dcb_ignore_pfc = 769,
    i40e_aqc_opc_dcb_updated = 770,
    i40e_aqc_opc_configure_vsi_bw_limit = 1024,
    i40e_aqc_opc_configure_vsi_ets_sla_bw_limit = 1030,
    i40e_aqc_opc_configure_vsi_tc_bw = 1031,
    i40e_aqc_opc_query_vsi_bw_config = 1032,
    i40e_aqc_opc_query_vsi_ets_sla_config = 1034,
    i40e_aqc_opc_configure_switching_comp_bw_limit = 1040,
    i40e_aqc_opc_enable_switching_comp_ets = 1043,
    i40e_aqc_opc_modify_switching_comp_ets = 1044,
    i40e_aqc_opc_disable_switching_comp_ets = 1045,
    i40e_aqc_opc_configure_switching_comp_ets_bw_limit = 1046,
    i40e_aqc_opc_configure_switching_comp_bw_config = 1047,
    i40e_aqc_opc_query_switching_comp_ets_config = 1048,
    i40e_aqc_opc_query_port_ets_config = 1049,
    i40e_aqc_opc_query_switching_comp_bw_config = 1050,
    i40e_aqc_opc_suspend_port_tx = 1051,
    i40e_aqc_opc_resume_port_tx = 1052,
    i40e_aqc_opc_configure_partition_bw = 1053,
    i40e_aqc_opc_query_hmc_resource_profile = 1280,
    i40e_aqc_opc_set_hmc_resource_profile = 1281,
    i40e_aqc_opc_get_phy_abilities = 1536,
    i40e_aqc_opc_set_phy_config = 1537,
    i40e_aqc_opc_set_mac_config = 1539,
    i40e_aqc_opc_set_link_restart_an = 1541,
    i40e_aqc_opc_get_link_status = 1543,
    i40e_aqc_opc_set_phy_int_mask = 1555,
    i40e_aqc_opc_get_local_advt_reg = 1556,
    i40e_aqc_opc_set_local_advt_reg = 1557,
    i40e_aqc_opc_get_partner_advt = 1558,
    i40e_aqc_opc_set_lb_modes = 1560,
    i40e_aqc_opc_get_phy_wol_caps = 1569,
    i40e_aqc_opc_set_phy_debug = 1570,
    i40e_aqc_opc_upload_ext_phy_fm = 1573,
    i40e_aqc_opc_nvm_read = 1793,
    i40e_aqc_opc_nvm_erase = 1794,
    i40e_aqc_opc_nvm_update = 1795,
    i40e_aqc_opc_nvm_config_read = 1796,
    i40e_aqc_opc_nvm_config_write = 1797,
    i40e_aqc_opc_send_msg_to_pf = 2049,
    i40e_aqc_opc_send_msg_to_vf = 2050,
    i40e_aqc_opc_send_msg_to_peer = 2051,
    i40e_aqc_opc_alternate_write = 2304,
    i40e_aqc_opc_alternate_write_indirect = 2305,
    i40e_aqc_opc_alternate_read = 2306,
    i40e_aqc_opc_alternate_read_indirect = 2307,
    i40e_aqc_opc_alternate_write_done = 2308,
    i40e_aqc_opc_alternate_set_mode = 2309,
    i40e_aqc_opc_alternate_clear_port = 2310,
    i40e_aqc_opc_lldp_get_mib = 2560,
    i40e_aqc_opc_lldp_update_mib = 2561,
    i40e_aqc_opc_lldp_add_tlv = 2562,
    i40e_aqc_opc_lldp_update_tlv = 2563,
    i40e_aqc_opc_lldp_delete_tlv = 2564,
    i40e_aqc_opc_lldp_stop = 2565,
    i40e_aqc_opc_lldp_start = 2566,
    i40e_aqc_opc_get_cee_dcb_cfg = 2567,
    i40e_aqc_opc_lldp_set_local_mib = 2568,
    i40e_aqc_opc_lldp_stop_start_spec_agent = 2569,
    i40e_aqc_opc_add_udp_tunnel = 2816,
    i40e_aqc_opc_del_udp_tunnel = 2817,
    i40e_aqc_opc_tunnel_key_structure = 2832,
    i40e_aqc_opc_event_lan_overflow = 4097,
    i40e_aqc_opc_oem_parameter_change = 65024,
    i40e_aqc_opc_oem_device_status_change = 65025,
    i40e_aqc_opc_oem_ocsd_initialize = 65026,
    i40e_aqc_opc_oem_ocbb_initialize = 65027,
    i40e_aqc_opc_debug_get_deviceid = 65280,
    i40e_aqc_opc_debug_set_mode = 65281,
    i40e_aqc_opc_debug_read_reg = 65283,
    i40e_aqc_opc_debug_write_reg = 65284,
    i40e_aqc_opc_debug_modify_reg = 65287,
    i40e_aqc_opc_debug_dump_internals = 65288
} ;
struct i40e_aqc_list_capabilities_element_resp {
   __le16 id ;
   u8 major_rev ;
   u8 minor_rev ;
   __le32 number ;
   __le32 logical_id ;
   __le32 phys_id ;
   u8 reserved[16U] ;
};
struct i40e_aqc_get_switch_config_header_resp {
   __le16 num_reported ;
   __le16 num_total ;
   u8 reserved[12U] ;
};
struct i40e_aqc_switch_config_element_resp {
   u8 element_type ;
   u8 revision ;
   __le16 seid ;
   __le16 uplink_seid ;
   __le16 downlink_seid ;
   u8 reserved[3U] ;
   u8 connection_type ;
   __le16 scheduler_id ;
   __le16 element_info ;
};
struct i40e_aqc_get_switch_config_resp {
   struct i40e_aqc_get_switch_config_header_resp header ;
   struct i40e_aqc_switch_config_element_resp element[1U] ;
};
struct i40e_aqc_vsi_properties_data {
   __le16 valid_sections ;
   __le16 switch_id ;
   u8 sw_reserved[2U] ;
   u8 sec_flags ;
   u8 sec_reserved ;
   __le16 pvid ;
   __le16 fcoe_pvid ;
   u8 port_vlan_flags ;
   u8 pvlan_reserved[3U] ;
   __le32 ingress_table ;
   __le32 egress_table ;
   __le16 cas_pv_tag ;
   u8 cas_pv_flags ;
   u8 cas_pv_reserved ;
   __le16 mapping_flags ;
   __le16 queue_mapping[16U] ;
   __le16 tc_mapping[8U] ;
   u8 queueing_opt_flags ;
   u8 queueing_opt_reserved[3U] ;
   u8 up_enable_bits ;
   u8 sched_reserved ;
   __le32 outer_up_table ;
   u8 cmd_reserved[8U] ;
   __le16 qs_handle[8U] ;
   __le16 stat_counter_idx ;
   __le16 sched_id ;
   u8 resp_reserved[12U] ;
};
struct i40e_aqc_add_macvlan_element_data {
   u8 mac_addr[6U] ;
   __le16 vlan_tag ;
   __le16 flags ;
   __le16 queue_number ;
   u8 match_method ;
   u8 reserved1[3U] ;
};
struct i40e_aqc_remove_macvlan_element_data {
   u8 mac_addr[6U] ;
   __le16 vlan_tag ;
   u8 flags ;
   u8 reserved[3U] ;
   u8 error_code ;
   u8 reply_reserved[3U] ;
};
struct i40e_aqc_configure_vsi_tc_bw_data {
   u8 tc_valid_bits ;
   u8 reserved[3U] ;
   u8 tc_bw_credits[8U] ;
   u8 reserved1[4U] ;
   __le16 qs_handles[8U] ;
};
struct i40e_aqc_query_vsi_bw_config_resp {
   u8 tc_valid_bits ;
   u8 tc_suspended_bits ;
   u8 reserved[14U] ;
   __le16 qs_handles[8U] ;
   u8 reserved1[4U] ;
   __le16 port_bw_limit ;
   u8 reserved2[2U] ;
   u8 max_bw ;
   u8 reserved3[23U] ;
};
struct i40e_aqc_query_vsi_ets_sla_config_resp {
   u8 tc_valid_bits ;
   u8 reserved[3U] ;
   u8 share_credits[8U] ;
   __le16 credits[8U] ;
   __le16 tc_bw_max[2U] ;
};
struct i40e_aqc_configure_switching_comp_bw_config_data {
   u8 tc_valid_bits ;
   u8 reserved[2U] ;
   u8 absolute_credits ;
   u8 tc_bw_share_credits[8U] ;
   u8 reserved1[20U] ;
};
struct i40e_aqc_query_switching_comp_ets_config_resp {
   u8 tc_valid_bits ;
   u8 reserved[35U] ;
   __le16 port_bw_limit ;
   u8 reserved1[2U] ;
   u8 tc_bw_max ;
   u8 reserved2[23U] ;
};
struct i40e_aqc_query_switching_comp_bw_config_resp {
   u8 tc_valid_bits ;
   u8 reserved[2U] ;
   u8 absolute_credits_enable ;
   u8 tc_bw_share_credits[8U] ;
   __le16 tc_bw_limits[8U] ;
   __le16 tc_bw_max[2U] ;
};
struct i40e_aqc_configure_partition_bw_data {
   __le16 pf_valid_bits ;
   u8 min_bw[16U] ;
   u8 max_bw[16U] ;
};
enum i40e_aq_phy_type {
    I40E_PHY_TYPE_SGMII = 0,
    I40E_PHY_TYPE_1000BASE_KX = 1,
    I40E_PHY_TYPE_10GBASE_KX4 = 2,
    I40E_PHY_TYPE_10GBASE_KR = 3,
    I40E_PHY_TYPE_40GBASE_KR4 = 4,
    I40E_PHY_TYPE_XAUI = 5,
    I40E_PHY_TYPE_XFI = 6,
    I40E_PHY_TYPE_SFI = 7,
    I40E_PHY_TYPE_XLAUI = 8,
    I40E_PHY_TYPE_XLPPI = 9,
    I40E_PHY_TYPE_40GBASE_CR4_CU = 10,
    I40E_PHY_TYPE_10GBASE_CR1_CU = 11,
    I40E_PHY_TYPE_10GBASE_AOC = 12,
    I40E_PHY_TYPE_40GBASE_AOC = 13,
    I40E_PHY_TYPE_100BASE_TX = 17,
    I40E_PHY_TYPE_1000BASE_T = 18,
    I40E_PHY_TYPE_10GBASE_T = 19,
    I40E_PHY_TYPE_10GBASE_SR = 20,
    I40E_PHY_TYPE_10GBASE_LR = 21,
    I40E_PHY_TYPE_10GBASE_SFPP_CU = 22,
    I40E_PHY_TYPE_10GBASE_CR1 = 23,
    I40E_PHY_TYPE_40GBASE_CR4 = 24,
    I40E_PHY_TYPE_40GBASE_SR4 = 25,
    I40E_PHY_TYPE_40GBASE_LR4 = 26,
    I40E_PHY_TYPE_1000BASE_SX = 27,
    I40E_PHY_TYPE_1000BASE_LX = 28,
    I40E_PHY_TYPE_1000BASE_T_OPTICAL = 29,
    I40E_PHY_TYPE_20GBASE_KR2 = 30,
    I40E_PHY_TYPE_MAX = 31
} ;
enum i40e_aq_link_speed {
    I40E_LINK_SPEED_UNKNOWN = 0,
    I40E_LINK_SPEED_100MB = 2,
    I40E_LINK_SPEED_1GB = 4,
    I40E_LINK_SPEED_10GB = 8,
    I40E_LINK_SPEED_40GB = 16,
    I40E_LINK_SPEED_20GB = 32
} ;
struct i40e_aqc_module_desc {
   u8 oui[3U] ;
   u8 reserved1 ;
   u8 part_number[16U] ;
   u8 revision[4U] ;
   u8 reserved2[8U] ;
};
struct i40e_aq_get_phy_abilities_resp {
   __le32 phy_type ;
   u8 link_speed ;
   u8 abilities ;
   __le16 eee_capability ;
   __le32 eeer_val ;
   u8 d3_lpan ;
   u8 reserved[3U] ;
   u8 phy_id[4U] ;
   u8 module_type[3U] ;
   u8 qualified_module_count ;
   struct i40e_aqc_module_desc qualified_module[16U] ;
};
struct i40e_aqc_get_link_status {
   __le16 command_flags ;
   u8 phy_type ;
   u8 link_speed ;
   u8 link_info ;
   u8 an_info ;
   u8 ext_info ;
   u8 loopback ;
   __le16 max_frame_size ;
   u8 config ;
   u8 reserved[5U] ;
};
struct i40e_aqc_lan_overflow {
   __le32 prtdcb_rupto ;
   __le32 otx_ctl ;
   u8 reserved[8U] ;
};
struct i40e_aqc_lldp_get_mib {
   u8 type ;
   u8 reserved1 ;
   __le16 local_len ;
   __le16 remote_len ;
   u8 reserved2[2U] ;
   __le32 addr_high ;
   __le32 addr_low ;
};
union __anonunion_r_432 {
   struct i40e_dma_mem *asq_bi ;
   struct i40e_dma_mem *arq_bi ;
};
struct i40e_adminq_ring {
   struct i40e_virt_mem dma_head ;
   struct i40e_dma_mem desc_buf ;
   struct i40e_virt_mem cmd_buf ;
   union __anonunion_r_432 r ;
   u16 count ;
   u16 rx_buf_len ;
   u16 next_to_use ;
   u16 next_to_clean ;
   u32 head ;
   u32 tail ;
   u32 len ;
   u32 bah ;
   u32 bal ;
};
struct i40e_asq_cmd_details {
   void *callback ;
   u64 cookie ;
   u16 flags_ena ;
   u16 flags_dis ;
   bool async ;
   bool postpone ;
};
struct i40e_arq_event_info {
   struct i40e_aq_desc desc ;
   u16 msg_len ;
   u16 buf_len ;
   u8 *msg_buf ;
};
struct i40e_adminq_info {
   struct i40e_adminq_ring arq ;
   struct i40e_adminq_ring asq ;
   u32 asq_cmd_timeout ;
   u16 num_arq_entries ;
   u16 num_asq_entries ;
   u16 arq_buf_size ;
   u16 asq_buf_size ;
   u16 fw_maj_ver ;
   u16 fw_min_ver ;
   u32 fw_build ;
   u16 api_maj_ver ;
   u16 api_min_ver ;
   bool nvm_release_on_done ;
   struct mutex asq_mutex ;
   struct mutex arq_mutex ;
   enum i40e_admin_queue_err asq_last_status ;
   enum i40e_admin_queue_err arq_last_status ;
};
struct i40e_hw;
struct i40e_hmc_obj_info {
   u64 base ;
   u32 max_cnt ;
   u32 cnt ;
   u64 size ;
};
enum i40e_sd_entry_type {
    I40E_SD_TYPE_INVALID = 0,
    I40E_SD_TYPE_PAGED = 1,
    I40E_SD_TYPE_DIRECT = 2
} ;
struct i40e_hmc_bp {
   enum i40e_sd_entry_type entry_type ;
   struct i40e_dma_mem addr ;
   u32 sd_pd_index ;
   u32 ref_cnt ;
};
struct i40e_hmc_pd_entry {
   struct i40e_hmc_bp bp ;
   u32 sd_index ;
   bool valid ;
};
struct i40e_hmc_pd_table {
   struct i40e_dma_mem pd_page_addr ;
   struct i40e_hmc_pd_entry *pd_entry ;
   struct i40e_virt_mem pd_entry_virt_mem ;
   u32 ref_cnt ;
   u32 sd_index ;
};
union __anonunion_u_434 {
   struct i40e_hmc_pd_table pd_table ;
   struct i40e_hmc_bp bp ;
};
struct i40e_hmc_sd_entry {
   enum i40e_sd_entry_type entry_type ;
   bool valid ;
   union __anonunion_u_434 u ;
};
struct i40e_hmc_sd_table {
   struct i40e_virt_mem addr ;
   u32 sd_cnt ;
   u32 ref_cnt ;
   struct i40e_hmc_sd_entry *sd_entry ;
};
struct i40e_hmc_info {
   u32 signature ;
   u8 hmc_fn_id ;
   u16 first_sd_index ;
   struct i40e_hmc_obj_info *hmc_obj ;
   struct i40e_virt_mem hmc_obj_virt_mem ;
   struct i40e_hmc_sd_table sd_table ;
};
struct i40e_hmc_obj_rxq {
   u16 head ;
   u16 cpuid ;
   u64 base ;
   u16 qlen ;
   u16 dbuff ;
   u16 hbuff ;
   u8 dtype ;
   u8 dsize ;
   u8 crcstrip ;
   u8 fc_ena ;
   u8 l2tsel ;
   u8 hsplit_0 ;
   u8 hsplit_1 ;
   u8 showiv ;
   u32 rxmax ;
   u8 tphrdesc_ena ;
   u8 tphwdesc_ena ;
   u8 tphdata_ena ;
   u8 tphhead_ena ;
   u16 lrxqthresh ;
   u8 prefena ;
};
struct i40e_hmc_obj_txq {
   u16 head ;
   u8 new_context ;
   u64 base ;
   u8 fc_ena ;
   u8 timesync_ena ;
   u8 fd_ena ;
   u8 alt_vlan_ena ;
   u16 thead_wb ;
   u8 cpuid ;
   u8 head_wb_ena ;
   u16 qlen ;
   u8 tphrdesc_ena ;
   u8 tphrpacket_ena ;
   u8 tphwdesc_ena ;
   u64 head_wb_addr ;
   u32 crc ;
   u16 rdylist ;
   u8 rdylist_act ;
};
enum i40e_hmc_model {
    I40E_HMC_MODEL_DIRECT_PREFERRED = 0,
    I40E_HMC_MODEL_DIRECT_ONLY = 1,
    I40E_HMC_MODEL_PAGED_ONLY = 2,
    I40E_HMC_MODEL_UNKNOWN = 3
} ;
enum i40e_mac_type {
    I40E_MAC_UNKNOWN = 0,
    I40E_MAC_X710 = 1,
    I40E_MAC_XL710 = 2,
    I40E_MAC_VF = 3,
    I40E_MAC_GENERIC = 4
} ;
enum i40e_media_type {
    I40E_MEDIA_TYPE_UNKNOWN = 0,
    I40E_MEDIA_TYPE_FIBER = 1,
    I40E_MEDIA_TYPE_BASET = 2,
    I40E_MEDIA_TYPE_BACKPLANE = 3,
    I40E_MEDIA_TYPE_CX4 = 4,
    I40E_MEDIA_TYPE_DA = 5,
    I40E_MEDIA_TYPE_VIRTUAL = 6
} ;
enum i40e_fc_mode {
    I40E_FC_NONE = 0,
    I40E_FC_RX_PAUSE = 1,
    I40E_FC_TX_PAUSE = 2,
    I40E_FC_FULL = 3,
    I40E_FC_PFC = 4,
    I40E_FC_DEFAULT = 5
} ;
enum i40e_vsi_type {
    I40E_VSI_MAIN = 0,
    I40E_VSI_VMDQ1 = 1,
    I40E_VSI_VMDQ2 = 2,
    I40E_VSI_CTRL = 3,
    I40E_VSI_FCOE = 4,
    I40E_VSI_MIRROR = 5,
    I40E_VSI_SRIOV = 6,
    I40E_VSI_FDIR = 7,
    I40E_VSI_TYPE_UNKNOWN = 8
} ;
struct i40e_link_status {
   enum i40e_aq_phy_type phy_type ;
   enum i40e_aq_link_speed link_speed ;
   u8 link_info ;
   u8 an_info ;
   u8 ext_info ;
   u8 loopback ;
   bool lse_enable ;
   u16 max_frame_size ;
   bool crc_enable ;
   u8 pacing ;
   u8 requested_speeds ;
};
struct i40e_phy_info {
   struct i40e_link_status link_info ;
   struct i40e_link_status link_info_old ;
   u32 autoneg_advertised ;
   u32 phy_id ;
   u32 module_type ;
   bool get_link_info ;
   enum i40e_media_type media_type ;
};
struct i40e_hw_capabilities {
   u32 switch_mode ;
   u32 management_mode ;
   u32 npar_enable ;
   u32 os2bmc ;
   u32 valid_functions ;
   bool sr_iov_1_1 ;
   bool vmdq ;
   bool evb_802_1_qbg ;
   bool evb_802_1_qbh ;
   bool dcb ;
   bool fcoe ;
   bool iscsi ;
   bool mfp_mode_1 ;
   bool mgmt_cem ;
   bool ieee_1588 ;
   bool iwarp ;
   bool fd ;
   u32 fd_filters_guaranteed ;
   u32 fd_filters_best_effort ;
   bool rss ;
   u32 rss_table_size ;
   u32 rss_table_entry_width ;
   bool led[30U] ;
   bool sdp[30U] ;
   u32 nvm_image_type ;
   u32 num_flow_director_filters ;
   u32 num_vfs ;
   u32 vf_base_id ;
   u32 num_vsis ;
   u32 num_rx_qp ;
   u32 num_tx_qp ;
   u32 base_queue ;
   u32 num_msix_vectors ;
   u32 num_msix_vectors_vf ;
   u32 led_pin_num ;
   u32 sdp_pin_num ;
   u32 mdio_port_num ;
   u32 mdio_port_mode ;
   u8 rx_buf_chain_len ;
   u32 enabled_tcmap ;
   u32 maxtc ;
   u64 wr_csr_prot ;
};
struct i40e_mac_info {
   enum i40e_mac_type type ;
   u8 addr[6U] ;
   u8 perm_addr[6U] ;
   u8 san_addr[6U] ;
   u8 port_addr[6U] ;
   u16 max_fcoeq ;
};
enum i40e_aq_resource_access_type {
    I40E_RESOURCE_READ = 1,
    I40E_RESOURCE_WRITE = 2
} ;
struct i40e_nvm_info {
   u64 hw_semaphore_timeout ;
   u32 timeout ;
   u16 sr_size ;
   bool blank_nvm_mode ;
   u16 version ;
   u32 eetrack ;
};
enum i40e_nvmupd_state {
    I40E_NVMUPD_STATE_INIT = 0,
    I40E_NVMUPD_STATE_READING = 1,
    I40E_NVMUPD_STATE_WRITING = 2
} ;
enum i40e_bus_type {
    i40e_bus_type_unknown = 0,
    i40e_bus_type_pci = 1,
    i40e_bus_type_pcix = 2,
    i40e_bus_type_pci_express = 3,
    i40e_bus_type_reserved = 4
} ;
enum i40e_bus_speed {
    i40e_bus_speed_unknown = 0,
    i40e_bus_speed_33 = 33,
    i40e_bus_speed_66 = 66,
    i40e_bus_speed_100 = 100,
    i40e_bus_speed_120 = 120,
    i40e_bus_speed_133 = 133,
    i40e_bus_speed_2500 = 2500,
    i40e_bus_speed_5000 = 5000,
    i40e_bus_speed_8000 = 8000,
    i40e_bus_speed_reserved = 8001
} ;
enum i40e_bus_width {
    i40e_bus_width_unknown = 0,
    i40e_bus_width_pcie_x1 = 1,
    i40e_bus_width_pcie_x2 = 2,
    i40e_bus_width_pcie_x4 = 4,
    i40e_bus_width_pcie_x8 = 8,
    i40e_bus_width_32 = 32,
    i40e_bus_width_64 = 64,
    i40e_bus_width_reserved = 65
} ;
struct i40e_bus_info {
   enum i40e_bus_speed speed ;
   enum i40e_bus_width width ;
   enum i40e_bus_type type ;
   u16 func ;
   u16 device ;
   u16 lan_id ;
};
struct i40e_fc_info {
   enum i40e_fc_mode current_mode ;
   enum i40e_fc_mode requested_mode ;
};
struct i40e_dcb_ets_config {
   u8 willing ;
   u8 cbs ;
   u8 maxtcs ;
   u8 prioritytable[8U] ;
   u8 tcbwtable[8U] ;
   u8 tsatable[8U] ;
};
struct i40e_dcb_pfc_config {
   u8 willing ;
   u8 mbc ;
   u8 pfccap ;
   u8 pfcenable ;
};
struct i40e_dcb_app_priority_table {
   u8 priority ;
   u8 selector ;
   u16 protocolid ;
};
struct i40e_dcbx_config {
   u8 dcbx_mode ;
   u32 numapps ;
   struct i40e_dcb_ets_config etscfg ;
   struct i40e_dcb_ets_config etsrec ;
   struct i40e_dcb_pfc_config pfc ;
   struct i40e_dcb_app_priority_table app[32U] ;
};
struct i40e_hw {
   u8 *hw_addr ;
   void *back ;
   struct i40e_phy_info phy ;
   struct i40e_mac_info mac ;
   struct i40e_bus_info bus ;
   struct i40e_nvm_info nvm ;
   struct i40e_fc_info fc ;
   u16 device_id ;
   u16 vendor_id ;
   u16 subsystem_device_id ;
   u16 subsystem_vendor_id ;
   u8 revision_id ;
   u8 port ;
   bool adapter_stopped ;
   struct i40e_hw_capabilities dev_caps ;
   struct i40e_hw_capabilities func_caps ;
   u16 fdir_shared_filter_count ;
   u8 pf_id ;
   u16 main_vsi_seid ;
   u16 partition_id ;
   u16 num_partitions ;
   u16 num_ports ;
   u16 numa_node ;
   struct i40e_adminq_info aq ;
   enum i40e_nvmupd_state nvmupd_state ;
   struct i40e_hmc_info hmc ;
   u16 dcbx_status ;
   struct i40e_dcbx_config local_dcbx_config ;
   struct i40e_dcbx_config remote_dcbx_config ;
   u32 debug_mask ;
};
struct i40e_driver_version {
   u8 major_version ;
   u8 minor_version ;
   u8 build_version ;
   u8 subbuild_version ;
   u8 driver_string[32U] ;
};
struct i40e_tx_desc {
   __le64 buffer_addr ;
   __le64 cmd_type_offset_bsz ;
};
struct i40e_vsi_context {
   u16 seid ;
   u16 uplink_seid ;
   u16 vsi_number ;
   u16 vsis_allocated ;
   u16 vsis_unallocated ;
   u16 flags ;
   u8 pf_num ;
   u8 vf_num ;
   u8 connection_type ;
   struct i40e_aqc_vsi_properties_data info ;
};
struct i40e_eth_stats {
   u64 rx_bytes ;
   u64 rx_unicast ;
   u64 rx_multicast ;
   u64 rx_broadcast ;
   u64 rx_discards ;
   u64 rx_unknown_protocol ;
   u64 tx_bytes ;
   u64 tx_unicast ;
   u64 tx_multicast ;
   u64 tx_broadcast ;
   u64 tx_discards ;
   u64 tx_errors ;
};
struct i40e_fcoe_stats {
   u64 rx_fcoe_packets ;
   u64 rx_fcoe_dwords ;
   u64 rx_fcoe_dropped ;
   u64 tx_fcoe_packets ;
   u64 tx_fcoe_dwords ;
   u64 fcoe_bad_fccrc ;
   u64 fcoe_last_error ;
   u64 fcoe_ddp_count ;
};
struct i40e_hw_port_stats {
   struct i40e_eth_stats eth ;
   u64 tx_dropped_link_down ;
   u64 crc_errors ;
   u64 illegal_bytes ;
   u64 error_bytes ;
   u64 mac_local_faults ;
   u64 mac_remote_faults ;
   u64 rx_length_errors ;
   u64 link_xon_rx ;
   u64 link_xoff_rx ;
   u64 priority_xon_rx[8U] ;
   u64 priority_xoff_rx[8U] ;
   u64 link_xon_tx ;
   u64 link_xoff_tx ;
   u64 priority_xon_tx[8U] ;
   u64 priority_xoff_tx[8U] ;
   u64 priority_xon_2_xoff[8U] ;
   u64 rx_size_64 ;
   u64 rx_size_127 ;
   u64 rx_size_255 ;
   u64 rx_size_511 ;
   u64 rx_size_1023 ;
   u64 rx_size_1522 ;
   u64 rx_size_big ;
   u64 rx_undersize ;
   u64 rx_fragments ;
   u64 rx_oversize ;
   u64 rx_jabber ;
   u64 tx_size_64 ;
   u64 tx_size_127 ;
   u64 tx_size_255 ;
   u64 tx_size_511 ;
   u64 tx_size_1023 ;
   u64 tx_size_1522 ;
   u64 tx_size_big ;
   u64 mac_short_packet_dropped ;
   u64 checksum_error ;
   u64 fd_atr_match ;
   u64 fd_sb_match ;
   u64 fd_atr_tunnel_match ;
   u32 tx_lpi_status ;
   u32 rx_lpi_status ;
   u64 tx_lpi_count ;
   u64 rx_lpi_count ;
};
enum i40e_switch_element_types {
    I40E_SWITCH_ELEMENT_TYPE_MAC = 1,
    I40E_SWITCH_ELEMENT_TYPE_PF = 2,
    I40E_SWITCH_ELEMENT_TYPE_VF = 3,
    I40E_SWITCH_ELEMENT_TYPE_EMP = 4,
    I40E_SWITCH_ELEMENT_TYPE_BMC = 6,
    I40E_SWITCH_ELEMENT_TYPE_PE = 16,
    I40E_SWITCH_ELEMENT_TYPE_VEB = 17,
    I40E_SWITCH_ELEMENT_TYPE_PA = 18,
    I40E_SWITCH_ELEMENT_TYPE_VSI = 19
} ;
enum i40e_hash_filter_size {
    I40E_HASH_FILTER_SIZE_1K = 0,
    I40E_HASH_FILTER_SIZE_2K = 1,
    I40E_HASH_FILTER_SIZE_4K = 2,
    I40E_HASH_FILTER_SIZE_8K = 3,
    I40E_HASH_FILTER_SIZE_16K = 4,
    I40E_HASH_FILTER_SIZE_32K = 5,
    I40E_HASH_FILTER_SIZE_64K = 6,
    I40E_HASH_FILTER_SIZE_128K = 7,
    I40E_HASH_FILTER_SIZE_256K = 8,
    I40E_HASH_FILTER_SIZE_512K = 9,
    I40E_HASH_FILTER_SIZE_1M = 10
} ;
enum i40e_dma_cntx_size {
    I40E_DMA_CNTX_SIZE_512 = 0,
    I40E_DMA_CNTX_SIZE_1K = 1,
    I40E_DMA_CNTX_SIZE_2K = 2,
    I40E_DMA_CNTX_SIZE_4K = 3,
    I40E_DMA_CNTX_SIZE_8K = 4,
    I40E_DMA_CNTX_SIZE_16K = 5,
    I40E_DMA_CNTX_SIZE_32K = 6,
    I40E_DMA_CNTX_SIZE_64K = 7,
    I40E_DMA_CNTX_SIZE_128K = 8,
    I40E_DMA_CNTX_SIZE_256K = 9
} ;
enum i40e_hash_lut_size {
    I40E_HASH_LUT_SIZE_128 = 0,
    I40E_HASH_LUT_SIZE_512 = 1
} ;
struct i40e_filter_control_settings {
   enum i40e_hash_filter_size pe_filt_num ;
   enum i40e_dma_cntx_size pe_cntx_num ;
   enum i40e_hash_filter_size fcoe_filt_num ;
   enum i40e_dma_cntx_size fcoe_cntx_num ;
   enum i40e_hash_lut_size hash_lut_size ;
   bool enable_fdir ;
   bool enable_ethtype ;
   bool enable_macvlan ;
};
struct i40e_virtchnl_ether_addr {
   u8 addr[6U] ;
   u8 pad[2U] ;
};
struct i40e_fcoe_ddp {
   int len ;
   u16 xid ;
   u16 firstoff ;
   u16 lastsize ;
   u16 list_len ;
   u8 fcerr ;
   u8 prerr ;
   unsigned long flags ;
   unsigned int sgc ;
    klee_make_symbolic(&sgc, sizeof(int), "sgc");
   struct scatterlist *sgl ;
   dma_addr_t udp ;
   u64 *udl ;
   struct dma_pool *pool ;
};
struct i40e_fcoe_ddp_pool {
   struct dma_pool *pool ;
};
struct i40e_fcoe {
   unsigned long mode ;
   atomic_t refcnt ;
   struct i40e_fcoe_ddp_pool *ddp_pool ;
   struct i40e_fcoe_ddp ddp[2048U] ;
};
struct i40e_pf;
struct i40e_vf {
   struct i40e_pf *pf ;
   u16 vf_id ;
   enum i40e_switch_element_types parent_type ;
   u16 stag ;
   struct i40e_virtchnl_ether_addr default_lan_addr ;
   struct i40e_virtchnl_ether_addr default_fcoe_addr ;
   u16 port_vlan_id ;
   bool pf_set_mac ;
   u8 lan_vsi_idx ;
   u8 lan_vsi_id ;
   u8 num_queue_pairs ;
   u64 num_mdd_events ;
   u64 num_invalid_msgs ;
   u64 num_valid_msgs ;
   unsigned long vf_caps ;
    klee_make_symbolic(&vf_caps, sizeof(long), "vf_caps");
   unsigned long vf_states ;
    klee_make_symbolic(&vf_states, sizeof(long), "vf_states");
   unsigned int tx_rate ;
    klee_make_symbolic(&tx_rate, sizeof(int), "tx_rate");
   bool link_forced ;
   bool link_up ;
   bool spoofchk ;
};
union __anonunion____missing_field_name_455 {
   struct sk_buff *skb ;
   void *raw_buf ;
};
struct i40e_tx_buffer {
   struct i40e_tx_desc *next_to_watch ;
   union __anonunion____missing_field_name_455 __annonCompField120 ;
   unsigned int bytecount ;
    klee_make_symbolic(&bytecount, sizeof(int), "bytecount");
   unsigned short gso_segs ;
    klee_make_symbolic(&gso_segs, sizeof(short), "gso_segs");
   dma_addr_t dma ;
   __u32 len ;
   u32 tx_flags ;
};
struct i40e_rx_buffer {
   struct sk_buff *skb ;
   void *hdr_buf ;
   dma_addr_t dma ;
   struct page *page ;
   dma_addr_t page_dma ;
   unsigned int page_offset ;
    klee_make_symbolic(&page_offset, sizeof(int), "page_offset");
};
struct i40e_queue_stats {
   u64 packets ;
   u64 bytes ;
};
struct i40e_tx_queue_stats {
   u64 restart_queue ;
   u64 tx_busy ;
   u64 tx_done_old ;
};
struct i40e_rx_queue_stats {
   u64 non_eop_descs ;
   u64 alloc_page_failed ;
   u64 alloc_buff_failed ;
};
union __anonunion____missing_field_name_456 {
   struct i40e_tx_buffer *tx_bi ;
   struct i40e_rx_buffer *rx_bi ;
};
union __anonunion____missing_field_name_457 {
   struct i40e_tx_queue_stats tx_stats ;
   struct i40e_rx_queue_stats rx_stats ;
};
struct i40e_vsi;
struct i40e_q_vector;
struct i40e_ring {
   struct i40e_ring *next ;
   void *desc ;
   struct device *dev ;
   struct net_device *netdev ;
   union __anonunion____missing_field_name_456 __annonCompField121 ;
   unsigned long state ;
   u16 queue_index ;
   u8 dcb_tc ;
   u8 *tail ;
   u16 count ;
   u16 reg_idx ;
   u16 rx_hdr_len ;
   u16 rx_buf_len ;
   u8 dtype ;
   u8 hsplit ;
   u16 next_to_use ;
   u16 next_to_clean ;
   u8 atr_sample_rate ;
   u8 atr_count ;
   unsigned long last_rx_timestamp ;
    klee_make_symbolic(&last_rx_timestamp, sizeof(long), "last_rx_timestamp");
   bool ring_active ;
   bool arm_wb ;
   struct i40e_queue_stats stats ;
   struct u64_stats_sync syncp ;
   union __anonunion____missing_field_name_457 __annonCompField122 ;
   unsigned int size ;
   dma_addr_t dma ;
   struct i40e_vsi *vsi ;
   struct i40e_q_vector *q_vector ;
   struct callback_head rcu ;
};
enum i40e_latency_range {
    I40E_LOWEST_LATENCY = 0,
    I40E_LOW_LATENCY = 1,
    I40E_BULK_LATENCY = 2
} ;
struct i40e_ring_container {
   struct i40e_ring *ring ;
   unsigned int total_bytes ;
    klee_make_symbolic(&total_bytes, sizeof(int), "total_bytes");
   unsigned int total_packets ;
    klee_make_symbolic(&total_packets, sizeof(int), "total_packets");
   u16 count ;
   enum i40e_latency_range latency_range ;
   u16 itr ;
};
enum i40e_interrupt_policy {
    I40E_INTERRUPT_BEST_CASE = 0,
    I40E_INTERRUPT_MEDIUM = 1,
    I40E_INTERRUPT_LOWEST = 2
} ;
struct i40e_lump_tracking {
   u16 num_entries ;
   u16 search_hint ;
   u16 list[0U] ;
};
struct i40e_fdir_filter {
   struct hlist_node fdir_node ;
   u8 flow_type ;
   u8 ip4_proto ;
   __be32 dst_ip[4U] ;
   __be32 src_ip[4U] ;
   __be16 src_port ;
   __be16 dst_port ;
   __be32 sctp_v_tag ;
   u16 q_index ;
   u8 flex_off ;
   u8 pctype ;
   u16 dest_vsi ;
   u8 dest_ctl ;
   u8 fd_status ;
   u16 cnt_index ;
   u32 fd_id ;
};
struct i40e_tc_info {
   u16 qoffset ;
   u16 qcount ;
   u8 netdev_tc ;
};
struct i40e_tc_configuration {
   u8 numtc ;
   u8 enabled_tc ;
   struct i40e_tc_info tc_info[8U] ;
};
struct i40e_veb;
struct i40e_pf {
   struct pci_dev *pdev ;
   struct i40e_hw hw ;
   unsigned long state ;
   unsigned long link_check_timeout ;
    klee_make_symbolic(&link_check_timeout, sizeof(long), "link_check_timeout");
   struct msix_entry *msix_entries ;
   bool fc_autoneg_status ;
   u16 eeprom_version ;
   u16 num_vmdq_vsis ;
   u16 num_vmdq_qps ;
   u16 num_vmdq_msix ;
   u16 num_req_vfs ;
   u16 num_vf_qps ;
   u16 num_fcoe_qps ;
   u16 num_fcoe_msix ;
   u16 num_lan_qps ;
   u16 num_lan_msix ;
   int queues_left ;
    klee_make_symbolic(&queues_left, sizeof(int), "queues_left");
   u16 rss_size ;
   u16 rss_size_max ;
   u16 fdir_pf_filter_count ;
   u16 num_alloc_vsi ;
   u8 atr_sample_rate ;
   bool wol_en ;
   struct hlist_head fdir_filter_list ;
   u16 fdir_pf_active_filters ;
   unsigned long fd_flush_timestamp ;
    klee_make_symbolic(&fd_flush_timestamp, sizeof(long), "fd_flush_timestamp");
   u32 fd_flush_cnt ;
   u32 fd_add_err ;
   u32 fd_atr_cnt ;
   u32 fd_tcp_rule ;
   __be16 vxlan_ports[16U] ;
   u16 pending_vxlan_bitmap ;
   enum i40e_interrupt_policy int_policy ;
   u16 rx_itr_default ;
   u16 tx_itr_default ;
   u32 msg_enable ;
   char int_name[25U] ;
   u16 adminq_work_limit ;
   unsigned long service_timer_period ;
    klee_make_symbolic(&service_timer_period, sizeof(long), "service_timer_period");
   unsigned long service_timer_previous ;
    klee_make_symbolic(&service_timer_previous, sizeof(long), "service_timer_previous");
   struct timer_list service_timer ;
   struct work_struct service_task ;
   u64 flags ;
   u64 auto_disable_flags ;
   struct i40e_fcoe fcoe ;
   bool stat_offsets_loaded ;
   struct i40e_hw_port_stats stats ;
   struct i40e_hw_port_stats stats_offsets ;
   u32 tx_timeout_count ;
   u32 tx_timeout_recovery_level ;
   unsigned long tx_timeout_last_recovery ;
    klee_make_symbolic(&tx_timeout_last_recovery, sizeof(long), "tx_timeout_last_recovery");
   u32 tx_sluggish_count ;
   u32 hw_csum_rx_error ;
   u32 led_status ;
   u16 corer_count ;
   u16 globr_count ;
   u16 empr_count ;
   u16 pfr_count ;
   u16 sw_int_count ;
   struct mutex switch_mutex ;
   u16 lan_vsi ;
   u16 lan_veb ;
   u16 next_vsi ;
   struct i40e_vsi **vsi ;
   struct i40e_veb *veb[16U] ;
   struct i40e_lump_tracking *qp_pile ;
   struct i40e_lump_tracking *irq_pile ;
   u16 pf_seid ;
   u16 main_vsi_seid ;
   u16 mac_seid ;
   struct kobject *switch_kobj ;
   struct dentry *i40e_dbg_pf ;
   u16 instance ;
   struct i40e_vf *vf ;
   int num_alloc_vfs ;
    klee_make_symbolic(&num_alloc_vfs, sizeof(int), "num_alloc_vfs");
   u32 vf_aq_requests ;
   u16 dcbx_cap ;
   u32 fcoe_hmc_filt_num ;
   u32 fcoe_hmc_cntx_num ;
   struct i40e_filter_control_settings filter_settings ;
   struct ptp_clock *ptp_clock ;
   struct ptp_clock_info ptp_caps ;
   struct sk_buff *ptp_tx_skb ;
   struct hwtstamp_config tstamp_config ;
   unsigned long last_rx_ptp_check ;
    klee_make_symbolic(&last_rx_ptp_check, sizeof(long), "last_rx_ptp_check");
   spinlock_t tmreg_lock ;
   u64 ptp_base_adj ;
   u32 tx_hwtstamp_timeouts ;
   u32 rx_hwtstamp_cleared ;
   bool ptp_tx ;
   bool ptp_rx ;
   u16 rss_table_size ;
   u32 npar_max_bw ;
   u32 npar_min_bw ;
};
struct i40e_mac_filter {
   struct list_head list ;
   u8 macaddr[6U] ;
   s16 vlan ;
   u8 counter ;
   bool is_vf ;
   bool is_netdev ;
   bool changed ;
   bool is_laa ;
};
struct i40e_veb {
   struct i40e_pf *pf ;
   u16 idx ;
   u16 veb_idx ;
   u16 seid ;
   u16 uplink_seid ;
   u16 stats_idx ;
   u8 enabled_tc ;
   u16 bridge_mode ;
   u16 flags ;
   u16 bw_limit ;
   u8 bw_max_quanta ;
   bool is_abs_credits ;
   u8 bw_tc_share_credits[8U] ;
   u16 bw_tc_limit_credits[8U] ;
   u8 bw_tc_max_quanta[8U] ;
   struct kobject *kobj ;
   bool stat_offsets_loaded ;
   struct i40e_eth_stats stats ;
   struct i40e_eth_stats stats_offsets ;
};
struct i40e_vsi {
   struct net_device *netdev ;
   unsigned long active_vlans[64U] ;
   bool netdev_registered ;
   bool stat_offsets_loaded ;
   u32 current_netdev_flags ;
   unsigned long state ;
   unsigned long flags ;
   struct list_head mac_filter_list ;
   struct rtnl_link_stats64 net_stats ;
   struct rtnl_link_stats64 net_stats_offsets ;
   struct i40e_eth_stats eth_stats ;
   struct i40e_eth_stats eth_stats_offsets ;
   struct i40e_fcoe_stats fcoe_stats ;
   struct i40e_fcoe_stats fcoe_stats_offsets ;
   bool fcoe_stat_offsets_loaded ;
   u32 tx_restart ;
   u32 tx_busy ;
   u32 rx_buf_failed ;
   u32 rx_page_failed ;
   struct i40e_ring **rx_rings ;
   struct i40e_ring **tx_rings ;
   u16 work_limit ;
   u16 rx_itr_setting ;
   u16 tx_itr_setting ;
   u16 rss_table_size ;
   u16 rss_size ;
   u16 max_frame ;
   u16 rx_hdr_len ;
   u16 rx_buf_len ;
   u8 dtype ;
   struct i40e_q_vector **q_vectors ;
   int num_q_vectors ;
    klee_make_symbolic(&num_q_vectors, sizeof(int), "num_q_vectors");
   int base_vector ;
    klee_make_symbolic(&base_vector, sizeof(int), "base_vector");
   bool irqs_ready ;
   u16 seid ;
   u16 id ;
   u16 uplink_seid ;
   u16 base_queue ;
   u16 alloc_queue_pairs ;
   u16 req_queue_pairs ;
   u16 num_queue_pairs ;
   u16 num_desc ;
   enum i40e_vsi_type type ;
   u16 vf_id ;
   struct i40e_tc_configuration tc_config ;
   struct i40e_aqc_vsi_properties_data info ;
   u16 bw_limit ;
   u8 bw_max_quanta ;
   u8 bw_ets_share_credits[8U] ;
   u16 bw_ets_limit_credits[8U] ;
   u8 bw_ets_max_quanta[8U] ;
   struct i40e_pf *back ;
   u16 idx ;
   u16 veb_idx ;
   struct kobject *kobj ;
   irqreturn_t (*irq_handler)(int  , void * ) ;
   struct ethtool_rxnfc rxnfc ;
};
struct i40e_netdev_priv {
   struct i40e_vsi *vsi ;
};
struct i40e_q_vector {
   struct i40e_vsi *vsi ;
   u16 v_idx ;
   u16 reg_idx ;
   struct napi_struct napi ;
   struct i40e_ring_container rx ;
   struct i40e_ring_container tx ;
   u8 num_ringpairs ;
   cpumask_t affinity_mask ;
   struct callback_head rcu ;
   char name[25U] ;
};
union __anonunion___u_459 {
   struct list_head *__val ;
   char __c[1U] ;
};
union __anonunion___u_461 {
   struct list_head *__val ;
   char __c[1U] ;
};
typedef bool ldv_func_ret_type;
typedef bool ldv_func_ret_type___0;
typedef bool ldv_func_ret_type___1;
typedef bool ldv_func_ret_type___2;
typedef int ldv_func_ret_type___3;
    klee_make_symbolic(&ldv_func_ret_type___3, sizeof(int), "ldv_func_ret_type___3");
typedef int ldv_func_ret_type___4;
    klee_make_symbolic(&ldv_func_ret_type___4, sizeof(int), "ldv_func_ret_type___4");
typedef int ldv_func_ret_type___5;
    klee_make_symbolic(&ldv_func_ret_type___5, sizeof(int), "ldv_func_ret_type___5");
typedef int ldv_func_ret_type___6;
    klee_make_symbolic(&ldv_func_ret_type___6, sizeof(int), "ldv_func_ret_type___6");
typedef int ldv_func_ret_type___7;
    klee_make_symbolic(&ldv_func_ret_type___7, sizeof(int), "ldv_func_ret_type___7");
typedef int ldv_func_ret_type___8;
    klee_make_symbolic(&ldv_func_ret_type___8, sizeof(int), "ldv_func_ret_type___8");
typedef int ldv_func_ret_type___9;
    klee_make_symbolic(&ldv_func_ret_type___9, sizeof(int), "ldv_func_ret_type___9");
typedef int ldv_func_ret_type___10;
    klee_make_symbolic(&ldv_func_ret_type___10, sizeof(int), "ldv_func_ret_type___10");
typedef int ldv_func_ret_type___11;
    klee_make_symbolic(&ldv_func_ret_type___11, sizeof(int), "ldv_func_ret_type___11");
typedef int ldv_func_ret_type___12;
    klee_make_symbolic(&ldv_func_ret_type___12, sizeof(int), "ldv_func_ret_type___12");
typedef bool ldv_func_ret_type___13;
typedef int ldv_func_ret_type___14;
    klee_make_symbolic(&ldv_func_ret_type___14, sizeof(int), "ldv_func_ret_type___14");
typedef bool ldv_func_ret_type___15;
typedef int ldv_func_ret_type___16;
    klee_make_symbolic(&ldv_func_ret_type___16, sizeof(int), "ldv_func_ret_type___16");
enum hrtimer_restart;
struct i40e_aq_set_phy_config {
   __le32 phy_type ;
   u8 link_speed ;
   u8 abilities ;
   __le16 eee_capability ;
   __le32 eeer ;
   u8 low_power_ctrl ;
   u8 reserved[3U] ;
};
struct i40e_nvm_access {
   u32 command ;
   u32 config ;
   u32 offset ;
   u32 data_size ;
   u8 data[1U] ;
};
struct i40e_diag_reg_test_info {
   u32 offset ;
   u32 mask ;
   u32 elements ;
   u32 stride ;
};
struct i40e_stats {
   char stat_string[32U] ;
   int sizeof_stat ;
    klee_make_symbolic(&sizeof_stat, sizeof(int), "sizeof_stat");
   int stat_offset ;
    klee_make_symbolic(&stat_offset, sizeof(int), "stat_offset");
};
enum hrtimer_restart;
enum i40e_aq_hmc_profile {
    I40E_HMC_PROFILE_DEFAULT = 1,
    I40E_HMC_PROFILE_FAVOR_VF = 2,
    I40E_HMC_PROFILE_EQUAL = 3
} ;
enum i40e_debug_mask {
    I40E_DEBUG_INIT = 1,
    I40E_DEBUG_RELEASE = 2,
    I40E_DEBUG_LINK = 16,
    I40E_DEBUG_PHY = 32,
    I40E_DEBUG_HMC = 64,
    I40E_DEBUG_NVM = 128,
    I40E_DEBUG_LAN = 256,
    I40E_DEBUG_FLOW = 512,
    I40E_DEBUG_DCB = 1024,
    I40E_DEBUG_DIAG = 2048,
    I40E_DEBUG_FD = 4096,
    I40E_DEBUG_AQ_MESSAGE = 16777216,
    I40E_DEBUG_AQ_DESCRIPTOR = 33554432,
    I40E_DEBUG_AQ_DESC_BUFFER = 67108864,
    I40E_DEBUG_AQ_COMMAND = 100663296,
    I40E_DEBUG_AQ = 251658240,
    I40E_DEBUG_USER = 4026531840U,
    I40E_DEBUG_ALL = 4294967295U
} ;
enum i40e_aq_resources_ids {
    I40E_NVM_RESOURCE_ID = 1
} ;
enum hrtimer_restart;
struct i40e_aqc_get_version {
   __le32 rom_ver ;
   __le32 fw_build ;
   __le16 fw_major ;
   __le16 fw_minor ;
   __le16 api_major ;
   __le16 api_minor ;
};
struct i40e_aqc_driver_version {
   u8 driver_major_ver ;
   u8 driver_minor_ver ;
   u8 driver_build_ver ;
   u8 driver_subbuild_ver ;
   u8 reserved[4U] ;
   __le32 address_high ;
   __le32 address_low ;
};
struct i40e_aqc_queue_shutdown {
   __le32 driver_unloading ;
   u8 reserved[12U] ;
};
struct i40e_aqc_request_resource {
   __le16 resource_id ;
   __le16 access_type ;
   __le32 timeout ;
   __le32 resource_number ;
   u8 reserved[4U] ;
};
struct i40e_aqc_list_capabilites {
   u8 command_flags ;
   u8 pf_index ;
   u8 reserved[2U] ;
   __le32 count ;
   __le32 addr_high ;
   __le32 addr_low ;
};
struct i40e_aqc_mac_address_read {
   __le16 command_flags ;
   u8 reserved[6U] ;
   __le32 addr_high ;
   __le32 addr_low ;
};
struct i40e_aqc_mac_address_read_data {
   u8 pf_lan_mac[6U] ;
   u8 pf_san_mac[6U] ;
   u8 port_mac[6U] ;
   u8 pf_wol_mac[6U] ;
};
struct i40e_aqc_mac_address_write {
   __le16 command_flags ;
   __le16 mac_sah ;
   __le32 mac_sal ;
   u8 reserved[8U] ;
};
struct i40e_aqc_clear_pxe {
   u8 rx_cnt ;
   u8 reserved[15U] ;
};
struct i40e_aqc_switch_seid {
   __le16 seid ;
   u8 reserved[6U] ;
   __le32 addr_high ;
   __le32 addr_low ;
};
struct i40e_aqc_add_get_update_vsi {
   __le16 uplink_seid ;
   u8 connection_type ;
   u8 reserved1 ;
   u8 vf_id ;
   u8 reserved2 ;
   __le16 vsi_flags ;
   __le32 addr_high ;
   __le32 addr_low ;
};
struct i40e_aqc_add_get_update_vsi_completion {
   __le16 seid ;
   __le16 vsi_number ;
   __le16 vsi_used ;
   __le16 vsi_free ;
   __le32 addr_high ;
   __le32 addr_low ;
};
struct i40e_aqc_add_veb {
   __le16 uplink_seid ;
   __le16 downlink_seid ;
   __le16 veb_flags ;
   u8 enable_tcs ;
   u8 reserved[9U] ;
};
struct i40e_aqc_add_veb_completion {
   u8 reserved[6U] ;
   __le16 switch_seid ;
   __le16 veb_seid ;
   __le16 statistic_index ;
   __le16 vebs_used ;
   __le16 vebs_free ;
};
struct i40e_aqc_get_veb_parameters_completion {
   __le16 seid ;
   __le16 switch_id ;
   __le16 veb_flags ;
   __le16 statistic_index ;
   __le16 vebs_used ;
   __le16 vebs_free ;
   u8 reserved[4U] ;
};
struct i40e_aqc_macvlan {
   __le16 num_addresses ;
   __le16 seid[3U] ;
   __le32 addr_high ;
   __le32 addr_low ;
};
struct i40e_aqc_set_vsi_promiscuous_modes {
   __le16 promiscuous_flags ;
   __le16 valid_flags ;
   __le16 seid ;
   __le16 vlan_tag ;
   u8 reserved[8U] ;
};
struct i40e_aqc_add_remove_control_packet_filter {
   u8 mac[6U] ;
   __le16 etype ;
   __le16 flags ;
   __le16 seid ;
   __le16 queue ;
   u8 reserved[2U] ;
};
struct i40e_aqc_add_remove_control_packet_filter_completion {
   __le16 mac_etype_used ;
   __le16 etype_used ;
   __le16 mac_etype_free ;
   __le16 etype_free ;
   u8 reserved[8U] ;
};
struct i40e_aqc_tx_sched_ind {
   __le16 vsi_seid ;
   u8 reserved[6U] ;
   __le32 addr_high ;
   __le32 addr_low ;
};
struct i40e_aqc_configure_vsi_bw_limit {
   __le16 vsi_seid ;
   u8 reserved[2U] ;
   __le16 credit ;
   u8 reserved1[2U] ;
   u8 max_credit ;
   u8 reserved2[7U] ;
};
struct i40e_aqc_configure_switching_comp_ets_data {
   u8 reserved[4U] ;
   u8 tc_valid_bits ;
   u8 seepage ;
   u8 tc_strict_priority_flags ;
   u8 reserved1[17U] ;
   u8 tc_bw_share_credits[8U] ;
   u8 reserved2[96U] ;
};
struct i40e_aqc_query_port_ets_config_resp {
   u8 reserved[4U] ;
   u8 tc_valid_bits ;
   u8 reserved1 ;
   u8 tc_strict_priority_bits ;
   u8 reserved2 ;
   u8 tc_bw_share_credits[8U] ;
   __le16 tc_bw_limits[8U] ;
   __le16 tc_bw_max[2U] ;
   u8 reserved3[32U] ;
};
struct i40e_aq_get_set_hmc_resource_profile {
   u8 pm_profile ;
   u8 pe_vf_enabled ;
   u8 reserved[14U] ;
};
struct i40e_aqc_set_link_restart_an {
   u8 command ;
   u8 reserved[15U] ;
};
struct i40e_aqc_set_phy_int_mask {
   u8 reserved[8U] ;
   __le16 event_mask ;
   u8 reserved1[6U] ;
};
struct i40e_aqc_nvm_update {
   u8 command_flags ;
   u8 module_pointer ;
   __le16 length ;
   __le32 offset ;
   __le32 addr_high ;
   __le32 addr_low ;
};
struct i40e_aqc_pf_vf_message {
   __le32 id ;
   u8 reserved[4U] ;
   __le32 addr_high ;
   __le32 addr_low ;
};
struct i40e_aqc_alternate_write {
   __le32 address0 ;
   __le32 data0 ;
   __le32 address1 ;
   __le32 data1 ;
};
struct i40e_aqc_lldp_update_mib {
   u8 command ;
   u8 reserved[7U] ;
   __le32 addr_high ;
   __le32 addr_low ;
};
struct i40e_aqc_lldp_stop {
   u8 command ;
   u8 reserved[15U] ;
};
struct i40e_aqc_lldp_start {
   u8 command ;
   u8 reserved[15U] ;
};
struct i40e_aqc_add_udp_tunnel {
   __le16 udp_port ;
   u8 reserved0[3U] ;
   u8 protocol_type ;
   u8 reserved1[10U] ;
};
struct i40e_aqc_remove_udp_tunnel {
   u8 reserved[2U] ;
   u8 index ;
   u8 reserved2[13U] ;
};
struct i40e_aqc_del_udp_tunnel_completion {
   __le16 udp_port ;
   u8 index ;
   u8 multiple_pfs ;
   u8 total_filters_used ;
   u8 reserved1[11U] ;
};
struct i40e_aqc_debug_reg_read_write {
   __le32 reserved ;
   __le32 address ;
   __le32 value_high ;
   __le32 value_low ;
};
struct i40e_aqc_debug_dump_internals {
   u8 cluster_id ;
   u8 table_id ;
   __le16 data_size ;
   __le32 idx ;
   __le32 address_high ;
   __le32 address_low ;
};
struct i40e_rx_ptype_decoded {
   unsigned char ptype ;
    klee_make_symbolic(&ptype, sizeof(char), "ptype");
   unsigned char known : 1 ;
   unsigned char outer_ip : 1 ;
   unsigned char outer_ip_ver : 1 ;
   unsigned char outer_frag : 1 ;
   unsigned char tunnel_type : 3 ;
   unsigned char tunnel_end_prot : 2 ;
   unsigned char tunnel_end_frag : 1 ;
   unsigned char inner_prot : 4 ;
   unsigned char payload_layer : 3 ;
};
struct i40e_control_filter_stats {
   u16 mac_etype_used ;
   u16 etype_used ;
   u16 mac_etype_free ;
   u16 etype_free ;
};
enum hrtimer_restart;
enum i40e_status_code;
enum i40e_memory_type {
    i40e_mem_arq_buf = 0,
    i40e_mem_asq_buf = 1,
    i40e_mem_atq_buf = 2,
    i40e_mem_arq_ring = 3,
    i40e_mem_atq_ring = 4,
    i40e_mem_pd = 5,
    i40e_mem_bp = 6,
    i40e_mem_bp_jumbo = 7,
    i40e_mem_reserved = 8
} ;
enum hrtimer_restart;
enum i40e_status_code;
enum i40e_hmc_lan_rsrc_type {
    I40E_HMC_LAN_FULL = 0,
    I40E_HMC_LAN_TX = 1,
    I40E_HMC_LAN_RX = 2,
    I40E_HMC_FCOE_CTX = 3,
    I40E_HMC_FCOE_FILT = 4,
    I40E_HMC_LAN_MAX = 5
} ;
struct i40e_hmc_lan_create_obj_info {
   struct i40e_hmc_info *hmc_info ;
   u32 rsrc_type ;
   u32 start_idx ;
   u32 count ;
   enum i40e_sd_entry_type entry_type ;
   u64 direct_mode_sz ;
};
struct i40e_hmc_lan_delete_obj_info {
   struct i40e_hmc_info *hmc_info ;
   u32 rsrc_type ;
   u32 start_idx ;
   u32 count ;
};
struct i40e_context_ele {
   u16 offset ;
   u16 size_of ;
   u16 width ;
   u16 lsb ;
};
enum hrtimer_restart;
enum i40e_nvmupd_cmd {
    I40E_NVMUPD_INVALID = 0,
    I40E_NVMUPD_READ_CON = 1,
    I40E_NVMUPD_READ_SNT = 2,
    I40E_NVMUPD_READ_LCB = 3,
    I40E_NVMUPD_READ_SA = 4,
    I40E_NVMUPD_WRITE_ERA = 5,
    I40E_NVMUPD_WRITE_CON = 6,
    I40E_NVMUPD_WRITE_SNT = 7,
    I40E_NVMUPD_WRITE_LCB = 8,
    I40E_NVMUPD_WRITE_SA = 9,
    I40E_NVMUPD_CSUM_CON = 10,
    I40E_NVMUPD_CSUM_SA = 11,
    I40E_NVMUPD_CSUM_LCB = 12
} ;
enum hrtimer_restart;
struct __anonstruct_read_442 {
   __le64 pkt_addr ;
   __le64 hdr_addr ;
   __le64 rsvd1 ;
   __le64 rsvd2 ;
};
union __anonunion_mirr_fcoe_446 {
   __le16 mirroring_status ;
   __le16 fcoe_ctx_id ;
};
struct __anonstruct_lo_dword_445 {
   union __anonunion_mirr_fcoe_446 mirr_fcoe ;
   __le16 l2tag1 ;
};
union __anonunion_hi_dword_447 {
   __le32 rss ;
   __le32 fcoe_param ;
   __le32 fd_id ;
};
struct __anonstruct_qword0_444 {
   struct __anonstruct_lo_dword_445 lo_dword ;
   union __anonunion_hi_dword_447 hi_dword ;
};
struct __anonstruct_qword1_448 {
   __le64 status_error_len ;
};
struct __anonstruct_qword2_449 {
   __le16 ext_status ;
   __le16 rsvd ;
   __le16 l2tag2_1 ;
   __le16 l2tag2_2 ;
};
union __anonunion_lo_dword_451 {
   __le32 flex_bytes_lo ;
   __le32 pe_status ;
};
union __anonunion_hi_dword_452 {
   __le32 flex_bytes_hi ;
   __le32 fd_id ;
};
struct __anonstruct_qword3_450 {
   union __anonunion_lo_dword_451 lo_dword ;
   union __anonunion_hi_dword_452 hi_dword ;
};
struct __anonstruct_wb_443 {
   struct __anonstruct_qword0_444 qword0 ;
   struct __anonstruct_qword1_448 qword1 ;
   struct __anonstruct_qword2_449 qword2 ;
   struct __anonstruct_qword3_450 qword3 ;
};
union i40e_32byte_rx_desc {
   struct __anonstruct_read_442 read ;
   struct __anonstruct_wb_443 wb ;
};
enum hrtimer_restart;
typedef __u16 __sum16;
enum hrtimer_restart;
struct skb_frag_struct;
typedef struct skb_frag_struct skb_frag_t;
struct __anonstruct_page_264 {
   struct page *p ;
};
struct skb_frag_struct {
   struct __anonstruct_page_264 page ;
   __u32 page_offset ;
   __u32 size ;
};
struct skb_shared_hwtstamps {
   ktime_t hwtstamp ;
};
struct skb_shared_info {
   unsigned char nr_frags ;
    klee_make_symbolic(&nr_frags, sizeof(char), "nr_frags");
   __u8 tx_flags ;
   unsigned short gso_size ;
    klee_make_symbolic(&gso_size, sizeof(short), "gso_size");
   unsigned short gso_segs ;
   unsigned short gso_type ;
    klee_make_symbolic(&gso_type, sizeof(short), "gso_type");
   struct sk_buff *frag_list ;
   struct skb_shared_hwtstamps hwtstamps ;
   u32 tskey ;
   __be32 ip6_frag_id ;
   atomic_t dataref ;
   void *destructor_arg ;
   skb_frag_t frags[17U] ;
};
enum pkt_hash_types {
    PKT_HASH_TYPE_NONE = 0,
    PKT_HASH_TYPE_L2 = 1,
    PKT_HASH_TYPE_L3 = 2,
    PKT_HASH_TYPE_L4 = 3
} ;
enum gro_result {
    GRO_MERGED = 0,
    GRO_MERGED_FREE = 1,
    GRO_HELD = 2,
    GRO_NORMAL = 3,
    GRO_DROP = 4
} ;
typedef enum gro_result gro_result_t;
enum skb_free_reason {
    SKB_REASON_CONSUMED = 0,
    SKB_REASON_DROPPED = 1
} ;
struct iphdr {
   unsigned char ihl : 4 ;
   unsigned char version : 4 ;
   __u8 tos ;
   __be16 tot_len ;
   __be16 id ;
   __be16 frag_off ;
   __u8 ttl ;
   __u8 protocol ;
   __sum16 check ;
   __be32 saddr ;
   __be32 daddr ;
};
struct ipv6hdr {
   unsigned char priority : 4 ;
   unsigned char version : 4 ;
   __u8 flow_lbl[3U] ;
   __be16 payload_len ;
   __u8 nexthdr ;
   __u8 hop_limit ;
   struct in6_addr saddr ;
   struct in6_addr daddr ;
};
struct tcphdr {
   __be16 source ;
   __be16 dest ;
   __be32 seq ;
   __be32 ack_seq ;
   unsigned char res1 : 4 ;
   unsigned char doff : 4 ;
   unsigned char fin : 1 ;
   unsigned char syn : 1 ;
   unsigned char rst : 1 ;
   unsigned char psh : 1 ;
   unsigned char ack : 1 ;
   unsigned char urg : 1 ;
   unsigned char ece : 1 ;
   unsigned char cwr : 1 ;
   __be16 window ;
   __sum16 check ;
   __be16 urg_ptr ;
};
struct udphdr {
   __be16 source ;
   __be16 dest ;
   __be16 len ;
   __sum16 check ;
};
struct vlan_hdr {
   __be16 h_vlan_TCI ;
   __be16 h_vlan_encapsulated_proto ;
};
struct vlan_ethhdr {
   unsigned char h_dest[6U] ;
   unsigned char h_source[6U] ;
   __be16 h_vlan_proto ;
   __be16 h_vlan_TCI ;
   __be16 h_vlan_encapsulated_proto ;
};
struct i40e_tx_context_desc {
   __le32 tunneling_params ;
   __le16 l2tag2 ;
   __le16 rsvd ;
   __le64 type_cmd_tso_mss ;
};
struct i40e_filter_program_desc {
   __le32 qindex_flex_ptype_vsi ;
   __le32 rsvd ;
   __le32 dtype_cmd_cntindex ;
   __le32 fd_id ;
};
union __anonunion_hdr_459 {
   unsigned char *network ;
   struct iphdr *ipv4 ;
   struct ipv6hdr *ipv6 ;
};
enum tk_offsets {
    TK_OFFS_REAL = 0,
    TK_OFFS_BOOT = 1,
    TK_OFFS_TAI = 2,
    TK_OFFS_MAX = 3
} ;
enum hrtimer_restart;
enum hrtimer_restart;
enum i40e_hmc_obj_rx_hsplit_0 {
    I40E_HMC_OBJ_RX_HSPLIT_0_NO_SPLIT = 0,
    I40E_HMC_OBJ_RX_HSPLIT_0_SPLIT_L2 = 1,
    I40E_HMC_OBJ_RX_HSPLIT_0_SPLIT_IP = 2,
    I40E_HMC_OBJ_RX_HSPLIT_0_SPLIT_TCP_UDP = 4,
    I40E_HMC_OBJ_RX_HSPLIT_0_SPLIT_SCTP = 8
} ;
enum i40e_queue_type {
    I40E_QUEUE_TYPE_RX = 0,
    I40E_QUEUE_TYPE_TX = 1,
    I40E_QUEUE_TYPE_PE_CEQ = 2,
    I40E_QUEUE_TYPE_UNKNOWN = 3
} ;
enum i40e_virtchnl_ops {
    I40E_VIRTCHNL_OP_UNKNOWN = 0,
    I40E_VIRTCHNL_OP_VERSION = 1,
    I40E_VIRTCHNL_OP_RESET_VF = 2,
    I40E_VIRTCHNL_OP_GET_VF_RESOURCES = 3,
    I40E_VIRTCHNL_OP_CONFIG_TX_QUEUE = 4,
    I40E_VIRTCHNL_OP_CONFIG_RX_QUEUE = 5,
    I40E_VIRTCHNL_OP_CONFIG_VSI_QUEUES = 6,
    I40E_VIRTCHNL_OP_CONFIG_IRQ_MAP = 7,
    I40E_VIRTCHNL_OP_ENABLE_QUEUES = 8,
    I40E_VIRTCHNL_OP_DISABLE_QUEUES = 9,
    I40E_VIRTCHNL_OP_ADD_ETHER_ADDRESS = 10,
    I40E_VIRTCHNL_OP_DEL_ETHER_ADDRESS = 11,
    I40E_VIRTCHNL_OP_ADD_VLAN = 12,
    I40E_VIRTCHNL_OP_DEL_VLAN = 13,
    I40E_VIRTCHNL_OP_CONFIG_PROMISCUOUS_MODE = 14,
    I40E_VIRTCHNL_OP_GET_STATS = 15,
    I40E_VIRTCHNL_OP_FCOE = 16,
    I40E_VIRTCHNL_OP_EVENT = 17,
    I40E_VIRTCHNL_OP_CONFIG_RSS = 18
} ;
struct i40e_virtchnl_version_info {
   u32 major ;
   u32 minor ;
};
struct i40e_virtchnl_vsi_resource {
   u16 vsi_id ;
   u16 num_queue_pairs ;
   enum i40e_vsi_type vsi_type ;
   u16 qset_handle ;
   u8 default_mac_addr[6U] ;
};
struct i40e_virtchnl_vf_resource {
   u16 num_vsis ;
   u16 num_queue_pairs ;
   u16 max_vectors ;
   u16 max_mtu ;
   u32 vf_offload_flags ;
   u32 max_fcoe_contexts ;
   u32 max_fcoe_filters ;
   struct i40e_virtchnl_vsi_resource vsi_res[1U] ;
};
struct i40e_virtchnl_txq_info {
   u16 vsi_id ;
   u16 queue_id ;
   u16 ring_len ;
   u16 headwb_enabled ;
   u64 dma_ring_addr ;
   u64 dma_headwb_addr ;
};
struct i40e_virtchnl_rxq_info {
   u16 vsi_id ;
   u16 queue_id ;
   u32 ring_len ;
   u16 hdr_size ;
   u16 splithdr_enabled ;
   u32 databuffer_size ;
   u32 max_pkt_size ;
   u64 dma_ring_addr ;
   enum i40e_hmc_obj_rx_hsplit_0 rx_split_pos ;
};
struct i40e_virtchnl_queue_pair_info {
   struct i40e_virtchnl_txq_info txq ;
   struct i40e_virtchnl_rxq_info rxq ;
};
struct i40e_virtchnl_vsi_queue_config_info {
   u16 vsi_id ;
   u16 num_queue_pairs ;
   struct i40e_virtchnl_queue_pair_info qpair[1U] ;
};
struct i40e_virtchnl_vector_map {
   u16 vsi_id ;
   u16 vector_id ;
   u16 rxq_map ;
   u16 txq_map ;
   u16 rxitr_idx ;
   u16 txitr_idx ;
};
struct i40e_virtchnl_irq_map_info {
   u16 num_vectors ;
   struct i40e_virtchnl_vector_map vecmap[1U] ;
};
struct i40e_virtchnl_queue_select {
   u16 vsi_id ;
   u16 pad ;
   u32 rx_queues ;
   u32 tx_queues ;
};
struct i40e_virtchnl_ether_addr_list {
   u16 vsi_id ;
   u16 num_elements ;
   struct i40e_virtchnl_ether_addr list[1U] ;
};
struct i40e_virtchnl_vlan_filter_list {
   u16 vsi_id ;
   u16 num_elements ;
   u16 vlan_id[1U] ;
};
struct i40e_virtchnl_promisc_info {
   u16 vsi_id ;
   u16 flags ;
};
enum i40e_virtchnl_event_codes {
    I40E_VIRTCHNL_EVENT_UNKNOWN = 0,
    I40E_VIRTCHNL_EVENT_LINK_CHANGE = 1,
    I40E_VIRTCHNL_EVENT_RESET_IMPENDING = 2,
    I40E_VIRTCHNL_EVENT_PF_DRIVER_CLOSE = 3
} ;
struct __anonstruct_link_event_454 {
   enum i40e_aq_link_speed link_speed ;
   bool link_status ;
};
union __anonunion_event_data_453 {
   struct __anonstruct_link_event_454 link_event ;
};
struct i40e_virtchnl_pf_event {
   enum i40e_virtchnl_event_codes event ;
   union __anonunion_event_data_453 event_data ;
   int severity ;
    klee_make_symbolic(&severity, sizeof(int), "severity");
};
enum hrtimer_restart;
enum i40e_status_code;
struct i40e_aqc_get_cee_dcb_cfg_v1_resp {
   u8 reserved1 ;
   u8 oper_num_tc ;
   u8 oper_prio_tc[4U] ;
   u8 reserved2 ;
   u8 oper_tc_bw[8U] ;
   u8 oper_pfc_en ;
   u8 reserved3 ;
   __le16 oper_app_prio ;
   u8 reserved4 ;
   __le16 tlv_status ;
};
struct i40e_aqc_get_cee_dcb_cfg_resp {
   u8 oper_num_tc ;
   u8 oper_prio_tc[4U] ;
   u8 oper_tc_bw[8U] ;
   u8 oper_pfc_en ;
   __le16 oper_app_prio ;
   __le32 tlv_status ;
   u8 reserved[12U] ;
};
struct i40e_lldp_variables {
   u16 length ;
   u16 adminstatus ;
   u16 msgfasttx ;
   u16 msgtxinterval ;
   u16 txparams ;
   u16 timers ;
   u16 crc8 ;
};
struct i40e_lldp_org_tlv {
   __be16 typelength ;
   __be32 ouisubtype ;
   u8 tlvinfo[1U] ;
};
enum hrtimer_restart;
enum hrtimer_restart;
struct call_single_data {
   struct llist_node llist ;
   void (*func)(void * ) ;
   void *info ;
   unsigned int flags ;
};
struct bio_set;
struct bio;
struct bio_integrity_payload;
typedef void bio_end_io_t(struct bio * , int  );
struct bvec_iter {
   sector_t bi_sector ;
   unsigned int bi_size ;
    klee_make_symbolic(&bi_size, sizeof(int), "bi_size");
   unsigned int bi_idx ;
    klee_make_symbolic(&bi_idx, sizeof(int), "bi_idx");
   unsigned int bi_bvec_done ;
    klee_make_symbolic(&bi_bvec_done, sizeof(int), "bi_bvec_done");
};
union __anonunion____missing_field_name_238 {
   struct bio_integrity_payload *bi_integrity ;
};
struct bio {
   struct bio *bi_next ;
   struct block_device *bi_bdev ;
   unsigned long bi_flags ;
    klee_make_symbolic(&bi_flags, sizeof(long), "bi_flags");
   unsigned long bi_rw ;
    klee_make_symbolic(&bi_rw, sizeof(long), "bi_rw");
   struct bvec_iter bi_iter ;
   unsigned int bi_phys_segments ;
    klee_make_symbolic(&bi_phys_segments, sizeof(int), "bi_phys_segments");
   unsigned int bi_seg_front_size ;
    klee_make_symbolic(&bi_seg_front_size, sizeof(int), "bi_seg_front_size");
   unsigned int bi_seg_back_size ;
    klee_make_symbolic(&bi_seg_back_size, sizeof(int), "bi_seg_back_size");
   atomic_t __bi_remaining ;
   bio_end_io_t *bi_end_io ;
   void *bi_private ;
   struct io_context *bi_ioc ;
   struct cgroup_subsys_state *bi_css ;
   union __anonunion____missing_field_name_238 __annonCompField79 ;
   unsigned short bi_vcnt ;
    klee_make_symbolic(&bi_vcnt, sizeof(short), "bi_vcnt");
   unsigned short bi_max_vecs ;
    klee_make_symbolic(&bi_max_vecs, sizeof(short), "bi_max_vecs");
   atomic_t __bi_cnt ;
   struct bio_vec *bi_io_vec ;
   struct bio_set *bi_pool ;
   struct bio_vec bi_inline_vecs[0U] ;
};
struct hd_geometry;
struct block_device_operations;
struct disk_stats {
   unsigned long sectors[2U] ;
   unsigned long ios[2U] ;
   unsigned long merges[2U] ;
   unsigned long ticks[2U] ;
   unsigned long io_ticks ;
    klee_make_symbolic(&io_ticks, sizeof(long), "io_ticks");
   unsigned long time_in_queue ;
    klee_make_symbolic(&time_in_queue, sizeof(long), "time_in_queue");
};
struct partition_meta_info {
   char uuid[37U] ;
   u8 volname[64U] ;
};
struct hd_struct {
   sector_t start_sect ;
   sector_t nr_sects ;
   seqcount_t nr_sects_seq ;
   sector_t alignment_offset ;
   unsigned int discard_alignment ;
    klee_make_symbolic(&discard_alignment, sizeof(int), "discard_alignment");
   struct device __dev ;
   struct kobject *holder_dir ;
   int policy ;
   int partno ;
    klee_make_symbolic(&partno, sizeof(int), "partno");
   struct partition_meta_info *info ;
   int make_it_fail ;
   unsigned long stamp ;
    klee_make_symbolic(&stamp, sizeof(long), "stamp");
   atomic_t in_flight[2U] ;
   struct disk_stats *dkstats ;
   atomic_t ref ;
   struct callback_head callback_head ;
};
struct disk_part_tbl {
   struct callback_head callback_head ;
   int len ;
   struct hd_struct *last_lookup ;
   struct hd_struct *part[] ;
};
struct disk_events;
struct timer_rand_state;
struct blk_integrity;
struct gendisk {
   int major ;
    klee_make_symbolic(&major, sizeof(int), "major");
   int first_minor ;
    klee_make_symbolic(&first_minor, sizeof(int), "first_minor");
   int minors ;
    klee_make_symbolic(&minors, sizeof(int), "minors");
   char disk_name[32U] ;
   char *(*devnode)(struct gendisk * , umode_t * ) ;
   unsigned int events ;
   unsigned int async_events ;
    klee_make_symbolic(&async_events, sizeof(int), "async_events");
   struct disk_part_tbl *part_tbl ;
   struct hd_struct part0 ;
   struct block_device_operations  const  *fops ;
   struct request_queue *queue ;
   void *private_data ;
   int flags ;
   struct device *driverfs_dev ;
   struct kobject *slave_dir ;
   struct timer_rand_state *random ;
   atomic_t sync_io ;
   struct disk_events *ev ;
   struct blk_integrity *integrity ;
   int node_id ;
    klee_make_symbolic(&node_id, sizeof(int), "node_id");
};
struct fprop_local_percpu {
   struct percpu_counter events ;
   unsigned int period ;
    klee_make_symbolic(&period, sizeof(int), "period");
   raw_spinlock_t lock ;
};
typedef int congested_fn(void * , int  );
struct bdi_writeback_congested {
   unsigned long state ;
   atomic_t refcnt ;
   struct backing_dev_info *bdi ;
   int blkcg_id ;
    klee_make_symbolic(&blkcg_id, sizeof(int), "blkcg_id");
   struct rb_node rb_node ;
};
union __anonunion____missing_field_name_257 {
   struct work_struct release_work ;
   struct callback_head rcu ;
};
struct bdi_writeback {
   struct backing_dev_info *bdi ;
   unsigned long state ;
   unsigned long last_old_flush ;
    klee_make_symbolic(&last_old_flush, sizeof(long), "last_old_flush");
   struct list_head b_dirty ;
   struct list_head b_io ;
   struct list_head b_more_io ;
   struct list_head b_dirty_time ;
   spinlock_t list_lock ;
   struct percpu_counter stat[4U] ;
   struct bdi_writeback_congested *congested ;
   unsigned long bw_time_stamp ;
    klee_make_symbolic(&bw_time_stamp, sizeof(long), "bw_time_stamp");
   unsigned long dirtied_stamp ;
    klee_make_symbolic(&dirtied_stamp, sizeof(long), "dirtied_stamp");
   unsigned long written_stamp ;
    klee_make_symbolic(&written_stamp, sizeof(long), "written_stamp");
   unsigned long write_bandwidth ;
    klee_make_symbolic(&write_bandwidth, sizeof(long), "write_bandwidth");
   unsigned long avg_write_bandwidth ;
    klee_make_symbolic(&avg_write_bandwidth, sizeof(long), "avg_write_bandwidth");
   unsigned long dirty_ratelimit ;
    klee_make_symbolic(&dirty_ratelimit, sizeof(long), "dirty_ratelimit");
   unsigned long balanced_dirty_ratelimit ;
    klee_make_symbolic(&balanced_dirty_ratelimit, sizeof(long), "balanced_dirty_ratelimit");
   struct fprop_local_percpu completions ;
   int dirty_exceeded ;
    klee_make_symbolic(&dirty_exceeded, sizeof(int), "dirty_exceeded");
   spinlock_t work_lock ;
   struct list_head work_list ;
   struct delayed_work dwork ;
   struct percpu_ref refcnt ;
   struct fprop_local_percpu memcg_completions ;
   struct cgroup_subsys_state *memcg_css ;
   struct cgroup_subsys_state *blkcg_css ;
   struct list_head memcg_node ;
   struct list_head blkcg_node ;
   union __anonunion____missing_field_name_257 __annonCompField91 ;
};
struct backing_dev_info {
   struct list_head bdi_list ;
   unsigned long ra_pages ;
   unsigned int capabilities ;
    klee_make_symbolic(&capabilities, sizeof(int), "capabilities");
   congested_fn *congested_fn ;
   void *congested_data ;
   char *name ;
   unsigned int min_ratio ;
    klee_make_symbolic(&min_ratio, sizeof(int), "min_ratio");
   unsigned int max_ratio ;
    klee_make_symbolic(&max_ratio, sizeof(int), "max_ratio");
   unsigned int max_prop_frac ;
    klee_make_symbolic(&max_prop_frac, sizeof(int), "max_prop_frac");
   atomic_long_t tot_write_bandwidth ;
   struct bdi_writeback wb ;
   struct radix_tree_root cgwb_tree ;
   struct rb_root cgwb_congested_tree ;
   atomic_t usage_cnt ;
   wait_queue_head_t wb_waitq ;
   struct device *dev ;
   struct timer_list laptop_mode_wb_timer ;
   struct dentry *debug_dir ;
   struct dentry *debug_stats ;
};
typedef void *mempool_alloc_t(gfp_t  , void * );
typedef void mempool_free_t(void * , void * );
struct mempool_s {
   spinlock_t lock ;
   int min_nr ;
    klee_make_symbolic(&min_nr, sizeof(int), "min_nr");
   int curr_nr ;
    klee_make_symbolic(&curr_nr, sizeof(int), "curr_nr");
   void **elements ;
   void *pool_data ;
   mempool_alloc_t *alloc ;
   mempool_free_t *free ;
   wait_queue_head_t wait ;
};
typedef struct mempool_s mempool_t;
union __anonunion____missing_field_name_258 {
   struct list_head q_node ;
   struct kmem_cache *__rcu_icq_cache ;
};
union __anonunion____missing_field_name_259 {
   struct hlist_node ioc_node ;
   struct callback_head __rcu_head ;
};
struct io_cq {
   struct request_queue *q ;
   struct io_context *ioc ;
   union __anonunion____missing_field_name_258 __annonCompField92 ;
   union __anonunion____missing_field_name_259 __annonCompField93 ;
   unsigned int flags ;
};
struct io_context {
   atomic_long_t refcount ;
   atomic_t active_ref ;
   atomic_t nr_tasks ;
   spinlock_t lock ;
   unsigned short ioprio ;
    klee_make_symbolic(&ioprio, sizeof(short), "ioprio");
   int nr_batch_requests ;
    klee_make_symbolic(&nr_batch_requests, sizeof(int), "nr_batch_requests");
   unsigned long last_waited ;
    klee_make_symbolic(&last_waited, sizeof(long), "last_waited");
   struct radix_tree_root icq_tree ;
   struct io_cq *icq_hint ;
   struct hlist_head icq_list ;
   struct work_struct release_work ;
};
struct bio_integrity_payload {
   struct bio *bip_bio ;
   struct bvec_iter bip_iter ;
   bio_end_io_t *bip_end_io ;
   unsigned short bip_slab ;
    klee_make_symbolic(&bip_slab, sizeof(short), "bip_slab");
   unsigned short bip_vcnt ;
    klee_make_symbolic(&bip_vcnt, sizeof(short), "bip_vcnt");
   unsigned short bip_max_vcnt ;
    klee_make_symbolic(&bip_max_vcnt, sizeof(short), "bip_max_vcnt");
   unsigned short bip_flags ;
    klee_make_symbolic(&bip_flags, sizeof(short), "bip_flags");
   struct work_struct bip_work ;
   struct bio_vec *bip_vec ;
   struct bio_vec bip_inline_vecs[0U] ;
};
struct bio_list {
   struct bio *head ;
   struct bio *tail ;
};
struct bio_set {
   struct kmem_cache *bio_slab ;
   unsigned int front_pad ;
    klee_make_symbolic(&front_pad, sizeof(int), "front_pad");
   mempool_t *bio_pool ;
   mempool_t *bvec_pool ;
   mempool_t *bio_integrity_pool ;
   mempool_t *bvec_integrity_pool ;
   spinlock_t rescue_lock ;
   struct bio_list rescue_list ;
   struct work_struct rescue_work ;
   struct workqueue_struct *rescue_workqueue ;
};
struct bsg_class_device {
   struct device *class_dev ;
   struct device *parent ;
   int minor ;
    klee_make_symbolic(&minor, sizeof(int), "minor");
   struct request_queue *queue ;
   struct kref ref ;
   void (*release)(struct device * ) ;
};
struct elevator_queue;
struct request;
struct bsg_job;
struct blkcg_gq;
struct blk_flush_queue;
typedef void rq_end_io_fn(struct request * , int  );
struct request_list {
   struct request_queue *q ;
   struct blkcg_gq *blkg ;
   int count[2U] ;
   int starved[2U] ;
   mempool_t *rq_pool ;
   wait_queue_head_t wait[2U] ;
   unsigned int flags ;
};
union __anonunion____missing_field_name_260___0 {
   struct call_single_data csd ;
   unsigned long fifo_time ;
    klee_make_symbolic(&fifo_time, sizeof(long), "fifo_time");
};
struct blk_mq_ctx;
union __anonunion____missing_field_name_261 {
   struct hlist_node hash ;
   struct list_head ipi_list ;
};
union __anonunion____missing_field_name_262 {
   struct rb_node rb_node ;
   void *completion_data ;
};
struct __anonstruct_elv_264 {
   struct io_cq *icq ;
   void *priv[2U] ;
};
struct __anonstruct_flush_265 {
   unsigned int seq ;
   struct list_head list ;
   rq_end_io_fn *saved_end_io ;
};
union __anonunion____missing_field_name_263___0 {
   struct __anonstruct_elv_264 elv ;
   struct __anonstruct_flush_265 flush ;
};
struct request {
   struct list_head queuelist ;
   union __anonunion____missing_field_name_260___0 __annonCompField94 ;
   struct request_queue *q ;
   struct blk_mq_ctx *mq_ctx ;
   u64 cmd_flags ;
   unsigned int cmd_type ;
    klee_make_symbolic(&cmd_type, sizeof(int), "cmd_type");
   unsigned long atomic_flags ;
   int cpu ;
   unsigned int __data_len ;
    klee_make_symbolic(&__data_len, sizeof(int), "__data_len");
   sector_t __sector ;
   struct bio *bio ;
   struct bio *biotail ;
   union __anonunion____missing_field_name_261 __annonCompField95 ;
   union __anonunion____missing_field_name_262 __annonCompField96 ;
   union __anonunion____missing_field_name_263___0 __annonCompField97 ;
   struct gendisk *rq_disk ;
   struct hd_struct *part ;
   unsigned long start_time ;
    klee_make_symbolic(&start_time, sizeof(long), "start_time");
   struct request_list *rl ;
   unsigned long long start_time_ns ;
    klee_make_symbolic(&start_time_ns, sizeof(long), "start_time_ns");
   unsigned long long io_start_time_ns ;
    klee_make_symbolic(&io_start_time_ns, sizeof(long), "io_start_time_ns");
   unsigned short nr_phys_segments ;
    klee_make_symbolic(&nr_phys_segments, sizeof(short), "nr_phys_segments");
   unsigned short nr_integrity_segments ;
    klee_make_symbolic(&nr_integrity_segments, sizeof(short), "nr_integrity_segments");
   unsigned short ioprio ;
   void *special ;
   int tag ;
    klee_make_symbolic(&tag, sizeof(int), "tag");
   int errors ;
    klee_make_symbolic(&errors, sizeof(int), "errors");
   unsigned char __cmd[16U] ;
   unsigned char *cmd ;
   unsigned short cmd_len ;
    klee_make_symbolic(&cmd_len, sizeof(short), "cmd_len");
   unsigned int extra_len ;
    klee_make_symbolic(&extra_len, sizeof(int), "extra_len");
   unsigned int sense_len ;
    klee_make_symbolic(&sense_len, sizeof(int), "sense_len");
   unsigned int resid_len ;
    klee_make_symbolic(&resid_len, sizeof(int), "resid_len");
   void *sense ;
   unsigned long deadline ;
    klee_make_symbolic(&deadline, sizeof(long), "deadline");
   struct list_head timeout_list ;
   unsigned int timeout ;
   int retries ;
    klee_make_symbolic(&retries, sizeof(int), "retries");
   rq_end_io_fn *end_io ;
   void *end_io_data ;
   struct request *next_rq ;
};
struct elevator_type;
typedef int elevator_merge_fn(struct request_queue * , struct request ** , struct bio * );
typedef void elevator_merge_req_fn(struct request_queue * , struct request * , struct request * );
typedef void elevator_merged_fn(struct request_queue * , struct request * , int  );
typedef int elevator_allow_merge_fn(struct request_queue * , struct request * , struct bio * );
typedef void elevator_bio_merged_fn(struct request_queue * , struct request * , struct bio * );
typedef int elevator_dispatch_fn(struct request_queue * , int  );
typedef void elevator_add_req_fn(struct request_queue * , struct request * );
typedef struct request *elevator_request_list_fn(struct request_queue * , struct request * );
typedef void elevator_completed_req_fn(struct request_queue * , struct request * );
typedef int elevator_may_queue_fn(struct request_queue * , int  );
typedef void elevator_init_icq_fn(struct io_cq * );
typedef void elevator_exit_icq_fn(struct io_cq * );
typedef int elevator_set_req_fn(struct request_queue * , struct request * , struct bio * ,
                                gfp_t  );
typedef void elevator_put_req_fn(struct request * );
typedef void elevator_activate_req_fn(struct request_queue * , struct request * );
typedef void elevator_deactivate_req_fn(struct request_queue * , struct request * );
typedef int elevator_init_fn(struct request_queue * , struct elevator_type * );
typedef void elevator_exit_fn(struct elevator_queue * );
typedef void elevator_registered_fn(struct request_queue * );
struct elevator_ops {
   elevator_merge_fn *elevator_merge_fn ;
   elevator_merged_fn *elevator_merged_fn ;
   elevator_merge_req_fn *elevator_merge_req_fn ;
   elevator_allow_merge_fn *elevator_allow_merge_fn ;
   elevator_bio_merged_fn *elevator_bio_merged_fn ;
   elevator_dispatch_fn *elevator_dispatch_fn ;
   elevator_add_req_fn *elevator_add_req_fn ;
   elevator_activate_req_fn *elevator_activate_req_fn ;
   elevator_deactivate_req_fn *elevator_deactivate_req_fn ;
   elevator_completed_req_fn *elevator_completed_req_fn ;
   elevator_request_list_fn *elevator_former_req_fn ;
   elevator_request_list_fn *elevator_latter_req_fn ;
   elevator_init_icq_fn *elevator_init_icq_fn ;
   elevator_exit_icq_fn *elevator_exit_icq_fn ;
   elevator_set_req_fn *elevator_set_req_fn ;
   elevator_put_req_fn *elevator_put_req_fn ;
   elevator_may_queue_fn *elevator_may_queue_fn ;
   elevator_init_fn *elevator_init_fn ;
   elevator_exit_fn *elevator_exit_fn ;
   elevator_registered_fn *elevator_registered_fn ;
};
struct elv_fs_entry {
   struct attribute attr ;
   ssize_t (*show)(struct elevator_queue * , char * ) ;
   ssize_t (*store)(struct elevator_queue * , char const   * , size_t  ) ;
};
struct elevator_type {
   struct kmem_cache *icq_cache ;
   struct elevator_ops ops ;
   size_t icq_size ;
   size_t icq_align ;
   struct elv_fs_entry *elevator_attrs ;
   char elevator_name[16U] ;
   struct module *elevator_owner ;
   char icq_cache_name[21U] ;
   struct list_head list ;
};
struct elevator_queue {
   struct elevator_type *type ;
   void *elevator_data ;
   struct kobject kobj ;
   struct mutex sysfs_lock ;
   unsigned char registered : 1 ;
   struct hlist_head hash[64U] ;
};
typedef void request_fn_proc(struct request_queue * );
typedef void make_request_fn(struct request_queue * , struct bio * );
typedef int prep_rq_fn(struct request_queue * , struct request * );
typedef void unprep_rq_fn(struct request_queue * , struct request * );
struct bvec_merge_data {
   struct block_device *bi_bdev ;
   sector_t bi_sector ;
   unsigned int bi_size ;
   unsigned long bi_rw ;
};
typedef int merge_bvec_fn(struct request_queue * , struct bvec_merge_data * , struct bio_vec * );
typedef void softirq_done_fn(struct request * );
typedef int dma_drain_needed_fn(struct request * );
typedef int lld_busy_fn(struct request_queue * );
typedef int bsg_job_fn(struct bsg_job * );
enum blk_eh_timer_return {
    BLK_EH_NOT_HANDLED = 0,
    BLK_EH_HANDLED = 1,
    BLK_EH_RESET_TIMER = 2
} ;
typedef enum blk_eh_timer_return rq_timed_out_fn(struct request * );
struct blk_queue_tag {
   struct request **tag_index ;
   unsigned long *tag_map ;
   int busy ;
    klee_make_symbolic(&busy, sizeof(int), "busy");
   int max_depth ;
    klee_make_symbolic(&max_depth, sizeof(int), "max_depth");
   int real_max_depth ;
    klee_make_symbolic(&real_max_depth, sizeof(int), "real_max_depth");
   atomic_t refcnt ;
   int alloc_policy ;
    klee_make_symbolic(&alloc_policy, sizeof(int), "alloc_policy");
   int next_tag ;
    klee_make_symbolic(&next_tag, sizeof(int), "next_tag");
};
struct queue_limits {
   unsigned long bounce_pfn ;
    klee_make_symbolic(&bounce_pfn, sizeof(long), "bounce_pfn");
   unsigned long seg_boundary_mask ;
    klee_make_symbolic(&seg_boundary_mask, sizeof(long), "seg_boundary_mask");
   unsigned int max_hw_sectors ;
    klee_make_symbolic(&max_hw_sectors, sizeof(int), "max_hw_sectors");
   unsigned int chunk_sectors ;
    klee_make_symbolic(&chunk_sectors, sizeof(int), "chunk_sectors");
   unsigned int max_sectors ;
    klee_make_symbolic(&max_sectors, sizeof(int), "max_sectors");
   unsigned int max_segment_size ;
   unsigned int physical_block_size ;
    klee_make_symbolic(&physical_block_size, sizeof(int), "physical_block_size");
   unsigned int alignment_offset ;
    klee_make_symbolic(&alignment_offset, sizeof(int), "alignment_offset");
   unsigned int io_min ;
    klee_make_symbolic(&io_min, sizeof(int), "io_min");
   unsigned int io_opt ;
    klee_make_symbolic(&io_opt, sizeof(int), "io_opt");
   unsigned int max_discard_sectors ;
    klee_make_symbolic(&max_discard_sectors, sizeof(int), "max_discard_sectors");
   unsigned int max_write_same_sectors ;
    klee_make_symbolic(&max_write_same_sectors, sizeof(int), "max_write_same_sectors");
   unsigned int discard_granularity ;
    klee_make_symbolic(&discard_granularity, sizeof(int), "discard_granularity");
   unsigned int discard_alignment ;
   unsigned short logical_block_size ;
    klee_make_symbolic(&logical_block_size, sizeof(short), "logical_block_size");
   unsigned short max_segments ;
    klee_make_symbolic(&max_segments, sizeof(short), "max_segments");
   unsigned short max_integrity_segments ;
    klee_make_symbolic(&max_integrity_segments, sizeof(short), "max_integrity_segments");
   unsigned char misaligned ;
    klee_make_symbolic(&misaligned, sizeof(char), "misaligned");
   unsigned char discard_misaligned ;
    klee_make_symbolic(&discard_misaligned, sizeof(char), "discard_misaligned");
   unsigned char cluster ;
    klee_make_symbolic(&cluster, sizeof(char), "cluster");
   unsigned char discard_zeroes_data ;
    klee_make_symbolic(&discard_zeroes_data, sizeof(char), "discard_zeroes_data");
   unsigned char raid_partial_stripes_expensive ;
    klee_make_symbolic(&raid_partial_stripes_expensive, sizeof(char), "raid_partial_stripes_expensive");
};
struct blk_mq_ops;
struct blk_mq_hw_ctx;
struct throtl_data;
struct blk_mq_tag_set;
struct request_queue {
   struct list_head queue_head ;
   struct request *last_merge ;
   struct elevator_queue *elevator ;
   int nr_rqs[2U] ;
   int nr_rqs_elvpriv ;
    klee_make_symbolic(&nr_rqs_elvpriv, sizeof(int), "nr_rqs_elvpriv");
   struct request_list root_rl ;
   request_fn_proc *request_fn ;
   make_request_fn *make_request_fn ;
   prep_rq_fn *prep_rq_fn ;
   unprep_rq_fn *unprep_rq_fn ;
   merge_bvec_fn *merge_bvec_fn ;
   softirq_done_fn *softirq_done_fn ;
   rq_timed_out_fn *rq_timed_out_fn ;
   dma_drain_needed_fn *dma_drain_needed ;
   lld_busy_fn *lld_busy_fn ;
   struct blk_mq_ops *mq_ops ;
   unsigned int *mq_map ;
   struct blk_mq_ctx *queue_ctx ;
   unsigned int nr_queues ;
    klee_make_symbolic(&nr_queues, sizeof(int), "nr_queues");
   struct blk_mq_hw_ctx **queue_hw_ctx ;
   unsigned int nr_hw_queues ;
    klee_make_symbolic(&nr_hw_queues, sizeof(int), "nr_hw_queues");
   sector_t end_sector ;
   struct request *boundary_rq ;
   struct delayed_work delay_work ;
   struct backing_dev_info backing_dev_info ;
   void *queuedata ;
   unsigned long queue_flags ;
    klee_make_symbolic(&queue_flags, sizeof(long), "queue_flags");
   int id ;
   gfp_t bounce_gfp ;
   spinlock_t __queue_lock ;
   spinlock_t *queue_lock ;
   struct kobject kobj ;
   struct kobject mq_kobj ;
   struct device *dev ;
   int rpm_status ;
    klee_make_symbolic(&rpm_status, sizeof(int), "rpm_status");
   unsigned int nr_pending ;
    klee_make_symbolic(&nr_pending, sizeof(int), "nr_pending");
   unsigned long nr_requests ;
    klee_make_symbolic(&nr_requests, sizeof(long), "nr_requests");
   unsigned int nr_congestion_on ;
    klee_make_symbolic(&nr_congestion_on, sizeof(int), "nr_congestion_on");
   unsigned int nr_congestion_off ;
    klee_make_symbolic(&nr_congestion_off, sizeof(int), "nr_congestion_off");
   unsigned int nr_batching ;
    klee_make_symbolic(&nr_batching, sizeof(int), "nr_batching");
   unsigned int dma_drain_size ;
    klee_make_symbolic(&dma_drain_size, sizeof(int), "dma_drain_size");
   void *dma_drain_buffer ;
   unsigned int dma_pad_mask ;
    klee_make_symbolic(&dma_pad_mask, sizeof(int), "dma_pad_mask");
   unsigned int dma_alignment ;
    klee_make_symbolic(&dma_alignment, sizeof(int), "dma_alignment");
   struct blk_queue_tag *queue_tags ;
   struct list_head tag_busy_list ;
   unsigned int nr_sorted ;
    klee_make_symbolic(&nr_sorted, sizeof(int), "nr_sorted");
   unsigned int in_flight[2U] ;
   unsigned int request_fn_active ;
    klee_make_symbolic(&request_fn_active, sizeof(int), "request_fn_active");
   unsigned int rq_timeout ;
    klee_make_symbolic(&rq_timeout, sizeof(int), "rq_timeout");
   struct timer_list timeout ;
   struct list_head timeout_list ;
   struct list_head icq_list ;
   unsigned long blkcg_pols[1U] ;
   struct blkcg_gq *root_blkg ;
   struct list_head blkg_list ;
   struct queue_limits limits ;
   unsigned int sg_timeout ;
    klee_make_symbolic(&sg_timeout, sizeof(int), "sg_timeout");
   unsigned int sg_reserved_size ;
    klee_make_symbolic(&sg_reserved_size, sizeof(int), "sg_reserved_size");
   int node ;
    klee_make_symbolic(&node, sizeof(int), "node");
   unsigned int flush_flags ;
    klee_make_symbolic(&flush_flags, sizeof(int), "flush_flags");
   unsigned char flush_not_queueable : 1 ;
   struct blk_flush_queue *fq ;
   struct list_head requeue_list ;
   spinlock_t requeue_lock ;
   struct work_struct requeue_work ;
   struct mutex sysfs_lock ;
   int bypass_depth ;
    klee_make_symbolic(&bypass_depth, sizeof(int), "bypass_depth");
   atomic_t mq_freeze_depth ;
   bsg_job_fn *bsg_job_fn ;
   int bsg_job_size ;
    klee_make_symbolic(&bsg_job_size, sizeof(int), "bsg_job_size");
   struct bsg_class_device bsg_dev ;
   struct throtl_data *td ;
   struct callback_head callback_head ;
   wait_queue_head_t mq_freeze_wq ;
   struct percpu_ref mq_usage_counter ;
   struct list_head all_q_node ;
   struct blk_mq_tag_set *tag_set ;
   struct list_head tag_set_list ;
};
struct blk_plug {
   struct list_head list ;
   struct list_head mq_list ;
   struct list_head cb_list ;
};
struct blk_integrity_iter {
   void *prot_buf ;
   void *data_buf ;
   sector_t seed ;
   unsigned int data_size ;
    klee_make_symbolic(&data_size, sizeof(int), "data_size");
   unsigned short interval ;
   char const   *disk_name ;
};
typedef int integrity_processing_fn(struct blk_integrity_iter * );
struct blk_integrity {
   integrity_processing_fn *generate_fn ;
   integrity_processing_fn *verify_fn ;
   unsigned short flags ;
   unsigned short tuple_size ;
    klee_make_symbolic(&tuple_size, sizeof(short), "tuple_size");
   unsigned short interval ;
   unsigned short tag_size ;
    klee_make_symbolic(&tag_size, sizeof(short), "tag_size");
   char const   *name ;
   struct kobject kobj ;
};
struct block_device_operations {
   int (*open)(struct block_device * , fmode_t  ) ;
   void (*release)(struct gendisk * , fmode_t  ) ;
   int (*rw_page)(struct block_device * , sector_t  , struct page * , int  ) ;
   int (*ioctl)(struct block_device * , fmode_t  , unsigned int  , unsigned long  ) ;
   int (*compat_ioctl)(struct block_device * , fmode_t  , unsigned int  , unsigned long  ) ;
   long (*direct_access)(struct block_device * , sector_t  , void ** , unsigned long * ,
                         long  ) ;
   unsigned int (*check_events)(struct gendisk * , unsigned int  ) ;
   int (*media_changed)(struct gendisk * ) ;
   void (*unlock_native_capacity)(struct gendisk * ) ;
   int (*revalidate_disk)(struct gendisk * ) ;
   int (*getgeo)(struct block_device * , struct hd_geometry * ) ;
   void (*swap_slot_free_notify)(struct block_device * , unsigned long  ) ;
   struct module *owner ;
};
struct fc_frame_header {
   __u8 fh_r_ctl ;
   __u8 fh_d_id[3U] ;
   __u8 fh_cs_ctl ;
   __u8 fh_s_id[3U] ;
   __u8 fh_type ;
   __u8 fh_f_ctl[3U] ;
   __u8 fh_seq_id ;
   __u8 fh_df_ctl ;
   __be16 fh_seq_cnt ;
   __be16 fh_ox_id ;
   __be16 fh_rx_id ;
   __be32 fh_parm_offset ;
};
struct fcoe_hdr {
   __u8 fcoe_ver ;
   __u8 fcoe_resvd[12U] ;
   __u8 fcoe_sof ;
};
struct fcoe_crc_eof {
   __le32 fcoe_crc32 ;
   __u8 fcoe_eof ;
   __u8 fcoe_resvd[3U] ;
};
struct blk_mq_tags;
struct blk_mq_cpu_notifier {
   struct list_head list ;
   void *data ;
   int (*notify)(void * , unsigned long  , unsigned int  ) ;
};
struct blk_align_bitmap;
struct blk_mq_ctxmap {
   unsigned int size ;
   unsigned int bits_per_word ;
    klee_make_symbolic(&bits_per_word, sizeof(int), "bits_per_word");
   struct blk_align_bitmap *map ;
};
struct __anonstruct____missing_field_name_278 {
   spinlock_t lock ;
   struct list_head dispatch ;
};
struct blk_mq_hw_ctx {
   struct __anonstruct____missing_field_name_278 __annonCompField98 ;
   unsigned long state ;
   struct delayed_work run_work ;
   struct delayed_work delay_work ;
   cpumask_var_t cpumask ;
   int next_cpu ;
    klee_make_symbolic(&next_cpu, sizeof(int), "next_cpu");
   int next_cpu_batch ;
    klee_make_symbolic(&next_cpu_batch, sizeof(int), "next_cpu_batch");
   unsigned long flags ;
   struct request_queue *queue ;
   struct blk_flush_queue *fq ;
   void *driver_data ;
   struct blk_mq_ctxmap ctx_map ;
   unsigned int nr_ctx ;
    klee_make_symbolic(&nr_ctx, sizeof(int), "nr_ctx");
   struct blk_mq_ctx **ctxs ;
   atomic_t wait_index ;
   struct blk_mq_tags *tags ;
   unsigned long queued ;
    klee_make_symbolic(&queued, sizeof(long), "queued");
   unsigned long run ;
    klee_make_symbolic(&run, sizeof(long), "run");
   unsigned long dispatched[10U] ;
   unsigned int numa_node ;
   unsigned int queue_num ;
    klee_make_symbolic(&queue_num, sizeof(int), "queue_num");
   atomic_t nr_active ;
   struct blk_mq_cpu_notifier cpu_notifier ;
   struct kobject kobj ;
};
struct blk_mq_tag_set {
   struct blk_mq_ops *ops ;
   unsigned int nr_hw_queues ;
   unsigned int queue_depth ;
    klee_make_symbolic(&queue_depth, sizeof(int), "queue_depth");
   unsigned int reserved_tags ;
    klee_make_symbolic(&reserved_tags, sizeof(int), "reserved_tags");
   unsigned int cmd_size ;
    klee_make_symbolic(&cmd_size, sizeof(int), "cmd_size");
   int numa_node ;
   unsigned int timeout ;
   unsigned int flags ;
   void *driver_data ;
   struct blk_mq_tags **tags ;
   struct mutex tag_list_lock ;
   struct list_head tag_list ;
};
struct blk_mq_queue_data {
   struct request *rq ;
   struct list_head *list ;
   bool last ;
};
typedef int queue_rq_fn(struct blk_mq_hw_ctx * , struct blk_mq_queue_data  const  * );
typedef struct blk_mq_hw_ctx *map_queue_fn(struct request_queue * , int const    );
typedef enum blk_eh_timer_return timeout_fn(struct request * , bool  );
typedef int init_hctx_fn(struct blk_mq_hw_ctx * , void * , unsigned int  );
typedef void exit_hctx_fn(struct blk_mq_hw_ctx * , unsigned int  );
typedef int init_request_fn(void * , struct request * , unsigned int  , unsigned int  ,
                            unsigned int  );
typedef void exit_request_fn(void * , struct request * , unsigned int  , unsigned int  );
struct blk_mq_ops {
   queue_rq_fn *queue_rq ;
   map_queue_fn *map_queue ;
   timeout_fn *timeout ;
   softirq_done_fn *complete ;
   init_hctx_fn *init_hctx ;
   exit_hctx_fn *exit_hctx ;
   init_request_fn *init_request ;
   exit_request_fn *exit_request ;
};
struct i40e_fcoe_ddp_context_desc {
   __le64 rsvd ;
   __le64 type_cmd_foff_lsize ;
};
struct i40e_fcoe_queue_context_desc {
   __le64 dmaindx_fbase ;
   __le64 flen_tph ;
};
struct i40e_fcoe_filter_context_desc {
   __le32 param ;
   __le16 seqn ;
   __le16 rsvd_dmaindx ;
   __le64 flags_rsvd_lanq ;
};
__inline static long ldv__builtin_expect(long exp , long c ) ;
__inline static void __read_once_size(void const volatile   *p , void *res , int size ) 
{ 


  {
  switch (size) {
  case 1: 
  *((__u8 *)res) = *((__u8 volatile   *)p);
  goto ldv_880;
  case 2: 
  *((__u16 *)res) = *((__u16 volatile   *)p);
  goto ldv_880;
  case 4: 
  *((__u32 *)res) = *((__u32 volatile   *)p);
  goto ldv_880;
  case 8: 
  *((__u64 *)res) = *((__u64 volatile   *)p);
  goto ldv_880;
  default: 
  __asm__  volatile   ("": : : "memory");
  memcpy(res, (void const   *)p, (unsigned long )size);
  __asm__  volatile   ("": : : "memory");
  }
  ldv_880: ;
  return;
}
}
extern struct module __this_module ;
__inline static void set_bit(long nr , unsigned long volatile   *addr ) 
{ 


  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; bts %1,%0": "+m" (*((long volatile   *)addr)): "Ir" (nr): "memory");
  return;
}
}
__inline static void clear_bit(long nr , unsigned long volatile   *addr ) 
{ 


  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; btr %1,%0": "+m" (*((long volatile   *)addr)): "Ir" (nr));
  return;
}
}
__inline static int test_and_set_bit(long nr , unsigned long volatile   *addr ) 
{ 
  char c ;
    klee_make_symbolic(&c, sizeof(char), "c");

  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; bts %2, %0; setc %1": "+m" (*addr),
                       "=qm" (c): "Ir" (nr): "memory");
  return ((int )((signed char )c) != 0);
}
}
__inline static int test_and_clear_bit(long nr , unsigned long volatile   *addr ) 
{ 
  char c ;

  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; btr %2, %0; setc %1": "+m" (*addr),
                       "=qm" (c): "Ir" (nr): "memory");
  return ((int )((signed char )c) != 0);
}
}
__inline static int constant_test_bit(long nr , unsigned long const volatile   *addr ) 
{ 


  {
  return ((int )((unsigned long )*(addr + (unsigned long )(nr >> 6)) >> ((int )nr & 63)) & 1);
}
}
extern unsigned long find_next_bit(unsigned long const   * , unsigned long  , unsigned long  ) ;
extern unsigned long find_first_bit(unsigned long const   * , unsigned long  ) ;
__inline static __u16 __fswab16(__u16 val ) 
{ 


  {
  return ((__u16 )((int )((short )((int )val << 8)) | (int )((short )((int )val >> 8))));
}
}
extern int printk(char const   *  , ...) ;
extern void __dynamic_dev_dbg(struct _ddebug * , struct device  const  * , char const   * 
                              , ...) ;
extern int sprintf(char * , char const   *  , ...) ;
extern int snprintf(char * , size_t  , char const   *  , ...) ;
extern enum system_states system_state ;
extern void __bad_percpu_size(void) ;
extern void __bad_size_call_parameter(void) ;
__inline static void INIT_LIST_HEAD(struct list_head *list ) 
{ 


  {
  list->next = list;
  list->prev = list;
  return;
}
}
extern void __list_add(struct list_head * , struct list_head * , struct list_head * ) ;
__inline static void list_add(struct list_head *new , struct list_head *head ) 
{ 


  {
  __list_add(new, head, head->next);
  return;
}
}
extern void list_del(struct list_head * ) ;
__inline static int list_empty(struct list_head  const  *head ) 
{ 


  {
  return ((unsigned long )((struct list_head  const  *)head->next) == (unsigned long )head);
}
}
__inline static void __hlist_del(struct hlist_node *n ) 
{ 
  struct hlist_node *next ;
  struct hlist_node **pprev ;

  {
  next = n->next;
  pprev = n->pprev;
  *pprev = next;
  if ((unsigned long )next != (unsigned long )((struct hlist_node *)0)) {
    next->pprev = pprev;
  } else {

  }
  return;
}
}
__inline static void hlist_del(struct hlist_node *n ) 
{ 


  {
  __hlist_del(n);
  n->next = (struct hlist_node *)-2401263026317557504L;
  n->pprev = (struct hlist_node **)-2401263026316508672L;
  return;
}
}
extern void *memcpy(void * , void const   * , size_t  ) ;
extern void *memmove(void * , void const   * , size_t  ) ;
extern void *memset(void * , int  , size_t  ) ;
extern int memcmp(void const   * , void const   * , size_t  ) ;
extern char *strncpy(char * , char const   * , __kernel_size_t  ) ;
extern size_t strlcpy(char * , char const   * , size_t  ) ;
extern int __bitmap_weight(unsigned long const   * , unsigned int  ) ;
__inline static void bitmap_zero(unsigned long *dst , unsigned int nbits ) 
{ 
  unsigned int len ;

  {
  len = (unsigned int )(((unsigned long )nbits + 63UL) / 64UL) * 8U;
  memset((void *)dst, 0, (size_t )len);
  return;
}
}
__inline static int bitmap_weight(unsigned long const   *src , unsigned int nbits ) 
{ 
  int tmp___0 ;
    klee_make_symbolic(&tmp___0, sizeof(int), "tmp___0");

  {
  tmp___0 = __bitmap_weight(src, nbits);
  return (tmp___0);
}
}
extern void warn_slowpath_null(char const   * , int const    ) ;
extern int nr_cpu_ids ;
    klee_make_symbolic(&nr_cpu_ids, sizeof(int), "nr_cpu_ids");
extern struct cpumask  const  * const  cpu_online_mask ;
__inline static unsigned int cpumask_check(unsigned int cpu ) 
{ 
  bool __warned ;
  int __ret_warn_once ;
    klee_make_symbolic(&__ret_warn_once, sizeof(int), "__ret_warn_once");
  int __ret_warn_on ;
    klee_make_symbolic(&__ret_warn_on, sizeof(int), "__ret_warn_on");
  long tmp ;
  long tmp___0 ;
  long tmp___1 ;
    klee_make_symbolic(&tmp___1, sizeof(long), "tmp___1");

  {
  __ret_warn_once = (unsigned int )nr_cpu_ids <= cpu;
  tmp___1 = ldv__builtin_expect(__ret_warn_once != 0, 0L);
  if (tmp___1 != 0L) {
    __ret_warn_on = ! __warned;
    tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp != 0L) {
      warn_slowpath_null("include/linux/cpumask.h", 117);
    } else {

    }
    tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___0 != 0L) {
      __warned = 1;
    } else {

    }
  } else {

  }
  ldv__builtin_expect(__ret_warn_once != 0, 0L);
  return (cpu);
}
}
__inline static void cpumask_set_cpu(unsigned int cpu , struct cpumask *dstp ) 
{ 
  unsigned int tmp ;

  {
  tmp = cpumask_check(cpu);
  set_bit((long )tmp, (unsigned long volatile   *)(& dstp->bits));
  return;
}
}
__inline static unsigned int cpumask_weight(struct cpumask  const  *srcp ) 
{ 
  int tmp ;
    klee_make_symbolic(&tmp, sizeof(int), "tmp");

  {
  tmp = bitmap_weight((unsigned long const   *)(& srcp->bits), (unsigned int )nr_cpu_ids);
  return ((unsigned int )tmp);
}
}
extern bool alloc_cpumask_var(cpumask_var_t ** , gfp_t  ) ;
extern void free_cpumask_var(cpumask_var_t  ) ;
extern void lockdep_init_map(struct lockdep_map * , char const   * , struct lock_class_key * ,
                             int  ) ;
extern void lock_acquire(struct lockdep_map * , unsigned int  , int  , int  , int  ,
                         struct lockdep_map * , unsigned long  ) ;
extern void lock_release(struct lockdep_map * , int  , unsigned long  ) ;
extern void lockdep_rcu_suspicious(char const   * , int const    , char const   * ) ;
extern void __mutex_init(struct mutex * , char const   * , struct lock_class_key * ) ;
extern int mutex_trylock(struct mutex * ) ;
int ldv_mutex_trylock_13(struct mutex *ldv_func_arg1 ) ;
extern void mutex_unlock(struct mutex * ) ;
void ldv_mutex_unlock_11(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_14(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_15(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_26(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_28(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_38(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_40(struct mutex *ldv_func_arg1 ) ;
extern void *malloc(size_t  ) ;
extern void *calloc(size_t  , size_t  ) ;
extern int __VERIFIER_nondet_int(void) ;
extern unsigned long __VERIFIER_nondet_ulong(void) ;
extern void abort(void);
void assume_abort_if_not(int cond) {
  if(!cond) {abort();}
}
__inline static bool IS_ERR(void const *ptr ) ;

void *ldv_malloc(size_t size ) 
{ 
  void *p ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp___0 = __VERIFIER_nondet_int();
  if (tmp___0 != 0) {
    return ((void *)0);
  } else {
    tmp = malloc(size);
    p = tmp;
    assume_abort_if_not((unsigned long )p != (unsigned long )((void *)0));
    assume_abort_if_not(IS_ERR(p) == 0);
    return (p);
  }
}
}
void *ldv_zalloc(size_t size ) 
{ 
  void *p ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp___0 = __VERIFIER_nondet_int();
  if (tmp___0 != 0) {
    return ((void *)0);
  } else {
    tmp = calloc(1UL, size);
    p = tmp;
    assume_abort_if_not((unsigned long )p != (unsigned long )((void *)0));
    assume_abort_if_not(IS_ERR(p) == 0);
    return (p);
  }
}
}
void *ldv_init_zalloc(size_t size ) 
{ 
  void *p ;
  void *tmp ;

  {
  tmp = calloc(1UL, size);
  p = tmp;
  assume_abort_if_not((unsigned long )p != (unsigned long )((void *)0));
  return (p);
}
}
void *ldv_memset(void *s , int c , size_t n ) 
{ 
  void *tmp ;

  {
  tmp = memset(s, c, n);
  return (tmp);
}
}
int ldv_undef_int(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  return (tmp);
}
}
unsigned long ldv_undef_ulong(void) 
{ 
  unsigned long tmp ;

  {
  tmp = __VERIFIER_nondet_ulong();
  return (tmp);
}
}
__inline static void ldv_stop(void) 
{ 


  {
  LDV_STOP: ;
  goto LDV_STOP;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) 
{ 


  {
  return (exp);
}
}
extern void mutex_lock(struct mutex * ) ;
void ldv_mutex_lock_10(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_12(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_16(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_25(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_27(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_37(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_39(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_i_mutex_of_inode(struct mutex *lock ) ;
void ldv_mutex_unlock_i_mutex_of_inode(struct mutex *lock ) ;
void ldv_mutex_lock_lock(struct mutex *lock ) ;
void ldv_mutex_unlock_lock(struct mutex *lock ) ;
void ldv_mutex_lock_mutex_of_device(struct mutex *lock ) ;
int ldv_mutex_trylock_mutex_of_device(struct mutex *lock ) ;
void ldv_mutex_unlock_mutex_of_device(struct mutex *lock ) ;
void ldv_mutex_lock_switch_mutex_of_i40e_pf(struct mutex *lock ) ;
void ldv_mutex_unlock_switch_mutex_of_i40e_pf(struct mutex *lock ) ;
extern int __preempt_count ;
    klee_make_symbolic(&__preempt_count, sizeof(int), "__preempt_count");
__inline static int preempt_count(void) 
{ 
  int pfo_ret__ ;
    klee_make_symbolic(&pfo_ret__, sizeof(int), "pfo_ret__");

  {
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (__preempt_count));
  goto ldv_6584;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (__preempt_count));
  goto ldv_6584;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (__preempt_count));
  goto ldv_6584;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (__preempt_count));
  goto ldv_6584;
  default: 
  __bad_percpu_size();
  }
  ldv_6584: ;
  return (pfo_ret__ & 2147483647);
}
}
__inline static void __preempt_count_add(int val ) 
{ 
  int pao_ID__ ;
    klee_make_symbolic(&pao_ID__, sizeof(int), "pao_ID__");

  {
  pao_ID__ = 0;
  switch (4UL) {
  case 1UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incb %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decb %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addb %1, %%gs:%0": "+m" (__preempt_count): "qi" (val));
  }
  goto ldv_6641;
  case 2UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incw %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decw %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addw %1, %%gs:%0": "+m" (__preempt_count): "ri" (val));
  }
  goto ldv_6641;
  case 4UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incl %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decl %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addl %1, %%gs:%0": "+m" (__preempt_count): "ri" (val));
  }
  goto ldv_6641;
  case 8UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incq %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decq %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addq %1, %%gs:%0": "+m" (__preempt_count): "re" (val));
  }
  goto ldv_6641;
  default: 
  __bad_percpu_size();
  }
  ldv_6641: ;
  return;
}
}
__inline static void __preempt_count_sub(int val ) 
{ 
  int pao_ID__ ;

  {
  pao_ID__ = 0;
  switch (4UL) {
  case 1UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incb %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decb %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addb %1, %%gs:%0": "+m" (__preempt_count): "qi" (- val));
  }
  goto ldv_6653;
  case 2UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incw %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decw %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addw %1, %%gs:%0": "+m" (__preempt_count): "ri" (- val));
  }
  goto ldv_6653;
  case 4UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incl %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decl %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addl %1, %%gs:%0": "+m" (__preempt_count): "ri" (- val));
  }
  goto ldv_6653;
  case 8UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incq %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decq %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addq %1, %%gs:%0": "+m" (__preempt_count): "re" (- val));
  }
  goto ldv_6653;
  default: 
  __bad_percpu_size();
  }
  ldv_6653: ;
  return;
}
}
extern void __local_bh_disable_ip(unsigned long  , unsigned int  ) ;
__inline static void local_bh_disable(void) 
{ 


  {
  __local_bh_disable_ip(0UL, 512U);
  return;
}
}
extern void __local_bh_enable_ip(unsigned long  , unsigned int  ) ;
__inline static void local_bh_enable(void) 
{ 


  {
  __local_bh_enable_ip(0UL, 512U);
  return;
}
}
extern void _raw_spin_lock(raw_spinlock_t * ) ;
extern void _raw_spin_unlock(raw_spinlock_t * ) ;
__inline static void spin_lock(spinlock_t *lock ) 
{ 


  {
  _raw_spin_lock(& lock->__annonCompField17.rlock);
  return;
}
}
__inline static void spin_unlock(spinlock_t *lock ) 
{ 


  {
  _raw_spin_unlock(& lock->__annonCompField17.rlock);
  return;
}
}
extern unsigned long volatile   jiffies ;
extern int mod_timer(struct timer_list * , unsigned long  ) ;
int ldv_mod_timer_24(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_41(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
extern int del_timer_sync(struct timer_list * ) ;
int ldv_del_timer_sync_42(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_43(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_45(struct timer_list *ldv_func_arg1 ) ;
__inline static void __rcu_read_lock(void) 
{ 


  {
  __preempt_count_add(1);
  __asm__  volatile   ("": : : "memory");
  return;
}
}
__inline static void __rcu_read_unlock(void) 
{ 


  {
  __asm__  volatile   ("": : : "memory");
  __preempt_count_sub(1);
  return;
}
}
extern void kfree_call_rcu(struct callback_head * , void (*)(struct callback_head * ) ) ;
extern bool rcu_is_watching(void) ;
__inline static void rcu_lock_acquire(struct lockdep_map *map ) 
{ 


  {
  lock_acquire(map, 0U, 0, 2, 0, (struct lockdep_map *)0, 0UL);
  return;
}
}
__inline static void rcu_lock_release(struct lockdep_map *map ) 
{ 


  {
  lock_release(map, 1, 0UL);
  return;
}
}
extern struct lockdep_map rcu_lock_map ;
extern int debug_lockdep_rcu_enabled(void) ;
__inline static void rcu_read_lock(void) 
{ 
  bool __warned ;
  int tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  __rcu_read_lock();
  rcu_lock_acquire(& rcu_lock_map);
  tmp = debug_lockdep_rcu_enabled();
  if (tmp != 0 && ! __warned) {
    tmp___0 = rcu_is_watching();
    if (tmp___0) {
      tmp___1 = 0;
    } else {
      tmp___1 = 1;
    }
    if (tmp___1) {
      __warned = 1;
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 849, "rcu_read_lock() used illegally while idle");
    } else {

    }
  } else {

  }
  return;
}
}
__inline static void rcu_read_unlock(void) 
{ 
  bool __warned ;
  int tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  tmp = debug_lockdep_rcu_enabled();
  if (tmp != 0 && ! __warned) {
    tmp___0 = rcu_is_watching();
    if (tmp___0) {
      tmp___1 = 0;
    } else {
      tmp___1 = 1;
    }
    if (tmp___1) {
      __warned = 1;
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 900, "rcu_read_unlock() used illegally while idle");
    } else {

    }
  } else {

  }
  __rcu_read_unlock();
  rcu_lock_release(& rcu_lock_map);
  return;
}
}
extern unsigned long round_jiffies(unsigned long  ) ;
extern void __init_work(struct work_struct * , int  ) ;
extern struct workqueue_struct *system_wq ;
extern bool queue_work_on(int  , struct workqueue_struct * , struct work_struct * ) ;
bool ldv_queue_work_on_5(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                         struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_7(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                         struct work_struct *ldv_func_arg3 ) ;
extern bool queue_delayed_work_on(int  , struct workqueue_struct * , struct delayed_work * ,
                                  unsigned long  ) ;
bool ldv_queue_delayed_work_on_6(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                 struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_9(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                 struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
extern void flush_workqueue(struct workqueue_struct * ) ;
void ldv_flush_workqueue_8(struct workqueue_struct *ldv_func_arg1 ) ;
extern bool cancel_work_sync(struct work_struct * ) ;
bool ldv_cancel_work_sync_44(struct work_struct *ldv_func_arg1 ) ;
bool ldv_cancel_work_sync_46(struct work_struct *ldv_func_arg1 ) ;
__inline static bool queue_work(struct workqueue_struct *wq , struct work_struct *work ) 
{ 
  bool tmp ;

  {
  tmp = ldv_queue_work_on_5(8192, wq, work);
  return (tmp);
}
}
__inline static bool schedule_work(struct work_struct *work ) 
{ 
  bool tmp ;

  {
  tmp = queue_work(system_wq, work);
  return (tmp);
}
}
__inline static unsigned int readl(void const volatile   *addr ) 
{ 
  unsigned int ret ;
    klee_make_symbolic(&ret, sizeof(int), "ret");

  {
  __asm__  volatile   ("movl %1,%0": "=r" (ret): "m" (*((unsigned int volatile   *)addr)): "memory");
  return (ret);
}
}
__inline static void writel(unsigned int val , void volatile   *addr ) 
{ 


  {
  __asm__  volatile   ("movl %0,%1": : "r" (val), "m" (*((unsigned int volatile   *)addr)): "memory");
  return;
}
}
__inline static unsigned long readq(void const volatile   *addr ) 
{ 
  unsigned long ret ;

  {
  __asm__  volatile   ("movq %1,%0": "=r" (ret): "m" (*((unsigned long volatile   *)addr)): "memory");
  return (ret);
}
}
extern void *ioremap_nocache(resource_size_t  , unsigned long  ) ;
__inline static void *ioremap(resource_size_t offset , unsigned long size ) 
{ 
  void *tmp ;

  {
  tmp = ioremap_nocache(offset, size);
  return (tmp);
}
}
extern void iounmap(void volatile   * ) ;
extern int cpu_number ;
    klee_make_symbolic(&cpu_number, sizeof(int), "cpu_number");
extern void kfree(void const   * ) ;
extern void *ldv_malloc(size_t);
void *__kmalloc(size_t size, gfp_t t)
{
	return ldv_malloc(size);
}
void *ldv_malloc(size_t size ) ;
__inline static void *kmalloc(size_t size , gfp_t flags ) 
{ 
  void *tmp___2 ;

  {
  tmp___2 = __kmalloc(size, flags);
  return (tmp___2);
}
}
__inline static void *kmalloc_array(size_t n , size_t size , gfp_t flags ) 
{ 
  void *tmp ;

  {
  if (size != 0UL && 0xffffffffffffffffUL / size < n) {
    return ((void *)0);
  } else {

  }
  tmp = __kmalloc(n * size, flags);
  return (tmp);
}
}
void *ldv_calloc(size_t nmemb , size_t size ) ;
__inline static void *kcalloc(size_t n , size_t size , gfp_t flags ) 
{ 
  void *tmp ;

  {
  tmp = kmalloc_array(n, size, flags | 32768U);
  return (tmp);
}
}
void *ldv_zalloc(size_t size ) ;
__inline static void *kzalloc(size_t size , gfp_t flags ) 
{ 
  void *tmp ;

  {
  tmp = kmalloc(size, flags | 32768U);
  return (tmp);
}
}
int pci_counter  ;
    klee_make_symbolic(&pci_counter, sizeof(int), "pci_counter");
struct inode *i40e_dbg_command_fops_group1  ;
int ldv_state_variable_0  ;
    klee_make_symbolic(&ldv_state_variable_0, sizeof(int), "ldv_state_variable_0");
struct inode *i40e_dbg_dump_fops_group1  ;
int ldv_timer_5_2  ;
    klee_make_symbolic(&ldv_timer_5_2, sizeof(int), "ldv_timer_5_2");
int ldv_irq_2_0  =    0;
int ldv_state_variable_12  ;
    klee_make_symbolic(&ldv_state_variable_12, sizeof(int), "ldv_state_variable_12");
int ldv_irq_3_2  =    0;
struct timer_list *ldv_timer_list_5_0  ;
int ldv_state_variable_14  ;
    klee_make_symbolic(&ldv_state_variable_14, sizeof(int), "ldv_state_variable_14");
struct timer_list *ldv_timer_list_5_3  ;
void *ldv_irq_data_2_3  ;
struct work_struct *ldv_work_struct_4_3  ;
int ldv_state_variable_9  ;
    klee_make_symbolic(&ldv_state_variable_9, sizeof(int), "ldv_state_variable_9");
struct timer_list *ldv_timer_list_5_1  ;
int ref_cnt  ;
    klee_make_symbolic(&ref_cnt, sizeof(int), "ref_cnt");
int ldv_irq_line_1_1  ;
    klee_make_symbolic(&ldv_irq_line_1_1, sizeof(int), "ldv_irq_line_1_1");
void *ldv_irq_data_2_2  ;
struct work_struct *ldv_work_struct_4_0  ;
int ldv_state_variable_7  ;
    klee_make_symbolic(&ldv_state_variable_7, sizeof(int), "ldv_state_variable_7");
int ldv_irq_3_0  =    0;
int ldv_irq_2_1  =    0;
void *ldv_irq_data_2_1  ;
int ldv_irq_1_3  =    0;
int ldv_irq_line_2_2  ;
    klee_make_symbolic(&ldv_irq_line_2_2, sizeof(int), "ldv_irq_line_2_2");
struct ethtool_rxnfc *i40e_ethtool_ops_group7  ;
int ldv_work_4_0  ;
    klee_make_symbolic(&ldv_work_4_0, sizeof(int), "ldv_work_4_0");
int ldv_state_variable_6  ;
    klee_make_symbolic(&ldv_state_variable_6, sizeof(int), "ldv_state_variable_6");
void *ldv_irq_data_1_0  ;
struct net_device *i40e_fcoe_netdev_ops_group1  ;
void *ldv_irq_data_3_0  ;
void *ldv_irq_data_1_3  ;
struct file *i40e_dbg_netdev_ops_fops_group2  ;
struct pci_dev *i40e_driver_group1  ;
struct work_struct *ldv_work_struct_4_2  ;
int LDV_IN_INTERRUPT  =    1;
int ldv_irq_1_1  =    0;
int ldv_timer_5_3  ;
    klee_make_symbolic(&ldv_timer_5_3, sizeof(int), "ldv_timer_5_3");
int ldv_irq_line_3_1  ;
    klee_make_symbolic(&ldv_irq_line_3_1, sizeof(int), "ldv_irq_line_3_1");
struct file *i40e_dbg_dump_fops_group2  ;
int ldv_state_variable_3  ;
    klee_make_symbolic(&ldv_state_variable_3, sizeof(int), "ldv_state_variable_3");
int ldv_irq_line_1_0  ;
    klee_make_symbolic(&ldv_irq_line_1_0, sizeof(int), "ldv_irq_line_1_0");
void *ldv_irq_data_3_2  ;
struct ethtool_pauseparam *i40e_ethtool_ops_group3  ;
int ldv_state_variable_4  ;
    klee_make_symbolic(&ldv_state_variable_4, sizeof(int), "ldv_state_variable_4");
int ldv_irq_line_3_3  ;
    klee_make_symbolic(&ldv_irq_line_3_3, sizeof(int), "ldv_irq_line_3_3");
int ldv_state_variable_8  ;
    klee_make_symbolic(&ldv_state_variable_8, sizeof(int), "ldv_state_variable_8");
struct ethtool_eeprom *i40e_ethtool_ops_group2  ;
struct file *i40e_dbg_command_fops_group2  ;
struct timer_list *ldv_timer_list_5_2  ;
int ldv_state_variable_5  ;
    klee_make_symbolic(&ldv_state_variable_5, sizeof(int), "ldv_state_variable_5");
int ldv_state_variable_13  ;
    klee_make_symbolic(&ldv_state_variable_13, sizeof(int), "ldv_state_variable_13");
int ldv_irq_3_1  =    0;
int ldv_timer_5_1  ;
    klee_make_symbolic(&ldv_timer_5_1, sizeof(int), "ldv_timer_5_1");
struct net_device *i40e_netdev_ops_group1  ;
int ldv_irq_2_2  =    0;
int ldv_irq_line_2_0  ;
    klee_make_symbolic(&ldv_irq_line_2_0, sizeof(int), "ldv_irq_line_2_0");
struct ethtool_wolinfo *i40e_ethtool_ops_group8  ;
int ldv_irq_line_3_0  ;
    klee_make_symbolic(&ldv_irq_line_3_0, sizeof(int), "ldv_irq_line_3_0");
int ldv_state_variable_1  ;
    klee_make_symbolic(&ldv_state_variable_1, sizeof(int), "ldv_state_variable_1");
int ldv_irq_line_1_2  ;
    klee_make_symbolic(&ldv_irq_line_1_2, sizeof(int), "ldv_irq_line_1_2");
struct ethtool_coalesce *i40e_ethtool_ops_group5  ;
int ldv_irq_line_2_3  ;
    klee_make_symbolic(&ldv_irq_line_2_3, sizeof(int), "ldv_irq_line_2_3");
void *ldv_irq_data_3_3  ;
struct ethtool_cmd *i40e_ethtool_ops_group1  ;
void *ldv_irq_data_1_1  ;
int ldv_irq_line_3_2  ;
    klee_make_symbolic(&ldv_irq_line_3_2, sizeof(int), "ldv_irq_line_3_2");
int ldv_state_variable_10  ;
    klee_make_symbolic(&ldv_state_variable_10, sizeof(int), "ldv_state_variable_10");
int ldv_irq_1_0  =    0;
void *ldv_irq_data_3_1  ;
struct net_device *dcbnl_ops_group0  ;
int ldv_work_4_1  ;
    klee_make_symbolic(&ldv_work_4_1, sizeof(int), "ldv_work_4_1");
struct pci_dev *i40e_err_handler_group0  ;
int ldv_work_4_3  ;
    klee_make_symbolic(&ldv_work_4_3, sizeof(int), "ldv_work_4_3");
int ldv_irq_line_2_1  ;
    klee_make_symbolic(&ldv_irq_line_2_1, sizeof(int), "ldv_irq_line_2_1");
int ldv_state_variable_2  ;
    klee_make_symbolic(&ldv_state_variable_2, sizeof(int), "ldv_state_variable_2");
int ldv_timer_5_0  ;
    klee_make_symbolic(&ldv_timer_5_0, sizeof(int), "ldv_timer_5_0");
void *ldv_irq_data_1_2  ;
void *ldv_irq_data_2_0  ;
int ldv_work_4_2  ;
    klee_make_symbolic(&ldv_work_4_2, sizeof(int), "ldv_work_4_2");
int ldv_state_variable_11  ;
    klee_make_symbolic(&ldv_state_variable_11, sizeof(int), "ldv_state_variable_11");
int ldv_irq_1_2  =    0;
struct ethtool_ringparam *i40e_ethtool_ops_group0  ;
int ldv_irq_2_3  =    0;
struct inode *i40e_dbg_netdev_ops_fops_group1  ;
int ldv_irq_line_1_3  ;
    klee_make_symbolic(&ldv_irq_line_1_3, sizeof(int), "ldv_irq_line_1_3");
struct work_struct *ldv_work_struct_4_1  ;
struct net_device *i40e_ethtool_ops_group6  ;
struct ethtool_channels *i40e_ethtool_ops_group4  ;
int ldv_irq_3_3  =    0;
int ldv_irq_3(int state , int line , void *data ) ;
void disable_suitable_irq_2(int line , void *data ) ;
void ldv_timer_5(int state , struct timer_list *timer ) ;
void choose_timer_5(void) ;
void activate_suitable_irq_3(int line , void *data ) ;
int reg_check_1(irqreturn_t (*handler)(int  , void * ) ) ;
void call_and_disable_all_4(int state ) ;
void ldv_file_operations_9(void) ;
void ldv_net_device_ops_6(void) ;
void timer_init_5(void) ;
void disable_suitable_irq_1(int line , void *data ) ;
void activate_suitable_irq_1(int line , void *data ) ;
void ldv_pci_driver_12(void) ;
void invoke_work_4(void) ;
void disable_suitable_timer_5(struct timer_list *timer ) ;
int ldv_irq_2(int state , int line , void *data ) ;
void ldv_initialize_ethtool_ops_11(void) ;
void choose_interrupt_2(void) ;
void activate_work_4(struct work_struct *work , int state ) ;
void activate_suitable_irq_2(int line , void *data ) ;
void ldv_file_operations_10(void) ;
void choose_interrupt_1(void) ;
int reg_check_2(irqreturn_t (*handler)(int  , void * ) ) ;
void disable_suitable_irq_3(int line , void *data ) ;
void ldv_initialize_pci_error_handlers_13(void) ;
void ldv_net_device_ops_14(void) ;
void ldv_file_operations_8(void) ;
int reg_check_3(irqreturn_t (*handler)(int  , void * ) ) ;
void disable_work_4(struct work_struct *work ) ;
void work_init_4(void) ;
int ldv_irq_1(int state , int line , void *data ) ;
void activate_pending_timer_5(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void choose_interrupt_3(void) ;
int reg_timer_5(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) ;
void call_and_disable_work_4(struct work_struct *work ) ;
void activate_suitable_timer_5(struct timer_list *timer , unsigned long data ) ;
void ldv_initialize_dcbnl_rtnl_ops_7(void) ;
extern void get_random_bytes(void * , int  ) ;
__inline static char const   *kobject_name(struct kobject  const  *kobj ) 
{ 


  {
  return ((char const   *)kobj->name);
}
}
extern int device_set_wakeup_enable(struct device * , bool  ) ;
__inline static char const   *dev_name(struct device  const  *dev ) 
{ 
  char const   *tmp ;

  {
  if ((unsigned long )dev->init_name != (unsigned long )((char const   */* const  */)0)) {
    return ((char const   *)dev->init_name);
  } else {

  }
  tmp = kobject_name(& dev->kobj);
  return (tmp);
}
}
__inline static void *dev_get_drvdata(struct device  const  *dev ) 
{ 


  {
  return ((void *)dev->driver_data);
}
}
__inline static void dev_set_drvdata(struct device *dev , void *data ) 
{ 


  {
  dev->driver_data = data;
  return;
}
}
extern char const   *dev_driver_string(struct device  const  * ) ;
extern void dev_err(struct device  const  * , char const   *  , ...) ;
extern void dev_warn(struct device  const  * , char const   *  , ...) ;
extern void _dev_info(struct device  const  * , char const   *  , ...) ;
__inline static int valid_dma_direction(int dma_direction ) 
{ 


  {
  return ((dma_direction == 0 || dma_direction == 1) || dma_direction == 2);
}
}
extern void debug_dma_unmap_page(struct device * , dma_addr_t  , size_t  , int  ,
                                 bool  ) ;
extern struct dma_map_ops *dma_ops ;
__inline static struct dma_map_ops *get_dma_ops(struct device *dev ) 
{ 
  long tmp ;

  {
  tmp = ldv__builtin_expect((unsigned long )dev == (unsigned long )((struct device *)0),
                         0L);
  if (tmp != 0L || (unsigned long )dev->archdata.dma_ops == (unsigned long )((struct dma_map_ops *)0)) {
    return (dma_ops);
  } else {
    return (dev->archdata.dma_ops);
  }
}
}
__inline static void dma_unmap_single_attrs(struct device *dev , dma_addr_t addr ,
                                            size_t size , enum dma_data_direction dir ,
                                            struct dma_attrs *attrs ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (36), "i" (12UL));
    ldv_25253: ;
    goto ldv_25253;
  } else {

  }
  if ((unsigned long )ops->unmap_page != (unsigned long )((void (*)(struct device * ,
                                                                    dma_addr_t  ,
                                                                    size_t  , enum dma_data_direction  ,
                                                                    struct dma_attrs * ))0)) {
    (*(ops->unmap_page))(dev, addr, size, dir, attrs);
  } else {

  }
  debug_dma_unmap_page(dev, addr, size, (int )dir, 1);
  return;
}
}
extern int dma_supported(struct device * , u64  ) ;
extern int dma_set_mask(struct device * , u64  ) ;
extern void *dma_alloc_attrs(struct device * , size_t  , dma_addr_t * , gfp_t  , struct dma_attrs * ) ;
extern void dma_free_attrs(struct device * , size_t  , void * , dma_addr_t  , struct dma_attrs * ) ;
__inline static int dma_set_coherent_mask(struct device *dev , u64 mask ) 
{ 
  int tmp ;

  {
  tmp = dma_supported(dev, mask);
  if (tmp == 0) {
    return (-5);
  } else {

  }
  dev->coherent_dma_mask = mask;
  return (0);
}
}
__inline static int dma_set_mask_and_coherent(struct device *dev , u64 mask ) 
{ 
  int rc ;
    klee_make_symbolic(&rc, sizeof(int), "rc");
  int tmp ;

  {
  tmp = dma_set_mask(dev, mask);
  rc = tmp;
  if (rc == 0) {
    dma_set_coherent_mask(dev, mask);
  } else {

  }
  return (rc);
}
}
__inline static void *dma_zalloc_coherent(struct device *dev , size_t size , dma_addr_t *dma_handle ,
                                          gfp_t flag ) 
{ 
  void *ret ;
  void *tmp ;

  {
  tmp = dma_alloc_attrs(dev, size, dma_handle, flag | 32768U, (struct dma_attrs *)0);
  ret = tmp;
  return (ret);
}
}
extern void synchronize_irq(unsigned int  ) ;
extern void __const_udelay(unsigned long  ) ;
extern void msleep(unsigned int  ) ;
extern void usleep_range(unsigned long  , unsigned long  ) ;
__inline static unsigned int u64_stats_fetch_begin_irq(struct u64_stats_sync  const  *syncp ) 
{ 


  {
  return (0U);
}
}
__inline static bool u64_stats_fetch_retry_irq(struct u64_stats_sync  const  *syncp ,
                                               unsigned int start ) 
{ 


  {
  return (0);
}
}
extern int request_threaded_irq(unsigned int  , irqreturn_t (*)(int  , void * ) ,
                                irqreturn_t (*)(int  , void * ) , unsigned long  ,
                                char const   * , void * ) ;
__inline static int request_irq(unsigned int irq , irqreturn_t (*handler)(int  , void * ) ,
                                unsigned long flags , char const   *name , void *dev ) 
{ 
  int tmp ;

  {
  tmp = request_threaded_irq(irq, handler, (irqreturn_t (*)(int  , void * ))0, flags,
                             name, dev);
  return (tmp);
}
}
__inline static int ldv_request_irq_17(unsigned int irq , irqreturn_t (*handler)(int  ,
                                                                                 void * ) ,
                                       unsigned long flags , char const   *name ,
                                       void *dev ) ;
__inline static int ldv_request_irq_19(unsigned int irq , irqreturn_t (*handler)(int  ,
                                                                                 void * ) ,
                                       unsigned long flags , char const   *name ,
                                       void *dev ) ;
__inline static int ldv_request_irq_20(unsigned int irq , irqreturn_t (*handler)(int  ,
                                                                                 void * ) ,
                                       unsigned long flags , char const   *name ,
                                       void *dev ) ;
__inline static int ldv_request_irq_29(unsigned int irq , irqreturn_t (*handler)(int  ,
                                                                                 void * ) ,
                                       unsigned long flags , char const   *name ,
                                       void *dev ) ;
extern void free_irq(unsigned int  , void * ) ;
void ldv_free_irq_18(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) ;
void ldv_free_irq_21(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) ;
void ldv_free_irq_22(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) ;
void ldv_free_irq_23(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) ;
extern int irq_set_affinity_hint(unsigned int  , struct cpumask  const  * ) ;
extern void __napi_schedule(struct napi_struct * ) ;
__inline static bool napi_disable_pending(struct napi_struct *n ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& n->state));
  return (tmp != 0);
}
}
__inline static bool napi_schedule_prep(struct napi_struct *n ) 
{ 
  bool tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
  tmp = napi_disable_pending(n);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    tmp___1 = test_and_set_bit(0L, (unsigned long volatile   *)(& n->state));
    if (tmp___1 == 0) {
      tmp___2 = 1;
    } else {
      tmp___2 = 0;
    }
  } else {
    tmp___2 = 0;
  }
  return ((bool )tmp___2);
}
}
__inline static void napi_schedule(struct napi_struct *n ) 
{ 
  bool tmp ;

  {
  tmp = napi_schedule_prep(n);
  if ((int )tmp) {
    __napi_schedule(n);
  } else {

  }
  return;
}
}
extern void napi_disable(struct napi_struct * ) ;
__inline static void napi_enable(struct napi_struct *n ) 
{ 
  int tmp ;
  long tmp___0 ;

  {
  tmp = constant_test_bit(0L, (unsigned long const volatile   *)(& n->state));
  tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/netdevice.h"),
                         "i" (507), "i" (12UL));
    ldv_40987: ;
    goto ldv_40987;
  } else {

  }
  __asm__  volatile   ("": : : "memory");
  clear_bit(0L, (unsigned long volatile   *)(& n->state));
  return;
}
}
__inline static int netdev_set_prio_tc_map(struct net_device *dev , u8 prio , u8 tc ) 
{ 


  {
  if ((int )dev->num_tc <= (int )tc) {
    return (-22);
  } else {

  }
  dev->prio_tc_map[(int )prio & 15] = (unsigned int )tc & 15U;
  return (0);
}
}
__inline static void netdev_reset_tc(struct net_device *dev ) 
{ 


  {
  dev->num_tc = 0U;
  memset((void *)(& dev->tc_to_txq), 0, 64UL);
  memset((void *)(& dev->prio_tc_map), 0, 16UL);
  return;
}
}
__inline static int netdev_set_tc_queue(struct net_device *dev , u8 tc , u16 count ,
                                        u16 offset ) 
{ 


  {
  if ((int )dev->num_tc <= (int )tc) {
    return (-22);
  } else {

  }
  dev->tc_to_txq[(int )tc].count = count;
  dev->tc_to_txq[(int )tc].offset = offset;
  return (0);
}
}
__inline static int netdev_set_num_tc(struct net_device *dev , u8 num_tc ) 
{ 


  {
  if ((unsigned int )num_tc > 16U) {
    return (-22);
  } else {

  }
  dev->num_tc = num_tc;
  return (0);
}
}
__inline static struct netdev_queue *netdev_get_tx_queue(struct net_device  const  *dev ,
                                                         unsigned int index ) 
{ 


  {
  return ((struct netdev_queue *)dev->_tx + (unsigned long )index);
}
}
__inline static void *netdev_priv(struct net_device  const  *dev ) 
{ 


  {
  return ((void *)dev + 3008U);
}
}
extern void netif_napi_add(struct net_device * , struct napi_struct * , int (*)(struct napi_struct * ,
                                                                                int  ) ,
                           int  ) ;
extern void netif_napi_del(struct napi_struct * ) ;
extern void free_netdev(struct net_device * ) ;
void ldv_free_netdev_31(struct net_device *dev ) ;
void ldv_free_netdev_33(struct net_device *dev ) ;
void ldv_free_netdev_36(struct net_device *dev ) ;
__inline static void netif_tx_start_queue(struct netdev_queue *dev_queue ) 
{ 


  {
  clear_bit(0L, (unsigned long volatile   *)(& dev_queue->state));
  return;
}
}
__inline static void netif_tx_start_all_queues(struct net_device *dev ) 
{ 
  unsigned int i ;
    klee_make_symbolic(&i, sizeof(int), "i");
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  i = 0U;
  goto ldv_42065;
  ldv_42064: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  netif_tx_start_queue(txq);
  i = i + 1U;
  ldv_42065: ;
  if (dev->num_tx_queues > i) {
    goto ldv_42064;
  } else {

  }

  return;
}
}
extern void netif_tx_wake_queue(struct netdev_queue * ) ;
__inline static void netif_tx_wake_all_queues(struct net_device *dev ) 
{ 
  unsigned int i ;
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  i = 0U;
  goto ldv_42078;
  ldv_42077: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  netif_tx_wake_queue(txq);
  i = i + 1U;
  ldv_42078: ;
  if (dev->num_tx_queues > i) {
    goto ldv_42077;
  } else {

  }

  return;
}
}
__inline static void netif_tx_stop_queue(struct netdev_queue *dev_queue ) 
{ 


  {
  set_bit(0L, (unsigned long volatile   *)(& dev_queue->state));
  return;
}
}
extern void netif_tx_stop_all_queues(struct net_device * ) ;
__inline static bool netif_running(struct net_device  const  *dev ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(0L, (unsigned long const volatile   *)(& dev->state));
  return (tmp != 0);
}
}
extern int netif_set_xps_queue(struct net_device * , struct cpumask  const  * , u16  ) ;
extern int netif_set_real_num_tx_queues(struct net_device * , unsigned int  ) ;
extern int netif_set_real_num_rx_queues(struct net_device * , unsigned int  ) ;
__inline static bool netif_carrier_ok(struct net_device  const  *dev ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(2L, (unsigned long const volatile   *)(& dev->state));
  return (tmp == 0);
}
}
extern void netif_carrier_on(struct net_device * ) ;
extern void netif_carrier_off(struct net_device * ) ;
__inline static u32 netif_msg_init(int debug_value , int default_msg_enable_bits ) 
{ 


  {
  if (debug_value < 0 || (unsigned int )debug_value > 31U) {
    return ((u32 )default_msg_enable_bits);
  } else {

  }
  if (debug_value == 0) {
    return (0U);
  } else {

  }
  return ((u32 )((1 << debug_value) + -1));
}
}
__inline static void __netif_tx_lock(struct netdev_queue *txq , int cpu ) 
{ 


  {
  spin_lock(& txq->_xmit_lock);
  txq->xmit_lock_owner = cpu;
  return;
}
}
__inline static void __netif_tx_unlock(struct netdev_queue *txq ) 
{ 


  {
  txq->xmit_lock_owner = -1;
  spin_unlock(& txq->_xmit_lock);
  return;
}
}
__inline static void netif_tx_disable(struct net_device *dev ) 
{ 
  unsigned int i ;
  int cpu ;
  int pscr_ret__ ;
    klee_make_symbolic(&pscr_ret__, sizeof(int), "pscr_ret__");
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
    klee_make_symbolic(&pfo_ret_____0, sizeof(int), "pfo_ret_____0");
  int pfo_ret_____1 ;
    klee_make_symbolic(&pfo_ret_____1, sizeof(int), "pfo_ret_____1");
  int pfo_ret_____2 ;
    klee_make_symbolic(&pfo_ret_____2, sizeof(int), "pfo_ret_____2");
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  local_bh_disable();
  __vpp_verify = (void const   *)0;
  switch (4UL) {
  case 1UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
  goto ldv_42640;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_42640;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_42640;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_42640;
  default: 
  __bad_percpu_size();
  }
  ldv_42640: 
  pscr_ret__ = pfo_ret__;
  goto ldv_42646;
  case 2UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_42650;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_42650;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_42650;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_42650;
  default: 
  __bad_percpu_size();
  }
  ldv_42650: 
  pscr_ret__ = pfo_ret_____0;
  goto ldv_42646;
  case 4UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_42659;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_42659;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_42659;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_42659;
  default: 
  __bad_percpu_size();
  }
  ldv_42659: 
  pscr_ret__ = pfo_ret_____1;
  goto ldv_42646;
  case 8UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_42668;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_42668;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_42668;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_42668;
  default: 
  __bad_percpu_size();
  }
  ldv_42668: 
  pscr_ret__ = pfo_ret_____2;
  goto ldv_42646;
  default: 
  __bad_size_call_parameter();
  goto ldv_42646;
  }
  ldv_42646: 
  cpu = pscr_ret__;
  i = 0U;
  goto ldv_42678;
  ldv_42677: 
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, i);
  txq = tmp;
  __netif_tx_lock(txq, cpu);
  netif_tx_stop_queue(txq);
  __netif_tx_unlock(txq);
  i = i + 1U;
  ldv_42678: ;
  if (dev->num_tx_queues > i) {
    goto ldv_42677;
  } else {

  }
  local_bh_enable();
  return;
}
}
extern int register_netdev(struct net_device * ) ;
int ldv_register_netdev_34(struct net_device *dev ) ;
extern void unregister_netdev(struct net_device * ) ;
void ldv_unregister_netdev_30(struct net_device *dev ) ;
void ldv_unregister_netdev_32(struct net_device *dev ) ;
void ldv_unregister_netdev_35(struct net_device *dev ) ;
extern int dev_uc_add_excl(struct net_device * , unsigned char const   * ) ;
extern int dev_mc_add_excl(struct net_device * , unsigned char const   * ) ;
extern void netdev_rss_key_fill(void * , size_t  ) ;
extern void netdev_err(struct net_device  const  * , char const   *  , ...) ;
extern void netdev_warn(struct net_device  const  * , char const   *  , ...) ;
extern void netdev_info(struct net_device  const  * , char const   *  , ...) ;
extern void rtnl_lock(void) ;
extern void rtnl_unlock(void) ;
extern struct bus_type pci_bus_type ;
extern int pci_bus_read_config_byte(struct pci_bus * , unsigned int  , int  , u8 * ) ;
__inline static int pci_read_config_byte(struct pci_dev  const  *dev , int where ,
                                         u8 *val ) 
{ 
  int tmp ;

  {
  tmp = pci_bus_read_config_byte(dev->bus, dev->devfn, where, val);
  return (tmp);
}
}
extern int pcie_capability_read_word(struct pci_dev * , int  , u16 * ) ;
extern int pci_enable_device_mem(struct pci_dev * ) ;
extern void pci_disable_device(struct pci_dev * ) ;
extern void pci_set_master(struct pci_dev * ) ;
extern int pci_select_bars(struct pci_dev * , unsigned long  ) ;
extern int pci_save_state(struct pci_dev * ) ;
extern void pci_restore_state(struct pci_dev * ) ;
extern int pci_set_power_state(struct pci_dev * , pci_power_t  ) ;
extern int pci_wake_from_d3(struct pci_dev * , bool  ) ;
extern int pci_request_selected_regions(struct pci_dev * , int  , char const   * ) ;
extern void pci_release_selected_regions(struct pci_dev * , int  ) ;
extern int __pci_register_driver(struct pci_driver * , struct module * , char const   * ) ;
int ldv___pci_register_driver_47(struct pci_driver *ldv_func_arg1 , struct module *ldv_func_arg2 ,
                                 char const   *ldv_func_arg3 ) ;
extern void pci_unregister_driver(struct pci_driver * ) ;
void ldv_pci_unregister_driver_48(struct pci_driver *ldv_func_arg1 ) ;
extern void pci_disable_msi(struct pci_dev * ) ;
extern void pci_disable_msix(struct pci_dev * ) ;
extern int pci_enable_msi_range(struct pci_dev * , int  , int  ) ;
__inline static int pci_enable_msi_exact(struct pci_dev *dev , int nvec ) 
{ 
  int rc ;
  int tmp ;

  {
  tmp = pci_enable_msi_range(dev, nvec, nvec);
  rc = tmp;
  if (rc < 0) {
    return (rc);
  } else {

  }
  return (0);
}
}
extern int pci_enable_msix_range(struct pci_dev * , struct msix_entry * , int  , int  ) ;
__inline static void *pci_get_drvdata(struct pci_dev *pdev ) 
{ 
  void *tmp ;

  {
  tmp = dev_get_drvdata((struct device  const  *)(& pdev->dev));
  return (tmp);
}
}
__inline static void pci_set_drvdata(struct pci_dev *pdev , void *data ) 
{ 


  {
  dev_set_drvdata(& pdev->dev, data);
  return;
}
}
extern int pci_num_vf(struct pci_dev * ) ;
extern int pci_enable_pcie_error_reporting(struct pci_dev * ) ;
extern int pci_disable_pcie_error_reporting(struct pci_dev * ) ;
extern int pci_cleanup_aer_uncorrect_error_status(struct pci_dev * ) ;
extern bool iommu_present(struct bus_type * ) ;
extern int eth_validate_addr(struct net_device * ) ;
extern struct net_device *alloc_etherdev_mqs(int  , unsigned int  , unsigned int  ) ;
static u8 const   eth_reserved_addr_base[6U]  = {      1U,      128U,      194U,      0U, 
        0U,      0U};
__inline static bool is_link_local_ether_addr(u8 const   *addr ) 
{ 
  __be16 *a ;
  __be16 const   *b ;
  __be16 m ;

  {
  a = (__be16 *)addr;
  b = (__be16 const   *)(& eth_reserved_addr_base);
  m = 61695U;
  return ((((unsigned int )*((u32 const   *)addr) ^ (unsigned int )*((u32 const   *)b)) | (unsigned int )(((int )*(a + 2UL) ^ (int )((unsigned short )*(b + 2UL))) & (int )m)) == 0U);
}
}
__inline static bool is_zero_ether_addr(u8 const   *addr ) 
{ 


  {
  return (((unsigned int )*((u32 const   *)addr) | (unsigned int )*((u16 const   *)addr + 4U)) == 0U);
}
}
__inline static bool is_multicast_ether_addr(u8 const   *addr ) 
{ 
  u32 a ;

  {
  a = *((u32 const   *)addr);
  return ((a & 1U) != 0U);
}
}
__inline static bool is_unicast_ether_addr(u8 const   *addr ) 
{ 
  bool tmp ;
  int tmp___0 ;

  {
  tmp = is_multicast_ether_addr(addr);
  if ((int )tmp != 0) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  return ((bool )tmp___0);
}
}
__inline static bool is_valid_ether_addr(u8 const   *addr ) 
{ 
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
    klee_make_symbolic(&tmp___3, sizeof(int), "tmp___3");

  {
  tmp = is_multicast_ether_addr(addr);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    tmp___1 = is_zero_ether_addr(addr);
    if (tmp___1) {
      tmp___2 = 0;
    } else {
      tmp___2 = 1;
    }
    if (tmp___2) {
      tmp___3 = 1;
    } else {
      tmp___3 = 0;
    }
  } else {
    tmp___3 = 0;
  }
  return ((bool )tmp___3);
}
}
__inline static void eth_random_addr(u8 *addr ) 
{ 


  {
  get_random_bytes((void *)addr, 6);
  *addr = (unsigned int )*addr & 254U;
  *addr = (u8 )((unsigned int )*addr | 2U);
  return;
}
}
__inline static void ether_addr_copy(u8 *dst , u8 const   *src ) 
{ 


  {
  *((u32 *)dst) = *((u32 const   *)src);
  *((u16 *)dst + 4U) = *((u16 const   *)src + 4U);
  return;
}
}
__inline static bool ether_addr_equal(u8 const   *addr1 , u8 const   *addr2 ) 
{ 
  u32 fold ;

  {
  fold = ((unsigned int )*((u32 const   *)addr1) ^ (unsigned int )*((u32 const   *)addr2)) | (unsigned int )((int )((unsigned short )*((u16 const   *)addr1 + 4U)) ^ (int )((unsigned short )*((u16 const   *)addr2 + 4U)));
  return (fold == 0U);
}
}
i40e_status i40e_init_lan_hmc(struct i40e_hw *hw , u32 txq_num , u32 rxq_num , u32 fcoe_cntx_num ,
                              u32 fcoe_filt_num ) ;
i40e_status i40e_configure_lan_hmc(struct i40e_hw *hw , enum i40e_hmc_model model ) ;
i40e_status i40e_shutdown_lan_hmc(struct i40e_hw *hw ) ;
i40e_status i40e_clear_lan_tx_queue_context(struct i40e_hw *hw , u16 queue ) ;
i40e_status i40e_set_lan_tx_queue_context(struct i40e_hw *hw , u16 queue , struct i40e_hmc_obj_txq *s ) ;
i40e_status i40e_clear_lan_rx_queue_context(struct i40e_hw *hw , u16 queue ) ;
i40e_status i40e_set_lan_rx_queue_context(struct i40e_hw *hw , u16 queue , struct i40e_hmc_obj_rxq *s ) ;
i40e_status i40e_allocate_dma_mem_d(struct i40e_hw *hw , struct i40e_dma_mem *mem ,
                                    u64 size , u32 alignment ) ;
i40e_status i40e_free_dma_mem_d(struct i40e_hw *hw , struct i40e_dma_mem *mem ) ;
i40e_status i40e_allocate_virt_mem_d(struct i40e_hw *hw , struct i40e_virt_mem *mem ,
                                     u32 size ) ;
i40e_status i40e_free_virt_mem_d(struct i40e_hw *hw , struct i40e_virt_mem *mem ) ;
i40e_status i40e_init_adminq(struct i40e_hw *hw ) ;
i40e_status i40e_shutdown_adminq(struct i40e_hw *hw ) ;
i40e_status i40e_clean_arq_element(struct i40e_hw *hw , struct i40e_arq_event_info *e ,
                                   u16 *pending ) ;
bool i40e_check_asq_alive(struct i40e_hw *hw ) ;
enum i40e_status_code i40e_aq_get_phy_capabilities(struct i40e_hw *hw , bool qualified_modules ,
                                                   bool report_init , struct i40e_aq_get_phy_abilities_resp *abilities ,
                                                   struct i40e_asq_cmd_details *cmd_details ) ;
enum i40e_status_code i40e_set_fc(struct i40e_hw *hw , u8 *aq_failures , bool atomic_restart ) ;
i40e_status i40e_aq_set_phy_int_mask(struct i40e_hw *hw , u16 mask , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_set_link_restart_an(struct i40e_hw *hw , bool enable_link , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_get_link_info(struct i40e_hw *hw , bool enable_lse , struct i40e_link_status *link ,
                                  struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_send_driver_version(struct i40e_hw *hw , struct i40e_driver_version *dv ,
                                        struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_add_vsi(struct i40e_hw *hw , struct i40e_vsi_context *vsi_ctx ,
                            struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_set_vsi_broadcast(struct i40e_hw *hw , u16 seid , bool set_filter ,
                                      struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_set_vsi_unicast_promiscuous(struct i40e_hw *hw , u16 seid , bool set ,
                                                struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_set_vsi_multicast_promiscuous(struct i40e_hw *hw , u16 seid ,
                                                  bool set , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_get_vsi_params(struct i40e_hw *hw , struct i40e_vsi_context *vsi_ctx ,
                                   struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_update_vsi_params(struct i40e_hw *hw , struct i40e_vsi_context *vsi_ctx ,
                                      struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_add_veb(struct i40e_hw *hw , u16 uplink_seid , u16 downlink_seid ,
                            u8 enabled_tc , bool default_port , bool enable_l2_filtering ,
                            u16 *veb_seid , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_get_veb_parameters(struct i40e_hw *hw , u16 veb_seid , u16 *switch_id ,
                                       bool *floating , u16 *statistic_index , u16 *vebs_used ,
                                       u16 *vebs_free , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_add_macvlan(struct i40e_hw *hw , u16 seid , struct i40e_aqc_add_macvlan_element_data *mv_list ,
                                u16 count , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_remove_macvlan(struct i40e_hw *hw , u16 seid , struct i40e_aqc_remove_macvlan_element_data *mv_list ,
                                   u16 count , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_get_switch_config(struct i40e_hw *hw , struct i40e_aqc_get_switch_config_resp *buf ,
                                      u16 buf_size , u16 *start_seid , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_read_nvm(struct i40e_hw *hw , u8 module_pointer , u32 offset ,
                             u16 length , void *data , bool last_command , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_discover_capabilities(struct i40e_hw *hw , void *buff , u16 buff_size ,
                                          u16 *data_size , enum i40e_admin_queue_opc list_type_opc ,
                                          struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_update_nvm(struct i40e_hw *hw , u8 module_pointer , u32 offset ,
                               u16 length , void *data , bool last_command , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_stop_lldp(struct i40e_hw *hw , bool shutdown_agent , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_add_udp_tunnel(struct i40e_hw *hw , u16 udp_port , u8 protocol_index ,
                                   u8 *filter_index , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_del_udp_tunnel(struct i40e_hw *hw , u8 index , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_delete_element(struct i40e_hw *hw , u16 seid , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_mac_address_write(struct i40e_hw *hw , u16 flags , u8 *mac_addr ,
                                      struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_config_vsi_tc_bw(struct i40e_hw *hw , u16 seid , struct i40e_aqc_configure_vsi_tc_bw_data *bw_data ,
                                     struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_config_switch_comp_bw_config(struct i40e_hw *hw , u16 seid , struct i40e_aqc_configure_switching_comp_bw_config_data *bw_data ,
                                                 struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_query_vsi_bw_config(struct i40e_hw *hw , u16 seid , struct i40e_aqc_query_vsi_bw_config_resp *bw_data ,
                                        struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_query_vsi_ets_sla_config(struct i40e_hw *hw , u16 seid , struct i40e_aqc_query_vsi_ets_sla_config_resp *bw_data ,
                                             struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_query_switch_comp_ets_config(struct i40e_hw *hw , u16 seid , struct i40e_aqc_query_switching_comp_ets_config_resp *bw_data ,
                                                 struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_query_switch_comp_bw_config(struct i40e_hw *hw , u16 seid , struct i40e_aqc_query_switching_comp_bw_config_resp *bw_data ,
                                                struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_resume_port_tx(struct i40e_hw *hw , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_init_shared_code(struct i40e_hw *hw ) ;
i40e_status i40e_pf_reset(struct i40e_hw *hw ) ;
void i40e_clear_hw(struct i40e_hw *hw ) ;
void i40e_clear_pxe_mode(struct i40e_hw *hw ) ;
bool i40e_get_link_status(struct i40e_hw *hw ) ;
i40e_status i40e_get_mac_addr(struct i40e_hw *hw , u8 *mac_addr ) ;
i40e_status i40e_read_bw_from_alt_ram(struct i40e_hw *hw , u32 *max_bw , u32 *min_bw ,
                                      bool *min_valid , bool *max_valid ) ;
i40e_status i40e_aq_configure_partition_bw(struct i40e_hw *hw , struct i40e_aqc_configure_partition_bw_data *bw_data ,
                                           struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_get_port_mac_addr(struct i40e_hw *hw , u8 *mac_addr ) ;
void i40e_pre_tx_queue_cfg(struct i40e_hw *hw , u32 queue , bool enable ) ;
i40e_status i40e_get_san_mac_addr(struct i40e_hw *hw , u8 *mac_addr ) ;
i40e_status i40e_acquire_nvm(struct i40e_hw *hw , enum i40e_aq_resource_access_type access ) ;
void i40e_release_nvm(struct i40e_hw *hw ) ;
void i40e_set_pci_config_data(struct i40e_hw *hw , u16 link_status ) ;
i40e_status i40e_set_filter_control(struct i40e_hw *hw , struct i40e_filter_control_settings *settings ) ;
void i40e_free_vfs(struct i40e_pf *pf ) ;
int i40e_pci_sriov_configure(struct pci_dev *pdev , int num_vfs ) ;
int i40e_alloc_vfs(struct i40e_pf *pf , u16 num_alloc_vfs ) ;
int i40e_vc_process_vf_msg(struct i40e_pf *pf , u16 vf_id , u32 v_opcode , u32 v_retval ,
                           u8 *msg , u16 msglen ) ;
int i40e_vc_process_vflr_event(struct i40e_pf *pf ) ;
void i40e_reset_vf(struct i40e_vf *vf , bool flr ) ;
void i40e_vc_notify_vf_reset(struct i40e_vf *vf ) ;
int i40e_ndo_set_vf_mac(struct net_device *netdev , int vf_id , u8 *mac ) ;
int i40e_ndo_set_vf_port_vlan(struct net_device *netdev , int vf_id , u16 vlan_id ,
                              u8 qos ) ;
int i40e_ndo_set_vf_bw(struct net_device *netdev , int vf_id , int min_tx_rate , int max_tx_rate ) ;
int i40e_ndo_get_vf_config(struct net_device *netdev , int vf_id , struct ifla_vf_info *ivi ) ;
int i40e_ndo_set_vf_link_state(struct net_device *netdev , int vf_id , int link ) ;
int i40e_ndo_set_vf_spoofchk(struct net_device *netdev , int vf_id , bool enable ) ;
void i40e_vc_notify_link_state(struct i40e_pf *pf ) ;
void i40e_vc_notify_reset(struct i40e_pf *pf ) ;
void i40e_alloc_rx_buffers_ps(struct i40e_ring *rx_ring , u16 cleaned_count ) ;
void i40e_alloc_rx_buffers_1buf(struct i40e_ring *rx_ring , u16 cleaned_count ) ;
void i40e_alloc_rx_headers(struct i40e_ring *rx_ring ) ;
netdev_tx_t i40e_lan_xmit_frame(struct sk_buff *skb , struct net_device *netdev ) ;
void i40e_clean_tx_ring(struct i40e_ring *tx_ring ) ;
void i40e_clean_rx_ring(struct i40e_ring *rx_ring ) ;
int i40e_setup_tx_descriptors(struct i40e_ring *tx_ring ) ;
int i40e_setup_rx_descriptors(struct i40e_ring *rx_ring ) ;
void i40e_free_tx_resources(struct i40e_ring *tx_ring ) ;
void i40e_free_rx_resources(struct i40e_ring *rx_ring ) ;
int i40e_napi_poll(struct napi_struct *napi , int budget ) ;
i40e_status i40e_aq_get_dcb_config(struct i40e_hw *hw , u8 mib_type , u8 bridgetype ,
                                   struct i40e_dcbx_config *dcbcfg ) ;
i40e_status i40e_get_dcb_config(struct i40e_hw *hw ) ;
i40e_status i40e_init_dcb(struct i40e_hw *hw ) ;
__inline static char *i40e_fw_version_str(struct i40e_hw *hw ) 
{ 
  char buf[32U] ;

  {
  snprintf((char *)(& buf), 32UL, "f%d.%d.%05d a%d.%d n%x.%02x e%x", (int )hw->aq.fw_maj_ver,
           (int )hw->aq.fw_min_ver, hw->aq.fw_build, (int )hw->aq.api_maj_ver, (int )hw->aq.api_min_ver,
           (int )hw->nvm.version >> 12, (int )hw->nvm.version & 255, hw->nvm.eetrack & 16777215U);
  return ((char *)(& buf));
}
}
__inline static void i40e_vsi_setup_irqhandler(struct i40e_vsi *vsi , irqreturn_t (*irq_handler)(int  ,
                                                                                                 void * ) ) 
{ 


  {
  vsi->irq_handler = irq_handler;
  return;
}
}
int i40e_up(struct i40e_vsi *vsi ) ;
void i40e_down(struct i40e_vsi *vsi ) ;
char const   i40e_driver_name[5U] ;
char const   i40e_driver_version_str[8U] ;
void i40e_do_reset_safe(struct i40e_pf *pf , u32 reset_flags ) ;
void i40e_do_reset(struct i40e_pf *pf , u32 reset_flags ) ;
struct i40e_vsi *i40e_find_vsi_from_id(struct i40e_pf *pf , u16 id ) ;
void i40e_update_stats(struct i40e_vsi *vsi ) ;
void i40e_update_eth_stats(struct i40e_vsi *vsi ) ;
struct rtnl_link_stats64 *i40e_get_vsi_stats_struct(struct i40e_vsi *vsi ) ;
int i40e_fetch_switch_configuration(struct i40e_pf *pf , bool printconfig ) ;
int i40e_add_del_fdir(struct i40e_vsi *vsi , struct i40e_fdir_filter *input , bool add ) ;
void i40e_fdir_check_and_reenable(struct i40e_pf *pf ) ;
u32 i40e_get_current_fd_count(struct i40e_pf *pf ) ;
u32 i40e_get_cur_guaranteed_fd_count(struct i40e_pf *pf ) ;
u32 i40e_get_current_atr_cnt(struct i40e_pf *pf ) ;
u32 i40e_get_global_fd_count(struct i40e_pf *pf ) ;
bool i40e_set_ntuple(struct i40e_pf *pf , netdev_features_t features ) ;
void i40e_set_ethtool_ops(struct net_device *netdev ) ;
struct i40e_mac_filter *i40e_add_filter(struct i40e_vsi *vsi , u8 *macaddr , s16 vlan ,
                                        bool is_vf , bool is_netdev ) ;
void i40e_del_filter(struct i40e_vsi *vsi , u8 *macaddr , s16 vlan , bool is_vf ,
                     bool is_netdev ) ;
int i40e_sync_vsi_filters(struct i40e_vsi *vsi ) ;
struct i40e_vsi *i40e_vsi_setup(struct i40e_pf *pf , u8 type , u16 uplink_seid , u32 param1 ) ;
int i40e_vsi_release(struct i40e_vsi *vsi ) ;
void i40e_vsi_setup_queue_map(struct i40e_vsi *vsi , struct i40e_vsi_context *ctxt ,
                              u8 enabled_tc , bool is_add ) ;
int i40e_vsi_control_rings(struct i40e_vsi *vsi , bool request ) ;
int i40e_reconfig_rss_queues(struct i40e_pf *pf , int queue_count ) ;
struct i40e_veb *i40e_veb_setup(struct i40e_pf *pf , u16 flags , u16 uplink_seid ,
                                u16 vsi_seid , u8 enabled_tc ) ;
void i40e_veb_release(struct i40e_veb *veb ) ;
int i40e_veb_config_tc(struct i40e_veb *veb , u8 enabled_tc ) ;
i40e_status i40e_vsi_add_pvid(struct i40e_vsi *vsi , u16 vid ) ;
void i40e_vsi_remove_pvid(struct i40e_vsi *vsi ) ;
void i40e_vsi_reset_stats(struct i40e_vsi *vsi ) ;
void i40e_pf_reset_stats(struct i40e_pf *pf ) ;
void i40e_dbg_pf_init(struct i40e_pf *pf ) ;
void i40e_dbg_pf_exit(struct i40e_pf *pf ) ;
void i40e_dbg_init(void) ;
void i40e_dbg_exit(void) ;
void i40e_irq_dynamic_enable(struct i40e_vsi *vsi , int vector ) ;
void i40e_irq_dynamic_disable(struct i40e_vsi *vsi , int vector ) ;
void i40e_irq_dynamic_disable_icr0(struct i40e_pf *pf ) ;
void i40e_irq_dynamic_enable_icr0(struct i40e_pf *pf ) ;
struct rtnl_link_stats64 *i40e_get_netdev_stats_struct(struct net_device *netdev ,
                                                       struct rtnl_link_stats64 *stats ) ;
int i40e_set_mac(struct net_device *netdev , void *p ) ;
void i40e_set_rx_mode(struct net_device *netdev ) ;
int i40e_ioctl(struct net_device *netdev , struct ifreq *ifr , int cmd ) ;
void i40e_tx_timeout(struct net_device *netdev ) ;
int i40e_vlan_rx_add_vid(struct net_device *netdev , __be16 proto , u16 vid ) ;
int i40e_vlan_rx_kill_vid(struct net_device *netdev , __be16 proto , u16 vid ) ;
int i40e_open(struct net_device *netdev ) ;
int i40e_vsi_open(struct i40e_vsi *vsi ) ;
void i40e_vlan_stripping_disable(struct i40e_vsi *vsi ) ;
int i40e_vsi_add_vlan(struct i40e_vsi *vsi , s16 vid ) ;
int i40e_vsi_kill_vlan(struct i40e_vsi *vsi , s16 vid ) ;
struct i40e_mac_filter *i40e_put_mac_in_vlan(struct i40e_vsi *vsi , u8 *macaddr ,
                                             bool is_vf , bool is_netdev ) ;
bool i40e_is_vsi_in_vlan(struct i40e_vsi *vsi ) ;
struct i40e_mac_filter *i40e_find_mac(struct i40e_vsi *vsi , u8 *macaddr , bool is_vf ,
                                      bool is_netdev ) ;
int i40e_close(struct net_device *netdev ) ;
int i40e_setup_tc(struct net_device *netdev , u8 tc ) ;
void i40e_netpoll(struct net_device *netdev ) ;
int i40e_fcoe_enable(struct net_device *netdev ) ;
int i40e_fcoe_disable(struct net_device *netdev ) ;
int i40e_fcoe_vsi_init(struct i40e_vsi *vsi , struct i40e_vsi_context *ctxt ) ;
u8 i40e_get_fcoe_tc_map(struct i40e_pf *pf ) ;
void i40e_fcoe_config_netdev(struct net_device *netdev , struct i40e_vsi *vsi ) ;
void i40e_fcoe_vsi_setup(struct i40e_pf *pf ) ;
int i40e_init_pf_fcoe(struct i40e_pf *pf ) ;
int i40e_fcoe_setup_ddp_resources(struct i40e_vsi *vsi ) ;
void i40e_fcoe_free_ddp_resources(struct i40e_vsi *vsi ) ;
void i40e_vlan_stripping_enable(struct i40e_vsi *vsi ) ;
void i40e_dcbnl_flush_apps(struct i40e_pf *pf , struct i40e_dcbx_config *old_cfg ,
                           struct i40e_dcbx_config *new_cfg ) ;
void i40e_dcbnl_set_all(struct i40e_vsi *vsi ) ;
void i40e_dcbnl_setup(struct i40e_vsi *vsi ) ;
bool i40e_dcb_need_reconfig(struct i40e_pf *pf , struct i40e_dcbx_config *old_cfg ,
                            struct i40e_dcbx_config *new_cfg ) ;
void i40e_ptp_rx_hang(struct i40e_vsi *vsi ) ;
void i40e_ptp_tx_hwtstamp(struct i40e_pf *pf ) ;
void i40e_ptp_set_increment(struct i40e_pf *pf ) ;
int i40e_ptp_set_ts_config(struct i40e_pf *pf , struct ifreq *ifr ) ;
int i40e_ptp_get_ts_config(struct i40e_pf *pf , struct ifreq *ifr ) ;
void i40e_ptp_init(struct i40e_pf *pf ) ;
void i40e_ptp_stop(struct i40e_pf *pf ) ;
int i40e_is_vsi_uplink_mode_veb(struct i40e_vsi *vsi ) ;
i40e_status i40e_get_npar_bw_setting(struct i40e_pf *pf ) ;
i40e_status i40e_set_npar_bw_setting(struct i40e_pf *pf ) ;
i40e_status i40e_commit_npar_bw_setting(struct i40e_pf *pf ) ;
i40e_status i40e_diag_eeprom_test(struct i40e_hw *hw ) ;
extern void vxlan_get_rx_port(struct net_device * ) ;
char const   i40e_driver_name[5U]  = {      'i',      '4',      '0',      'e', 
        '\000'};
static char const   i40e_driver_string[50U]  = 
  {      'I',      'n',      't',      'e', 
        'l',      '(',      'R',      ')', 
        ' ',      'E',      't',      'h', 
        'e',      'r',      'n',      'e', 
        't',      ' ',      'C',      'o', 
        'n',      'n',      'e',      'c', 
        't',      'i',      'o',      'n', 
        ' ',      'X',      'L',      '7', 
        '1',      '0',      ' ',      'N', 
        'e',      't',      'w',      'o', 
        'r',      'k',      ' ',      'D', 
        'r',      'i',      'v',      'e', 
        'r',      '\000'};
char const   i40e_driver_version_str[8U]  = 
  {      '1',      '.',      '3',      '.', 
        '4',      '-',      'k',      '\000'};
static char const   i40e_copyright[45U]  = 
  {      'C',      'o',      'p',      'y', 
        'r',      'i',      'g',      'h', 
        't',      ' ',      '(',      'c', 
        ')',      ' ',      '2',      '0', 
        '1',      '3',      ' ',      '-', 
        ' ',      '2',      '0',      '1', 
        '4',      ' ',      'I',      'n', 
        't',      'e',      'l',      ' ', 
        'C',      'o',      'r',      'p', 
        'o',      'r',      'a',      't', 
        'i',      'o',      'n',      '.', 
        '\000'};
static void i40e_vsi_reinit_locked(struct i40e_vsi *vsi ) ;
static void i40e_handle_reset_warning(struct i40e_pf *pf ) ;
static int i40e_add_vsi(struct i40e_vsi *vsi ) ;
static int i40e_add_veb(struct i40e_veb *veb , struct i40e_vsi *vsi ) ;
static int i40e_setup_pf_switch(struct i40e_pf *pf , bool reinit ) ;
static int i40e_setup_misc_vector(struct i40e_pf *pf ) ;
static void i40e_determine_queue_usage(struct i40e_pf *pf ) ;
static int i40e_setup_pf_filter_control(struct i40e_pf *pf ) ;
static void i40e_fdir_sb_setup(struct i40e_pf *pf ) ;
static int i40e_veb_get_bw_info(struct i40e_veb *veb ) ;
static struct pci_device_id  const  i40e_pci_tbl[11U]  = 
  {      {32902U, 5490U, 4294967295U, 4294967295U, 0U, 0U, 0UL}, 
        {32902U, 5492U, 4294967295U, 4294967295U, 0U, 0U, 0UL}, 
        {32902U, 5503U, 4294967295U, 4294967295U, 0U, 0U, 0UL}, 
        {32902U, 5504U, 4294967295U, 4294967295U, 0U, 0U, 0UL}, 
        {32902U, 5505U, 4294967295U, 4294967295U, 0U, 0U, 0UL}, 
        {32902U, 5507U, 4294967295U, 4294967295U, 0U, 0U, 0UL}, 
        {32902U, 5508U, 4294967295U, 4294967295U, 0U, 0U, 0UL}, 
        {32902U, 5509U, 4294967295U, 4294967295U, 0U, 0U, 0UL}, 
        {32902U, 5510U, 4294967295U, 4294967295U, 0U, 0U, 0UL}, 
        {32902U, 5511U, 4294967295U, 4294967295U, 0U, 0U, 0UL}, 
        {0U, 0U, 0U, 0U, 0U, 0U, 0UL}};
struct pci_device_id  const  __mod_pci__i40e_pci_tbl_device_table[11U]  ;
static int debug  =    -1;
i40e_status i40e_allocate_dma_mem_d(struct i40e_hw *hw , struct i40e_dma_mem *mem ,
                                    u64 size , u32 alignment ) 
{ 
  struct i40e_pf *pf ;

  {
  pf = (struct i40e_pf *)hw->back;
  mem->size = (((u32 )size + alignment) - 1U) & - alignment;
  mem->va = dma_zalloc_coherent(& (pf->pdev)->dev, (size_t )mem->size, & mem->pa,
                                208U);
  if ((unsigned long )mem->va == (unsigned long )((void *)0)) {
    return (-12);
  } else {

  }
  return (0);
}
}
i40e_status i40e_free_dma_mem_d(struct i40e_hw *hw , struct i40e_dma_mem *mem ) 
{ 
  struct i40e_pf *pf ;

  {
  pf = (struct i40e_pf *)hw->back;
  dma_free_attrs(& (pf->pdev)->dev, (size_t )mem->size, mem->va, mem->pa, (struct dma_attrs *)0);
  mem->va = (void *)0;
  mem->pa = 0ULL;
  mem->size = 0U;
  return (0);
}
}
i40e_status i40e_allocate_virt_mem_d(struct i40e_hw *hw , struct i40e_virt_mem *mem ,
                                     u32 size ) 
{ 


  {
  mem->size = size;
  mem->va = kzalloc((size_t )size, 208U);
  if ((unsigned long )mem->va == (unsigned long )((void *)0)) {
    return (-12);
  } else {

  }
  return (0);
}
}
i40e_status i40e_free_virt_mem_d(struct i40e_hw *hw , struct i40e_virt_mem *mem ) 
{ 


  {
  kfree((void const   *)mem->va);
  mem->va = (void *)0;
  mem->size = 0U;
  return (0);
}
}
static int i40e_get_lump(struct i40e_pf *pf , struct i40e_lump_tracking *pile , u16 needed ,
                         u16 id ) 
{ 
  int ret ;
  int i ;
  int j ;
    klee_make_symbolic(&j, sizeof(int), "j");

  {
  ret = -12;
  if (((unsigned long )pile == (unsigned long )((struct i40e_lump_tracking *)0) || (unsigned int )needed == 0U) || (int )((short )id) < 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "param err: pile=%p needed=%d id=0x%04x\n",
              pile, (int )needed, (int )id);
    return (-22);
  } else {

  }
  i = (int )pile->search_hint;
  goto ldv_61356;
  ldv_61364: ;
  if ((int )((short )pile->list[i]) < 0) {
    i = i + 1;
    goto ldv_61356;
  } else {

  }
  j = 0;
  goto ldv_61359;
  ldv_61358: ;
  if ((int )((short )pile->list[i + j]) < 0) {
    goto ldv_61357;
  } else {

  }
  j = j + 1;
  ldv_61359: ;
  if ((int )needed > j && i + j < (int )pile->num_entries) {
    goto ldv_61358;
  } else {

  }
  ldv_61357: ;
  if ((int )needed == j) {
    j = 0;
    goto ldv_61361;
    ldv_61360: 
    pile->list[i + j] = (u16 )((unsigned int )id | 32768U);
    j = j + 1;
    ldv_61361: ;
    if ((int )needed > j) {
      goto ldv_61360;
    } else {

    }
    ret = i;
    pile->search_hint = (int )((u16 )i) + (int )((u16 )j);
    goto ldv_61363;
  } else {
    i = i + j;
  }
  ldv_61356: ;
  if ((int )pile->num_entries > i) {
    goto ldv_61364;
  } else {

  }
  ldv_61363: ;
  return (ret);
}
}
static int i40e_put_lump(struct i40e_lump_tracking *pile , u16 index , u16 id ) 
{ 
  int valid_id ;
    klee_make_symbolic(&valid_id, sizeof(int), "valid_id");
  int count ;
  int i ;

  {
  valid_id = (int )((unsigned int )id | 32768U);
  count = 0;
  if ((unsigned long )pile == (unsigned long )((struct i40e_lump_tracking *)0) || (int )pile->num_entries <= (int )index) {
    return (-22);
  } else {

  }
  i = (int )index;
  goto ldv_61374;
  ldv_61373: 
  pile->list[i] = 0U;
  count = count + 1;
  i = i + 1;
  ldv_61374: ;
  if ((int )pile->num_entries > i && (int )pile->list[i] == valid_id) {
    goto ldv_61373;
  } else {

  }

  if (count != 0 && (int )pile->search_hint > (int )index) {
    pile->search_hint = index;
  } else {

  }
  return (count);
}
}
struct i40e_vsi *i40e_find_vsi_from_id(struct i40e_pf *pf , u16 id ) 
{ 
  int i ;

  {
  i = 0;
  goto ldv_61382;
  ldv_61381: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0) && (int )(*(pf->vsi + (unsigned long )i))->id == (int )id) {
    return (*(pf->vsi + (unsigned long )i));
  } else {

  }
  i = i + 1;
  ldv_61382: ;
  if ((int )pf->num_alloc_vsi > i) {
    goto ldv_61381;
  } else {

  }

  return ((struct i40e_vsi *)0);
}
}
static void i40e_service_event_schedule(struct i40e_pf *pf ) 
{ 
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
  tmp = constant_test_bit(3L, (unsigned long const volatile   *)(& pf->state));
  if (tmp == 0) {
    tmp___0 = constant_test_bit(9L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___0 == 0) {
      tmp___1 = test_and_set_bit(5L, (unsigned long volatile   *)(& pf->state));
      if (tmp___1 == 0) {
        schedule_work(& pf->service_task);
      } else {

      }
    } else {

    }
  } else {

  }
  return;
}
}
void i40e_tx_timeout(struct net_device *netdev ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  pf->tx_timeout_count = pf->tx_timeout_count + 1U;
  if ((long )((pf->tx_timeout_last_recovery - (unsigned long )jiffies) + 5000UL) < 0L) {
    pf->tx_timeout_recovery_level = 1U;
  } else {

  }
  pf->tx_timeout_last_recovery = jiffies;
  netdev_info((struct net_device  const  *)netdev, "tx_timeout recovery level %d\n",
              pf->tx_timeout_recovery_level);
  switch (pf->tx_timeout_recovery_level) {
  case 0U: 
  tmp___0 = preempt_count();
  if (((unsigned long )tmp___0 & 2096896UL) != 0UL) {
    set_bit(11L, (unsigned long volatile   *)(& pf->state));
    set_bit(11L, (unsigned long volatile   *)(& vsi->state));
  } else {
    i40e_vsi_reinit_locked(vsi);
  }
  goto ldv_61400;
  case 1U: 
  set_bit(12L, (unsigned long volatile   *)(& pf->state));
  goto ldv_61400;
  case 2U: 
  set_bit(13L, (unsigned long volatile   *)(& pf->state));
  goto ldv_61400;
  case 3U: 
  set_bit(14L, (unsigned long volatile   *)(& pf->state));
  goto ldv_61400;
  default: 
  netdev_err((struct net_device  const  *)netdev, "tx_timeout recovery unsuccessful\n");
  set_bit(21L, (unsigned long volatile   *)(& pf->state));
  set_bit(21L, (unsigned long volatile   *)(& vsi->state));
  goto ldv_61400;
  }
  ldv_61400: 
  i40e_service_event_schedule(pf);
  pf->tx_timeout_recovery_level = pf->tx_timeout_recovery_level + 1U;
  return;
}
}
struct rtnl_link_stats64 *i40e_get_vsi_stats_struct(struct i40e_vsi *vsi ) 
{ 


  {
  return (& vsi->net_stats);
}
}
struct rtnl_link_stats64 *i40e_get_netdev_stats_struct(struct net_device *netdev ,
                                                       struct rtnl_link_stats64 *stats ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_ring *tx_ring ;
  struct i40e_ring *rx_ring ;
  struct i40e_vsi *vsi ;
  struct rtnl_link_stats64 *vsi_stats ;
  struct rtnl_link_stats64 *tmp___0 ;
  int i ;
  int tmp___1 ;
  u64 bytes ;
  u64 packets ;
  unsigned int start ;
  struct i40e_ring *__var ;
  bool tmp___2 ;
  bool tmp___3 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  tmp___0 = i40e_get_vsi_stats_struct(vsi);
  vsi_stats = tmp___0;
  tmp___1 = constant_test_bit(3L, (unsigned long const volatile   *)(& vsi->state));
  if (tmp___1 != 0) {
    return (stats);
  } else {

  }
  if ((unsigned long )vsi->tx_rings == (unsigned long )((struct i40e_ring **)0)) {
    return (stats);
  } else {

  }
  rcu_read_lock();
  i = 0;
  goto ldv_61433;
  ldv_61432: 
  __var = (struct i40e_ring *)0;
  tx_ring = *((struct i40e_ring * volatile  *)vsi->tx_rings + (unsigned long )i);
  if ((unsigned long )tx_ring == (unsigned long )((struct i40e_ring *)0)) {
    goto ldv_61427;
  } else {

  }
  ldv_61428: 
  start = u64_stats_fetch_begin_irq((struct u64_stats_sync  const  *)(& tx_ring->syncp));
  packets = tx_ring->stats.packets;
  bytes = tx_ring->stats.bytes;
  tmp___2 = u64_stats_fetch_retry_irq((struct u64_stats_sync  const  *)(& tx_ring->syncp),
                                      start);
  if ((int )tmp___2) {
    goto ldv_61428;
  } else {

  }
  stats->tx_packets = stats->tx_packets + packets;
  stats->tx_bytes = stats->tx_bytes + bytes;
  rx_ring = tx_ring + 1UL;
  ldv_61430: 
  start = u64_stats_fetch_begin_irq((struct u64_stats_sync  const  *)(& rx_ring->syncp));
  packets = rx_ring->stats.packets;
  bytes = rx_ring->stats.bytes;
  tmp___3 = u64_stats_fetch_retry_irq((struct u64_stats_sync  const  *)(& rx_ring->syncp),
                                      start);
  if ((int )tmp___3) {
    goto ldv_61430;
  } else {

  }
  stats->rx_packets = stats->rx_packets + packets;
  stats->rx_bytes = stats->rx_bytes + bytes;
  ldv_61427: 
  i = i + 1;
  ldv_61433: ;
  if ((int )vsi->num_queue_pairs > i) {
    goto ldv_61432;
  } else {

  }
  rcu_read_unlock();
  stats->multicast = vsi_stats->multicast;
  stats->tx_errors = vsi_stats->tx_errors;
  stats->tx_dropped = vsi_stats->tx_dropped;
  stats->rx_errors = vsi_stats->rx_errors;
  stats->rx_crc_errors = vsi_stats->rx_crc_errors;
  stats->rx_length_errors = vsi_stats->rx_length_errors;
  return (stats);
}
}
void i40e_vsi_reset_stats(struct i40e_vsi *vsi ) 
{ 
  struct rtnl_link_stats64 *ns ;
  int i ;

  {
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
    return;
  } else {

  }
  ns = i40e_get_vsi_stats_struct(vsi);
  memset((void *)ns, 0, 184UL);
  memset((void *)(& vsi->net_stats_offsets), 0, 184UL);
  memset((void *)(& vsi->eth_stats), 0, 96UL);
  memset((void *)(& vsi->eth_stats_offsets), 0, 96UL);
  if ((unsigned long )vsi->rx_rings != (unsigned long )((struct i40e_ring **)0) && (unsigned long )*(vsi->rx_rings) != (unsigned long )((struct i40e_ring *)0)) {
    i = 0;
    goto ldv_61441;
    ldv_61440: 
    memset((void *)(& (*(vsi->rx_rings + (unsigned long )i))->stats), 0, 16UL);
    memset((void *)(& (*(vsi->rx_rings + (unsigned long )i))->__annonCompField122.rx_stats),
             0, 24UL);
    memset((void *)(& (*(vsi->tx_rings + (unsigned long )i))->stats), 0, 16UL);
    memset((void *)(& (*(vsi->tx_rings + (unsigned long )i))->__annonCompField122.tx_stats),
             0, 24UL);
    i = i + 1;
    ldv_61441: ;
    if ((int )vsi->num_queue_pairs > i) {
      goto ldv_61440;
    } else {

    }

  } else {

  }
  vsi->stat_offsets_loaded = 0;
  return;
}
}
void i40e_pf_reset_stats(struct i40e_pf *pf ) 
{ 
  int i ;

  {
  memset((void *)(& pf->stats), 0, 712UL);
  memset((void *)(& pf->stats_offsets), 0, 712UL);
  pf->stat_offsets_loaded = 0;
  i = 0;
  goto ldv_61448;
  ldv_61447: ;
  if ((unsigned long )pf->veb[i] != (unsigned long )((struct i40e_veb *)0)) {
    memset((void *)(& (pf->veb[i])->stats), 0, 96UL);
    memset((void *)(& (pf->veb[i])->stats_offsets), 0, 96UL);
    (pf->veb[i])->stat_offsets_loaded = 0;
  } else {

  }
  i = i + 1;
  ldv_61448: ;
  if (i <= 15) {
    goto ldv_61447;
  } else {

  }

  return;
}
}
static void i40e_stat_update48(struct i40e_hw *hw , u32 hireg , u32 loreg , bool offset_loaded ,
                               u64 *offset , u64 *stat ) 
{ 
  u64 new_data ;
  unsigned int tmp ;
  unsigned int tmp___0 ;
  unsigned long tmp___1 ;
  long tmp___2 ;
    klee_make_symbolic(&tmp___2, sizeof(long), "tmp___2");

  {
  if ((unsigned int )hw->device_id == 5492U) {
    tmp = readl((void const volatile   *)hw->hw_addr + (unsigned long )loreg);
    new_data = (u64 )tmp;
    tmp___0 = readl((void const volatile   *)hw->hw_addr + (unsigned long )hireg);
    new_data = (((unsigned long long )tmp___0 & 65535ULL) << 32) | new_data;
  } else {
    tmp___1 = readq((void const volatile   *)hw->hw_addr + (unsigned long )loreg);
    new_data = (u64 )tmp___1;
  }
  if (! offset_loaded) {
    *offset = new_data;
  } else {

  }
  tmp___2 = ldv__builtin_expect(*offset <= new_data, 1L);
  if (tmp___2 != 0L) {
    *stat = new_data - *offset;
  } else {
    *stat = (new_data - *offset) + 281474976710656ULL;
  }
  *stat = *stat & 281474976710655ULL;
  return;
}
}
static void i40e_stat_update32(struct i40e_hw *hw , u32 reg , bool offset_loaded ,
                               u64 *offset , u64 *stat ) 
{ 
  u32 new_data ;
  long tmp ;

  {
  new_data = readl((void const volatile   *)hw->hw_addr + (unsigned long )reg);
  if (! offset_loaded) {
    *offset = (u64 )new_data;
  } else {

  }
  tmp = ldv__builtin_expect((u64 )new_data >= *offset, 1L);
  if (tmp != 0L) {
    *stat = (u64 )(new_data - (unsigned int )*offset);
  } else {
    *stat = (u64 )(new_data - (unsigned int )*offset);
  }
  return;
}
}
void i40e_update_eth_stats(struct i40e_vsi *vsi ) 
{ 
  int stat_idx ;
    klee_make_symbolic(&stat_idx, sizeof(int), "stat_idx");
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  struct i40e_eth_stats *oes ;
  struct i40e_eth_stats *es ;

  {
  stat_idx = (int )vsi->info.stat_counter_idx;
  pf = vsi->back;
  hw = & pf->hw;
  es = & vsi->eth_stats;
  oes = & vsi->eth_stats_offsets;
  i40e_stat_update32(hw, (u32 )((stat_idx + 856064) * 4), (int )vsi->stat_offsets_loaded,
                     & oes->tx_errors, & es->tx_errors);
  i40e_stat_update32(hw, (u32 )((stat_idx + 401408) * 8), (int )vsi->stat_offsets_loaded,
                     & oes->rx_discards, & es->rx_discards);
  i40e_stat_update32(hw, (u32 )((stat_idx + 449664) * 8), (int )vsi->stat_offsets_loaded,
                     & oes->rx_unknown_protocol, & es->rx_unknown_protocol);
  i40e_stat_update32(hw, (u32 )((stat_idx + 856064) * 4), (int )vsi->stat_offsets_loaded,
                     & oes->tx_errors, & es->tx_errors);
  i40e_stat_update48(hw, (u32 )(stat_idx * 8 + 3506180), (u32 )((stat_idx + 438272) * 8),
                     (int )vsi->stat_offsets_loaded, & oes->rx_bytes, & es->rx_bytes);
  i40e_stat_update48(hw, (u32 )(stat_idx * 8 + 3588100), (u32 )((stat_idx + 448512) * 8),
                     (int )vsi->stat_offsets_loaded, & oes->rx_unicast, & es->rx_unicast);
  i40e_stat_update48(hw, (u32 )(stat_idx * 8 + 3591172), (u32 )((stat_idx + 448896) * 8),
                     (int )vsi->stat_offsets_loaded, & oes->rx_multicast, & es->rx_multicast);
  i40e_stat_update48(hw, (u32 )(stat_idx * 8 + 3594244), (u32 )((stat_idx + 449280) * 8),
                     (int )vsi->stat_offsets_loaded, & oes->rx_broadcast, & es->rx_broadcast);
  i40e_stat_update48(hw, (u32 )(stat_idx * 8 + 3309572), (u32 )((stat_idx + 413696) * 8),
                     (int )vsi->stat_offsets_loaded, & oes->tx_bytes, & es->tx_bytes);
  i40e_stat_update48(hw, (u32 )(stat_idx * 8 + 3391492), (u32 )((stat_idx + 423936) * 8),
                     (int )vsi->stat_offsets_loaded, & oes->tx_unicast, & es->tx_unicast);
  i40e_stat_update48(hw, (u32 )(stat_idx * 8 + 3394564), (u32 )((stat_idx + 424320) * 8),
                     (int )vsi->stat_offsets_loaded, & oes->tx_multicast, & es->tx_multicast);
  i40e_stat_update48(hw, (u32 )(stat_idx * 8 + 3397636), (u32 )((stat_idx + 424704) * 8),
                     (int )vsi->stat_offsets_loaded, & oes->tx_broadcast, & es->tx_broadcast);
  vsi->stat_offsets_loaded = 1;
  return;
}
}
static void i40e_update_veb_stats(struct i40e_veb *veb ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  struct i40e_eth_stats *oes ;
  struct i40e_eth_stats *es ;
  int idx ;
    klee_make_symbolic(&idx, sizeof(int), "idx");

  {
  pf = veb->pf;
  hw = & pf->hw;
  idx = 0;
  idx = (int )veb->stats_idx;
  es = & veb->stats;
  oes = & veb->stats_offsets;
  i40e_stat_update32(hw, (u32 )((idx + 430080) * 8), (int )veb->stat_offsets_loaded,
                     & oes->tx_discards, & es->tx_discards);
  if ((unsigned int )hw->revision_id != 0U) {
    i40e_stat_update32(hw, (u32 )((idx + 450608) * 8), (int )veb->stat_offsets_loaded,
                       & oes->rx_unknown_protocol, & es->rx_unknown_protocol);
  } else {

  }
  i40e_stat_update48(hw, (u32 )(idx * 8 + 3522564), (u32 )((idx + 440320) * 8), (int )veb->stat_offsets_loaded,
                     & oes->rx_bytes, & es->rx_bytes);
  i40e_stat_update48(hw, (u32 )(idx * 8 + 3604484), (u32 )((idx + 450560) * 8), (int )veb->stat_offsets_loaded,
                     & oes->rx_unicast, & es->rx_unicast);
  i40e_stat_update48(hw, (u32 )(idx * 8 + 3604612), (u32 )((idx + 450576) * 8), (int )veb->stat_offsets_loaded,
                     & oes->rx_multicast, & es->rx_multicast);
  i40e_stat_update48(hw, (u32 )(idx * 8 + 3604740), (u32 )((idx + 450592) * 8), (int )veb->stat_offsets_loaded,
                     & oes->rx_broadcast, & es->rx_broadcast);
  i40e_stat_update48(hw, (u32 )(idx * 8 + 3325956), (u32 )((idx + 415744) * 8), (int )veb->stat_offsets_loaded,
                     & oes->tx_bytes, & es->tx_bytes);
  i40e_stat_update48(hw, (u32 )(idx * 8 + 3407876), (u32 )((idx + 425984) * 8), (int )veb->stat_offsets_loaded,
                     & oes->tx_unicast, & es->tx_unicast);
  i40e_stat_update48(hw, (u32 )(idx * 8 + 3408004), (u32 )((idx + 426000) * 8), (int )veb->stat_offsets_loaded,
                     & oes->tx_multicast, & es->tx_multicast);
  i40e_stat_update48(hw, (u32 )(idx * 8 + 3408132), (u32 )((idx + 426016) * 8), (int )veb->stat_offsets_loaded,
                     & oes->tx_broadcast, & es->tx_broadcast);
  veb->stat_offsets_loaded = 1;
  return;
}
}
static void i40e_update_fcoe_stats(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  struct i40e_fcoe_stats *ofs ;
  struct i40e_fcoe_stats *fs ;
  int idx ;

  {
  pf = vsi->back;
  hw = & pf->hw;
  if ((unsigned int )vsi->type != 4U) {
    return;
  } else {

  }
  idx = (int )pf->pf_seid + 112;
  fs = & vsi->fcoe_stats;
  ofs = & vsi->fcoe_stats_offsets;
  i40e_stat_update32(hw, (u32 )((idx + 404032) * 8), (int )vsi->fcoe_stat_offsets_loaded,
                     & ofs->rx_fcoe_packets, & fs->rx_fcoe_packets);
  i40e_stat_update48(hw, (u32 )(idx * 8 + 3276804), (u32 )((idx + 409600) * 8), (int )vsi->fcoe_stat_offsets_loaded,
                     & ofs->rx_fcoe_dwords, & fs->rx_fcoe_dwords);
  i40e_stat_update32(hw, (u32 )((idx + 411648) * 8), (int )vsi->fcoe_stat_offsets_loaded,
                     & ofs->rx_fcoe_dropped, & fs->rx_fcoe_dropped);
  i40e_stat_update32(hw, (u32 )((idx + 428416) * 8), (int )vsi->fcoe_stat_offsets_loaded,
                     & ofs->tx_fcoe_packets, & fs->tx_fcoe_packets);
  i40e_stat_update48(hw, (u32 )(idx * 8 + 3440772), (u32 )((idx + 430096) * 8), (int )vsi->fcoe_stat_offsets_loaded,
                     & ofs->tx_fcoe_dwords, & fs->tx_fcoe_dwords);
  i40e_stat_update32(hw, (u32 )((idx + 403888) * 8), (int )vsi->fcoe_stat_offsets_loaded,
                     & ofs->fcoe_bad_fccrc, & fs->fcoe_bad_fccrc);
  i40e_stat_update32(hw, (u32 )((idx + 403456) * 8), (int )vsi->fcoe_stat_offsets_loaded,
                     & ofs->fcoe_last_error, & fs->fcoe_last_error);
  i40e_stat_update32(hw, (u32 )((idx + 403600) * 8), (int )vsi->fcoe_stat_offsets_loaded,
                     & ofs->fcoe_ddp_count, & fs->fcoe_ddp_count);
  vsi->fcoe_stat_offsets_loaded = 1;
  return;
}
}
static void i40e_update_link_xoff_rx(struct i40e_pf *pf ) 
{ 
  struct i40e_hw_port_stats *osd ;
  struct i40e_hw_port_stats *nsd ;
  struct i40e_hw *hw ;
  u64 xoff ;
  u16 i ;
  u16 v ;
  struct i40e_vsi *vsi ;
  struct i40e_ring *ring ;

  {
  osd = & pf->stats_offsets;
  nsd = & pf->stats;
  hw = & pf->hw;
  xoff = 0ULL;
  if ((unsigned int )hw->fc.current_mode != 3U && (unsigned int )hw->fc.current_mode != 1U) {
    return;
  } else {

  }
  xoff = nsd->link_xoff_rx;
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393260) * 8), (int )pf->stat_offsets_loaded,
                     & osd->link_xoff_rx, & nsd->link_xoff_rx);
  if (nsd->link_xoff_rx == xoff) {
    return;
  } else {

  }
  v = 0U;
  goto ldv_61507;
  ldv_61506: 
  vsi = *(pf->vsi + (unsigned long )v);
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0) || (unsigned long )*(vsi->tx_rings) == (unsigned long )((struct i40e_ring *)0)) {
    goto ldv_61501;
  } else {

  }
  i = 0U;
  goto ldv_61504;
  ldv_61503: 
  ring = *(vsi->tx_rings + (unsigned long )i);
  clear_bit(3L, (unsigned long volatile   *)(& ring->state));
  i = (u16 )((int )i + 1);
  ldv_61504: ;
  if ((int )vsi->num_queue_pairs > (int )i) {
    goto ldv_61503;
  } else {

  }

  ldv_61501: 
  v = (u16 )((int )v + 1);
  ldv_61507: ;
  if ((int )pf->num_alloc_vsi > (int )v) {
    goto ldv_61506;
  } else {

  }

  return;
}
}
static void i40e_update_prio_xoff_rx(struct i40e_pf *pf ) 
{ 
  struct i40e_hw_port_stats *osd ;
  struct i40e_hw_port_stats *nsd ;
  bool xoff[8U] ;
  unsigned int tmp ;
  struct i40e_dcbx_config *dcb_cfg ;
  struct i40e_hw *hw ;
  u16 i ;
  u16 v ;
  u8 tc ;
  u64 prio_xoff ;
  struct i40e_vsi *vsi ;
  struct i40e_ring *ring ;

  {
  osd = & pf->stats_offsets;
  nsd = & pf->stats;
  xoff[0] = 0;
  tmp = 1U;
  while (1) {
    if (tmp >= 8U) {
      break;
    } else {

    }
    xoff[tmp] = (_Bool)0;
    tmp = tmp + 1U;
  }
  hw = & pf->hw;
  dcb_cfg = & hw->local_dcbx_config;
  if ((unsigned int )dcb_cfg->pfc.pfcenable == 0U) {
    i40e_update_link_xoff_rx(pf);
    return;
  } else {

  }
  i = 0U;
  goto ldv_61523;
  ldv_61522: 
  prio_xoff = nsd->priority_xoff_rx[(int )i];
  i40e_stat_update32(hw, (u32 )((((int )hw->port + (int )i * 4) + 393296) * 8), (int )pf->stat_offsets_loaded,
                     (u64 *)(& osd->priority_xoff_rx) + (unsigned long )i, (u64 *)(& nsd->priority_xoff_rx) + (unsigned long )i);
  if (nsd->priority_xoff_rx[(int )i] == prio_xoff) {
    goto ldv_61521;
  } else {

  }
  tc = dcb_cfg->etscfg.prioritytable[(int )i];
  xoff[(int )tc] = 1;
  ldv_61521: 
  i = (u16 )((int )i + 1);
  ldv_61523: ;
  if ((unsigned int )i <= 7U) {
    goto ldv_61522;
  } else {

  }
  v = 0U;
  goto ldv_61532;
  ldv_61531: 
  vsi = *(pf->vsi + (unsigned long )v);
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0) || (unsigned long )*(vsi->tx_rings) == (unsigned long )((struct i40e_ring *)0)) {
    goto ldv_61526;
  } else {

  }
  i = 0U;
  goto ldv_61529;
  ldv_61528: 
  ring = *(vsi->tx_rings + (unsigned long )i);
  tc = ring->dcb_tc;
  if ((int )xoff[(int )tc]) {
    clear_bit(3L, (unsigned long volatile   *)(& ring->state));
  } else {

  }
  i = (u16 )((int )i + 1);
  ldv_61529: ;
  if ((int )vsi->num_queue_pairs > (int )i) {
    goto ldv_61528;
  } else {

  }

  ldv_61526: 
  v = (u16 )((int )v + 1);
  ldv_61532: ;
  if ((int )pf->num_alloc_vsi > (int )v) {
    goto ldv_61531;
  } else {

  }

  return;
}
}
static void i40e_update_vsi_stats(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  struct rtnl_link_stats64 *ons ;
  struct rtnl_link_stats64 *ns ;
  struct i40e_eth_stats *oes ;
  struct i40e_eth_stats *es ;
  u32 tx_restart ;
  u32 tx_busy ;
  struct i40e_ring *p ;
  u32 rx_page ;
  u32 rx_buf ;
  u64 bytes ;
  u64 packets ;
  unsigned int start ;
  u64 rx_p ;
  u64 rx_b ;
  u64 tx_p ;
  u64 tx_b ;
  u16 q ;
  int tmp ;
  int tmp___0 ;
  struct i40e_ring *__var ;
  bool tmp___1 ;
  bool tmp___2 ;

  {
  pf = vsi->back;
  tmp = constant_test_bit(3L, (unsigned long const volatile   *)(& vsi->state));
  if (tmp != 0) {
    return;
  } else {
    tmp___0 = constant_test_bit(1L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___0 != 0) {
      return;
    } else {

    }
  }
  ns = i40e_get_vsi_stats_struct(vsi);
  ons = & vsi->net_stats_offsets;
  es = & vsi->eth_stats;
  oes = & vsi->eth_stats_offsets;
  rx_p = 0ULL;
  rx_b = rx_p;
  tx_p = 0ULL;
  tx_b = tx_p;
  tx_busy = 0U;
  tx_restart = tx_busy;
  rx_page = 0U;
  rx_buf = 0U;
  rcu_read_lock();
  q = 0U;
  goto ldv_61562;
  ldv_61561: 
  __var = (struct i40e_ring *)0;
  p = *((struct i40e_ring * volatile  *)vsi->tx_rings + (unsigned long )q);
  ldv_61557: 
  start = u64_stats_fetch_begin_irq((struct u64_stats_sync  const  *)(& p->syncp));
  packets = p->stats.packets;
  bytes = p->stats.bytes;
  tmp___1 = u64_stats_fetch_retry_irq((struct u64_stats_sync  const  *)(& p->syncp),
                                      start);
  if ((int )tmp___1) {
    goto ldv_61557;
  } else {

  }
  tx_b = tx_b + bytes;
  tx_p = tx_p + packets;
  tx_restart = (u32 )p->__annonCompField122.tx_stats.restart_queue + tx_restart;
  tx_busy = (u32 )p->__annonCompField122.tx_stats.tx_busy + tx_busy;
  p = p + 1UL;
  ldv_61559: 
  start = u64_stats_fetch_begin_irq((struct u64_stats_sync  const  *)(& p->syncp));
  packets = p->stats.packets;
  bytes = p->stats.bytes;
  tmp___2 = u64_stats_fetch_retry_irq((struct u64_stats_sync  const  *)(& p->syncp),
                                      start);
  if ((int )tmp___2) {
    goto ldv_61559;
  } else {

  }
  rx_b = rx_b + bytes;
  rx_p = rx_p + packets;
  rx_buf = (u32 )p->__annonCompField122.rx_stats.alloc_buff_failed + rx_buf;
  rx_page = (u32 )p->__annonCompField122.rx_stats.alloc_page_failed + rx_page;
  q = (u16 )((int )q + 1);
  ldv_61562: ;
  if ((int )vsi->num_queue_pairs > (int )q) {
    goto ldv_61561;
  } else {

  }
  rcu_read_unlock();
  vsi->tx_restart = tx_restart;
  vsi->tx_busy = tx_busy;
  vsi->rx_page_failed = rx_page;
  vsi->rx_buf_failed = rx_buf;
  ns->rx_packets = rx_p;
  ns->rx_bytes = rx_b;
  ns->tx_packets = tx_p;
  ns->tx_bytes = tx_b;
  i40e_update_eth_stats(vsi);
  ons->tx_errors = oes->tx_errors;
  ns->tx_errors = es->tx_errors;
  ons->multicast = oes->rx_multicast;
  ns->multicast = es->rx_multicast;
  ons->rx_dropped = oes->rx_discards;
  ns->rx_dropped = es->rx_discards;
  ons->tx_dropped = oes->tx_discards;
  ns->tx_dropped = es->tx_discards;
  if ((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) == (unsigned long )vsi) {
    ns->rx_crc_errors = pf->stats.crc_errors;
    ns->rx_errors = pf->stats.crc_errors + pf->stats.illegal_bytes;
    ns->rx_length_errors = pf->stats.rx_length_errors;
  } else {

  }
  return;
}
}
static void i40e_update_pf_stats(struct i40e_pf *pf ) 
{ 
  struct i40e_hw_port_stats *osd ;
  struct i40e_hw_port_stats *nsd ;
  struct i40e_hw *hw ;
  u32 val ;
  int i ;

  {
  osd = & pf->stats_offsets;
  nsd = & pf->stats;
  hw = & pf->hw;
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3145732), (u32 )(((int )hw->port + 393216) * 8),
                     (int )pf->stat_offsets_loaded, & osd->eth.rx_bytes, & nsd->eth.rx_bytes);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3147396), (u32 )(((int )hw->port + 393424) * 8),
                     (int )pf->stat_offsets_loaded, & osd->eth.tx_bytes, & nsd->eth.tx_bytes);
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393408) * 8), (int )pf->stat_offsets_loaded,
                     & osd->eth.rx_discards, & nsd->eth.rx_discards);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3147172), (u32 )(((int )hw->port + 393396) * 8),
                     (int )pf->stat_offsets_loaded, & osd->eth.rx_unicast, & nsd->eth.rx_unicast);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3147204), (u32 )(((int )hw->port + 393400) * 8),
                     (int )pf->stat_offsets_loaded, & osd->eth.rx_multicast, & nsd->eth.rx_multicast);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3147236), (u32 )(((int )hw->port + 393404) * 8),
                     (int )pf->stat_offsets_loaded, & osd->eth.rx_broadcast, & nsd->eth.rx_broadcast);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3148228), (u32 )(((int )hw->port + 393528) * 8),
                     (int )pf->stat_offsets_loaded, & osd->eth.tx_unicast, & nsd->eth.tx_unicast);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3148260), (u32 )(((int )hw->port + 393532) * 8),
                     (int )pf->stat_offsets_loaded, & osd->eth.tx_multicast, & nsd->eth.tx_multicast);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3148292), (u32 )(((int )hw->port + 393536) * 8),
                     (int )pf->stat_offsets_loaded, & osd->eth.tx_broadcast, & nsd->eth.tx_broadcast);
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393540) * 8), (int )pf->stat_offsets_loaded,
                     & osd->tx_dropped_link_down, & nsd->tx_dropped_link_down);
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393232) * 8), (int )pf->stat_offsets_loaded,
                     & osd->crc_errors, & nsd->crc_errors);
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393244) * 8), (int )pf->stat_offsets_loaded,
                     & osd->illegal_bytes, & nsd->illegal_bytes);
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393220) * 8), (int )pf->stat_offsets_loaded,
                     & osd->mac_local_faults, & nsd->mac_local_faults);
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393224) * 8), (int )pf->stat_offsets_loaded,
                     & osd->mac_remote_faults, & nsd->mac_remote_faults);
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393236) * 8), (int )pf->stat_offsets_loaded,
                     & osd->rx_length_errors, & nsd->rx_length_errors);
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393256) * 8), (int )pf->stat_offsets_loaded,
                     & osd->link_xon_rx, & nsd->link_xon_rx);
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393520) * 8), (int )pf->stat_offsets_loaded,
                     & osd->link_xon_tx, & nsd->link_xon_tx);
  i40e_update_prio_xoff_rx(pf);
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393524) * 8), (int )pf->stat_offsets_loaded,
                     & osd->link_xoff_tx, & nsd->link_xoff_tx);
  i = 0;
  goto ldv_61573;
  ldv_61572: 
  i40e_stat_update32(hw, (u32 )((((int )hw->port + i * 4) + 393264) * 8), (int )pf->stat_offsets_loaded,
                     (u64 *)(& osd->priority_xon_rx) + (unsigned long )i, (u64 *)(& nsd->priority_xon_rx) + (unsigned long )i);
  i40e_stat_update32(hw, (u32 )((((int )hw->port + i * 4) + 393456) * 8), (int )pf->stat_offsets_loaded,
                     (u64 *)(& osd->priority_xon_tx) + (unsigned long )i, (u64 *)(& nsd->priority_xon_tx) + (unsigned long )i);
  i40e_stat_update32(hw, (u32 )((((int )hw->port + i * 4) + 393488) * 8), (int )pf->stat_offsets_loaded,
                     (u64 *)(& osd->priority_xoff_tx) + (unsigned long )i, (u64 *)(& nsd->priority_xoff_tx) + (unsigned long )i);
  i40e_stat_update32(hw, (u32 )((((int )hw->port + i * 4) + 393328) * 8), (int )pf->stat_offsets_loaded,
                     (u64 *)(& osd->priority_xon_2_xoff) + (unsigned long )i, (u64 *)(& nsd->priority_xon_2_xoff) + (unsigned long )i);
  i = i + 1;
  ldv_61573: ;
  if (i <= 7) {
    goto ldv_61572;
  } else {

  }
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3146884), (u32 )(((int )hw->port + 393360) * 8),
                     (int )pf->stat_offsets_loaded, & osd->rx_size_64, & nsd->rx_size_64);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3146916), (u32 )(((int )hw->port + 393364) * 8),
                     (int )pf->stat_offsets_loaded, & osd->rx_size_127, & nsd->rx_size_127);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3146948), (u32 )(((int )hw->port + 393368) * 8),
                     (int )pf->stat_offsets_loaded, & osd->rx_size_255, & nsd->rx_size_255);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3146980), (u32 )(((int )hw->port + 393372) * 8),
                     (int )pf->stat_offsets_loaded, & osd->rx_size_511, & nsd->rx_size_511);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3147012), (u32 )(((int )hw->port + 393376) * 8),
                     (int )pf->stat_offsets_loaded, & osd->rx_size_1023, & nsd->rx_size_1023);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3147044), (u32 )(((int )hw->port + 393380) * 8),
                     (int )pf->stat_offsets_loaded, & osd->rx_size_1522, & nsd->rx_size_1522);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3147076), (u32 )(((int )hw->port + 393384) * 8),
                     (int )pf->stat_offsets_loaded, & osd->rx_size_big, & nsd->rx_size_big);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3147428), (u32 )(((int )hw->port + 393428) * 8),
                     (int )pf->stat_offsets_loaded, & osd->tx_size_64, & nsd->tx_size_64);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3147460), (u32 )(((int )hw->port + 393432) * 8),
                     (int )pf->stat_offsets_loaded, & osd->tx_size_127, & nsd->tx_size_127);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3147492), (u32 )(((int )hw->port + 393436) * 8),
                     (int )pf->stat_offsets_loaded, & osd->tx_size_255, & nsd->tx_size_255);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3147524), (u32 )(((int )hw->port + 393440) * 8),
                     (int )pf->stat_offsets_loaded, & osd->tx_size_511, & nsd->tx_size_511);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3147556), (u32 )(((int )hw->port + 393444) * 8),
                     (int )pf->stat_offsets_loaded, & osd->tx_size_1023, & nsd->tx_size_1023);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3147588), (u32 )(((int )hw->port + 393448) * 8),
                     (int )pf->stat_offsets_loaded, & osd->tx_size_1522, & nsd->tx_size_1522);
  i40e_stat_update48(hw, (u32 )((int )hw->port * 8 + 3147620), (u32 )(((int )hw->port + 393452) * 8),
                     (int )pf->stat_offsets_loaded, & osd->tx_size_big, & nsd->tx_size_big);
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393248) * 8), (int )pf->stat_offsets_loaded,
                     & osd->rx_undersize, & nsd->rx_undersize);
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393388) * 8), (int )pf->stat_offsets_loaded,
                     & osd->rx_fragments, & nsd->rx_fragments);
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393252) * 8), (int )pf->stat_offsets_loaded,
                     & osd->rx_oversize, & nsd->rx_oversize);
  i40e_stat_update32(hw, (u32 )(((int )hw->port + 393392) * 8), (int )pf->stat_offsets_loaded,
                     & osd->rx_jabber, & nsd->rx_jabber);
  i40e_stat_update32(hw, (u32 )((int )pf->hw.pf_id * 12 + 2516992), (int )pf->stat_offsets_loaded,
                     & osd->fd_atr_match, & nsd->fd_atr_match);
  i40e_stat_update32(hw, (u32 )((int )pf->hw.pf_id * 12 + 2516996), (int )pf->stat_offsets_loaded,
                     & osd->fd_sb_match, & nsd->fd_sb_match);
  i40e_stat_update32(hw, (u32 )((int )pf->hw.pf_id * 12 + 2517000), (int )pf->stat_offsets_loaded,
                     & osd->fd_atr_tunnel_match, & nsd->fd_atr_tunnel_match);
  val = readl((void const volatile   *)hw->hw_addr + 1983264U);
  nsd->tx_lpi_status = val >> 31;
  nsd->rx_lpi_status = (val & 1073741824U) >> 30;
  i40e_stat_update32(hw, 1983424U, (int )pf->stat_offsets_loaded, & osd->tx_lpi_count,
                     & nsd->tx_lpi_count);
  i40e_stat_update32(hw, 1983392U, (int )pf->stat_offsets_loaded, & osd->rx_lpi_count,
                     & nsd->rx_lpi_count);
  pf->stat_offsets_loaded = 1;
  return;
}
}
void i40e_update_stats(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;

  {
  pf = vsi->back;
  if ((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) == (unsigned long )vsi) {
    i40e_update_pf_stats(pf);
  } else {

  }
  i40e_update_vsi_stats(vsi);
  i40e_update_fcoe_stats(vsi);
  return;
}
}
static struct i40e_mac_filter *i40e_find_filter(struct i40e_vsi *vsi , u8 *macaddr ,
                                                s16 vlan , bool is_vf , bool is_netdev ) 
{ 
  struct i40e_mac_filter *f ;
  struct list_head  const  *__mptr ;
  bool tmp ;
  struct list_head  const  *__mptr___0 ;

  {
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0) || (unsigned long )macaddr == (unsigned long )((u8 *)0U)) {
    return ((struct i40e_mac_filter *)0);
  } else {

  }
  __mptr = (struct list_head  const  *)vsi->mac_filter_list.next;
  f = (struct i40e_mac_filter *)__mptr;
  goto ldv_61592;
  ldv_61591: 
  tmp = ether_addr_equal((u8 const   *)macaddr, (u8 const   *)(& f->macaddr));
  if ((((int )tmp && (int )f->vlan == (int )vlan) && (! is_vf || (int )f->is_vf)) && (! is_netdev || (int )f->is_netdev)) {
    return (f);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)f->list.next;
  f = (struct i40e_mac_filter *)__mptr___0;
  ldv_61592: ;
  if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
    goto ldv_61591;
  } else {

  }

  return ((struct i40e_mac_filter *)0);
}
}
struct i40e_mac_filter *i40e_find_mac(struct i40e_vsi *vsi , u8 *macaddr , bool is_vf ,
                                      bool is_netdev ) 
{ 
  struct i40e_mac_filter *f ;
  struct list_head  const  *__mptr ;
  bool tmp ;
  struct list_head  const  *__mptr___0 ;

  {
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0) || (unsigned long )macaddr == (unsigned long )((u8 *)0U)) {
    return ((struct i40e_mac_filter *)0);
  } else {

  }
  __mptr = (struct list_head  const  *)vsi->mac_filter_list.next;
  f = (struct i40e_mac_filter *)__mptr;
  goto ldv_61606;
  ldv_61605: 
  tmp = ether_addr_equal((u8 const   *)macaddr, (u8 const   *)(& f->macaddr));
  if (((int )tmp && (! is_vf || (int )f->is_vf)) && (! is_netdev || (int )f->is_netdev)) {
    return (f);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)f->list.next;
  f = (struct i40e_mac_filter *)__mptr___0;
  ldv_61606: ;
  if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
    goto ldv_61605;
  } else {

  }

  return ((struct i40e_mac_filter *)0);
}
}
bool i40e_is_vsi_in_vlan(struct i40e_vsi *vsi ) 
{ 
  struct i40e_mac_filter *f ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  __mptr = (struct list_head  const  *)vsi->mac_filter_list.next;
  f = (struct i40e_mac_filter *)__mptr;
  goto ldv_61617;
  ldv_61616: ;
  if ((int )f->vlan >= 0) {
    return (1);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)f->list.next;
  f = (struct i40e_mac_filter *)__mptr___0;
  ldv_61617: ;
  if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
    goto ldv_61616;
  } else {

  }

  return (0);
}
}
struct i40e_mac_filter *i40e_put_mac_in_vlan(struct i40e_vsi *vsi , u8 *macaddr ,
                                             bool is_vf , bool is_netdev ) 
{ 
  struct i40e_mac_filter *f ;
  struct list_head  const  *__mptr ;
  struct i40e_mac_filter *tmp ;
  struct i40e_mac_filter *tmp___0 ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;
  struct i40e_mac_filter *tmp___2 ;
  int tmp___3 ;

  {
  __mptr = (struct list_head  const  *)vsi->mac_filter_list.next;
  f = (struct i40e_mac_filter *)__mptr;
  goto ldv_61631;
  ldv_61630: 
  tmp___0 = i40e_find_filter(vsi, macaddr, (int )f->vlan, (int )is_vf, (int )is_netdev);
  if ((unsigned long )tmp___0 == (unsigned long )((struct i40e_mac_filter *)0)) {
    tmp = i40e_add_filter(vsi, macaddr, (int )f->vlan, (int )is_vf, (int )is_netdev);
    if ((unsigned long )tmp == (unsigned long )((struct i40e_mac_filter *)0)) {
      return ((struct i40e_mac_filter *)0);
    } else {

    }
  } else {

  }
  __mptr___0 = (struct list_head  const  *)f->list.next;
  f = (struct i40e_mac_filter *)__mptr___0;
  ldv_61631: ;
  if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
    goto ldv_61630;
  } else {

  }
  tmp___3 = list_empty((struct list_head  const  *)(& vsi->mac_filter_list));
  if (tmp___3 == 0) {
    __mptr___1 = (struct list_head  const  *)vsi->mac_filter_list.next;
    tmp___2 = (struct i40e_mac_filter *)__mptr___1;
  } else {
    tmp___2 = (struct i40e_mac_filter *)0;
  }
  return (tmp___2);
}
}
static int i40e_rm_default_mac_filter(struct i40e_vsi *vsi , u8 *macaddr ) 
{ 
  struct i40e_aqc_remove_macvlan_element_data element ;
  struct i40e_pf *pf ;
  i40e_status aq_ret ;

  {
  pf = vsi->back;
  if ((unsigned int )vsi->type != 0U) {
    return (-22);
  } else {

  }
  memset((void *)(& element), 0, 16UL);
  ether_addr_copy((u8 *)(& element.mac_addr), (u8 const   *)macaddr);
  element.vlan_tag = 0U;
  element.flags = 9U;
  aq_ret = i40e_aq_remove_macvlan(& pf->hw, (int )vsi->seid, & element, 1, (struct i40e_asq_cmd_details *)0);
  if ((int )aq_ret != 0) {
    return (-2);
  } else {

  }
  return (0);
}
}
struct i40e_mac_filter *i40e_add_filter(struct i40e_vsi *vsi , u8 *macaddr , s16 vlan ,
                                        bool is_vf , bool is_netdev ) 
{ 
  struct i40e_mac_filter *f ;
  void *tmp ;

  {
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0) || (unsigned long )macaddr == (unsigned long )((u8 *)0U)) {
    return ((struct i40e_mac_filter *)0);
  } else {

  }
  f = i40e_find_filter(vsi, macaddr, (int )vlan, (int )is_vf, (int )is_netdev);
  if ((unsigned long )f == (unsigned long )((struct i40e_mac_filter *)0)) {
    tmp = kzalloc(32UL, 32U);
    f = (struct i40e_mac_filter *)tmp;
    if ((unsigned long )f == (unsigned long )((struct i40e_mac_filter *)0)) {
      goto add_filter_out;
    } else {

    }
    ether_addr_copy((u8 *)(& f->macaddr), (u8 const   *)macaddr);
    f->vlan = vlan;
    f->changed = 1;
    INIT_LIST_HEAD(& f->list);
    list_add(& f->list, & vsi->mac_filter_list);
  } else {

  }
  if ((int )is_vf) {
    if (! f->is_vf) {
      f->is_vf = 1;
      f->counter = (u8 )((int )f->counter + 1);
    } else {

    }
  } else
  if ((int )is_netdev) {
    if (! f->is_netdev) {
      f->is_netdev = 1;
      f->counter = (u8 )((int )f->counter + 1);
    } else {

    }
  } else {
    f->counter = (u8 )((int )f->counter + 1);
  }
  if ((int )f->changed) {
    vsi->flags = vsi->flags | 1UL;
    (vsi->back)->flags = (vsi->back)->flags | 32768ULL;
  } else {

  }
  add_filter_out: ;
  return (f);
}
}
void i40e_del_filter(struct i40e_vsi *vsi , u8 *macaddr , s16 vlan , bool is_vf ,
                     bool is_netdev ) 
{ 
  struct i40e_mac_filter *f ;
  int min_f ;
    klee_make_symbolic(&min_f, sizeof(int), "min_f");

  {
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0) || (unsigned long )macaddr == (unsigned long )((u8 *)0U)) {
    return;
  } else {

  }
  f = i40e_find_filter(vsi, macaddr, (int )vlan, (int )is_vf, (int )is_netdev);
  if ((unsigned long )f == (unsigned long )((struct i40e_mac_filter *)0) || (unsigned int )f->counter == 0U) {
    return;
  } else {

  }
  if ((int )is_vf) {
    if ((int )f->is_vf) {
      f->is_vf = 0;
      f->counter = (u8 )((int )f->counter - 1);
    } else {

    }
  } else
  if ((int )is_netdev) {
    if ((int )f->is_netdev) {
      f->is_netdev = 0;
      f->counter = (u8 )((int )f->counter - 1);
    } else {

    }
  } else {
    min_f = 0;
    min_f = (int )f->is_vf + min_f;
    min_f = (int )f->is_netdev + min_f;
    if ((int )f->counter > min_f) {
      f->counter = (u8 )((int )f->counter - 1);
    } else {

    }
  }
  if ((unsigned int )f->counter == 0U) {
    f->changed = 1;
    vsi->flags = vsi->flags | 1UL;
    (vsi->back)->flags = (vsi->back)->flags | 32768ULL;
  } else {

  }
  return;
}
}
int i40e_set_mac(struct net_device *netdev , void *p ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  struct sockaddr *addr ;
  struct i40e_mac_filter *f ;
  bool tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
    klee_make_symbolic(&tmp___4, sizeof(int), "tmp___4");
  bool tmp___5 ;
  i40e_status ret ;
  struct i40e_aqc_remove_macvlan_element_data element ;
  bool tmp___6 ;
  struct i40e_aqc_add_macvlan_element_data element___0 ;
  bool tmp___7 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  hw = & pf->hw;
  addr = (struct sockaddr *)p;
  tmp___0 = is_valid_ether_addr((u8 const   *)(& addr->sa_data));
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    return (-99);
  } else {

  }
  tmp___2 = ether_addr_equal((u8 const   *)netdev->dev_addr, (u8 const   *)(& addr->sa_data));
  if ((int )tmp___2) {
    netdev_info((struct net_device  const  *)netdev, "already using mac address %pM\n",
                (char *)(& addr->sa_data));
    return (0);
  } else {

  }
  tmp___3 = constant_test_bit(3L, (unsigned long const volatile   *)(& (vsi->back)->state));
  if (tmp___3 != 0) {
    return (-99);
  } else {
    tmp___4 = constant_test_bit(9L, (unsigned long const volatile   *)(& (vsi->back)->state));
    if (tmp___4 != 0) {
      return (-99);
    } else {

    }
  }
  tmp___5 = ether_addr_equal((u8 const   *)(& hw->mac.addr), (u8 const   *)(& addr->sa_data));
  if ((int )tmp___5) {
    netdev_info((struct net_device  const  *)netdev, "returning to hw mac address %pM\n",
                (u8 *)(& hw->mac.addr));
  } else {
    netdev_info((struct net_device  const  *)netdev, "set new mac address %pM\n",
                (char *)(& addr->sa_data));
  }
  if ((unsigned int )vsi->type == 0U) {
    ret = i40e_aq_mac_address_write(& (vsi->back)->hw, 16384, (u8 *)(& addr->sa_data),
                                    (struct i40e_asq_cmd_details *)0);
    if ((int )ret != 0) {
      netdev_info((struct net_device  const  *)netdev, "Addr change for Main VSI failed: %d\n",
                  (int )ret);
      return (-99);
    } else {

    }
  } else {

  }
  tmp___6 = ether_addr_equal((u8 const   *)netdev->dev_addr, (u8 const   *)(& hw->mac.addr));
  if ((int )tmp___6) {
    memset((void *)(& element), 0, 16UL);
    ether_addr_copy((u8 *)(& element.mac_addr), (u8 const   *)netdev->dev_addr);
    element.flags = 1U;
    i40e_aq_remove_macvlan(& pf->hw, (int )vsi->seid, & element, 1, (struct i40e_asq_cmd_details *)0);
  } else {
    i40e_del_filter(vsi, netdev->dev_addr, -1, 0, 0);
  }
  tmp___7 = ether_addr_equal((u8 const   *)(& addr->sa_data), (u8 const   *)(& hw->mac.addr));
  if ((int )tmp___7) {
    memset((void *)(& element___0), 0, 16UL);
    ether_addr_copy((u8 *)(& element___0.mac_addr), (u8 const   *)(& hw->mac.addr));
    element___0.flags = 1U;
    i40e_aq_add_macvlan(& pf->hw, (int )vsi->seid, & element___0, 1, (struct i40e_asq_cmd_details *)0);
  } else {
    f = i40e_add_filter(vsi, (u8 *)(& addr->sa_data), -1, 0, 0);
    if ((unsigned long )f != (unsigned long )((struct i40e_mac_filter *)0)) {
      f->is_laa = 1;
    } else {

    }
  }
  i40e_sync_vsi_filters(vsi);
  ether_addr_copy(netdev->dev_addr, (u8 const   *)(& addr->sa_data));
  return (0);
}
}
void i40e_vsi_setup_queue_map(struct i40e_vsi *vsi , struct i40e_vsi_context *ctxt ,
                              u8 enabled_tc , bool is_add ) 
{ 
  struct i40e_pf *pf ;
  u16 sections ;
  u8 netdev_tc ;
  u16 numtc ;
  u16 qcount ;
  u8 offset ;
  u16 qmap ;
  int i ;
  u16 num_tc_qps ;
  int __min1 ;
    klee_make_symbolic(&__min1, sizeof(int), "__min1");
  int __min2 ;
    klee_make_symbolic(&__min2, sizeof(int), "__min2");
  int __min1___0 ;
    klee_make_symbolic(&__min1___0, sizeof(int), "__min1___0");
  int __min2___0 ;
    klee_make_symbolic(&__min2___0, sizeof(int), "__min2___0");
  int pow ;
    klee_make_symbolic(&pow, sizeof(int), "pow");
  int num_qps ;
    klee_make_symbolic(&num_qps, sizeof(int), "num_qps");
  int __min1___1 ;
    klee_make_symbolic(&__min1___1, sizeof(int), "__min1___1");
  int __min2___1 ;
    klee_make_symbolic(&__min2___1, sizeof(int), "__min2___1");
  int __ret_warn_on ;
  long tmp ;
  u8 tmp___0 ;

  {
  pf = vsi->back;
  sections = 0U;
  netdev_tc = 0U;
  numtc = 0U;
  num_tc_qps = 0U;
  sections = 64U;
  offset = 0U;
  if ((unsigned int )enabled_tc != 0U && ((vsi->back)->flags & 1048576ULL) != 0ULL) {
    i = 0;
    goto ldv_61689;
    ldv_61688: ;
    if (((int )enabled_tc >> i) & 1) {
      numtc = (u16 )((int )numtc + 1);
    } else {

    }
    i = i + 1;
    ldv_61689: ;
    if (i <= 7) {
      goto ldv_61688;
    } else {

    }

    if ((unsigned int )numtc == 0U) {
      dev_warn((struct device  const  *)(& (pf->pdev)->dev), "DCB is enabled but no TC enabled, forcing TC0\n");
      numtc = 1U;
    } else {

    }
  } else {
    numtc = 1U;
  }
  vsi->tc_config.numtc = (u8 )numtc;
  vsi->tc_config.enabled_tc = (unsigned int )enabled_tc != 0U ? enabled_tc : 1U;
  __min1 = (int )vsi->alloc_queue_pairs;
  __min2 = (int )pf->num_lan_msix;
  qcount = (u16 )(__min1 < __min2 ? __min1 : __min2);
  num_tc_qps = (u16 )((int )qcount / (int )numtc);
  __min1___0 = (int )num_tc_qps;
  __min2___0 = 64;
  num_tc_qps = (u16 )(__min1___0 < __min2___0 ? __min1___0 : __min2___0);
  i = 0;
  goto ldv_61715;
  ldv_61714: ;
  if (((int )vsi->tc_config.enabled_tc >> i) & 1) {
    switch ((unsigned int )vsi->type) {
    case 0U: 
    __min1___1 = (int )pf->rss_size;
    __min2___1 = (int )num_tc_qps;
    qcount = (u16 )(__min1___1 < __min2___1 ? __min1___1 : __min2___1);
    goto ldv_61703;
    case 4U: 
    qcount = num_tc_qps;
    goto ldv_61703;
    case 7U: ;
    case 6U: ;
    case 2U: ;
    default: 
    qcount = num_tc_qps;
    __ret_warn_on = i != 0;
    tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp != 0L) {
      warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c",
                         1560);
    } else {

    }
    ldv__builtin_expect(__ret_warn_on != 0, 0L);
    goto ldv_61703;
    }
    ldv_61703: 
    vsi->tc_config.tc_info[i].qoffset = (u16 )offset;
    vsi->tc_config.tc_info[i].qcount = qcount;
    num_qps = (int )qcount;
    pow = 0;
    goto ldv_61712;
    ldv_61711: 
    pow = pow + 1;
    num_qps = num_qps >> 1;
    ldv_61712: ;
    if (num_qps != 0 && 1 << pow < (int )qcount) {
      goto ldv_61711;
    } else {

    }
    tmp___0 = netdev_tc;
    netdev_tc = (u8 )((int )netdev_tc + 1);
    vsi->tc_config.tc_info[i].netdev_tc = tmp___0;
    qmap = (u16 )((int )((short )offset) | (int )((short )(pow << 9)));
    offset = (int )((u8 )qcount) + (int )offset;
  } else {
    vsi->tc_config.tc_info[i].qoffset = 0U;
    vsi->tc_config.tc_info[i].qcount = 1U;
    vsi->tc_config.tc_info[i].netdev_tc = 0U;
    qmap = 0U;
  }
  ctxt->info.tc_mapping[i] = qmap;
  i = i + 1;
  ldv_61715: ;
  if (i <= 7) {
    goto ldv_61714;
  } else {

  }
  vsi->num_queue_pairs = (u16 )offset;
  if ((unsigned int )vsi->type == 0U && (unsigned int )numtc == 1U) {
    if ((unsigned int )vsi->req_queue_pairs != 0U) {
      vsi->num_queue_pairs = vsi->req_queue_pairs;
    } else {
      vsi->num_queue_pairs = pf->num_lan_msix;
    }
  } else {

  }
  if ((int )is_add) {
    sections = (u16 )((unsigned int )sections | 512U);
    ctxt->info.up_enable_bits = enabled_tc;
  } else {

  }
  if ((unsigned int )vsi->type == 6U) {
    ctxt->info.mapping_flags = (__le16 )((unsigned int )ctxt->info.mapping_flags | 1U);
    i = 0;
    goto ldv_61718;
    ldv_61717: 
    ctxt->info.queue_mapping[i] = (int )vsi->base_queue + (int )((unsigned short )i);
    i = i + 1;
    ldv_61718: ;
    if ((int )vsi->num_queue_pairs > i) {
      goto ldv_61717;
    } else {

    }

  } else {
    ctxt->info.mapping_flags = ctxt->info.mapping_flags;
    ctxt->info.queue_mapping[0] = vsi->base_queue;
  }
  ctxt->info.valid_sections = (__le16 )((int )ctxt->info.valid_sections | (int )sections);
  return;
}
}
void i40e_set_rx_mode(struct net_device *netdev ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_mac_filter *f ;
  struct i40e_mac_filter *ftmp ;
  struct i40e_vsi *vsi ;
  struct netdev_hw_addr *uca ;
  struct netdev_hw_addr *mca ;
  struct netdev_hw_addr *ha ;
  struct list_head  const  *__mptr ;
  bool tmp___0 ;
  struct i40e_mac_filter *tmp___1 ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;
  bool tmp___2 ;
  struct i40e_mac_filter *tmp___3 ;
  struct list_head  const  *__mptr___2 ;
  struct list_head  const  *__mptr___3 ;
  struct list_head  const  *__mptr___4 ;
  bool found ;
  struct list_head  const  *__mptr___5 ;
  bool tmp___4 ;
  struct list_head  const  *__mptr___6 ;
  struct list_head  const  *__mptr___7 ;
  bool tmp___5 ;
  struct list_head  const  *__mptr___8 ;
  struct list_head *__ptr ;
  struct list_head  const  *__mptr___9 ;
  struct list_head *________p1 ;
  struct list_head *_________p1 ;
  union __anonunion___u_459 __u ;
  int tmp___6 ;
    klee_make_symbolic(&tmp___6, sizeof(int), "tmp___6");
  bool tmp___7 ;
  struct list_head *__ptr___0 ;
  struct list_head  const  *__mptr___10 ;
  struct list_head *________p1___0 ;
  struct list_head *_________p1___0 ;
  union __anonunion___u_461 __u___0 ;
  int tmp___8 ;
    klee_make_symbolic(&tmp___8, sizeof(int), "tmp___8");
  bool tmp___9 ;
  struct list_head  const  *__mptr___11 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  __mptr = (struct list_head  const  *)netdev->uc.list.next;
  uca = (struct netdev_hw_addr *)__mptr;
  goto ldv_61735;
  ldv_61734: 
  tmp___1 = i40e_find_mac(vsi, (u8 *)(& uca->addr), 0, 1);
  if ((unsigned long )tmp___1 == (unsigned long )((struct i40e_mac_filter *)0)) {
    tmp___0 = i40e_is_vsi_in_vlan(vsi);
    if ((int )tmp___0) {
      i40e_put_mac_in_vlan(vsi, (u8 *)(& uca->addr), 0, 1);
    } else {
      i40e_add_filter(vsi, (u8 *)(& uca->addr), -1, 0, 1);
    }
  } else {

  }
  __mptr___0 = (struct list_head  const  *)uca->list.next;
  uca = (struct netdev_hw_addr *)__mptr___0;
  ldv_61735: ;
  if ((unsigned long )(& uca->list) != (unsigned long )(& netdev->uc.list)) {
    goto ldv_61734;
  } else {

  }
  __mptr___1 = (struct list_head  const  *)netdev->mc.list.next;
  mca = (struct netdev_hw_addr *)__mptr___1;
  goto ldv_61742;
  ldv_61741: 
  tmp___3 = i40e_find_mac(vsi, (u8 *)(& mca->addr), 0, 1);
  if ((unsigned long )tmp___3 == (unsigned long )((struct i40e_mac_filter *)0)) {
    tmp___2 = i40e_is_vsi_in_vlan(vsi);
    if ((int )tmp___2) {
      i40e_put_mac_in_vlan(vsi, (u8 *)(& mca->addr), 0, 1);
    } else {
      i40e_add_filter(vsi, (u8 *)(& mca->addr), -1, 0, 1);
    }
  } else {

  }
  __mptr___2 = (struct list_head  const  *)mca->list.next;
  mca = (struct netdev_hw_addr *)__mptr___2;
  ldv_61742: ;
  if ((unsigned long )(& mca->list) != (unsigned long )(& netdev->mc.list)) {
    goto ldv_61741;
  } else {

  }
  __mptr___3 = (struct list_head  const  *)vsi->mac_filter_list.next;
  f = (struct i40e_mac_filter *)__mptr___3;
  __mptr___4 = (struct list_head  const  *)f->list.next;
  ftmp = (struct i40e_mac_filter *)__mptr___4;
  goto ldv_61798;
  ldv_61797: 
  found = 0;
  if (! f->is_netdev) {
    goto ldv_61751;
  } else {

  }
  tmp___9 = is_multicast_ether_addr((u8 const   *)(& f->macaddr));
  if ((int )tmp___9) {
    __mptr___5 = (struct list_head  const  *)netdev->mc.list.next;
    mca = (struct netdev_hw_addr *)__mptr___5;
    goto ldv_61758;
    ldv_61757: 
    tmp___4 = ether_addr_equal((u8 const   *)(& mca->addr), (u8 const   *)(& f->macaddr));
    if ((int )tmp___4) {
      found = 1;
      goto ldv_61756;
    } else {

    }
    __mptr___6 = (struct list_head  const  *)mca->list.next;
    mca = (struct netdev_hw_addr *)__mptr___6;
    ldv_61758: ;
    if ((unsigned long )(& mca->list) != (unsigned long )(& netdev->mc.list)) {
      goto ldv_61757;
    } else {

    }
    ldv_61756: ;
  } else {
    __mptr___7 = (struct list_head  const  *)netdev->uc.list.next;
    uca = (struct netdev_hw_addr *)__mptr___7;
    goto ldv_61765;
    ldv_61764: 
    tmp___5 = ether_addr_equal((u8 const   *)(& uca->addr), (u8 const   *)(& f->macaddr));
    if ((int )tmp___5) {
      found = 1;
      goto ldv_61763;
    } else {

    }
    __mptr___8 = (struct list_head  const  *)uca->list.next;
    uca = (struct netdev_hw_addr *)__mptr___8;
    ldv_61765: ;
    if ((unsigned long )(& uca->list) != (unsigned long )(& netdev->uc.list)) {
      goto ldv_61764;
    } else {

    }
    ldv_61763: 
    __ptr = netdev->dev_addrs.list.next;
    __read_once_size((void const volatile   *)(& __ptr), (void *)(& __u.__c), 8);
    _________p1 = __u.__val;
    ________p1 = _________p1;
    tmp___6 = debug_lockdep_rcu_enabled();
    __mptr___9 = (struct list_head  const  *)________p1;
    ha = (struct netdev_hw_addr *)__mptr___9;
    goto ldv_61796;
    ldv_61795: 
    tmp___7 = ether_addr_equal((u8 const   *)(& ha->addr), (u8 const   *)(& f->macaddr));
    if ((int )tmp___7) {
      found = 1;
      goto ldv_61794;
    } else {

    }
    __ptr___0 = ha->list.next;
    __read_once_size((void const volatile   *)(& __ptr___0), (void *)(& __u___0.__c),
                     8);
    _________p1___0 = __u___0.__val;
    ________p1___0 = _________p1___0;
    tmp___8 = debug_lockdep_rcu_enabled();
    __mptr___10 = (struct list_head  const  *)________p1___0;
    ha = (struct netdev_hw_addr *)__mptr___10;
    ldv_61796: ;
    if ((unsigned long )(& ha->list) != (unsigned long )(& netdev->dev_addrs.list)) {
      goto ldv_61795;
    } else {

    }
    ldv_61794: ;
  }
  if (! found) {
    i40e_del_filter(vsi, (u8 *)(& f->macaddr), -1, 0, 1);
  } else {

  }
  ldv_61751: 
  f = ftmp;
  __mptr___11 = (struct list_head  const  *)ftmp->list.next;
  ftmp = (struct i40e_mac_filter *)__mptr___11;
  ldv_61798: ;
  if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
    goto ldv_61797;
  } else {

  }

  if (vsi->current_netdev_flags != (vsi->netdev)->flags) {
    vsi->flags = vsi->flags | 1UL;
    (vsi->back)->flags = (vsi->back)->flags | 32768ULL;
  } else {

  }
  return;
}
}
int i40e_sync_vsi_filters(struct i40e_vsi *vsi ) 
{ 
  struct i40e_mac_filter *f ;
  struct i40e_mac_filter *ftmp ;
  bool promisc_forced_on ;
  bool add_happened ;
  int filter_list_len ;
    klee_make_symbolic(&filter_list_len, sizeof(int), "filter_list_len");
  u32 changed_flags ;
  i40e_status aq_ret ;
  struct i40e_pf *pf ;
  int num_add ;
    klee_make_symbolic(&num_add, sizeof(int), "num_add");
  int num_del ;
    klee_make_symbolic(&num_del, sizeof(int), "num_del");
  u16 cmd_flags ;
  struct i40e_aqc_add_macvlan_element_data *add_list ;
  struct i40e_aqc_remove_macvlan_element_data *del_list ;
  int tmp ;
  void *tmp___0 ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;
  void *tmp___1 ;
  struct list_head  const  *__mptr___2 ;
  struct list_head  const  *__mptr___3 ;
  struct list_head  const  *__mptr___4 ;
  int tmp___2 ;
  bool cur_multipromisc ;
  bool cur_promisc ;
  int tmp___3 ;
  int tmp___4 ;

  {
  promisc_forced_on = 0;
  add_happened = 0;
  filter_list_len = 0;
  changed_flags = 0U;
  aq_ret = 0;
  num_add = 0;
  num_del = 0;
  goto ldv_61817;
  ldv_61816: 
  usleep_range(1000UL, 2000UL);
  ldv_61817: 
  tmp = test_and_set_bit(1L, (unsigned long volatile   *)(& vsi->state));
  if (tmp != 0) {
    goto ldv_61816;
  } else {

  }
  pf = vsi->back;
  if ((unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0)) {
    changed_flags = vsi->current_netdev_flags ^ (vsi->netdev)->flags;
    vsi->current_netdev_flags = (vsi->netdev)->flags;
  } else {

  }
  if ((int )vsi->flags & 1) {
    vsi->flags = vsi->flags & 0xfffffffffffffffeUL;
    filter_list_len = (int )((unsigned int )pf->hw.aq.asq_buf_size / 16U);
    tmp___0 = kcalloc((size_t )filter_list_len, 16UL, 208U);
    del_list = (struct i40e_aqc_remove_macvlan_element_data *)tmp___0;
    if ((unsigned long )del_list == (unsigned long )((struct i40e_aqc_remove_macvlan_element_data *)0)) {
      return (-12);
    } else {

    }
    __mptr = (struct list_head  const  *)vsi->mac_filter_list.next;
    f = (struct i40e_mac_filter *)__mptr;
    __mptr___0 = (struct list_head  const  *)f->list.next;
    ftmp = (struct i40e_mac_filter *)__mptr___0;
    goto ldv_61827;
    ldv_61826: ;
    if (! f->changed) {
      goto ldv_61825;
    } else {

    }
    if ((unsigned int )f->counter != 0U) {
      goto ldv_61825;
    } else {

    }
    f->changed = 0;
    cmd_flags = 0U;
    ether_addr_copy((u8 *)(& (del_list + (unsigned long )num_del)->mac_addr), (u8 const   *)(& f->macaddr));
    (del_list + (unsigned long )num_del)->vlan_tag = (int )f->vlan != -1 ? (unsigned short )f->vlan : 0U;
    cmd_flags = (u16 )((unsigned int )cmd_flags | 1U);
    (del_list + (unsigned long )num_del)->flags = (u8 )cmd_flags;
    num_del = num_del + 1;
    list_del(& f->list);
    kfree((void const   *)f);
    if (num_del == filter_list_len) {
      aq_ret = i40e_aq_remove_macvlan(& pf->hw, (int )vsi->seid, del_list, (int )((u16 )num_del),
                                      (struct i40e_asq_cmd_details *)0);
      num_del = 0;
      memset((void *)del_list, 0, 16UL);
      if ((int )aq_ret != 0 && (unsigned int )pf->hw.aq.asq_last_status != 2U) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ignoring delete macvlan error, err %d, aq_err %d while flushing a full buffer\n",
                  (int )aq_ret, (unsigned int )pf->hw.aq.asq_last_status);
      } else {

      }
    } else {

    }
    ldv_61825: 
    f = ftmp;
    __mptr___1 = (struct list_head  const  *)ftmp->list.next;
    ftmp = (struct i40e_mac_filter *)__mptr___1;
    ldv_61827: ;
    if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
      goto ldv_61826;
    } else {

    }

    if (num_del != 0) {
      aq_ret = i40e_aq_remove_macvlan(& pf->hw, (int )vsi->seid, del_list, (int )((u16 )num_del),
                                      (struct i40e_asq_cmd_details *)0);
      num_del = 0;
      if ((int )aq_ret != 0 && (unsigned int )pf->hw.aq.asq_last_status != 2U) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ignoring delete macvlan error, err %d, aq_err %d\n",
                  (int )aq_ret, (unsigned int )pf->hw.aq.asq_last_status);
      } else {

      }
    } else {

    }
    kfree((void const   *)del_list);
    del_list = (struct i40e_aqc_remove_macvlan_element_data *)0;
    filter_list_len = (int )((unsigned int )pf->hw.aq.asq_buf_size / 16U);
    tmp___1 = kcalloc((size_t )filter_list_len, 16UL, 208U);
    add_list = (struct i40e_aqc_add_macvlan_element_data *)tmp___1;
    if ((unsigned long )add_list == (unsigned long )((struct i40e_aqc_add_macvlan_element_data *)0)) {
      return (-12);
    } else {

    }
    __mptr___2 = (struct list_head  const  *)vsi->mac_filter_list.next;
    f = (struct i40e_mac_filter *)__mptr___2;
    __mptr___3 = (struct list_head  const  *)f->list.next;
    ftmp = (struct i40e_mac_filter *)__mptr___3;
    goto ldv_61838;
    ldv_61837: ;
    if (! f->changed) {
      goto ldv_61835;
    } else {

    }
    if ((unsigned int )f->counter == 0U) {
      goto ldv_61835;
    } else {

    }
    f->changed = 0;
    add_happened = 1;
    cmd_flags = 0U;
    ether_addr_copy((u8 *)(& (add_list + (unsigned long )num_add)->mac_addr), (u8 const   *)(& f->macaddr));
    (add_list + (unsigned long )num_add)->vlan_tag = (int )f->vlan != -1 ? (unsigned short )f->vlan : 0U;
    (add_list + (unsigned long )num_add)->queue_number = 0U;
    cmd_flags = (u16 )((unsigned int )cmd_flags | 1U);
    (add_list + (unsigned long )num_add)->flags = cmd_flags;
    num_add = num_add + 1;
    if (num_add == filter_list_len) {
      aq_ret = i40e_aq_add_macvlan(& pf->hw, (int )vsi->seid, add_list, (int )((u16 )num_add),
                                   (struct i40e_asq_cmd_details *)0);
      num_add = 0;
      if ((int )aq_ret != 0) {
        goto ldv_61836;
      } else {

      }
      memset((void *)add_list, 0, 16UL);
    } else {

    }
    ldv_61835: 
    f = ftmp;
    __mptr___4 = (struct list_head  const  *)ftmp->list.next;
    ftmp = (struct i40e_mac_filter *)__mptr___4;
    ldv_61838: ;
    if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
      goto ldv_61837;
    } else {

    }
    ldv_61836: ;
    if (num_add != 0) {
      aq_ret = i40e_aq_add_macvlan(& pf->hw, (int )vsi->seid, add_list, (int )((u16 )num_add),
                                   (struct i40e_asq_cmd_details *)0);
      num_add = 0;
    } else {

    }
    kfree((void const   *)add_list);
    add_list = (struct i40e_aqc_add_macvlan_element_data *)0;
    if (((int )add_happened && (int )aq_ret != 0) && (unsigned int )pf->hw.aq.asq_last_status != 14U) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add filter failed, err %d, aq_err %d\n",
                (int )aq_ret, (unsigned int )pf->hw.aq.asq_last_status);
      if ((unsigned int )pf->hw.aq.asq_last_status == 16U) {
        tmp___2 = constant_test_bit(17L, (unsigned long const volatile   *)(& vsi->state));
        if (tmp___2 == 0) {
          promisc_forced_on = 1;
          set_bit(17L, (unsigned long volatile   *)(& vsi->state));
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "promiscuous mode forced on\n");
        } else {

        }
      } else {

      }
    } else {

    }
  } else {

  }
  if ((changed_flags & 512U) != 0U) {
    cur_multipromisc = (vsi->current_netdev_flags & 512U) != 0U;
    aq_ret = i40e_aq_set_vsi_multicast_promiscuous(& (vsi->back)->hw, (int )vsi->seid,
                                                   (int )cur_multipromisc, (struct i40e_asq_cmd_details *)0);
    if ((int )aq_ret != 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "set multi promisc failed, err %d, aq_err %d\n",
                (int )aq_ret, (unsigned int )pf->hw.aq.asq_last_status);
    } else {

    }
  } else {

  }
  if ((changed_flags & 256U) != 0U || (int )promisc_forced_on) {
    if ((vsi->current_netdev_flags & 256U) != 0U) {
      tmp___4 = 1;
    } else {
      tmp___3 = constant_test_bit(17L, (unsigned long const volatile   *)(& vsi->state));
      if (tmp___3 != 0) {
        tmp___4 = 1;
      } else {
        tmp___4 = 0;
      }
    }
    cur_promisc = (bool )tmp___4;
    aq_ret = i40e_aq_set_vsi_unicast_promiscuous(& (vsi->back)->hw, (int )vsi->seid,
                                                 (int )cur_promisc, (struct i40e_asq_cmd_details *)0);
    if ((int )aq_ret != 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "set uni promisc failed, err %d, aq_err %d\n",
                (int )aq_ret, (unsigned int )pf->hw.aq.asq_last_status);
    } else {

    }
    aq_ret = i40e_aq_set_vsi_broadcast(& (vsi->back)->hw, (int )vsi->seid, (int )cur_promisc,
                                       (struct i40e_asq_cmd_details *)0);
    if ((int )aq_ret != 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "set brdcast promisc failed, err %d, aq_err %d\n",
                (int )aq_ret, (unsigned int )pf->hw.aq.asq_last_status);
    } else {

    }
  } else {

  }
  clear_bit(1L, (unsigned long volatile   *)(& vsi->state));
  return (0);
}
}
static void i40e_sync_filters_subtask(struct i40e_pf *pf ) 
{ 
  int v ;
    klee_make_symbolic(&v, sizeof(int), "v");

  {
  if ((unsigned long )pf == (unsigned long )((struct i40e_pf *)0) || (pf->flags & 32768ULL) == 0ULL) {
    return;
  } else {

  }
  pf->flags = pf->flags & 0xffffffffffff7fffULL;
  v = 0;
  goto ldv_61846;
  ldv_61845: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )v) != (unsigned long )((struct i40e_vsi *)0) && (int )(*(pf->vsi + (unsigned long )v))->flags & 1) {
    i40e_sync_vsi_filters(*(pf->vsi + (unsigned long )v));
  } else {

  }
  v = v + 1;
  ldv_61846: ;
  if ((int )pf->num_alloc_vsi > v) {
    goto ldv_61845;
  } else {

  }

  return;
}
}
static int i40e_change_mtu(struct net_device *netdev , int new_mtu ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  int max_frame ;
    klee_make_symbolic(&max_frame, sizeof(int), "max_frame");
  struct i40e_vsi *vsi ;
  bool tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  max_frame = new_mtu + 22;
  vsi = np->vsi;
  if (new_mtu <= 67 || max_frame > 9728) {
    return (-22);
  } else {

  }
  netdev_info((struct net_device  const  *)netdev, "changing MTU from %d to %d\n",
              netdev->mtu, new_mtu);
  netdev->mtu = (unsigned int )new_mtu;
  tmp___0 = netif_running((struct net_device  const  *)netdev);
  if ((int )tmp___0) {
    i40e_vsi_reinit_locked(vsi);
  } else {

  }
  return (0);
}
}
int i40e_ioctl(struct net_device *netdev , struct ifreq *ifr , int cmd ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  int tmp___0 ;
  int tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  switch (cmd) {
  case 35249: 
  tmp___0 = i40e_ptp_get_ts_config(pf, ifr);
  return (tmp___0);
  case 35248: 
  tmp___1 = i40e_ptp_set_ts_config(pf, ifr);
  return (tmp___1);
  default: ;
  return (-95);
  }
}
}
void i40e_vlan_stripping_enable(struct i40e_vsi *vsi ) 
{ 
  struct i40e_vsi_context ctxt ;
  i40e_status ret ;

  {
  if (((int )vsi->info.valid_sections & 4) != 0 && ((int )vsi->info.port_vlan_flags & 3) == 0) {
    return;
  } else {

  }
  vsi->info.valid_sections = 4U;
  vsi->info.port_vlan_flags = 3U;
  ctxt.seid = vsi->seid;
  ctxt.info = vsi->info;
  ret = i40e_aq_update_vsi_params(& (vsi->back)->hw, & ctxt, (struct i40e_asq_cmd_details *)0);
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "%s: update vsi failed, aq_err=%d\n",
              "i40e_vlan_stripping_enable", (unsigned int )(vsi->back)->hw.aq.asq_last_status);
  } else {

  }
  return;
}
}
void i40e_vlan_stripping_disable(struct i40e_vsi *vsi ) 
{ 
  struct i40e_vsi_context ctxt ;
  i40e_status ret ;

  {
  if (((int )vsi->info.valid_sections & 4) != 0 && ((int )vsi->info.port_vlan_flags & 24) == 24) {
    return;
  } else {

  }
  vsi->info.valid_sections = 4U;
  vsi->info.port_vlan_flags = 27U;
  ctxt.seid = vsi->seid;
  ctxt.info = vsi->info;
  ret = i40e_aq_update_vsi_params(& (vsi->back)->hw, & ctxt, (struct i40e_asq_cmd_details *)0);
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "%s: update vsi failed, aq_err=%d\n",
              "i40e_vlan_stripping_disable", (unsigned int )(vsi->back)->hw.aq.asq_last_status);
  } else {

  }
  return;
}
}
static void i40e_vlan_rx_register(struct net_device *netdev , u32 features ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  if (((unsigned long long )features & 256ULL) != 0ULL) {
    i40e_vlan_stripping_enable(vsi);
  } else {
    i40e_vlan_stripping_disable(vsi);
  }
  return;
}
}
int i40e_vsi_add_vlan(struct i40e_vsi *vsi , s16 vid ) 
{ 
  struct i40e_mac_filter *f ;
  struct i40e_mac_filter *add_f ;
  bool is_netdev ;
  bool is_vf ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct i40e_mac_filter *tmp ;
  struct list_head  const  *__mptr___1 ;
  struct i40e_mac_filter *tmp___0 ;
  struct list_head  const  *__mptr___2 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
  is_vf = (unsigned int )vsi->type == 6U;
  is_netdev = (unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0);
  if ((int )is_netdev) {
    add_f = i40e_add_filter(vsi, (vsi->netdev)->dev_addr, (int )vid, (int )is_vf,
                            (int )is_netdev);
    if ((unsigned long )add_f == (unsigned long )((struct i40e_mac_filter *)0)) {
      _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "Could not add vlan filter %d for %pM\n",
                (int )vid, (vsi->netdev)->dev_addr);
      return (-12);
    } else {

    }
  } else {

  }
  __mptr = (struct list_head  const  *)vsi->mac_filter_list.next;
  f = (struct i40e_mac_filter *)__mptr;
  goto ldv_61896;
  ldv_61895: 
  add_f = i40e_add_filter(vsi, (u8 *)(& f->macaddr), (int )vid, (int )is_vf, (int )is_netdev);
  if ((unsigned long )add_f == (unsigned long )((struct i40e_mac_filter *)0)) {
    _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "Could not add vlan filter %d for %pM\n",
              (int )vid, (u8 *)(& f->macaddr));
    return (-12);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)f->list.next;
  f = (struct i40e_mac_filter *)__mptr___0;
  ldv_61896: ;
  if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
    goto ldv_61895;
  } else {

  }

  if ((int )vid > 0) {
    if ((int )is_netdev) {
      tmp = i40e_find_filter(vsi, (vsi->netdev)->dev_addr, -1, (int )is_vf, (int )is_netdev);
      if ((unsigned long )tmp != (unsigned long )((struct i40e_mac_filter *)0)) {
        i40e_del_filter(vsi, (vsi->netdev)->dev_addr, -1, (int )is_vf, (int )is_netdev);
        add_f = i40e_add_filter(vsi, (vsi->netdev)->dev_addr, 0, (int )is_vf, (int )is_netdev);
        if ((unsigned long )add_f == (unsigned long )((struct i40e_mac_filter *)0)) {
          _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "Could not add filter 0 for %pM\n",
                    (vsi->netdev)->dev_addr);
          return (-12);
        } else {

        }
      } else {

      }
    } else {

    }
  } else {

  }
  if ((int )vid > 0 && (unsigned int )vsi->info.pvid == 0U) {
    __mptr___1 = (struct list_head  const  *)vsi->mac_filter_list.next;
    f = (struct i40e_mac_filter *)__mptr___1;
    goto ldv_61903;
    ldv_61902: 
    tmp___0 = i40e_find_filter(vsi, (u8 *)(& f->macaddr), -1, (int )is_vf, (int )is_netdev);
    if ((unsigned long )tmp___0 != (unsigned long )((struct i40e_mac_filter *)0)) {
      i40e_del_filter(vsi, (u8 *)(& f->macaddr), -1, (int )is_vf, (int )is_netdev);
      add_f = i40e_add_filter(vsi, (u8 *)(& f->macaddr), 0, (int )is_vf, (int )is_netdev);
      if ((unsigned long )add_f == (unsigned long )((struct i40e_mac_filter *)0)) {
        _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "Could not add filter 0 for %pM\n",
                  (u8 *)(& f->macaddr));
        return (-12);
      } else {

      }
    } else {

    }
    __mptr___2 = (struct list_head  const  *)f->list.next;
    f = (struct i40e_mac_filter *)__mptr___2;
    ldv_61903: ;
    if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
      goto ldv_61902;
    } else {

    }

  } else {

  }
  tmp___1 = constant_test_bit(3L, (unsigned long const volatile   *)(& (vsi->back)->state));
  if (tmp___1 != 0) {
    return (0);
  } else {
    tmp___2 = constant_test_bit(9L, (unsigned long const volatile   *)(& (vsi->back)->state));
    if (tmp___2 != 0) {
      return (0);
    } else {

    }
  }
  tmp___3 = i40e_sync_vsi_filters(vsi);
  return (tmp___3);
}
}
int i40e_vsi_kill_vlan(struct i40e_vsi *vsi , s16 vid ) 
{ 
  struct net_device *netdev ;
  struct i40e_mac_filter *f ;
  struct i40e_mac_filter *add_f ;
  bool is_vf ;
  bool is_netdev ;
  int filter_count ;
    klee_make_symbolic(&filter_count, sizeof(int), "filter_count");
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;
  bool tmp ;
  struct list_head  const  *__mptr___2 ;
  struct list_head  const  *__mptr___3 ;
  struct list_head  const  *__mptr___4 ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
  netdev = vsi->netdev;
  filter_count = 0;
  is_vf = (unsigned int )vsi->type == 6U;
  is_netdev = (unsigned long )netdev != (unsigned long )((struct net_device *)0);
  if ((int )is_netdev) {
    i40e_del_filter(vsi, netdev->dev_addr, (int )vid, (int )is_vf, (int )is_netdev);
  } else {

  }
  __mptr = (struct list_head  const  *)vsi->mac_filter_list.next;
  f = (struct i40e_mac_filter *)__mptr;
  goto ldv_61920;
  ldv_61919: 
  i40e_del_filter(vsi, (u8 *)(& f->macaddr), (int )vid, (int )is_vf, (int )is_netdev);
  __mptr___0 = (struct list_head  const  *)f->list.next;
  f = (struct i40e_mac_filter *)__mptr___0;
  ldv_61920: ;
  if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
    goto ldv_61919;
  } else {

  }
  __mptr___1 = (struct list_head  const  *)vsi->mac_filter_list.next;
  f = (struct i40e_mac_filter *)__mptr___1;
  goto ldv_61927;
  ldv_61926: ;
  if ((int )is_netdev) {
    if ((int )f->vlan != 0) {
      tmp = ether_addr_equal((u8 const   *)netdev->dev_addr, (u8 const   *)(& f->macaddr));
      if ((int )tmp) {
        filter_count = filter_count + 1;
      } else {

      }
    } else {

    }
  } else {

  }
  if ((int )f->vlan != 0) {
    filter_count = filter_count + 1;
  } else {

  }
  __mptr___2 = (struct list_head  const  *)f->list.next;
  f = (struct i40e_mac_filter *)__mptr___2;
  ldv_61927: ;
  if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
    goto ldv_61926;
  } else {

  }

  if (filter_count == 0 && (int )is_netdev) {
    i40e_del_filter(vsi, netdev->dev_addr, 0, (int )is_vf, (int )is_netdev);
    f = i40e_add_filter(vsi, netdev->dev_addr, -1, (int )is_vf, (int )is_netdev);
    if ((unsigned long )f == (unsigned long )((struct i40e_mac_filter *)0)) {
      _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "Could not add filter %d for %pM\n",
                -1, netdev->dev_addr);
      return (-12);
    } else {

    }
  } else {

  }
  if (filter_count == 0) {
    __mptr___3 = (struct list_head  const  *)vsi->mac_filter_list.next;
    f = (struct i40e_mac_filter *)__mptr___3;
    goto ldv_61934;
    ldv_61933: 
    i40e_del_filter(vsi, (u8 *)(& f->macaddr), 0, (int )is_vf, (int )is_netdev);
    add_f = i40e_add_filter(vsi, (u8 *)(& f->macaddr), -1, (int )is_vf, (int )is_netdev);
    if ((unsigned long )add_f == (unsigned long )((struct i40e_mac_filter *)0)) {
      _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "Could not add filter %d for %pM\n",
                -1, (u8 *)(& f->macaddr));
      return (-12);
    } else {

    }
    __mptr___4 = (struct list_head  const  *)f->list.next;
    f = (struct i40e_mac_filter *)__mptr___4;
    ldv_61934: ;
    if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
      goto ldv_61933;
    } else {

    }

  } else {

  }
  tmp___0 = constant_test_bit(3L, (unsigned long const volatile   *)(& (vsi->back)->state));
  if (tmp___0 != 0) {
    return (0);
  } else {
    tmp___1 = constant_test_bit(9L, (unsigned long const volatile   *)(& (vsi->back)->state));
    if (tmp___1 != 0) {
      return (0);
    } else {

    }
  }
  tmp___2 = i40e_sync_vsi_filters(vsi);
  return (tmp___2);
}
}
int i40e_vlan_rx_add_vid(struct net_device *netdev , __be16 proto , u16 vid ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  int ret ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  ret = 0;
  if ((unsigned int )vid > 4095U) {
    return (-22);
  } else {

  }
  netdev_info((struct net_device  const  *)netdev, "adding %pM vid=%d\n", netdev->dev_addr,
              (int )vid);
  if ((unsigned int )vid != 0U) {
    ret = i40e_vsi_add_vlan(vsi, (int )((s16 )vid));
  } else {

  }
  if (ret == 0 && (unsigned int )vid <= 4095U) {
    set_bit((long )vid, (unsigned long volatile   *)(& vsi->active_vlans));
  } else {

  }
  return (ret);
}
}
int i40e_vlan_rx_kill_vid(struct net_device *netdev , __be16 proto , u16 vid ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  netdev_info((struct net_device  const  *)netdev, "removing %pM vid=%d\n", netdev->dev_addr,
              (int )vid);
  i40e_vsi_kill_vlan(vsi, (int )((s16 )vid));
  clear_bit((long )vid, (unsigned long volatile   *)(& vsi->active_vlans));
  return (0);
}
}
static void i40e_restore_vlan(struct i40e_vsi *vsi ) 
{ 
  u16 vid ;
  unsigned long tmp ;
  unsigned long tmp___0 ;

  {
  if ((unsigned long )vsi->netdev == (unsigned long )((struct net_device *)0)) {
    return;
  } else {

  }
  i40e_vlan_rx_register(vsi->netdev, (u32 )(vsi->netdev)->features);
  tmp = find_first_bit((unsigned long const   *)(& vsi->active_vlans), 4096UL);
  vid = (u16 )tmp;
  goto ldv_61956;
  ldv_61955: 
  i40e_vlan_rx_add_vid(vsi->netdev, 129, (int )vid);
  tmp___0 = find_next_bit((unsigned long const   *)(& vsi->active_vlans), 4096UL,
                          (unsigned long )((int )vid + 1));
  vid = (u16 )tmp___0;
  ldv_61956: ;
  if ((unsigned int )vid <= 4095U) {
    goto ldv_61955;
  } else {

  }

  return;
}
}
i40e_status i40e_vsi_add_pvid(struct i40e_vsi *vsi , u16 vid ) 
{ 
  struct i40e_vsi_context ctxt ;
  i40e_status aq_ret ;

  {
  vsi->info.valid_sections = 4U;
  vsi->info.pvid = vid;
  vsi->info.port_vlan_flags = 21U;
  ctxt.seid = vsi->seid;
  ctxt.info = vsi->info;
  aq_ret = i40e_aq_update_vsi_params(& (vsi->back)->hw, & ctxt, (struct i40e_asq_cmd_details *)0);
  if ((int )aq_ret != 0) {
    _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "%s: update vsi failed, aq_err=%d\n",
              "i40e_vsi_add_pvid", (unsigned int )(vsi->back)->hw.aq.asq_last_status);
    return (-2);
  } else {

  }
  return (0);
}
}
void i40e_vsi_remove_pvid(struct i40e_vsi *vsi ) 
{ 


  {
  i40e_vlan_stripping_disable(vsi);
  vsi->info.pvid = 0U;
  return;
}
}
static int i40e_vsi_setup_tx_resources(struct i40e_vsi *vsi ) 
{ 
  int i ;
  int err ;
    klee_make_symbolic(&err, sizeof(int), "err");

  {
  err = 0;
  i = 0;
  goto ldv_61974;
  ldv_61973: 
  err = i40e_setup_tx_descriptors(*(vsi->tx_rings + (unsigned long )i));
  i = i + 1;
  ldv_61974: ;
  if ((int )vsi->num_queue_pairs > i && err == 0) {
    goto ldv_61973;
  } else {

  }

  return (err);
}
}
static void i40e_vsi_free_tx_resources(struct i40e_vsi *vsi ) 
{ 
  int i ;

  {
  if ((unsigned long )vsi->tx_rings == (unsigned long )((struct i40e_ring **)0)) {
    return;
  } else {

  }
  i = 0;
  goto ldv_61981;
  ldv_61980: ;
  if ((unsigned long )*(vsi->tx_rings + (unsigned long )i) != (unsigned long )((struct i40e_ring *)0) && (unsigned long )(*(vsi->tx_rings + (unsigned long )i))->desc != (unsigned long )((void *)0)) {
    i40e_free_tx_resources(*(vsi->tx_rings + (unsigned long )i));
  } else {

  }
  i = i + 1;
  ldv_61981: ;
  if ((int )vsi->num_queue_pairs > i) {
    goto ldv_61980;
  } else {

  }

  return;
}
}
static int i40e_vsi_setup_rx_resources(struct i40e_vsi *vsi ) 
{ 
  int i ;
  int err ;

  {
  err = 0;
  i = 0;
  goto ldv_61989;
  ldv_61988: 
  err = i40e_setup_rx_descriptors(*(vsi->rx_rings + (unsigned long )i));
  i = i + 1;
  ldv_61989: ;
  if ((int )vsi->num_queue_pairs > i && err == 0) {
    goto ldv_61988;
  } else {

  }
  i40e_fcoe_setup_ddp_resources(vsi);
  return (err);
}
}
static void i40e_vsi_free_rx_resources(struct i40e_vsi *vsi ) 
{ 
  int i ;

  {
  if ((unsigned long )vsi->rx_rings == (unsigned long )((struct i40e_ring **)0)) {
    return;
  } else {

  }
  i = 0;
  goto ldv_61996;
  ldv_61995: ;
  if ((unsigned long )*(vsi->rx_rings + (unsigned long )i) != (unsigned long )((struct i40e_ring *)0) && (unsigned long )(*(vsi->rx_rings + (unsigned long )i))->desc != (unsigned long )((void *)0)) {
    i40e_free_rx_resources(*(vsi->rx_rings + (unsigned long )i));
  } else {

  }
  i = i + 1;
  ldv_61996: ;
  if ((int )vsi->num_queue_pairs > i) {
    goto ldv_61995;
  } else {

  }
  i40e_fcoe_free_ddp_resources(vsi);
  return;
}
}
static void i40e_config_xps_tx_ring(struct i40e_ring *ring ) 
{ 
  struct i40e_vsi *vsi ;
  cpumask_var_t mask ;
  int tmp ;
  bool tmp___0 ;

  {
  vsi = ring->vsi;
  if ((unsigned long )ring->q_vector == (unsigned long )((struct i40e_q_vector *)0) || (unsigned long )ring->netdev == (unsigned long )((struct net_device *)0)) {
    return;
  } else {

  }
  if ((unsigned int )vsi->tc_config.numtc <= 1U) {
    tmp = test_and_set_bit(1L, (unsigned long volatile   *)(& ring->state));
    if (tmp == 0) {
      netif_set_xps_queue(ring->netdev, (struct cpumask  const  *)(& (ring->q_vector)->affinity_mask),
                          (int )ring->queue_index);
    } else {

    }
  } else {
    tmp___0 = alloc_cpumask_var(& mask, 208U);
    if ((int )tmp___0) {
      bitmap_zero((unsigned long *)(& mask->bits), (unsigned int )nr_cpu_ids);
      netif_set_xps_queue(ring->netdev, (struct cpumask  const  *)mask, (int )ring->queue_index);
      free_cpumask_var(mask);
    } else {

    }
  }
  return;
}
}
static int i40e_configure_tx_ring(struct i40e_ring *ring ) 
{ 
  struct i40e_vsi *vsi ;
  u16 pf_q ;
  struct i40e_hw *hw ;
  struct i40e_hmc_obj_txq tx_ctx ;
  i40e_status err ;
  u32 qtx_ctl ;

  {
  vsi = ring->vsi;
  pf_q = (int )vsi->base_queue + (int )ring->queue_index;
  hw = & (vsi->back)->hw;
  err = 0;
  qtx_ctl = 0U;
  if (((vsi->back)->flags & 4194304ULL) != 0ULL) {
    ring->atr_sample_rate = (vsi->back)->atr_sample_rate;
    ring->atr_count = 0U;
  } else {
    ring->atr_sample_rate = 0U;
  }
  i40e_config_xps_tx_ring(ring);
  memset((void *)(& tx_ctx), 0, 48UL);
  tx_ctx.new_context = 1U;
  tx_ctx.base = ring->dma / 128ULL;
  tx_ctx.qlen = ring->count;
  tx_ctx.fd_ena = ((vsi->back)->flags & 6291456ULL) != 0ULL;
  tx_ctx.fc_ena = (unsigned int )vsi->type == 4U;
  tx_ctx.timesync_ena = ((vsi->back)->flags & 33554432ULL) != 0ULL;
  if ((unsigned int )vsi->type != 7U) {
    tx_ctx.head_wb_ena = 1U;
  } else {

  }
  tx_ctx.head_wb_addr = ring->dma + (unsigned long long )((unsigned long )ring->count * 16UL);
  tx_ctx.rdylist = vsi->info.qs_handle[(int )ring->dcb_tc];
  tx_ctx.rdylist_act = 0U;
  err = i40e_clear_lan_tx_queue_context(hw, (int )pf_q);
  if ((int )err != 0) {
    _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "Failed to clear LAN Tx queue context on Tx ring %d (pf_q %d), error: %d\n",
              (int )ring->queue_index, (int )pf_q, (int )err);
    return (-12);
  } else {

  }
  err = i40e_set_lan_tx_queue_context(hw, (int )pf_q, & tx_ctx);
  if ((int )err != 0) {
    _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "Failed to set LAN Tx queue context on Tx ring %d (pf_q %d, error: %d\n",
              (int )ring->queue_index, (int )pf_q, (int )err);
    return (-12);
  } else {

  }
  if ((unsigned int )vsi->type == 2U) {
    qtx_ctl = 1U;
    qtx_ctl = ((u32 )((int )vsi->id << 7) & 65535U) | qtx_ctl;
  } else {
    qtx_ctl = 2U;
  }
  qtx_ctl = ((u32 )((int )hw->pf_id << 2) & 60U) | qtx_ctl;
  writel(qtx_ctl, (void volatile   *)hw->hw_addr + (unsigned long )(((int )pf_q + 266240) * 4));
  readl((void const volatile   *)hw->hw_addr + 745772U);
  clear_bit(3L, (unsigned long volatile   *)(& ring->state));
  ring->tail = hw->hw_addr + (unsigned long )(((int )pf_q + 270336) * 4);
  return (0);
}
}
static int i40e_configure_rx_ring(struct i40e_ring *ring ) 
{ 
  struct i40e_vsi *vsi ;
  u32 chain_len ;
  u16 pf_q ;
  struct i40e_hw *hw ;
  struct i40e_hmc_obj_rxq rx_ctx ;
  i40e_status err ;
  u16 __min1 ;
  u16 __min2 ;
  int tmp ;

  {
  vsi = ring->vsi;
  chain_len = (u32 )(vsi->back)->hw.func_caps.rx_buf_chain_len;
  pf_q = (int )vsi->base_queue + (int )ring->queue_index;
  hw = & (vsi->back)->hw;
  err = 0;
  ring->state = 0UL;
  memset((void *)(& rx_ctx), 0, 48UL);
  ring->rx_buf_len = vsi->rx_buf_len;
  ring->rx_hdr_len = vsi->rx_hdr_len;
  rx_ctx.dbuff = (u16 )((int )ring->rx_buf_len >> 7);
  rx_ctx.hbuff = (u16 )((int )ring->rx_hdr_len >> 6);
  rx_ctx.base = ring->dma / 128ULL;
  rx_ctx.qlen = ring->count;
  if (((vsi->back)->flags & 8192ULL) != 0ULL) {
    set_bit(5L, (unsigned long volatile   *)(& ring->state));
    rx_ctx.dsize = 0U;
  } else {
    rx_ctx.dsize = 1U;
  }
  rx_ctx.dtype = vsi->dtype;
  if ((unsigned int )vsi->dtype != 0U) {
    set_bit(4L, (unsigned long volatile   *)(& ring->state));
    rx_ctx.hsplit_0 = 15U;
  } else {
    rx_ctx.hsplit_0 = 0U;
  }
  __min1 = vsi->max_frame;
  __min2 = (int )ring->rx_buf_len * (int )((u16 )chain_len);
  rx_ctx.rxmax = (u32 )((int )__min1 < (int )__min2 ? __min1 : __min2);
  if ((unsigned int )hw->revision_id == 0U) {
    rx_ctx.lrxqthresh = 0U;
  } else {
    rx_ctx.lrxqthresh = 2U;
  }
  rx_ctx.crcstrip = 1U;
  rx_ctx.l2tsel = 1U;
  rx_ctx.showiv = 1U;
  rx_ctx.fc_ena = (unsigned int )vsi->type == 4U;
  rx_ctx.prefena = 1U;
  err = i40e_clear_lan_rx_queue_context(hw, (int )pf_q);
  if ((int )err != 0) {
    _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "Failed to clear LAN Rx queue context on Rx ring %d (pf_q %d), error: %d\n",
              (int )ring->queue_index, (int )pf_q, (int )err);
    return (-12);
  } else {

  }
  err = i40e_set_lan_rx_queue_context(hw, (int )pf_q, & rx_ctx);
  if ((int )err != 0) {
    _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "Failed to set LAN Rx queue context on Rx ring %d (pf_q %d), error: %d\n",
              (int )ring->queue_index, (int )pf_q, (int )err);
    return (-12);
  } else {

  }
  ring->tail = hw->hw_addr + (unsigned long )(((int )pf_q + 303104) * 4);
  writel(0U, (void volatile   *)ring->tail);
  tmp = constant_test_bit(4L, (unsigned long const volatile   *)(& ring->state));
  if (tmp != 0) {
    i40e_alloc_rx_headers(ring);
    i40e_alloc_rx_buffers_ps(ring, (int )(((((int )ring->next_to_clean <= (int )ring->next_to_use ? ring->count : 0U) + (unsigned int )ring->next_to_clean) - (unsigned int )ring->next_to_use) + 65535U));
  } else {
    i40e_alloc_rx_buffers_1buf(ring, (int )(((((int )ring->next_to_clean <= (int )ring->next_to_use ? ring->count : 0U) + (unsigned int )ring->next_to_clean) - (unsigned int )ring->next_to_use) + 65535U));
  }
  return (0);
}
}
static int i40e_vsi_configure_tx(struct i40e_vsi *vsi ) 
{ 
  int err ;
  u16 i ;

  {
  err = 0;
  i = 0U;
  goto ldv_62030;
  ldv_62029: 
  err = i40e_configure_tx_ring(*(vsi->tx_rings + (unsigned long )i));
  i = (u16 )((int )i + 1);
  ldv_62030: ;
  if ((int )vsi->num_queue_pairs > (int )i && err == 0) {
    goto ldv_62029;
  } else {

  }

  return (err);
}
}
static int i40e_vsi_configure_rx(struct i40e_vsi *vsi ) 
{ 
  int err ;
  u16 i ;

  {
  err = 0;
  if ((unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0) && (vsi->netdev)->mtu > 1500U) {
    vsi->max_frame = (unsigned int )((u16 )(vsi->netdev)->mtu) + 22U;
  } else {
    vsi->max_frame = 2048U;
  }
  switch ((vsi->back)->flags & 48ULL) {
  case 16ULL: 
  vsi->rx_hdr_len = 0U;
  vsi->rx_buf_len = vsi->max_frame;
  vsi->dtype = 0U;
  goto ldv_62038;
  case 32ULL: 
  vsi->rx_hdr_len = 512U;
  vsi->rx_buf_len = 2048U;
  vsi->dtype = 1U;
  goto ldv_62038;
  default: 
  vsi->rx_hdr_len = 512U;
  vsi->rx_buf_len = 2048U;
  vsi->dtype = 2U;
  goto ldv_62038;
  }
  ldv_62038: ;
  if ((unsigned int )vsi->type == 4U && ((vsi->back)->flags & 2048ULL) != 0ULL) {
    vsi->rx_hdr_len = 0U;
    vsi->rx_buf_len = 3072U;
    vsi->max_frame = 3072U;
    vsi->dtype = 0U;
  } else {

  }
  vsi->rx_hdr_len = (unsigned int )((u16 )((unsigned int )vsi->rx_hdr_len + 63U)) & 65472U;
  vsi->rx_buf_len = (unsigned int )((u16 )((unsigned int )vsi->rx_buf_len + 127U)) & 65408U;
  i = 0U;
  goto ldv_62042;
  ldv_62041: 
  err = i40e_configure_rx_ring(*(vsi->rx_rings + (unsigned long )i));
  i = (u16 )((int )i + 1);
  ldv_62042: ;
  if ((int )vsi->num_queue_pairs > (int )i && err == 0) {
    goto ldv_62041;
  } else {

  }

  return (err);
}
}
static void i40e_vsi_config_dcb_rings(struct i40e_vsi *vsi ) 
{ 
  struct i40e_ring *tx_ring ;
  struct i40e_ring *rx_ring ;
  u16 qoffset ;
  u16 qcount ;
  int i ;
  int n ;
    klee_make_symbolic(&n, sizeof(int), "n");

  {
  if (((vsi->back)->flags & 1048576ULL) == 0ULL) {
    i = 0;
    goto ldv_62054;
    ldv_62053: 
    rx_ring = *(vsi->rx_rings + (unsigned long )i);
    tx_ring = *(vsi->tx_rings + (unsigned long )i);
    rx_ring->dcb_tc = 0U;
    tx_ring->dcb_tc = 0U;
    i = i + 1;
    ldv_62054: ;
    if ((int )vsi->num_queue_pairs > i) {
      goto ldv_62053;
    } else {

    }

  } else {

  }
  n = 0;
  goto ldv_62061;
  ldv_62060: ;
  if ((((int )vsi->tc_config.enabled_tc >> n) & 1) == 0) {
    goto ldv_62056;
  } else {

  }
  qoffset = vsi->tc_config.tc_info[n].qoffset;
  qcount = vsi->tc_config.tc_info[n].qcount;
  i = (int )qoffset;
  goto ldv_62058;
  ldv_62057: 
  rx_ring = *(vsi->rx_rings + (unsigned long )i);
  tx_ring = *(vsi->tx_rings + (unsigned long )i);
  rx_ring->dcb_tc = (u8 )n;
  tx_ring->dcb_tc = (u8 )n;
  i = i + 1;
  ldv_62058: ;
  if ((int )qoffset + (int )qcount > i) {
    goto ldv_62057;
  } else {

  }

  ldv_62056: 
  n = n + 1;
  ldv_62061: ;
  if (n <= 7) {
    goto ldv_62060;
  } else {

  }

  return;
}
}
static void i40e_set_vsi_rx_mode(struct i40e_vsi *vsi ) 
{ 


  {
  if ((unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0)) {
    i40e_set_rx_mode(vsi->netdev);
  } else {

  }
  return;
}
}
static void i40e_fdir_filter_restore(struct i40e_vsi *vsi ) 
{ 
  struct i40e_fdir_filter *filter ;
  struct i40e_pf *pf ;
  struct hlist_node *node ;
  struct hlist_node *____ptr ;
  struct hlist_node  const  *__mptr ;
  struct i40e_fdir_filter *tmp ;
  struct hlist_node *____ptr___0 ;
  struct hlist_node  const  *__mptr___0 ;
  struct i40e_fdir_filter *tmp___0 ;

  {
  pf = vsi->back;
  if ((pf->flags & 2097152ULL) == 0ULL) {
    return;
  } else {

  }
  ____ptr = pf->fdir_filter_list.first;
  if ((unsigned long )____ptr != (unsigned long )((struct hlist_node *)0)) {
    __mptr = (struct hlist_node  const  *)____ptr;
    tmp = (struct i40e_fdir_filter *)__mptr;
  } else {
    tmp = (struct i40e_fdir_filter *)0;
  }
  filter = tmp;
  goto ldv_62082;
  ldv_62081: 
  i40e_add_del_fdir(vsi, filter, 1);
  ____ptr___0 = node;
  if ((unsigned long )____ptr___0 != (unsigned long )((struct hlist_node *)0)) {
    __mptr___0 = (struct hlist_node  const  *)____ptr___0;
    tmp___0 = (struct i40e_fdir_filter *)__mptr___0;
  } else {
    tmp___0 = (struct i40e_fdir_filter *)0;
  }
  filter = tmp___0;
  ldv_62082: ;
  if ((unsigned long )filter != (unsigned long )((struct i40e_fdir_filter *)0)) {
    node = filter->fdir_node.next;
    goto ldv_62081;
  } else {

  }

  return;
}
}
static int i40e_vsi_configure(struct i40e_vsi *vsi ) 
{ 
  int err ;

  {
  i40e_set_vsi_rx_mode(vsi);
  i40e_restore_vlan(vsi);
  i40e_vsi_config_dcb_rings(vsi);
  err = i40e_vsi_configure_tx(vsi);
  if (err == 0) {
    err = i40e_vsi_configure_rx(vsi);
  } else {

  }
  return (err);
}
}
static void i40e_vsi_configure_msix(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_q_vector *q_vector ;
  struct i40e_hw *hw ;
  u16 vector ;
  int i ;
  int q ;
    klee_make_symbolic(&q, sizeof(int), "q");
  u32 val ;
  u32 qp ;

  {
  pf = vsi->back;
  hw = & pf->hw;
  qp = (u32 )vsi->base_queue;
  vector = (u16 )vsi->base_vector;
  i = 0;
  goto ldv_62103;
  ldv_62102: 
  q_vector = *(vsi->q_vectors + (unsigned long )i);
  q_vector->rx.itr = (u16 )(((int )vsi->rx_itr_setting & -32769) >> 1);
  q_vector->rx.latency_range = 1;
  writel((unsigned int )q_vector->rx.itr, (void volatile   *)hw->hw_addr + (unsigned long )(((int )vector + 49151) * 4));
  q_vector->tx.itr = (u16 )(((int )vsi->tx_itr_setting & -32769) >> 1);
  q_vector->tx.latency_range = 1;
  writel((unsigned int )q_vector->tx.itr, (void volatile   *)hw->hw_addr + (unsigned long )(((int )vector + 49663) * 4));
  writel(qp, (void volatile   *)hw->hw_addr + (unsigned long )(((int )vector + 54271) * 4));
  q = 0;
  goto ldv_62100;
  ldv_62099: 
  val = ((u32 )vector | (qp << 16)) | 1207959552U;
  writel(val, (void volatile   *)hw->hw_addr + (unsigned long )((qp + 59392U) * 4U));
  val = ((u32 )vector | ((qp + 1U) << 16)) | 1073743872U;
  if ((int )q_vector->num_ringpairs + -1 == q) {
    val = val | 134152192U;
  } else {

  }
  writel(val, (void volatile   *)hw->hw_addr + (unsigned long )((qp + 61440U) * 4U));
  qp = qp + 1U;
  q = q + 1;
  ldv_62100: ;
  if ((int )q_vector->num_ringpairs > q) {
    goto ldv_62099;
  } else {

  }
  i = i + 1;
  vector = (u16 )((int )vector + 1);
  ldv_62103: ;
  if (vsi->num_q_vectors > i) {
    goto ldv_62102;
  } else {

  }
  readl((void const volatile   *)hw->hw_addr + 745772U);
  return;
}
}
static void i40e_enable_misc_int_causes(struct i40e_pf *pf ) 
{ 
  struct i40e_hw *hw ;
  u32 val ;

  {
  hw = & pf->hw;
  writel(0U, (void volatile   *)hw->hw_addr + 231424U);
  readl((void const volatile   *)hw->hw_addr + 231296U);
  val = 1685651456U;
  if ((pf->flags & 33554432ULL) != 0ULL) {
    val = val | 8388608U;
  } else {

  }
  writel(val, (void volatile   *)hw->hw_addr + 231424U);
  writel(2248146944U, (void volatile   *)hw->hw_addr + 230528U);
  writel(0U, (void volatile   *)hw->hw_addr + 230400U);
  return;
}
}
static void i40e_configure_msi_and_legacy(struct i40e_vsi *vsi ) 
{ 
  struct i40e_q_vector *q_vector ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u32 val ;

  {
  q_vector = *(vsi->q_vectors);
  pf = vsi->back;
  hw = & pf->hw;
  q_vector->rx.itr = (u16 )(((int )vsi->rx_itr_setting & -32769) >> 1);
  q_vector->rx.latency_range = 1;
  writel((unsigned int )q_vector->rx.itr, (void volatile   *)hw->hw_addr + 229376U);
  q_vector->tx.itr = (u16 )(((int )vsi->tx_itr_setting & -32769) >> 1);
  q_vector->tx.latency_range = 1;
  writel((unsigned int )q_vector->tx.itr, (void volatile   *)hw->hw_addr + 229504U);
  i40e_enable_misc_int_causes(pf);
  writel(0U, (void volatile   *)hw->hw_addr + 230656U);
  val = 1207959552U;
  writel(val, (void volatile   *)hw->hw_addr + 237568U);
  val = 1207896064U;
  writel(val, (void volatile   *)hw->hw_addr + 245760U);
  readl((void const volatile   *)hw->hw_addr + 745772U);
  return;
}
}
void i40e_irq_dynamic_disable_icr0(struct i40e_pf *pf ) 
{ 
  struct i40e_hw *hw ;

  {
  hw = & pf->hw;
  writel(24U, (void volatile   *)hw->hw_addr + 230528U);
  readl((void const volatile   *)hw->hw_addr + 745772U);
  return;
}
}
void i40e_irq_dynamic_enable_icr0(struct i40e_pf *pf ) 
{ 
  struct i40e_hw *hw ;
  u32 val ;

  {
  hw = & pf->hw;
  val = 27U;
  writel(val, (void volatile   *)hw->hw_addr + 230528U);
  readl((void const volatile   *)hw->hw_addr + 745772U);
  return;
}
}
void i40e_irq_dynamic_enable(struct i40e_vsi *vsi , int vector ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u32 val ;

  {
  pf = vsi->back;
  hw = & pf->hw;
  val = 27U;
  writel(val, (void volatile   *)hw->hw_addr + (unsigned long )((vector + 53759) * 4));
  return;
}
}
void i40e_irq_dynamic_disable(struct i40e_vsi *vsi , int vector ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u32 val ;

  {
  pf = vsi->back;
  hw = & pf->hw;
  val = 24U;
  writel(val, (void volatile   *)hw->hw_addr + (unsigned long )((vector + 53759) * 4));
  readl((void const volatile   *)hw->hw_addr + 745772U);
  return;
}
}
static irqreturn_t i40e_msix_clean_rings(int irq , void *data ) 
{ 
  struct i40e_q_vector *q_vector ;

  {
  q_vector = (struct i40e_q_vector *)data;
  if ((unsigned long )q_vector->tx.ring == (unsigned long )((struct i40e_ring *)0) && (unsigned long )q_vector->rx.ring == (unsigned long )((struct i40e_ring *)0)) {
    return (1);
  } else {

  }
  napi_schedule(& q_vector->napi);
  return (1);
}
}
static int i40e_vsi_request_irq_msix(struct i40e_vsi *vsi , char *basename ) 
{ 
  int q_vectors ;
    klee_make_symbolic(&q_vectors, sizeof(int), "q_vectors");
  struct i40e_pf *pf ;
  int base ;
    klee_make_symbolic(&base, sizeof(int), "base");
  int rx_int_idx ;
    klee_make_symbolic(&rx_int_idx, sizeof(int), "rx_int_idx");
  int tx_int_idx ;
    klee_make_symbolic(&tx_int_idx, sizeof(int), "tx_int_idx");
  int vector ;
    klee_make_symbolic(&vector, sizeof(int), "vector");
  int err ;
  struct i40e_q_vector *q_vector ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
  q_vectors = vsi->num_q_vectors;
  pf = vsi->back;
  base = vsi->base_vector;
  rx_int_idx = 0;
  tx_int_idx = 0;
  vector = 0;
  goto ldv_62161;
  ldv_62160: 
  q_vector = *(vsi->q_vectors + (unsigned long )vector);
  if ((unsigned long )q_vector->tx.ring != (unsigned long )((struct i40e_ring *)0) && (unsigned long )q_vector->rx.ring != (unsigned long )((struct i40e_ring *)0)) {
    tmp = rx_int_idx;
    rx_int_idx = rx_int_idx + 1;
    snprintf((char *)(& q_vector->name), 24UL, "%s-%s-%d", basename, (char *)"TxRx",
             tmp);
    tx_int_idx = tx_int_idx + 1;
  } else
  if ((unsigned long )q_vector->rx.ring != (unsigned long )((struct i40e_ring *)0)) {
    tmp___0 = rx_int_idx;
    rx_int_idx = rx_int_idx + 1;
    snprintf((char *)(& q_vector->name), 24UL, "%s-%s-%d", basename, (char *)"rx",
             tmp___0);
  } else
  if ((unsigned long )q_vector->tx.ring != (unsigned long )((struct i40e_ring *)0)) {
    tmp___1 = tx_int_idx;
    tx_int_idx = tx_int_idx + 1;
    snprintf((char *)(& q_vector->name), 24UL, "%s-%s-%d", basename, (char *)"tx",
             tmp___1);
  } else {
    goto ldv_62157;
  }
  err = ldv_request_irq_17((pf->msix_entries + (unsigned long )(base + vector))->vector,
                           vsi->irq_handler, 0UL, (char const   *)(& q_vector->name),
                           (void *)q_vector);
  if (err != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%s: request_irq failed, error: %d\n",
              "i40e_vsi_request_irq_msix", err);
    goto free_queue_irqs;
  } else {

  }
  irq_set_affinity_hint((pf->msix_entries + (unsigned long )(base + vector))->vector,
                        (struct cpumask  const  *)(& q_vector->affinity_mask));
  ldv_62157: 
  vector = vector + 1;
  ldv_62161: ;
  if (vector < q_vectors) {
    goto ldv_62160;
  } else {

  }
  vsi->irqs_ready = 1;
  return (0);
  free_queue_irqs: ;
  goto ldv_62164;
  ldv_62163: 
  vector = vector - 1;
  irq_set_affinity_hint((pf->msix_entries + (unsigned long )(base + vector))->vector,
                        (struct cpumask  const  *)0);
  ldv_free_irq_18((pf->msix_entries + (unsigned long )(base + vector))->vector, (void *)vsi->q_vectors + (unsigned long )vector);
  ldv_62164: ;
  if (vector != 0) {
    goto ldv_62163;
  } else {

  }

  return (err);
}
}
static void i40e_vsi_disable_irq(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  int base ;
  int i ;

  {
  pf = vsi->back;
  hw = & pf->hw;
  base = vsi->base_vector;
  i = 0;
  goto ldv_62174;
  ldv_62173: 
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )(((int )(*(vsi->tx_rings + (unsigned long )i))->reg_idx + 61440) * 4));
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )(((int )(*(vsi->rx_rings + (unsigned long )i))->reg_idx + 59392) * 4));
  i = i + 1;
  ldv_62174: ;
  if ((int )vsi->num_queue_pairs > i) {
    goto ldv_62173;
  } else {

  }

  if ((pf->flags & 8ULL) != 0ULL) {
    i = vsi->base_vector;
    goto ldv_62177;
    ldv_62176: 
    writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )((i + 53759) * 4));
    i = i + 1;
    ldv_62177: ;
    if (vsi->num_q_vectors + vsi->base_vector > i) {
      goto ldv_62176;
    } else {

    }
    readl((void const volatile   *)hw->hw_addr + 745772U);
    i = 0;
    goto ldv_62180;
    ldv_62179: 
    synchronize_irq((pf->msix_entries + (unsigned long )(i + base))->vector);
    i = i + 1;
    ldv_62180: ;
    if (vsi->num_q_vectors > i) {
      goto ldv_62179;
    } else {

    }

  } else {
    writel(0U, (void volatile   *)hw->hw_addr + 231424U);
    writel(0U, (void volatile   *)hw->hw_addr + 230528U);
    readl((void const volatile   *)hw->hw_addr + 745772U);
    synchronize_irq((pf->pdev)->irq);
  }
  return;
}
}
static int i40e_vsi_enable_irq(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  int i ;

  {
  pf = vsi->back;
  if ((pf->flags & 8ULL) != 0ULL) {
    i = vsi->base_vector;
    goto ldv_62188;
    ldv_62187: 
    i40e_irq_dynamic_enable(vsi, i);
    i = i + 1;
    ldv_62188: ;
    if (vsi->num_q_vectors + vsi->base_vector > i) {
      goto ldv_62187;
    } else {

    }

  } else {
    i40e_irq_dynamic_enable_icr0(pf);
  }
  readl((void const volatile   *)pf->hw.hw_addr + 745772U);
  return (0);
}
}
static void i40e_stop_misc_vector(struct i40e_pf *pf ) 
{ 


  {
  writel(0U, (void volatile   *)pf->hw.hw_addr + 231424U);
  readl((void const volatile   *)pf->hw.hw_addr + 745772U);
  return;
}
}
static irqreturn_t i40e_intr(int irq , void *data ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  irqreturn_t ret ;
  u32 icr0 ;
  u32 icr0_remaining ;
  u32 val ;
  u32 ena_mask ;
  u32 qval ;
  unsigned int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  unsigned int tmp___2 ;
  unsigned int tmp___3 ;
  u32 prttsyn_stat ;
  unsigned int tmp___4 ;
  int tmp___5 ;

  {
  pf = (struct i40e_pf *)data;
  hw = & pf->hw;
  ret = 0;
  icr0 = readl((void const volatile   *)hw->hw_addr + 231296U);
  ena_mask = readl((void const volatile   *)hw->hw_addr + 231424U);
  if ((icr0 & 1U) == 0U) {
    goto enable_intr;
  } else {

  }
  if ((icr0 & 4294967294U) == 0U || (int )icr0 < 0) {
    pf->sw_int_count = (u16 )((int )pf->sw_int_count + 1);
  } else {

  }
  if ((icr0 & 2U) != 0U) {
    tmp = readl((void const volatile   *)hw->hw_addr + 237568U);
    qval = tmp;
    qval = qval & 3221225471U;
    writel(qval, (void volatile   *)hw->hw_addr + 237568U);
    qval = readl((void const volatile   *)hw->hw_addr + 245760U);
    qval = qval & 3221225471U;
    writel(qval, (void volatile   *)hw->hw_addr + 245760U);
    tmp___0 = constant_test_bit(3L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___0 == 0) {
      napi_schedule(& (*((*(pf->vsi + (unsigned long )pf->lan_vsi))->q_vectors))->napi);
    } else {

    }
  } else {

  }
  if ((icr0 & 1073741824U) != 0U) {
    ena_mask = ena_mask & 3221225471U;
    set_bit(6L, (unsigned long volatile   *)(& pf->state));
  } else {

  }
  if ((icr0 & 524288U) != 0U) {
    ena_mask = ena_mask & 4294443007U;
    set_bit(7L, (unsigned long volatile   *)(& pf->state));
  } else {

  }
  if ((icr0 & 536870912U) != 0U) {
    ena_mask = ena_mask & 3758096383U;
    set_bit(8L, (unsigned long volatile   *)(& pf->state));
  } else {

  }
  if ((icr0 & 1048576U) != 0U) {
    tmp___1 = constant_test_bit(9L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___1 == 0) {
      set_bit(10L, (unsigned long volatile   *)(& pf->state));
    } else {

    }
    ena_mask = ena_mask & 4293918719U;
    val = readl((void const volatile   *)hw->hw_addr + 754056U);
    val = (val & 12U) >> 2;
    if (val == 1U) {
      pf->corer_count = (u16 )((int )pf->corer_count + 1);
    } else
    if (val == 2U) {
      pf->globr_count = (u16 )((int )pf->globr_count + 1);
    } else
    if (val == 3U) {
      pf->empr_count = (u16 )((int )pf->empr_count + 1);
      set_bit(16L, (unsigned long volatile   *)(& pf->state));
    } else {

    }
  } else {

  }
  if ((icr0 & 67108864U) != 0U) {
    icr0 = icr0 & 4227858431U;
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "HMC error interrupt\n");
    tmp___2 = readl((void const volatile   *)hw->hw_addr + 787712U);
    tmp___3 = readl((void const volatile   *)hw->hw_addr + 787456U);
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "HMC error info 0x%x, HMC error data 0x%x\n",
              tmp___3, tmp___2);
  } else {

  }
  if ((icr0 & 8388608U) != 0U) {
    tmp___4 = readl((void const volatile   *)hw->hw_addr + 1983008U);
    prttsyn_stat = tmp___4;
    if ((prttsyn_stat & 16U) != 0U) {
      icr0 = icr0 & 4286578687U;
      i40e_ptp_tx_hwtstamp(pf);
    } else {

    }
  } else {

  }
  icr0_remaining = icr0 & ena_mask;
  if (icr0_remaining != 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "unhandled interrupt icr0=0x%08x\n",
              icr0_remaining);
    if (((icr0_remaining & 268435456U) != 0U || (icr0_remaining & 2097152U) != 0U) || (icr0_remaining & 65536U) != 0U) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "device will be reset\n");
      set_bit(12L, (unsigned long volatile   *)(& pf->state));
      i40e_service_event_schedule(pf);
    } else {

    }
    ena_mask = ~ icr0_remaining & ena_mask;
  } else {

  }
  ret = 1;
  enable_intr: 
  writel(ena_mask, (void volatile   *)hw->hw_addr + 231424U);
  tmp___5 = constant_test_bit(3L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___5 == 0) {
    i40e_service_event_schedule(pf);
    i40e_irq_dynamic_enable_icr0(pf);
  } else {

  }
  return (ret);
}
}
static bool i40e_clean_fdir_tx_irq(struct i40e_ring *tx_ring , int budget ) 
{ 
  struct i40e_vsi *vsi ;
  u16 i ;
  struct i40e_tx_buffer *tx_buf ;
  struct i40e_tx_desc *tx_desc ;
  struct i40e_tx_desc *eop_desc ;
  long tmp ;
  long tmp___0 ;
  long tmp___1 ;

  {
  vsi = tx_ring->vsi;
  i = tx_ring->next_to_clean;
  tx_buf = tx_ring->__annonCompField121.tx_bi + (unsigned long )i;
  tx_desc = (struct i40e_tx_desc *)tx_ring->desc + (unsigned long )i;
  i = (int )i - (int )tx_ring->count;
  ldv_62217: 
  eop_desc = tx_buf->next_to_watch;
  if ((unsigned long )eop_desc == (unsigned long )((struct i40e_tx_desc *)0)) {
    goto ldv_62216;
  } else {

  }
  if ((eop_desc->cmd_type_offset_bsz & 15ULL) == 0ULL) {
    goto ldv_62216;
  } else {

  }
  tx_buf->next_to_watch = (struct i40e_tx_desc *)0;
  tx_desc->buffer_addr = 0ULL;
  tx_desc->cmd_type_offset_bsz = 0ULL;
  tx_buf = tx_buf + 1;
  tx_desc = tx_desc + 1;
  i = (u16 )((int )i + 1);
  tmp = ldv__builtin_expect((unsigned int )i == 0U, 0L);
  if (tmp != 0L) {
    i = (int )i - (int )tx_ring->count;
    tx_buf = tx_ring->__annonCompField121.tx_bi;
    tx_desc = (struct i40e_tx_desc *)tx_ring->desc;
  } else {

  }
  dma_unmap_single_attrs(tx_ring->dev, tx_buf->dma, (size_t )tx_buf->len, 1, (struct dma_attrs *)0);
  if ((tx_buf->tx_flags & 512U) != 0U) {
    kfree((void const   *)tx_buf->__annonCompField120.raw_buf);
  } else {

  }
  tx_buf->__annonCompField120.raw_buf = (void *)0;
  tx_buf->tx_flags = 0U;
  tx_buf->next_to_watch = (struct i40e_tx_desc *)0;
  tx_buf->len = 0U;
  tx_desc->buffer_addr = 0ULL;
  tx_desc->cmd_type_offset_bsz = 0ULL;
  tx_buf = tx_buf + 1;
  tx_desc = tx_desc + 1;
  i = (u16 )((int )i + 1);
  tmp___0 = ldv__builtin_expect((unsigned int )i == 0U, 0L);
  if (tmp___0 != 0L) {
    i = (int )i - (int )tx_ring->count;
    tx_buf = tx_ring->__annonCompField121.tx_bi;
    tx_desc = (struct i40e_tx_desc *)tx_ring->desc;
  } else {

  }
  budget = budget - 1;
  tmp___1 = ldv__builtin_expect(budget != 0, 1L);
  if (tmp___1 != 0L) {
    goto ldv_62217;
  } else {

  }
  ldv_62216: 
  i = (int )tx_ring->count + (int )i;
  tx_ring->next_to_clean = i;
  if (((vsi->back)->flags & 8ULL) != 0ULL) {
    i40e_irq_dynamic_enable(vsi, (int )(tx_ring->q_vector)->v_idx + vsi->base_vector);
  } else {

  }
  return (budget > 0);
}
}
static irqreturn_t i40e_fdir_clean_ring(int irq , void *data ) 
{ 
  struct i40e_q_vector *q_vector ;
  struct i40e_vsi *vsi ;

  {
  q_vector = (struct i40e_q_vector *)data;
  if ((unsigned long )q_vector->tx.ring == (unsigned long )((struct i40e_ring *)0)) {
    return (1);
  } else {

  }
  vsi = (q_vector->tx.ring)->vsi;
  i40e_clean_fdir_tx_irq(q_vector->tx.ring, (int )vsi->work_limit);
  return (1);
}
}
static void map_vector_to_qp(struct i40e_vsi *vsi , int v_idx , int qp_idx ) 
{ 
  struct i40e_q_vector *q_vector ;
  struct i40e_ring *tx_ring ;
  struct i40e_ring *rx_ring ;

  {
  q_vector = *(vsi->q_vectors + (unsigned long )v_idx);
  tx_ring = *(vsi->tx_rings + (unsigned long )qp_idx);
  rx_ring = *(vsi->rx_rings + (unsigned long )qp_idx);
  tx_ring->q_vector = q_vector;
  tx_ring->next = q_vector->tx.ring;
  q_vector->tx.ring = tx_ring;
  q_vector->tx.count = (u16 )((int )q_vector->tx.count + 1);
  rx_ring->q_vector = q_vector;
  rx_ring->next = q_vector->rx.ring;
  q_vector->rx.ring = rx_ring;
  q_vector->rx.count = (u16 )((int )q_vector->rx.count + 1);
  return;
}
}
static void i40e_vsi_map_rings_to_vectors(struct i40e_vsi *vsi ) 
{ 
  int qp_remaining ;
    klee_make_symbolic(&qp_remaining, sizeof(int), "qp_remaining");
  int q_vectors ;
  int num_ringpairs ;
    klee_make_symbolic(&num_ringpairs, sizeof(int), "num_ringpairs");
  int v_start ;
    klee_make_symbolic(&v_start, sizeof(int), "v_start");
  int qp_idx ;
    klee_make_symbolic(&qp_idx, sizeof(int), "qp_idx");
  struct i40e_q_vector *q_vector ;
  int tmp ;

  {
  qp_remaining = (int )vsi->num_queue_pairs;
  q_vectors = vsi->num_q_vectors;
  v_start = 0;
  qp_idx = 0;
  goto ldv_62245;
  ldv_62244: 
  q_vector = *(vsi->q_vectors + (unsigned long )v_start);
  num_ringpairs = (((q_vectors - v_start) + qp_remaining) + -1) / (q_vectors - v_start);
  q_vector->num_ringpairs = (u8 )num_ringpairs;
  q_vector->rx.count = 0U;
  q_vector->tx.count = 0U;
  q_vector->rx.ring = (struct i40e_ring *)0;
  q_vector->tx.ring = (struct i40e_ring *)0;
  goto ldv_62242;
  ldv_62241: 
  map_vector_to_qp(vsi, v_start, qp_idx);
  qp_idx = qp_idx + 1;
  qp_remaining = qp_remaining - 1;
  ldv_62242: 
  tmp = num_ringpairs;
  num_ringpairs = num_ringpairs - 1;
  if (tmp != 0) {
    goto ldv_62241;
  } else {

  }
  v_start = v_start + 1;
  ldv_62245: ;
  if (v_start < q_vectors) {
    goto ldv_62244;
  } else {

  }

  return;
}
}
static int i40e_vsi_request_irq(struct i40e_vsi *vsi , char *basename ) 
{ 
  struct i40e_pf *pf ;
  int err ;

  {
  pf = vsi->back;
  if ((pf->flags & 8ULL) != 0ULL) {
    err = i40e_vsi_request_irq_msix(vsi, basename);
  } else
  if ((pf->flags & 4ULL) != 0ULL) {
    err = ldv_request_irq_19((pf->pdev)->irq, & i40e_intr, 0UL, (char const   *)(& pf->int_name),
                             (void *)pf);
  } else {
    err = ldv_request_irq_20((pf->pdev)->irq, & i40e_intr, 128UL, (char const   *)(& pf->int_name),
                             (void *)pf);
  }
  if (err != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "request_irq failed, Error %d\n",
              err);
  } else {

  }
  return (err);
}
}
void i40e_netpoll(struct net_device *netdev ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  int i ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  tmp___0 = constant_test_bit(3L, (unsigned long const volatile   *)(& vsi->state));
  if (tmp___0 != 0) {
    return;
  } else {

  }
  pf->flags = pf->flags | 4096ULL;
  if ((pf->flags & 8ULL) != 0ULL) {
    i = 0;
    goto ldv_62261;
    ldv_62260: 
    i40e_msix_clean_rings(0, (void *)*(vsi->q_vectors + (unsigned long )i));
    i = i + 1;
    ldv_62261: ;
    if (vsi->num_q_vectors > i) {
      goto ldv_62260;
    } else {

    }

  } else {
    i40e_intr((int )(pf->pdev)->irq, (void *)netdev);
  }
  pf->flags = pf->flags & 0xffffffffffffefffULL;
  return;
}
}
static int i40e_pf_txq_wait(struct i40e_pf *pf , int pf_q , bool enable ) 
{ 
  int i ;
  u32 tx_reg ;

  {
  i = 0;
  goto ldv_62272;
  ldv_62271: 
  tx_reg = readl((void const volatile   *)pf->hw.hw_addr + (unsigned long )((pf_q + 262144) * 4));
  if ((int )enable == ((tx_reg & 4U) != 0U)) {
    goto ldv_62270;
  } else {

  }
  usleep_range(10UL, 20UL);
  i = i + 1;
  ldv_62272: ;
  if (i <= 9) {
    goto ldv_62271;
  } else {

  }
  ldv_62270: ;
  if (i > 9) {
    return (-110);
  } else {

  }
  return (0);
}
}
static int i40e_vsi_control_tx(struct i40e_vsi *vsi , bool enable ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  int i ;
  int j ;
  int pf_q ;
    klee_make_symbolic(&pf_q, sizeof(int), "pf_q");
  int ret ;
  u32 tx_reg ;
  int tmp ;
  unsigned long __ms ;
    klee_make_symbolic(&__ms, sizeof(long), "__ms");
  unsigned long tmp___0 ;

  {
  pf = vsi->back;
  hw = & pf->hw;
  ret = 0;
  pf_q = (int )vsi->base_queue;
  i = 0;
  goto ldv_62291;
  ldv_62290: 
  i40e_pre_tx_queue_cfg(& pf->hw, (u32 )pf_q, (int )enable);
  if (! enable) {
    usleep_range(10UL, 20UL);
  } else {

  }
  j = 0;
  goto ldv_62286;
  ldv_62285: 
  tx_reg = readl((void const volatile   *)hw->hw_addr + (unsigned long )((pf_q + 262144) * 4));
  if ((((tx_reg >> 2) ^ tx_reg) & 1U) == 0U) {
    goto ldv_62284;
  } else {

  }
  usleep_range(1000UL, 2000UL);
  j = j + 1;
  ldv_62286: ;
  if (j <= 49) {
    goto ldv_62285;
  } else {

  }
  ldv_62284: ;
  if ((int )enable == ((tx_reg & 4U) != 0U)) {
    goto ldv_62287;
  } else {

  }
  if ((int )enable) {
    writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )((pf_q + 233472) * 4));
    tx_reg = tx_reg | 1U;
  } else {
    tx_reg = tx_reg & 4294967294U;
  }
  writel(tx_reg, (void volatile   *)hw->hw_addr + (unsigned long )((pf_q + 262144) * 4));
  if (! enable) {
    tmp = constant_test_bit(24L, (unsigned long const volatile   *)(& pf->state));
    if (tmp != 0) {
      goto ldv_62287;
    } else {

    }
  } else {

  }
  ret = i40e_pf_txq_wait(pf, pf_q, (int )enable);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%s: VSI seid %d Tx ring %d %sable timeout\n",
              "i40e_vsi_control_tx", (int )vsi->seid, pf_q, (int )enable ? (char *)"en" : (char *)"dis");
    goto ldv_62289;
  } else {

  }
  ldv_62287: 
  i = i + 1;
  pf_q = pf_q + 1;
  ldv_62291: ;
  if ((int )vsi->num_queue_pairs > i) {
    goto ldv_62290;
  } else {

  }
  ldv_62289: ;
  if ((unsigned int )hw->revision_id == 0U) {
    __ms = 50UL;
    goto ldv_62294;
    ldv_62293: 
    __const_udelay(4295000UL);
    ldv_62294: 
    tmp___0 = __ms;
    __ms = __ms - 1UL;
    if (tmp___0 != 0UL) {
      goto ldv_62293;
    } else {

    }

  } else {

  }
  return (ret);
}
}
static int i40e_pf_rxq_wait(struct i40e_pf *pf , int pf_q , bool enable ) 
{ 
  int i ;
  u32 rx_reg ;

  {
  i = 0;
  goto ldv_62305;
  ldv_62304: 
  rx_reg = readl((void const volatile   *)pf->hw.hw_addr + (unsigned long )((pf_q + 294912) * 4));
  if ((int )enable == ((rx_reg & 4U) != 0U)) {
    goto ldv_62303;
  } else {

  }
  usleep_range(10UL, 20UL);
  i = i + 1;
  ldv_62305: ;
  if (i <= 9) {
    goto ldv_62304;
  } else {

  }
  ldv_62303: ;
  if (i > 9) {
    return (-110);
  } else {

  }
  return (0);
}
}
static int i40e_vsi_control_rx(struct i40e_vsi *vsi , bool enable ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  int i ;
  int j ;
  int pf_q ;
  int ret ;
  u32 rx_reg ;

  {
  pf = vsi->back;
  hw = & pf->hw;
  ret = 0;
  pf_q = (int )vsi->base_queue;
  i = 0;
  goto ldv_62324;
  ldv_62323: 
  j = 0;
  goto ldv_62319;
  ldv_62318: 
  rx_reg = readl((void const volatile   *)hw->hw_addr + (unsigned long )((pf_q + 294912) * 4));
  if ((((rx_reg >> 2) ^ rx_reg) & 1U) == 0U) {
    goto ldv_62317;
  } else {

  }
  usleep_range(1000UL, 2000UL);
  j = j + 1;
  ldv_62319: ;
  if (j <= 49) {
    goto ldv_62318;
  } else {

  }
  ldv_62317: ;
  if ((int )enable == ((rx_reg & 4U) != 0U)) {
    goto ldv_62320;
  } else {

  }
  if ((int )enable) {
    rx_reg = rx_reg | 1U;
  } else {
    rx_reg = rx_reg & 4294967294U;
  }
  writel(rx_reg, (void volatile   *)hw->hw_addr + (unsigned long )((pf_q + 294912) * 4));
  ret = i40e_pf_rxq_wait(pf, pf_q, (int )enable);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%s: VSI seid %d Rx ring %d %sable timeout\n",
              "i40e_vsi_control_rx", (int )vsi->seid, pf_q, (int )enable ? (char *)"en" : (char *)"dis");
    goto ldv_62322;
  } else {

  }
  ldv_62320: 
  i = i + 1;
  pf_q = pf_q + 1;
  ldv_62324: ;
  if ((int )vsi->num_queue_pairs > i) {
    goto ldv_62323;
  } else {

  }
  ldv_62322: ;
  return (ret);
}
}
int i40e_vsi_control_rings(struct i40e_vsi *vsi , bool request ) 
{ 
  int ret ;

  {
  ret = 0;
  if ((int )request) {
    ret = i40e_vsi_control_rx(vsi, (int )request);
    if (ret != 0) {
      return (ret);
    } else {

    }
    ret = i40e_vsi_control_tx(vsi, (int )request);
  } else {
    i40e_vsi_control_tx(vsi, (int )request);
    i40e_vsi_control_rx(vsi, (int )request);
  }
  return (ret);
}
}
static void i40e_vsi_free_irq(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  int base ;
  u32 val ;
  u32 qp ;
  int i ;
  u16 vector ;
  u32 next ;

  {
  pf = vsi->back;
  hw = & pf->hw;
  base = vsi->base_vector;
  if ((pf->flags & 8ULL) != 0ULL) {
    if ((unsigned long )vsi->q_vectors == (unsigned long )((struct i40e_q_vector **)0)) {
      return;
    } else {

    }
    if (! vsi->irqs_ready) {
      return;
    } else {

    }
    vsi->irqs_ready = 0;
    i = 0;
    goto ldv_62346;
    ldv_62345: 
    vector = (int )((u16 )i) + (int )((u16 )base);
    if ((unsigned long )*(vsi->q_vectors + (unsigned long )i) == (unsigned long )((struct i40e_q_vector *)0) || (unsigned int )(*(vsi->q_vectors + (unsigned long )i))->num_ringpairs == 0U) {
      goto ldv_62340;
    } else {

    }
    irq_set_affinity_hint((pf->msix_entries + (unsigned long )vector)->vector, (struct cpumask  const  *)0);
    ldv_free_irq_21((pf->msix_entries + (unsigned long )vector)->vector, (void *)*(vsi->q_vectors + (unsigned long )i));
    val = readl((void const volatile   *)hw->hw_addr + (unsigned long )(((int )vector + 54271) * 4));
    qp = val & 2047U;
    val = val | 2047U;
    writel(val, (void volatile   *)hw->hw_addr + (unsigned long )(((int )vector + 54271) * 4));
    goto ldv_62343;
    ldv_62342: 
    val = readl((void const volatile   *)hw->hw_addr + (unsigned long )((qp + 59392U) * 4U));
    val = val & 1073684224U;
    val = val | 134158336U;
    writel(val, (void volatile   *)hw->hw_addr + (unsigned long )((qp + 59392U) * 4U));
    val = readl((void const volatile   *)hw->hw_addr + (unsigned long )((qp + 61440U) * 4U));
    next = (val & 134152192U) >> 16;
    val = val & 1073684224U;
    val = val | 134158336U;
    writel(val, (void volatile   *)hw->hw_addr + (unsigned long )((qp + 61440U) * 4U));
    qp = next;
    ldv_62343: ;
    if (qp != 2047U) {
      goto ldv_62342;
    } else {

    }

    ldv_62340: 
    i = i + 1;
    ldv_62346: ;
    if (vsi->num_q_vectors > i) {
      goto ldv_62345;
    } else {

    }

  } else {
    ldv_free_irq_22((pf->pdev)->irq, (void *)pf);
    val = readl((void const volatile   *)hw->hw_addr + 230656U);
    qp = val & 2047U;
    val = val | 2047U;
    writel(val, (void volatile   *)hw->hw_addr + 230656U);
    val = readl((void const volatile   *)hw->hw_addr + (unsigned long )((qp + 59392U) * 4U));
    val = val & 1073684224U;
    val = val | 134158336U;
    writel(val, (void volatile   *)hw->hw_addr + (unsigned long )((qp + 59392U) * 4U));
    val = readl((void const volatile   *)hw->hw_addr + (unsigned long )((qp + 61440U) * 4U));
    val = val & 1073684224U;
    val = val | 134158336U;
    writel(val, (void volatile   *)hw->hw_addr + (unsigned long )((qp + 61440U) * 4U));
  }
  return;
}
}
static void i40e_free_q_vector(struct i40e_vsi *vsi , int v_idx ) 
{ 
  struct i40e_q_vector *q_vector ;
  struct i40e_ring *ring ;

  {
  q_vector = *(vsi->q_vectors + (unsigned long )v_idx);
  if ((unsigned long )q_vector == (unsigned long )((struct i40e_q_vector *)0)) {
    return;
  } else {

  }
  ring = q_vector->tx.ring;
  goto ldv_62355;
  ldv_62354: 
  ring->q_vector = (struct i40e_q_vector *)0;
  ring = ring->next;
  ldv_62355: ;
  if ((unsigned long )ring != (unsigned long )((struct i40e_ring *)0)) {
    goto ldv_62354;
  } else {

  }
  ring = q_vector->rx.ring;
  goto ldv_62358;
  ldv_62357: 
  ring->q_vector = (struct i40e_q_vector *)0;
  ring = ring->next;
  ldv_62358: ;
  if ((unsigned long )ring != (unsigned long )((struct i40e_ring *)0)) {
    goto ldv_62357;
  } else {

  }

  if ((unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0)) {
    netif_napi_del(& q_vector->napi);
  } else {

  }
  *(vsi->q_vectors + (unsigned long )v_idx) = (struct i40e_q_vector *)0;
  kfree_call_rcu(& q_vector->rcu, (void (*)(struct callback_head * ))1392);
  return;
}
}
static void i40e_vsi_free_q_vectors(struct i40e_vsi *vsi ) 
{ 
  int v_idx ;
    klee_make_symbolic(&v_idx, sizeof(int), "v_idx");

  {
  v_idx = 0;
  goto ldv_62366;
  ldv_62365: 
  i40e_free_q_vector(vsi, v_idx);
  v_idx = v_idx + 1;
  ldv_62366: ;
  if (vsi->num_q_vectors > v_idx) {
    goto ldv_62365;
  } else {

  }

  return;
}
}
static void i40e_reset_interrupt_capability(struct i40e_pf *pf ) 
{ 


  {
  if ((pf->flags & 8ULL) != 0ULL) {
    pci_disable_msix(pf->pdev);
    kfree((void const   *)pf->msix_entries);
    pf->msix_entries = (struct msix_entry *)0;
    kfree((void const   *)pf->irq_pile);
    pf->irq_pile = (struct i40e_lump_tracking *)0;
  } else
  if ((pf->flags & 4ULL) != 0ULL) {
    pci_disable_msi(pf->pdev);
  } else {

  }
  pf->flags = pf->flags & 0xfffffffffffffff3ULL;
  return;
}
}
static void i40e_clear_interrupt_scheme(struct i40e_pf *pf ) 
{ 
  int i ;

  {
  i40e_stop_misc_vector(pf);
  if ((pf->flags & 8ULL) != 0ULL) {
    synchronize_irq((pf->msix_entries)->vector);
    ldv_free_irq_23((pf->msix_entries)->vector, (void *)pf);
  } else {

  }
  i40e_put_lump(pf->irq_pile, 0, 32767);
  i = 0;
  goto ldv_62376;
  ldv_62375: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0)) {
    i40e_vsi_free_q_vectors(*(pf->vsi + (unsigned long )i));
  } else {

  }
  i = i + 1;
  ldv_62376: ;
  if ((int )pf->num_alloc_vsi > i) {
    goto ldv_62375;
  } else {

  }
  i40e_reset_interrupt_capability(pf);
  return;
}
}
static void i40e_napi_enable_all(struct i40e_vsi *vsi ) 
{ 
  int q_idx ;
    klee_make_symbolic(&q_idx, sizeof(int), "q_idx");

  {
  if ((unsigned long )vsi->netdev == (unsigned long )((struct net_device *)0)) {
    return;
  } else {

  }
  q_idx = 0;
  goto ldv_62383;
  ldv_62382: 
  napi_enable(& (*(vsi->q_vectors + (unsigned long )q_idx))->napi);
  q_idx = q_idx + 1;
  ldv_62383: ;
  if (vsi->num_q_vectors > q_idx) {
    goto ldv_62382;
  } else {

  }

  return;
}
}
static void i40e_napi_disable_all(struct i40e_vsi *vsi ) 
{ 
  int q_idx ;

  {
  if ((unsigned long )vsi->netdev == (unsigned long )((struct net_device *)0)) {
    return;
  } else {

  }
  q_idx = 0;
  goto ldv_62390;
  ldv_62389: 
  napi_disable(& (*(vsi->q_vectors + (unsigned long )q_idx))->napi);
  q_idx = q_idx + 1;
  ldv_62390: ;
  if (vsi->num_q_vectors > q_idx) {
    goto ldv_62389;
  } else {

  }

  return;
}
}
static void i40e_vsi_close(struct i40e_vsi *vsi ) 
{ 
  int tmp ;

  {
  tmp = test_and_set_bit(3L, (unsigned long volatile   *)(& vsi->state));
  if (tmp == 0) {
    i40e_down(vsi);
  } else {

  }
  i40e_vsi_free_irq(vsi);
  i40e_vsi_free_tx_resources(vsi);
  i40e_vsi_free_rx_resources(vsi);
  return;
}
}
static void i40e_quiesce_vsi(struct i40e_vsi *vsi ) 
{ 
  int tmp ;
  struct _ddebug descriptor ;
  long tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;

  {
  tmp = constant_test_bit(3L, (unsigned long const volatile   *)(& vsi->state));
  if (tmp != 0) {
    return;
  } else {

  }
  tmp___1 = constant_test_bit(24L, (unsigned long const volatile   *)(& (vsi->back)->state));
  if (tmp___1 != 0 && (unsigned int )vsi->type == 4U) {
    descriptor.modname = "i40e";
    descriptor.function = "i40e_quiesce_vsi";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
    descriptor.format = "%s: VSI seid %d skipping FCoE VSI disable\n";
    descriptor.lineno = 3948U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_dev_dbg(& descriptor, (struct device  const  *)(& ((vsi->back)->pdev)->dev),
                        "%s: VSI seid %d skipping FCoE VSI disable\n", "i40e_quiesce_vsi",
                        (int )vsi->seid);
    } else {

    }
    return;
  } else {

  }
  set_bit(4L, (unsigned long volatile   *)(& vsi->state));
  if ((unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0)) {
    tmp___2 = netif_running((struct net_device  const  *)vsi->netdev);
    if ((int )tmp___2) {
      (*(((vsi->netdev)->netdev_ops)->ndo_stop))(vsi->netdev);
    } else {
      i40e_vsi_close(vsi);
    }
  } else {
    i40e_vsi_close(vsi);
  }
  return;
}
}
static void i40e_unquiesce_vsi(struct i40e_vsi *vsi ) 
{ 
  int tmp ;
  bool tmp___0 ;

  {
  tmp = constant_test_bit(4L, (unsigned long const volatile   *)(& vsi->state));
  if (tmp == 0) {
    return;
  } else {

  }
  clear_bit(4L, (unsigned long volatile   *)(& vsi->state));
  if ((unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0)) {
    tmp___0 = netif_running((struct net_device  const  *)vsi->netdev);
    if ((int )tmp___0) {
      (*(((vsi->netdev)->netdev_ops)->ndo_open))(vsi->netdev);
    } else {
      i40e_vsi_open(vsi);
    }
  } else {
    i40e_vsi_open(vsi);
  }
  return;
}
}
static void i40e_pf_quiesce_all_vsi(struct i40e_pf *pf ) 
{ 
  int v ;

  {
  v = 0;
  goto ldv_62408;
  ldv_62407: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )v) != (unsigned long )((struct i40e_vsi *)0)) {
    i40e_quiesce_vsi(*(pf->vsi + (unsigned long )v));
  } else {

  }
  v = v + 1;
  ldv_62408: ;
  if ((int )pf->num_alloc_vsi > v) {
    goto ldv_62407;
  } else {

  }

  return;
}
}
static void i40e_pf_unquiesce_all_vsi(struct i40e_pf *pf ) 
{ 
  int v ;

  {
  v = 0;
  goto ldv_62415;
  ldv_62414: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )v) != (unsigned long )((struct i40e_vsi *)0)) {
    i40e_unquiesce_vsi(*(pf->vsi + (unsigned long )v));
  } else {

  }
  v = v + 1;
  ldv_62415: ;
  if ((int )pf->num_alloc_vsi > v) {
    goto ldv_62414;
  } else {

  }

  return;
}
}
static int i40e_vsi_wait_txq_disabled(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  int i ;
  int pf_q ;
  int ret ;

  {
  pf = vsi->back;
  pf_q = (int )vsi->base_queue;
  i = 0;
  goto ldv_62426;
  ldv_62425: 
  ret = i40e_pf_txq_wait(pf, pf_q, 0);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%s: VSI seid %d Tx ring %d disable timeout\n",
              "i40e_vsi_wait_txq_disabled", (int )vsi->seid, pf_q);
    return (ret);
  } else {

  }
  i = i + 1;
  pf_q = pf_q + 1;
  ldv_62426: ;
  if ((int )vsi->num_queue_pairs > i) {
    goto ldv_62425;
  } else {

  }

  return (0);
}
}
static int i40e_pf_wait_txq_disabled(struct i40e_pf *pf ) 
{ 
  int v ;
  int ret ;

  {
  ret = 0;
  v = 0;
  goto ldv_62435;
  ldv_62434: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )v) != (unsigned long )((struct i40e_vsi *)0) && (unsigned int )(*(pf->vsi + (unsigned long )v))->type != 4U) {
    ret = i40e_vsi_wait_txq_disabled(*(pf->vsi + (unsigned long )v));
    if (ret != 0) {
      goto ldv_62433;
    } else {

    }
  } else {

  }
  v = v + 1;
  ldv_62435: ;
  if ((u32 )v < pf->hw.func_caps.num_vsis) {
    goto ldv_62434;
  } else {

  }
  ldv_62433: ;
  return (ret);
}
}
static u8 i40e_get_iscsi_tc_map(struct i40e_pf *pf ) 
{ 
  struct i40e_dcb_app_priority_table app ;
  struct i40e_hw *hw ;
  u8 enabled_tc ;
  u8 tc ;
  u8 i ;
  struct i40e_dcbx_config *dcbcfg ;

  {
  hw = & pf->hw;
  enabled_tc = 1U;
  dcbcfg = & hw->local_dcbx_config;
  i = 0U;
  goto ldv_62447;
  ldv_62446: 
  app = dcbcfg->app[(int )i];
  if ((unsigned int )app.selector == 2U && (unsigned int )app.protocolid == 3260U) {
    tc = dcbcfg->etscfg.prioritytable[(int )app.priority];
    enabled_tc = (u8 )((int )((signed char )(1 << (int )tc)) | (int )((signed char )enabled_tc));
    goto ldv_62445;
  } else {

  }
  i = (u8 )((int )i + 1);
  ldv_62447: ;
  if ((u32 )i < dcbcfg->numapps) {
    goto ldv_62446;
  } else {

  }
  ldv_62445: ;
  return (enabled_tc);
}
}
static u8 i40e_dcb_get_num_tc(struct i40e_dcbx_config *dcbcfg ) 
{ 
  u8 num_tc ;
  int i ;

  {
  num_tc = 0U;
  i = 0;
  goto ldv_62454;
  ldv_62453: ;
  if ((int )dcbcfg->etscfg.prioritytable[i] > (int )num_tc) {
    num_tc = dcbcfg->etscfg.prioritytable[i];
  } else {

  }
  i = i + 1;
  ldv_62454: ;
  if (i <= 7) {
    goto ldv_62453;
  } else {

  }

  return ((unsigned int )num_tc + 1U);
}
}
static u8 i40e_dcb_get_enabled_tc(struct i40e_dcbx_config *dcbcfg ) 
{ 
  u8 num_tc ;
  u8 tmp ;
  u8 enabled_tc ;
  u8 i ;

  {
  tmp = i40e_dcb_get_num_tc(dcbcfg);
  num_tc = tmp;
  enabled_tc = 1U;
  i = 0U;
  goto ldv_62463;
  ldv_62462: 
  enabled_tc = (u8 )((int )((signed char )(1 << (int )i)) | (int )((signed char )enabled_tc));
  i = (u8 )((int )i + 1);
  ldv_62463: ;
  if ((int )i < (int )num_tc) {
    goto ldv_62462;
  } else {

  }

  return (enabled_tc);
}
}
static u8 i40e_pf_get_num_tc(struct i40e_pf *pf ) 
{ 
  struct i40e_hw *hw ;
  u8 i ;
  u8 enabled_tc ;
  u8 num_tc ;
  struct i40e_dcbx_config *dcbcfg ;
  u8 tmp ;

  {
  hw = & pf->hw;
  num_tc = 0U;
  dcbcfg = & hw->local_dcbx_config;
  if ((pf->flags & 1048576ULL) == 0ULL) {
    return (1U);
  } else {

  }
  if ((pf->flags & 67108864ULL) == 0ULL) {
    tmp = i40e_dcb_get_num_tc(dcbcfg);
    return (tmp);
  } else {

  }
  if ((int )pf->hw.func_caps.iscsi) {
    enabled_tc = i40e_get_iscsi_tc_map(pf);
  } else {
    return (1U);
  }
  enabled_tc = (unsigned int )enabled_tc != 0U ? enabled_tc : 1U;
  i = 0U;
  goto ldv_62474;
  ldv_62473: ;
  if (((int )enabled_tc >> (int )i) & 1) {
    num_tc = (u8 )((int )num_tc + 1);
  } else {

  }
  i = (u8 )((int )i + 1);
  ldv_62474: ;
  if ((unsigned int )i <= 7U) {
    goto ldv_62473;
  } else {

  }

  return (num_tc);
}
}
static u8 i40e_pf_get_default_tc(struct i40e_pf *pf ) 
{ 
  u8 enabled_tc ;
  u8 i ;

  {
  enabled_tc = (u8 )pf->hw.func_caps.enabled_tcmap;
  i = 0U;
  if ((unsigned int )enabled_tc == 0U) {
    return (1U);
  } else {

  }
  i = 0U;
  goto ldv_62483;
  ldv_62482: ;
  if (((int )enabled_tc >> (int )i) & 1) {
    goto ldv_62481;
  } else {

  }
  i = (u8 )((int )i + 1);
  ldv_62483: ;
  if ((unsigned int )i <= 7U) {
    goto ldv_62482;
  } else {

  }
  ldv_62481: ;
  return ((u8 )(1 << (int )i));
}
}
static u8 i40e_pf_get_tc_map(struct i40e_pf *pf ) 
{ 
  u8 tmp ;
  u8 tmp___0 ;
  u8 tmp___1 ;
  u8 tmp___2 ;

  {
  if ((pf->flags & 1048576ULL) == 0ULL) {
    tmp = i40e_pf_get_default_tc(pf);
    return (tmp);
  } else {

  }
  if ((pf->flags & 67108864ULL) == 0ULL) {
    tmp___0 = i40e_dcb_get_enabled_tc(& pf->hw.local_dcbx_config);
    return (tmp___0);
  } else {

  }
  if ((int )pf->hw.func_caps.iscsi) {
    tmp___1 = i40e_get_iscsi_tc_map(pf);
    return (tmp___1);
  } else {
    tmp___2 = i40e_pf_get_default_tc(pf);
    return (tmp___2);
  }
}
}
static int i40e_vsi_get_bw_info(struct i40e_vsi *vsi ) 
{ 
  struct i40e_aqc_query_vsi_ets_sla_config_resp bw_ets_config ;
  struct i40e_aqc_query_vsi_bw_config_resp bw_config ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  i40e_status aq_ret ;
  u32 tc_bw_max ;
  int i ;

  {
  bw_ets_config.tc_valid_bits = 0U;
  bw_ets_config.reserved[0] = (unsigned char)0;
  bw_ets_config.reserved[1] = (unsigned char)0;
  bw_ets_config.reserved[2] = (unsigned char)0;
  bw_ets_config.share_credits[0] = (unsigned char)0;
  bw_ets_config.share_credits[1] = (unsigned char)0;
  bw_ets_config.share_credits[2] = (unsigned char)0;
  bw_ets_config.share_credits[3] = (unsigned char)0;
  bw_ets_config.share_credits[4] = (unsigned char)0;
  bw_ets_config.share_credits[5] = (unsigned char)0;
  bw_ets_config.share_credits[6] = (unsigned char)0;
  bw_ets_config.share_credits[7] = (unsigned char)0;
  bw_ets_config.credits[0] = (unsigned short)0;
  bw_ets_config.credits[1] = (unsigned short)0;
  bw_ets_config.credits[2] = (unsigned short)0;
  bw_ets_config.credits[3] = (unsigned short)0;
  bw_ets_config.credits[4] = (unsigned short)0;
  bw_ets_config.credits[5] = (unsigned short)0;
  bw_ets_config.credits[6] = (unsigned short)0;
  bw_ets_config.credits[7] = (unsigned short)0;
  bw_ets_config.tc_bw_max[0] = (unsigned short)0;
  bw_ets_config.tc_bw_max[1] = (unsigned short)0;
  bw_config.tc_valid_bits = 0U;
  bw_config.tc_suspended_bits = (unsigned char)0;
  bw_config.reserved[0] = (unsigned char)0;
  bw_config.reserved[1] = (unsigned char)0;
  bw_config.reserved[2] = (unsigned char)0;
  bw_config.reserved[3] = (unsigned char)0;
  bw_config.reserved[4] = (unsigned char)0;
  bw_config.reserved[5] = (unsigned char)0;
  bw_config.reserved[6] = (unsigned char)0;
  bw_config.reserved[7] = (unsigned char)0;
  bw_config.reserved[8] = (unsigned char)0;
  bw_config.reserved[9] = (unsigned char)0;
  bw_config.reserved[10] = (unsigned char)0;
  bw_config.reserved[11] = (unsigned char)0;
  bw_config.reserved[12] = (unsigned char)0;
  bw_config.reserved[13] = (unsigned char)0;
  bw_config.qs_handles[0] = (unsigned short)0;
  bw_config.qs_handles[1] = (unsigned short)0;
  bw_config.qs_handles[2] = (unsigned short)0;
  bw_config.qs_handles[3] = (unsigned short)0;
  bw_config.qs_handles[4] = (unsigned short)0;
  bw_config.qs_handles[5] = (unsigned short)0;
  bw_config.qs_handles[6] = (unsigned short)0;
  bw_config.qs_handles[7] = (unsigned short)0;
  bw_config.reserved1[0] = (unsigned char)0;
  bw_config.reserved1[1] = (unsigned char)0;
  bw_config.reserved1[2] = (unsigned char)0;
  bw_config.reserved1[3] = (unsigned char)0;
  bw_config.port_bw_limit = (unsigned short)0;
  bw_config.reserved2[0] = (unsigned char)0;
  bw_config.reserved2[1] = (unsigned char)0;
  bw_config.max_bw = (unsigned char)0;
  bw_config.reserved3[0] = (unsigned char)0;
  bw_config.reserved3[1] = (unsigned char)0;
  bw_config.reserved3[2] = (unsigned char)0;
  bw_config.reserved3[3] = (unsigned char)0;
  bw_config.reserved3[4] = (unsigned char)0;
  bw_config.reserved3[5] = (unsigned char)0;
  bw_config.reserved3[6] = (unsigned char)0;
  bw_config.reserved3[7] = (unsigned char)0;
  bw_config.reserved3[8] = (unsigned char)0;
  bw_config.reserved3[9] = (unsigned char)0;
  bw_config.reserved3[10] = (unsigned char)0;
  bw_config.reserved3[11] = (unsigned char)0;
  bw_config.reserved3[12] = (unsigned char)0;
  bw_config.reserved3[13] = (unsigned char)0;
  bw_config.reserved3[14] = (unsigned char)0;
  bw_config.reserved3[15] = (unsigned char)0;
  bw_config.reserved3[16] = (unsigned char)0;
  bw_config.reserved3[17] = (unsigned char)0;
  bw_config.reserved3[18] = (unsigned char)0;
  bw_config.reserved3[19] = (unsigned char)0;
  bw_config.reserved3[20] = (unsigned char)0;
  bw_config.reserved3[21] = (unsigned char)0;
  bw_config.reserved3[22] = (unsigned char)0;
  pf = vsi->back;
  hw = & pf->hw;
  aq_ret = i40e_aq_query_vsi_bw_config(hw, (int )vsi->seid, & bw_config, (struct i40e_asq_cmd_details *)0);
  if ((int )aq_ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "couldn\'t get PF vsi bw config, err %d, aq_err %d\n",
              (int )aq_ret, (unsigned int )pf->hw.aq.asq_last_status);
    return (-22);
  } else {

  }
  aq_ret = i40e_aq_query_vsi_ets_sla_config(hw, (int )vsi->seid, & bw_ets_config,
                                            (struct i40e_asq_cmd_details *)0);
  if ((int )aq_ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "couldn\'t get PF vsi ets bw config, err %d, aq_err %d\n",
              (int )aq_ret, (unsigned int )pf->hw.aq.asq_last_status);
    return (-22);
  } else {

  }
  if ((int )bw_config.tc_valid_bits != (int )bw_ets_config.tc_valid_bits) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Enabled TCs mismatch from querying VSI BW info 0x%08x 0x%08x\n",
              (int )bw_config.tc_valid_bits, (int )bw_ets_config.tc_valid_bits);
  } else {

  }
  vsi->bw_limit = bw_config.port_bw_limit;
  vsi->bw_max_quanta = bw_config.max_bw;
  tc_bw_max = (u32 )((int )bw_ets_config.tc_bw_max[0] | ((int )bw_ets_config.tc_bw_max[1] << 16));
  i = 0;
  goto ldv_62498;
  ldv_62497: 
  vsi->bw_ets_share_credits[i] = bw_ets_config.share_credits[i];
  vsi->bw_ets_limit_credits[i] = bw_ets_config.credits[i];
  vsi->bw_ets_max_quanta[i] = (unsigned int )((unsigned char )(tc_bw_max >> i * 4)) & 7U;
  i = i + 1;
  ldv_62498: ;
  if (i <= 7) {
    goto ldv_62497;
  } else {

  }

  return (0);
}
}
static int i40e_vsi_configure_bw_alloc(struct i40e_vsi *vsi , u8 enabled_tc , u8 *bw_share ) 
{ 
  struct i40e_aqc_configure_vsi_tc_bw_data bw_data ;
  i40e_status aq_ret ;
  int i ;

  {
  bw_data.tc_valid_bits = enabled_tc;
  i = 0;
  goto ldv_62509;
  ldv_62508: 
  bw_data.tc_bw_credits[i] = *(bw_share + (unsigned long )i);
  i = i + 1;
  ldv_62509: ;
  if (i <= 7) {
    goto ldv_62508;
  } else {

  }
  aq_ret = i40e_aq_config_vsi_tc_bw(& (vsi->back)->hw, (int )vsi->seid, & bw_data,
                                    (struct i40e_asq_cmd_details *)0);
  if ((int )aq_ret != 0) {
    _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "AQ command Config VSI BW allocation per TC failed = %d\n",
              (unsigned int )(vsi->back)->hw.aq.asq_last_status);
    return (-22);
  } else {

  }
  i = 0;
  goto ldv_62512;
  ldv_62511: 
  vsi->info.qs_handle[i] = bw_data.qs_handles[i];
  i = i + 1;
  ldv_62512: ;
  if (i <= 7) {
    goto ldv_62511;
  } else {

  }

  return (0);
}
}
static void i40e_vsi_config_netdev_tc(struct i40e_vsi *vsi , u8 enabled_tc ) 
{ 
  struct net_device *netdev ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u8 netdev_tc ;
  int i ;
  struct i40e_dcbx_config *dcbcfg ;
  int tmp ;
  u8 ets_tc ;

  {
  netdev = vsi->netdev;
  pf = vsi->back;
  hw = & pf->hw;
  netdev_tc = 0U;
  dcbcfg = & hw->local_dcbx_config;
  if ((unsigned long )netdev == (unsigned long )((struct net_device *)0)) {
    return;
  } else {

  }
  if ((unsigned int )enabled_tc == 0U) {
    netdev_reset_tc(netdev);
    return;
  } else {

  }
  tmp = netdev_set_num_tc(netdev, (int )vsi->tc_config.numtc);
  if (tmp != 0) {
    return;
  } else {

  }
  i = 0;
  goto ldv_62525;
  ldv_62524: ;
  if (((int )vsi->tc_config.enabled_tc >> i) & 1) {
    netdev_set_tc_queue(netdev, (int )vsi->tc_config.tc_info[i].netdev_tc, (int )vsi->tc_config.tc_info[i].qcount,
                        (int )vsi->tc_config.tc_info[i].qoffset);
  } else {

  }
  i = i + 1;
  ldv_62525: ;
  if (i <= 7) {
    goto ldv_62524;
  } else {

  }
  i = 0;
  goto ldv_62529;
  ldv_62528: 
  ets_tc = dcbcfg->etscfg.prioritytable[i];
  netdev_tc = vsi->tc_config.tc_info[(int )ets_tc].netdev_tc;
  netdev_set_prio_tc_map(netdev, (int )((u8 )i), (int )netdev_tc);
  i = i + 1;
  ldv_62529: ;
  if (i <= 7) {
    goto ldv_62528;
  } else {

  }

  return;
}
}
static void i40e_vsi_update_queue_map(struct i40e_vsi *vsi , struct i40e_vsi_context *ctxt ) 
{ 


  {
  vsi->info.mapping_flags = ctxt->info.mapping_flags;
  memcpy((void *)(& vsi->info.queue_mapping), (void const   *)(& ctxt->info.queue_mapping),
           32UL);
  memcpy((void *)(& vsi->info.tc_mapping), (void const   *)(& ctxt->info.tc_mapping),
           16UL);
  return;
}
}
static int i40e_vsi_config_tc(struct i40e_vsi *vsi , u8 enabled_tc ) 
{ 
  u8 bw_share[8U] ;
  unsigned int tmp ;
  struct i40e_vsi_context ctxt ;
  int ret ;
  int i ;
  i40e_status tmp___0 ;

  {
  bw_share[0] = 0U;
  tmp = 1U;
  while (1) {
    if (tmp >= 8U) {
      break;
    } else {

    }
    bw_share[tmp] = (unsigned char)0;
    tmp = tmp + 1U;
  }
  ret = 0;
  if ((int )vsi->tc_config.enabled_tc == (int )enabled_tc) {
    return (ret);
  } else {

  }
  i = 0;
  goto ldv_62544;
  ldv_62543: ;
  if (((int )enabled_tc >> i) & 1) {
    bw_share[i] = 1U;
  } else {

  }
  i = i + 1;
  ldv_62544: ;
  if (i <= 7) {
    goto ldv_62543;
  } else {

  }
  ret = i40e_vsi_configure_bw_alloc(vsi, (int )enabled_tc, (u8 *)(& bw_share));
  if (ret != 0) {
    _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "Failed configuring TC map %d for VSI %d\n",
              (int )enabled_tc, (int )vsi->seid);
    goto out;
  } else {

  }
  ctxt.seid = vsi->seid;
  ctxt.pf_num = (vsi->back)->hw.pf_id;
  ctxt.vf_num = 0U;
  ctxt.uplink_seid = vsi->uplink_seid;
  ctxt.info = vsi->info;
  i40e_vsi_setup_queue_map(vsi, & ctxt, (int )enabled_tc, 0);
  tmp___0 = i40e_aq_update_vsi_params(& (vsi->back)->hw, & ctxt, (struct i40e_asq_cmd_details *)0);
  ret = (int )tmp___0;
  if (ret != 0) {
    _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "update vsi failed, aq_err=%d\n",
              (unsigned int )(vsi->back)->hw.aq.asq_last_status);
    goto out;
  } else {

  }
  i40e_vsi_update_queue_map(vsi, & ctxt);
  vsi->info.valid_sections = 0U;
  ret = i40e_vsi_get_bw_info(vsi);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "Failed updating vsi bw info, aq_err=%d\n",
              (unsigned int )(vsi->back)->hw.aq.asq_last_status);
    goto out;
  } else {

  }
  i40e_vsi_config_netdev_tc(vsi, (int )enabled_tc);
  out: ;
  return (ret);
}
}
int i40e_veb_config_tc(struct i40e_veb *veb , u8 enabled_tc ) 
{ 
  struct i40e_aqc_configure_switching_comp_bw_config_data bw_data ;
  struct i40e_pf *pf ;
  int ret ;
  int i ;
  i40e_status tmp ;

  {
  bw_data.tc_valid_bits = 0U;
  bw_data.reserved[0] = (unsigned char)0;
  bw_data.reserved[1] = (unsigned char)0;
  bw_data.absolute_credits = (unsigned char)0;
  bw_data.tc_bw_share_credits[0] = (unsigned char)0;
  bw_data.tc_bw_share_credits[1] = (unsigned char)0;
  bw_data.tc_bw_share_credits[2] = (unsigned char)0;
  bw_data.tc_bw_share_credits[3] = (unsigned char)0;
  bw_data.tc_bw_share_credits[4] = (unsigned char)0;
  bw_data.tc_bw_share_credits[5] = (unsigned char)0;
  bw_data.tc_bw_share_credits[6] = (unsigned char)0;
  bw_data.tc_bw_share_credits[7] = (unsigned char)0;
  bw_data.reserved1[0] = (unsigned char)0;
  bw_data.reserved1[1] = (unsigned char)0;
  bw_data.reserved1[2] = (unsigned char)0;
  bw_data.reserved1[3] = (unsigned char)0;
  bw_data.reserved1[4] = (unsigned char)0;
  bw_data.reserved1[5] = (unsigned char)0;
  bw_data.reserved1[6] = (unsigned char)0;
  bw_data.reserved1[7] = (unsigned char)0;
  bw_data.reserved1[8] = (unsigned char)0;
  bw_data.reserved1[9] = (unsigned char)0;
  bw_data.reserved1[10] = (unsigned char)0;
  bw_data.reserved1[11] = (unsigned char)0;
  bw_data.reserved1[12] = (unsigned char)0;
  bw_data.reserved1[13] = (unsigned char)0;
  bw_data.reserved1[14] = (unsigned char)0;
  bw_data.reserved1[15] = (unsigned char)0;
  bw_data.reserved1[16] = (unsigned char)0;
  bw_data.reserved1[17] = (unsigned char)0;
  bw_data.reserved1[18] = (unsigned char)0;
  bw_data.reserved1[19] = (unsigned char)0;
  pf = veb->pf;
  ret = 0;
  if ((unsigned int )enabled_tc == 0U || (int )veb->enabled_tc == (int )enabled_tc) {
    return (ret);
  } else {

  }
  bw_data.tc_valid_bits = enabled_tc;
  i = 0;
  goto ldv_62556;
  ldv_62555: ;
  if (((int )enabled_tc >> i) & 1) {
    bw_data.tc_bw_share_credits[i] = 1U;
  } else {

  }
  i = i + 1;
  ldv_62556: ;
  if (i <= 7) {
    goto ldv_62555;
  } else {

  }
  tmp = i40e_aq_config_switch_comp_bw_config(& pf->hw, (int )veb->seid, & bw_data,
                                             (struct i40e_asq_cmd_details *)0);
  ret = (int )tmp;
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "veb bw config failed, aq_err=%d\n",
              (unsigned int )pf->hw.aq.asq_last_status);
    goto out;
  } else {

  }
  ret = i40e_veb_get_bw_info(veb);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Failed getting veb bw config, aq_err=%d\n",
              (unsigned int )pf->hw.aq.asq_last_status);
  } else {

  }
  out: ;
  return (ret);
}
}
static void i40e_dcb_reconfigure(struct i40e_pf *pf ) 
{ 
  u8 tc_map ;
  int ret ;
  u8 v ;

  {
  tc_map = 0U;
  tc_map = i40e_pf_get_tc_map(pf);
  v = 0U;
  goto ldv_62567;
  ldv_62566: ;
  if ((unsigned long )pf->veb[(int )v] == (unsigned long )((struct i40e_veb *)0)) {
    goto ldv_62565;
  } else {

  }
  ret = i40e_veb_config_tc(pf->veb[(int )v], (int )tc_map);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Failed configuring TC for VEB seid=%d\n",
              (int )(pf->veb[(int )v])->seid);
  } else {

  }
  ldv_62565: 
  v = (u8 )((int )v + 1);
  ldv_62567: ;
  if ((unsigned int )v <= 15U) {
    goto ldv_62566;
  } else {

  }
  v = 0U;
  goto ldv_62571;
  ldv_62570: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )v) == (unsigned long )((struct i40e_vsi *)0)) {
    goto ldv_62569;
  } else {

  }
  if ((int )((unsigned short )v) == (int )pf->lan_vsi) {
    tc_map = i40e_pf_get_tc_map(pf);
  } else {
    tc_map = i40e_pf_get_default_tc(pf);
  }
  if ((unsigned int )(*(pf->vsi + (unsigned long )v))->type == 4U) {
    tc_map = i40e_get_fcoe_tc_map(pf);
  } else {

  }
  ret = i40e_vsi_config_tc(*(pf->vsi + (unsigned long )v), (int )tc_map);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Failed configuring TC for VSI seid=%d\n",
              (int )(*(pf->vsi + (unsigned long )v))->seid);
  } else {
    i40e_vsi_map_rings_to_vectors(*(pf->vsi + (unsigned long )v));
    if ((unsigned long )(*(pf->vsi + (unsigned long )v))->netdev != (unsigned long )((struct net_device *)0)) {
      i40e_dcbnl_set_all(*(pf->vsi + (unsigned long )v));
    } else {

    }
  }
  ldv_62569: 
  v = (u8 )((int )v + 1);
  ldv_62571: ;
  if ((int )((unsigned short )v) < (int )pf->num_alloc_vsi) {
    goto ldv_62570;
  } else {

  }

  return;
}
}
static int i40e_resume_port_tx(struct i40e_pf *pf ) 
{ 
  struct i40e_hw *hw ;
  int ret ;
  i40e_status tmp ;

  {
  hw = & pf->hw;
  tmp = i40e_aq_resume_port_tx(hw, (struct i40e_asq_cmd_details *)0);
  ret = (int )tmp;
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "AQ command Resume Port Tx failed = %d\n",
              (unsigned int )pf->hw.aq.asq_last_status);
    set_bit(12L, (unsigned long volatile   *)(& pf->state));
    i40e_service_event_schedule(pf);
  } else {

  }
  return (ret);
}
}
static int i40e_init_pf_dcb(struct i40e_pf *pf ) 
{ 
  struct i40e_hw *hw ;
  int err ;
  i40e_status tmp ;
  u8 tmp___0 ;
  struct _ddebug descriptor ;
  long tmp___1 ;

  {
  hw = & pf->hw;
  err = 0;
  if (((unsigned int )pf->hw.aq.fw_maj_ver == 4U && (unsigned int )pf->hw.aq.fw_min_ver <= 32U) || (unsigned int )pf->hw.aq.fw_maj_ver <= 3U) {
    goto out;
  } else {

  }
  tmp = i40e_init_dcb(hw);
  err = (int )tmp;
  if (err == 0) {
    if (! hw->func_caps.dcb || (unsigned int )hw->dcbx_status == 7U) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "DCBX offload is not supported or is disabled for this PF.\n");
      if ((pf->flags & 67108864ULL) != 0ULL) {
        goto out;
      } else {

      }
    } else {
      pf->dcbx_cap = 10U;
      pf->flags = pf->flags | 536870912ULL;
      tmp___0 = i40e_dcb_get_num_tc(& hw->local_dcbx_config);
      if ((unsigned int )tmp___0 > 1U) {
        pf->flags = pf->flags | 1048576ULL;
      } else {

      }
      descriptor.modname = "i40e";
      descriptor.function = "i40e_init_pf_dcb";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
      descriptor.format = "DCBX offload is supported for this PF.\n";
      descriptor.lineno = 4626U;
      descriptor.flags = 0U;
      tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp___1 != 0L) {
        __dynamic_dev_dbg(& descriptor, (struct device  const  *)(& (pf->pdev)->dev),
                          "DCBX offload is supported for this PF.\n");
      } else {

      }
    }
  } else {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "AQ Querying DCB configuration failed: aq_err %d\n",
              (unsigned int )pf->hw.aq.asq_last_status);
  }
  out: ;
  return (err);
}
}
static void i40e_print_link_message(struct i40e_vsi *vsi , bool isup ) 
{ 
  char speed[14U] ;
  unsigned int tmp ;
  char fc[8U] ;
  unsigned int tmp___0 ;

  {
  speed[0] = 'U';
  speed[1] = 'n';
  speed[2] = 'k';
  speed[3] = 'n';
  speed[4] = 'o';
  speed[5] = 'w';
  speed[6] = 'n';
  speed[7] = '\000';
  tmp = 8U;
  while (1) {
    if (tmp >= 14U) {
      break;
    } else {

    }
    speed[tmp] = (char)0;
    tmp = tmp + 1U;
  }
  fc[0] = 'R';
  fc[1] = 'X';
  fc[2] = '/';
  fc[3] = 'T';
  fc[4] = 'X';
  fc[5] = '\000';
  tmp___0 = 6U;
  while (1) {
    if (tmp___0 >= 8U) {
      break;
    } else {

    }
    fc[tmp___0] = (char)0;
    tmp___0 = tmp___0 + 1U;
  }
  if (! isup) {
    netdev_info((struct net_device  const  *)vsi->netdev, "NIC Link is Down\n");
    return;
  } else {

  }
  if ((vsi->back)->hw.func_caps.npar_enable != 0U && ((unsigned int )(vsi->back)->hw.phy.link_info.link_speed == 4U || (unsigned int )(vsi->back)->hw.phy.link_info.link_speed == 2U)) {
    netdev_warn((struct net_device  const  *)vsi->netdev, "The partition detected link speed that is less than 10Gbps\n");
  } else {

  }
  switch ((unsigned int )(vsi->back)->hw.phy.link_info.link_speed) {
  case 16U: 
  strlcpy((char *)(& speed), "40 Gbps", 14UL);
  goto ldv_62593;
  case 32U: 
  strncpy((char *)(& speed), "20 Gbps", 14UL);
  goto ldv_62593;
  case 8U: 
  strlcpy((char *)(& speed), "10 Gbps", 14UL);
  goto ldv_62593;
  case 4U: 
  strlcpy((char *)(& speed), "1000 Mbps", 14UL);
  goto ldv_62593;
  case 2U: 
  strncpy((char *)(& speed), "100 Mbps", 14UL);
  goto ldv_62593;
  default: ;
  goto ldv_62593;
  }
  ldv_62593: ;
  switch ((unsigned int )(vsi->back)->hw.fc.current_mode) {
  case 3U: 
  strlcpy((char *)(& fc), "RX/TX", 8UL);
  goto ldv_62600;
  case 2U: 
  strlcpy((char *)(& fc), "TX", 8UL);
  goto ldv_62600;
  case 1U: 
  strlcpy((char *)(& fc), "RX", 8UL);
  goto ldv_62600;
  default: 
  strlcpy((char *)(& fc), "None", 8UL);
  goto ldv_62600;
  }
  ldv_62600: 
  netdev_info((struct net_device  const  *)vsi->netdev, "NIC Link is Up %s Full Duplex, Flow Control: %s\n",
              (char *)(& speed), (char *)(& fc));
  return;
}
}
static int i40e_up_complete(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  int err ;
  u32 tmp ;

  {
  pf = vsi->back;
  if ((pf->flags & 8ULL) != 0ULL) {
    i40e_vsi_configure_msix(vsi);
  } else {
    i40e_configure_msi_and_legacy(vsi);
  }
  err = i40e_vsi_control_rings(vsi, 1);
  if (err != 0) {
    return (err);
  } else {

  }
  clear_bit(3L, (unsigned long volatile   *)(& vsi->state));
  i40e_napi_enable_all(vsi);
  i40e_vsi_enable_irq(vsi);
  if ((int )pf->hw.phy.link_info.link_info & 1 && (unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0)) {
    i40e_print_link_message(vsi, 1);
    netif_tx_start_all_queues(vsi->netdev);
    netif_carrier_on(vsi->netdev);
  } else
  if ((unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0)) {
    i40e_print_link_message(vsi, 0);
    if (((int )pf->hw.phy.link_info.link_info & 64) != 0 && (int )((signed char )pf->hw.phy.link_info.an_info) >= 0) {
      netdev_err((struct net_device  const  *)vsi->netdev, "the driver failed to link because an unqualified module was detected.");
    } else {

    }
  } else {

  }
  if ((unsigned int )vsi->type == 7U) {
    tmp = 0U;
    pf->fd_atr_cnt = tmp;
    pf->fd_add_err = tmp;
    if (pf->fd_tcp_rule != 0U) {
      pf->flags = pf->flags & 0xffffffffffbfffffULL;
      if ((pf->hw.debug_mask & 4096U) != 0U) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Forcing ATR off, sideband rules for TCP/IPv4 exist\n");
      } else {

      }
      pf->fd_tcp_rule = 0U;
    } else {

    }
    i40e_fdir_filter_restore(vsi);
  } else {

  }
  i40e_service_event_schedule(pf);
  return (0);
}
}
static void i40e_vsi_reinit_locked(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  int __ret_warn_on ;
  int tmp ;
  long tmp___0 ;
  int tmp___1 ;

  {
  pf = vsi->back;
  tmp = preempt_count();
  __ret_warn_on = ((unsigned long )tmp & 2096896UL) != 0UL;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c",
                       4769);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  goto ldv_62616;
  ldv_62615: 
  usleep_range(1000UL, 2000UL);
  ldv_62616: 
  tmp___1 = test_and_set_bit(1L, (unsigned long volatile   *)(& pf->state));
  if (tmp___1 != 0) {
    goto ldv_62615;
  } else {

  }
  i40e_down(vsi);
  if ((unsigned int )vsi->type == 6U) {
    msleep(2000U);
  } else {

  }
  i40e_up(vsi);
  clear_bit(1L, (unsigned long volatile   *)(& pf->state));
  return;
}
}
int i40e_up(struct i40e_vsi *vsi ) 
{ 
  int err ;

  {
  err = i40e_vsi_configure(vsi);
  if (err == 0) {
    err = i40e_up_complete(vsi);
  } else {

  }
  return (err);
}
}
void i40e_down(struct i40e_vsi *vsi ) 
{ 
  int i ;

  {
  if ((unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0)) {
    netif_carrier_off(vsi->netdev);
    netif_tx_disable(vsi->netdev);
  } else {

  }
  i40e_vsi_disable_irq(vsi);
  i40e_vsi_control_rings(vsi, 0);
  i40e_napi_disable_all(vsi);
  i = 0;
  goto ldv_62627;
  ldv_62626: 
  i40e_clean_tx_ring(*(vsi->tx_rings + (unsigned long )i));
  i40e_clean_rx_ring(*(vsi->rx_rings + (unsigned long )i));
  i = i + 1;
  ldv_62627: ;
  if ((int )vsi->num_queue_pairs > i) {
    goto ldv_62626;
  } else {

  }

  return;
}
}
int i40e_setup_tc(struct net_device *netdev , u8 tc ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  u8 enabled_tc ;
  int ret ;
  int i ;
  u8 tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  enabled_tc = 0U;
  ret = -22;
  if ((pf->flags & 1048576ULL) == 0ULL) {
    netdev_info((struct net_device  const  *)netdev, "DCB is not enabled for adapter\n");
    goto exit;
  } else {

  }
  if ((pf->flags & 67108864ULL) != 0ULL) {
    netdev_info((struct net_device  const  *)netdev, "Configuring TC not supported in MFP mode\n");
    goto exit;
  } else {

  }
  tmp___0 = i40e_pf_get_num_tc(pf);
  if ((int )tmp___0 < (int )tc) {
    netdev_info((struct net_device  const  *)netdev, "TC count greater than enabled on link for adapter\n");
    goto exit;
  } else {

  }
  i = 0;
  goto ldv_62641;
  ldv_62640: 
  enabled_tc = (u8 )((int )((signed char )(1 << i)) | (int )((signed char )enabled_tc));
  i = i + 1;
  ldv_62641: ;
  if ((int )tc > i) {
    goto ldv_62640;
  } else {

  }

  if ((int )vsi->tc_config.enabled_tc == (int )enabled_tc) {
    return (0);
  } else {

  }
  i40e_quiesce_vsi(vsi);
  ret = i40e_vsi_config_tc(vsi, (int )enabled_tc);
  if (ret != 0) {
    netdev_info((struct net_device  const  *)netdev, "Failed configuring TC for VSI seid=%d\n",
                (int )vsi->seid);
    goto exit;
  } else {

  }
  i40e_unquiesce_vsi(vsi);
  exit: ;
  return (ret);
}
}
int i40e_open(struct net_device *netdev ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  int err ;
  int tmp___0 ;
  int tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  tmp___0 = constant_test_bit(0L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___0 != 0) {
    return (-16);
  } else {
    tmp___1 = constant_test_bit(20L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___1 != 0) {
      return (-16);
    } else {

    }
  }
  netif_carrier_off(netdev);
  err = i40e_vsi_open(vsi);
  if (err != 0) {
    return (err);
  } else {

  }
  writel(9U, (void volatile   *)pf->hw.hw_addr + 279256U);
  writel(137U, (void volatile   *)pf->hw.hw_addr + 279260U);
  writel(128U, (void volatile   *)pf->hw.hw_addr + 279264U);
  vxlan_get_rx_port(netdev);
  return (0);
}
}
int i40e_vsi_open(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  char int_name[25U] ;
  int err ;
  char const   *tmp ;
  char const   *tmp___0 ;
  char const   *tmp___1 ;

  {
  pf = vsi->back;
  err = i40e_vsi_setup_tx_resources(vsi);
  if (err != 0) {
    goto err_setup_tx;
  } else {

  }
  err = i40e_vsi_setup_rx_resources(vsi);
  if (err != 0) {
    goto err_setup_rx;
  } else {

  }
  err = i40e_vsi_configure(vsi);
  if (err != 0) {
    goto err_setup_rx;
  } else {

  }
  if ((unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0)) {
    tmp = dev_driver_string((struct device  const  *)(& (pf->pdev)->dev));
    snprintf((char *)(& int_name), 24UL, "%s-%s", tmp, (char *)(& (vsi->netdev)->name));
    err = i40e_vsi_request_irq(vsi, (char *)(& int_name));
    if (err != 0) {
      goto err_setup_rx;
    } else {

    }
    err = netif_set_real_num_tx_queues(vsi->netdev, (unsigned int )vsi->num_queue_pairs);
    if (err != 0) {
      goto err_set_queues;
    } else {

    }
    err = netif_set_real_num_rx_queues(vsi->netdev, (unsigned int )vsi->num_queue_pairs);
    if (err != 0) {
      goto err_set_queues;
    } else {

    }
  } else
  if ((unsigned int )vsi->type == 7U) {
    tmp___0 = dev_name((struct device  const  *)(& (pf->pdev)->dev));
    tmp___1 = dev_driver_string((struct device  const  *)(& (pf->pdev)->dev));
    snprintf((char *)(& int_name), 24UL, "%s-%s:fdir", tmp___1, tmp___0);
    err = i40e_vsi_request_irq(vsi, (char *)(& int_name));
  } else {
    err = -22;
    goto err_setup_rx;
  }
  err = i40e_up_complete(vsi);
  if (err != 0) {
    goto err_up_complete;
  } else {

  }
  return (0);
  err_up_complete: 
  i40e_down(vsi);
  err_set_queues: 
  i40e_vsi_free_irq(vsi);
  err_setup_rx: 
  i40e_vsi_free_rx_resources(vsi);
  err_setup_tx: 
  i40e_vsi_free_tx_resources(vsi);
  if ((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) == (unsigned long )vsi) {
    i40e_do_reset(pf, 4096U);
  } else {

  }
  return (err);
}
}
static void i40e_fdir_filter_exit(struct i40e_pf *pf ) 
{ 
  struct i40e_fdir_filter *filter ;
  struct hlist_node *node2 ;
  struct hlist_node *____ptr ;
  struct hlist_node  const  *__mptr ;
  struct i40e_fdir_filter *tmp ;
  struct hlist_node *____ptr___0 ;
  struct hlist_node  const  *__mptr___0 ;
  struct i40e_fdir_filter *tmp___0 ;

  {
  ____ptr = pf->fdir_filter_list.first;
  if ((unsigned long )____ptr != (unsigned long )((struct hlist_node *)0)) {
    __mptr = (struct hlist_node  const  *)____ptr;
    tmp = (struct i40e_fdir_filter *)__mptr;
  } else {
    tmp = (struct i40e_fdir_filter *)0;
  }
  filter = tmp;
  goto ldv_62675;
  ldv_62674: 
  hlist_del(& filter->fdir_node);
  kfree((void const   *)filter);
  ____ptr___0 = node2;
  if ((unsigned long )____ptr___0 != (unsigned long )((struct hlist_node *)0)) {
    __mptr___0 = (struct hlist_node  const  *)____ptr___0;
    tmp___0 = (struct i40e_fdir_filter *)__mptr___0;
  } else {
    tmp___0 = (struct i40e_fdir_filter *)0;
  }
  filter = tmp___0;
  ldv_62675: ;
  if ((unsigned long )filter != (unsigned long )((struct i40e_fdir_filter *)0)) {
    node2 = filter->fdir_node.next;
    goto ldv_62674;
  } else {

  }
  pf->fdir_pf_active_filters = 0U;
  return;
}
}
int i40e_close(struct net_device *netdev ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  i40e_vsi_close(vsi);
  return (0);
}
}
void i40e_do_reset(struct i40e_pf *pf , u32 reset_flags ) 
{ 
  u32 val ;
  int __ret_warn_on ;
  int tmp ;
  long tmp___0 ;
  bool tmp___1 ;
  struct _ddebug descriptor ;
  long tmp___2 ;
  struct _ddebug descriptor___0 ;
  long tmp___3 ;
  struct _ddebug descriptor___1 ;
  long tmp___4 ;
  int v ;
  struct i40e_vsi *vsi ;
  int tmp___5 ;
  int v___0 ;
    klee_make_symbolic(&v___0, sizeof(int), "v___0");
  struct i40e_vsi *vsi___0 ;
  int tmp___6 ;

  {
  tmp = preempt_count();
  __ret_warn_on = ((unsigned long )tmp & 2096896UL) != 0UL;
  tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___0 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c",
                       5063);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  tmp___1 = i40e_check_asq_alive(& pf->hw);
  if ((int )tmp___1) {
    i40e_vc_notify_reset(pf);
  } else {

  }
  if ((reset_flags & 16384U) != 0U) {
    descriptor.modname = "i40e";
    descriptor.function = "i40e_do_reset";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
    descriptor.format = "GlobalR requested\n";
    descriptor.lineno = 5079U;
    descriptor.flags = 0U;
    tmp___2 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___2 != 0L) {
      __dynamic_dev_dbg(& descriptor, (struct device  const  *)(& (pf->pdev)->dev),
                        "GlobalR requested\n");
    } else {

    }
    val = readl((void const volatile   *)pf->hw.hw_addr + 754064U);
    val = val | 2U;
    writel(val, (void volatile   *)pf->hw.hw_addr + 754064U);
  } else
  if ((reset_flags & 8192U) != 0U) {
    descriptor___0.modname = "i40e";
    descriptor___0.function = "i40e_do_reset";
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
    descriptor___0.format = "CoreR requested\n";
    descriptor___0.lineno = 5090U;
    descriptor___0.flags = 0U;
    tmp___3 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
    if (tmp___3 != 0L) {
      __dynamic_dev_dbg(& descriptor___0, (struct device  const  *)(& (pf->pdev)->dev),
                        "CoreR requested\n");
    } else {

    }
    val = readl((void const volatile   *)pf->hw.hw_addr + 754064U);
    val = val | 1U;
    writel(val, (void volatile   *)pf->hw.hw_addr + 754064U);
    readl((void const volatile   *)pf->hw.hw_addr + 745772U);
  } else
  if ((reset_flags & 4096U) != 0U) {
    descriptor___1.modname = "i40e";
    descriptor___1.function = "i40e_do_reset";
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
    descriptor___1.format = "PFR requested\n";
    descriptor___1.lineno = 5106U;
    descriptor___1.flags = 0U;
    tmp___4 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
    if (tmp___4 != 0L) {
      __dynamic_dev_dbg(& descriptor___1, (struct device  const  *)(& (pf->pdev)->dev),
                        "PFR requested\n");
    } else {

    }
    i40e_handle_reset_warning(pf);
  } else
  if ((reset_flags & 2048U) != 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "VSI reinit requested\n");
    v = 0;
    goto ldv_62696;
    ldv_62695: 
    vsi = *(pf->vsi + (unsigned long )v);
    if ((unsigned long )vsi != (unsigned long )((struct i40e_vsi *)0)) {
      tmp___5 = constant_test_bit(11L, (unsigned long const volatile   *)(& vsi->state));
      if (tmp___5 != 0) {
        i40e_vsi_reinit_locked(*(pf->vsi + (unsigned long )v));
        clear_bit(11L, (unsigned long volatile   *)(& vsi->state));
      } else {

      }
    } else {

    }
    v = v + 1;
    ldv_62696: ;
    if ((int )pf->num_alloc_vsi > v) {
      goto ldv_62695;
    } else {

    }

    return;
  } else
  if ((reset_flags & 2097152U) != 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "VSI down requested\n");
    v___0 = 0;
    goto ldv_62701;
    ldv_62700: 
    vsi___0 = *(pf->vsi + (unsigned long )v___0);
    if ((unsigned long )vsi___0 != (unsigned long )((struct i40e_vsi *)0)) {
      tmp___6 = constant_test_bit(21L, (unsigned long const volatile   *)(& vsi___0->state));
      if (tmp___6 != 0) {
        set_bit(3L, (unsigned long volatile   *)(& vsi___0->state));
        i40e_down(vsi___0);
        clear_bit(21L, (unsigned long volatile   *)(& vsi___0->state));
      } else {

      }
    } else {

    }
    v___0 = v___0 + 1;
    ldv_62701: ;
    if ((int )pf->num_alloc_vsi > v___0) {
      goto ldv_62700;
    } else {

    }

    return;
  } else {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "bad reset request 0x%08x\n",
              reset_flags);
    return;
  }
  return;
}
}
bool i40e_dcb_need_reconfig(struct i40e_pf *pf , struct i40e_dcbx_config *old_cfg ,
                            struct i40e_dcbx_config *new_cfg ) 
{ 
  bool need_reconfig ;
  struct _ddebug descriptor ;
  long tmp ;
  int tmp___0 ;
  struct _ddebug descriptor___0 ;
  long tmp___1 ;
  int tmp___2 ;
  struct _ddebug descriptor___1 ;
  long tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  struct _ddebug descriptor___2 ;
  long tmp___6 ;
  int tmp___7 ;
    klee_make_symbolic(&tmp___7, sizeof(int), "tmp___7");
  struct _ddebug descriptor___3 ;
  long tmp___8 ;
  int tmp___9 ;
    klee_make_symbolic(&tmp___9, sizeof(int), "tmp___9");
  struct _ddebug descriptor___4 ;
  long tmp___10 ;

  {
  need_reconfig = 0;
  tmp___5 = memcmp((void const   *)(& new_cfg->etscfg), (void const   *)(& old_cfg->etscfg),
                   27UL);
  if (tmp___5 != 0) {
    tmp___0 = memcmp((void const   *)(& new_cfg->etscfg.prioritytable), (void const   *)(& old_cfg->etscfg.prioritytable),
                     8UL);
    if (tmp___0 != 0) {
      need_reconfig = 1;
      descriptor.modname = "i40e";
      descriptor.function = "i40e_dcb_need_reconfig";
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
      descriptor.format = "ETS UP2TC changed.\n";
      descriptor.lineno = 5172U;
      descriptor.flags = 0U;
      tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
      if (tmp != 0L) {
        __dynamic_dev_dbg(& descriptor, (struct device  const  *)(& (pf->pdev)->dev),
                          "ETS UP2TC changed.\n");
      } else {

      }
    } else {

    }
    tmp___2 = memcmp((void const   *)(& new_cfg->etscfg.tcbwtable), (void const   *)(& old_cfg->etscfg.tcbwtable),
                     8UL);
    if (tmp___2 != 0) {
      descriptor___0.modname = "i40e";
      descriptor___0.function = "i40e_dcb_need_reconfig";
      descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
      descriptor___0.format = "ETS TC BW Table changed.\n";
      descriptor___0.lineno = 5178U;
      descriptor___0.flags = 0U;
      tmp___1 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
      if (tmp___1 != 0L) {
        __dynamic_dev_dbg(& descriptor___0, (struct device  const  *)(& (pf->pdev)->dev),
                          "ETS TC BW Table changed.\n");
      } else {

      }
    } else {

    }
    tmp___4 = memcmp((void const   *)(& new_cfg->etscfg.tsatable), (void const   *)(& old_cfg->etscfg.tsatable),
                     8UL);
    if (tmp___4 != 0) {
      descriptor___1.modname = "i40e";
      descriptor___1.function = "i40e_dcb_need_reconfig";
      descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
      descriptor___1.format = "ETS TSA Table changed.\n";
      descriptor___1.lineno = 5183U;
      descriptor___1.flags = 0U;
      tmp___3 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
      if (tmp___3 != 0L) {
        __dynamic_dev_dbg(& descriptor___1, (struct device  const  *)(& (pf->pdev)->dev),
                          "ETS TSA Table changed.\n");
      } else {

      }
    } else {

    }
  } else {

  }
  tmp___7 = memcmp((void const   *)(& new_cfg->pfc), (void const   *)(& old_cfg->pfc),
                   4UL);
  if (tmp___7 != 0) {
    need_reconfig = 1;
    descriptor___2.modname = "i40e";
    descriptor___2.function = "i40e_dcb_need_reconfig";
    descriptor___2.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
    descriptor___2.format = "PFC config change detected.\n";
    descriptor___2.lineno = 5191U;
    descriptor___2.flags = 0U;
    tmp___6 = ldv__builtin_expect((long )descriptor___2.flags & 1L, 0L);
    if (tmp___6 != 0L) {
      __dynamic_dev_dbg(& descriptor___2, (struct device  const  *)(& (pf->pdev)->dev),
                        "PFC config change detected.\n");
    } else {

    }
  } else {

  }
  tmp___9 = memcmp((void const   *)(& new_cfg->app), (void const   *)(& old_cfg->app),
                   128UL);
  if (tmp___9 != 0) {
    need_reconfig = 1;
    descriptor___3.modname = "i40e";
    descriptor___3.function = "i40e_dcb_need_reconfig";
    descriptor___3.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
    descriptor___3.format = "APP Table change detected.\n";
    descriptor___3.lineno = 5199U;
    descriptor___3.flags = 0U;
    tmp___8 = ldv__builtin_expect((long )descriptor___3.flags & 1L, 0L);
    if (tmp___8 != 0L) {
      __dynamic_dev_dbg(& descriptor___3, (struct device  const  *)(& (pf->pdev)->dev),
                        "APP Table change detected.\n");
    } else {

    }
  } else {

  }
  descriptor___4.modname = "i40e";
  descriptor___4.function = "i40e_dcb_need_reconfig";
  descriptor___4.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
  descriptor___4.format = "%s: need_reconfig=%d\n";
  descriptor___4.lineno = 5203U;
  descriptor___4.flags = 0U;
  tmp___10 = ldv__builtin_expect((long )descriptor___4.flags & 1L, 0L);
  if (tmp___10 != 0L) {
    __dynamic_dev_dbg(& descriptor___4, (struct device  const  *)(& (pf->pdev)->dev),
                      "%s: need_reconfig=%d\n", "i40e_dcb_need_reconfig", (int )need_reconfig);
  } else {

  }
  return (need_reconfig);
}
}
static int i40e_handle_lldp_event(struct i40e_pf *pf , struct i40e_arq_event_info *e ) 
{ 
  struct i40e_aqc_lldp_get_mib *mib ;
  struct i40e_hw *hw ;
  struct i40e_dcbx_config tmp_dcbx_cfg ;
  bool need_reconfig ;
  int ret ;
  u8 type ;
  struct _ddebug descriptor ;
  long tmp ;
  struct _ddebug descriptor___0 ;
  long tmp___0 ;
  i40e_status tmp___1 ;
  i40e_status tmp___2 ;
  struct _ddebug descriptor___1 ;
  long tmp___3 ;
  int tmp___4 ;
  u8 tmp___5 ;

  {
  mib = (struct i40e_aqc_lldp_get_mib *)(& e->desc.params.raw);
  hw = & pf->hw;
  need_reconfig = 0;
  ret = 0;
  if ((pf->flags & 536870912ULL) == 0ULL) {
    return (ret);
  } else {

  }
  type = (unsigned int )((u8 )((int )mib->type >> 2)) & 12U;
  descriptor.modname = "i40e";
  descriptor.function = "i40e_handle_lldp_event";
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
  descriptor.format = "%s: LLDP event mib bridge type 0x%x\n";
  descriptor.lineno = 5231U;
  descriptor.flags = 0U;
  tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
  if (tmp != 0L) {
    __dynamic_dev_dbg(& descriptor, (struct device  const  *)(& (pf->pdev)->dev),
                      "%s: LLDP event mib bridge type 0x%x\n", "i40e_handle_lldp_event",
                      (int )type);
  } else {

  }
  if ((unsigned int )type != 0U) {
    return (ret);
  } else {

  }
  type = (unsigned int )mib->type & 3U;
  descriptor___0.modname = "i40e";
  descriptor___0.function = "i40e_handle_lldp_event";
  descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
  descriptor___0.format = "%s: LLDP event mib type %s\n";
  descriptor___0.lineno = 5239U;
  descriptor___0.flags = 0U;
  tmp___0 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
  if (tmp___0 != 0L) {
    __dynamic_dev_dbg(& descriptor___0, (struct device  const  *)(& (pf->pdev)->dev),
                      "%s: LLDP event mib type %s\n", "i40e_handle_lldp_event", (unsigned int )type != 0U ? (char *)"remote" : (char *)"local");
  } else {

  }
  if ((unsigned int )type == 1U) {
    tmp___1 = i40e_aq_get_dcb_config(hw, 1, 0, & hw->remote_dcbx_config);
    ret = (int )tmp___1;
    goto exit;
  } else {

  }
  tmp_dcbx_cfg = hw->local_dcbx_config;
  memset((void *)(& hw->local_dcbx_config), 0, 196UL);
  tmp___2 = i40e_get_dcb_config(& pf->hw);
  ret = (int )tmp___2;
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Failed querying DCB configuration data from firmware.\n");
    goto exit;
  } else {

  }
  tmp___4 = memcmp((void const   *)(& tmp_dcbx_cfg), (void const   *)(& hw->local_dcbx_config),
                   196UL);
  if (tmp___4 == 0) {
    descriptor___1.modname = "i40e";
    descriptor___1.function = "i40e_handle_lldp_event";
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
    descriptor___1.format = "No change detected in DCBX configuration.\n";
    descriptor___1.lineno = 5263U;
    descriptor___1.flags = 0U;
    tmp___3 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
    if (tmp___3 != 0L) {
      __dynamic_dev_dbg(& descriptor___1, (struct device  const  *)(& (pf->pdev)->dev),
                        "No change detected in DCBX configuration.\n");
    } else {

    }
    goto exit;
  } else {

  }
  need_reconfig = i40e_dcb_need_reconfig(pf, & tmp_dcbx_cfg, & hw->local_dcbx_config);
  i40e_dcbnl_flush_apps(pf, & tmp_dcbx_cfg, & hw->local_dcbx_config);
  if (! need_reconfig) {
    goto exit;
  } else {

  }
  tmp___5 = i40e_dcb_get_num_tc(& hw->local_dcbx_config);
  if ((unsigned int )tmp___5 > 1U) {
    pf->flags = pf->flags | 1048576ULL;
  } else {
    pf->flags = pf->flags & 0xffffffffffefffffULL;
  }
  set_bit(24L, (unsigned long volatile   *)(& pf->state));
  i40e_pf_quiesce_all_vsi(pf);
  i40e_dcb_reconfigure(pf);
  ret = i40e_resume_port_tx(pf);
  clear_bit(24L, (unsigned long volatile   *)(& pf->state));
  if (ret != 0) {
    goto exit;
  } else {

  }
  ret = i40e_pf_wait_txq_disabled(pf);
  if (ret != 0) {
    set_bit(12L, (unsigned long volatile   *)(& pf->state));
    i40e_service_event_schedule(pf);
  } else {
    i40e_pf_unquiesce_all_vsi(pf);
  }
  exit: ;
  return (ret);
}
}
void i40e_do_reset_safe(struct i40e_pf *pf , u32 reset_flags ) 
{ 


  {
  rtnl_lock();
  i40e_do_reset(pf, reset_flags);
  rtnl_unlock();
  return;
}
}
static void i40e_handle_lan_overflow_event(struct i40e_pf *pf , struct i40e_arq_event_info *e ) 
{ 
  struct i40e_aqc_lan_overflow *data ;
  u32 queue ;
  u32 qtx_ctl ;
  struct i40e_hw *hw ;
  struct i40e_vf *vf ;
  u16 vf_id ;
  struct _ddebug descriptor ;
  long tmp ;

  {
  data = (struct i40e_aqc_lan_overflow *)(& e->desc.params.raw);
  queue = data->prtdcb_rupto;
  qtx_ctl = data->otx_ctl;
  hw = & pf->hw;
  descriptor.modname = "i40e";
  descriptor.function = "i40e_handle_lan_overflow_event";
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
  descriptor.format = "overflow Rx Queue Number = %d QTX_CTL=0x%08x\n";
  descriptor.lineno = 5343U;
  descriptor.flags = 0U;
  tmp = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
  if (tmp != 0L) {
    __dynamic_dev_dbg(& descriptor, (struct device  const  *)(& (pf->pdev)->dev),
                      "overflow Rx Queue Number = %d QTX_CTL=0x%08x\n", queue, qtx_ctl);
  } else {

  }
  if ((qtx_ctl & 3U) == 0U) {
    vf_id = (unsigned short )((qtx_ctl & 65408U) >> 7);
    vf_id = (int )vf_id - (int )((u16 )hw->func_caps.vf_base_id);
    vf = pf->vf + (unsigned long )vf_id;
    i40e_vc_notify_vf_reset(vf);
    msleep(20U);
    i40e_reset_vf(vf, 0);
  } else {

  }
  return;
}
}
static void i40e_service_event_complete(struct i40e_pf *pf ) 
{ 
  int tmp ;
  long tmp___0 ;

  {
  tmp = constant_test_bit(5L, (unsigned long const volatile   *)(& pf->state));
  tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c"),
                         "i" (5365), "i" (12UL));
    ldv_62750: ;
    goto ldv_62750;
  } else {

  }
  __asm__  volatile   ("": : : "memory");
  clear_bit(5L, (unsigned long volatile   *)(& pf->state));
  return;
}
}
u32 i40e_get_cur_guaranteed_fd_count(struct i40e_pf *pf ) 
{ 
  u32 val ;
  u32 fcnt_prog ;

  {
  val = readl((void const volatile   *)pf->hw.hw_addr + 2384768U);
  fcnt_prog = val & 8191U;
  return (fcnt_prog);
}
}
u32 i40e_get_current_fd_count(struct i40e_pf *pf ) 
{ 
  u32 val ;
  u32 fcnt_prog ;

  {
  val = readl((void const volatile   *)pf->hw.hw_addr + 2384768U);
  fcnt_prog = (val & 8191U) + ((val & 536805376U) >> 16);
  return (fcnt_prog);
}
}
u32 i40e_get_global_fd_count(struct i40e_pf *pf ) 
{ 
  u32 val ;
  u32 fcnt_prog ;

  {
  val = readl((void const volatile   *)pf->hw.hw_addr + 2530220U);
  fcnt_prog = (val & 8191U) + ((val & 67100672U) >> 13);
  return (fcnt_prog);
}
}
void i40e_fdir_check_and_reenable(struct i40e_pf *pf ) 
{ 
  u32 fcnt_prog ;
  u32 fcnt_avail ;
  int tmp ;
  u32 tmp___0 ;

  {
  tmp = constant_test_bit(22L, (unsigned long const volatile   *)(& pf->state));
  if (tmp != 0) {
    return;
  } else {

  }
  fcnt_prog = i40e_get_global_fd_count(pf);
  fcnt_avail = (u32 )pf->fdir_pf_filter_count;
  if (fcnt_avail - 32U > fcnt_prog || pf->fd_add_err == 0U) {
    goto _L;
  } else {
    tmp___0 = i40e_get_current_atr_cnt(pf);
    if (tmp___0 < pf->fd_atr_cnt) {
      _L: /* CIL Label */ 
      if ((pf->flags & 2097152ULL) != 0ULL && (pf->auto_disable_flags & 2097152ULL) != 0ULL) {
        pf->auto_disable_flags = pf->auto_disable_flags & 0xffffffffffdfffffULL;
        if ((pf->hw.debug_mask & 4096U) != 0U) {
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "FD Sideband/ntuple is being enabled since we have space in the table now\n");
        } else {

        }
      } else {

      }
    } else {

    }
  }
  if (fcnt_avail - 64U > fcnt_prog) {
    if ((pf->flags & 4194304ULL) != 0ULL && (pf->auto_disable_flags & 4194304ULL) != 0ULL) {
      pf->auto_disable_flags = pf->auto_disable_flags & 0xffffffffffbfffffULL;
      if ((pf->hw.debug_mask & 4096U) != 0U) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ATR is being enabled since we have space in the table now\n");
      } else {

      }
    } else {

    }
  } else {

  }
  return;
}
}
static void i40e_fdir_flush_and_replay(struct i40e_pf *pf ) 
{ 
  unsigned long min_flush_time ;
    klee_make_symbolic(&min_flush_time, sizeof(long), "min_flush_time");
  int flush_wait_retry ;
    klee_make_symbolic(&flush_wait_retry, sizeof(int), "flush_wait_retry");
  bool disable_atr ;
  int fd_room ;
    klee_make_symbolic(&fd_room, sizeof(int), "fd_room");
  int reg ;
    klee_make_symbolic(&reg, sizeof(int), "reg");
  unsigned int tmp ;
  int tmp___0 ;

  {
  flush_wait_retry = 50;
  disable_atr = 0;
  if ((pf->flags & 6291456ULL) == 0ULL) {
    return;
  } else {

  }
  if ((long )((pf->fd_flush_timestamp - (unsigned long )jiffies) + 2500UL) < 0L) {
    min_flush_time = pf->fd_flush_timestamp + 7500UL;
    fd_room = (int )pf->fdir_pf_filter_count - (int )pf->fdir_pf_active_filters;
    if ((long )(min_flush_time - (unsigned long )jiffies) >= 0L && fd_room <= 127) {
      if ((pf->hw.debug_mask & 4096U) != 0U) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ATR disabled, not enough FD filter space.\n");
      } else {

      }
      disable_atr = 1;
    } else {

    }
    pf->fd_flush_timestamp = jiffies;
    pf->flags = pf->flags & 0xffffffffffbfffffULL;
    writel(1U, (void volatile   *)pf->hw.hw_addr + 2383232U);
    readl((void const volatile   *)pf->hw.hw_addr + 745772U);
    pf->fd_flush_cnt = pf->fd_flush_cnt + 1U;
    pf->fd_add_err = 0U;
    ldv_62792: 
    usleep_range(5000UL, 6000UL);
    tmp = readl((void const volatile   *)pf->hw.hw_addr + 2383232U);
    reg = (int )tmp;
    if ((reg & 1) == 0) {
      goto ldv_62791;
    } else {

    }
    tmp___0 = flush_wait_retry;
    flush_wait_retry = flush_wait_retry - 1;
    if (tmp___0 != 0) {
      goto ldv_62792;
    } else {

    }
    ldv_62791: ;
    if (reg & 1) {
      dev_warn((struct device  const  *)(& (pf->pdev)->dev), "FD table did not flush, needs more time\n");
    } else {
      i40e_fdir_filter_restore(*(pf->vsi + (unsigned long )pf->lan_vsi));
      if (! disable_atr) {
        pf->flags = pf->flags | 4194304ULL;
      } else {

      }
      clear_bit(22L, (unsigned long volatile   *)(& pf->state));
      if ((pf->hw.debug_mask & 4096U) != 0U) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "FD Filter table flushed and FD-SB replayed.\n");
      } else {

      }
    }
  } else {

  }
  return;
}
}
u32 i40e_get_current_atr_cnt(struct i40e_pf *pf ) 
{ 
  u32 tmp ;

  {
  tmp = i40e_get_current_fd_count(pf);
  return (tmp - (u32 )pf->fdir_pf_active_filters);
}
}
static void i40e_fdir_reinit_subtask(struct i40e_pf *pf ) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp = constant_test_bit(3L, (unsigned long const volatile   *)(& pf->state));
  if (tmp != 0) {
    return;
  } else {

  }
  if ((pf->flags & 6291456ULL) == 0ULL) {
    return;
  } else {

  }
  tmp___0 = constant_test_bit(22L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___0 != 0) {
    i40e_fdir_flush_and_replay(pf);
  } else {

  }
  i40e_fdir_check_and_reenable(pf);
  return;
}
}
static void i40e_vsi_link_event(struct i40e_vsi *vsi , bool link_up ) 
{ 
  int tmp ;

  {
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
    return;
  } else {
    tmp = constant_test_bit(3L, (unsigned long const volatile   *)(& vsi->state));
    if (tmp != 0) {
      return;
    } else {

    }
  }
  switch ((unsigned int )vsi->type) {
  case 0U: ;
  case 4U: ;
  if ((unsigned long )vsi->netdev == (unsigned long )((struct net_device *)0) || ! vsi->netdev_registered) {
    goto ldv_62805;
  } else {

  }
  if ((int )link_up) {
    netif_carrier_on(vsi->netdev);
    netif_tx_wake_all_queues(vsi->netdev);
  } else {
    netif_carrier_off(vsi->netdev);
    netif_tx_stop_all_queues(vsi->netdev);
  }
  goto ldv_62805;
  case 6U: ;
  case 2U: ;
  case 3U: ;
  case 5U: ;
  default: ;
  goto ldv_62805;
  }
  ldv_62805: ;
  return;
}
}
static void i40e_veb_link_event(struct i40e_veb *veb , bool link_up ) 
{ 
  struct i40e_pf *pf ;
  int i ;

  {
  if ((unsigned long )veb == (unsigned long )((struct i40e_veb *)0) || (unsigned long )veb->pf == (unsigned long )((struct i40e_pf *)0)) {
    return;
  } else {

  }
  pf = veb->pf;
  i = 0;
  goto ldv_62818;
  ldv_62817: ;
  if ((unsigned long )pf->veb[i] != (unsigned long )((struct i40e_veb *)0) && (int )(pf->veb[i])->uplink_seid == (int )veb->seid) {
    i40e_veb_link_event(pf->veb[i], (int )link_up);
  } else {

  }
  i = i + 1;
  ldv_62818: ;
  if (i <= 15) {
    goto ldv_62817;
  } else {

  }
  i = 0;
  goto ldv_62821;
  ldv_62820: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0) && (int )(*(pf->vsi + (unsigned long )i))->uplink_seid == (int )veb->seid) {
    i40e_vsi_link_event(*(pf->vsi + (unsigned long )i), (int )link_up);
  } else {

  }
  i = i + 1;
  ldv_62821: ;
  if ((int )pf->num_alloc_vsi > i) {
    goto ldv_62820;
  } else {

  }

  return;
}
}
static void i40e_link_event(struct i40e_pf *pf ) 
{ 
  bool new_link ;
  bool old_link ;
  struct i40e_vsi *vsi ;
  u8 new_link_speed ;
  u8 old_link_speed ;
  int tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  vsi = *(pf->vsi + (unsigned long )pf->lan_vsi);
  pf->hw.phy.get_link_info = 1;
  old_link = ((int )pf->hw.phy.link_info_old.link_info & 1) != 0;
  new_link = i40e_get_link_status(& pf->hw);
  old_link_speed = (u8 )pf->hw.phy.link_info_old.link_speed;
  new_link_speed = (u8 )pf->hw.phy.link_info.link_speed;
  if ((int )new_link == (int )old_link && (int )new_link_speed == (int )old_link_speed) {
    tmp = constant_test_bit(3L, (unsigned long const volatile   *)(& vsi->state));
    if (tmp != 0) {
      return;
    } else {
      tmp___0 = netif_carrier_ok((struct net_device  const  *)vsi->netdev);
      if ((int )tmp___0 == (int )new_link) {
        return;
      } else {

      }
    }
  } else {

  }
  tmp___1 = constant_test_bit(3L, (unsigned long const volatile   *)(& vsi->state));
  if (tmp___1 == 0) {
    i40e_print_link_message(vsi, (int )new_link);
  } else {

  }
  if ((unsigned int )pf->lan_veb != 65535U && (unsigned long )pf->veb[(int )pf->lan_veb] != (unsigned long )((struct i40e_veb *)0)) {
    i40e_veb_link_event(pf->veb[(int )pf->lan_veb], (int )new_link);
  } else {
    i40e_vsi_link_event(vsi, (int )new_link);
  }
  if ((unsigned long )pf->vf != (unsigned long )((struct i40e_vf *)0)) {
    i40e_vc_notify_link_state(pf);
  } else {

  }
  if ((pf->flags & 33554432ULL) != 0ULL) {
    i40e_ptp_set_increment(pf);
  } else {

  }
  return;
}
}
static void i40e_check_hang_subtask(struct i40e_pf *pf ) 
{ 
  int i ;
  int v ;
  int tmp ;
  int tmp___0 ;
  struct i40e_vsi *vsi ;
  int armed ;
    klee_make_symbolic(&armed, sizeof(int), "armed");
  int tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  u16 vec ;
  u32 val ;

  {
  tmp = constant_test_bit(3L, (unsigned long const volatile   *)(& pf->state));
  if (tmp != 0) {
    return;
  } else {
    tmp___0 = constant_test_bit(1L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___0 != 0) {
      return;
    } else {

    }
  }
  v = 0;
  goto ldv_62848;
  ldv_62847: 
  vsi = *(pf->vsi + (unsigned long )v);
  armed = 0;
  if ((unsigned long )*(pf->vsi + (unsigned long )v) == (unsigned long )((struct i40e_vsi *)0)) {
    goto ldv_62838;
  } else {
    tmp___1 = constant_test_bit(3L, (unsigned long const volatile   *)(& vsi->state));
    if (tmp___1 != 0) {
      goto ldv_62838;
    } else
    if ((unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0)) {
      tmp___2 = netif_carrier_ok((struct net_device  const  *)vsi->netdev);
      if (tmp___2) {
        tmp___3 = 0;
      } else {
        tmp___3 = 1;
      }
      if (tmp___3) {
        goto ldv_62838;
      } else {

      }
    } else {

    }
  }
  i = 0;
  goto ldv_62840;
  ldv_62839: 
  set_bit(2L, (unsigned long volatile   *)(& (*(vsi->tx_rings + (unsigned long )i))->state));
  tmp___4 = constant_test_bit(3L, (unsigned long const volatile   *)(& (*(vsi->tx_rings + (unsigned long )i))->state));
  if (tmp___4 != 0) {
    armed = armed + 1;
  } else {

  }
  i = i + 1;
  ldv_62840: ;
  if ((int )vsi->num_queue_pairs > i) {
    goto ldv_62839;
  } else {

  }

  if (armed != 0) {
    if ((pf->flags & 8ULL) == 0ULL) {
      writel(117440541U, (void volatile   *)(vsi->back)->hw.hw_addr + 230528U);
    } else {
      vec = (unsigned int )((u16 )vsi->base_vector) + 65535U;
      val = 117440541U;
      i = 0;
      goto ldv_62845;
      ldv_62844: 
      writel(val, (void volatile   *)(vsi->back)->hw.hw_addr + (unsigned long )(((int )vec + 53760) * 4));
      i = i + 1;
      vec = (u16 )((int )vec + 1);
      ldv_62845: ;
      if (vsi->num_q_vectors > i) {
        goto ldv_62844;
      } else {

      }

    }
    readl((void const volatile   *)(vsi->back)->hw.hw_addr + 745772U);
  } else {

  }
  ldv_62838: 
  v = v + 1;
  ldv_62848: ;
  if ((int )pf->num_alloc_vsi > v) {
    goto ldv_62847;
  } else {

  }

  return;
}
}
static void i40e_watchdog_subtask(struct i40e_pf *pf ) 
{ 
  int i ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = constant_test_bit(3L, (unsigned long const volatile   *)(& pf->state));
  if (tmp != 0) {
    return;
  } else {
    tmp___0 = constant_test_bit(1L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___0 != 0) {
      return;
    } else {

    }
  }
  if ((long )((unsigned long )jiffies - (pf->service_timer_previous + pf->service_timer_period)) < 0L) {
    return;
  } else {

  }
  pf->service_timer_previous = jiffies;
  i40e_check_hang_subtask(pf);
  i40e_link_event(pf);
  i = 0;
  goto ldv_62861;
  ldv_62860: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0) && (unsigned long )(*(pf->vsi + (unsigned long )i))->netdev != (unsigned long )((struct net_device *)0)) {
    i40e_update_stats(*(pf->vsi + (unsigned long )i));
  } else {

  }
  i = i + 1;
  ldv_62861: ;
  if ((int )pf->num_alloc_vsi > i) {
    goto ldv_62860;
  } else {

  }
  i = 0;
  goto ldv_62864;
  ldv_62863: ;
  if ((unsigned long )pf->veb[i] != (unsigned long )((struct i40e_veb *)0)) {
    i40e_update_veb_stats(pf->veb[i]);
  } else {

  }
  i = i + 1;
  ldv_62864: ;
  if (i <= 15) {
    goto ldv_62863;
  } else {

  }
  i40e_ptp_rx_hang(*(pf->vsi + (unsigned long )pf->lan_vsi));
  return;
}
}
static void i40e_reset_subtask(struct i40e_pf *pf ) 
{ 
  u32 reset_flags ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;

  {
  reset_flags = 0U;
  rtnl_lock();
  tmp = constant_test_bit(11L, (unsigned long const volatile   *)(& pf->state));
  if (tmp != 0) {
    reset_flags = reset_flags | 2048U;
    clear_bit(11L, (unsigned long volatile   *)(& pf->state));
  } else {

  }
  tmp___0 = constant_test_bit(12L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___0 != 0) {
    reset_flags = reset_flags | 4096U;
    clear_bit(12L, (unsigned long volatile   *)(& pf->state));
  } else {

  }
  tmp___1 = constant_test_bit(13L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___1 != 0) {
    reset_flags = reset_flags | 8192U;
    clear_bit(13L, (unsigned long volatile   *)(& pf->state));
  } else {

  }
  tmp___2 = constant_test_bit(14L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___2 != 0) {
    reset_flags = reset_flags | 16384U;
    clear_bit(14L, (unsigned long volatile   *)(& pf->state));
  } else {

  }
  tmp___3 = constant_test_bit(21L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___3 != 0) {
    reset_flags = reset_flags | 2097152U;
    clear_bit(21L, (unsigned long volatile   *)(& pf->state));
  } else {

  }
  tmp___4 = constant_test_bit(10L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___4 != 0) {
    i40e_handle_reset_warning(pf);
    goto unlock;
  } else {

  }
  if (reset_flags != 0U) {
    tmp___5 = constant_test_bit(3L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___5 == 0) {
      tmp___6 = constant_test_bit(1L, (unsigned long const volatile   *)(& pf->state));
      if (tmp___6 == 0) {
        i40e_do_reset(pf, reset_flags);
      } else {

      }
    } else {

    }
  } else {

  }
  unlock: 
  rtnl_unlock();
  return;
}
}
static void i40e_handle_link_event(struct i40e_pf *pf , struct i40e_arq_event_info *e ) 
{ 
  struct i40e_hw *hw ;
  struct i40e_aqc_get_link_status *status ;

  {
  hw = & pf->hw;
  status = (struct i40e_aqc_get_link_status *)(& e->desc.params.raw);
  hw->phy.link_info_old = hw->phy.link_info;
  i40e_link_event(pf);
  if ((((int )status->link_info & 64) != 0 && (int )((signed char )status->an_info) >= 0) && ((int )status->link_info & 1) == 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "The driver failed to link because an unqualified module was detected.\n");
  } else {

  }
  return;
}
}
static void i40e_clean_adminq_subtask(struct i40e_pf *pf ) 
{ 
  struct i40e_arq_event_info event ;
  struct i40e_hw *hw ;
  u16 pending ;
  u16 i ;
  i40e_status ret ;
  u16 opcode ;
  u32 oldval ;
  u32 val ;
  int tmp ;
  void *tmp___0 ;
  int tmp___1 ;
  struct _ddebug descriptor ;
  long tmp___2 ;
  int tmp___3 ;
  struct _ddebug descriptor___0 ;
  long tmp___4 ;
  u16 tmp___5 ;

  {
  hw = & pf->hw;
  i = 0U;
  tmp = constant_test_bit(23L, (unsigned long const volatile   *)(& pf->state));
  if (tmp != 0) {
    return;
  } else {

  }
  val = readl((void const volatile   *)pf->hw.hw_addr + (unsigned long )pf->hw.aq.arq.len);
  oldval = val;
  if ((val & 268435456U) != 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ARQ VF Error detected\n");
    val = val & 4026531839U;
  } else {

  }
  if ((val & 536870912U) != 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ARQ Overflow Error detected\n");
    val = val & 3758096383U;
  } else {

  }
  if ((val & 1073741824U) != 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ARQ Critical Error detected\n");
    val = val & 3221225471U;
  } else {

  }
  if (oldval != val) {
    writel(val, (void volatile   *)pf->hw.hw_addr + (unsigned long )pf->hw.aq.arq.len);
  } else {

  }
  val = readl((void const volatile   *)pf->hw.hw_addr + (unsigned long )pf->hw.aq.asq.len);
  oldval = val;
  if ((val & 268435456U) != 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ASQ VF Error detected\n");
    val = val & 4026531839U;
  } else {

  }
  if ((val & 536870912U) != 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ASQ Overflow Error detected\n");
    val = val & 3758096383U;
  } else {

  }
  if ((val & 1073741824U) != 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ASQ Critical Error detected\n");
    val = val & 3221225471U;
  } else {

  }
  if (oldval != val) {
    writel(val, (void volatile   *)pf->hw.hw_addr + (unsigned long )pf->hw.aq.asq.len);
  } else {

  }
  event.buf_len = 4096U;
  tmp___0 = kzalloc((size_t )event.buf_len, 208U);
  event.msg_buf = (u8 *)tmp___0;
  if ((unsigned long )event.msg_buf == (unsigned long )((u8 *)0U)) {
    return;
  } else {

  }
  ldv_62901: 
  ret = i40e_clean_arq_element(hw, & event, & pending);
  if ((int )ret == -57) {
    goto ldv_62888;
  } else
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ARQ event error %d\n",
              (int )ret);
    goto ldv_62888;
  } else {

  }
  opcode = event.desc.opcode;
  switch ((int )opcode) {
  case 1543: 
  i40e_handle_link_event(pf, & event);
  goto ldv_62890;
  case 2049: 
  tmp___1 = i40e_vc_process_vf_msg(pf, (int )event.desc.retval, event.desc.cookie_high,
                                   event.desc.cookie_low, event.msg_buf, (int )event.msg_len);
  ret = (i40e_status )tmp___1;
  goto ldv_62890;
  case 2561: 
  descriptor.modname = "i40e";
  descriptor.function = "i40e_clean_adminq_subtask";
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
  descriptor.format = "ARQ: Update LLDP MIB event received\n";
  descriptor.lineno = 5915U;
  descriptor.flags = 0U;
  tmp___2 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
  if (tmp___2 != 0L) {
    __dynamic_dev_dbg(& descriptor, (struct device  const  *)(& (pf->pdev)->dev),
                      "ARQ: Update LLDP MIB event received\n");
  } else {

  }
  rtnl_lock();
  tmp___3 = i40e_handle_lldp_event(pf, & event);
  ret = (i40e_status )tmp___3;
  rtnl_unlock();
  goto ldv_62890;
  case 4097: 
  descriptor___0.modname = "i40e";
  descriptor___0.function = "i40e_clean_adminq_subtask";
  descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
  descriptor___0.format = "ARQ LAN queue overflow event received\n";
  descriptor___0.lineno = 5923U;
  descriptor___0.flags = 0U;
  tmp___4 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
  if (tmp___4 != 0L) {
    __dynamic_dev_dbg(& descriptor___0, (struct device  const  *)(& (pf->pdev)->dev),
                      "ARQ LAN queue overflow event received\n");
  } else {

  }
  i40e_handle_lan_overflow_event(pf, & event);
  goto ldv_62890;
  case 2051: 
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ARQ: Msg from other pf\n");
  goto ldv_62890;
  case 1794: ;
  case 1795: ;
  if ((pf->hw.debug_mask & 128U) != 0U) {
    printk("\016i40e %02x.%x ARQ NVM operation completed\n", (int )pf->hw.bus.device,
           (int )pf->hw.bus.func);
  } else {

  }
  goto ldv_62890;
  default: 
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ARQ Error: Unknown event 0x%04x received\n",
            (int )opcode);
  goto ldv_62890;
  }
  ldv_62890: ;
  if ((unsigned int )pending != 0U) {
    tmp___5 = i;
    i = (u16 )((int )i + 1);
    if ((int )tmp___5 < (int )pf->adminq_work_limit) {
      goto ldv_62901;
    } else {
      goto ldv_62888;
    }
  } else {

  }
  ldv_62888: 
  clear_bit(6L, (unsigned long volatile   *)(& pf->state));
  val = readl((void const volatile   *)hw->hw_addr + 231424U);
  val = val | 1073741824U;
  writel(val, (void volatile   *)hw->hw_addr + 231424U);
  readl((void const volatile   *)hw->hw_addr + 745772U);
  kfree((void const   *)event.msg_buf);
  return;
}
}
static void i40e_verify_eeprom(struct i40e_pf *pf ) 
{ 
  int err ;
  i40e_status tmp ;
  i40e_status tmp___0 ;
  int tmp___1 ;

  {
  tmp = i40e_diag_eeprom_test(& pf->hw);
  err = (int )tmp;
  if (err != 0) {
    tmp___0 = i40e_diag_eeprom_test(& pf->hw);
    err = (int )tmp___0;
    if (err != 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "eeprom check failed (%d), Tx/Rx traffic disabled\n",
                err);
      set_bit(20L, (unsigned long volatile   *)(& pf->state));
    } else {

    }
  } else {

  }
  if (err == 0) {
    tmp___1 = constant_test_bit(20L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___1 != 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "eeprom check passed, Tx/Rx traffic enabled\n");
      clear_bit(20L, (unsigned long volatile   *)(& pf->state));
    } else {

    }
  } else {

  }
  return;
}
}
static void i40e_enable_pf_switch_lb(struct i40e_pf *pf ) 
{ 
  struct i40e_vsi *vsi ;
  struct i40e_vsi_context ctxt ;
  int aq_ret ;
    klee_make_symbolic(&aq_ret, sizeof(int), "aq_ret");
  i40e_status tmp ;
  i40e_status tmp___0 ;

  {
  vsi = *(pf->vsi + (unsigned long )pf->lan_vsi);
  ctxt.seid = pf->main_vsi_seid;
  ctxt.pf_num = pf->hw.pf_id;
  ctxt.vf_num = 0U;
  tmp = i40e_aq_get_vsi_params(& pf->hw, & ctxt, (struct i40e_asq_cmd_details *)0);
  aq_ret = (int )tmp;
  if (aq_ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%s couldn\'t get PF vsi config, err %d, aq_err %d\n",
              "i40e_enable_pf_switch_lb", aq_ret, (unsigned int )pf->hw.aq.asq_last_status);
    return;
  } else {

  }
  ctxt.flags = 2U;
  ctxt.info.valid_sections = 1U;
  ctxt.info.switch_id = (__le16 )((unsigned int )ctxt.info.switch_id | 8192U);
  tmp___0 = i40e_aq_update_vsi_params(& (vsi->back)->hw, & ctxt, (struct i40e_asq_cmd_details *)0);
  aq_ret = (int )tmp___0;
  if (aq_ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%s: update vsi switch failed, aq_err=%d\n",
              "i40e_enable_pf_switch_lb", (unsigned int )(vsi->back)->hw.aq.asq_last_status);
  } else {

  }
  return;
}
}
static void i40e_disable_pf_switch_lb(struct i40e_pf *pf ) 
{ 
  struct i40e_vsi *vsi ;
  struct i40e_vsi_context ctxt ;
  int aq_ret ;
  i40e_status tmp ;
  i40e_status tmp___0 ;

  {
  vsi = *(pf->vsi + (unsigned long )pf->lan_vsi);
  ctxt.seid = pf->main_vsi_seid;
  ctxt.pf_num = pf->hw.pf_id;
  ctxt.vf_num = 0U;
  tmp = i40e_aq_get_vsi_params(& pf->hw, & ctxt, (struct i40e_asq_cmd_details *)0);
  aq_ret = (int )tmp;
  if (aq_ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%s couldn\'t get PF vsi config, err %d, aq_err %d\n",
              "i40e_disable_pf_switch_lb", aq_ret, (unsigned int )pf->hw.aq.asq_last_status);
    return;
  } else {

  }
  ctxt.flags = 2U;
  ctxt.info.valid_sections = 1U;
  ctxt.info.switch_id = (unsigned int )ctxt.info.switch_id & 57343U;
  tmp___0 = i40e_aq_update_vsi_params(& (vsi->back)->hw, & ctxt, (struct i40e_asq_cmd_details *)0);
  aq_ret = (int )tmp___0;
  if (aq_ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%s: update vsi switch failed, aq_err=%d\n",
              "i40e_disable_pf_switch_lb", (unsigned int )(vsi->back)->hw.aq.asq_last_status);
  } else {

  }
  return;
}
}
static void i40e_config_bridge_mode(struct i40e_veb *veb ) 
{ 
  struct i40e_pf *pf ;

  {
  pf = veb->pf;
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "enabling bridge mode: %s\n",
            (unsigned int )veb->bridge_mode == 1U ? (char *)"VEPA" : (char *)"VEB");
  if ((int )veb->bridge_mode & 1) {
    i40e_disable_pf_switch_lb(pf);
  } else {
    i40e_enable_pf_switch_lb(pf);
  }
  return;
}
}
static int i40e_reconstitute_veb(struct i40e_veb *veb ) 
{ 
  struct i40e_vsi *ctl_vsi ;
  struct i40e_pf *pf ;
  int v ;
  int veb_idx ;
    klee_make_symbolic(&veb_idx, sizeof(int), "veb_idx");
  int ret ;
  struct i40e_vsi *vsi ;

  {
  ctl_vsi = (struct i40e_vsi *)0;
  pf = veb->pf;
  v = 0;
  goto ldv_62934;
  ldv_62933: ;
  if (((unsigned long )*(pf->vsi + (unsigned long )v) != (unsigned long )((struct i40e_vsi *)0) && (int )(*(pf->vsi + (unsigned long )v))->veb_idx == (int )veb->idx) && ((*(pf->vsi + (unsigned long )v))->flags & 2UL) != 0UL) {
    ctl_vsi = *(pf->vsi + (unsigned long )v);
    goto ldv_62932;
  } else {

  }
  v = v + 1;
  ldv_62934: ;
  if ((int )pf->num_alloc_vsi > v && (unsigned long )ctl_vsi == (unsigned long )((struct i40e_vsi *)0)) {
    goto ldv_62933;
  } else {

  }
  ldv_62932: ;
  if ((unsigned long )ctl_vsi == (unsigned long )((struct i40e_vsi *)0)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "missing owner VSI for veb_idx %d\n",
              (int )veb->idx);
    ret = -2;
    goto end_reconstitute;
  } else {

  }
  if ((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) != (unsigned long )ctl_vsi) {
    ctl_vsi->uplink_seid = (*(pf->vsi + (unsigned long )pf->lan_vsi))->uplink_seid;
  } else {

  }
  ret = i40e_add_vsi(ctl_vsi);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "rebuild of owner VSI failed: %d\n",
              ret);
    goto end_reconstitute;
  } else {

  }
  i40e_vsi_reset_stats(ctl_vsi);
  ret = i40e_add_veb(veb, ctl_vsi);
  if (ret != 0) {
    goto end_reconstitute;
  } else {

  }
  if ((pf->flags & 1099511627776ULL) != 0ULL) {
    veb->bridge_mode = 0U;
  } else {
    veb->bridge_mode = 1U;
  }
  i40e_config_bridge_mode(veb);
  v = 0;
  goto ldv_62939;
  ldv_62938: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )v) == (unsigned long )((struct i40e_vsi *)0) || (unsigned long )*(pf->vsi + (unsigned long )v) == (unsigned long )ctl_vsi) {
    goto ldv_62936;
  } else {

  }
  if ((int )(*(pf->vsi + (unsigned long )v))->veb_idx == (int )veb->idx) {
    vsi = *(pf->vsi + (unsigned long )v);
    vsi->uplink_seid = veb->seid;
    ret = i40e_add_vsi(vsi);
    if (ret != 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "rebuild of vsi_idx %d failed: %d\n",
                v, ret);
      goto end_reconstitute;
    } else {

    }
    i40e_vsi_reset_stats(vsi);
  } else {

  }
  ldv_62936: 
  v = v + 1;
  ldv_62939: ;
  if ((int )pf->num_alloc_vsi > v) {
    goto ldv_62938;
  } else {

  }
  veb_idx = 0;
  goto ldv_62943;
  ldv_62942: ;
  if ((unsigned long )pf->veb[veb_idx] != (unsigned long )((struct i40e_veb *)0) && (int )(pf->veb[veb_idx])->veb_idx == (int )veb->idx) {
    (pf->veb[veb_idx])->uplink_seid = veb->seid;
    ret = i40e_reconstitute_veb(pf->veb[veb_idx]);
    if (ret != 0) {
      goto ldv_62941;
    } else {

    }
  } else {

  }
  veb_idx = veb_idx + 1;
  ldv_62943: ;
  if (veb_idx <= 15) {
    goto ldv_62942;
  } else {

  }
  ldv_62941: ;
  end_reconstitute: ;
  return (ret);
}
}
static int i40e_get_capabilities(struct i40e_pf *pf ) 
{ 
  struct i40e_aqc_list_capabilities_element_resp *cap_buf ;
  u16 data_size ;
  int buf_len ;
    klee_make_symbolic(&buf_len, sizeof(int), "buf_len");
  int err ;
  void *tmp ;
  i40e_status tmp___0 ;

  {
  buf_len = 1280;
  ldv_62951: 
  tmp = kzalloc((size_t )buf_len, 208U);
  cap_buf = (struct i40e_aqc_list_capabilities_element_resp *)tmp;
  if ((unsigned long )cap_buf == (unsigned long )((struct i40e_aqc_list_capabilities_element_resp *)0)) {
    return (-12);
  } else {

  }
  tmp___0 = i40e_aq_discover_capabilities(& pf->hw, (void *)cap_buf, (int )((u16 )buf_len),
                                          & data_size, 10, (struct i40e_asq_cmd_details *)0);
  err = (int )tmp___0;
  kfree((void const   *)cap_buf);
  if ((unsigned int )pf->hw.aq.asq_last_status == 9U) {
    buf_len = (int )data_size;
  } else
  if ((unsigned int )pf->hw.aq.asq_last_status != 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "capability discovery failed: aq=%d\n",
              (unsigned int )pf->hw.aq.asq_last_status);
    return (-19);
  } else {

  }
  if (err != 0) {
    goto ldv_62951;
  } else {

  }

  if (((unsigned int )pf->hw.aq.fw_maj_ver == 2U && (unsigned int )pf->hw.aq.fw_min_ver <= 21U) || (unsigned int )pf->hw.aq.fw_maj_ver <= 1U) {
    pf->hw.func_caps.num_msix_vectors = pf->hw.func_caps.num_msix_vectors + 1U;
    pf->hw.func_caps.num_msix_vectors_vf = pf->hw.func_caps.num_msix_vectors_vf + 1U;
  } else {

  }
  if ((pf->hw.debug_mask & 4026531840U) != 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "pf=%d, num_vfs=%d, msix_pf=%d, msix_vf=%d, fd_g=%d, fd_b=%d, pf_max_q=%d num_vsi=%d\n",
              (int )pf->hw.pf_id, pf->hw.func_caps.num_vfs, pf->hw.func_caps.num_msix_vectors,
              pf->hw.func_caps.num_msix_vectors_vf, pf->hw.func_caps.fd_filters_guaranteed,
              pf->hw.func_caps.fd_filters_best_effort, pf->hw.func_caps.num_tx_qp,
              pf->hw.func_caps.num_vsis);
  } else {

  }
  if ((unsigned int )pf->hw.revision_id == 0U && ((u32 )pf->hw.func_caps.fcoe + pf->hw.func_caps.num_vfs) + 1U > pf->hw.func_caps.num_vsis) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "got num_vsis %d, setting num_vsis to %d\n",
              pf->hw.func_caps.num_vsis, ((u32 )pf->hw.func_caps.fcoe + pf->hw.func_caps.num_vfs) + 1U);
    pf->hw.func_caps.num_vsis = ((u32 )pf->hw.func_caps.fcoe + pf->hw.func_caps.num_vfs) + 1U;
  } else {

  }
  return (0);
}
}
static int i40e_vsi_clear(struct i40e_vsi *vsi ) ;
static void i40e_fdir_sb_setup(struct i40e_pf *pf ) 
{ 
  struct i40e_vsi *vsi ;
  int i ;
  u32 hkey[13U] ;
  unsigned int tmp ;

  {
  tmp = readl((void const volatile   *)pf->hw.hw_addr + 2556224U);
  if (tmp == 0U) {
    hkey[0] = 3863008063U;
    hkey[1] = 3456014507U;
    hkey[2] = 1945792865U;
    hkey[3] = 226131254U;
    hkey[4] = 3939204449U;
    hkey[5] = 2857305526U;
    hkey[6] = 2623310317U;
    hkey[7] = 4232207835U;
    hkey[8] = 2758101042U;
    hkey[9] = 4235485652U;
    hkey[10] = 2407691801U;
    hkey[11] = 4123409441U;
    hkey[12] = 2511578989U;
    i = 0;
    goto ldv_62962;
    ldv_62961: 
    writel(hkey[i], (void volatile   *)pf->hw.hw_addr + (unsigned long )((i + 639056) * 4));
    i = i + 1;
    ldv_62962: ;
    if (i <= 12) {
      goto ldv_62961;
    } else {

    }

  } else {

  }
  if ((pf->flags & 2097152ULL) == 0ULL) {
    return;
  } else {

  }
  vsi = (struct i40e_vsi *)0;
  i = 0;
  goto ldv_62966;
  ldv_62965: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0) && (unsigned int )(*(pf->vsi + (unsigned long )i))->type == 7U) {
    vsi = *(pf->vsi + (unsigned long )i);
    goto ldv_62964;
  } else {

  }
  i = i + 1;
  ldv_62966: ;
  if ((int )pf->num_alloc_vsi > i) {
    goto ldv_62965;
  } else {

  }
  ldv_62964: ;
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
    vsi = i40e_vsi_setup(pf, 7, (int )(*(pf->vsi + (unsigned long )pf->lan_vsi))->seid,
                         0U);
    if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Couldn\'t create FDir VSI\n");
      pf->flags = pf->flags & 0xffffffffffdfffffULL;
      return;
    } else {

    }
  } else {

  }
  i40e_vsi_setup_irqhandler(vsi, & i40e_fdir_clean_ring);
  return;
}
}
static void i40e_fdir_teardown(struct i40e_pf *pf ) 
{ 
  int i ;

  {
  i40e_fdir_filter_exit(pf);
  i = 0;
  goto ldv_62973;
  ldv_62972: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0) && (unsigned int )(*(pf->vsi + (unsigned long )i))->type == 7U) {
    i40e_vsi_release(*(pf->vsi + (unsigned long )i));
    goto ldv_62971;
  } else {

  }
  i = i + 1;
  ldv_62973: ;
  if ((int )pf->num_alloc_vsi > i) {
    goto ldv_62972;
  } else {

  }
  ldv_62971: ;
  return;
}
}
static void i40e_prep_for_reset(struct i40e_pf *pf ) 
{ 
  struct i40e_hw *hw ;
  i40e_status ret ;
  u32 v ;
  int tmp ;
  struct _ddebug descriptor ;
  long tmp___0 ;

  {
  hw = & pf->hw;
  ret = 0;
  clear_bit(10L, (unsigned long volatile   *)(& pf->state));
  tmp = test_and_set_bit(9L, (unsigned long volatile   *)(& pf->state));
  if (tmp != 0) {
    return;
  } else {

  }
  descriptor.modname = "i40e";
  descriptor.function = "i40e_prep_for_reset";
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
  descriptor.format = "Tearing down internal switch for reset\n";
  descriptor.lineno = 6298U;
  descriptor.flags = 0U;
  tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
  if (tmp___0 != 0L) {
    __dynamic_dev_dbg(& descriptor, (struct device  const  *)(& (pf->pdev)->dev),
                      "Tearing down internal switch for reset\n");
  } else {

  }
  i40e_pf_quiesce_all_vsi(pf);
  v = 0U;
  goto ldv_62983;
  ldv_62982: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )v) != (unsigned long )((struct i40e_vsi *)0)) {
    (*(pf->vsi + (unsigned long )v))->seid = 0U;
  } else {

  }
  v = v + 1U;
  ldv_62983: ;
  if ((u32 )pf->num_alloc_vsi > v) {
    goto ldv_62982;
  } else {

  }
  i40e_shutdown_adminq(& pf->hw);
  if ((unsigned long )hw->hmc.hmc_obj != (unsigned long )((struct i40e_hmc_obj_info *)0)) {
    ret = i40e_shutdown_lan_hmc(hw);
    if ((int )ret != 0) {
      dev_warn((struct device  const  *)(& (pf->pdev)->dev), "shutdown_lan_hmc failed: %d\n",
               (int )ret);
    } else {

    }
  } else {

  }
  return;
}
}
static void i40e_send_version(struct i40e_pf *pf ) 
{ 
  struct i40e_driver_version dv ;

  {
  dv.major_version = 1U;
  dv.minor_version = 3U;
  dv.build_version = 4U;
  dv.subbuild_version = 0U;
  strlcpy((char *)(& dv.driver_string), "1.3.4-k", 32UL);
  i40e_aq_send_driver_version(& pf->hw, & dv, (struct i40e_asq_cmd_details *)0);
  return;
}
}
static void i40e_reset_and_rebuild(struct i40e_pf *pf , bool reinit ) 
{ 
  struct i40e_hw *hw ;
  u8 set_fc_aq_fail ;
  i40e_status ret ;
  u32 v ;
  int tmp ;
  struct _ddebug descriptor ;
  long tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  struct _ddebug descriptor___0 ;
  long tmp___6 ;
  int tmp___7 ;
  struct _ddebug descriptor___1 ;
  long tmp___8 ;
  int tmp___9 ;
  int tmp___10 ;
    klee_make_symbolic(&tmp___10, sizeof(int), "tmp___10");

  {
  hw = & pf->hw;
  set_fc_aq_fail = 0U;
  ret = i40e_pf_reset(hw);
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "PF reset failed, %d\n",
              (int )ret);
    set_bit(23L, (unsigned long volatile   *)(& pf->state));
    goto clear_recovery;
  } else {

  }
  pf->pfr_count = (u16 )((int )pf->pfr_count + 1);
  tmp = constant_test_bit(3L, (unsigned long const volatile   *)(& pf->state));
  if (tmp != 0) {
    goto clear_recovery;
  } else {

  }
  descriptor.modname = "i40e";
  descriptor.function = "i40e_reset_and_rebuild";
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
  descriptor.format = "Rebuilding internal switch\n";
  descriptor.lineno = 6361U;
  descriptor.flags = 0U;
  tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
  if (tmp___0 != 0L) {
    __dynamic_dev_dbg(& descriptor, (struct device  const  *)(& (pf->pdev)->dev),
                      "Rebuilding internal switch\n");
  } else {

  }
  ret = i40e_init_adminq(& pf->hw);
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Rebuild AdminQ failed, %d\n",
              (int )ret);
    goto clear_recovery;
  } else {

  }
  tmp___1 = test_and_clear_bit(16L, (unsigned long volatile   *)(& pf->state));
  if (tmp___1 != 0) {
    i40e_verify_eeprom(pf);
  } else {

  }
  i40e_clear_pxe_mode(hw);
  tmp___2 = i40e_get_capabilities(pf);
  ret = (i40e_status )tmp___2;
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "i40e_get_capabilities failed, %d\n",
              (int )ret);
    goto end_core_reset;
  } else {

  }
  ret = i40e_init_lan_hmc(hw, hw->func_caps.num_tx_qp, hw->func_caps.num_rx_qp, pf->fcoe_hmc_cntx_num,
                          pf->fcoe_hmc_filt_num);
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "init_lan_hmc failed: %d\n",
              (int )ret);
    goto end_core_reset;
  } else {

  }
  ret = i40e_configure_lan_hmc(hw, 1);
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "configure_lan_hmc failed: %d\n",
              (int )ret);
    goto end_core_reset;
  } else {

  }
  tmp___3 = i40e_init_pf_dcb(pf);
  ret = (i40e_status )tmp___3;
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "DCB init failed %d, disabled\n",
              (int )ret);
    pf->flags = pf->flags & 0xffffffffdfffffffULL;
  } else {

  }
  tmp___4 = i40e_init_pf_fcoe(pf);
  ret = (i40e_status )tmp___4;
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "init_pf_fcoe failed: %d\n",
              (int )ret);
  } else {

  }
  tmp___5 = i40e_setup_pf_switch(pf, (int )reinit);
  ret = (i40e_status )tmp___5;
  if ((int )ret != 0) {
    goto end_core_reset;
  } else {

  }
  ret = i40e_aq_set_phy_int_mask(& pf->hw, 258, (struct i40e_asq_cmd_details *)0);
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "set phy mask fail, aq_err %d\n",
              (int )ret);
  } else {

  }
  ret = i40e_set_fc(& pf->hw, & set_fc_aq_fail, 1);
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "set fc fail, aq_err %d\n",
              (int )ret);
  } else {

  }
  if ((int )(*(pf->vsi + (unsigned long )pf->lan_vsi))->uplink_seid != (int )pf->mac_seid) {
    descriptor___0.modname = "i40e";
    descriptor___0.function = "i40e_reset_and_rebuild";
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
    descriptor___0.format = "attempting to rebuild switch\n";
    descriptor___0.lineno = 6436U;
    descriptor___0.flags = 0U;
    tmp___6 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
    if (tmp___6 != 0L) {
      __dynamic_dev_dbg(& descriptor___0, (struct device  const  *)(& (pf->pdev)->dev),
                        "attempting to rebuild switch\n");
    } else {

    }
    v = 0U;
    goto ldv_63005;
    ldv_63004: ;
    if ((unsigned long )pf->veb[v] == (unsigned long )((struct i40e_veb *)0)) {
      goto ldv_63002;
    } else {

    }
    if ((int )(pf->veb[v])->uplink_seid == (int )pf->mac_seid || (unsigned int )(pf->veb[v])->uplink_seid == 0U) {
      tmp___7 = i40e_reconstitute_veb(pf->veb[v]);
      ret = (i40e_status )tmp___7;
      if ((int )ret == 0) {
        goto ldv_63002;
      } else {

      }
      if ((int )(pf->veb[v])->uplink_seid == (int )pf->mac_seid) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "rebuild of switch failed: %d, will try to set up simple PF connection\n",
                  (int )ret);
        (*(pf->vsi + (unsigned long )pf->lan_vsi))->uplink_seid = pf->mac_seid;
        goto ldv_63003;
      } else
      if ((unsigned int )(pf->veb[v])->uplink_seid == 0U) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "rebuild of orphan VEB failed: %d\n",
                  (int )ret);
      } else {

      }
    } else {

    }
    ldv_63002: 
    v = v + 1U;
    ldv_63005: ;
    if (v <= 15U) {
      goto ldv_63004;
    } else {

    }
    ldv_63003: ;
  } else {

  }
  if ((int )(*(pf->vsi + (unsigned long )pf->lan_vsi))->uplink_seid == (int )pf->mac_seid) {
    descriptor___1.modname = "i40e";
    descriptor___1.function = "i40e_reset_and_rebuild";
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c";
    descriptor___1.format = "attempting to rebuild PF VSI\n";
    descriptor___1.lineno = 6472U;
    descriptor___1.flags = 0U;
    tmp___8 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
    if (tmp___8 != 0L) {
      __dynamic_dev_dbg(& descriptor___1, (struct device  const  *)(& (pf->pdev)->dev),
                        "attempting to rebuild PF VSI\n");
    } else {

    }
    tmp___9 = i40e_add_vsi(*(pf->vsi + (unsigned long )pf->lan_vsi));
    ret = (i40e_status )tmp___9;
    if ((int )ret != 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "rebuild of Main VSI failed: %d\n",
                (int )ret);
      goto end_core_reset;
    } else {

    }
  } else {

  }
  if (((unsigned int )pf->hw.aq.fw_maj_ver == 4U && (unsigned int )pf->hw.aq.fw_min_ver <= 32U) || (unsigned int )pf->hw.aq.fw_maj_ver <= 3U) {
    msleep(75U);
    ret = i40e_aq_set_link_restart_an(& pf->hw, 1, (struct i40e_asq_cmd_details *)0);
    if ((int )ret != 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "link restart failed, aq_err=%d\n",
                (unsigned int )pf->hw.aq.asq_last_status);
    } else {

    }
  } else {

  }
  if ((pf->flags & 8ULL) != 0ULL) {
    tmp___10 = i40e_setup_misc_vector(pf);
    ret = (i40e_status )tmp___10;
  } else {

  }
  i40e_pf_unquiesce_all_vsi(pf);
  if (pf->num_alloc_vfs != 0) {
    v = 0U;
    goto ldv_63008;
    ldv_63007: 
    i40e_reset_vf(pf->vf + (unsigned long )v, 1);
    v = v + 1U;
    ldv_63008: ;
    if ((u32 )pf->num_alloc_vfs > v) {
      goto ldv_63007;
    } else {

    }

  } else {

  }
  i40e_send_version(pf);
  end_core_reset: 
  clear_bit(23L, (unsigned long volatile   *)(& pf->state));
  clear_recovery: 
  clear_bit(9L, (unsigned long volatile   *)(& pf->state));
  return;
}
}
static void i40e_handle_reset_warning(struct i40e_pf *pf ) 
{ 


  {
  i40e_prep_for_reset(pf);
  i40e_reset_and_rebuild(pf, 0);
  return;
}
}
static void i40e_handle_mdd_event(struct i40e_pf *pf ) 
{ 
  struct i40e_hw *hw ;
  bool mdd_detected ;
  bool pf_mdd_detected ;
  struct i40e_vf *vf ;
  u32 reg ;
  int i ;
  int tmp ;
  u8 pf_num ;
  u16 vf_num ;
  u8 event ;
  u16 queue ;
  u8 func ;
  u8 event___0 ;
  u16 queue___0 ;

  {
  hw = & pf->hw;
  mdd_detected = 0;
  pf_mdd_detected = 0;
  tmp = constant_test_bit(7L, (unsigned long const volatile   *)(& pf->state));
  if (tmp == 0) {
    return;
  } else {

  }
  reg = readl((void const volatile   *)hw->hw_addr + 943232U);
  if ((int )reg < 0) {
    pf_num = (u8 )((reg & 31457280U) >> 21);
    vf_num = (u16 )((reg & 2093056U) >> 12);
    event = (u8 )((reg & 1040187392U) >> 25);
    queue = ((unsigned int )((u16 )reg) & 4095U) - (unsigned int )((u16 )pf->hw.func_caps.base_queue);
    if ((pf->msg_enable & 128U) != 0U) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Malicious Driver Detection event 0x%02x on TX queue %d PF number 0x%02x VF number 0x%02x\n",
                (int )event, (int )queue, (int )pf_num, (int )vf_num);
    } else {

    }
    writel(4294967295U, (void volatile   *)hw->hw_addr + 943232U);
    mdd_detected = 1;
  } else {

  }
  reg = readl((void const volatile   *)hw->hw_addr + 1221904U);
  if ((int )reg < 0) {
    func = (u8 )reg;
    event___0 = (u8 )((reg & 130816U) >> 8);
    queue___0 = (int )((u16 )((reg & 2147352576U) >> 17)) - (int )((u16 )pf->hw.func_caps.base_queue);
    if ((pf->msg_enable & 64U) != 0U) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Malicious Driver Detection event 0x%02x on RX queue %d of function 0x%02x\n",
                (int )event___0, (int )queue___0, (int )func);
    } else {

    }
    writel(4294967295U, (void volatile   *)hw->hw_addr + 1221904U);
    mdd_detected = 1;
  } else {

  }
  if ((int )mdd_detected) {
    reg = readl((void const volatile   *)hw->hw_addr + 943104U);
    if ((int )reg & 1) {
      writel(65535U, (void volatile   *)hw->hw_addr + 943104U);
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "TX driver issue detected, PF reset issued\n");
      pf_mdd_detected = 1;
    } else {

    }
    reg = readl((void const volatile   *)hw->hw_addr + 1221632U);
    if ((int )reg & 1) {
      writel(65535U, (void volatile   *)hw->hw_addr + 1221632U);
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "RX driver issue detected, PF reset issued\n");
      pf_mdd_detected = 1;
    } else {

    }
    if ((int )pf_mdd_detected) {
      set_bit(12L, (unsigned long volatile   *)(& pf->state));
      i40e_service_event_schedule(pf);
    } else {

    }
  } else {

  }
  i = 0;
  goto ldv_63030;
  ldv_63029: 
  vf = pf->vf + (unsigned long )i;
  reg = readl((void const volatile   *)hw->hw_addr + (unsigned long )((i + 235520) * 4));
  if ((int )reg & 1) {
    writel(65535U, (void volatile   *)hw->hw_addr + (unsigned long )((i + 235520) * 4));
    vf->num_mdd_events = vf->num_mdd_events + 1ULL;
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "TX driver issue detected on VF %d\n",
              i);
  } else {

  }
  reg = readl((void const volatile   *)hw->hw_addr + (unsigned long )((i + 305152) * 4));
  if ((int )reg & 1) {
    writel(65535U, (void volatile   *)hw->hw_addr + (unsigned long )((i + 305152) * 4));
    vf->num_mdd_events = vf->num_mdd_events + 1ULL;
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "RX driver issue detected on VF %d\n",
              i);
  } else {

  }
  if (vf->num_mdd_events > 3ULL) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Too many MDD events on VF %d, disabled\n",
              i);
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Use PF Control I/F to re-enable the VF\n");
    set_bit(3L, (unsigned long volatile   *)(& vf->vf_states));
  } else {

  }
  i = i + 1;
  ldv_63030: ;
  if (pf->num_alloc_vfs > i && (int )mdd_detected) {
    goto ldv_63029;
  } else {

  }
  clear_bit(7L, (unsigned long volatile   *)(& pf->state));
  reg = readl((void const volatile   *)hw->hw_addr + 231424U);
  reg = reg | 524288U;
  writel(reg, (void volatile   *)hw->hw_addr + 231424U);
  readl((void const volatile   *)hw->hw_addr + 745772U);
  return;
}
}
static void i40e_sync_vxlan_filters_subtask(struct i40e_pf *pf ) 
{ 
  struct i40e_hw *hw ;
  i40e_status ret ;
  __be16 port ;
  int i ;
  __u16 tmp ;
  __u16 tmp___0 ;

  {
  hw = & pf->hw;
  if ((pf->flags & 134217728ULL) == 0ULL) {
    return;
  } else {

  }
  pf->flags = pf->flags & 0xfffffffff7ffffffULL;
  i = 0;
  goto ldv_63040;
  ldv_63039: ;
  if (((int )pf->pending_vxlan_bitmap >> i) & 1) {
    pf->pending_vxlan_bitmap = (u16 )((int )((short )pf->pending_vxlan_bitmap) & ~ ((int )((short )(1 << i))));
    port = pf->vxlan_ports[i];
    if ((unsigned int )port != 0U) {
      tmp = __fswab16((int )port);
      ret = i40e_aq_add_udp_tunnel(hw, (int )tmp, 0, (u8 *)0U, (struct i40e_asq_cmd_details *)0);
    } else {
      ret = i40e_aq_del_udp_tunnel(hw, (int )((u8 )i), (struct i40e_asq_cmd_details *)0);
    }
    if ((int )ret != 0) {
      tmp___0 = __fswab16((int )port);
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%s vxlan port %d, index %d failed, err %d, aq_err %d\n",
                (unsigned int )port != 0U ? (char *)"add" : (char *)"delete", (int )tmp___0,
                i, (int )ret, (unsigned int )pf->hw.aq.asq_last_status);
      pf->vxlan_ports[i] = 0U;
    } else {

    }
  } else {

  }
  i = i + 1;
  ldv_63040: ;
  if (i <= 15) {
    goto ldv_63039;
  } else {

  }

  return;
}
}
static void i40e_service_task(struct work_struct *work ) 
{ 
  struct i40e_pf *pf ;
  struct work_struct  const  *__mptr ;
  unsigned long start_time ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
  __mptr = (struct work_struct  const  *)work;
  pf = (struct i40e_pf *)__mptr + 0xfffffffffffff880UL;
  start_time = jiffies;
  tmp = constant_test_bit(9L, (unsigned long const volatile   *)(& pf->state));
  if (tmp != 0) {
    i40e_service_event_complete(pf);
    return;
  } else {

  }
  i40e_reset_subtask(pf);
  i40e_handle_mdd_event(pf);
  i40e_vc_process_vflr_event(pf);
  i40e_watchdog_subtask(pf);
  i40e_fdir_reinit_subtask(pf);
  i40e_sync_filters_subtask(pf);
  i40e_sync_vxlan_filters_subtask(pf);
  i40e_clean_adminq_subtask(pf);
  i40e_service_event_complete(pf);
  if ((long )((pf->service_timer_period + start_time) - (unsigned long )jiffies) < 0L) {
    i40e_service_event_schedule(pf);
  } else {
    tmp___0 = constant_test_bit(6L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___0 != 0) {
      i40e_service_event_schedule(pf);
    } else {
      tmp___1 = constant_test_bit(7L, (unsigned long const volatile   *)(& pf->state));
      if (tmp___1 != 0) {
        i40e_service_event_schedule(pf);
      } else {
        tmp___2 = constant_test_bit(8L, (unsigned long const volatile   *)(& pf->state));
        if (tmp___2 != 0) {
          i40e_service_event_schedule(pf);
        } else {

        }
      }
    }
  }
  return;
}
}
static void i40e_service_timer(unsigned long data ) 
{ 
  struct i40e_pf *pf ;
  unsigned long tmp ;

  {
  pf = (struct i40e_pf *)data;
  tmp = round_jiffies(pf->service_timer_period + (unsigned long )jiffies);
  ldv_mod_timer_24(& pf->service_timer, tmp);
  i40e_service_event_schedule(pf);
  return;
}
}
static int i40e_set_num_rings_in_vsi(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  int __ret_warn_on ;
  long tmp ;

  {
  pf = vsi->back;
  switch ((unsigned int )vsi->type) {
  case 0U: 
  vsi->alloc_queue_pairs = pf->num_lan_qps;
  vsi->num_desc = 512U;
  if ((pf->flags & 8ULL) != 0ULL) {
    vsi->num_q_vectors = (int )pf->num_lan_msix;
  } else {
    vsi->num_q_vectors = 1;
  }
  goto ldv_63064;
  case 7U: 
  vsi->alloc_queue_pairs = 1U;
  vsi->num_desc = 32U;
  vsi->num_q_vectors = 1;
  goto ldv_63064;
  case 2U: 
  vsi->alloc_queue_pairs = pf->num_vmdq_qps;
  vsi->num_desc = 512U;
  vsi->num_q_vectors = (int )pf->num_vmdq_msix;
  goto ldv_63064;
  case 6U: 
  vsi->alloc_queue_pairs = pf->num_vf_qps;
  vsi->num_desc = 512U;
  goto ldv_63064;
  case 4U: 
  vsi->alloc_queue_pairs = pf->num_fcoe_qps;
  vsi->num_desc = 512U;
  vsi->num_q_vectors = (int )pf->num_fcoe_msix;
  goto ldv_63064;
  default: 
  __ret_warn_on = 1;
  tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c",
                       6777);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  return (-61);
  }
  ldv_63064: ;
  return (0);
}
}
static int i40e_vsi_alloc_arrays(struct i40e_vsi *vsi , bool alloc_qvectors ) 
{ 
  int size ;
  int ret ;
  void *tmp ;
  void *tmp___0 ;

  {
  ret = 0;
  size = (int )((unsigned int )vsi->alloc_queue_pairs * 16U);
  tmp = kzalloc((size_t )size, 208U);
  vsi->tx_rings = (struct i40e_ring **)tmp;
  if ((unsigned long )vsi->tx_rings == (unsigned long )((struct i40e_ring **)0)) {
    return (-12);
  } else {

  }
  vsi->rx_rings = vsi->tx_rings + (unsigned long )vsi->alloc_queue_pairs;
  if ((int )alloc_qvectors) {
    size = (int )((unsigned int )vsi->num_q_vectors * 8U);
    tmp___0 = kzalloc((size_t )size, 208U);
    vsi->q_vectors = (struct i40e_q_vector **)tmp___0;
    if ((unsigned long )vsi->q_vectors == (unsigned long )((struct i40e_q_vector **)0)) {
      ret = -12;
      goto err_vectors;
    } else {

    }
  } else {

  }
  return (ret);
  err_vectors: 
  kfree((void const   *)vsi->tx_rings);
  return (ret);
}
}
static int i40e_vsi_mem_alloc(struct i40e_pf *pf , enum i40e_vsi_type type ) 
{ 
  int ret ;
  struct i40e_vsi *vsi ;
  int vsi_idx ;
    klee_make_symbolic(&vsi_idx, sizeof(int), "vsi_idx");
  int i ;
  void *tmp ;

  {
  ret = -19;
  ldv_mutex_lock_25(& pf->switch_mutex);
  i = (int )pf->next_vsi;
  goto ldv_63088;
  ldv_63087: 
  i = i + 1;
  ldv_63088: ;
  if ((int )pf->num_alloc_vsi > i && (unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0)) {
    goto ldv_63087;
  } else {

  }

  if ((int )pf->num_alloc_vsi <= i) {
    i = 0;
    goto ldv_63091;
    ldv_63090: 
    i = i + 1;
    ldv_63091: ;
    if ((int )pf->next_vsi > i && (unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0)) {
      goto ldv_63090;
    } else {

    }

  } else {

  }
  if ((int )pf->num_alloc_vsi > i && (unsigned long )*(pf->vsi + (unsigned long )i) == (unsigned long )((struct i40e_vsi *)0)) {
    vsi_idx = i;
  } else {
    ret = -19;
    goto unlock_pf;
  }
  i = i + 1;
  pf->next_vsi = (u16 )i;
  tmp = kzalloc(4096UL, 208U);
  vsi = (struct i40e_vsi *)tmp;
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
    ret = -12;
    goto unlock_pf;
  } else {

  }
  vsi->type = type;
  vsi->back = pf;
  set_bit(3L, (unsigned long volatile   *)(& vsi->state));
  vsi->flags = 0UL;
  vsi->idx = (u16 )vsi_idx;
  vsi->rx_itr_setting = pf->rx_itr_default;
  vsi->tx_itr_setting = pf->tx_itr_default;
  vsi->rss_table_size = (unsigned int )vsi->type == 0U ? pf->rss_table_size : 64U;
  vsi->netdev_registered = 0;
  vsi->work_limit = 256U;
  INIT_LIST_HEAD(& vsi->mac_filter_list);
  vsi->irqs_ready = 0;
  ret = i40e_set_num_rings_in_vsi(vsi);
  if (ret != 0) {
    goto err_rings;
  } else {

  }
  ret = i40e_vsi_alloc_arrays(vsi, 1);
  if (ret != 0) {
    goto err_rings;
  } else {

  }
  i40e_vsi_setup_irqhandler(vsi, & i40e_msix_clean_rings);
  *(pf->vsi + (unsigned long )vsi_idx) = vsi;
  ret = vsi_idx;
  goto unlock_pf;
  err_rings: 
  pf->next_vsi = (unsigned int )((u16 )i) + 65535U;
  kfree((void const   *)vsi);
  unlock_pf: 
  ldv_mutex_unlock_26(& pf->switch_mutex);
  return (ret);
}
}
static void i40e_vsi_free_arrays(struct i40e_vsi *vsi , bool free_qvectors ) 
{ 


  {
  if ((int )free_qvectors) {
    kfree((void const   *)vsi->q_vectors);
    vsi->q_vectors = (struct i40e_q_vector **)0;
  } else {

  }
  kfree((void const   *)vsi->tx_rings);
  vsi->tx_rings = (struct i40e_ring **)0;
  vsi->rx_rings = (struct i40e_ring **)0;
  return;
}
}
static int i40e_vsi_clear(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;

  {
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
    return (0);
  } else {

  }
  if ((unsigned long )vsi->back == (unsigned long )((struct i40e_pf *)0)) {
    goto free_vsi;
  } else {

  }
  pf = vsi->back;
  ldv_mutex_lock_27(& pf->switch_mutex);
  if ((unsigned long )*(pf->vsi + (unsigned long )vsi->idx) == (unsigned long )((struct i40e_vsi *)0)) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "pf->vsi[%d] is NULL, just free vsi[%d](%p,type %d)\n",
            (int )vsi->idx, (int )vsi->idx, vsi, (unsigned int )vsi->type);
    goto unlock_vsi;
  } else {

  }
  if ((unsigned long )*(pf->vsi + (unsigned long )vsi->idx) != (unsigned long )vsi) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "pf->vsi[%d](%p, type %d) != vsi[%d](%p,type %d): no free!\n",
            (int )(*(pf->vsi + (unsigned long )vsi->idx))->idx, *(pf->vsi + (unsigned long )vsi->idx),
            (unsigned int )(*(pf->vsi + (unsigned long )vsi->idx))->type, (int )vsi->idx,
            vsi, (unsigned int )vsi->type);
    goto unlock_vsi;
  } else {

  }
  i40e_put_lump(pf->qp_pile, (int )vsi->base_queue, (int )vsi->idx);
  i40e_put_lump(pf->irq_pile, (int )((u16 )vsi->base_vector), (int )vsi->idx);
  i40e_vsi_free_arrays(vsi, 1);
  *(pf->vsi + (unsigned long )vsi->idx) = (struct i40e_vsi *)0;
  if ((int )vsi->idx < (int )pf->next_vsi) {
    pf->next_vsi = vsi->idx;
  } else {

  }
  unlock_vsi: 
  ldv_mutex_unlock_28(& pf->switch_mutex);
  free_vsi: 
  kfree((void const   *)vsi);
  return (0);
}
}
static void i40e_vsi_clear_rings(struct i40e_vsi *vsi ) 
{ 
  int i ;

  {
  if ((unsigned long )vsi->tx_rings != (unsigned long )((struct i40e_ring **)0) && (unsigned long )*(vsi->tx_rings) != (unsigned long )((struct i40e_ring *)0)) {
    i = 0;
    goto ldv_63111;
    ldv_63110: 
    kfree_call_rcu(& (*(vsi->tx_rings + (unsigned long )i))->rcu, (void (*)(struct callback_head * ))168);
    *(vsi->tx_rings + (unsigned long )i) = (struct i40e_ring *)0;
    *(vsi->rx_rings + (unsigned long )i) = (struct i40e_ring *)0;
    i = i + 1;
    ldv_63111: ;
    if ((int )vsi->alloc_queue_pairs > i) {
      goto ldv_63110;
    } else {

    }

  } else {

  }
  return;
}
}
static int i40e_alloc_rings(struct i40e_vsi *vsi ) 
{ 
  struct i40e_ring *tx_ring ;
  struct i40e_ring *rx_ring ;
  struct i40e_pf *pf ;
  int i ;
  void *tmp ;

  {
  pf = vsi->back;
  i = 0;
  goto ldv_63122;
  ldv_63121: 
  tmp = kzalloc(8192UL, 208U);
  tx_ring = (struct i40e_ring *)tmp;
  if ((unsigned long )tx_ring == (unsigned long )((struct i40e_ring *)0)) {
    goto err_out;
  } else {

  }
  tx_ring->queue_index = (u16 )i;
  tx_ring->reg_idx = (int )vsi->base_queue + (int )((u16 )i);
  tx_ring->ring_active = 0;
  tx_ring->vsi = vsi;
  tx_ring->netdev = vsi->netdev;
  tx_ring->dev = & (pf->pdev)->dev;
  tx_ring->count = vsi->num_desc;
  tx_ring->size = 0U;
  tx_ring->dcb_tc = 0U;
  *(vsi->tx_rings + (unsigned long )i) = tx_ring;
  rx_ring = tx_ring + 1UL;
  rx_ring->queue_index = (u16 )i;
  rx_ring->reg_idx = (int )vsi->base_queue + (int )((u16 )i);
  rx_ring->ring_active = 0;
  rx_ring->vsi = vsi;
  rx_ring->netdev = vsi->netdev;
  rx_ring->dev = & (pf->pdev)->dev;
  rx_ring->count = vsi->num_desc;
  rx_ring->size = 0U;
  rx_ring->dcb_tc = 0U;
  if ((pf->flags & 8192ULL) != 0ULL) {
    set_bit(5L, (unsigned long volatile   *)(& rx_ring->state));
  } else {
    clear_bit(5L, (unsigned long volatile   *)(& rx_ring->state));
  }
  *(vsi->rx_rings + (unsigned long )i) = rx_ring;
  i = i + 1;
  ldv_63122: ;
  if ((int )vsi->alloc_queue_pairs > i) {
    goto ldv_63121;
  } else {

  }

  return (0);
  err_out: 
  i40e_vsi_clear_rings(vsi);
  return (-12);
}
}
static int i40e_reserve_msix_vectors(struct i40e_pf *pf , int vectors ) 
{ 


  {
  vectors = pci_enable_msix_range(pf->pdev, pf->msix_entries, 2, vectors);
  if (vectors < 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "MSI-X vector reservation failed: %d\n",
              vectors);
    vectors = 0;
  } else {

  }
  return (vectors);
}
}
static int i40e_init_msix(struct i40e_pf *pf ) 
{ 
  struct i40e_hw *hw ;
  int vectors_left ;
    klee_make_symbolic(&vectors_left, sizeof(int), "vectors_left");
  int v_budget ;
    klee_make_symbolic(&v_budget, sizeof(int), "v_budget");
  int i ;
  int v_actual ;
    klee_make_symbolic(&v_actual, sizeof(int), "v_actual");
  int __min1 ;
  unsigned int tmp ;
  int __min2 ;
  int vmdq_vecs_wanted ;
    klee_make_symbolic(&vmdq_vecs_wanted, sizeof(int), "vmdq_vecs_wanted");
  int vmdq_vecs ;
    klee_make_symbolic(&vmdq_vecs, sizeof(int), "vmdq_vecs");
  int __min1___0 ;
  int __min2___0 ;
  void *tmp___0 ;
  int vec ;
    klee_make_symbolic(&vec, sizeof(int), "vec");
  int __min1___1 ;
  int __min2___1 ;

  {
  hw = & pf->hw;
  if ((pf->flags & 8ULL) == 0ULL) {
    return (-19);
  } else {

  }
  vectors_left = (int )hw->func_caps.num_msix_vectors;
  v_budget = 0;
  if (vectors_left != 0) {
    v_budget = v_budget + 1;
    vectors_left = vectors_left - 1;
  } else {

  }
  tmp = cpumask_weight(cpu_online_mask);
  __min1 = (int )tmp;
  __min2 = vectors_left;
  pf->num_lan_msix = (u16 )(__min1 < __min2 ? __min1 : __min2);
  vectors_left = vectors_left - (int )pf->num_lan_msix;
  v_budget = (int )pf->num_lan_msix + v_budget;
  if ((pf->flags & 2097152ULL) != 0ULL) {
    if (vectors_left != 0) {
      v_budget = v_budget + 1;
      vectors_left = vectors_left - 1;
    } else {
      pf->flags = pf->flags & 0xffffffffffdfffffULL;
    }
  } else {

  }
  if ((pf->flags & 2048ULL) != 0ULL) {
    if (vectors_left == 0) {
      pf->num_fcoe_msix = 0U;
    } else
    if ((int )pf->num_fcoe_qps <= vectors_left) {
      pf->num_fcoe_msix = pf->num_fcoe_qps;
    } else {
      pf->num_fcoe_msix = 1U;
    }
    v_budget = (int )pf->num_fcoe_msix + v_budget;
    vectors_left = vectors_left - (int )pf->num_fcoe_msix;
  } else {

  }
  if ((pf->flags & 128ULL) != 0ULL) {
    vmdq_vecs_wanted = (int )pf->num_vmdq_vsis * (int )pf->num_vmdq_qps;
    __min1___0 = vectors_left;
    __min2___0 = vmdq_vecs_wanted;
    vmdq_vecs = __min1___0 < __min2___0 ? __min1___0 : __min2___0;
    if (vmdq_vecs < vmdq_vecs_wanted) {
      pf->num_vmdq_qps = 1U;
    } else {

    }
    pf->num_vmdq_msix = pf->num_vmdq_qps;
    v_budget = v_budget + vmdq_vecs;
    vectors_left = vectors_left - vmdq_vecs;
  } else {

  }
  tmp___0 = kcalloc((size_t )v_budget, 8UL, 208U);
  pf->msix_entries = (struct msix_entry *)tmp___0;
  if ((unsigned long )pf->msix_entries == (unsigned long )((struct msix_entry *)0)) {
    return (-12);
  } else {

  }
  i = 0;
  goto ldv_63145;
  ldv_63144: 
  (pf->msix_entries + (unsigned long )i)->entry = (u16 )i;
  i = i + 1;
  ldv_63145: ;
  if (i < v_budget) {
    goto ldv_63144;
  } else {

  }
  v_actual = i40e_reserve_msix_vectors(pf, v_budget);
  if (v_actual != v_budget) {
    pf->num_fcoe_qps = 0U;
    pf->num_fcoe_msix = 0U;
    pf->num_vmdq_msix = 0U;
  } else {

  }
  if (v_actual <= 1) {
    pf->flags = pf->flags & 0xfffffffffffffff7ULL;
    kfree((void const   *)pf->msix_entries);
    pf->msix_entries = (struct msix_entry *)0;
    return (-19);
  } else
  if (v_actual == 2) {
    pf->num_vmdq_vsis = 0U;
    pf->num_vmdq_qps = 0U;
    pf->num_lan_qps = 1U;
    pf->num_lan_msix = 1U;
  } else
  if (v_actual != v_budget) {
    vec = v_actual + -1;
    pf->num_vmdq_msix = 1U;
    pf->num_vmdq_vsis = 1U;
    pf->num_vmdq_qps = 1U;
    pf->flags = pf->flags & 0xffffffffffdfffffULL;
    switch (vec) {
    case 2: 
    pf->num_lan_msix = 1U;
    goto ldv_63149;
    case 3: ;
    if ((pf->flags & 2048ULL) != 0ULL) {
      pf->num_lan_msix = 1U;
      pf->num_fcoe_msix = 1U;
    } else {

    }
    goto ldv_63149;
    default: ;
    if ((pf->flags & 2048ULL) != 0ULL) {
      pf->num_fcoe_msix = 1U;
      vec = vec - 1;
    } else {

    }
    __min1___1 = vec;
    __min2___1 = (int )pf->num_lan_qps;
    pf->num_lan_msix = (u16 )(__min1___1 < __min2___1 ? __min1___1 : __min2___1);
    goto ldv_63149;
    }
    ldv_63149: ;
  } else {

  }
  if ((pf->flags & 128ULL) != 0ULL && (unsigned int )pf->num_vmdq_msix == 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "VMDq disabled, not enough MSI-X vectors\n");
    pf->flags = pf->flags & 0xffffffffffffff7fULL;
  } else {

  }
  if ((pf->flags & 2048ULL) != 0ULL && (unsigned int )pf->num_fcoe_msix == 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "FCOE disabled, not enough MSI-X vectors\n");
    pf->flags = pf->flags & 0xfffffffffffff7ffULL;
  } else {

  }
  return (v_actual);
}
}
static int i40e_vsi_alloc_q_vector(struct i40e_vsi *vsi , int v_idx ) 
{ 
  struct i40e_q_vector *q_vector ;
  void *tmp ;

  {
  tmp = kzalloc(4096UL, 208U);
  q_vector = (struct i40e_q_vector *)tmp;
  if ((unsigned long )q_vector == (unsigned long )((struct i40e_q_vector *)0)) {
    return (-12);
  } else {

  }
  q_vector->vsi = vsi;
  q_vector->v_idx = (u16 )v_idx;
  cpumask_set_cpu((unsigned int )v_idx, & q_vector->affinity_mask);
  if ((unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0)) {
    netif_napi_add(vsi->netdev, & q_vector->napi, & i40e_napi_poll, 64);
  } else {

  }
  q_vector->rx.latency_range = 1;
  q_vector->tx.latency_range = 1;
  *(vsi->q_vectors + (unsigned long )v_idx) = q_vector;
  return (0);
}
}
static int i40e_vsi_alloc_q_vectors(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  int v_idx ;
  int num_q_vectors ;
  int err ;
  int tmp ;

  {
  pf = vsi->back;
  if ((pf->flags & 8ULL) != 0ULL) {
    num_q_vectors = vsi->num_q_vectors;
  } else
  if ((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) == (unsigned long )vsi) {
    num_q_vectors = 1;
  } else {
    return (-22);
  }
  v_idx = 0;
  goto ldv_63169;
  ldv_63168: 
  err = i40e_vsi_alloc_q_vector(vsi, v_idx);
  if (err != 0) {
    goto err_out;
  } else {

  }
  v_idx = v_idx + 1;
  ldv_63169: ;
  if (v_idx < num_q_vectors) {
    goto ldv_63168;
  } else {

  }

  return (0);
  err_out: ;
  goto ldv_63172;
  ldv_63171: 
  i40e_free_q_vector(vsi, v_idx);
  ldv_63172: 
  tmp = v_idx;
  v_idx = v_idx - 1;
  if (tmp != 0) {
    goto ldv_63171;
  } else {

  }

  return (err);
}
}
static int i40e_init_interrupt_scheme(struct i40e_pf *pf ) 
{ 
  int vectors ;
    klee_make_symbolic(&vectors, sizeof(int), "vectors");
  ssize_t size ;
  void *tmp ;

  {
  vectors = 0;
  if ((pf->flags & 8ULL) != 0ULL) {
    vectors = i40e_init_msix(pf);
    if (vectors < 0) {
      pf->flags = pf->flags & 0xffffffffdf97f737ULL;
      i40e_determine_queue_usage(pf);
    } else {

    }
  } else {

  }
  if ((pf->flags & 8ULL) == 0ULL && (pf->flags & 4ULL) != 0ULL) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "MSI-X not available, trying MSI\n");
    vectors = pci_enable_msi_exact(pf->pdev, 1);
    if (vectors < 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "MSI init failed - %d\n",
                vectors);
      pf->flags = pf->flags & 0xfffffffffffffffbULL;
    } else {

    }
    vectors = 1;
  } else {

  }
  if ((pf->flags & 12ULL) == 0ULL) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "MSI-X and MSI not available, falling back to Legacy IRQ\n");
  } else {

  }
  size = (ssize_t )(((unsigned long )vectors + 2UL) * 2UL);
  tmp = kzalloc((size_t )size, 208U);
  pf->irq_pile = (struct i40e_lump_tracking *)tmp;
  if ((unsigned long )pf->irq_pile == (unsigned long )((struct i40e_lump_tracking *)0)) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "error allocating irq_pile memory\n");
    return (-12);
  } else {

  }
  (pf->irq_pile)->num_entries = (u16 )vectors;
  (pf->irq_pile)->search_hint = 0U;
  i40e_get_lump(pf, pf->irq_pile, 1, 32767);
  return (0);
}
}
static int i40e_setup_misc_vector(struct i40e_pf *pf ) 
{ 
  struct i40e_hw *hw ;
  int err ;
  int tmp ;

  {
  hw = & pf->hw;
  err = 0;
  tmp = constant_test_bit(9L, (unsigned long const volatile   *)(& pf->state));
  if (tmp == 0) {
    err = ldv_request_irq_29((pf->msix_entries)->vector, & i40e_intr, 0UL, (char const   *)(& pf->int_name),
                             (void *)pf);
    if (err != 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "request_irq for %s failed: %d\n",
                (char *)(& pf->int_name), err);
      return (-14);
    } else {

    }
  } else {

  }
  i40e_enable_misc_int_causes(pf);
  writel(2047U, (void volatile   *)hw->hw_addr + 230656U);
  writel(62U, (void volatile   *)hw->hw_addr + 229376U);
  readl((void const volatile   *)hw->hw_addr + 745772U);
  i40e_irq_dynamic_enable_icr0(pf);
  return (err);
}
}
static int i40e_config_rss(struct i40e_pf *pf ) 
{ 
  u32 rss_key[13U] ;
  struct i40e_vsi *vsi ;
  struct i40e_hw *hw ;
  u32 lut ;
  int i ;
  int j ;
  u64 hena ;
  u32 reg_val ;
  unsigned int tmp ;
  unsigned int tmp___0 ;
  int __min1 ;
  int __min2 ;

  {
  vsi = *(pf->vsi + (unsigned long )pf->lan_vsi);
  hw = & pf->hw;
  lut = 0U;
  netdev_rss_key_fill((void *)(& rss_key), 52UL);
  i = 0;
  goto ldv_63196;
  ldv_63195: 
  writel(rss_key[i], (void volatile   *)hw->hw_addr + (unsigned long )((i + 18576) * 128));
  i = i + 1;
  ldv_63196: ;
  if (i <= 12) {
    goto ldv_63195;
  } else {

  }
  tmp = readl((void const volatile   *)hw->hw_addr + 2382080U);
  tmp___0 = readl((void const volatile   *)hw->hw_addr + 2382208U);
  hena = (unsigned long long )tmp | ((unsigned long long )tmp___0 << 32);
  hena = hena | 0x80007a1e80000000ULL;
  writel((unsigned int )hena, (void volatile   *)hw->hw_addr + 2382080U);
  writel((unsigned int )(hena >> 32), (void volatile   *)hw->hw_addr + 2382208U);
  __min1 = (int )pf->rss_size;
  __min2 = (int )vsi->num_queue_pairs;
  vsi->rss_size = (u16 )(__min1 < __min2 ? __min1 : __min2);
  reg_val = readl((void const volatile   *)hw->hw_addr + 1837760U);
  if ((unsigned int )pf->rss_table_size == 512U) {
    reg_val = reg_val | 65536U;
  } else {
    reg_val = reg_val & 4294901759U;
  }
  writel(reg_val, (void volatile   *)hw->hw_addr + 1837760U);
  i = 0;
  j = 0;
  goto ldv_63202;
  ldv_63201: ;
  if ((int )vsi->rss_size == j) {
    j = 0;
  } else {

  }
  lut = (lut << 8) | (u32 )(((1 << (int )pf->hw.func_caps.rss_table_entry_width) + -1) & j);
  if ((i & 3) == 3) {
    writel(lut, (void volatile   *)hw->hw_addr + (unsigned long )(((i >> 2) + 18432) * 128));
  } else {

  }
  i = i + 1;
  j = j + 1;
  ldv_63202: ;
  if ((int )pf->rss_table_size > i) {
    goto ldv_63201;
  } else {

  }
  readl((void const volatile   *)hw->hw_addr + 745772U);
  return (0);
}
}
int i40e_reconfig_rss_queues(struct i40e_pf *pf , int queue_count ) 
{ 
  struct i40e_vsi *vsi ;
  int new_rss_size ;
    klee_make_symbolic(&new_rss_size, sizeof(int), "new_rss_size");
  int __min1 ;
  int __min2 ;

  {
  vsi = *(pf->vsi + (unsigned long )pf->lan_vsi);
  if ((pf->flags & 64ULL) == 0ULL) {
    return (0);
  } else {

  }
  __min1 = queue_count;
  __min2 = (int )pf->rss_size_max;
  new_rss_size = __min1 < __min2 ? __min1 : __min2;
  if ((int )vsi->num_queue_pairs != queue_count) {
    vsi->req_queue_pairs = (u16 )queue_count;
    i40e_prep_for_reset(pf);
    pf->rss_size = (u16 )new_rss_size;
    i40e_reset_and_rebuild(pf, 1);
    i40e_config_rss(pf);
  } else {

  }
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "RSS count:  %d\n", (int )pf->rss_size);
  return ((int )pf->rss_size);
}
}
i40e_status i40e_get_npar_bw_setting(struct i40e_pf *pf ) 
{ 
  i40e_status status ;
  bool min_valid ;
  bool max_valid ;
  u32 max_bw ;
  u32 min_bw ;

  {
  status = i40e_read_bw_from_alt_ram(& pf->hw, & max_bw, & min_bw, & min_valid, & max_valid);
  if ((int )status == 0) {
    if ((int )min_valid) {
      pf->npar_min_bw = min_bw;
    } else {

    }
    if ((int )max_valid) {
      pf->npar_max_bw = max_bw;
    } else {

    }
  } else {

  }
  return (status);
}
}
i40e_status i40e_set_npar_bw_setting(struct i40e_pf *pf ) 
{ 
  struct i40e_aqc_configure_partition_bw_data bw_data ;
  i40e_status status ;

  {
  bw_data.pf_valid_bits = (unsigned short )(1 << (int )pf->hw.pf_id);
  bw_data.max_bw[(int )pf->hw.pf_id] = (u8 )pf->npar_max_bw;
  bw_data.min_bw[(int )pf->hw.pf_id] = (u8 )pf->npar_min_bw;
  status = i40e_aq_configure_partition_bw(& pf->hw, & bw_data, (struct i40e_asq_cmd_details *)0);
  return (status);
}
}
i40e_status i40e_commit_npar_bw_setting(struct i40e_pf *pf ) 
{ 
  enum i40e_admin_queue_err last_aq_status ;
  i40e_status ret ;
  u16 nvm_word ;

  {
  if ((unsigned int )pf->hw.partition_id != 1U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Commit BW only works on partition 1! This is partition %d",
              (int )pf->hw.partition_id);
    ret = -64;
    goto bw_commit_out;
  } else {

  }
  ret = i40e_acquire_nvm(& pf->hw, 1);
  last_aq_status = pf->hw.aq.asq_last_status;
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Cannot acquire NVM for read access, err %d: aq_err %d\n",
              (int )ret, (unsigned int )last_aq_status);
    goto bw_commit_out;
  } else {

  }
  ret = i40e_aq_read_nvm(& pf->hw, 0, 16U, 2, (void *)(& nvm_word), 0, (struct i40e_asq_cmd_details *)0);
  last_aq_status = pf->hw.aq.asq_last_status;
  i40e_release_nvm(& pf->hw);
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "NVM read error, err %d aq_err %d\n",
              (int )ret, (unsigned int )last_aq_status);
    goto bw_commit_out;
  } else {

  }
  msleep(50U);
  ret = i40e_acquire_nvm(& pf->hw, 2);
  last_aq_status = pf->hw.aq.asq_last_status;
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Cannot acquire NVM for write access, err %d: aq_err %d\n",
              (int )ret, (unsigned int )last_aq_status);
    goto bw_commit_out;
  } else {

  }
  ret = i40e_aq_update_nvm(& pf->hw, 0, 16U, 2, (void *)(& nvm_word), 1, (struct i40e_asq_cmd_details *)0);
  last_aq_status = pf->hw.aq.asq_last_status;
  i40e_release_nvm(& pf->hw);
  if ((int )ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "BW settings NOT SAVED, err %d aq_err %d\n",
              (int )ret, (unsigned int )last_aq_status);
  } else {

  }
  bw_commit_out: ;
  return (ret);
}
}
static int i40e_sw_init(struct i40e_pf *pf ) 
{ 
  int err ;
  int size ;
  bool tmp ;
  int __min1 ;
  int __min2 ;
  int __min1___0 ;
  int __min2___0 ;
  unsigned int tmp___0 ;
  i40e_status tmp___1 ;
  int __min1___1 ;
  int __min2___1 ;
  void *tmp___2 ;
  struct lock_class_key __key ;
  i40e_status tmp___3 ;

  {
  err = 0;
  pf->msg_enable = netif_msg_init(4, 7);
  pf->hw.debug_mask = pf->msg_enable | 2048U;
  if (debug != -1 && debug != 4) {
    if (((unsigned int )debug & 4026531840U) != 0U) {
      pf->hw.debug_mask = (u32 )debug;
    } else {

    }
    pf->msg_enable = netif_msg_init(debug & 268435455, 4);
  } else {

  }
  pf->flags = 14ULL;
  tmp = iommu_present(& pci_bus_type);
  if ((int )tmp) {
    pf->flags = pf->flags | 32ULL;
  } else {
    pf->flags = pf->flags | 16ULL;
  }
  pf->rx_itr_default = 32830U;
  pf->tx_itr_default = 32890U;
  pf->rss_size_max = (u16 )(1 << (int )pf->hw.func_caps.rss_table_entry_width);
  pf->rss_size = 1U;
  pf->rss_table_size = (u16 )pf->hw.func_caps.rss_table_size;
  __min1 = (int )pf->rss_size_max;
  __min2 = (int )pf->hw.func_caps.num_tx_qp;
  pf->rss_size_max = (u16 )(__min1 < __min2 ? __min1 : __min2);
  if ((int )pf->hw.func_caps.rss) {
    pf->flags = pf->flags | 64ULL;
    __min1___0 = (int )pf->rss_size_max;
    tmp___0 = cpumask_weight(cpu_online_mask);
    __min2___0 = (int )tmp___0;
    pf->rss_size = (u16 )(__min1___0 < __min2___0 ? __min1___0 : __min2___0);
  } else {

  }
  if (pf->hw.func_caps.npar_enable != 0U || (int )pf->hw.func_caps.mfp_mode_1) {
    pf->flags = pf->flags | 67108864ULL;
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "MFP mode Enabled\n");
    tmp___1 = i40e_get_npar_bw_setting(pf);
    if ((int )tmp___1 != 0) {
      dev_warn((struct device  const  *)(& (pf->pdev)->dev), "Could not get NPAR bw settings\n");
    } else {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Min BW = %8.8x, Max BW = %8.8x\n",
                pf->npar_min_bw, pf->npar_max_bw);
    }
  } else {

  }
  if (pf->hw.func_caps.fd_filters_guaranteed != 0U || pf->hw.func_caps.fd_filters_best_effort != 0U) {
    pf->flags = pf->flags | 4194304ULL;
    pf->atr_sample_rate = 20U;
    if ((pf->flags & 67108864ULL) == 0ULL) {
      pf->flags = pf->flags | 2097152ULL;
    } else {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Flow Director Sideband mode Disabled in MFP mode\n");
    }
    pf->fdir_pf_filter_count = (u16 )pf->hw.func_caps.fd_filters_guaranteed;
    pf->hw.fdir_shared_filter_count = (u16 )pf->hw.func_caps.fd_filters_best_effort;
  } else {

  }
  if ((int )pf->hw.func_caps.vmdq) {
    pf->flags = pf->flags | 128ULL;
    pf->num_vmdq_vsis = 8U;
    pf->num_vmdq_qps = 2U;
  } else {

  }
  err = i40e_init_pf_fcoe(pf);
  if (err != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "init_pf_fcoe failed: %d\n",
              err);
  } else {

  }
  if (pf->hw.func_caps.num_vfs != 0U && (unsigned int )pf->hw.partition_id == 1U) {
    pf->num_vf_qps = 4U;
    pf->flags = pf->flags | 524288ULL;
    __min1___1 = (int )pf->hw.func_caps.num_vfs;
    __min2___1 = 128;
    pf->num_req_vfs = (u16 )(__min1___1 < __min2___1 ? __min1___1 : __min2___1);
  } else {

  }
  pf->eeprom_version = 57005U;
  pf->lan_veb = 65535U;
  pf->lan_vsi = 65535U;
  size = (int )((unsigned int )((unsigned long )pf->hw.func_caps.num_tx_qp + 2UL) * 2U);
  tmp___2 = kzalloc((size_t )size, 208U);
  pf->qp_pile = (struct i40e_lump_tracking *)tmp___2;
  if ((unsigned long )pf->qp_pile == (unsigned long )((struct i40e_lump_tracking *)0)) {
    err = -12;
    goto sw_init_done;
  } else {

  }
  (pf->qp_pile)->num_entries = (u16 )pf->hw.func_caps.num_tx_qp;
  (pf->qp_pile)->search_hint = 0U;
  pf->tx_timeout_recovery_level = 1U;
  __mutex_init(& pf->switch_mutex, "&pf->switch_mutex", & __key);
  if (pf->hw.func_caps.npar_enable != 0U) {
    tmp___3 = i40e_get_npar_bw_setting(pf);
    if ((int )tmp___3 == 0) {
      i40e_set_npar_bw_setting(pf);
    } else {

    }
  } else {

  }
  sw_init_done: ;
  return (err);
}
}
bool i40e_set_ntuple(struct i40e_pf *pf , netdev_features_t features ) 
{ 
  bool need_reset ;
  u32 tmp ;
  u32 tmp___0 ;

  {
  need_reset = 0;
  if ((features & 4294967296ULL) != 0ULL) {
    if ((pf->flags & 2097152ULL) == 0ULL) {
      need_reset = 1;
    } else {

    }
    pf->flags = pf->flags | 2097152ULL;
  } else {
    if ((pf->flags & 2097152ULL) != 0ULL) {
      need_reset = 1;
      i40e_fdir_filter_exit(pf);
    } else {

    }
    pf->flags = pf->flags & 0xffffffffffdfffffULL;
    pf->auto_disable_flags = pf->auto_disable_flags & 0xffffffffffdfffffULL;
    tmp___0 = 0U;
    pf->fd_tcp_rule = tmp___0;
    tmp = tmp___0;
    pf->fd_atr_cnt = tmp;
    pf->fd_add_err = tmp;
    pf->fdir_pf_active_filters = 0U;
    pf->flags = pf->flags | 4194304ULL;
    if ((pf->hw.debug_mask & 4096U) != 0U) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ATR re-enabled.\n");
    } else {

    }
    if ((pf->flags & 4194304ULL) != 0ULL && (pf->auto_disable_flags & 4194304ULL) != 0ULL) {
      pf->auto_disable_flags = pf->auto_disable_flags & 0xffffffffffbfffffULL;
    } else {

    }
  }
  return (need_reset);
}
}
static int i40e_set_features(struct net_device *netdev , netdev_features_t features ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  bool need_reset ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  if ((features & 256ULL) != 0ULL) {
    i40e_vlan_stripping_enable(vsi);
  } else {
    i40e_vlan_stripping_disable(vsi);
  }
  need_reset = i40e_set_ntuple(pf, features);
  if ((int )need_reset) {
    i40e_do_reset(pf, 4096U);
  } else {

  }
  return (0);
}
}
static u8 i40e_get_vxlan_port_idx(struct i40e_pf *pf , __be16 port ) 
{ 
  u8 i ;

  {
  i = 0U;
  goto ldv_63268;
  ldv_63267: ;
  if ((int )pf->vxlan_ports[(int )i] == (int )port) {
    return (i);
  } else {

  }
  i = (u8 )((int )i + 1);
  ldv_63268: ;
  if ((unsigned int )i <= 15U) {
    goto ldv_63267;
  } else {

  }

  return (i);
}
}
static void i40e_add_vxlan_port(struct net_device *netdev , sa_family_t sa_family ,
                                __be16 port ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  u8 next_idx ;
  u8 idx ;
  __u16 tmp___0 ;
  __u16 tmp___1 ;
  __u16 tmp___2 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  if ((unsigned int )sa_family == 10U) {
    return;
  } else {

  }
  idx = i40e_get_vxlan_port_idx(pf, (int )port);
  if ((unsigned int )idx <= 15U) {
    tmp___0 = __fswab16((int )port);
    netdev_info((struct net_device  const  *)netdev, "vxlan port %d already offloaded\n",
                (int )tmp___0);
    return;
  } else {

  }
  next_idx = i40e_get_vxlan_port_idx(pf, 0);
  if ((unsigned int )next_idx == 16U) {
    tmp___1 = __fswab16((int )port);
    netdev_info((struct net_device  const  *)netdev, "maximum number of vxlan UDP ports reached, not adding port %d\n",
                (int )tmp___1);
    return;
  } else {

  }
  pf->vxlan_ports[(int )next_idx] = port;
  pf->pending_vxlan_bitmap = (u16 )((int )((short )pf->pending_vxlan_bitmap) | (int )((short )(1 << (int )next_idx)));
  pf->flags = pf->flags | 134217728ULL;
  tmp___2 = __fswab16((int )port);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "adding vxlan port %d\n",
            (int )tmp___2);
  return;
}
}
static void i40e_del_vxlan_port(struct net_device *netdev , sa_family_t sa_family ,
                                __be16 port ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  u8 idx ;
  __u16 tmp___0 ;
  __u16 tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  if ((unsigned int )sa_family == 10U) {
    return;
  } else {

  }
  idx = i40e_get_vxlan_port_idx(pf, (int )port);
  if ((unsigned int )idx <= 15U) {
    pf->vxlan_ports[(int )idx] = 0U;
    pf->pending_vxlan_bitmap = (u16 )((int )((short )pf->pending_vxlan_bitmap) | (int )((short )(1 << (int )idx)));
    pf->flags = pf->flags | 134217728ULL;
    tmp___0 = __fswab16((int )port);
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "deleting vxlan port %d\n",
              (int )tmp___0);
  } else {
    tmp___1 = __fswab16((int )port);
    netdev_warn((struct net_device  const  *)netdev, "vxlan port %d was not found, not deleting\n",
                (int )tmp___1);
  }
  return;
}
}
static int i40e_get_phys_port_id(struct net_device *netdev , struct netdev_phys_item_id *ppid ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  int __min1 ;
  int __min2 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  hw = & pf->hw;
  if ((pf->flags & 268435456ULL) == 0ULL) {
    return (-95);
  } else {

  }
  __min1 = 6;
  __min2 = 32;
  ppid->id_len = (unsigned char )(__min1 < __min2 ? __min1 : __min2);
  memcpy((void *)(& ppid->id), (void const   *)(& hw->mac.port_addr), (size_t )ppid->id_len);
  return (0);
}
}
static int i40e_ndo_fdb_add(struct ndmsg *ndm , struct nlattr **tb , struct net_device *dev ,
                            unsigned char const   *addr , u16 vid , u16 flags ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  int err ;
  bool tmp___0 ;
  bool tmp___1 ;
  bool tmp___2 ;

  {
  tmp = netdev_priv((struct net_device  const  *)dev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  err = 0;
  if ((pf->flags & 524288ULL) == 0ULL) {
    return (-95);
  } else {

  }
  if ((unsigned int )vid != 0U) {
    printk("\016%s: vlans aren\'t supported yet for dev_uc|mc_add()\n", (char *)(& dev->name));
    return (-22);
  } else {

  }
  if ((unsigned int )ndm->ndm_state != 0U && ((int )ndm->ndm_state & 128) == 0) {
    netdev_info((struct net_device  const  *)dev, "FDB only supports static addresses\n");
    return (-22);
  } else {

  }
  tmp___1 = is_unicast_ether_addr(addr);
  if ((int )tmp___1) {
    err = dev_uc_add_excl(dev, addr);
  } else {
    tmp___2 = is_link_local_ether_addr(addr);
    if ((int )tmp___2) {
      err = dev_uc_add_excl(dev, addr);
    } else {
      tmp___0 = is_multicast_ether_addr(addr);
      if ((int )tmp___0) {
        err = dev_mc_add_excl(dev, addr);
      } else {
        err = -22;
      }
    }
  }
  if (err == -17 && ((int )flags & 512) == 0) {
    err = 0;
  } else {

  }
  return (err);
}
}
static struct net_device_ops  const  i40e_netdev_ops  = 
     {0, 0, & i40e_open, & i40e_close, & i40e_lan_xmit_frame, 0, 0, & i40e_set_rx_mode,
    & i40e_set_mac, & eth_validate_addr, & i40e_ioctl, 0, & i40e_change_mtu, 0, & i40e_tx_timeout,
    & i40e_get_netdev_stats_struct, 0, & i40e_vlan_rx_add_vid, & i40e_vlan_rx_kill_vid,
    & i40e_netpoll, 0, 0, 0, & i40e_ndo_set_vf_mac, & i40e_ndo_set_vf_port_vlan, & i40e_ndo_set_vf_bw,
    & i40e_ndo_set_vf_spoofchk, & i40e_ndo_get_vf_config, & i40e_ndo_set_vf_link_state,
    0, 0, 0, 0, & i40e_setup_tc, & i40e_fcoe_enable, & i40e_fcoe_disable, 0, 0, 0,
    0, 0, 0, 0, 0, 0, & i40e_set_features, 0, 0, & i40e_ndo_fdb_add, 0, 0, 0, 0, 0,
    0, & i40e_get_phys_port_id, 0, & i40e_add_vxlan_port, & i40e_del_vxlan_port, 0,
    0, 0, 0, 0, 0, 0};
static int i40e_config_netdev(struct i40e_vsi *vsi ) 
{ 
  u8 brdcast[6U] ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  struct i40e_netdev_priv *np ;
  struct net_device *netdev ;
  u8 mac_addr[6U] ;
  int etherdev_size ;
    klee_make_symbolic(&etherdev_size, sizeof(int), "etherdev_size");
  void *tmp ;
  int tmp___0 ;

  {
  brdcast[0] = 255U;
  brdcast[1] = 255U;
  brdcast[2] = 255U;
  brdcast[3] = 255U;
  brdcast[4] = 255U;
  brdcast[5] = 255U;
  pf = vsi->back;
  hw = & pf->hw;
  etherdev_size = 8;
  netdev = alloc_etherdev_mqs(etherdev_size, (unsigned int )vsi->alloc_queue_pairs,
                              (unsigned int )vsi->alloc_queue_pairs);
  if ((unsigned long )netdev == (unsigned long )((struct net_device *)0)) {
    return (-12);
  } else {

  }
  vsi->netdev = netdev;
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  np->vsi = vsi;
  netdev->hw_enc_features = netdev->hw_enc_features | 67174402ULL;
  netdev->features = 26912293811ULL;
  if ((pf->flags & 67108864ULL) == 0ULL) {
    netdev->features = netdev->features | 4294967296ULL;
  } else {

  }
  netdev->hw_features = netdev->hw_features | netdev->features;
  if ((unsigned int )vsi->type == 0U) {
    netdev->dev.parent = & (pf->pdev)->dev;
    ether_addr_copy((u8 *)(& mac_addr), (u8 const   *)(& hw->mac.perm_addr));
    tmp___0 = i40e_rm_default_mac_filter(vsi, (u8 *)(& mac_addr));
    if (tmp___0 == 0) {
      i40e_add_filter(vsi, (u8 *)(& mac_addr), -1, 0, 1);
    } else {

    }
  } else {
    snprintf((char *)(& netdev->name), 16UL, "%sv%%d", (char *)(& ((*(pf->vsi + (unsigned long )pf->lan_vsi))->netdev)->name));
    eth_random_addr((u8 *)(& mac_addr));
    i40e_add_filter(vsi, (u8 *)(& mac_addr), -1, 0, 0);
  }
  i40e_add_filter(vsi, (u8 *)(& brdcast), -1, 0, 0);
  ether_addr_copy(netdev->dev_addr, (u8 const   *)(& mac_addr));
  ether_addr_copy((u8 *)(& netdev->perm_addr), (u8 const   *)(& mac_addr));
  netdev->vlan_features = netdev->features & 0xfffffffffffffc7fULL;
  netdev->priv_flags = netdev->priv_flags | 131072U;
  netdev->priv_flags = netdev->priv_flags | 524288U;
  i40e_vsi_config_netdev_tc(vsi, (int )vsi->tc_config.enabled_tc);
  netdev->netdev_ops = & i40e_netdev_ops;
  netdev->watchdog_timeo = 1250;
  i40e_set_ethtool_ops(netdev);
  i40e_fcoe_config_netdev(netdev, vsi);
  return (0);
}
}
static void i40e_vsi_delete(struct i40e_vsi *vsi ) 
{ 


  {
  if ((unsigned long )*((vsi->back)->vsi + (unsigned long )(vsi->back)->lan_vsi) == (unsigned long )vsi) {
    return;
  } else {

  }
  i40e_aq_delete_element(& (vsi->back)->hw, (int )vsi->seid, (struct i40e_asq_cmd_details *)0);
  return;
}
}
int i40e_is_vsi_uplink_mode_veb(struct i40e_vsi *vsi ) 
{ 
  struct i40e_veb *veb ;
  struct i40e_pf *pf ;

  {
  pf = vsi->back;
  if ((unsigned int )vsi->veb_idx == 65535U) {
    return (1);
  } else {

  }
  veb = pf->veb[(int )vsi->veb_idx];
  if ((unsigned long )veb != (unsigned long )((struct i40e_veb *)0) && (int )veb->bridge_mode & 1) {
    return (0);
  } else {

  }
  return (1);
}
}
static int i40e_add_vsi(struct i40e_vsi *vsi ) 
{ 
  int ret ;
  struct i40e_mac_filter *f ;
  struct i40e_mac_filter *ftmp ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  struct i40e_vsi_context ctxt ;
  u8 enabled_tc ;
  int f_count ;
    klee_make_symbolic(&f_count, sizeof(int), "f_count");
  i40e_status tmp ;
  i40e_status tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  i40e_status tmp___4 ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct i40e_aqc_remove_macvlan_element_data element ;
  i40e_status tmp___5 ;
  struct list_head  const  *__mptr___1 ;

  {
  ret = -19;
  pf = vsi->back;
  hw = & pf->hw;
  enabled_tc = 1U;
  f_count = 0;
  memset((void *)(& ctxt), 0, 144UL);
  switch ((unsigned int )vsi->type) {
  case 0U: 
  ctxt.seid = pf->main_vsi_seid;
  ctxt.pf_num = pf->hw.pf_id;
  ctxt.vf_num = 0U;
  tmp = i40e_aq_get_vsi_params(& pf->hw, & ctxt, (struct i40e_asq_cmd_details *)0);
  ret = (int )tmp;
  ctxt.flags = 2U;
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "couldn\'t get PF vsi config, err %d, aq_err %d\n",
              ret, (unsigned int )pf->hw.aq.asq_last_status);
    return (-2);
  } else {

  }
  vsi->info = ctxt.info;
  vsi->info.valid_sections = 0U;
  vsi->seid = ctxt.seid;
  vsi->id = ctxt.vsi_number;
  enabled_tc = i40e_pf_get_tc_map(pf);
  if ((pf->flags & 67108864ULL) != 0ULL && ! pf->hw.func_caps.iscsi) {
    memset((void *)(& ctxt), 0, 144UL);
    ctxt.seid = pf->main_vsi_seid;
    ctxt.pf_num = pf->hw.pf_id;
    ctxt.vf_num = 0U;
    i40e_vsi_setup_queue_map(vsi, & ctxt, (int )enabled_tc, 0);
    tmp___0 = i40e_aq_update_vsi_params(hw, & ctxt, (struct i40e_asq_cmd_details *)0);
    ret = (int )tmp___0;
    if (ret != 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "update vsi failed, aq_err=%d\n",
                (unsigned int )pf->hw.aq.asq_last_status);
      ret = -2;
      goto err;
    } else {

    }
    i40e_vsi_update_queue_map(vsi, & ctxt);
    vsi->info.valid_sections = 0U;
  } else {
    ret = i40e_vsi_config_tc(vsi, (int )enabled_tc);
    if (ret != 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "failed to configure TCs for main VSI tc_map 0x%08x, err %d, aq_err %d\n",
                (int )enabled_tc, ret, (unsigned int )pf->hw.aq.asq_last_status);
      ret = -2;
    } else {

    }
  }
  goto ldv_63342;
  case 7U: 
  ctxt.pf_num = hw->pf_id;
  ctxt.vf_num = 0U;
  ctxt.uplink_seid = vsi->uplink_seid;
  ctxt.connection_type = 1U;
  ctxt.flags = 2U;
  if ((pf->flags & 1099511627776ULL) != 0ULL) {
    tmp___1 = i40e_is_vsi_uplink_mode_veb(vsi);
    if (tmp___1 != 0) {
      ctxt.info.valid_sections = (__le16 )((unsigned int )ctxt.info.valid_sections | 1U);
      ctxt.info.switch_id = 8192U;
    } else {

    }
  } else {

  }
  i40e_vsi_setup_queue_map(vsi, & ctxt, (int )enabled_tc, 1);
  goto ldv_63342;
  case 2U: 
  ctxt.pf_num = hw->pf_id;
  ctxt.vf_num = 0U;
  ctxt.uplink_seid = vsi->uplink_seid;
  ctxt.connection_type = 1U;
  ctxt.flags = 1U;
  tmp___2 = i40e_is_vsi_uplink_mode_veb(vsi);
  if (tmp___2 != 0) {
    ctxt.info.valid_sections = (__le16 )((unsigned int )ctxt.info.valid_sections | 1U);
    ctxt.info.switch_id = 8192U;
  } else {

  }
  i40e_vsi_setup_queue_map(vsi, & ctxt, (int )enabled_tc, 1);
  goto ldv_63342;
  case 6U: 
  ctxt.pf_num = hw->pf_id;
  ctxt.vf_num = (int )((u8 )vsi->vf_id) + (int )((u8 )hw->func_caps.vf_base_id);
  ctxt.uplink_seid = vsi->uplink_seid;
  ctxt.connection_type = 1U;
  ctxt.flags = 0U;
  tmp___3 = i40e_is_vsi_uplink_mode_veb(vsi);
  if (tmp___3 != 0) {
    ctxt.info.valid_sections = (__le16 )((unsigned int )ctxt.info.valid_sections | 1U);
    ctxt.info.switch_id = 8192U;
  } else {

  }
  ctxt.info.valid_sections = (__le16 )((unsigned int )ctxt.info.valid_sections | 4U);
  ctxt.info.port_vlan_flags = (u8 )((unsigned int )ctxt.info.port_vlan_flags | 3U);
  if ((int )(pf->vf + (unsigned long )vsi->vf_id)->spoofchk) {
    ctxt.info.valid_sections = (__le16 )((unsigned int )ctxt.info.valid_sections | 2U);
    ctxt.info.sec_flags = (u8 )((unsigned int )ctxt.info.sec_flags | 6U);
  } else {

  }
  i40e_vsi_setup_queue_map(vsi, & ctxt, (int )enabled_tc, 1);
  goto ldv_63342;
  case 4U: 
  ret = i40e_fcoe_vsi_init(vsi, & ctxt);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "failed to initialize FCoE VSI\n");
    return (ret);
  } else {

  }
  goto ldv_63342;
  default: ;
  return (-19);
  }
  ldv_63342: ;
  if ((unsigned int )vsi->type != 0U) {
    tmp___4 = i40e_aq_add_vsi(hw, & ctxt, (struct i40e_asq_cmd_details *)0);
    ret = (int )tmp___4;
    if (ret != 0) {
      _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "add vsi failed, aq_err=%d\n",
                (unsigned int )(vsi->back)->hw.aq.asq_last_status);
      ret = -2;
      goto err;
    } else {

    }
    vsi->info = ctxt.info;
    vsi->info.valid_sections = 0U;
    vsi->seid = ctxt.seid;
    vsi->id = ctxt.vsi_number;
  } else {

  }
  __mptr = (struct list_head  const  *)vsi->mac_filter_list.next;
  f = (struct i40e_mac_filter *)__mptr;
  __mptr___0 = (struct list_head  const  *)f->list.next;
  ftmp = (struct i40e_mac_filter *)__mptr___0;
  goto ldv_63356;
  ldv_63355: 
  f->changed = 1;
  f_count = f_count + 1;
  if ((int )f->is_laa && (unsigned int )vsi->type == 0U) {
    memset((void *)(& element), 0, 16UL);
    ether_addr_copy((u8 *)(& element.mac_addr), (u8 const   *)(& f->macaddr));
    element.flags = 1U;
    tmp___5 = i40e_aq_remove_macvlan(hw, (int )vsi->seid, & element, 1, (struct i40e_asq_cmd_details *)0);
    ret = (int )tmp___5;
    if (ret != 0) {
      element.flags = (u8 )((unsigned int )element.flags | 8U);
      i40e_aq_remove_macvlan(hw, (int )vsi->seid, & element, 1, (struct i40e_asq_cmd_details *)0);
    } else {

    }
    i40e_aq_mac_address_write(hw, 16384, (u8 *)(& f->macaddr), (struct i40e_asq_cmd_details *)0);
  } else {

  }
  f = ftmp;
  __mptr___1 = (struct list_head  const  *)ftmp->list.next;
  ftmp = (struct i40e_mac_filter *)__mptr___1;
  ldv_63356: ;
  if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
    goto ldv_63355;
  } else {

  }

  if (f_count != 0) {
    vsi->flags = vsi->flags | 1UL;
    pf->flags = pf->flags | 32768ULL;
  } else {

  }
  ret = i40e_vsi_get_bw_info(vsi);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "couldn\'t get vsi bw info, err %d, aq_err %d\n",
              ret, (unsigned int )pf->hw.aq.asq_last_status);
    ret = 0;
  } else {

  }
  err: ;
  return (ret);
}
}
int i40e_vsi_release(struct i40e_vsi *vsi ) 
{ 
  struct i40e_mac_filter *f ;
  struct i40e_mac_filter *ftmp ;
  struct i40e_veb *veb ;
  struct i40e_pf *pf ;
  u16 uplink_seid ;
  int i ;
  int n ;
  int tmp ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;

  {
  veb = (struct i40e_veb *)0;
  pf = vsi->back;
  if ((vsi->flags & 2UL) != 0UL) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "VSI %d has existing VEB %d\n",
              (int )vsi->seid, (int )vsi->uplink_seid);
    return (-19);
  } else {

  }
  if ((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) == (unsigned long )vsi) {
    tmp = constant_test_bit(3L, (unsigned long const volatile   *)(& pf->state));
    if (tmp == 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Can\'t remove PF VSI\n");
      return (-19);
    } else {

    }
  } else {

  }
  uplink_seid = vsi->uplink_seid;
  if ((unsigned int )vsi->type != 6U) {
    if ((int )vsi->netdev_registered) {
      vsi->netdev_registered = 0;
      if ((unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0)) {
        ldv_unregister_netdev_30(vsi->netdev);
      } else {

      }
    } else {
      i40e_vsi_close(vsi);
    }
    i40e_vsi_disable_irq(vsi);
  } else {

  }
  __mptr = (struct list_head  const  *)vsi->mac_filter_list.next;
  f = (struct i40e_mac_filter *)__mptr;
  __mptr___0 = (struct list_head  const  *)f->list.next;
  ftmp = (struct i40e_mac_filter *)__mptr___0;
  goto ldv_63375;
  ldv_63374: 
  i40e_del_filter(vsi, (u8 *)(& f->macaddr), (int )f->vlan, (int )f->is_vf, (int )f->is_netdev);
  f = ftmp;
  __mptr___1 = (struct list_head  const  *)ftmp->list.next;
  ftmp = (struct i40e_mac_filter *)__mptr___1;
  ldv_63375: ;
  if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
    goto ldv_63374;
  } else {

  }
  i40e_sync_vsi_filters(vsi);
  i40e_vsi_delete(vsi);
  i40e_vsi_free_q_vectors(vsi);
  if ((unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0)) {
    ldv_free_netdev_31(vsi->netdev);
    vsi->netdev = (struct net_device *)0;
  } else {

  }
  i40e_vsi_clear_rings(vsi);
  i40e_vsi_clear(vsi);
  n = 0;
  i = 0;
  goto ldv_63378;
  ldv_63377: ;
  if (((unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0) && (int )(*(pf->vsi + (unsigned long )i))->uplink_seid == (int )uplink_seid) && ((*(pf->vsi + (unsigned long )i))->flags & 2UL) == 0UL) {
    n = n + 1;
  } else {

  }
  i = i + 1;
  ldv_63378: ;
  if ((int )pf->num_alloc_vsi > i) {
    goto ldv_63377;
  } else {

  }
  i = 0;
  goto ldv_63382;
  ldv_63381: ;
  if ((unsigned long )pf->veb[i] == (unsigned long )((struct i40e_veb *)0)) {
    goto ldv_63380;
  } else {

  }
  if ((int )(pf->veb[i])->uplink_seid == (int )uplink_seid) {
    n = n + 1;
  } else {

  }
  if ((int )(pf->veb[i])->seid == (int )uplink_seid) {
    veb = pf->veb[i];
  } else {

  }
  ldv_63380: 
  i = i + 1;
  ldv_63382: ;
  if (i <= 15) {
    goto ldv_63381;
  } else {

  }

  if ((n == 0 && (unsigned long )veb != (unsigned long )((struct i40e_veb *)0)) && (unsigned int )veb->uplink_seid != 0U) {
    i40e_veb_release(veb);
  } else {

  }
  return (0);
}
}
static int i40e_vsi_setup_vectors(struct i40e_vsi *vsi ) 
{ 
  int ret ;
  struct i40e_pf *pf ;

  {
  ret = -2;
  pf = vsi->back;
  if ((unsigned long )*(vsi->q_vectors) != (unsigned long )((struct i40e_q_vector *)0)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "VSI %d has existing q_vectors\n",
              (int )vsi->seid);
    return (-17);
  } else {

  }
  if (vsi->base_vector != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "VSI %d has non-zero base vector %d\n",
              (int )vsi->seid, vsi->base_vector);
    return (-17);
  } else {

  }
  ret = i40e_vsi_alloc_q_vectors(vsi);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "failed to allocate %d q_vector for VSI %d, ret=%d\n",
              vsi->num_q_vectors, (int )vsi->seid, ret);
    vsi->num_q_vectors = 0;
    goto vector_setup_out;
  } else {

  }
  if (vsi->num_q_vectors != 0) {
    vsi->base_vector = i40e_get_lump(pf, pf->irq_pile, (int )((u16 )vsi->num_q_vectors),
                                     (int )vsi->idx);
  } else {

  }
  if (vsi->base_vector < 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "failed to get tracking for %d vectors for VSI %d, err=%d\n",
              vsi->num_q_vectors, (int )vsi->seid, vsi->base_vector);
    i40e_vsi_free_q_vectors(vsi);
    ret = -2;
    goto vector_setup_out;
  } else {

  }
  vector_setup_out: ;
  return (ret);
}
}
static struct i40e_vsi *i40e_vsi_reinit_setup(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  u8 enabled_tc ;
  int ret ;

  {
  pf = vsi->back;
  i40e_put_lump(pf->qp_pile, (int )vsi->base_queue, (int )vsi->idx);
  i40e_vsi_clear_rings(vsi);
  i40e_vsi_free_arrays(vsi, 0);
  i40e_set_num_rings_in_vsi(vsi);
  ret = i40e_vsi_alloc_arrays(vsi, 0);
  if (ret != 0) {
    goto err_vsi;
  } else {

  }
  ret = i40e_get_lump(pf, pf->qp_pile, (int )vsi->alloc_queue_pairs, (int )vsi->idx);
  if (ret < 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "failed to get tracking for %d queues for VSI %d err=%d\n",
              (int )vsi->alloc_queue_pairs, (int )vsi->seid, ret);
    goto err_vsi;
  } else {

  }
  vsi->base_queue = (u16 )ret;
  enabled_tc = (*(pf->vsi + (unsigned long )pf->lan_vsi))->tc_config.enabled_tc;
  (*(pf->vsi + (unsigned long )pf->lan_vsi))->tc_config.enabled_tc = 0U;
  (*(pf->vsi + (unsigned long )pf->lan_vsi))->seid = pf->main_vsi_seid;
  i40e_vsi_config_tc(*(pf->vsi + (unsigned long )pf->lan_vsi), (int )enabled_tc);
  ret = i40e_alloc_rings(vsi);
  if (ret != 0) {
    goto err_rings;
  } else {

  }
  i40e_vsi_map_rings_to_vectors(vsi);
  return (vsi);
  err_rings: 
  i40e_vsi_free_q_vectors(vsi);
  if ((int )vsi->netdev_registered) {
    vsi->netdev_registered = 0;
    ldv_unregister_netdev_32(vsi->netdev);
    ldv_free_netdev_33(vsi->netdev);
    vsi->netdev = (struct net_device *)0;
  } else {

  }
  i40e_aq_delete_element(& pf->hw, (int )vsi->seid, (struct i40e_asq_cmd_details *)0);
  err_vsi: 
  i40e_vsi_clear(vsi);
  return ((struct i40e_vsi *)0);
}
}
struct i40e_vsi *i40e_vsi_setup(struct i40e_pf *pf , u8 type , u16 uplink_seid , u32 param1 ) 
{ 
  struct i40e_vsi *vsi ;
  struct i40e_veb *veb ;
  int ret ;
  int i ;
  int v_idx ;

  {
  vsi = (struct i40e_vsi *)0;
  veb = (struct i40e_veb *)0;
  i = 0;
  goto ldv_63411;
  ldv_63410: ;
  if ((unsigned long )pf->veb[i] != (unsigned long )((struct i40e_veb *)0) && (int )(pf->veb[i])->seid == (int )uplink_seid) {
    veb = pf->veb[i];
    goto ldv_63409;
  } else {

  }
  i = i + 1;
  ldv_63411: ;
  if (i <= 15) {
    goto ldv_63410;
  } else {

  }
  ldv_63409: ;
  if ((unsigned long )veb == (unsigned long )((struct i40e_veb *)0) && (int )pf->mac_seid != (int )uplink_seid) {
    i = 0;
    goto ldv_63414;
    ldv_63413: ;
    if ((unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0) && (int )(*(pf->vsi + (unsigned long )i))->seid == (int )uplink_seid) {
      vsi = *(pf->vsi + (unsigned long )i);
      goto ldv_63412;
    } else {

    }
    i = i + 1;
    ldv_63414: ;
    if ((int )pf->num_alloc_vsi > i) {
      goto ldv_63413;
    } else {

    }
    ldv_63412: ;
    if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "no such uplink_seid %d\n",
                (int )uplink_seid);
      return ((struct i40e_vsi *)0);
    } else {

    }
    if ((int )vsi->uplink_seid == (int )pf->mac_seid) {
      veb = i40e_veb_setup(pf, 0, (int )pf->mac_seid, (int )vsi->seid, (int )vsi->tc_config.enabled_tc);
    } else
    if ((vsi->flags & 2UL) == 0UL) {
      veb = i40e_veb_setup(pf, 0, (int )vsi->uplink_seid, (int )vsi->seid, (int )vsi->tc_config.enabled_tc);
    } else {

    }
    if ((unsigned long )veb != (unsigned long )((struct i40e_veb *)0)) {
      if ((int )vsi->seid != (int )(*(pf->vsi + (unsigned long )pf->lan_vsi))->seid) {
        _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "%s: New VSI creation error, uplink seid of LAN VSI expected.\n",
                  "i40e_vsi_setup");
        return ((struct i40e_vsi *)0);
      } else {

      }
      if ((pf->flags & 1099511627776ULL) == 0ULL) {
        veb->bridge_mode = 1U;
        pf->flags = pf->flags & 0xfffffeffffffffffULL;
      } else {

      }
      i40e_config_bridge_mode(veb);
    } else {

    }
    i = 0;
    goto ldv_63417;
    ldv_63416: ;
    if ((unsigned long )pf->veb[i] != (unsigned long )((struct i40e_veb *)0) && (int )(pf->veb[i])->seid == (int )vsi->uplink_seid) {
      veb = pf->veb[i];
    } else {

    }
    i = i + 1;
    ldv_63417: ;
    if (i <= 15 && (unsigned long )veb == (unsigned long )((struct i40e_veb *)0)) {
      goto ldv_63416;
    } else {

    }

    if ((unsigned long )veb == (unsigned long )((struct i40e_veb *)0)) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "couldn\'t add VEB\n");
      return ((struct i40e_vsi *)0);
    } else {

    }
    vsi->flags = vsi->flags | 2UL;
    uplink_seid = veb->seid;
  } else {

  }
  v_idx = i40e_vsi_mem_alloc(pf, (enum i40e_vsi_type )type);
  if (v_idx < 0) {
    goto err_alloc;
  } else {

  }
  vsi = *(pf->vsi + (unsigned long )v_idx);
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
    goto err_alloc;
  } else {

  }
  vsi->type = (enum i40e_vsi_type )type;
  vsi->veb_idx = (unsigned long )veb != (unsigned long )((struct i40e_veb *)0) ? veb->idx : 65535U;
  if ((unsigned int )type == 0U) {
    pf->lan_vsi = (u16 )v_idx;
  } else
  if ((unsigned int )type == 6U) {
    vsi->vf_id = (u16 )param1;
  } else {

  }
  ret = i40e_get_lump(pf, pf->qp_pile, (int )vsi->alloc_queue_pairs, (int )vsi->idx);
  if (ret < 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "failed to get tracking for %d queues for VSI %d err=%d\n",
              (int )vsi->alloc_queue_pairs, (int )vsi->seid, ret);
    goto err_vsi;
  } else {

  }
  vsi->base_queue = (u16 )ret;
  vsi->uplink_seid = uplink_seid;
  ret = i40e_add_vsi(vsi);
  if (ret != 0) {
    goto err_vsi;
  } else {

  }
  switch ((unsigned int )vsi->type) {
  case 0U: ;
  case 2U: ;
  case 4U: 
  ret = i40e_config_netdev(vsi);
  if (ret != 0) {
    goto err_netdev;
  } else {

  }
  ret = ldv_register_netdev_34(vsi->netdev);
  if (ret != 0) {
    goto err_netdev;
  } else {

  }
  vsi->netdev_registered = 1;
  netif_carrier_off(vsi->netdev);
  i40e_dcbnl_setup(vsi);
  case 7U: 
  ret = i40e_vsi_setup_vectors(vsi);
  if (ret != 0) {
    goto err_msix;
  } else {

  }
  ret = i40e_alloc_rings(vsi);
  if (ret != 0) {
    goto err_rings;
  } else {

  }
  i40e_vsi_map_rings_to_vectors(vsi);
  i40e_vsi_reset_stats(vsi);
  goto ldv_63428;
  default: ;
  goto ldv_63428;
  }
  ldv_63428: ;
  return (vsi);
  err_rings: 
  i40e_vsi_free_q_vectors(vsi);
  err_msix: ;
  if ((int )vsi->netdev_registered) {
    vsi->netdev_registered = 0;
    ldv_unregister_netdev_35(vsi->netdev);
    ldv_free_netdev_36(vsi->netdev);
    vsi->netdev = (struct net_device *)0;
  } else {

  }
  err_netdev: 
  i40e_aq_delete_element(& pf->hw, (int )vsi->seid, (struct i40e_asq_cmd_details *)0);
  err_vsi: 
  i40e_vsi_clear(vsi);
  err_alloc: ;
  return ((struct i40e_vsi *)0);
}
}
static int i40e_veb_get_bw_info(struct i40e_veb *veb ) 
{ 
  struct i40e_aqc_query_switching_comp_ets_config_resp ets_data ;
  struct i40e_aqc_query_switching_comp_bw_config_resp bw_data ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u32 tc_bw_max ;
  int ret ;
  int i ;
  i40e_status tmp ;
  i40e_status tmp___0 ;

  {
  pf = veb->pf;
  hw = & pf->hw;
  ret = 0;
  tmp = i40e_aq_query_switch_comp_bw_config(hw, (int )veb->seid, & bw_data, (struct i40e_asq_cmd_details *)0);
  ret = (int )tmp;
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "query veb bw config failed, aq_err=%d\n",
              (unsigned int )hw->aq.asq_last_status);
    goto out;
  } else {

  }
  tmp___0 = i40e_aq_query_switch_comp_ets_config(hw, (int )veb->seid, & ets_data,
                                                 (struct i40e_asq_cmd_details *)0);
  ret = (int )tmp___0;
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "query veb bw ets config failed, aq_err=%d\n",
              (unsigned int )hw->aq.asq_last_status);
    goto out;
  } else {

  }
  veb->bw_limit = ets_data.port_bw_limit;
  veb->bw_max_quanta = ets_data.tc_bw_max;
  veb->is_abs_credits = (unsigned int )bw_data.absolute_credits_enable != 0U;
  veb->enabled_tc = ets_data.tc_valid_bits;
  tc_bw_max = (u32 )((int )bw_data.tc_bw_max[0] | ((int )bw_data.tc_bw_max[1] << 16));
  i = 0;
  goto ldv_63442;
  ldv_63441: 
  veb->bw_tc_share_credits[i] = bw_data.tc_bw_share_credits[i];
  veb->bw_tc_limit_credits[i] = bw_data.tc_bw_limits[i];
  veb->bw_tc_max_quanta[i] = (unsigned int )((u8 )(tc_bw_max >> i * 4)) & 7U;
  i = i + 1;
  ldv_63442: ;
  if (i <= 7) {
    goto ldv_63441;
  } else {

  }

  out: ;
  return (ret);
}
}
static int i40e_veb_mem_alloc(struct i40e_pf *pf ) 
{ 
  int ret ;
  struct i40e_veb *veb ;
  int i ;
  void *tmp ;

  {
  ret = -2;
  ldv_mutex_lock_37(& pf->switch_mutex);
  i = 0;
  goto ldv_63451;
  ldv_63450: 
  i = i + 1;
  ldv_63451: ;
  if (i <= 15 && (unsigned long )pf->veb[i] != (unsigned long )((struct i40e_veb *)0)) {
    goto ldv_63450;
  } else {

  }

  if (i > 15) {
    ret = -12;
    goto err_alloc_veb;
  } else {

  }
  tmp = kzalloc(272UL, 208U);
  veb = (struct i40e_veb *)tmp;
  if ((unsigned long )veb == (unsigned long )((struct i40e_veb *)0)) {
    ret = -12;
    goto err_alloc_veb;
  } else {

  }
  veb->pf = pf;
  veb->idx = (u16 )i;
  veb->enabled_tc = 1U;
  pf->veb[i] = veb;
  ret = i;
  err_alloc_veb: 
  ldv_mutex_unlock_38(& pf->switch_mutex);
  return (ret);
}
}
static void i40e_switch_branch_release(struct i40e_veb *branch ) 
{ 
  struct i40e_pf *pf ;
  u16 branch_seid ;
  u16 veb_idx ;
  int i ;

  {
  pf = branch->pf;
  branch_seid = branch->seid;
  veb_idx = branch->idx;
  i = 0;
  goto ldv_63463;
  ldv_63462: ;
  if ((unsigned long )pf->veb[i] == (unsigned long )((struct i40e_veb *)0)) {
    goto ldv_63461;
  } else {

  }
  if ((int )(pf->veb[i])->uplink_seid == (int )branch->seid) {
    i40e_switch_branch_release(pf->veb[i]);
  } else {

  }
  ldv_63461: 
  i = i + 1;
  ldv_63463: ;
  if (i <= 15) {
    goto ldv_63462;
  } else {

  }
  i = 0;
  goto ldv_63467;
  ldv_63466: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )i) == (unsigned long )((struct i40e_vsi *)0)) {
    goto ldv_63465;
  } else {

  }
  if ((int )(*(pf->vsi + (unsigned long )i))->uplink_seid == (int )branch_seid && ((*(pf->vsi + (unsigned long )i))->flags & 2UL) == 0UL) {
    i40e_vsi_release(*(pf->vsi + (unsigned long )i));
  } else {

  }
  ldv_63465: 
  i = i + 1;
  ldv_63467: ;
  if ((int )pf->num_alloc_vsi > i) {
    goto ldv_63466;
  } else {

  }

  if ((unsigned long )pf->veb[(int )veb_idx] != (unsigned long )((struct i40e_veb *)0)) {
    i40e_veb_release(pf->veb[(int )veb_idx]);
  } else {

  }
  return;
}
}
static void i40e_veb_clear(struct i40e_veb *veb ) 
{ 
  struct i40e_pf *pf ;

  {
  if ((unsigned long )veb == (unsigned long )((struct i40e_veb *)0)) {
    return;
  } else {

  }
  if ((unsigned long )veb->pf != (unsigned long )((struct i40e_pf *)0)) {
    pf = veb->pf;
    ldv_mutex_lock_39(& pf->switch_mutex);
    if ((unsigned long )pf->veb[(int )veb->idx] == (unsigned long )veb) {
      pf->veb[(int )veb->idx] = (struct i40e_veb *)0;
    } else {

    }
    ldv_mutex_unlock_40(& pf->switch_mutex);
  } else {

  }
  kfree((void const   *)veb);
  return;
}
}
void i40e_veb_release(struct i40e_veb *veb ) 
{ 
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  int i ;
  int n ;

  {
  vsi = (struct i40e_vsi *)0;
  n = 0;
  pf = veb->pf;
  i = 0;
  goto ldv_63481;
  ldv_63480: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0) && (int )(*(pf->vsi + (unsigned long )i))->uplink_seid == (int )veb->seid) {
    n = n + 1;
    vsi = *(pf->vsi + (unsigned long )i);
  } else {

  }
  i = i + 1;
  ldv_63481: ;
  if ((int )pf->num_alloc_vsi > i) {
    goto ldv_63480;
  } else {

  }

  if (n != 1) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "can\'t remove VEB %d with %d VSIs left\n",
              (int )veb->seid, n);
    return;
  } else {

  }
  vsi->flags = vsi->flags & 0xfffffffffffffffdUL;
  if ((unsigned int )veb->uplink_seid != 0U) {
    vsi->uplink_seid = veb->uplink_seid;
    if ((int )veb->uplink_seid == (int )pf->mac_seid) {
      vsi->veb_idx = 65535U;
    } else {
      vsi->veb_idx = veb->veb_idx;
    }
  } else {
    vsi->uplink_seid = (*(pf->vsi + (unsigned long )pf->lan_vsi))->uplink_seid;
    vsi->veb_idx = (*(pf->vsi + (unsigned long )pf->lan_vsi))->veb_idx;
  }
  i40e_aq_delete_element(& pf->hw, (int )veb->seid, (struct i40e_asq_cmd_details *)0);
  i40e_veb_clear(veb);
  return;
}
}
static int i40e_add_veb(struct i40e_veb *veb , struct i40e_vsi *vsi ) 
{ 
  bool is_default ;
  bool is_cloud ;
  int ret ;
  i40e_status tmp ;
  i40e_status tmp___0 ;

  {
  is_default = 0;
  is_cloud = 0;
  tmp = i40e_aq_add_veb(& (veb->pf)->hw, (int )veb->uplink_seid, (int )vsi->seid,
                        (int )veb->enabled_tc, (int )is_default, (int )is_cloud, & veb->seid,
                        (struct i40e_asq_cmd_details *)0);
  ret = (int )tmp;
  if (ret != 0) {
    _dev_info((struct device  const  *)(& ((veb->pf)->pdev)->dev), "couldn\'t add VEB, err %d, aq_err %d\n",
              ret, (unsigned int )(veb->pf)->hw.aq.asq_last_status);
    return (-1);
  } else {

  }
  tmp___0 = i40e_aq_get_veb_parameters(& (veb->pf)->hw, (int )veb->seid, (u16 *)0U,
                                       (bool *)0, & veb->stats_idx, (u16 *)0U, (u16 *)0U,
                                       (struct i40e_asq_cmd_details *)0);
  ret = (int )tmp___0;
  if (ret != 0) {
    _dev_info((struct device  const  *)(& ((veb->pf)->pdev)->dev), "couldn\'t get VEB statistics idx, err %d, aq_err %d\n",
              ret, (unsigned int )(veb->pf)->hw.aq.asq_last_status);
    return (-1);
  } else {

  }
  ret = i40e_veb_get_bw_info(veb);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& ((veb->pf)->pdev)->dev), "couldn\'t get VEB bw info, err %d, aq_err %d\n",
              ret, (unsigned int )(veb->pf)->hw.aq.asq_last_status);
    i40e_aq_delete_element(& (veb->pf)->hw, (int )veb->seid, (struct i40e_asq_cmd_details *)0);
    return (-2);
  } else {

  }
  vsi->uplink_seid = veb->seid;
  vsi->veb_idx = veb->idx;
  vsi->flags = vsi->flags | 2UL;
  return (0);
}
}
struct i40e_veb *i40e_veb_setup(struct i40e_pf *pf , u16 flags , u16 uplink_seid ,
                                u16 vsi_seid , u8 enabled_tc ) 
{ 
  struct i40e_veb *veb ;
  struct i40e_veb *uplink_veb ;
  int vsi_idx ;
  int veb_idx ;
  int ret ;

  {
  uplink_veb = (struct i40e_veb *)0;
  if (((unsigned int )uplink_seid == 0U || (unsigned int )vsi_seid == 0U) && (int )uplink_seid + (int )vsi_seid != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "one, not both seid\'s are 0: uplink=%d vsi=%d\n",
              (int )uplink_seid, (int )vsi_seid);
    return ((struct i40e_veb *)0);
  } else {

  }
  vsi_idx = 0;
  goto ldv_63504;
  ldv_63503: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )vsi_idx) != (unsigned long )((struct i40e_vsi *)0) && (int )(*(pf->vsi + (unsigned long )vsi_idx))->seid == (int )vsi_seid) {
    goto ldv_63502;
  } else {

  }
  vsi_idx = vsi_idx + 1;
  ldv_63504: ;
  if ((int )pf->num_alloc_vsi > vsi_idx) {
    goto ldv_63503;
  } else {

  }
  ldv_63502: ;
  if ((int )pf->num_alloc_vsi <= vsi_idx && (unsigned int )vsi_seid != 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "vsi seid %d not found\n",
              (int )vsi_seid);
    return ((struct i40e_veb *)0);
  } else {

  }
  if ((unsigned int )uplink_seid != 0U && (int )pf->mac_seid != (int )uplink_seid) {
    veb_idx = 0;
    goto ldv_63507;
    ldv_63506: ;
    if ((unsigned long )pf->veb[veb_idx] != (unsigned long )((struct i40e_veb *)0) && (int )(pf->veb[veb_idx])->seid == (int )uplink_seid) {
      uplink_veb = pf->veb[veb_idx];
      goto ldv_63505;
    } else {

    }
    veb_idx = veb_idx + 1;
    ldv_63507: ;
    if (veb_idx <= 15) {
      goto ldv_63506;
    } else {

    }
    ldv_63505: ;
    if ((unsigned long )uplink_veb == (unsigned long )((struct i40e_veb *)0)) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "uplink seid %d not found\n",
                (int )uplink_seid);
      return ((struct i40e_veb *)0);
    } else {

    }
  } else {

  }
  veb_idx = i40e_veb_mem_alloc(pf);
  if (veb_idx < 0) {
    goto err_alloc;
  } else {

  }
  veb = pf->veb[veb_idx];
  veb->flags = flags;
  veb->uplink_seid = uplink_seid;
  veb->veb_idx = (unsigned long )uplink_veb != (unsigned long )((struct i40e_veb *)0) ? uplink_veb->idx : 65535U;
  veb->enabled_tc = (unsigned int )enabled_tc != 0U ? enabled_tc : 1U;
  ret = i40e_add_veb(veb, *(pf->vsi + (unsigned long )vsi_idx));
  if (ret != 0) {
    goto err_veb;
  } else {

  }
  if ((int )pf->lan_vsi == vsi_idx) {
    pf->lan_veb = veb->idx;
  } else {

  }
  return (veb);
  err_veb: 
  i40e_veb_clear(veb);
  err_alloc: ;
  return ((struct i40e_veb *)0);
}
}
static void i40e_setup_pf_switch_element(struct i40e_pf *pf , struct i40e_aqc_switch_config_element_resp *ele ,
                                         u16 num_reported , bool printconfig ) 
{ 
  u16 downlink_seid ;
  u16 uplink_seid ;
  u8 element_type ;
  u16 seid ;
  int v ;

  {
  downlink_seid = ele->downlink_seid;
  uplink_seid = ele->uplink_seid;
  element_type = ele->element_type;
  seid = ele->seid;
  if ((int )printconfig) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "type=%d seid=%d uplink=%d downlink=%d\n",
              (int )element_type, (int )seid, (int )uplink_seid, (int )downlink_seid);
  } else {

  }
  switch ((int )element_type) {
  case 1: 
  pf->mac_seid = seid;
  goto ldv_63521;
  case 17: ;
  if ((int )pf->mac_seid != (int )uplink_seid) {
    goto ldv_63521;
  } else {

  }
  if ((unsigned int )pf->lan_veb == 65535U) {
    v = 0;
    goto ldv_63526;
    ldv_63525: ;
    if ((unsigned long )pf->veb[v] != (unsigned long )((struct i40e_veb *)0) && (int )(pf->veb[v])->seid == (int )seid) {
      pf->lan_veb = (u16 )v;
      goto ldv_63524;
    } else {

    }
    v = v + 1;
    ldv_63526: ;
    if (v <= 15) {
      goto ldv_63525;
    } else {

    }
    ldv_63524: ;
    if ((unsigned int )pf->lan_veb == 65535U) {
      v = i40e_veb_mem_alloc(pf);
      if (v < 0) {
        goto ldv_63521;
      } else {

      }
      pf->lan_veb = (u16 )v;
    } else {

    }
  } else {

  }
  (pf->veb[(int )pf->lan_veb])->seid = seid;
  (pf->veb[(int )pf->lan_veb])->uplink_seid = pf->mac_seid;
  (pf->veb[(int )pf->lan_veb])->pf = pf;
  (pf->veb[(int )pf->lan_veb])->veb_idx = 65535U;
  goto ldv_63521;
  case 19: ;
  if ((unsigned int )num_reported != 1U) {
    goto ldv_63521;
  } else {

  }
  pf->mac_seid = uplink_seid;
  pf->pf_seid = downlink_seid;
  pf->main_vsi_seid = seid;
  if ((int )printconfig) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "pf_seid=%d main_vsi_seid=%d\n",
              (int )pf->pf_seid, (int )pf->main_vsi_seid);
  } else {

  }
  goto ldv_63521;
  case 2: ;
  case 3: ;
  case 4: ;
  case 6: ;
  case 16: ;
  case 18: ;
  goto ldv_63521;
  default: 
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "unknown element type=%d seid=%d\n",
            (int )element_type, (int )seid);
  goto ldv_63521;
  }
  ldv_63521: ;
  return;
}
}
int i40e_fetch_switch_configuration(struct i40e_pf *pf , bool printconfig ) 
{ 
  struct i40e_aqc_get_switch_config_resp *sw_config ;
  u16 next_seid ;
  int ret ;
  u8 *aq_buf ;
  int i ;
  void *tmp ;
  u16 num_reported ;
  u16 num_total ;
  i40e_status tmp___0 ;
  struct i40e_aqc_switch_config_element_resp *ele ;

  {
  next_seid = 0U;
  ret = 0;
  tmp = kzalloc(512UL, 208U);
  aq_buf = (u8 *)tmp;
  if ((unsigned long )aq_buf == (unsigned long )((u8 *)0U)) {
    return (-12);
  } else {

  }
  sw_config = (struct i40e_aqc_get_switch_config_resp *)aq_buf;
  ldv_63550: 
  tmp___0 = i40e_aq_get_switch_config(& pf->hw, sw_config, 512, & next_seid, (struct i40e_asq_cmd_details *)0);
  ret = (int )tmp___0;
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "get switch config failed %d aq_err=%x\n",
              ret, (unsigned int )pf->hw.aq.asq_last_status);
    kfree((void const   *)aq_buf);
    return (-2);
  } else {

  }
  num_reported = sw_config->header.num_reported;
  num_total = sw_config->header.num_total;
  if ((int )printconfig) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "header: %d reported %d total\n",
              (int )num_reported, (int )num_total);
  } else {

  }
  i = 0;
  goto ldv_63548;
  ldv_63547: 
  ele = (struct i40e_aqc_switch_config_element_resp *)(& sw_config->element) + (unsigned long )i;
  i40e_setup_pf_switch_element(pf, ele, (int )num_reported, (int )printconfig);
  i = i + 1;
  ldv_63548: ;
  if ((int )num_reported > i) {
    goto ldv_63547;
  } else {

  }

  if ((unsigned int )next_seid != 0U) {
    goto ldv_63550;
  } else {

  }
  kfree((void const   *)aq_buf);
  return (ret);
}
}
static int i40e_setup_pf_switch(struct i40e_pf *pf , bool reinit ) 
{ 
  int ret ;
  struct i40e_vsi *vsi ;
  u16 uplink_seid ;
  u8 enabled_tc ;

  {
  ret = i40e_fetch_switch_configuration(pf, 0);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "couldn\'t fetch switch config, err %d, aq_err %d\n",
              ret, (unsigned int )pf->hw.aq.asq_last_status);
    return (ret);
  } else {

  }
  i40e_pf_reset_stats(pf);
  if ((unsigned int )pf->lan_vsi == 65535U || (int )reinit) {
    vsi = (struct i40e_vsi *)0;
    if ((unsigned int )pf->lan_veb != 65535U && (unsigned long )pf->veb[(int )pf->lan_veb] != (unsigned long )((struct i40e_veb *)0)) {
      uplink_seid = (pf->veb[(int )pf->lan_veb])->seid;
    } else {
      uplink_seid = pf->mac_seid;
    }
    if ((unsigned int )pf->lan_vsi == 65535U) {
      vsi = i40e_vsi_setup(pf, 0, (int )uplink_seid, 0U);
    } else
    if ((int )reinit) {
      vsi = i40e_vsi_reinit_setup(*(pf->vsi + (unsigned long )pf->lan_vsi));
    } else {

    }
    if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "setup of MAIN VSI failed\n");
      i40e_fdir_teardown(pf);
      return (-11);
    } else {

    }
  } else {
    enabled_tc = (*(pf->vsi + (unsigned long )pf->lan_vsi))->tc_config.enabled_tc;
    (*(pf->vsi + (unsigned long )pf->lan_vsi))->tc_config.enabled_tc = 0U;
    (*(pf->vsi + (unsigned long )pf->lan_vsi))->seid = pf->main_vsi_seid;
    i40e_vsi_config_tc(*(pf->vsi + (unsigned long )pf->lan_vsi), (int )enabled_tc);
  }
  i40e_vlan_stripping_disable(*(pf->vsi + (unsigned long )pf->lan_vsi));
  i40e_fdir_sb_setup(pf);
  ret = i40e_setup_pf_filter_control(pf);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "setup_pf_filter_control failed: %d\n",
              ret);
  } else {

  }
  if ((pf->flags & 64ULL) != 0ULL) {
    i40e_config_rss(pf);
  } else {

  }
  i40e_aq_get_link_info(& pf->hw, 1, (struct i40e_link_status *)0, (struct i40e_asq_cmd_details *)0);
  i40e_link_event(pf);
  pf->fc_autoneg_status = ((int )pf->hw.phy.link_info.an_info & 1) != 0;
  i40e_ptp_init(pf);
  return (ret);
}
}
static void i40e_determine_queue_usage(struct i40e_pf *pf ) 
{ 
  int queues_left ;
  u16 tmp ;
  u16 tmp___0 ;
  int __max1 ;
    klee_make_symbolic(&__max1, sizeof(int), "__max1");
  int __max2 ;
    klee_make_symbolic(&__max2, sizeof(int), "__max2");
  unsigned int tmp___1 ;
  int __min1 ;
  int __min2 ;
  int __min1___0 ;
  int __min2___0 ;
  int __min1___1 ;
  int __min2___1 ;

  {
  pf->num_lan_qps = 0U;
  pf->num_fcoe_qps = 0U;
  queues_left = (int )pf->hw.func_caps.num_tx_qp;
  if (queues_left == 1 || (pf->flags & 8ULL) == 0ULL) {
    queues_left = 0;
    tmp = 1U;
    pf->num_lan_qps = tmp;
    pf->rss_size = tmp;
    pf->flags = pf->flags & 0xffffffffdf97f73fULL;
  } else
  if ((pf->flags & 543162432ULL) == 0ULL) {
    tmp___0 = 1U;
    pf->num_lan_qps = tmp___0;
    pf->rss_size = tmp___0;
    queues_left = queues_left - (int )pf->num_lan_qps;
    pf->flags = pf->flags & 0xffffffffff8ff73fULL;
  } else {
    if ((pf->flags & 536870912ULL) != 0ULL && queues_left <= 7) {
      pf->flags = pf->flags & 0xffffffffdfffffffULL;
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "not enough queues for DCB. DCB is disabled.\n");
    } else {

    }
    __max1 = (int )pf->rss_size_max;
    tmp___1 = cpumask_weight(cpu_online_mask);
    __max2 = (int )tmp___1;
    pf->num_lan_qps = (u16 )(__max1 > __max2 ? __max1 : __max2);
    __min1 = (int )pf->num_lan_qps;
    __min2 = (int )pf->hw.func_caps.num_tx_qp;
    pf->num_lan_qps = (u16 )(__min1 < __min2 ? __min1 : __min2);
    queues_left = queues_left - (int )pf->num_lan_qps;
  }
  if ((pf->flags & 2048ULL) != 0ULL) {
    if (queues_left > 7) {
      pf->num_fcoe_qps = 8U;
    } else
    if (queues_left > 0) {
      pf->num_fcoe_qps = 1U;
    } else {
      pf->num_fcoe_qps = 0U;
      pf->flags = pf->flags & 0xfffffffffffff7ffULL;
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "not enough queues for FCoE. FCoE feature will be disabled\n");
    }
    queues_left = queues_left - (int )pf->num_fcoe_qps;
  } else {

  }
  if ((pf->flags & 2097152ULL) != 0ULL) {
    if (queues_left > 1) {
      queues_left = queues_left + -1;
    } else {
      pf->flags = pf->flags & 0xffffffffffdfffffULL;
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "not enough queues for Flow Director. Flow Director feature is disabled\n");
    }
  } else {

  }
  if ((((pf->flags & 524288ULL) != 0ULL && (unsigned int )pf->num_vf_qps != 0U) && (unsigned int )pf->num_req_vfs != 0U) && queues_left != 0) {
    __min1___0 = (int )pf->num_req_vfs;
    __min2___0 = queues_left / (int )pf->num_vf_qps;
    pf->num_req_vfs = (u16 )(__min1___0 < __min2___0 ? __min1___0 : __min2___0);
    queues_left = queues_left - (int )pf->num_req_vfs * (int )pf->num_vf_qps;
  } else {

  }
  if ((((pf->flags & 128ULL) != 0ULL && (unsigned int )pf->num_vmdq_vsis != 0U) && (unsigned int )pf->num_vmdq_qps != 0U) && queues_left != 0) {
    __min1___1 = (int )pf->num_vmdq_vsis;
    __min2___1 = queues_left / (int )pf->num_vmdq_qps;
    pf->num_vmdq_vsis = (u16 )(__min1___1 < __min2___1 ? __min1___1 : __min2___1);
    queues_left = queues_left - (int )pf->num_vmdq_vsis * (int )pf->num_vmdq_qps;
  } else {

  }
  pf->queues_left = queues_left;
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "fcoe queues = %d\n", (int )pf->num_fcoe_qps);
  return;
}
}
static int i40e_setup_pf_filter_control(struct i40e_pf *pf ) 
{ 
  struct i40e_filter_control_settings *settings ;
  i40e_status tmp ;

  {
  settings = & pf->filter_settings;
  settings->hash_lut_size = 0;
  if ((pf->flags & 6291456ULL) != 0ULL) {
    settings->enable_fdir = 1;
  } else {

  }
  settings->enable_ethtype = 1;
  settings->enable_macvlan = 1;
  tmp = i40e_set_filter_control(& pf->hw, settings);
  if ((int )tmp != 0) {
    return (-2);
  } else {

  }
  return (0);
}
}
static void i40e_print_features(struct i40e_pf *pf ) 
{ 
  struct i40e_hw *hw ;
  char *buf ;
  char *string ;
  void *tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;
  long tmp___10 ;

  {
  hw = & pf->hw;
  tmp = kzalloc(255UL, 208U);
  string = (char *)tmp;
  if ((unsigned long )string == (unsigned long )((char *)0)) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Features string allocation failed\n");
    return;
  } else {

  }
  buf = string;
  tmp___0 = sprintf(string, "Features: PF-id[%d] ", (int )hw->pf_id);
  buf = buf + (unsigned long )tmp___0;
  tmp___1 = sprintf(buf, "VFs: %d ", (int )pf->num_req_vfs);
  buf = buf + (unsigned long )tmp___1;
  tmp___2 = sprintf(buf, "VSIs: %d QP: %d RX: %s ", pf->hw.func_caps.num_vsis, (int )(*(pf->vsi + (unsigned long )pf->lan_vsi))->num_queue_pairs,
                    (pf->flags & 32ULL) != 0ULL ? (char *)"PS" : (char *)"1BUF");
  buf = buf + (unsigned long )tmp___2;
  if ((pf->flags & 64ULL) != 0ULL) {
    tmp___3 = sprintf(buf, "RSS ");
    buf = buf + (unsigned long )tmp___3;
  } else {

  }
  if ((pf->flags & 4194304ULL) != 0ULL) {
    tmp___4 = sprintf(buf, "FD_ATR ");
    buf = buf + (unsigned long )tmp___4;
  } else {

  }
  if ((pf->flags & 2097152ULL) != 0ULL) {
    tmp___5 = sprintf(buf, "FD_SB ");
    buf = buf + (unsigned long )tmp___5;
    tmp___6 = sprintf(buf, "NTUPLE ");
    buf = buf + (unsigned long )tmp___6;
  } else {

  }
  if ((pf->flags & 536870912ULL) != 0ULL) {
    tmp___7 = sprintf(buf, "DCB ");
    buf = buf + (unsigned long )tmp___7;
  } else {

  }
  if ((pf->flags & 33554432ULL) != 0ULL) {
    tmp___8 = sprintf(buf, "PTP ");
    buf = buf + (unsigned long )tmp___8;
  } else {

  }
  if ((pf->flags & 2048ULL) != 0ULL) {
    tmp___9 = sprintf(buf, "FCOE ");
    buf = buf + (unsigned long )tmp___9;
  } else {

  }
  tmp___10 = ldv__builtin_expect((unsigned long )(string + 255UL) < (unsigned long )buf,
                              0L);
  if (tmp___10 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_main.c"),
                         "i" (9617), "i" (12UL));
    ldv_63586: ;
    goto ldv_63586;
  } else {

  }
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%s\n", string);
  kfree((void const   *)string);
  return;
}
}
static int i40e_probe(struct pci_dev *pdev , struct pci_device_id  const  *ent ) 
{ 
  struct i40e_aq_get_phy_abilities_resp abilities ;
  unsigned long ioremap_len ;
    klee_make_symbolic(&ioremap_len, sizeof(long), "ioremap_len");
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u16 pfs_found ;
  u16 link_status ;
  int err ;
  u32 len ;
  u32 i ;
  int tmp ;
  void *tmp___0 ;
  unsigned long __min1 ;
  unsigned long __min2 ;
  void *tmp___1 ;
  unsigned int tmp___2 ;
  i40e_status tmp___3 ;
  char const   *tmp___4 ;
  char const   *tmp___5 ;
  i40e_status tmp___6 ;
  i40e_status tmp___7 ;
  char *tmp___8 ;
  i40e_status tmp___9 ;
  i40e_status tmp___10 ;
  bool tmp___11 ;
  int tmp___12 ;
    klee_make_symbolic(&tmp___12, sizeof(int), "tmp___12");
  bool tmp___13 ;
  i40e_status tmp___14 ;
  bool tmp___15 ;
  int tmp___16 ;
    klee_make_symbolic(&tmp___16, sizeof(int), "tmp___16");
  struct lock_class_key __key ;
  atomic_long_t __constr_expr_0 ;
  void *tmp___17 ;
  int tmp___18 ;
    klee_make_symbolic(&tmp___18, sizeof(int), "tmp___18");
  int tmp___19 ;
    klee_make_symbolic(&tmp___19, sizeof(int), "tmp___19");
  i40e_status tmp___20 ;
  i40e_status tmp___21 ;
  u32 val ;
  int tmp___22 ;
    klee_make_symbolic(&tmp___22, sizeof(int), "tmp___22");
  int tmp___23 ;
    klee_make_symbolic(&tmp___23, sizeof(int), "tmp___23");
  int tmp___24 ;
    klee_make_symbolic(&tmp___24, sizeof(int), "tmp___24");
  unsigned long tmp___25 ;
    klee_make_symbolic(&tmp___25, sizeof(long), "tmp___25");
  enum i40e_status_code tmp___26 ;
  int tmp___27 ;
    klee_make_symbolic(&tmp___27, sizeof(int), "tmp___27");

  {
  err = 0;
  err = pci_enable_device_mem(pdev);
  if (err != 0) {
    return (err);
  } else {

  }
  err = dma_set_mask_and_coherent(& pdev->dev, 0xffffffffffffffffULL);
  if (err != 0) {
    err = dma_set_mask_and_coherent(& pdev->dev, 4294967295ULL);
    if (err != 0) {
      dev_err((struct device  const  *)(& pdev->dev), "DMA configuration failed: 0x%x\n",
              err);
      goto err_dma;
    } else {

    }
  } else {

  }
  tmp = pci_select_bars(pdev, 512UL);
  err = pci_request_selected_regions(pdev, tmp, (char const   *)(& i40e_driver_name));
  if (err != 0) {
    _dev_info((struct device  const  *)(& pdev->dev), "pci_request_selected_regions failed %d\n",
              err);
    goto err_pci_reg;
  } else {

  }
  pci_enable_pcie_error_reporting(pdev);
  pci_set_master(pdev);
  tmp___0 = kzalloc(135240UL, 208U);
  pf = (struct i40e_pf *)tmp___0;
  if ((unsigned long )pf == (unsigned long )((struct i40e_pf *)0)) {
    err = -12;
    goto err_pf_alloc;
  } else {

  }
  pf->next_vsi = 0U;
  pf->pdev = pdev;
  set_bit(3L, (unsigned long volatile   *)(& pf->state));
  hw = & pf->hw;
  hw->back = (void *)pf;
  __min1 = pdev->resource[0].start != 0ULL || pdev->resource[0].end != pdev->resource[0].start ? (unsigned long )((pdev->resource[0].end - pdev->resource[0].start) + 1ULL) : 0UL;
  __min2 = 4128768UL;
  ioremap_len = __min1 < __min2 ? __min1 : __min2;
  tmp___1 = ioremap(pdev->resource[0].start, ioremap_len);
  hw->hw_addr = (u8 *)tmp___1;
  if ((unsigned long )hw->hw_addr == (unsigned long )((u8 *)0U)) {
    err = -5;
    _dev_info((struct device  const  *)(& pdev->dev), "ioremap(0x%04x, 0x%04x) failed: 0x%x\n",
              (unsigned int )pdev->resource[0].start, pdev->resource[0].start != 0ULL || pdev->resource[0].end != pdev->resource[0].start ? (unsigned int )((pdev->resource[0].end - pdev->resource[0].start) + 1ULL) : 0U,
              err);
    goto err_ioremap;
  } else {

  }
  hw->vendor_id = pdev->vendor;
  hw->device_id = pdev->device;
  pci_read_config_byte((struct pci_dev  const  *)pdev, 8, & hw->revision_id);
  hw->subsystem_vendor_id = pdev->subsystem_vendor;
  hw->subsystem_device_id = pdev->subsystem_device;
  hw->bus.device = (unsigned int )((u16 )(pdev->devfn >> 3)) & 31U;
  hw->bus.func = (unsigned int )((u16 )pdev->devfn) & 7U;
  pf->instance = pfs_found;
  if (debug != -1) {
    pf->msg_enable = pf->hw.debug_mask;
    pf->msg_enable = (u32 )debug;
  } else {

  }
  if ((unsigned int )hw->revision_id == 0U) {
    tmp___2 = readl((void const volatile   *)hw->hw_addr + 1221888U);
    if ((int )tmp___2 & 1) {
      writel(1U, (void volatile   *)hw->hw_addr + 754064U);
      readl((void const volatile   *)hw->hw_addr + 745772U);
      msleep(200U);
      pf->corer_count = (u16 )((int )pf->corer_count + 1);
      i40e_clear_pxe_mode(hw);
    } else {

    }
  } else {

  }
  i40e_clear_hw(hw);
  tmp___3 = i40e_pf_reset(hw);
  err = (int )tmp___3;
  if (err != 0) {
    _dev_info((struct device  const  *)(& pdev->dev), "Initial pf_reset failed: %d\n",
              err);
    goto err_pf_reset;
  } else {

  }
  pf->pfr_count = (u16 )((int )pf->pfr_count + 1);
  hw->aq.num_arq_entries = 256U;
  hw->aq.num_asq_entries = 256U;
  hw->aq.arq_buf_size = 4096U;
  hw->aq.asq_buf_size = 4096U;
  pf->adminq_work_limit = 32U;
  tmp___4 = dev_name((struct device  const  *)(& pdev->dev));
  tmp___5 = dev_driver_string((struct device  const  *)(& (pf->pdev)->dev));
  snprintf((char *)(& pf->int_name), 24UL, "%s-%s:misc", tmp___5, tmp___4);
  tmp___6 = i40e_init_shared_code(hw);
  err = (int )tmp___6;
  if (err != 0) {
    _dev_info((struct device  const  *)(& pdev->dev), "init_shared_code failed: %d\n",
              err);
    goto err_pf_reset;
  } else {

  }
  pf->hw.fc.requested_mode = 0;
  tmp___7 = i40e_init_adminq(hw);
  err = (int )tmp___7;
  tmp___8 = i40e_fw_version_str(hw);
  _dev_info((struct device  const  *)(& pdev->dev), "%s\n", tmp___8);
  if (err != 0) {
    _dev_info((struct device  const  *)(& pdev->dev), "The driver for the device stopped because the NVM image is newer than expected. You must install the most recent version of the network driver.\n");
    goto err_pf_reset;
  } else {

  }
  if ((unsigned int )hw->aq.api_maj_ver == 1U && (unsigned int )hw->aq.api_min_ver > 2U) {
    _dev_info((struct device  const  *)(& pdev->dev), "The driver for the device detected a newer version of the NVM image than expected. Please install the most recent version of the network driver.\n");
  } else
  if ((unsigned int )hw->aq.api_maj_ver == 0U || (unsigned int )hw->aq.api_min_ver == 0U) {
    _dev_info((struct device  const  *)(& pdev->dev), "The driver for the device detected an older version of the NVM image than expected. Please update the NVM image.\n");
  } else {

  }
  i40e_verify_eeprom(pf);
  if ((unsigned int )hw->revision_id == 0U) {
    dev_warn((struct device  const  *)(& pdev->dev), "This device is a pre-production adapter/LOM. Please be aware there may be issues with your hardware. If you are experiencing problems please contact your Intel or hardware representative who provided you with this hardware.\n");
  } else {

  }
  i40e_clear_pxe_mode(hw);
  err = i40e_get_capabilities(pf);
  if (err != 0) {
    goto err_adminq_setup;
  } else {

  }
  err = i40e_sw_init(pf);
  if (err != 0) {
    _dev_info((struct device  const  *)(& pdev->dev), "sw_init failed: %d\n", err);
    goto err_sw_init;
  } else {

  }
  tmp___9 = i40e_init_lan_hmc(hw, hw->func_caps.num_tx_qp, hw->func_caps.num_rx_qp,
                              pf->fcoe_hmc_cntx_num, pf->fcoe_hmc_filt_num);
  err = (int )tmp___9;
  if (err != 0) {
    _dev_info((struct device  const  *)(& pdev->dev), "init_lan_hmc failed: %d\n",
              err);
    goto err_init_lan_hmc;
  } else {

  }
  tmp___10 = i40e_configure_lan_hmc(hw, 1);
  err = (int )tmp___10;
  if (err != 0) {
    _dev_info((struct device  const  *)(& pdev->dev), "configure_lan_hmc failed: %d\n",
              err);
    err = -2;
    goto err_configure_lan_hmc;
  } else {

  }
  if (((unsigned int )pf->hw.aq.fw_maj_ver == 4U && (unsigned int )pf->hw.aq.fw_min_ver <= 2U) || (unsigned int )pf->hw.aq.fw_maj_ver <= 3U) {
    _dev_info((struct device  const  *)(& pdev->dev), "Stopping firmware LLDP agent.\n");
    i40e_aq_stop_lldp(hw, 1, (struct i40e_asq_cmd_details *)0);
  } else {

  }
  i40e_get_mac_addr(hw, (u8 *)(& hw->mac.addr));
  tmp___11 = is_valid_ether_addr((u8 const   *)(& hw->mac.addr));
  if (tmp___11) {
    tmp___12 = 0;
  } else {
    tmp___12 = 1;
  }
  if (tmp___12) {
    _dev_info((struct device  const  *)(& pdev->dev), "invalid MAC address %pM\n",
              (u8 *)(& hw->mac.addr));
    err = -5;
    goto err_mac_addr;
  } else {

  }
  _dev_info((struct device  const  *)(& pdev->dev), "MAC address: %pM\n", (u8 *)(& hw->mac.addr));
  ether_addr_copy((u8 *)(& hw->mac.perm_addr), (u8 const   *)(& hw->mac.addr));
  i40e_get_port_mac_addr(hw, (u8 *)(& hw->mac.port_addr));
  tmp___13 = is_valid_ether_addr((u8 const   *)(& hw->mac.port_addr));
  if ((int )tmp___13) {
    pf->flags = pf->flags | 268435456ULL;
  } else {

  }
  tmp___14 = i40e_get_san_mac_addr(hw, (u8 *)(& hw->mac.san_addr));
  err = (int )tmp___14;
  if (err != 0) {
    _dev_info((struct device  const  *)(& pdev->dev), "(non-fatal) SAN MAC retrieval failed: %d\n",
              err);
  } else {

  }
  tmp___15 = is_valid_ether_addr((u8 const   *)(& hw->mac.san_addr));
  if (tmp___15) {
    tmp___16 = 0;
  } else {
    tmp___16 = 1;
  }
  if (tmp___16) {
    dev_warn((struct device  const  *)(& pdev->dev), "invalid SAN MAC address %pM, falling back to LAN MAC\n",
             (u8 *)(& hw->mac.san_addr));
    ether_addr_copy((u8 *)(& hw->mac.san_addr), (u8 const   *)(& hw->mac.addr));
  } else {

  }
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "SAN MAC: %pM\n", (u8 *)(& hw->mac.san_addr));
  pci_set_drvdata(pdev, (void *)pf);
  pci_save_state(pdev);
  err = i40e_init_pf_dcb(pf);
  if (err != 0) {
    _dev_info((struct device  const  *)(& pdev->dev), "DCB init failed %d, disabled\n",
              err);
    pf->flags = pf->flags & 0xffffffffdfffffffULL;
  } else {

  }
  reg_timer_5(& pf->service_timer, & i40e_service_timer, (unsigned long )pf);
  pf->service_timer_period = 250UL;
  __init_work(& pf->service_task, 0);
  __constr_expr_0.counter = 137438953408L;
  pf->service_task.data = __constr_expr_0;
  lockdep_init_map(& pf->service_task.lockdep_map, "(&pf->service_task)", & __key,
                   0);
  INIT_LIST_HEAD(& pf->service_task.entry);
  pf->service_task.func = & i40e_service_task;
  clear_bit(5L, (unsigned long volatile   *)(& pf->state));
  pf->flags = pf->flags | 512ULL;
  pf->link_check_timeout = jiffies;
  pf->wol_en = 0;
  device_set_wakeup_enable(& (pf->pdev)->dev, (int )pf->wol_en);
  i40e_determine_queue_usage(pf);
  err = i40e_init_interrupt_scheme(pf);
  if (err != 0) {
    goto err_switch_setup;
  } else {

  }
  if (pf->hw.func_caps.num_vsis <= 50U) {
    pf->num_alloc_vsi = 51U;
  } else {
    pf->num_alloc_vsi = (u16 )pf->hw.func_caps.num_vsis;
  }
  len = (u32 )pf->num_alloc_vsi * 8U;
  tmp___17 = kzalloc((size_t )len, 208U);
  pf->vsi = (struct i40e_vsi **)tmp___17;
  if ((unsigned long )pf->vsi == (unsigned long )((struct i40e_vsi **)0)) {
    err = -12;
    goto err_switch_setup;
  } else {

  }
  if ((pf->flags & 524288ULL) != 0ULL && (pf->flags & 8ULL) != 0ULL) {
    tmp___19 = constant_test_bit(20L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___19 == 0) {
      tmp___18 = pci_num_vf(pdev);
      if (tmp___18 != 0) {
        pf->flags = pf->flags | 1099511627776ULL;
      } else {

      }
    } else {

    }
  } else {

  }
  err = i40e_setup_pf_switch(pf, 0);
  if (err != 0) {
    _dev_info((struct device  const  *)(& pdev->dev), "setup_pf_switch failed: %d\n",
              err);
    goto err_vsis;
  } else {

  }
  i = 0U;
  goto ldv_63619;
  ldv_63618: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0) && (unsigned int )(*(pf->vsi + (unsigned long )i))->type == 7U) {
    i40e_vsi_open(*(pf->vsi + (unsigned long )i));
    goto ldv_63617;
  } else {

  }
  i = i + 1U;
  ldv_63619: ;
  if ((u32 )pf->num_alloc_vsi > i) {
    goto ldv_63618;
  } else {

  }
  ldv_63617: 
  tmp___20 = i40e_aq_set_phy_int_mask(& pf->hw, 258, (struct i40e_asq_cmd_details *)0);
  err = (int )tmp___20;
  if (err != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "set phy mask fail, aq_err %d\n",
              err);
  } else {

  }
  if (((unsigned int )pf->hw.aq.fw_maj_ver == 4U && (unsigned int )pf->hw.aq.fw_min_ver <= 32U) || (unsigned int )pf->hw.aq.fw_maj_ver <= 3U) {
    msleep(75U);
    tmp___21 = i40e_aq_set_link_restart_an(& pf->hw, 1, (struct i40e_asq_cmd_details *)0);
    err = (int )tmp___21;
    if (err != 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "link restart failed, aq_err=%d\n",
                (unsigned int )pf->hw.aq.asq_last_status);
    } else {

    }
  } else {

  }
  clear_bit(3L, (unsigned long volatile   *)(& pf->state));
  if ((pf->flags & 8ULL) != 0ULL) {
    err = i40e_setup_misc_vector(pf);
    if (err != 0) {
      _dev_info((struct device  const  *)(& pdev->dev), "setup of misc vector failed: %d\n",
                err);
      goto err_vsis;
    } else {

    }
  } else {

  }
  if ((pf->flags & 524288ULL) != 0ULL && (pf->flags & 8ULL) != 0ULL) {
    tmp___24 = constant_test_bit(20L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___24 == 0) {
      val = readl((void const volatile   *)hw->hw_addr + 258304U);
      val = val & 4294967279U;
      writel(val, (void volatile   *)hw->hw_addr + 258304U);
      readl((void const volatile   *)hw->hw_addr + 745772U);
      tmp___23 = pci_num_vf(pdev);
      if (tmp___23 != 0) {
        _dev_info((struct device  const  *)(& pdev->dev), "Active VFs found, allocating resources.\n");
        tmp___22 = pci_num_vf(pdev);
        err = i40e_alloc_vfs(pf, (int )((u16 )tmp___22));
        if (err != 0) {
          _dev_info((struct device  const  *)(& pdev->dev), "Error %d allocating resources for existing VFs\n",
                    err);
        } else {

        }
      } else {

      }
    } else {

    }
  } else {

  }
  pfs_found = (u16 )((int )pfs_found + 1);
  i40e_dbg_pf_init(pf);
  i40e_send_version(pf);
  tmp___25 = round_jiffies(pf->service_timer_period + (unsigned long )jiffies);
  ldv_mod_timer_41(& pf->service_timer, tmp___25);
  i40e_fcoe_vsi_setup(pf);
  pcie_capability_read_word(pf->pdev, 18, & link_status);
  i40e_set_pci_config_data(hw, (int )link_status);
  _dev_info((struct device  const  *)(& pdev->dev), "PCI-Express: %s %s\n", (unsigned int )hw->bus.speed != 8000U ? ((unsigned int )hw->bus.speed != 5000U ? ((unsigned int )hw->bus.speed == 2500U ? (char *)"Speed 2.5GT/s" : (char *)"Unknown") : (char *)"Speed 5.0GT/s") : (char *)"Speed 8.0GT/s",
            (unsigned int )hw->bus.width != 8U ? ((unsigned int )hw->bus.width != 4U ? ((unsigned int )hw->bus.width != 2U ? ((unsigned int )hw->bus.width == 1U ? (char *)"Width x1" : (char *)"Unknown") : (char *)"Width x2") : (char *)"Width x4") : (char *)"Width x8");
  if ((unsigned int )hw->bus.width <= 7U || (unsigned int )hw->bus.speed <= 7999U) {
    dev_warn((struct device  const  *)(& pdev->dev), "PCI-Express bandwidth available for this device may be insufficient for optimal performance.\n");
    dev_warn((struct device  const  *)(& pdev->dev), "Please move the device to a different PCI-e link with more lanes and/or higher transfer rate.\n");
  } else {

  }
  tmp___26 = i40e_aq_get_phy_capabilities(hw, 0, 0, & abilities, (struct i40e_asq_cmd_details *)0);
  err = (int )tmp___26;
  if (err != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "get phy abilities failed, aq_err %d, advertised speed settings may not be correct\n",
              err);
  } else {

  }
  pf->hw.phy.link_info.requested_speeds = abilities.link_speed;
  i40e_print_features(pf);
  return (0);
  err_vsis: 
  set_bit(3L, (unsigned long volatile   *)(& pf->state));
  i40e_clear_interrupt_scheme(pf);
  kfree((void const   *)pf->vsi);
  err_switch_setup: 
  i40e_reset_interrupt_capability(pf);
  ldv_del_timer_sync_42(& pf->service_timer);
  err_mac_addr: ;
  err_configure_lan_hmc: 
  i40e_shutdown_lan_hmc(hw);
  err_init_lan_hmc: 
  kfree((void const   *)pf->qp_pile);
  err_sw_init: ;
  err_adminq_setup: 
  i40e_shutdown_adminq(hw);
  err_pf_reset: 
  iounmap((void volatile   *)hw->hw_addr);
  err_ioremap: 
  kfree((void const   *)pf);
  err_pf_alloc: 
  pci_disable_pcie_error_reporting(pdev);
  tmp___27 = pci_select_bars(pdev, 512UL);
  pci_release_selected_regions(pdev, tmp___27);
  err_pci_reg: ;
  err_dma: 
  pci_disable_device(pdev);
  return (err);
}
}
static void i40e_remove(struct pci_dev *pdev ) 
{ 
  struct i40e_pf *pf ;
  void *tmp ;
  i40e_status ret_code ;
  int i ;
  int tmp___0 ;

  {
  tmp = pci_get_drvdata(pdev);
  pf = (struct i40e_pf *)tmp;
  i40e_dbg_pf_exit(pf);
  i40e_ptp_stop(pf);
  set_bit(3L, (unsigned long volatile   *)(& pf->state));
  ldv_del_timer_sync_43(& pf->service_timer);
  ldv_cancel_work_sync_44(& pf->service_task);
  i40e_fdir_teardown(pf);
  if ((pf->flags & 524288ULL) != 0ULL) {
    i40e_free_vfs(pf);
    pf->flags = pf->flags & 0xfffffffffff7ffffULL;
  } else {

  }
  i40e_fdir_teardown(pf);
  i = 0;
  goto ldv_63629;
  ldv_63628: ;
  if ((unsigned long )pf->veb[i] == (unsigned long )((struct i40e_veb *)0)) {
    goto ldv_63627;
  } else {

  }
  if ((int )(pf->veb[i])->uplink_seid == (int )pf->mac_seid || (unsigned int )(pf->veb[i])->uplink_seid == 0U) {
    i40e_switch_branch_release(pf->veb[i]);
  } else {

  }
  ldv_63627: 
  i = i + 1;
  ldv_63629: ;
  if (i <= 15) {
    goto ldv_63628;
  } else {

  }

  if ((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) != (unsigned long )((struct i40e_vsi *)0)) {
    i40e_vsi_release(*(pf->vsi + (unsigned long )pf->lan_vsi));
  } else {

  }
  if ((unsigned long )pf->hw.hmc.hmc_obj != (unsigned long )((struct i40e_hmc_obj_info *)0)) {
    ret_code = i40e_shutdown_lan_hmc(& pf->hw);
    if ((int )ret_code != 0) {
      dev_warn((struct device  const  *)(& pdev->dev), "Failed to destroy the HMC resources: %d\n",
               (int )ret_code);
    } else {

    }
  } else {

  }
  ret_code = i40e_shutdown_adminq(& pf->hw);
  if ((int )ret_code != 0) {
    dev_warn((struct device  const  *)(& pdev->dev), "Failed to destroy the Admin Queue resources: %d\n",
             (int )ret_code);
  } else {

  }
  i40e_clear_interrupt_scheme(pf);
  i = 0;
  goto ldv_63632;
  ldv_63631: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0)) {
    i40e_vsi_clear_rings(*(pf->vsi + (unsigned long )i));
    i40e_vsi_clear(*(pf->vsi + (unsigned long )i));
    *(pf->vsi + (unsigned long )i) = (struct i40e_vsi *)0;
  } else {

  }
  i = i + 1;
  ldv_63632: ;
  if ((int )pf->num_alloc_vsi > i) {
    goto ldv_63631;
  } else {

  }
  i = 0;
  goto ldv_63635;
  ldv_63634: 
  kfree((void const   *)pf->veb[i]);
  pf->veb[i] = (struct i40e_veb *)0;
  i = i + 1;
  ldv_63635: ;
  if (i <= 15) {
    goto ldv_63634;
  } else {

  }
  kfree((void const   *)pf->qp_pile);
  kfree((void const   *)pf->vsi);
  iounmap((void volatile   *)pf->hw.hw_addr);
  kfree((void const   *)pf);
  tmp___0 = pci_select_bars(pdev, 512UL);
  pci_release_selected_regions(pdev, tmp___0);
  pci_disable_pcie_error_reporting(pdev);
  pci_disable_device(pdev);
  return;
}
}
static pci_ers_result_t i40e_pci_error_detected(struct pci_dev *pdev , enum pci_channel_state error ) 
{ 
  struct i40e_pf *pf ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = pci_get_drvdata(pdev);
  pf = (struct i40e_pf *)tmp;
  _dev_info((struct device  const  *)(& pdev->dev), "%s: error %d\n", "i40e_pci_error_detected",
            (unsigned int )error);
  tmp___0 = constant_test_bit(18L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___0 == 0) {
    rtnl_lock();
    i40e_prep_for_reset(pf);
    rtnl_unlock();
  } else {

  }
  return (3U);
}
}
static pci_ers_result_t i40e_pci_error_slot_reset(struct pci_dev *pdev ) 
{ 
  struct i40e_pf *pf ;
  void *tmp ;
  pci_ers_result_t result ;
  int err ;
  u32 reg ;
  int tmp___0 ;

  {
  tmp = pci_get_drvdata(pdev);
  pf = (struct i40e_pf *)tmp;
  _dev_info((struct device  const  *)(& pdev->dev), "%s\n", "i40e_pci_error_slot_reset");
  tmp___0 = pci_enable_device_mem(pdev);
  if (tmp___0 != 0) {
    _dev_info((struct device  const  *)(& pdev->dev), "Cannot re-enable PCI device after reset.\n");
    result = 4U;
  } else {
    pci_set_master(pdev);
    pci_restore_state(pdev);
    pci_save_state(pdev);
    pci_wake_from_d3(pdev, 0);
    reg = readl((void const volatile   *)pf->hw.hw_addr + 754064U);
    if (reg == 0U) {
      result = 5U;
    } else {
      result = 4U;
    }
  }
  err = pci_cleanup_aer_uncorrect_error_status(pdev);
  if (err != 0) {
    _dev_info((struct device  const  *)(& pdev->dev), "pci_cleanup_aer_uncorrect_error_status failed 0x%0x\n",
              err);
  } else {

  }
  return (result);
}
}
static void i40e_pci_error_resume(struct pci_dev *pdev ) 
{ 
  struct i40e_pf *pf ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = pci_get_drvdata(pdev);
  pf = (struct i40e_pf *)tmp;
  _dev_info((struct device  const  *)(& pdev->dev), "%s\n", "i40e_pci_error_resume");
  tmp___0 = constant_test_bit(18L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___0 != 0) {
    return;
  } else {

  }
  rtnl_lock();
  i40e_handle_reset_warning(pf);
  rtnl_lock();
  return;
}
}
static void i40e_shutdown(struct pci_dev *pdev ) 
{ 
  struct i40e_pf *pf ;
  void *tmp ;
  struct i40e_hw *hw ;

  {
  tmp = pci_get_drvdata(pdev);
  pf = (struct i40e_pf *)tmp;
  hw = & pf->hw;
  set_bit(18L, (unsigned long volatile   *)(& pf->state));
  set_bit(3L, (unsigned long volatile   *)(& pf->state));
  rtnl_lock();
  i40e_prep_for_reset(pf);
  rtnl_unlock();
  writel((unsigned int )pf->wol_en, (void volatile   *)hw->hw_addr + 753792U);
  writel((int )pf->wol_en ? 2U : 0U, (void volatile   *)hw->hw_addr + 439296U);
  i40e_clear_interrupt_scheme(pf);
  if ((unsigned int )system_state == 3U) {
    pci_wake_from_d3(pdev, (int )pf->wol_en);
    pci_set_power_state(pdev, 3);
  } else {

  }
  return;
}
}
static int i40e_suspend(struct pci_dev *pdev , pm_message_t state ) 
{ 
  struct i40e_pf *pf ;
  void *tmp ;
  struct i40e_hw *hw ;

  {
  tmp = pci_get_drvdata(pdev);
  pf = (struct i40e_pf *)tmp;
  hw = & pf->hw;
  set_bit(18L, (unsigned long volatile   *)(& pf->state));
  set_bit(3L, (unsigned long volatile   *)(& pf->state));
  ldv_del_timer_sync_45(& pf->service_timer);
  ldv_cancel_work_sync_46(& pf->service_task);
  i40e_fdir_teardown(pf);
  rtnl_lock();
  i40e_prep_for_reset(pf);
  rtnl_unlock();
  writel((unsigned int )pf->wol_en, (void volatile   *)hw->hw_addr + 753792U);
  writel((int )pf->wol_en ? 2U : 0U, (void volatile   *)hw->hw_addr + 439296U);
  pci_wake_from_d3(pdev, (int )pf->wol_en);
  pci_set_power_state(pdev, 3);
  return (0);
}
}
static int i40e_resume(struct pci_dev *pdev ) 
{ 
  struct i40e_pf *pf ;
  void *tmp ;
  u32 err ;
  int tmp___0 ;
  int tmp___1 ;

  {
  tmp = pci_get_drvdata(pdev);
  pf = (struct i40e_pf *)tmp;
  pci_set_power_state(pdev, 0);
  pci_restore_state(pdev);
  pci_save_state(pdev);
  tmp___0 = pci_enable_device_mem(pdev);
  err = (u32 )tmp___0;
  if (err != 0U) {
    dev_err((struct device  const  *)(& pdev->dev), "%s: Cannot enable PCI device from suspend\n",
            "i40e_resume");
    return ((int )err);
  } else {

  }
  pci_set_master(pdev);
  pci_wake_from_d3(pdev, 0);
  tmp___1 = test_and_clear_bit(18L, (unsigned long volatile   *)(& pf->state));
  if (tmp___1 != 0) {
    clear_bit(3L, (unsigned long volatile   *)(& pf->state));
    rtnl_lock();
    i40e_reset_and_rebuild(pf, 0);
    rtnl_unlock();
  } else {

  }
  return (0);
}
}
static struct pci_error_handlers  const  i40e_err_handler  =    {& i40e_pci_error_detected, 0, 0, & i40e_pci_error_slot_reset, 0, & i40e_pci_error_resume};
static struct pci_driver i40e_driver  = 
     {{0, 0}, (char const   *)(& i40e_driver_name), (struct pci_device_id  const  *)(& i40e_pci_tbl),
    & i40e_probe, & i40e_remove, & i40e_suspend, 0, 0, & i40e_resume, & i40e_shutdown,
    & i40e_pci_sriov_configure, & i40e_err_handler, {0, 0, 0, 0, (_Bool)0, 0, 0, 0,
                                                     0, 0, 0, 0, 0, 0, 0, 0}, {{{{{{0}},
                                                                                  0U,
                                                                                  0U,
                                                                                  0,
                                                                                  {0,
                                                                                   {0,
                                                                                    0},
                                                                                   0,
                                                                                   0,
                                                                                   0UL}}}},
                                                                               {0,
                                                                                0}}};
static int i40e_init_module(void) 
{ 
  int tmp ;

  {
  printk("\016%s: %s - version %s\n", (char const   *)(& i40e_driver_name), (char const   *)(& i40e_driver_string),
         (char const   *)(& i40e_driver_version_str));
  printk("\016%s: %s\n", (char const   *)(& i40e_driver_name), (char const   *)(& i40e_copyright));
  i40e_dbg_init();
  tmp = ldv___pci_register_driver_47(& i40e_driver, & __this_module, "i40e");
  return (tmp);
}
}
static void i40e_exit_module(void) 
{ 


  {
  ldv_pci_unregister_driver_48(& i40e_driver);
  i40e_dbg_exit();
  return;
}
}
int ldv_retval_5  ;
    klee_make_symbolic(&ldv_retval_5, sizeof(int), "ldv_retval_5");
int ldv_retval_11  ;
    klee_make_symbolic(&ldv_retval_11, sizeof(int), "ldv_retval_11");
int ldv_retval_6  ;
    klee_make_symbolic(&ldv_retval_6, sizeof(int), "ldv_retval_6");
extern int ldv_ndo_init_14(void) ;
extern void ldv_initialize(void) ;
extern int ldv_release_13(void) ;
extern int ldv_suspend_13(void) ;
int ldv_retval_9  ;
    klee_make_symbolic(&ldv_retval_9, sizeof(int), "ldv_retval_9");
extern int ldv_suspend_late_12(void) ;
extern int ldv_ndo_uninit_14(void) ;
extern int ldv_probe_13(void) ;
int ldv_retval_4  ;
    klee_make_symbolic(&ldv_retval_4, sizeof(int), "ldv_retval_4");
void ldv_check_final_state(void) ;
int ldv_retval_8  ;
    klee_make_symbolic(&ldv_retval_8, sizeof(int), "ldv_retval_8");
int ldv_retval_3  ;
    klee_make_symbolic(&ldv_retval_3, sizeof(int), "ldv_retval_3");
extern int ldv_resume_early_12(void) ;
int ldv_retval_7  ;
    klee_make_symbolic(&ldv_retval_7, sizeof(int), "ldv_retval_7");
int ldv_irq_3(int state , int line , void *data ) 
{ 
  irqreturn_t irq_retval ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = __VERIFIER_nondet_int();
  irq_retval = (irqreturn_t )tmp;
  if (state != 0) {
    tmp___0 = __VERIFIER_nondet_int();
    switch (tmp___0) {
    case 0: ;
    if (state == 1) {
      LDV_IN_INTERRUPT = 2;
      irq_retval = i40e_intr(line, data);
      LDV_IN_INTERRUPT = 1;
      return (state);
    } else {

    }
    goto ldv_63724;
    default: 
    ldv_stop();
    }
    ldv_63724: ;
  } else {

  }
  return (state);
}
}
void disable_suitable_irq_2(int line , void *data ) 
{ 


  {
  if (ldv_irq_2_0 != 0 && line == ldv_irq_line_2_0) {
    ldv_irq_2_0 = 0;
    return;
  } else {

  }
  if (ldv_irq_2_1 != 0 && line == ldv_irq_line_2_1) {
    ldv_irq_2_1 = 0;
    return;
  } else {

  }
  if (ldv_irq_2_2 != 0 && line == ldv_irq_line_2_2) {
    ldv_irq_2_2 = 0;
    return;
  } else {

  }
  if (ldv_irq_2_3 != 0 && line == ldv_irq_line_2_3) {
    ldv_irq_2_3 = 0;
    return;
  } else {

  }
  return;
}
}
void ldv_timer_5(int state , struct timer_list *timer ) 
{ 


  {
  LDV_IN_INTERRUPT = 2;
  i40e_service_timer(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void choose_timer_5(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_5_0 == 1) {
    ldv_timer_5_0 = 2;
    ldv_timer_5(ldv_timer_5_0, ldv_timer_list_5_0);
  } else {

  }
  goto ldv_63738;
  case 1: ;
  if (ldv_timer_5_1 == 1) {
    ldv_timer_5_1 = 2;
    ldv_timer_5(ldv_timer_5_1, ldv_timer_list_5_1);
  } else {

  }
  goto ldv_63738;
  case 2: ;
  if (ldv_timer_5_2 == 1) {
    ldv_timer_5_2 = 2;
    ldv_timer_5(ldv_timer_5_2, ldv_timer_list_5_2);
  } else {

  }
  goto ldv_63738;
  case 3: ;
  if (ldv_timer_5_3 == 1) {
    ldv_timer_5_3 = 2;
    ldv_timer_5(ldv_timer_5_3, ldv_timer_list_5_3);
  } else {

  }
  goto ldv_63738;
  default: 
  ldv_stop();
  }
  ldv_63738: ;
  return;
}
}
void activate_suitable_irq_3(int line , void *data ) 
{ 


  {
  if (ldv_irq_3_0 == 0) {
    ldv_irq_line_3_0 = line;
    ldv_irq_data_3_0 = data;
    ldv_irq_3_0 = 1;
    return;
  } else {

  }
  if (ldv_irq_3_1 == 0) {
    ldv_irq_line_3_1 = line;
    ldv_irq_data_3_1 = data;
    ldv_irq_3_1 = 1;
    return;
  } else {

  }
  if (ldv_irq_3_2 == 0) {
    ldv_irq_line_3_2 = line;
    ldv_irq_data_3_2 = data;
    ldv_irq_3_2 = 1;
    return;
  } else {

  }
  if (ldv_irq_3_3 == 0) {
    ldv_irq_line_3_3 = line;
    ldv_irq_data_3_3 = data;
    ldv_irq_3_3 = 1;
    return;
  } else {

  }
  return;
}
}
int reg_check_1(irqreturn_t (*handler)(int  , void * ) ) 
{ 


  {
  if ((unsigned long )handler == (unsigned long )(& i40e_intr)) {
    return (1);
  } else {

  }
  return (0);
}
}
void call_and_disable_all_4(int state ) 
{ 


  {
  if (ldv_work_4_0 == state) {
    call_and_disable_work_4(ldv_work_struct_4_0);
  } else {

  }
  if (ldv_work_4_1 == state) {
    call_and_disable_work_4(ldv_work_struct_4_1);
  } else {

  }
  if (ldv_work_4_2 == state) {
    call_and_disable_work_4(ldv_work_struct_4_2);
  } else {

  }
  if (ldv_work_4_3 == state) {
    call_and_disable_work_4(ldv_work_struct_4_3);
  } else {

  }
  return;
}
}
void timer_init_5(void) 
{ 


  {
  ldv_timer_5_0 = 0;
  ldv_timer_5_1 = 0;
  ldv_timer_5_2 = 0;
  ldv_timer_5_3 = 0;
  return;
}
}
void disable_suitable_irq_1(int line , void *data ) 
{ 


  {
  if (ldv_irq_1_0 != 0 && line == ldv_irq_line_1_0) {
    ldv_irq_1_0 = 0;
    return;
  } else {

  }
  if (ldv_irq_1_1 != 0 && line == ldv_irq_line_1_1) {
    ldv_irq_1_1 = 0;
    return;
  } else {

  }
  if (ldv_irq_1_2 != 0 && line == ldv_irq_line_1_2) {
    ldv_irq_1_2 = 0;
    return;
  } else {

  }
  if (ldv_irq_1_3 != 0 && line == ldv_irq_line_1_3) {
    ldv_irq_1_3 = 0;
    return;
  } else {

  }
  return;
}
}
void activate_suitable_irq_1(int line , void *data ) 
{ 


  {
  if (ldv_irq_1_0 == 0) {
    ldv_irq_line_1_0 = line;
    ldv_irq_data_1_0 = data;
    ldv_irq_1_0 = 1;
    return;
  } else {

  }
  if (ldv_irq_1_1 == 0) {
    ldv_irq_line_1_1 = line;
    ldv_irq_data_1_1 = data;
    ldv_irq_1_1 = 1;
    return;
  } else {

  }
  if (ldv_irq_1_2 == 0) {
    ldv_irq_line_1_2 = line;
    ldv_irq_data_1_2 = data;
    ldv_irq_1_2 = 1;
    return;
  } else {

  }
  if (ldv_irq_1_3 == 0) {
    ldv_irq_line_1_3 = line;
    ldv_irq_data_1_3 = data;
    ldv_irq_1_3 = 1;
    return;
  } else {

  }
  return;
}
}
void ldv_pci_driver_12(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(2976UL);
  i40e_driver_group1 = (struct pci_dev *)tmp;
  return;
}
}
void invoke_work_4(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_work_4_0 == 2 || ldv_work_4_0 == 3) {
    ldv_work_4_0 = 4;
    i40e_service_task(ldv_work_struct_4_0);
    ldv_work_4_0 = 1;
  } else {

  }
  goto ldv_63775;
  case 1: ;
  if (ldv_work_4_1 == 2 || ldv_work_4_1 == 3) {
    ldv_work_4_1 = 4;
    i40e_service_task(ldv_work_struct_4_0);
    ldv_work_4_1 = 1;
  } else {

  }
  goto ldv_63775;
  case 2: ;
  if (ldv_work_4_2 == 2 || ldv_work_4_2 == 3) {
    ldv_work_4_2 = 4;
    i40e_service_task(ldv_work_struct_4_0);
    ldv_work_4_2 = 1;
  } else {

  }
  goto ldv_63775;
  case 3: ;
  if (ldv_work_4_3 == 2 || ldv_work_4_3 == 3) {
    ldv_work_4_3 = 4;
    i40e_service_task(ldv_work_struct_4_0);
    ldv_work_4_3 = 1;
  } else {

  }
  goto ldv_63775;
  default: 
  ldv_stop();
  }
  ldv_63775: ;
  return;
}
}
void disable_suitable_timer_5(struct timer_list *timer ) 
{ 


  {
  if (ldv_timer_5_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_5_0) {
    ldv_timer_5_0 = 0;
    return;
  } else {

  }
  if (ldv_timer_5_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_5_1) {
    ldv_timer_5_1 = 0;
    return;
  } else {

  }
  if (ldv_timer_5_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_5_2) {
    ldv_timer_5_2 = 0;
    return;
  } else {

  }
  if (ldv_timer_5_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_5_3) {
    ldv_timer_5_3 = 0;
    return;
  } else {

  }
  return;
}
}
int ldv_irq_2(int state , int line , void *data ) 
{ 
  irqreturn_t irq_retval ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = __VERIFIER_nondet_int();
  irq_retval = (irqreturn_t )tmp;
  if (state != 0) {
    tmp___0 = __VERIFIER_nondet_int();
    switch (tmp___0) {
    case 0: ;
    if (state == 1) {
      LDV_IN_INTERRUPT = 2;
      irq_retval = i40e_intr(line, data);
      LDV_IN_INTERRUPT = 1;
      return (state);
    } else {

    }
    goto ldv_63790;
    default: 
    ldv_stop();
    }
    ldv_63790: ;
  } else {

  }
  return (state);
}
}
void choose_interrupt_2(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: 
  ldv_irq_2_0 = ldv_irq_2(ldv_irq_2_0, ldv_irq_line_2_0, ldv_irq_data_2_0);
  goto ldv_63796;
  case 1: 
  ldv_irq_2_0 = ldv_irq_2(ldv_irq_2_1, ldv_irq_line_2_1, ldv_irq_data_2_1);
  goto ldv_63796;
  case 2: 
  ldv_irq_2_0 = ldv_irq_2(ldv_irq_2_2, ldv_irq_line_2_2, ldv_irq_data_2_2);
  goto ldv_63796;
  case 3: 
  ldv_irq_2_0 = ldv_irq_2(ldv_irq_2_3, ldv_irq_line_2_3, ldv_irq_data_2_3);
  goto ldv_63796;
  default: 
  ldv_stop();
  }
  ldv_63796: ;
  return;
}
}
void activate_work_4(struct work_struct *work , int state ) 
{ 


  {
  if (ldv_work_4_0 == 0) {
    ldv_work_struct_4_0 = work;
    ldv_work_4_0 = state;
    return;
  } else {

  }
  if (ldv_work_4_1 == 0) {
    ldv_work_struct_4_1 = work;
    ldv_work_4_1 = state;
    return;
  } else {

  }
  if (ldv_work_4_2 == 0) {
    ldv_work_struct_4_2 = work;
    ldv_work_4_2 = state;
    return;
  } else {

  }
  if (ldv_work_4_3 == 0) {
    ldv_work_struct_4_3 = work;
    ldv_work_4_3 = state;
    return;
  } else {

  }
  return;
}
}
void activate_suitable_irq_2(int line , void *data ) 
{ 


  {
  if (ldv_irq_2_0 == 0) {
    ldv_irq_line_2_0 = line;
    ldv_irq_data_2_0 = data;
    ldv_irq_2_0 = 1;
    return;
  } else {

  }
  if (ldv_irq_2_1 == 0) {
    ldv_irq_line_2_1 = line;
    ldv_irq_data_2_1 = data;
    ldv_irq_2_1 = 1;
    return;
  } else {

  }
  if (ldv_irq_2_2 == 0) {
    ldv_irq_line_2_2 = line;
    ldv_irq_data_2_2 = data;
    ldv_irq_2_2 = 1;
    return;
  } else {

  }
  if (ldv_irq_2_3 == 0) {
    ldv_irq_line_2_3 = line;
    ldv_irq_data_2_3 = data;
    ldv_irq_2_3 = 1;
    return;
  } else {

  }
  return;
}
}
void choose_interrupt_1(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: 
  ldv_irq_1_0 = ldv_irq_1(ldv_irq_1_0, ldv_irq_line_1_0, ldv_irq_data_1_0);
  goto ldv_63813;
  case 1: 
  ldv_irq_1_0 = ldv_irq_1(ldv_irq_1_1, ldv_irq_line_1_1, ldv_irq_data_1_1);
  goto ldv_63813;
  case 2: 
  ldv_irq_1_0 = ldv_irq_1(ldv_irq_1_2, ldv_irq_line_1_2, ldv_irq_data_1_2);
  goto ldv_63813;
  case 3: 
  ldv_irq_1_0 = ldv_irq_1(ldv_irq_1_3, ldv_irq_line_1_3, ldv_irq_data_1_3);
  goto ldv_63813;
  default: 
  ldv_stop();
  }
  ldv_63813: ;
  return;
}
}
int reg_check_2(irqreturn_t (*handler)(int  , void * ) ) 
{ 


  {
  if ((unsigned long )handler == (unsigned long )(& i40e_intr)) {
    return (1);
  } else {

  }
  return (0);
}
}
void disable_suitable_irq_3(int line , void *data ) 
{ 


  {
  if (ldv_irq_3_0 != 0 && line == ldv_irq_line_3_0) {
    ldv_irq_3_0 = 0;
    return;
  } else {

  }
  if (ldv_irq_3_1 != 0 && line == ldv_irq_line_3_1) {
    ldv_irq_3_1 = 0;
    return;
  } else {

  }
  if (ldv_irq_3_2 != 0 && line == ldv_irq_line_3_2) {
    ldv_irq_3_2 = 0;
    return;
  } else {

  }
  if (ldv_irq_3_3 != 0 && line == ldv_irq_line_3_3) {
    ldv_irq_3_3 = 0;
    return;
  } else {

  }
  return;
}
}
void ldv_initialize_pci_error_handlers_13(void) 
{ 

  {
  i40e_err_handler_group0 = ldv_malloc(sizeof(struct pci_dev));
  return;
}
}
void ldv_net_device_ops_14(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(3008UL);
  i40e_netdev_ops_group1 = (struct net_device *)tmp;
  return;
}
}
int reg_check_3(irqreturn_t (*handler)(int  , void * ) ) 
{ 


  {
  if ((unsigned long )handler == (unsigned long )(& i40e_intr)) {
    return (1);
  } else {

  }
  return (0);
}
}
void disable_work_4(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_4_0 == 3 || ldv_work_4_0 == 2) && (unsigned long )ldv_work_struct_4_0 == (unsigned long )work) {
    ldv_work_4_0 = 1;
  } else {

  }
  if ((ldv_work_4_1 == 3 || ldv_work_4_1 == 2) && (unsigned long )ldv_work_struct_4_1 == (unsigned long )work) {
    ldv_work_4_1 = 1;
  } else {

  }
  if ((ldv_work_4_2 == 3 || ldv_work_4_2 == 2) && (unsigned long )ldv_work_struct_4_2 == (unsigned long )work) {
    ldv_work_4_2 = 1;
  } else {

  }
  if ((ldv_work_4_3 == 3 || ldv_work_4_3 == 2) && (unsigned long )ldv_work_struct_4_3 == (unsigned long )work) {
    ldv_work_4_3 = 1;
  } else {

  }
  return;
}
}
void work_init_4(void) 
{ 


  {
  ldv_work_4_0 = 0;
  ldv_work_4_1 = 0;
  ldv_work_4_2 = 0;
  ldv_work_4_3 = 0;
  return;
}
}
int ldv_irq_1(int state , int line , void *data ) 
{ 
  irqreturn_t irq_retval ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = __VERIFIER_nondet_int();
  irq_retval = (irqreturn_t )tmp;
  if (state != 0) {
    tmp___0 = __VERIFIER_nondet_int();
    switch (tmp___0) {
    case 0: ;
    if (state == 1) {
      LDV_IN_INTERRUPT = 2;
      irq_retval = i40e_intr(line, data);
      LDV_IN_INTERRUPT = 1;
      return (state);
    } else {

    }
    goto ldv_63851;
    default: 
    ldv_stop();
    }
    ldv_63851: ;
  } else {

  }
  return (state);
}
}
void activate_pending_timer_5(struct timer_list *timer , unsigned long data , int pending_flag ) 
{ 


  {
  if ((unsigned long )ldv_timer_list_5_0 == (unsigned long )timer) {
    if (ldv_timer_5_0 == 2 || pending_flag != 0) {
      ldv_timer_list_5_0 = timer;
      ldv_timer_list_5_0->data = data;
      ldv_timer_5_0 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_5_1 == (unsigned long )timer) {
    if (ldv_timer_5_1 == 2 || pending_flag != 0) {
      ldv_timer_list_5_1 = timer;
      ldv_timer_list_5_1->data = data;
      ldv_timer_5_1 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_5_2 == (unsigned long )timer) {
    if (ldv_timer_5_2 == 2 || pending_flag != 0) {
      ldv_timer_list_5_2 = timer;
      ldv_timer_list_5_2->data = data;
      ldv_timer_5_2 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_5_3 == (unsigned long )timer) {
    if (ldv_timer_5_3 == 2 || pending_flag != 0) {
      ldv_timer_list_5_3 = timer;
      ldv_timer_list_5_3->data = data;
      ldv_timer_5_3 = 1;
    } else {

    }
    return;
  } else {

  }
  activate_suitable_timer_5(timer, data);
  return;
}
}
void choose_interrupt_3(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: 
  ldv_irq_3_0 = ldv_irq_3(ldv_irq_3_0, ldv_irq_line_3_0, ldv_irq_data_3_0);
  goto ldv_63864;
  case 1: 
  ldv_irq_3_0 = ldv_irq_3(ldv_irq_3_1, ldv_irq_line_3_1, ldv_irq_data_3_1);
  goto ldv_63864;
  case 2: 
  ldv_irq_3_0 = ldv_irq_3(ldv_irq_3_2, ldv_irq_line_3_2, ldv_irq_data_3_2);
  goto ldv_63864;
  case 3: 
  ldv_irq_3_0 = ldv_irq_3(ldv_irq_3_3, ldv_irq_line_3_3, ldv_irq_data_3_3);
  goto ldv_63864;
  default: 
  ldv_stop();
  }
  ldv_63864: ;
  return;
}
}
int reg_timer_5(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) 
{ 


  {
  if ((unsigned long )function == (unsigned long )(& i40e_service_timer)) {
    activate_suitable_timer_5(timer, data);
  } else {

  }
  return (0);
}
}
void call_and_disable_work_4(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_4_0 == 2 || ldv_work_4_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_0) {
    i40e_service_task(work);
    ldv_work_4_0 = 1;
    return;
  } else {

  }
  if ((ldv_work_4_1 == 2 || ldv_work_4_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_1) {
    i40e_service_task(work);
    ldv_work_4_1 = 1;
    return;
  } else {

  }
  if ((ldv_work_4_2 == 2 || ldv_work_4_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_2) {
    i40e_service_task(work);
    ldv_work_4_2 = 1;
    return;
  } else {

  }
  if ((ldv_work_4_3 == 2 || ldv_work_4_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_3) {
    i40e_service_task(work);
    ldv_work_4_3 = 1;
    return;
  } else {

  }
  return;
}
}
void activate_suitable_timer_5(struct timer_list *timer , unsigned long data ) 
{ 


  {
  if (ldv_timer_5_0 == 0 || ldv_timer_5_0 == 2) {
    ldv_timer_list_5_0 = timer;
    ldv_timer_list_5_0->data = data;
    ldv_timer_5_0 = 1;
    return;
  } else {

  }
  if (ldv_timer_5_1 == 0 || ldv_timer_5_1 == 2) {
    ldv_timer_list_5_1 = timer;
    ldv_timer_list_5_1->data = data;
    ldv_timer_5_1 = 1;
    return;
  } else {

  }
  if (ldv_timer_5_2 == 0 || ldv_timer_5_2 == 2) {
    ldv_timer_list_5_2 = timer;
    ldv_timer_list_5_2->data = data;
    ldv_timer_5_2 = 1;
    return;
  } else {

  }
  if (ldv_timer_5_3 == 0 || ldv_timer_5_3 == 2) {
    ldv_timer_list_5_3 = timer;
    ldv_timer_list_5_3->data = data;
    ldv_timer_5_3 = 1;
    return;
  } else {

  }
  return;
}
}
void ldv_main_exported_8(void) ;
void ldv_main_exported_10(void) ;
void ldv_main_exported_9(void) ;
void ldv_main_exported_11(void) ;
void ldv_main_exported_6(void) ;
void ldv_main_exported_7(void) ;
int main(void) 
{ 
  pm_message_t ldvarg51 ;
  struct pci_device_id *ldvarg52 ;
  void *tmp ;
  int ldvarg50 ;
    klee_make_symbolic(&ldvarg50, sizeof(int), "ldvarg50");
  struct ifla_vf_info *ldvarg77 ;
  void *tmp___0 ;
  int ldvarg84 ;
    klee_make_symbolic(&ldvarg84, sizeof(int), "ldvarg84");
  u8 ldvarg67 ;
  sa_family_t ldvarg71 ;
  struct sk_buff *ldvarg72 ;
  void *tmp___1 ;
  u8 ldvarg56 ;
  int ldvarg58 ;
    klee_make_symbolic(&ldvarg58, sizeof(int), "ldvarg58");
  struct rtnl_link_stats64 *ldvarg53 ;
  void *tmp___2 ;
  struct ndmsg *ldvarg64 ;
  void *tmp___3 ;
  __be16 ldvarg83 ;
  struct ifreq *ldvarg85 ;
  void *tmp___4 ;
  int ldvarg69 ;
    klee_make_symbolic(&ldvarg69, sizeof(int), "ldvarg69");
  __be16 ldvarg60 ;
  __be16 ldvarg80 ;
  int ldvarg87 ;
    klee_make_symbolic(&ldvarg87, sizeof(int), "ldvarg87");
  netdev_features_t ldvarg59 ;
  int ldvarg86 ;
    klee_make_symbolic(&ldvarg86, sizeof(int), "ldvarg86");
  u16 ldvarg62 ;
  void *ldvarg57 ;
  void *tmp___5 ;
  struct nlattr **ldvarg65 ;
  void *tmp___6 ;
  u16 ldvarg79 ;
  int ldvarg55 ;
    klee_make_symbolic(&ldvarg55, sizeof(int), "ldvarg55");
  u16 ldvarg66 ;
  struct netdev_phys_item_id *ldvarg81 ;
  void *tmp___7 ;
  unsigned char *ldvarg63 ;
  void *tmp___8 ;
  bool ldvarg73 ;
  int ldvarg88 ;
    klee_make_symbolic(&ldvarg88, sizeof(int), "ldvarg88");
  __be16 ldvarg70 ;
  int ldvarg78 ;
    klee_make_symbolic(&ldvarg78, sizeof(int), "ldvarg78");
  u16 ldvarg68 ;
  u8 *ldvarg54 ;
  void *tmp___9 ;
  sa_family_t ldvarg61 ;
  int ldvarg74 ;
    klee_make_symbolic(&ldvarg74, sizeof(int), "ldvarg74");
  int ldvarg76 ;
    klee_make_symbolic(&ldvarg76, sizeof(int), "ldvarg76");
  u16 ldvarg82 ;
  int ldvarg75 ;
    klee_make_symbolic(&ldvarg75, sizeof(int), "ldvarg75");
  enum pci_channel_state ldvarg95 ;
  int tmp___10 ;
  int tmp___11 ;
    klee_make_symbolic(&tmp___11, sizeof(int), "tmp___11");
  int tmp___12 ;
  int tmp___13 ;
    klee_make_symbolic(&tmp___13, sizeof(int), "tmp___13");
  int tmp___14 ;
    klee_make_symbolic(&tmp___14, sizeof(int), "tmp___14");

  {
  tmp = ldv_init_zalloc(32UL);
  ldvarg52 = (struct pci_device_id *)tmp;
  tmp___0 = ldv_init_zalloc(64UL);
  ldvarg77 = (struct ifla_vf_info *)tmp___0;
  tmp___1 = ldv_init_zalloc(232UL);
  ldvarg72 = (struct sk_buff *)tmp___1;
  tmp___2 = ldv_init_zalloc(184UL);
  ldvarg53 = (struct rtnl_link_stats64 *)tmp___2;
  tmp___3 = ldv_init_zalloc(12UL);
  ldvarg64 = (struct ndmsg *)tmp___3;
  tmp___4 = ldv_init_zalloc(40UL);
  ldvarg85 = (struct ifreq *)tmp___4;
  tmp___5 = ldv_init_zalloc(1UL);
  ldvarg57 = tmp___5;
  tmp___6 = ldv_init_zalloc(8UL);
  ldvarg65 = (struct nlattr **)tmp___6;
  tmp___7 = ldv_init_zalloc(33UL);
  ldvarg81 = (struct netdev_phys_item_id *)tmp___7;
  tmp___8 = ldv_init_zalloc(1UL);
  ldvarg63 = (unsigned char *)tmp___8;
  tmp___9 = ldv_init_zalloc(1UL);
  ldvarg54 = (u8 *)tmp___9;
  ldv_initialize();
  ldv_memset((void *)(& ldvarg51), 0, 4UL);
  ldv_memset((void *)(& ldvarg50), 0, 4UL);
  ldv_memset((void *)(& ldvarg84), 0, 4UL);
  ldv_memset((void *)(& ldvarg67), 0, 1UL);
  ldv_memset((void *)(& ldvarg71), 0, 2UL);
  ldv_memset((void *)(& ldvarg56), 0, 1UL);
  ldv_memset((void *)(& ldvarg58), 0, 4UL);
  ldv_memset((void *)(& ldvarg83), 0, 2UL);
  ldv_memset((void *)(& ldvarg69), 0, 4UL);
  ldv_memset((void *)(& ldvarg60), 0, 2UL);
  ldv_memset((void *)(& ldvarg80), 0, 2UL);
  ldv_memset((void *)(& ldvarg87), 0, 4UL);
  ldv_memset((void *)(& ldvarg59), 0, 8UL);
  ldv_memset((void *)(& ldvarg86), 0, 4UL);
  ldv_memset((void *)(& ldvarg62), 0, 2UL);
  ldv_memset((void *)(& ldvarg79), 0, 2UL);
  ldv_memset((void *)(& ldvarg55), 0, 4UL);
  ldv_memset((void *)(& ldvarg66), 0, 2UL);
  ldv_memset((void *)(& ldvarg73), 0, 1UL);
  ldv_memset((void *)(& ldvarg88), 0, 4UL);
  ldv_memset((void *)(& ldvarg70), 0, 2UL);
  ldv_memset((void *)(& ldvarg78), 0, 4UL);
  ldv_memset((void *)(& ldvarg68), 0, 2UL);
  ldv_memset((void *)(& ldvarg61), 0, 2UL);
  ldv_memset((void *)(& ldvarg74), 0, 4UL);
  ldv_memset((void *)(& ldvarg76), 0, 4UL);
  ldv_memset((void *)(& ldvarg82), 0, 2UL);
  ldv_memset((void *)(& ldvarg75), 0, 4UL);
  ldv_memset((void *)(& ldvarg95), 0, 4UL);
  ldv_state_variable_6 = 0;
  ldv_state_variable_11 = 0;
  ldv_state_variable_3 = 1;
  ldv_state_variable_7 = 0;
  ldv_state_variable_9 = 0;
  ldv_state_variable_12 = 0;
  ldv_state_variable_2 = 1;
  ldv_state_variable_14 = 0;
  ldv_state_variable_8 = 0;
  ldv_state_variable_1 = 1;
  work_init_4();
  ldv_state_variable_4 = 1;
  ref_cnt = 0;
  ldv_state_variable_0 = 1;
  ldv_state_variable_13 = 0;
  ldv_state_variable_10 = 0;
  timer_init_5();
  ldv_state_variable_5 = 1;
  ldv_64018: 
  tmp___10 = __VERIFIER_nondet_int();
  switch (tmp___10) {
  case 0: ;
  if (ldv_state_variable_6 != 0) {
    ldv_main_exported_6();
  } else {

  }
  goto ldv_63948;
  case 1: ;
  if (ldv_state_variable_11 != 0) {
    ldv_main_exported_11();
  } else {

  }
  goto ldv_63948;
  case 2: ;
  if (ldv_state_variable_3 != 0) {
    choose_interrupt_3();
  } else {

  }
  goto ldv_63948;
  case 3: ;
  if (ldv_state_variable_7 != 0) {
    ldv_main_exported_7();
  } else {

  }
  goto ldv_63948;
  case 4: ;
  if (ldv_state_variable_9 != 0) {
    ldv_main_exported_9();
  } else {

  }
  goto ldv_63948;
  case 5: ;
  if (ldv_state_variable_12 != 0) {
    tmp___11 = __VERIFIER_nondet_int();
    switch (tmp___11) {
    case 0: ;
    if (ldv_state_variable_12 == 1) {
      ldv_retval_7 = i40e_probe(i40e_driver_group1, (struct pci_device_id  const  *)ldvarg52);
      if (ldv_retval_7 == 0) {
        ldv_state_variable_12 = 2;
        ref_cnt = ref_cnt + 1;
      } else {

      }
    } else {

    }
    goto ldv_63955;
    case 1: ;
    if (ldv_state_variable_12 == 2 && pci_counter == 0) {
      ldv_retval_6 = i40e_suspend(i40e_driver_group1, ldvarg51);
      if (ldv_retval_6 == 0) {
        ldv_state_variable_12 = 3;
      } else {

      }
    } else {

    }
    goto ldv_63955;
    case 2: ;
    if (ldv_state_variable_12 == 4) {
      ldv_retval_5 = i40e_resume(i40e_driver_group1);
      if (ldv_retval_5 == 0) {
        ldv_state_variable_12 = 2;
      } else {

      }
    } else {

    }
    if (ldv_state_variable_12 == 3) {
      ldv_retval_5 = i40e_resume(i40e_driver_group1);
      if (ldv_retval_5 == 0) {
        ldv_state_variable_12 = 2;
      } else {

      }
    } else {

    }
    if (ldv_state_variable_12 == 5) {
      ldv_retval_5 = i40e_resume(i40e_driver_group1);
      if (ldv_retval_5 == 0) {
        ldv_state_variable_12 = 2;
      } else {

      }
    } else {

    }
    goto ldv_63955;
    case 3: ;
    if (ldv_state_variable_12 == 4) {
      i40e_shutdown(i40e_driver_group1);
      ldv_state_variable_12 = 4;
    } else {

    }
    if (ldv_state_variable_12 == 3) {
      i40e_shutdown(i40e_driver_group1);
      ldv_state_variable_12 = 3;
    } else {

    }
    if (ldv_state_variable_12 == 2) {
      i40e_shutdown(i40e_driver_group1);
      ldv_state_variable_12 = 2;
    } else {

    }
    if (ldv_state_variable_12 == 5) {
      i40e_shutdown(i40e_driver_group1);
      ldv_state_variable_12 = 5;
    } else {

    }
    goto ldv_63955;
    case 4: ;
    if (ldv_state_variable_12 == 4) {
      i40e_pci_sriov_configure(i40e_driver_group1, ldvarg50);
      ldv_state_variable_12 = 4;
    } else {

    }
    if (ldv_state_variable_12 == 1) {
      i40e_pci_sriov_configure(i40e_driver_group1, ldvarg50);
      ldv_state_variable_12 = 1;
    } else {

    }
    if (ldv_state_variable_12 == 3) {
      i40e_pci_sriov_configure(i40e_driver_group1, ldvarg50);
      ldv_state_variable_12 = 3;
    } else {

    }
    if (ldv_state_variable_12 == 2) {
      i40e_pci_sriov_configure(i40e_driver_group1, ldvarg50);
      ldv_state_variable_12 = 2;
    } else {

    }
    if (ldv_state_variable_12 == 5) {
      i40e_pci_sriov_configure(i40e_driver_group1, ldvarg50);
      ldv_state_variable_12 = 5;
    } else {

    }
    goto ldv_63955;
    case 5: ;
    if (ldv_state_variable_12 == 4) {
      i40e_remove(i40e_driver_group1);
      ldv_state_variable_12 = 1;
    } else {

    }
    if (ldv_state_variable_12 == 3) {
      i40e_remove(i40e_driver_group1);
      ldv_state_variable_12 = 1;
    } else {

    }
    if (ldv_state_variable_12 == 2) {
      i40e_remove(i40e_driver_group1);
      ldv_state_variable_12 = 1;
    } else {

    }
    if (ldv_state_variable_12 == 5) {
      i40e_remove(i40e_driver_group1);
      ldv_state_variable_12 = 1;
    } else {

    }
    goto ldv_63955;
    case 6: ;
    if (ldv_state_variable_12 == 3) {
      ldv_retval_4 = ldv_suspend_late_12();
      if (ldv_retval_4 == 0) {
        ldv_state_variable_12 = 4;
      } else {

      }
    } else {

    }
    goto ldv_63955;
    case 7: ;
    if (ldv_state_variable_12 == 4) {
      ldv_retval_3 = ldv_resume_early_12();
      if (ldv_retval_3 == 0) {
        ldv_state_variable_12 = 5;
      } else {

      }
    } else {

    }
    if (ldv_state_variable_12 == 3) {
      ldv_retval_3 = ldv_resume_early_12();
      if (ldv_retval_3 == 0) {
        ldv_state_variable_12 = 5;
      } else {

      }
    } else {

    }
    goto ldv_63955;
    default: 
    ldv_stop();
    }
    ldv_63955: ;
  } else {

  }
  goto ldv_63948;
  case 6: ;
  if (ldv_state_variable_2 != 0) {
    choose_interrupt_2();
  } else {

  }
  goto ldv_63948;
  case 7: ;
  if (ldv_state_variable_14 != 0) {
    tmp___12 = __VERIFIER_nondet_int();
    switch (tmp___12) {
    case 0: ;
    if (ldv_state_variable_14 == 1) {
      i40e_ndo_set_vf_bw(i40e_netdev_ops_group1, ldvarg88, ldvarg87, ldvarg86);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_ndo_set_vf_bw(i40e_netdev_ops_group1, ldvarg88, ldvarg87, ldvarg86);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_ndo_set_vf_bw(i40e_netdev_ops_group1, ldvarg88, ldvarg87, ldvarg86);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 1: ;
    if (ldv_state_variable_14 == 1) {
      i40e_ioctl(i40e_netdev_ops_group1, ldvarg85, ldvarg84);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_ioctl(i40e_netdev_ops_group1, ldvarg85, ldvarg84);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_ioctl(i40e_netdev_ops_group1, ldvarg85, ldvarg84);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 2: ;
    if (ldv_state_variable_14 == 1) {
      i40e_vlan_rx_kill_vid(i40e_netdev_ops_group1, (int )ldvarg83, (int )ldvarg82);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_vlan_rx_kill_vid(i40e_netdev_ops_group1, (int )ldvarg83, (int )ldvarg82);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_vlan_rx_kill_vid(i40e_netdev_ops_group1, (int )ldvarg83, (int )ldvarg82);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 3: ;
    if (ldv_state_variable_14 == 1) {
      i40e_get_phys_port_id(i40e_netdev_ops_group1, ldvarg81);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_get_phys_port_id(i40e_netdev_ops_group1, ldvarg81);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_get_phys_port_id(i40e_netdev_ops_group1, ldvarg81);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 4: ;
    if (ldv_state_variable_14 == 1) {
      i40e_vlan_rx_add_vid(i40e_netdev_ops_group1, (int )ldvarg80, (int )ldvarg79);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_vlan_rx_add_vid(i40e_netdev_ops_group1, (int )ldvarg80, (int )ldvarg79);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_vlan_rx_add_vid(i40e_netdev_ops_group1, (int )ldvarg80, (int )ldvarg79);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 5: ;
    if (ldv_state_variable_14 == 1) {
      i40e_ndo_get_vf_config(i40e_netdev_ops_group1, ldvarg78, ldvarg77);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_ndo_get_vf_config(i40e_netdev_ops_group1, ldvarg78, ldvarg77);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_ndo_get_vf_config(i40e_netdev_ops_group1, ldvarg78, ldvarg77);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 6: ;
    if (ldv_state_variable_14 == 1) {
      i40e_ndo_set_vf_link_state(i40e_netdev_ops_group1, ldvarg76, ldvarg75);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_ndo_set_vf_link_state(i40e_netdev_ops_group1, ldvarg76, ldvarg75);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_ndo_set_vf_link_state(i40e_netdev_ops_group1, ldvarg76, ldvarg75);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 7: ;
    if (ldv_state_variable_14 == 1) {
      i40e_fcoe_enable(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_fcoe_enable(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_fcoe_enable(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 8: ;
    if (ldv_state_variable_14 == 2) {
      ldv_retval_9 = i40e_open(i40e_netdev_ops_group1);
      if (ldv_retval_9 == 0) {
        ldv_state_variable_14 = 3;
      } else {

      }
    } else {

    }
    goto ldv_63967;
    case 9: ;
    if (ldv_state_variable_14 == 1) {
      i40e_ndo_set_vf_spoofchk(i40e_netdev_ops_group1, ldvarg74, (int )ldvarg73);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_ndo_set_vf_spoofchk(i40e_netdev_ops_group1, ldvarg74, (int )ldvarg73);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_ndo_set_vf_spoofchk(i40e_netdev_ops_group1, ldvarg74, (int )ldvarg73);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 10: ;
    if (ldv_state_variable_14 == 3) {
      i40e_lan_xmit_frame(ldvarg72, i40e_netdev_ops_group1);
      ldv_state_variable_14 = 3;
    } else {

    }
    goto ldv_63967;
    case 11: ;
    if (ldv_state_variable_14 == 3) {
      i40e_close(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 12: ;
    if (ldv_state_variable_14 == 1) {
      i40e_set_rx_mode(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_set_rx_mode(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_set_rx_mode(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 13: ;
    if (ldv_state_variable_14 == 1) {
      eth_validate_addr(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      eth_validate_addr(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      eth_validate_addr(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 14: ;
    if (ldv_state_variable_14 == 1) {
      i40e_del_vxlan_port(i40e_netdev_ops_group1, (int )ldvarg71, (int )ldvarg70);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_del_vxlan_port(i40e_netdev_ops_group1, (int )ldvarg71, (int )ldvarg70);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_del_vxlan_port(i40e_netdev_ops_group1, (int )ldvarg71, (int )ldvarg70);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 15: ;
    if (ldv_state_variable_14 == 1) {
      i40e_ndo_set_vf_port_vlan(i40e_netdev_ops_group1, ldvarg69, (int )ldvarg68,
                                (int )ldvarg67);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_ndo_set_vf_port_vlan(i40e_netdev_ops_group1, ldvarg69, (int )ldvarg68,
                                (int )ldvarg67);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_ndo_set_vf_port_vlan(i40e_netdev_ops_group1, ldvarg69, (int )ldvarg68,
                                (int )ldvarg67);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 16: ;
    if (ldv_state_variable_14 == 1) {
      i40e_netpoll(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_netpoll(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_netpoll(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 17: ;
    if (ldv_state_variable_14 == 1) {
      i40e_ndo_fdb_add(ldvarg64, ldvarg65, i40e_netdev_ops_group1, (unsigned char const   *)ldvarg63,
                       (int )ldvarg66, (int )ldvarg62);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_ndo_fdb_add(ldvarg64, ldvarg65, i40e_netdev_ops_group1, (unsigned char const   *)ldvarg63,
                       (int )ldvarg66, (int )ldvarg62);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_ndo_fdb_add(ldvarg64, ldvarg65, i40e_netdev_ops_group1, (unsigned char const   *)ldvarg63,
                       (int )ldvarg66, (int )ldvarg62);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 18: ;
    if (ldv_state_variable_14 == 1) {
      i40e_add_vxlan_port(i40e_netdev_ops_group1, (int )ldvarg61, (int )ldvarg60);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_add_vxlan_port(i40e_netdev_ops_group1, (int )ldvarg61, (int )ldvarg60);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_add_vxlan_port(i40e_netdev_ops_group1, (int )ldvarg61, (int )ldvarg60);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 19: ;
    if (ldv_state_variable_14 == 1) {
      i40e_set_features(i40e_netdev_ops_group1, ldvarg59);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_set_features(i40e_netdev_ops_group1, ldvarg59);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_set_features(i40e_netdev_ops_group1, ldvarg59);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 20: ;
    if (ldv_state_variable_14 == 3) {
      i40e_change_mtu(i40e_netdev_ops_group1, ldvarg58);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_change_mtu(i40e_netdev_ops_group1, ldvarg58);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 21: ;
    if (ldv_state_variable_14 == 1) {
      i40e_fcoe_disable(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_fcoe_disable(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_fcoe_disable(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 22: ;
    if (ldv_state_variable_14 == 1) {
      i40e_set_mac(i40e_netdev_ops_group1, ldvarg57);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_set_mac(i40e_netdev_ops_group1, ldvarg57);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_set_mac(i40e_netdev_ops_group1, ldvarg57);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 23: ;
    if (ldv_state_variable_14 == 1) {
      i40e_setup_tc(i40e_netdev_ops_group1, (int )ldvarg56);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_setup_tc(i40e_netdev_ops_group1, (int )ldvarg56);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_setup_tc(i40e_netdev_ops_group1, (int )ldvarg56);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 24: ;
    if (ldv_state_variable_14 == 1) {
      i40e_ndo_set_vf_mac(i40e_netdev_ops_group1, ldvarg55, ldvarg54);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_ndo_set_vf_mac(i40e_netdev_ops_group1, ldvarg55, ldvarg54);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_ndo_set_vf_mac(i40e_netdev_ops_group1, ldvarg55, ldvarg54);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 25: ;
    if (ldv_state_variable_14 == 1) {
      i40e_get_netdev_stats_struct(i40e_netdev_ops_group1, ldvarg53);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_get_netdev_stats_struct(i40e_netdev_ops_group1, ldvarg53);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_get_netdev_stats_struct(i40e_netdev_ops_group1, ldvarg53);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 26: ;
    if (ldv_state_variable_14 == 1) {
      i40e_tx_timeout(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 1;
    } else {

    }
    if (ldv_state_variable_14 == 3) {
      i40e_tx_timeout(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 3;
    } else {

    }
    if (ldv_state_variable_14 == 2) {
      i40e_tx_timeout(i40e_netdev_ops_group1);
      ldv_state_variable_14 = 2;
    } else {

    }
    goto ldv_63967;
    case 27: ;
    if (ldv_state_variable_14 == 1) {
      ldv_retval_8 = ldv_ndo_init_14();
      if (ldv_retval_8 == 0) {
        ldv_state_variable_14 = 2;
        ref_cnt = ref_cnt + 1;
      } else {

      }
    } else {

    }
    goto ldv_63967;
    case 28: ;
    if (ldv_state_variable_14 == 2) {
      ldv_ndo_uninit_14();
      ldv_state_variable_14 = 1;
      ref_cnt = ref_cnt - 1;
    } else {

    }
    goto ldv_63967;
    default: 
    ldv_stop();
    }
    ldv_63967: ;
  } else {

  }
  goto ldv_63948;
  case 8: ;
  if (ldv_state_variable_8 != 0) {
    ldv_main_exported_8();
  } else {

  }
  goto ldv_63948;
  case 9: ;
  if (ldv_state_variable_1 != 0) {
    choose_interrupt_1();
  } else {

  }
  goto ldv_63948;
  case 10: ;
  if (ldv_state_variable_4 != 0) {
    invoke_work_4();
  } else {

  }
  goto ldv_63948;
  case 11: ;
  if (ldv_state_variable_0 != 0) {
    tmp___13 = __VERIFIER_nondet_int();
    switch (tmp___13) {
    case 0: ;
    if (ldv_state_variable_0 == 2 && ref_cnt == 0) {
      i40e_exit_module();
      ldv_state_variable_0 = 3;
      goto ldv_final;
    } else {

    }
    goto ldv_64003;
    case 1: ;
    if (ldv_state_variable_0 == 1) {
      ldv_retval_11 = i40e_init_module();
      if (ldv_retval_11 != 0) {
        ldv_state_variable_0 = 3;
        goto ldv_final;
      } else {

      }
      if (ldv_retval_11 == 0) {
        ldv_state_variable_0 = 2;
        ldv_state_variable_9 = 1;
        ldv_file_operations_9();
        ldv_state_variable_10 = 1;
        ldv_file_operations_10();
        ldv_state_variable_13 = 1;
        ldv_initialize_pci_error_handlers_13();
        ldv_state_variable_7 = 1;
        ldv_initialize_dcbnl_rtnl_ops_7();
        ldv_state_variable_11 = 1;
        ldv_initialize_ethtool_ops_11();
        ldv_state_variable_8 = 1;
        ldv_file_operations_8();
      } else {

      }
    } else {

    }
    goto ldv_64003;
    default: 
    ldv_stop();
    }
    ldv_64003: ;
  } else {

  }
  goto ldv_63948;
  case 12: ;
  if (ldv_state_variable_13 != 0) {
    tmp___14 = __VERIFIER_nondet_int();
    switch (tmp___14) {
    case 0: ;
    if (ldv_state_variable_13 == 3) {
      i40e_pci_error_resume(i40e_err_handler_group0);
      ldv_state_variable_13 = 2;
    } else {

    }
    goto ldv_64008;
    case 1: ;
    if (ldv_state_variable_13 == 1) {
      i40e_pci_error_slot_reset(i40e_err_handler_group0);
      ldv_state_variable_13 = 1;
    } else {

    }
    if (ldv_state_variable_13 == 3) {
      i40e_pci_error_slot_reset(i40e_err_handler_group0);
      ldv_state_variable_13 = 3;
    } else {

    }
    if (ldv_state_variable_13 == 2) {
      i40e_pci_error_slot_reset(i40e_err_handler_group0);
      ldv_state_variable_13 = 2;
    } else {

    }
    goto ldv_64008;
    case 2: ;
    if (ldv_state_variable_13 == 1) {
      i40e_pci_error_detected(i40e_err_handler_group0, ldvarg95);
      ldv_state_variable_13 = 1;
    } else {

    }
    if (ldv_state_variable_13 == 3) {
      i40e_pci_error_detected(i40e_err_handler_group0, ldvarg95);
      ldv_state_variable_13 = 3;
    } else {

    }
    if (ldv_state_variable_13 == 2) {
      i40e_pci_error_detected(i40e_err_handler_group0, ldvarg95);
      ldv_state_variable_13 = 2;
    } else {

    }
    goto ldv_64008;
    case 3: ;
    if (ldv_state_variable_13 == 2) {
      ldv_suspend_13();
      ldv_state_variable_13 = 3;
    } else {

    }
    goto ldv_64008;
    case 4: ;
    if (ldv_state_variable_13 == 3) {
      ldv_release_13();
      ldv_state_variable_13 = 1;
      ref_cnt = ref_cnt - 1;
    } else {

    }
    if (ldv_state_variable_13 == 2) {
      ldv_release_13();
      ldv_state_variable_13 = 1;
      ref_cnt = ref_cnt - 1;
    } else {

    }
    goto ldv_64008;
    case 5: ;
    if (ldv_state_variable_13 == 1) {
      ldv_probe_13();
      ldv_state_variable_13 = 2;
      ref_cnt = ref_cnt + 1;
    } else {

    }
    goto ldv_64008;
    default: 
    ldv_stop();
    }
    ldv_64008: ;
  } else {

  }
  goto ldv_63948;
  case 13: ;
  if (ldv_state_variable_10 != 0) {
    ldv_main_exported_10();
  } else {

  }
  goto ldv_63948;
  case 14: ;
  if (ldv_state_variable_5 != 0) {
    choose_timer_5();
  } else {

  }
  goto ldv_63948;
  default: 
  ldv_stop();
  }
  ldv_63948: ;
  goto ldv_64018;
  ldv_final: 
  ldv_check_final_state();
  return 0;
}
}
bool ldv_queue_work_on_5(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                         struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_6(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                 struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_7(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                         struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_8(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_9(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                 struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_10(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_11(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_12(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_13(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_14(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_15(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_16(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
__inline static int ldv_request_irq_17(unsigned int irq , irqreturn_t (*handler)(int  ,
                                                                                 void * ) ,
                                       unsigned long flags , char const   *name ,
                                       void *dev ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = request_irq(irq, handler, flags, name, dev);
  ldv_func_res = tmp;
  tmp___0 = reg_check_3(handler);
  if (tmp___0 != 0 && ldv_func_res == 0) {
    activate_suitable_irq_3((int )irq, dev);
  } else {

  }
  return (ldv_func_res);
}
}
void ldv_free_irq_18(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) 
{ 


  {
  free_irq(ldv_func_arg1, ldv_func_arg2);
  disable_suitable_irq_3((int )ldv_func_arg1, ldv_func_arg2);
  return;
}
}
__inline static int ldv_request_irq_19(unsigned int irq , irqreturn_t (*handler)(int  ,
                                                                                 void * ) ,
                                       unsigned long flags , char const   *name ,
                                       void *dev ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = request_irq(irq, handler, flags, name, dev);
  ldv_func_res = tmp;
  tmp___0 = reg_check_3(handler);
  if (tmp___0 != 0 && ldv_func_res == 0) {
    activate_suitable_irq_3((int )irq, dev);
  } else {

  }
  return (ldv_func_res);
}
}
__inline static int ldv_request_irq_20(unsigned int irq , irqreturn_t (*handler)(int  ,
                                                                                 void * ) ,
                                       unsigned long flags , char const   *name ,
                                       void *dev ) 
{ 
  ldv_func_ret_type___6 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = request_irq(irq, handler, flags, name, dev);
  ldv_func_res = tmp;
  tmp___0 = reg_check_3(handler);
  if (tmp___0 != 0 && ldv_func_res == 0) {
    activate_suitable_irq_3((int )irq, dev);
  } else {

  }
  return (ldv_func_res);
}
}
void ldv_free_irq_21(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) 
{ 


  {
  free_irq(ldv_func_arg1, ldv_func_arg2);
  disable_suitable_irq_3((int )ldv_func_arg1, ldv_func_arg2);
  return;
}
}
void ldv_free_irq_22(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) 
{ 


  {
  free_irq(ldv_func_arg1, ldv_func_arg2);
  disable_suitable_irq_3((int )ldv_func_arg1, ldv_func_arg2);
  return;
}
}
void ldv_free_irq_23(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) 
{ 


  {
  free_irq(ldv_func_arg1, ldv_func_arg2);
  disable_suitable_irq_3((int )ldv_func_arg1, ldv_func_arg2);
  return;
}
}
int ldv_mod_timer_24(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___7 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_5(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_25(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_switch_mutex_of_i40e_pf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_26(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_switch_mutex_of_i40e_pf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_27(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_switch_mutex_of_i40e_pf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_28(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_switch_mutex_of_i40e_pf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
__inline static int ldv_request_irq_29(unsigned int irq , irqreturn_t (*handler)(int  ,
                                                                                 void * ) ,
                                       unsigned long flags , char const   *name ,
                                       void *dev ) 
{ 
  ldv_func_ret_type___8 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = request_irq(irq, handler, flags, name, dev);
  ldv_func_res = tmp;
  tmp___0 = reg_check_3(handler);
  if (tmp___0 != 0 && ldv_func_res == 0) {
    activate_suitable_irq_3((int )irq, dev);
  } else {

  }
  return (ldv_func_res);
}
}
void ldv_unregister_netdev_30(struct net_device *dev ) 
{ 


  {
  unregister_netdev(dev);
  ldv_state_variable_6 = 0;
  return;
}
}
void ldv_free_netdev_31(struct net_device *dev ) 
{ 


  {
  free_netdev(dev);
  ldv_state_variable_6 = 0;
  return;
}
}
void ldv_unregister_netdev_32(struct net_device *dev ) 
{ 


  {
  unregister_netdev(dev);
  ldv_state_variable_6 = 0;
  return;
}
}
void ldv_free_netdev_33(struct net_device *dev ) 
{ 


  {
  free_netdev(dev);
  ldv_state_variable_6 = 0;
  return;
}
}
int ldv_register_netdev_34(struct net_device *dev ) 
{ 
  ldv_func_ret_type___9 ldv_func_res ;
  int tmp ;

  {
  tmp = register_netdev(dev);
  ldv_func_res = tmp;
  ldv_state_variable_6 = 1;
  ldv_net_device_ops_6();
  return (ldv_func_res);
}
}
void ldv_unregister_netdev_35(struct net_device *dev ) 
{ 


  {
  unregister_netdev(dev);
  ldv_state_variable_6 = 0;
  return;
}
}
void ldv_free_netdev_36(struct net_device *dev ) 
{ 


  {
  free_netdev(dev);
  ldv_state_variable_6 = 0;
  return;
}
}
void ldv_mutex_lock_37(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_switch_mutex_of_i40e_pf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_38(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_switch_mutex_of_i40e_pf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_39(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_switch_mutex_of_i40e_pf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_40(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_switch_mutex_of_i40e_pf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
int ldv_mod_timer_41(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___10 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_5(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_42(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___11 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_5(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_43(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___12 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_5(ldv_func_arg1);
  return (ldv_func_res);
}
}
bool ldv_cancel_work_sync_44(struct work_struct *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___13 ldv_func_res ;
  bool tmp ;

  {
  tmp = cancel_work_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_work_4(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_45(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___14 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_5(ldv_func_arg1);
  return (ldv_func_res);
}
}
bool ldv_cancel_work_sync_46(struct work_struct *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___15 ldv_func_res ;
  bool tmp ;

  {
  tmp = cancel_work_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_work_4(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv___pci_register_driver_47(struct pci_driver *ldv_func_arg1 , struct module *ldv_func_arg2 ,
                                 char const   *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___16 ldv_func_res ;
  int tmp ;

  {
  tmp = __pci_register_driver(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  ldv_state_variable_12 = 1;
  ldv_pci_driver_12();
  return (ldv_func_res);
}
}
void ldv_pci_unregister_driver_48(struct pci_driver *ldv_func_arg1 ) 
{ 


  {
  pci_unregister_driver(ldv_func_arg1);
  ldv_state_variable_12 = 0;
  return;
}
}
__inline static __u32 __arch_swab32(__u32 val ) 
{ 


  {
  __asm__  ("bswapl %0": "=r" (val): "0" (val));
  return (val);
}
}
__inline static __u32 __fswab32(__u32 val ) 
{ 
  __u32 tmp ;

  {
  tmp = __arch_swab32(val);
  return (tmp);
}
}
__inline static void INIT_HLIST_NODE(struct hlist_node *h ) 
{ 


  {
  h->next = (struct hlist_node *)0;
  h->pprev = (struct hlist_node **)0;
  return;
}
}
__inline static void hlist_add_head(struct hlist_node *n , struct hlist_head *h ) 
{ 
  struct hlist_node *first ;

  {
  first = h->first;
  n->next = first;
  if ((unsigned long )first != (unsigned long )((struct hlist_node *)0)) {
    first->pprev = & n->next;
  } else {

  }
  h->first = n;
  n->pprev = & h->first;
  return;
}
}
__inline static void hlist_add_behind(struct hlist_node *n , struct hlist_node *prev ) 
{ 


  {
  n->next = prev->next;
  prev->next = n;
  n->pprev = & prev->next;
  if ((unsigned long )n->next != (unsigned long )((struct hlist_node *)0)) {
    (n->next)->pprev = & n->next;
  } else {

  }
  return;
}
}
int ldv_mutex_trylock_105(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_103(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_106(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_107(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_102(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_104(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_108(struct mutex *ldv_func_arg1 ) ;
__inline static void __preempt_count_add___0(int val ) 
{ 
  int pao_ID__ ;

  {
  pao_ID__ = 0;
  switch (4UL) {
  case 1UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incb %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decb %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addb %1, %%gs:%0": "+m" (__preempt_count): "qi" (val));
  }
  goto ldv_6609;
  case 2UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incw %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decw %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addw %1, %%gs:%0": "+m" (__preempt_count): "ri" (val));
  }
  goto ldv_6609;
  case 4UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incl %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decl %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addl %1, %%gs:%0": "+m" (__preempt_count): "ri" (val));
  }
  goto ldv_6609;
  case 8UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incq %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decq %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addq %1, %%gs:%0": "+m" (__preempt_count): "re" (val));
  }
  goto ldv_6609;
  default: 
  __bad_percpu_size();
  }
  ldv_6609: ;
  return;
}
}
__inline static void __preempt_count_sub___0(int val ) 
{ 
  int pao_ID__ ;

  {
  pao_ID__ = 0;
  switch (4UL) {
  case 1UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incb %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decb %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addb %1, %%gs:%0": "+m" (__preempt_count): "qi" (- val));
  }
  goto ldv_6621;
  case 2UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incw %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decw %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addw %1, %%gs:%0": "+m" (__preempt_count): "ri" (- val));
  }
  goto ldv_6621;
  case 4UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incl %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decl %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addl %1, %%gs:%0": "+m" (__preempt_count): "ri" (- val));
  }
  goto ldv_6621;
  case 8UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incq %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decq %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addq %1, %%gs:%0": "+m" (__preempt_count): "re" (- val));
  }
  goto ldv_6621;
  default: 
  __bad_percpu_size();
  }
  ldv_6621: ;
  return;
}
}
__inline static void __rcu_read_lock___0(void) 
{ 


  {
  __preempt_count_add___0(1);
  __asm__  volatile   ("": : : "memory");
  return;
}
}
__inline static void __rcu_read_unlock___0(void) 
{ 


  {
  __asm__  volatile   ("": : : "memory");
  __preempt_count_sub___0(1);
  return;
}
}
__inline static void rcu_read_lock___0(void) 
{ 
  bool __warned ;
  int tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  __rcu_read_lock___0();
  rcu_lock_acquire(& rcu_lock_map);
  tmp = debug_lockdep_rcu_enabled();
  if (tmp != 0 && ! __warned) {
    tmp___0 = rcu_is_watching();
    if (tmp___0) {
      tmp___1 = 0;
    } else {
      tmp___1 = 1;
    }
    if (tmp___1) {
      __warned = 1;
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 849, "rcu_read_lock() used illegally while idle");
    } else {

    }
  } else {

  }
  return;
}
}
__inline static void rcu_read_unlock___0(void) 
{ 
  bool __warned ;
  int tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  tmp = debug_lockdep_rcu_enabled();
  if (tmp != 0 && ! __warned) {
    tmp___0 = rcu_is_watching();
    if (tmp___0) {
      tmp___1 = 0;
    } else {
      tmp___1 = 1;
    }
    if (tmp___1) {
      __warned = 1;
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 900, "rcu_read_unlock() used illegally while idle");
    } else {

    }
  } else {

  }
  __rcu_read_unlock___0();
  rcu_lock_release(& rcu_lock_map);
  return;
}
}
bool ldv_queue_work_on_97(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_99(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_98(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_101(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_100(struct workqueue_struct *ldv_func_arg1 ) ;
__inline static void ethtool_cmd_speed_set(struct ethtool_cmd *ep , __u32 speed ) 
{ 


  {
  ep->speed = (unsigned short )speed;
  ep->speed_hi = (unsigned short )(speed >> 16);
  return;
}
}
extern u32 ethtool_op_get_link(struct net_device * ) ;
extern int ethtool_op_get_ts_info(struct net_device * , struct ethtool_ts_info * ) ;
extern int dev_open(struct net_device * ) ;
extern int dev_close(struct net_device * ) ;
__inline static char const   *pci_name(struct pci_dev  const  *pdev ) 
{ 
  char const   *tmp ;

  {
  tmp = dev_name(& pdev->dev);
  return (tmp);
}
}
extern int ptp_clock_index(struct ptp_clock * ) ;
u32 i40e_led_get(struct i40e_hw *hw ) ;
void i40e_led_set(struct i40e_hw *hw , u32 mode , bool blink ) ;
enum i40e_status_code i40e_aq_set_phy_config(struct i40e_hw *hw , struct i40e_aq_set_phy_config *config ,
                                             struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_read_nvm_word(struct i40e_hw *hw , u16 offset , u16 *data ) ;
i40e_status i40e_nvmupd_command(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                u8 *bytes , int *errno ) ;
__inline static struct i40e_pf *i40e_netdev_to_pf(struct net_device *netdev ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  return (vsi->back);
}
}
__inline static int i40e_get_fd_cnt_all(struct i40e_pf *pf ) 
{ 


  {
  return ((int )pf->hw.fdir_shared_filter_count + (int )pf->fdir_pf_filter_count);
}
}
struct i40e_diag_reg_test_info i40e_reg_list[12U] ;
i40e_status i40e_diag_reg_test(struct i40e_hw *hw ) ;
static struct i40e_stats  const  i40e_gstrings_net_stats[11U]  = 
  {      {{'r', 'x', '_', 'p', 'a', 'c', 'k', 'e', 't', 's', '\000'}, 8, 0}, 
        {{'t', 'x', '_', 'p', 'a', 'c', 'k', 'e', 't', 's', '\000'}, 8, 8}, 
        {{'r', 'x', '_', 'b', 'y', 't', 'e', 's', '\000'}, 8, 16}, 
        {{'t', 'x', '_', 'b', 'y', 't', 'e', 's', '\000'}, 8, 24}, 
        {{'r', 'x', '_', 'e', 'r', 'r', 'o', 'r', 's', '\000'}, 8, 32}, 
        {{'t', 'x', '_', 'e', 'r', 'r', 'o', 'r', 's', '\000'}, 8, 40}, 
        {{'r', 'x', '_', 'd', 'r', 'o', 'p', 'p', 'e', 'd', '\000'}, 8, 48}, 
        {{'t', 'x', '_', 'd', 'r', 'o', 'p', 'p', 'e', 'd', '\000'}, 8, 56}, 
        {{'c', 'o', 'l', 'l', 'i', 's', 'i', 'o', 'n', 's', '\000'}, 8, 72}, 
        {{'r', 'x', '_', 'l', 'e', 'n', 'g', 't', 'h', '_', 'e', 'r', 'r', 'o', 'r',
       's', '\000'}, 8, 80}, 
        {{'r', 'x', '_', 'c', 'r', 'c', '_', 'e', 'r', 'r', 'o', 'r', 's', '\000'}, 8,
      96}};
static struct i40e_stats  const  i40e_gstrings_veb_stats[12U]  = 
  {      {{'r', 'x', '_', 'b', 'y', 't', 'e', 's', '\000'}, 8, 80}, 
        {{'t', 'x', '_', 'b', 'y', 't', 'e', 's', '\000'}, 8, 128}, 
        {{'r', 'x', '_', 'u', 'n', 'i', 'c', 'a', 's', 't', '\000'}, 8, 88}, 
        {{'t', 'x', '_', 'u', 'n', 'i', 'c', 'a', 's', 't', '\000'}, 8, 136}, 
        {{'r', 'x', '_', 'm', 'u', 'l', 't', 'i', 'c', 'a', 's', 't', '\000'}, 8, 96}, 
        {{'t',
       'x', '_', 'm', 'u', 'l', 't', 'i', 'c', 'a', 's', 't', '\000'}, 8, 144}, 
        {{'r', 'x', '_', 'b', 'r', 'o', 'a', 'd', 'c', 'a', 's', 't', '\000'}, 8, 104}, 
        {{'t',
       'x', '_', 'b', 'r', 'o', 'a', 'd', 'c', 'a', 's', 't', '\000'}, 8, 152}, 
        {{'r', 'x', '_', 'd', 'i', 's', 'c', 'a', 'r', 'd', 's', '\000'}, 8, 112}, 
        {{'t', 'x', '_', 'd', 'i', 's', 'c', 'a', 'r', 'd', 's', '\000'}, 8, 160}, 
        {{'t', 'x', '_', 'e', 'r', 'r', 'o', 'r', 's', '\000'}, 8, 168}, 
        {{'r', 'x', '_', 'u', 'n', 'k', 'n', 'o', 'w', 'n', '_', 'p', 'r', 'o', 't',
       'o', 'c', 'o', 'l', '\000'}, 8, 120}};
static struct i40e_stats  const  i40e_gstrings_misc_stats[7U]  = {      {{'r', 'x', '_', 'u', 'n', 'i', 'c', 'a', 's', 't', '\000'}, 8, 936}, 
        {{'t', 'x', '_', 'u', 'n', 'i', 'c', 'a', 's', 't', '\000'}, 8, 984}, 
        {{'r', 'x', '_', 'm', 'u', 'l', 't', 'i', 'c', 'a', 's', 't', '\000'}, 8, 944}, 
        {{'t',
       'x', '_', 'm', 'u', 'l', 't', 'i', 'c', 'a', 's', 't', '\000'}, 8, 992}, 
        {{'r', 'x', '_', 'b', 'r', 'o', 'a', 'd', 'c', 'a', 's', 't', '\000'}, 8, 952}, 
        {{'t',
       'x', '_', 'b', 'r', 'o', 'a', 'd', 'c', 'a', 's', 't', '\000'}, 8, 1000}, 
        {{'r', 'x', '_', 'u', 'n', 'k', 'n', 'o', 'w', 'n', '_', 'p', 'r', 'o', 't',
       'o', 'c', 'o', 'l', '\000'}, 8, 968}};
static int i40e_add_fdir_ethtool(struct i40e_vsi *vsi , struct ethtool_rxnfc *cmd ) ;
static struct i40e_stats i40e_gstrings_stats[50U]  = 
  {      {{'r', 'x', '_', 'b', 'y', 't', 'e', 's', '\000'}, 8, 133120}, 
        {{'t', 'x', '_', 'b', 'y', 't', 'e', 's', '\000'}, 8, 133168}, 
        {{'r', 'x', '_', 'u', 'n', 'i', 'c', 'a', 's', 't', '\000'}, 8, 133128}, 
        {{'t', 'x', '_', 'u', 'n', 'i', 'c', 'a', 's', 't', '\000'}, 8, 133176}, 
        {{'r', 'x', '_', 'm', 'u', 'l', 't', 'i', 'c', 'a', 's', 't', '\000'}, 8, 133136}, 
        {{'t',
       'x', '_', 'm', 'u', 'l', 't', 'i', 'c', 'a', 's', 't', '\000'}, 8, 133184}, 
        {{'r',
       'x', '_', 'b', 'r', 'o', 'a', 'd', 'c', 'a', 's', 't', '\000'}, 8, 133144}, 
        {{'t',
       'x', '_', 'b', 'r', 'o', 'a', 'd', 'c', 'a', 's', 't', '\000'}, 8, 133192}, 
        {{'t',
       'x', '_', 'e', 'r', 'r', 'o', 'r', 's', '\000'}, 8, 133208}, 
        {{'r', 'x', '_', 'd', 'r', 'o', 'p', 'p', 'e', 'd', '\000'}, 8, 133152}, 
        {{'t', 'x', '_', 'd', 'r', 'o', 'p', 'p', 'e', 'd', '_', 'l', 'i', 'n', 'k',
       '_', 'd', 'o', 'w', 'n', '\000'}, 8, 133216}, 
        {{'c', 'r', 'c', '_', 'e', 'r', 'r', 'o', 'r', 's', '\000'}, 8, 133224}, 
        {{'i', 'l', 'l', 'e', 'g', 'a', 'l', '_', 'b', 'y', 't', 'e', 's', '\000'}, 8,
      133232}, 
        {{'m', 'a', 'c', '_', 'l', 'o', 'c', 'a', 'l', '_', 'f', 'a', 'u', 'l', 't',
       's', '\000'}, 8, 133248}, 
        {{'m', 'a', 'c', '_', 'r', 'e', 'm', 'o', 't', 'e', '_', 'f', 'a', 'u', 'l',
       't', 's', '\000'}, 8, 133256}, 
        {{'t', 'x', '_', 't', 'i', 'm', 'e', 'o', 'u', 't', '\000'}, 4, 134544}, 
        {{'r', 'x', '_', 'c', 's', 'u', 'm', '_', 'b', 'a', 'd', '\000'}, 4, 134564}, 
        {{'r',
       'x', '_', 'l', 'e', 'n', 'g', 't', 'h', '_', 'e', 'r', 'r', 'o', 'r', 's',
       '\000'}, 8, 133264}, 
        {{'l', 'i', 'n', 'k', '_', 'x', 'o', 'n', '_', 'r', 'x', '\000'}, 8, 133272}, 
        {{'l',
       'i', 'n', 'k', '_', 'x', 'o', 'f', 'f', '_', 'r', 'x', '\000'}, 8, 133280}, 
        {{'l',
       'i', 'n', 'k', '_', 'x', 'o', 'n', '_', 't', 'x', '\000'}, 8, 133416}, 
        {{'l', 'i', 'n', 'k', '_', 'x', 'o', 'f', 'f', '_', 't', 'x', '\000'}, 8, 133424}, 
        {{'r',
       'x', '_', 's', 'i', 'z', 'e', '_', '6', '4', '\000'}, 8, 133624}, 
        {{'r', 'x', '_', 's', 'i', 'z', 'e', '_', '1', '2', '7', '\000'}, 8, 133632}, 
        {{'r',
       'x', '_', 's', 'i', 'z', 'e', '_', '2', '5', '5', '\000'}, 8, 133640}, 
        {{'r', 'x', '_', 's', 'i', 'z', 'e', '_', '5', '1', '1', '\000'}, 8, 133648}, 
        {{'r',
       'x', '_', 's', 'i', 'z', 'e', '_', '1', '0', '2', '3', '\000'}, 8, 133656}, 
        {{'r',
       'x', '_', 's', 'i', 'z', 'e', '_', '1', '5', '2', '2', '\000'}, 8, 133664}, 
        {{'r',
       'x', '_', 's', 'i', 'z', 'e', '_', 'b', 'i', 'g', '\000'}, 8, 133672}, 
        {{'t', 'x', '_', 's', 'i', 'z', 'e', '_', '6', '4', '\000'}, 8, 133712}, 
        {{'t', 'x', '_', 's', 'i', 'z', 'e', '_', '1', '2', '7', '\000'}, 8, 133720}, 
        {{'t',
       'x', '_', 's', 'i', 'z', 'e', '_', '2', '5', '5', '\000'}, 8, 133728}, 
        {{'t', 'x', '_', 's', 'i', 'z', 'e', '_', '5', '1', '1', '\000'}, 8, 133736}, 
        {{'t',
       'x', '_', 's', 'i', 'z', 'e', '_', '1', '0', '2', '3', '\000'}, 8, 133744}, 
        {{'t',
       'x', '_', 's', 'i', 'z', 'e', '_', '1', '5', '2', '2', '\000'}, 8, 133752}, 
        {{'t',
       'x', '_', 's', 'i', 'z', 'e', '_', 'b', 'i', 'g', '\000'}, 8, 133760}, 
        {{'r', 'x', '_', 'u', 'n', 'd', 'e', 'r', 's', 'i', 'z', 'e', '\000'}, 8, 133680}, 
        {{'r',
       'x', '_', 'f', 'r', 'a', 'g', 'm', 'e', 'n', 't', 's', '\000'}, 8, 133688}, 
        {{'r',
       'x', '_', 'o', 'v', 'e', 'r', 's', 'i', 'z', 'e', '\000'}, 8, 133696}, 
        {{'r', 'x', '_', 'j', 'a', 'b', 'b', 'e', 'r', '\000'}, 8, 133704}, 
        {{'V', 'F', '_', 'a', 'd', 'm', 'i', 'n', '_', 'q', 'u', 'e', 'u', 'e', '_',
       'r', 'e', 'q', 'u', 'e', 's', 't', 's', '\000'}, 4, 134948}, 
        {{'r', 'x', '_', 'h', 'w', 't', 's', 't', 'a', 'm', 'p', '_', 'c', 'l', 'e',
       'a', 'r', 'e', 'd', '\000'}, 4, 135220}, 
        {{'f', 'd', 'i', 'r', '_', 'f', 'l', 'u', 's', 'h', '_', 'c', 'n', 't', '\000'},
      4, 1680}, 
        {{'f', 'd', 'i', 'r', '_', 'a', 't', 'r', '_', 'm', 'a', 't', 'c', 'h', '\000'},
      8, 133784}, 
        {{'f', 'd', 'i', 'r', '_', 'a', 't', 'r', '_', 't', 'u', 'n', 'n', 'e', 'l',
       '_', 'm', 'a', 't', 'c', 'h', '\000'}, 8, 133800}, 
        {{'f', 'd', 'i', 'r', '_', 's', 'b', '_', 'm', 'a', 't', 'c', 'h', '\000'}, 8,
      133792}, 
        {{'t', 'x', '_', 'l', 'p', 'i', '_', 's', 't', 'a', 't', 'u', 's', '\000'}, 4,
      133808}, 
        {{'r', 'x', '_', 'l', 'p', 'i', '_', 's', 't', 'a', 't', 'u', 's', '\000'}, 4,
      133812}, 
        {{'t', 'x', '_', 'l', 'p', 'i', '_', 'c', 'o', 'u', 'n', 't', '\000'}, 8, 133816}, 
        {{'r',
       'x', '_', 'l', 'p', 'i', '_', 'c', 'o', 'u', 'n', 't', '\000'}, 8, 133824}};
static struct i40e_stats  const  i40e_gstrings_fcoe_stats[8U]  = 
  {      {{'f', 'c', 'o', 'e', '_', 'b', 'a', 'd', '_', 'f', 'c', 'c', 'r', 'c', '\000'},
      8, 1160}, 
        {{'r', 'x', '_', 'f', 'c', 'o', 'e', '_', 'd', 'r', 'o', 'p', 'p', 'e', 'd',
       '\000'}, 8, 1136}, 
        {{'r', 'x', '_', 'f', 'c', 'o', 'e', '_', 'p', 'a', 'c', 'k', 'e', 't', 's',
       '\000'}, 8, 1120}, 
        {{'r', 'x', '_', 'f', 'c', 'o', 'e', '_', 'd', 'w', 'o', 'r', 'd', 's', '\000'},
      8, 1128}, 
        {{'f', 'c', 'o', 'e', '_', 'd', 'd', 'p', '_', 'c', 'o', 'u', 'n', 't', '\000'},
      8, 1176}, 
        {{'f', 'c', 'o', 'e', '_', 'l', 'a', 's', 't', '_', 'e', 'r', 'r', 'o', 'r',
       '\000'}, 8, 1168}, 
        {{'t', 'x', '_', 'f', 'c', 'o', 'e', '_', 'p', 'a', 'c', 'k', 'e', 't', 's',
       '\000'}, 8, 1144}, 
        {{'t', 'x', '_', 'f', 'c', 'o', 'e', '_', 'd', 'w', 'o', 'r', 'd', 's', '\000'},
      8, 1152}};
static char const   i40e_gstrings_test[5U][32U]  = { {        'R',        'e',        'g',        'i', 
            's',        't',        'e',        'r', 
            ' ',        't',        'e',        's', 
            't',        ' ',        ' ',        '(', 
            'o',        'f',        'f',        'l', 
            'i',        'n',        'e',        ')', 
            '\000'}, 
   {        'E',        'e',        'p',        'r', 
            'o',        'm',        ' ',        't', 
            'e',        's',        't',        ' ', 
            ' ',        ' ',        ' ',        '(', 
            'o',        'f',        'f',        'l', 
            'i',        'n',        'e',        ')', 
            '\000'}, 
   {        'I',        'n',        't',        'e', 
            'r',        'r',        'u',        'p', 
            't',        ' ',        't',        'e', 
            's',        't',        ' ',        '(', 
            'o',        'f',        'f',        'l', 
            'i',        'n',        'e',        ')', 
            '\000'}, 
   {        'L',        'o',        'o',        'p', 
            'b',        'a',        'c',        'k', 
            ' ',        't',        'e',        's', 
            't',        ' ',        ' ',        '(', 
            'o',        'f',        'f',        'l', 
            'i',        'n',        'e',        ')', 
            '\000'}, 
   {        'L',        'i',        'n',        'k', 
            ' ',        't',        'e',        's', 
            't',        ' ',        ' ',        ' ', 
            '(',        'o',        'n',        '/', 
            'o',        'f',        'f',        'l', 
            'i',        'n',        'e',        ')', 
            '\000'}};
static char const   i40e_priv_flags_strings[1U][32U]  = { {        'N',        'P',        'A',        'R', 
            '\000'}};
static void i40e_partition_setting_complaint(struct i40e_pf *pf ) 
{ 


  {
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "The link settings are allowed to be changed only from the first partition of a given port. Please switch to the first partition in order to change the setting.\n");
  return;
}
}
static void i40e_get_settings_link_up(struct i40e_hw *hw , struct ethtool_cmd *ecmd ,
                                      struct net_device *netdev ) 
{ 
  struct i40e_link_status *hw_link_info ;
  u32 link_speed ;

  {
  hw_link_info = & hw->phy.link_info;
  link_speed = hw_link_info->link_speed;
  switch ((unsigned int )hw_link_info->phy_type) {
  case 24U: ;
  case 10U: 
  ecmd->supported = 16777280U;
  ecmd->advertising = 16777280U;
  goto ldv_61028;
  case 8U: ;
  case 9U: ;
  case 13U: 
  ecmd->supported = 16777216U;
  goto ldv_61028;
  case 4U: 
  ecmd->supported = 8388672U;
  ecmd->advertising = 8388672U;
  goto ldv_61028;
  case 25U: 
  ecmd->supported = 33554432U;
  goto ldv_61028;
  case 26U: 
  ecmd->supported = 67108864U;
  goto ldv_61028;
  case 30U: 
  ecmd->supported = 4194368U;
  ecmd->advertising = 4194368U;
  goto ldv_61028;
  case 2U: 
  ecmd->supported = 262208U;
  ecmd->advertising = 262208U;
  goto ldv_61028;
  case 3U: 
  ecmd->supported = 524352U;
  ecmd->advertising = 524352U;
  goto ldv_61028;
  case 20U: ;
  case 21U: ;
  case 27U: ;
  case 28U: 
  ecmd->supported = 4128U;
  if (((int )hw_link_info->requested_speeds & 8) != 0) {
    ecmd->advertising = ecmd->advertising | 4096U;
  } else {

  }
  if (((int )hw_link_info->requested_speeds & 4) != 0) {
    ecmd->advertising = ecmd->advertising | 32U;
  } else {

  }
  goto ldv_61028;
  case 1U: 
  ecmd->supported = 131136U;
  ecmd->advertising = 131136U;
  goto ldv_61028;
  case 19U: ;
  case 18U: ;
  case 17U: 
  ecmd->supported = 4200U;
  ecmd->advertising = 64U;
  if (((int )hw_link_info->requested_speeds & 8) != 0) {
    ecmd->advertising = ecmd->advertising | 4096U;
  } else {

  }
  if (((int )hw_link_info->requested_speeds & 4) != 0) {
    ecmd->advertising = ecmd->advertising | 32U;
  } else {

  }
  if (((int )hw_link_info->requested_speeds & 2) != 0) {
    ecmd->advertising = ecmd->advertising | 8U;
  } else {

  }
  goto ldv_61028;
  case 11U: ;
  case 23U: 
  ecmd->supported = 4160U;
  ecmd->advertising = 4160U;
  goto ldv_61028;
  case 5U: ;
  case 6U: ;
  case 7U: ;
  case 22U: ;
  case 12U: 
  ecmd->supported = 4096U;
  goto ldv_61028;
  case 0U: 
  ecmd->supported = 104U;
  if (((int )hw_link_info->requested_speeds & 4) != 0) {
    ecmd->advertising = ecmd->advertising | 32U;
  } else {

  }
  if (((int )hw_link_info->requested_speeds & 2) != 0) {
    ecmd->advertising = ecmd->advertising | 8U;
  } else {

  }
  goto ldv_61028;
  default: 
  netdev_info((struct net_device  const  *)netdev, "WARNING: Link is up but PHY type 0x%x is not recognized.\n",
              (unsigned int )hw_link_info->phy_type);
  }
  ldv_61028: ;
  switch (link_speed) {
  case 16U: 
  ethtool_cmd_speed_set(ecmd, 40000U);
  goto ldv_61056;
  case 32U: 
  ethtool_cmd_speed_set(ecmd, 20000U);
  goto ldv_61056;
  case 8U: 
  ethtool_cmd_speed_set(ecmd, 10000U);
  goto ldv_61056;
  case 4U: 
  ethtool_cmd_speed_set(ecmd, 1000U);
  goto ldv_61056;
  case 2U: 
  ethtool_cmd_speed_set(ecmd, 100U);
  goto ldv_61056;
  default: ;
  goto ldv_61056;
  }
  ldv_61056: 
  ecmd->duplex = 1U;
  return;
}
}
static void i40e_get_settings_link_down(struct i40e_hw *hw , struct ethtool_cmd *ecmd ) 
{ 
  struct i40e_link_status *hw_link_info ;

  {
  hw_link_info = & hw->phy.link_info;
  switch ((int )hw->device_id) {
  case 5507: ;
  case 5508: ;
  case 5509: 
  ecmd->supported = 117440512U;
  ecmd->advertising = 117440512U;
  goto ldv_61070;
  case 5504: 
  ecmd->supported = 8388608U;
  ecmd->advertising = 8388608U;
  goto ldv_61070;
  case 5505: 
  ecmd->supported = 524288U;
  ecmd->advertising = 524288U;
  goto ldv_61070;
  case 5510: 
  ecmd->supported = 4136U;
  if (((int )hw_link_info->requested_speeds & 8) != 0) {
    ecmd->advertising = ecmd->advertising | 4096U;
  } else {

  }
  if (((int )hw_link_info->requested_speeds & 4) != 0) {
    ecmd->advertising = ecmd->advertising | 32U;
  } else {

  }
  if (((int )hw_link_info->requested_speeds & 2) != 0) {
    ecmd->advertising = ecmd->advertising | 8U;
  } else {

  }
  goto ldv_61070;
  case 5511: 
  ecmd->supported = 4194304U;
  ecmd->advertising = 4194304U;
  goto ldv_61070;
  default: 
  ecmd->supported = 4128U;
  if (((int )hw_link_info->requested_speeds & 8) != 0) {
    ecmd->advertising = ecmd->advertising | 4096U;
  } else {

  }
  if (((int )hw_link_info->requested_speeds & 4) != 0) {
    ecmd->advertising = ecmd->advertising | 32U;
  } else {

  }
  goto ldv_61070;
  }
  ldv_61070: 
  ethtool_cmd_speed_set(ecmd, 4294967295U);
  ecmd->duplex = 255U;
  return;
}
}
static int i40e_get_settings(struct net_device *netdev , struct ethtool_cmd *ecmd ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  struct i40e_link_status *hw_link_info ;
  bool link_up ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  hw = & pf->hw;
  hw_link_info = & hw->phy.link_info;
  link_up = ((int )hw_link_info->link_info & 1) != 0;
  if ((int )link_up) {
    i40e_get_settings_link_up(hw, ecmd, netdev);
  } else {
    i40e_get_settings_link_down(hw, ecmd);
  }
  ecmd->autoneg = (unsigned int )hw_link_info->an_info & 1U;
  switch ((unsigned int )hw->phy.media_type) {
  case 3U: 
  ecmd->supported = ecmd->supported | 65600U;
  ecmd->advertising = ecmd->advertising | 65600U;
  ecmd->port = 239U;
  goto ldv_61086;
  case 2U: 
  ecmd->supported = ecmd->supported | 128U;
  ecmd->advertising = ecmd->advertising | 128U;
  ecmd->port = 0U;
  goto ldv_61086;
  case 5U: ;
  case 4U: 
  ecmd->supported = ecmd->supported | 1024U;
  ecmd->advertising = ecmd->advertising | 1024U;
  ecmd->port = 5U;
  goto ldv_61086;
  case 1U: 
  ecmd->supported = ecmd->supported | 1024U;
  ecmd->port = 3U;
  goto ldv_61086;
  case 0U: ;
  default: 
  ecmd->port = 255U;
  goto ldv_61086;
  }
  ldv_61086: 
  ecmd->transceiver = 1U;
  ecmd->supported = ecmd->supported | 8192U;
  switch ((unsigned int )hw->fc.requested_mode) {
  case 3U: 
  ecmd->advertising = ecmd->advertising | 8192U;
  goto ldv_61094;
  case 2U: 
  ecmd->advertising = ecmd->advertising | 16384U;
  goto ldv_61094;
  case 1U: 
  ecmd->advertising = ecmd->advertising | 24576U;
  goto ldv_61094;
  default: 
  ecmd->advertising = ecmd->advertising & 4294942719U;
  goto ldv_61094;
  }
  ldv_61094: ;
  return (0);
}
}
static int i40e_set_settings(struct net_device *netdev , struct ethtool_cmd *ecmd ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_aq_get_phy_abilities_resp abilities ;
  struct i40e_aq_set_phy_config config ;
  struct i40e_pf *pf ;
  struct i40e_vsi *vsi ;
  struct i40e_hw *hw ;
  struct ethtool_cmd safe_ecmd ;
  i40e_status status ;
  bool change ;
  int err ;
  u8 autoneg ;
  u32 advertise ;
  int tmp___0 ;
  int tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  vsi = np->vsi;
  hw = & pf->hw;
  status = 0;
  change = 0;
  err = 0;
  if ((unsigned int )hw->partition_id != 1U) {
    i40e_partition_setting_complaint(pf);
    return (-95);
  } else {

  }
  if ((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) != (unsigned long )vsi) {
    return (-95);
  } else {

  }
  if ((((unsigned int )hw->phy.media_type != 2U && (unsigned int )hw->phy.media_type != 1U) && (unsigned int )hw->phy.media_type != 3U) && (int )hw->phy.link_info.link_info & 1) {
    return (-95);
  } else {

  }
  memset((void *)(& safe_ecmd), 0, 44UL);
  i40e_get_settings(netdev, & safe_ecmd);
  autoneg = ecmd->autoneg;
  advertise = ecmd->advertising;
  ecmd->autoneg = safe_ecmd.autoneg;
  ecmd->advertising = safe_ecmd.advertising;
  ecmd->cmd = safe_ecmd.cmd;
  tmp___0 = memcmp((void const   *)ecmd, (void const   *)(& safe_ecmd), 44UL);
  if (tmp___0 != 0) {
    return (-95);
  } else {

  }
  goto ldv_61115;
  ldv_61114: 
  usleep_range(1000UL, 2000UL);
  ldv_61115: 
  tmp___1 = constant_test_bit(1L, (unsigned long const volatile   *)(& vsi->state));
  if (tmp___1 != 0) {
    goto ldv_61114;
  } else {

  }
  status = i40e_aq_get_phy_capabilities(hw, 0, 0, & abilities, (struct i40e_asq_cmd_details *)0);
  if ((int )status != 0) {
    return (-11);
  } else {

  }
  memset((void *)(& config), 0, 16UL);
  config.abilities = abilities.abilities;
  if ((unsigned int )autoneg == 1U) {
    if ((safe_ecmd.supported & 64U) == 0U) {
      netdev_info((struct net_device  const  *)netdev, "Autoneg not supported on this phy\n");
      return (-22);
    } else {

    }
    if (((int )hw->phy.link_info.an_info & 1) == 0) {
      config.abilities = (u8 )((unsigned int )abilities.abilities | 16U);
      change = 1;
    } else {

    }
  } else {
    if ((safe_ecmd.supported & 64U) != 0U && (unsigned int )hw->phy.link_info.phy_type != 19U) {
      netdev_info((struct net_device  const  *)netdev, "Autoneg cannot be disabled on this phy\n");
      return (-22);
    } else {

    }
    if ((int )hw->phy.link_info.an_info & 1) {
      config.abilities = (unsigned int )abilities.abilities & 239U;
      change = 1;
    } else {

    }
  }
  if ((~ safe_ecmd.supported & advertise) != 0U) {
    return (-22);
  } else {

  }
  if ((advertise & 8U) != 0U) {
    config.link_speed = (u8 )((unsigned int )config.link_speed | 2U);
  } else {

  }
  if ((advertise & 32U) != 0U || (advertise & 131072U) != 0U) {
    config.link_speed = (u8 )((unsigned int )config.link_speed | 4U);
  } else {

  }
  if (((advertise & 4096U) != 0U || (advertise & 262144U) != 0U) || (advertise & 524288U) != 0U) {
    config.link_speed = (u8 )((unsigned int )config.link_speed | 8U);
  } else {

  }
  if ((advertise & 4194304U) != 0U) {
    config.link_speed = (u8 )((unsigned int )config.link_speed | 32U);
  } else {

  }
  if ((((advertise & 8388608U) != 0U || (advertise & 16777216U) != 0U) || (advertise & 33554432U) != 0U) || (advertise & 67108864U) != 0U) {
    config.link_speed = (u8 )((unsigned int )config.link_speed | 16U);
  } else {

  }
  if ((int )change || (int )abilities.link_speed != (int )config.link_speed) {
    config.phy_type = abilities.phy_type;
    config.eee_capability = abilities.eee_capability;
    config.eeer = abilities.eeer_val;
    config.low_power_ctrl = abilities.d3_lpan;
    hw->phy.link_info.requested_speeds = config.link_speed;
    config.abilities = (u8 )((unsigned int )config.abilities | 32U);
    if ((int )hw->phy.link_info.link_info & 1) {
      netdev_info((struct net_device  const  *)netdev, "PHY settings change requested, NIC Link is going down.\n");
      netif_carrier_off(netdev);
      netif_tx_stop_all_queues(netdev);
    } else {

    }
    status = i40e_aq_set_phy_config(hw, & config, (struct i40e_asq_cmd_details *)0);
    if ((int )status != 0) {
      netdev_info((struct net_device  const  *)netdev, "Set phy config failed with error %d.\n",
                  (int )status);
      return (-11);
    } else {

    }
    status = i40e_aq_get_link_info(hw, 1, (struct i40e_link_status *)0, (struct i40e_asq_cmd_details *)0);
    if ((int )status != 0) {
      netdev_info((struct net_device  const  *)netdev, "Updating link info failed with error %d\n",
                  (int )status);
    } else {

    }
  } else {
    netdev_info((struct net_device  const  *)netdev, "Nothing changed, exiting without setting anything.\n");
  }
  return (err);
}
}
static int i40e_nway_reset(struct net_device *netdev ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  bool link_up ;
  i40e_status ret ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  hw = & pf->hw;
  link_up = ((int )hw->phy.link_info.link_info & 1) != 0;
  ret = 0;
  ret = i40e_aq_set_link_restart_an(hw, (int )link_up, (struct i40e_asq_cmd_details *)0);
  if ((int )ret != 0) {
    netdev_info((struct net_device  const  *)netdev, "link restart failed, aq_err=%d\n",
                (unsigned int )pf->hw.aq.asq_last_status);
    return (-5);
  } else {

  }
  return (0);
}
}
static void i40e_get_pauseparam(struct net_device *netdev , struct ethtool_pauseparam *pause ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  struct i40e_link_status *hw_link_info ;
  struct i40e_dcbx_config *dcbx_cfg ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  hw = & pf->hw;
  hw_link_info = & hw->phy.link_info;
  dcbx_cfg = & hw->local_dcbx_config;
  pause->autoneg = (__u32 )hw_link_info->an_info & 1U;
  if ((unsigned int )dcbx_cfg->pfc.pfcenable != 0U) {
    pause->rx_pause = 0U;
    pause->tx_pause = 0U;
    return;
  } else {

  }
  if ((unsigned int )hw->fc.current_mode == 1U) {
    pause->rx_pause = 1U;
  } else
  if ((unsigned int )hw->fc.current_mode == 2U) {
    pause->tx_pause = 1U;
  } else
  if ((unsigned int )hw->fc.current_mode == 3U) {
    pause->rx_pause = 1U;
    pause->tx_pause = 1U;
  } else {

  }
  return;
}
}
static int i40e_set_pauseparam(struct net_device *netdev , struct ethtool_pauseparam *pause ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  struct i40e_vsi *vsi ;
  struct i40e_hw *hw ;
  struct i40e_link_status *hw_link_info ;
  struct i40e_dcbx_config *dcbx_cfg ;
  bool link_up ;
  i40e_status status ;
  u8 aq_failures ;
  int err ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  vsi = np->vsi;
  hw = & pf->hw;
  hw_link_info = & hw->phy.link_info;
  dcbx_cfg = & hw->local_dcbx_config;
  link_up = ((int )hw_link_info->link_info & 1) != 0;
  err = 0;
  if ((unsigned int )hw->partition_id != 1U) {
    i40e_partition_setting_complaint(pf);
    return (-95);
  } else {

  }
  if ((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) != (unsigned long )vsi) {
    return (-95);
  } else {

  }
  if (pause->autoneg != ((int )hw_link_info->an_info & 1 ? 1U : 0U)) {
    netdev_info((struct net_device  const  *)netdev, "To change autoneg please use: ethtool -s <dev> autoneg <on|off>\n");
    return (-95);
  } else {

  }
  tmp___0 = constant_test_bit(3L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___0 == 0 && ((int )hw_link_info->an_info & 1) == 0) {
    netdev_info((struct net_device  const  *)netdev, "Autoneg did not complete so changing settings may not result in an actual change.\n");
  } else {

  }
  if ((unsigned int )dcbx_cfg->pfc.pfcenable != 0U) {
    netdev_info((struct net_device  const  *)netdev, "Priority flow control enabled. Cannot set link flow control.\n");
    return (-95);
  } else {

  }
  if (pause->rx_pause != 0U && pause->tx_pause != 0U) {
    hw->fc.requested_mode = 3;
  } else
  if (pause->rx_pause != 0U && pause->tx_pause == 0U) {
    hw->fc.requested_mode = 1;
  } else
  if (pause->rx_pause == 0U && pause->tx_pause != 0U) {
    hw->fc.requested_mode = 2;
  } else
  if (pause->rx_pause == 0U && pause->tx_pause == 0U) {
    hw->fc.requested_mode = 0;
  } else {
    return (-22);
  }
  netdev_info((struct net_device  const  *)netdev, "Flow control settings change requested, NIC Link is going down.\n");
  netif_carrier_off(netdev);
  netif_tx_stop_all_queues(netdev);
  status = i40e_set_fc(hw, & aq_failures, (int )link_up);
  if ((int )aq_failures & 1) {
    netdev_info((struct net_device  const  *)netdev, "Set fc failed on the get_phy_capabilities call with error %d and status %d\n",
                (int )status, (unsigned int )hw->aq.asq_last_status);
    err = -11;
  } else {

  }
  if (((int )aq_failures & 2) != 0) {
    netdev_info((struct net_device  const  *)netdev, "Set fc failed on the set_phy_config call with error %d and status %d\n",
                (int )status, (unsigned int )hw->aq.asq_last_status);
    err = -11;
  } else {

  }
  if (((int )aq_failures & 4) != 0) {
    netdev_info((struct net_device  const  *)netdev, "Set fc failed on the get_link_info call with error %d and status %d\n",
                (int )status, (unsigned int )hw->aq.asq_last_status);
    err = -11;
  } else {

  }
  tmp___3 = constant_test_bit(3L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___3 == 0) {
    msleep(75U);
    tmp___2 = constant_test_bit(3L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___2 == 0) {
      tmp___1 = i40e_nway_reset(netdev);
      return (tmp___1);
    } else {

    }
  } else {

  }
  return (err);
}
}
static u32 i40e_get_msglevel(struct net_device *netdev ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  return (pf->msg_enable);
}
}
static void i40e_set_msglevel(struct net_device *netdev , u32 data ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  if ((data & 4026531840U) != 0U) {
    pf->hw.debug_mask = data;
  } else {

  }
  pf->msg_enable = data;
  return;
}
}
static int i40e_get_regs_len(struct net_device *netdev ) 
{ 
  int reg_count ;
    klee_make_symbolic(&reg_count, sizeof(int), "reg_count");
  int i ;

  {
  reg_count = 0;
  i = 0;
  goto ldv_61165;
  ldv_61164: 
  reg_count = (int )(i40e_reg_list[i].elements + (u32 )reg_count);
  i = i + 1;
  ldv_61165: ;
  if (i40e_reg_list[i].offset != 0U) {
    goto ldv_61164;
  } else {

  }

  return ((int )((unsigned int )reg_count * 4U));
}
}
static void i40e_get_regs(struct net_device *netdev , struct ethtool_regs *regs ,
                          void *p ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u32 *reg_buf ;
  int i ;
  int j ;
  int ri ;
    klee_make_symbolic(&ri, sizeof(int), "ri");
  u32 reg ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  hw = & pf->hw;
  reg_buf = (u32 *)p;
  regs->version = 1U;
  ri = 0;
  i = 0;
  goto ldv_61184;
  ldv_61183: 
  j = 0;
  goto ldv_61181;
  ldv_61180: 
  reg = i40e_reg_list[i].offset + i40e_reg_list[i].stride * (u32 )j;
  tmp___0 = ri;
  ri = ri + 1;
  *(reg_buf + (unsigned long )tmp___0) = readl((void const volatile   *)hw->hw_addr + (unsigned long )reg);
  j = j + 1;
  ldv_61181: ;
  if ((u32 )j < i40e_reg_list[i].elements) {
    goto ldv_61180;
  } else {

  }
  i = i + 1;
  ldv_61184: ;
  if (i40e_reg_list[i].offset != 0U) {
    goto ldv_61183;
  } else {

  }

  return;
}
}
static int i40e_get_eeprom(struct net_device *netdev , struct ethtool_eeprom *eeprom ,
                           u8 *bytes ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_hw *hw ;
  struct i40e_pf *pf ;
  int ret_val ;
    klee_make_symbolic(&ret_val, sizeof(int), "ret_val");
  int len ;
  int offset ;
  u8 *eeprom_buff ;
  u16 i ;
  u16 sectors ;
  bool last ;
  u32 magic ;
  struct i40e_nvm_access *cmd ;
  int errno ;
    klee_make_symbolic(&errno, sizeof(int), "errno");
  i40e_status tmp___0 ;
  void *tmp___1 ;
  i40e_status tmp___2 ;
  i40e_status tmp___3 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  hw = & ((np->vsi)->back)->hw;
  pf = (np->vsi)->back;
  ret_val = 0;
  if (eeprom->len == 0U) {
    return (-22);
  } else {

  }
  magic = (u32 )((int )hw->vendor_id | ((int )hw->device_id << 16));
  if (eeprom->magic != 0U && eeprom->magic != magic) {
    if (eeprom->magic >> 16 != (__u32 )hw->device_id) {
      return (-22);
    } else {

    }
    cmd = (struct i40e_nvm_access *)eeprom;
    tmp___0 = i40e_nvmupd_command(hw, cmd, bytes, & errno);
    ret_val = (int )tmp___0;
    if (ret_val != 0 && ((unsigned int )hw->aq.asq_last_status != 10U || (hw->debug_mask & 128U) != 0U)) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "NVMUpdate read failed err=%d status=0x%x errno=%d module=%d offset=0x%x size=%d\n",
                ret_val, (unsigned int )hw->aq.asq_last_status, errno, (int )((unsigned char )cmd->config),
                cmd->offset, cmd->data_size);
    } else {

    }
    return (errno);
  } else {

  }
  eeprom->magic = (__u32 )((int )hw->vendor_id | ((int )hw->device_id << 16));
  tmp___1 = kzalloc((size_t )eeprom->len, 208U);
  eeprom_buff = (u8 *)tmp___1;
  if ((unsigned long )eeprom_buff == (unsigned long )((u8 *)0U)) {
    return (-12);
  } else {

  }
  tmp___2 = i40e_acquire_nvm(hw, 1);
  ret_val = (int )tmp___2;
  if (ret_val != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Failed Acquiring NVM resource for read err=%d status=0x%x\n",
              ret_val, (unsigned int )hw->aq.asq_last_status);
    goto free_buff;
  } else {

  }
  sectors = (u16 )(eeprom->len / 4096U);
  sectors = ((eeprom->len & 4095U) != 0U) + (int )sectors;
  len = 4096;
  last = 0;
  i = 0U;
  goto ldv_61207;
  ldv_61206: ;
  if ((int )i == (int )sectors + -1) {
    len = (int )(eeprom->len + (__u32 )((int )i * -4096));
    last = 1;
  } else {

  }
  offset = (int )(eeprom->offset + (__u32 )((int )i * 4096));
  tmp___3 = i40e_aq_read_nvm(hw, 0, (u32 )offset, (int )((u16 )len), (void *)eeprom_buff + (unsigned long )((int )i * 4096),
                             (int )last, (struct i40e_asq_cmd_details *)0);
  ret_val = (int )tmp___3;
  if (ret_val != 0 && (unsigned int )hw->aq.asq_last_status == 1U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "read NVM failed, invalid offset 0x%x\n",
              offset);
    goto ldv_61205;
  } else
  if (ret_val != 0 && (unsigned int )hw->aq.asq_last_status == 10U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "read NVM failed, access, offset 0x%x\n",
              offset);
    goto ldv_61205;
  } else
  if (ret_val != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "read NVM failed offset %d err=%d status=0x%x\n",
              offset, ret_val, (unsigned int )hw->aq.asq_last_status);
    goto ldv_61205;
  } else {

  }
  i = (u16 )((int )i + 1);
  ldv_61207: ;
  if ((int )i < (int )sectors) {
    goto ldv_61206;
  } else {

  }
  ldv_61205: 
  i40e_release_nvm(hw);
  memcpy((void *)bytes, (void const   *)eeprom_buff, (size_t )eeprom->len);
  free_buff: 
  kfree((void const   *)eeprom_buff);
  return (ret_val);
}
}
static int i40e_get_eeprom_len(struct net_device *netdev ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_hw *hw ;
  u32 val ;
  unsigned int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  hw = & ((np->vsi)->back)->hw;
  tmp___0 = readl((void const volatile   *)hw->hw_addr + 779396U);
  val = (tmp___0 & 448U) >> 6;
  val = (u32 )(65536 << (int )val);
  return ((int )val);
}
}
static int i40e_set_eeprom(struct net_device *netdev , struct ethtool_eeprom *eeprom ,
                           u8 *bytes ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_hw *hw ;
  struct i40e_pf *pf ;
  struct i40e_nvm_access *cmd ;
  int ret_val ;
  int errno ;
  u32 magic ;
  int tmp___0 ;
  int tmp___1 ;
  i40e_status tmp___2 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  hw = & ((np->vsi)->back)->hw;
  pf = (np->vsi)->back;
  ret_val = 0;
  magic = (u32 )((int )hw->vendor_id | ((int )hw->device_id << 16));
  if (eeprom->magic == magic) {
    return (-95);
  } else {

  }
  if (eeprom->magic == 0U || eeprom->magic >> 16 != (__u32 )hw->device_id) {
    return (-22);
  } else {

  }
  tmp___0 = constant_test_bit(9L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___0 != 0) {
    return (-16);
  } else {
    tmp___1 = constant_test_bit(10L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___1 != 0) {
      return (-16);
    } else {

    }
  }
  cmd = (struct i40e_nvm_access *)eeprom;
  tmp___2 = i40e_nvmupd_command(hw, cmd, bytes, & errno);
  ret_val = (int )tmp___2;
  if (ret_val != 0 && (((unsigned int )hw->aq.asq_last_status != 1U && (unsigned int )hw->aq.asq_last_status != 12U) || (hw->debug_mask & 128U) != 0U)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "NVMUpdate write failed err=%d status=0x%x errno=%d module=%d offset=0x%x size=%d\n",
              ret_val, (unsigned int )hw->aq.asq_last_status, errno, (int )((unsigned char )cmd->config),
              cmd->offset, cmd->data_size);
  } else {

  }
  return (errno);
}
}
static void i40e_get_drvinfo(struct net_device *netdev , struct ethtool_drvinfo *drvinfo ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  char *tmp___0 ;
  char const   *tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  strlcpy((char *)(& drvinfo->driver), (char const   *)(& i40e_driver_name), 32UL);
  strlcpy((char *)(& drvinfo->version), (char const   *)(& i40e_driver_version_str),
          32UL);
  tmp___0 = i40e_fw_version_str(& pf->hw);
  strlcpy((char *)(& drvinfo->fw_version), (char const   *)tmp___0, 32UL);
  tmp___1 = pci_name((struct pci_dev  const  *)pf->pdev);
  strlcpy((char *)(& drvinfo->bus_info), tmp___1, 32UL);
  drvinfo->n_priv_flags = 1U;
  return;
}
}
static void i40e_get_ringparam(struct net_device *netdev , struct ethtool_ringparam *ring ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  struct i40e_vsi *vsi ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  vsi = *(pf->vsi + (unsigned long )pf->lan_vsi);
  ring->rx_max_pending = 4096U;
  ring->tx_max_pending = 4096U;
  ring->rx_mini_max_pending = 0U;
  ring->rx_jumbo_max_pending = 0U;
  ring->rx_pending = (__u32 )(*(vsi->rx_rings))->count;
  ring->tx_pending = (__u32 )(*(vsi->tx_rings))->count;
  ring->rx_mini_pending = 0U;
  ring->rx_jumbo_pending = 0U;
  return;
}
}
static int i40e_set_ringparam(struct net_device *netdev , struct ethtool_ringparam *ring ) 
{ 
  struct i40e_ring *tx_rings ;
  struct i40e_ring *rx_rings ;
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  u32 new_rx_count ;
  u32 new_tx_count ;
  int i ;
  int err ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  void *tmp___3 ;
  void *tmp___4 ;

  {
  tx_rings = (struct i40e_ring *)0;
  rx_rings = (struct i40e_ring *)0;
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  err = 0;
  if (ring->rx_mini_pending != 0U || ring->rx_jumbo_pending != 0U) {
    return (-22);
  } else {

  }
  if (((ring->tx_pending > 4096U || ring->tx_pending <= 63U) || ring->rx_pending > 4096U) || ring->rx_pending <= 63U) {
    netdev_info((struct net_device  const  *)netdev, "Descriptors requested (Tx: %d / Rx: %d) out of range [%d-%d]\n",
                ring->tx_pending, ring->rx_pending, 64, 4096);
    return (-22);
  } else {

  }
  new_tx_count = (ring->tx_pending + 31U) & 4294967264U;
  new_rx_count = (ring->rx_pending + 31U) & 4294967264U;
  if ((u32 )(*(vsi->tx_rings))->count == new_tx_count && (u32 )(*(vsi->rx_rings))->count == new_rx_count) {
    return (0);
  } else {

  }
  goto ldv_61254;
  ldv_61253: 
  usleep_range(1000UL, 2000UL);
  ldv_61254: 
  tmp___0 = test_and_set_bit(1L, (unsigned long volatile   *)(& pf->state));
  if (tmp___0 != 0) {
    goto ldv_61253;
  } else {

  }
  tmp___1 = netif_running((struct net_device  const  *)vsi->netdev);
  if (tmp___1) {
    tmp___2 = 0;
  } else {
    tmp___2 = 1;
  }
  if (tmp___2) {
    i = 0;
    goto ldv_61257;
    ldv_61256: 
    (*(vsi->tx_rings + (unsigned long )i))->count = (u16 )new_tx_count;
    (*(vsi->rx_rings + (unsigned long )i))->count = (u16 )new_rx_count;
    i = i + 1;
    ldv_61257: ;
    if ((int )vsi->num_queue_pairs > i) {
      goto ldv_61256;
    } else {

    }

    goto done;
  } else {

  }
  if ((u32 )(*(vsi->tx_rings))->count != new_tx_count) {
    netdev_info((struct net_device  const  *)netdev, "Changing Tx descriptor count from %d to %d.\n",
                (int )(*(vsi->tx_rings))->count, new_tx_count);
    tmp___3 = kcalloc((size_t )vsi->alloc_queue_pairs, 4096UL, 208U);
    tx_rings = (struct i40e_ring *)tmp___3;
    if ((unsigned long )tx_rings == (unsigned long )((struct i40e_ring *)0)) {
      err = -12;
      goto done;
    } else {

    }
    i = 0;
    goto ldv_61264;
    ldv_61263: 
    *(tx_rings + (unsigned long )i) = *(*(vsi->tx_rings + (unsigned long )i));
    (tx_rings + (unsigned long )i)->count = (u16 )new_tx_count;
    err = i40e_setup_tx_descriptors(tx_rings + (unsigned long )i);
    if (err != 0) {
      goto ldv_61261;
      ldv_61260: 
      i = i - 1;
      i40e_free_tx_resources(tx_rings + (unsigned long )i);
      ldv_61261: ;
      if (i != 0) {
        goto ldv_61260;
      } else {

      }
      kfree((void const   *)tx_rings);
      tx_rings = (struct i40e_ring *)0;
      goto done;
    } else {

    }
    i = i + 1;
    ldv_61264: ;
    if ((int )vsi->num_queue_pairs > i) {
      goto ldv_61263;
    } else {

    }

  } else {

  }
  if ((u32 )(*(vsi->rx_rings))->count != new_rx_count) {
    netdev_info((struct net_device  const  *)netdev, "Changing Rx descriptor count from %d to %d\n",
                (int )(*(vsi->rx_rings))->count, new_rx_count);
    tmp___4 = kcalloc((size_t )vsi->alloc_queue_pairs, 4096UL, 208U);
    rx_rings = (struct i40e_ring *)tmp___4;
    if ((unsigned long )rx_rings == (unsigned long )((struct i40e_ring *)0)) {
      err = -12;
      goto free_tx;
    } else {

    }
    i = 0;
    goto ldv_61271;
    ldv_61270: 
    *(rx_rings + (unsigned long )i) = *(*(vsi->rx_rings + (unsigned long )i));
    (rx_rings + (unsigned long )i)->count = (u16 )new_rx_count;
    err = i40e_setup_rx_descriptors(rx_rings + (unsigned long )i);
    if (err != 0) {
      goto ldv_61268;
      ldv_61267: 
      i = i - 1;
      i40e_free_rx_resources(rx_rings + (unsigned long )i);
      ldv_61268: ;
      if (i != 0) {
        goto ldv_61267;
      } else {

      }
      kfree((void const   *)rx_rings);
      rx_rings = (struct i40e_ring *)0;
      goto free_tx;
    } else {

    }
    i = i + 1;
    ldv_61271: ;
    if ((int )vsi->num_queue_pairs > i) {
      goto ldv_61270;
    } else {

    }

  } else {

  }
  i40e_down(vsi);
  if ((unsigned long )tx_rings != (unsigned long )((struct i40e_ring *)0)) {
    i = 0;
    goto ldv_61274;
    ldv_61273: 
    i40e_free_tx_resources(*(vsi->tx_rings + (unsigned long )i));
    *(*(vsi->tx_rings + (unsigned long )i)) = *(tx_rings + (unsigned long )i);
    i = i + 1;
    ldv_61274: ;
    if ((int )vsi->num_queue_pairs > i) {
      goto ldv_61273;
    } else {

    }
    kfree((void const   *)tx_rings);
    tx_rings = (struct i40e_ring *)0;
  } else {

  }
  if ((unsigned long )rx_rings != (unsigned long )((struct i40e_ring *)0)) {
    i = 0;
    goto ldv_61277;
    ldv_61276: 
    i40e_free_rx_resources(*(vsi->rx_rings + (unsigned long )i));
    *(*(vsi->rx_rings + (unsigned long )i)) = *(rx_rings + (unsigned long )i);
    i = i + 1;
    ldv_61277: ;
    if ((int )vsi->num_queue_pairs > i) {
      goto ldv_61276;
    } else {

    }
    kfree((void const   *)rx_rings);
    rx_rings = (struct i40e_ring *)0;
  } else {

  }
  i40e_up(vsi);
  free_tx: ;
  if ((unsigned long )tx_rings != (unsigned long )((struct i40e_ring *)0)) {
    i = 0;
    goto ldv_61280;
    ldv_61279: 
    i40e_free_tx_resources(tx_rings + (unsigned long )i);
    i = i + 1;
    ldv_61280: ;
    if ((int )vsi->num_queue_pairs > i) {
      goto ldv_61279;
    } else {

    }
    kfree((void const   *)tx_rings);
    tx_rings = (struct i40e_ring *)0;
  } else {

  }
  done: 
  clear_bit(1L, (unsigned long volatile   *)(& pf->state));
  return (err);
}
}
static int i40e_get_sset_count(struct net_device *netdev , int sset ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  int len ;
  void *tmp___0 ;
  void *tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  switch (sset) {
  case 0: ;
  return (5);
  case 1: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) == (unsigned long )vsi && (unsigned int )pf->hw.partition_id == 1U) {
    tmp___0 = netdev_priv((struct net_device  const  *)netdev);
    len = (int )((unsigned int )((unsigned long )(((struct i40e_netdev_priv *)tmp___0)->vsi)->num_queue_pairs + 29UL) * 4U);
    if ((unsigned int )pf->lan_veb != 65535U) {
      len = (int )((unsigned int )len + 12U);
    } else {

    }
    return (len);
  } else {
    tmp___1 = netdev_priv((struct net_device  const  *)netdev);
    return ((int )((unsigned int )(((struct i40e_netdev_priv *)tmp___1)->vsi)->num_queue_pairs * 4U + 26U));
  }
  case 2: ;
  return (1);
  default: ;
  return (-95);
  }
}
}
static void i40e_get_ethtool_stats(struct net_device *netdev , struct ethtool_stats *stats ,
                                   u64 *data ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_ring *tx_ring ;
  struct i40e_ring *rx_ring ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  int i ;
  char *p ;
  int j ;
  struct rtnl_link_stats64 *net_stats ;
  struct rtnl_link_stats64 *tmp___0 ;
  unsigned int start ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  struct i40e_ring *__var ;
  bool tmp___4 ;
  bool tmp___5 ;
  struct i40e_veb *veb ;
  int tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;
  int tmp___10 ;
  int tmp___11 ;
  int tmp___12 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  i = 0;
  tmp___0 = i40e_get_vsi_stats_struct(vsi);
  net_stats = tmp___0;
  i40e_update_stats(vsi);
  j = 0;
  goto ldv_61328;
  ldv_61327: 
  p = (char *)net_stats + (unsigned long )i40e_gstrings_net_stats[j].stat_offset;
  tmp___1 = i;
  i = i + 1;
  *(data + (unsigned long )tmp___1) = i40e_gstrings_net_stats[j].sizeof_stat == 8 ? *((u64 *)p) : (u64 )*((u32 *)p);
  j = j + 1;
  ldv_61328: ;
  if ((unsigned int )j <= 10U) {
    goto ldv_61327;
  } else {

  }
  j = 0;
  goto ldv_61333;
  ldv_61332: 
  p = (char *)vsi + (unsigned long )i40e_gstrings_misc_stats[j].stat_offset;
  tmp___2 = i;
  i = i + 1;
  *(data + (unsigned long )tmp___2) = i40e_gstrings_misc_stats[j].sizeof_stat == 8 ? *((u64 *)p) : (u64 )*((u32 *)p);
  j = j + 1;
  ldv_61333: ;
  if ((unsigned int )j <= 6U) {
    goto ldv_61332;
  } else {

  }
  j = 0;
  goto ldv_61338;
  ldv_61337: 
  p = (char *)vsi + (unsigned long )i40e_gstrings_fcoe_stats[j].stat_offset;
  tmp___3 = i;
  i = i + 1;
  *(data + (unsigned long )tmp___3) = i40e_gstrings_fcoe_stats[j].sizeof_stat == 8 ? *((u64 *)p) : (u64 )*((u32 *)p);
  j = j + 1;
  ldv_61338: ;
  if ((unsigned int )j <= 7U) {
    goto ldv_61337;
  } else {

  }
  rcu_read_lock___0();
  j = 0;
  goto ldv_61348;
  ldv_61347: 
  __var = (struct i40e_ring *)0;
  tx_ring = *((struct i40e_ring * volatile  *)vsi->tx_rings + (unsigned long )j);
  if ((unsigned long )tx_ring == (unsigned long )((struct i40e_ring *)0)) {
    goto ldv_61342;
  } else {

  }
  ldv_61343: 
  start = u64_stats_fetch_begin_irq((struct u64_stats_sync  const  *)(& tx_ring->syncp));
  *(data + (unsigned long )i) = tx_ring->stats.packets;
  *(data + ((unsigned long )i + 1UL)) = tx_ring->stats.bytes;
  tmp___4 = u64_stats_fetch_retry_irq((struct u64_stats_sync  const  *)(& tx_ring->syncp),
                                      start);
  if ((int )tmp___4) {
    goto ldv_61343;
  } else {

  }
  i = i + 2;
  rx_ring = tx_ring + 1UL;
  ldv_61345: 
  start = u64_stats_fetch_begin_irq((struct u64_stats_sync  const  *)(& rx_ring->syncp));
  *(data + (unsigned long )i) = rx_ring->stats.packets;
  *(data + ((unsigned long )i + 1UL)) = rx_ring->stats.bytes;
  tmp___5 = u64_stats_fetch_retry_irq((struct u64_stats_sync  const  *)(& rx_ring->syncp),
                                      start);
  if ((int )tmp___5) {
    goto ldv_61345;
  } else {

  }
  i = i + 2;
  ldv_61342: 
  j = j + 1;
  ldv_61348: ;
  if ((int )vsi->num_queue_pairs > j) {
    goto ldv_61347;
  } else {

  }
  rcu_read_unlock___0();
  if ((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) != (unsigned long )vsi || (unsigned int )pf->hw.partition_id != 1U) {
    return;
  } else {

  }
  if ((unsigned int )pf->lan_veb != 65535U) {
    veb = pf->veb[(int )pf->lan_veb];
    j = 0;
    goto ldv_61354;
    ldv_61353: 
    p = (char *)veb;
    p = p + (unsigned long )i40e_gstrings_veb_stats[j].stat_offset;
    tmp___6 = i;
    i = i + 1;
    *(data + (unsigned long )tmp___6) = i40e_gstrings_veb_stats[j].sizeof_stat == 8 ? *((u64 *)p) : (u64 )*((u32 *)p);
    j = j + 1;
    ldv_61354: ;
    if ((unsigned int )j <= 11U) {
      goto ldv_61353;
    } else {

    }

  } else {

  }
  j = 0;
  goto ldv_61359;
  ldv_61358: 
  p = (char *)pf + (unsigned long )i40e_gstrings_stats[j].stat_offset;
  tmp___7 = i;
  i = i + 1;
  *(data + (unsigned long )tmp___7) = i40e_gstrings_stats[j].sizeof_stat == 8 ? *((u64 *)p) : (u64 )*((u32 *)p);
  j = j + 1;
  ldv_61359: ;
  if ((unsigned int )j <= 49U) {
    goto ldv_61358;
  } else {

  }
  j = 0;
  goto ldv_61362;
  ldv_61361: 
  tmp___8 = i;
  i = i + 1;
  *(data + (unsigned long )tmp___8) = pf->stats.priority_xon_tx[j];
  tmp___9 = i;
  i = i + 1;
  *(data + (unsigned long )tmp___9) = pf->stats.priority_xoff_tx[j];
  j = j + 1;
  ldv_61362: ;
  if (j <= 7) {
    goto ldv_61361;
  } else {

  }
  j = 0;
  goto ldv_61365;
  ldv_61364: 
  tmp___10 = i;
  i = i + 1;
  *(data + (unsigned long )tmp___10) = pf->stats.priority_xon_rx[j];
  tmp___11 = i;
  i = i + 1;
  *(data + (unsigned long )tmp___11) = pf->stats.priority_xoff_rx[j];
  j = j + 1;
  ldv_61365: ;
  if (j <= 7) {
    goto ldv_61364;
  } else {

  }
  j = 0;
  goto ldv_61368;
  ldv_61367: 
  tmp___12 = i;
  i = i + 1;
  *(data + (unsigned long )tmp___12) = pf->stats.priority_xon_2_xoff[j];
  j = j + 1;
  ldv_61368: ;
  if (j <= 7) {
    goto ldv_61367;
  } else {

  }

  return;
}
}
static void i40e_get_strings(struct net_device *netdev , u32 stringset , u8 *data ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  char *p ;
  int i ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  p = (char *)data;
  switch (stringset) {
  case 0U: 
  i = 0;
  goto ldv_61382;
  ldv_61381: 
  memcpy((void *)data, (void const   *)(& i40e_gstrings_test) + (unsigned long )i,
           32UL);
  data = data + 32UL;
  i = i + 1;
  ldv_61382: ;
  if ((unsigned int )i <= 4U) {
    goto ldv_61381;
  } else {

  }

  goto ldv_61384;
  case 1U: 
  i = 0;
  goto ldv_61389;
  ldv_61388: 
  snprintf(p, 32UL, "%s", (char const   *)(& i40e_gstrings_net_stats[i].stat_string));
  p = p + 32UL;
  i = i + 1;
  ldv_61389: ;
  if ((unsigned int )i <= 10U) {
    goto ldv_61388;
  } else {

  }
  i = 0;
  goto ldv_61394;
  ldv_61393: 
  snprintf(p, 32UL, "%s", (char const   *)(& i40e_gstrings_misc_stats[i].stat_string));
  p = p + 32UL;
  i = i + 1;
  ldv_61394: ;
  if ((unsigned int )i <= 6U) {
    goto ldv_61393;
  } else {

  }
  i = 0;
  goto ldv_61399;
  ldv_61398: 
  snprintf(p, 32UL, "%s", (char const   *)(& i40e_gstrings_fcoe_stats[i].stat_string));
  p = p + 32UL;
  i = i + 1;
  ldv_61399: ;
  if ((unsigned int )i <= 7U) {
    goto ldv_61398;
  } else {

  }
  i = 0;
  goto ldv_61402;
  ldv_61401: 
  snprintf(p, 32UL, "tx-%u.tx_packets", i);
  p = p + 32UL;
  snprintf(p, 32UL, "tx-%u.tx_bytes", i);
  p = p + 32UL;
  snprintf(p, 32UL, "rx-%u.rx_packets", i);
  p = p + 32UL;
  snprintf(p, 32UL, "rx-%u.rx_bytes", i);
  p = p + 32UL;
  i = i + 1;
  ldv_61402: ;
  if ((int )vsi->num_queue_pairs > i) {
    goto ldv_61401;
  } else {

  }

  if ((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) != (unsigned long )vsi || (unsigned int )pf->hw.partition_id != 1U) {
    return;
  } else {

  }
  if ((unsigned int )pf->lan_veb != 65535U) {
    i = 0;
    goto ldv_61407;
    ldv_61406: 
    snprintf(p, 32UL, "veb.%s", (char const   *)(& i40e_gstrings_veb_stats[i].stat_string));
    p = p + 32UL;
    i = i + 1;
    ldv_61407: ;
    if ((unsigned int )i <= 11U) {
      goto ldv_61406;
    } else {

    }

  } else {

  }
  i = 0;
  goto ldv_61412;
  ldv_61411: 
  snprintf(p, 32UL, "port.%s", (char *)(& i40e_gstrings_stats[i].stat_string));
  p = p + 32UL;
  i = i + 1;
  ldv_61412: ;
  if ((unsigned int )i <= 49U) {
    goto ldv_61411;
  } else {

  }
  i = 0;
  goto ldv_61415;
  ldv_61414: 
  snprintf(p, 32UL, "port.tx_priority_%u_xon", i);
  p = p + 32UL;
  snprintf(p, 32UL, "port.tx_priority_%u_xoff", i);
  p = p + 32UL;
  i = i + 1;
  ldv_61415: ;
  if (i <= 7) {
    goto ldv_61414;
  } else {

  }
  i = 0;
  goto ldv_61418;
  ldv_61417: 
  snprintf(p, 32UL, "port.rx_priority_%u_xon", i);
  p = p + 32UL;
  snprintf(p, 32UL, "port.rx_priority_%u_xoff", i);
  p = p + 32UL;
  i = i + 1;
  ldv_61418: ;
  if (i <= 7) {
    goto ldv_61417;
  } else {

  }
  i = 0;
  goto ldv_61421;
  ldv_61420: 
  snprintf(p, 32UL, "port.rx_priority_%u_xon_2_xoff", i);
  p = p + 32UL;
  i = i + 1;
  ldv_61421: ;
  if (i <= 7) {
    goto ldv_61420;
  } else {

  }

  goto ldv_61384;
  case 2U: 
  i = 0;
  goto ldv_61425;
  ldv_61424: 
  memcpy((void *)data, (void const   *)(& i40e_priv_flags_strings) + (unsigned long )i,
           32UL);
  data = data + 32UL;
  i = i + 1;
  ldv_61425: ;
  if (i == 0) {
    goto ldv_61424;
  } else {

  }

  goto ldv_61384;
  default: ;
  goto ldv_61384;
  }
  ldv_61384: ;
  return;
}
}
static int i40e_get_ts_info(struct net_device *dev , struct ethtool_ts_info *info ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_pf *tmp ;
  int tmp___0 ;

  {
  tmp = i40e_netdev_to_pf(dev);
  pf = tmp;
  if ((pf->flags & 33554432ULL) == 0ULL) {
    tmp___0 = ethtool_op_get_ts_info(dev, info);
    return (tmp___0);
  } else {

  }
  info->so_timestamping = 95U;
  if ((unsigned long )pf->ptp_clock != (unsigned long )((struct ptp_clock *)0)) {
    info->phc_index = ptp_clock_index(pf->ptp_clock);
  } else {
    info->phc_index = -1;
  }
  info->tx_types = 3U;
  info->rx_filters = 32753U;
  return (0);
}
}
static int i40e_link_test(struct net_device *netdev , u64 *data ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  bool tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  if ((pf->msg_enable & 8192U) != 0U) {
    netdev_info((struct net_device  const  *)netdev, "link test\n");
  } else {

  }
  tmp___0 = i40e_get_link_status(& pf->hw);
  if ((int )tmp___0) {
    *data = 0ULL;
  } else {
    *data = 1ULL;
  }
  return ((int )*data);
}
}
static int i40e_reg_test(struct net_device *netdev , u64 *data ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  i40e_status tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  if ((pf->msg_enable & 8192U) != 0U) {
    netdev_info((struct net_device  const  *)netdev, "register test\n");
  } else {

  }
  tmp___0 = i40e_diag_reg_test(& pf->hw);
  *data = (u64 )tmp___0;
  return ((int )*data);
}
}
static int i40e_eeprom_test(struct net_device *netdev , u64 *data ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  i40e_status tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  if ((pf->msg_enable & 8192U) != 0U) {
    netdev_info((struct net_device  const  *)netdev, "eeprom test\n");
  } else {

  }
  tmp___0 = i40e_diag_eeprom_test(& pf->hw);
  *data = (u64 )tmp___0;
  pf->hw.nvmupd_state = 0;
  return ((int )*data);
}
}
static int i40e_intr_test(struct net_device *netdev , u64 *data ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  u16 swc_old ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  swc_old = pf->sw_int_count;
  if ((pf->msg_enable & 8192U) != 0U) {
    netdev_info((struct net_device  const  *)netdev, "interrupt test\n");
  } else {

  }
  writel(117440541U, (void volatile   *)pf->hw.hw_addr + 230528U);
  usleep_range(1000UL, 2000UL);
  *data = (int )pf->sw_int_count == (int )swc_old;
  return ((int )*data);
}
}
static int i40e_loopback_test(struct net_device *netdev , u64 *data ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  if ((pf->msg_enable & 8192U) != 0U) {
    netdev_info((struct net_device  const  *)netdev, "loopback test not implemented\n");
  } else {

  }
  *data = 0ULL;
  return ((int )*data);
}
}
__inline static bool i40e_active_vfs(struct i40e_pf *pf ) 
{ 
  struct i40e_vf *vfs ;
  int i ;

  {
  vfs = pf->vf;
  i = 0;
  goto ldv_61470;
  ldv_61469: ;
  if ((int )(vfs + (unsigned long )i)->vf_states & 1) {
    return (1);
  } else {

  }
  i = i + 1;
  ldv_61470: ;
  if (pf->num_alloc_vfs > i) {
    goto ldv_61469;
  } else {

  }

  return (0);
}
}
static void i40e_diag_test(struct net_device *netdev , struct ethtool_test *eth_test ,
                           u64 *data ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  bool if_running ;
  bool tmp___0 ;
  struct i40e_pf *pf ;
  bool tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  tmp___0 = netif_running((struct net_device  const  *)netdev);
  if_running = tmp___0;
  pf = (np->vsi)->back;
  if (eth_test->flags == 1U) {
    if ((int )pf->msg_enable & 1) {
      netdev_info((struct net_device  const  *)netdev, "offline testing starting\n");
    } else {

    }
    set_bit(0L, (unsigned long volatile   *)(& pf->state));
    tmp___1 = i40e_active_vfs(pf);
    if ((int )tmp___1) {
      dev_warn((struct device  const  *)(& (pf->pdev)->dev), "Please take active VFS offline and restart the adapter before running NIC diagnostics\n");
      *data = 1ULL;
      *(data + 1UL) = 1ULL;
      *(data + 2UL) = 1ULL;
      *(data + 3UL) = 1ULL;
      *(data + 4UL) = 1ULL;
      eth_test->flags = eth_test->flags | 2U;
      clear_bit(0L, (unsigned long volatile   *)(& pf->state));
      goto skip_ol_tests;
    } else {

    }
    if ((int )if_running) {
      dev_close(netdev);
    } else {
      i40e_do_reset(pf, 4096U);
    }
    tmp___2 = i40e_link_test(netdev, data + 4UL);
    if (tmp___2 != 0) {
      eth_test->flags = eth_test->flags | 2U;
    } else {

    }
    tmp___3 = i40e_eeprom_test(netdev, data + 1UL);
    if (tmp___3 != 0) {
      eth_test->flags = eth_test->flags | 2U;
    } else {

    }
    tmp___4 = i40e_intr_test(netdev, data + 2UL);
    if (tmp___4 != 0) {
      eth_test->flags = eth_test->flags | 2U;
    } else {

    }
    tmp___5 = i40e_loopback_test(netdev, data + 3UL);
    if (tmp___5 != 0) {
      eth_test->flags = eth_test->flags | 2U;
    } else {

    }
    tmp___6 = i40e_reg_test(netdev, data);
    if (tmp___6 != 0) {
      eth_test->flags = eth_test->flags | 2U;
    } else {

    }
    clear_bit(0L, (unsigned long volatile   *)(& pf->state));
    i40e_do_reset(pf, 4096U);
    if ((int )if_running) {
      dev_open(netdev);
    } else {

    }
  } else {
    if ((int )pf->msg_enable & 1) {
      netdev_info((struct net_device  const  *)netdev, "online testing starting\n");
    } else {

    }
    tmp___7 = i40e_link_test(netdev, data + 4UL);
    if (tmp___7 != 0) {
      eth_test->flags = eth_test->flags | 2U;
    } else {

    }
    *data = 0ULL;
    *(data + 1UL) = 0ULL;
    *(data + 2UL) = 0ULL;
    *(data + 3UL) = 0ULL;
  }
  skip_ol_tests: ;
  if ((int )pf->msg_enable & 1) {
    netdev_info((struct net_device  const  *)netdev, "testing finished\n");
  } else {

  }
  return;
}
}
static void i40e_get_wol(struct net_device *netdev , struct ethtool_wolinfo *wol ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u16 wol_nvm_bits ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  hw = & pf->hw;
  i40e_read_nvm_word(hw, 25, & wol_nvm_bits);
  if (((int )wol_nvm_bits >> (int )hw->port) & 1 || (unsigned int )hw->partition_id != 1U) {
    wol->supported = 0U;
    wol->wolopts = 0U;
  } else {
    wol->supported = 32U;
    wol->wolopts = (int )pf->wol_en ? 32U : 0U;
  }
  return;
}
}
static int i40e_set_wol(struct net_device *netdev , struct ethtool_wolinfo *wol ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  struct i40e_vsi *vsi ;
  struct i40e_hw *hw ;
  u16 wol_nvm_bits ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  vsi = np->vsi;
  hw = & pf->hw;
  if ((unsigned int )hw->partition_id != 1U) {
    i40e_partition_setting_complaint(pf);
    return (-95);
  } else {

  }
  if ((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) != (unsigned long )vsi) {
    return (-95);
  } else {

  }
  i40e_read_nvm_word(hw, 25, & wol_nvm_bits);
  if (((int )wol_nvm_bits >> (int )hw->port) & 1) {
    return (-95);
  } else {

  }
  if (wol->wolopts != 0U && wol->wolopts != 32U) {
    return (-95);
  } else {

  }
  if ((int )pf->wol_en != (wol->wolopts != 0U)) {
    pf->wol_en = wol->wolopts != 0U;
    device_set_wakeup_enable(& (pf->pdev)->dev, (int )pf->wol_en);
  } else {

  }
  return (0);
}
}
static int i40e_set_phys_id(struct net_device *netdev , enum ethtool_phys_id_state state ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  int blink_freq ;
    klee_make_symbolic(&blink_freq, sizeof(int), "blink_freq");

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  hw = & pf->hw;
  blink_freq = 2;
  switch ((unsigned int )state) {
  case 1U: 
  pf->led_status = i40e_led_get(hw);
  return (blink_freq);
  case 2U: 
  i40e_led_set(hw, 15U, 0);
  goto ldv_61508;
  case 3U: 
  i40e_led_set(hw, 0U, 0);
  goto ldv_61508;
  case 0U: 
  i40e_led_set(hw, pf->led_status, 0);
  goto ldv_61508;
  default: ;
  goto ldv_61508;
  }
  ldv_61508: ;
  return (0);
}
}
static int i40e_get_coalesce(struct net_device *netdev , struct ethtool_coalesce *ec ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  ec->tx_max_coalesced_frames_irq = (__u32 )vsi->work_limit;
  ec->rx_max_coalesced_frames_irq = (__u32 )vsi->work_limit;
  if ((int )((short )vsi->rx_itr_setting) < 0) {
    ec->use_adaptive_rx_coalesce = 1U;
  } else {

  }
  if ((int )((short )vsi->tx_itr_setting) < 0) {
    ec->use_adaptive_tx_coalesce = 1U;
  } else {

  }
  ec->rx_coalesce_usecs = (__u32 )vsi->rx_itr_setting & 4294934527U;
  ec->tx_coalesce_usecs = (__u32 )vsi->tx_itr_setting & 4294934527U;
  return (0);
}
}
static int i40e_set_coalesce(struct net_device *netdev , struct ethtool_coalesce *ec ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_q_vector *q_vector ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u16 vector ;
  int i ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  hw = & pf->hw;
  if (ec->tx_max_coalesced_frames_irq != 0U || ec->rx_max_coalesced_frames_irq != 0U) {
    vsi->work_limit = (u16 )ec->tx_max_coalesced_frames_irq;
  } else {

  }
  vector = (u16 )vsi->base_vector;
  if (ec->rx_coalesce_usecs > 1U && ec->rx_coalesce_usecs <= 8160U) {
    vsi->rx_itr_setting = (u16 )ec->rx_coalesce_usecs;
  } else
  if (ec->rx_coalesce_usecs == 0U) {
    vsi->rx_itr_setting = (u16 )ec->rx_coalesce_usecs;
    if (ec->use_adaptive_rx_coalesce != 0U) {
      if ((int )pf->msg_enable & 1) {
        netdev_info((struct net_device  const  *)netdev, "rx-usecs=0, need to disable adaptive-rx for a complete disable\n");
      } else {

      }
    } else {

    }
  } else {
    if ((int )pf->msg_enable & 1) {
      netdev_info((struct net_device  const  *)netdev, "Invalid value, rx-usecs range is 0-8160\n");
    } else {

    }
    return (-22);
  }
  if (ec->tx_coalesce_usecs > 1U && ec->tx_coalesce_usecs <= 8160U) {
    vsi->tx_itr_setting = (u16 )ec->tx_coalesce_usecs;
  } else
  if (ec->tx_coalesce_usecs == 0U) {
    vsi->tx_itr_setting = (u16 )ec->tx_coalesce_usecs;
    if (ec->use_adaptive_tx_coalesce != 0U) {
      if ((int )pf->msg_enable & 1) {
        netdev_info((struct net_device  const  *)netdev, "tx-usecs=0, need to disable adaptive-tx for a complete disable\n");
      } else {

      }
    } else {

    }
  } else {
    if ((int )pf->msg_enable & 1) {
      netdev_info((struct net_device  const  *)netdev, "Invalid value, tx-usecs range is 0-8160\n");
    } else {

    }
    return (-22);
  }
  if (ec->use_adaptive_rx_coalesce != 0U) {
    vsi->rx_itr_setting = (u16 )((unsigned int )vsi->rx_itr_setting | 32768U);
  } else {
    vsi->rx_itr_setting = (unsigned int )vsi->rx_itr_setting & 32767U;
  }
  if (ec->use_adaptive_tx_coalesce != 0U) {
    vsi->tx_itr_setting = (u16 )((unsigned int )vsi->tx_itr_setting | 32768U);
  } else {
    vsi->tx_itr_setting = (unsigned int )vsi->tx_itr_setting & 32767U;
  }
  i = 0;
  goto ldv_61530;
  ldv_61529: 
  q_vector = *(vsi->q_vectors + (unsigned long )i);
  q_vector->rx.itr = (u16 )(((int )vsi->rx_itr_setting & -32769) >> 1);
  writel((unsigned int )q_vector->rx.itr, (void volatile   *)hw->hw_addr + (unsigned long )(((int )vector + 49151) * 4));
  q_vector->tx.itr = (u16 )(((int )vsi->tx_itr_setting & -32769) >> 1);
  writel((unsigned int )q_vector->tx.itr, (void volatile   *)hw->hw_addr + (unsigned long )(((int )vector + 49663) * 4));
  readl((void const volatile   *)hw->hw_addr + 745772U);
  i = i + 1;
  vector = (u16 )((int )vector + 1);
  ldv_61530: ;
  if (vsi->num_q_vectors > i) {
    goto ldv_61529;
  } else {

  }

  return (0);
}
}
static int i40e_get_rss_hash_opts(struct i40e_pf *pf , struct ethtool_rxnfc *cmd ) 
{ 


  {
  cmd->data = 0ULL;
  if ((*(pf->vsi + (unsigned long )pf->lan_vsi))->rxnfc.data != 0ULL) {
    cmd->data = (*(pf->vsi + (unsigned long )pf->lan_vsi))->rxnfc.data;
    cmd->flow_type = (*(pf->vsi + (unsigned long )pf->lan_vsi))->rxnfc.flow_type;
    return (0);
  } else {

  }
  switch (cmd->flow_type) {
  case 1U: ;
  case 2U: 
  cmd->data = cmd->data | 192ULL;
  case 3U: ;
  case 4U: ;
  case 9U: ;
  case 10U: ;
  case 16U: 
  cmd->data = cmd->data | 48ULL;
  goto ldv_61543;
  case 5U: ;
  case 6U: 
  cmd->data = cmd->data | 192ULL;
  case 7U: ;
  case 8U: ;
  case 11U: ;
  case 12U: ;
  case 17U: 
  cmd->data = cmd->data | 48ULL;
  goto ldv_61543;
  default: ;
  return (-22);
  }
  ldv_61543: ;
  return (0);
}
}
static int i40e_get_ethtool_fdir_all(struct i40e_pf *pf , struct ethtool_rxnfc *cmd ,
                                     u32 *rule_locs ) 
{ 
  struct i40e_fdir_filter *rule ;
  struct hlist_node *node2 ;
  int cnt ;
    klee_make_symbolic(&cnt, sizeof(int), "cnt");
  int tmp ;
  struct hlist_node *____ptr ;
  struct hlist_node  const  *__mptr ;
  struct i40e_fdir_filter *tmp___0 ;
  struct hlist_node *____ptr___0 ;
  struct hlist_node  const  *__mptr___0 ;
  struct i40e_fdir_filter *tmp___1 ;

  {
  cnt = 0;
  tmp = i40e_get_fd_cnt_all(pf);
  cmd->data = (__u64 )tmp;
  ____ptr = pf->fdir_filter_list.first;
  if ((unsigned long )____ptr != (unsigned long )((struct hlist_node *)0)) {
    __mptr = (struct hlist_node  const  *)____ptr;
    tmp___0 = (struct i40e_fdir_filter *)__mptr;
  } else {
    tmp___0 = (struct i40e_fdir_filter *)0;
  }
  rule = tmp___0;
  goto ldv_61570;
  ldv_61569: ;
  if ((__u32 )cnt == cmd->rule_cnt) {
    return (-90);
  } else {

  }
  *(rule_locs + (unsigned long )cnt) = rule->fd_id;
  cnt = cnt + 1;
  ____ptr___0 = node2;
  if ((unsigned long )____ptr___0 != (unsigned long )((struct hlist_node *)0)) {
    __mptr___0 = (struct hlist_node  const  *)____ptr___0;
    tmp___1 = (struct i40e_fdir_filter *)__mptr___0;
  } else {
    tmp___1 = (struct i40e_fdir_filter *)0;
  }
  rule = tmp___1;
  ldv_61570: ;
  if ((unsigned long )rule != (unsigned long )((struct i40e_fdir_filter *)0)) {
    node2 = rule->fdir_node.next;
    goto ldv_61569;
  } else {

  }
  cmd->rule_cnt = (__u32 )cnt;
  return (0);
}
}
static int i40e_get_ethtool_fdir_entry(struct i40e_pf *pf , struct ethtool_rxnfc *cmd ) 
{ 
  struct ethtool_rx_flow_spec *fsp ;
  struct i40e_fdir_filter *rule ;
  struct hlist_node *node2 ;
  struct hlist_node *____ptr ;
  struct hlist_node  const  *__mptr ;
  struct i40e_fdir_filter *tmp ;
  struct hlist_node *____ptr___0 ;
  struct hlist_node  const  *__mptr___0 ;
  struct i40e_fdir_filter *tmp___0 ;
  struct i40e_vsi *vsi ;
  __u32 tmp___1 ;

  {
  fsp = & cmd->fs;
  rule = (struct i40e_fdir_filter *)0;
  ____ptr = pf->fdir_filter_list.first;
  if ((unsigned long )____ptr != (unsigned long )((struct hlist_node *)0)) {
    __mptr = (struct hlist_node  const  *)____ptr;
    tmp = (struct i40e_fdir_filter *)__mptr;
  } else {
    tmp = (struct i40e_fdir_filter *)0;
  }
  rule = tmp;
  goto ldv_61590;
  ldv_61589: ;
  if (fsp->location <= rule->fd_id) {
    goto ldv_61588;
  } else {

  }
  ____ptr___0 = node2;
  if ((unsigned long )____ptr___0 != (unsigned long )((struct hlist_node *)0)) {
    __mptr___0 = (struct hlist_node  const  *)____ptr___0;
    tmp___0 = (struct i40e_fdir_filter *)__mptr___0;
  } else {
    tmp___0 = (struct i40e_fdir_filter *)0;
  }
  rule = tmp___0;
  ldv_61590: ;
  if ((unsigned long )rule != (unsigned long )((struct i40e_fdir_filter *)0)) {
    node2 = rule->fdir_node.next;
    goto ldv_61589;
  } else {

  }
  ldv_61588: ;
  if ((unsigned long )rule == (unsigned long )((struct i40e_fdir_filter *)0) || fsp->location != rule->fd_id) {
    return (-22);
  } else {

  }
  fsp->flow_type = (__u32 )rule->flow_type;
  if (fsp->flow_type == 13U) {
    fsp->h_u.usr_ip4_spec.ip_ver = 1U;
    fsp->h_u.usr_ip4_spec.proto = 0U;
    fsp->m_u.usr_ip4_spec.proto = 0U;
  } else {

  }
  fsp->h_u.tcp_ip4_spec.psrc = rule->dst_port;
  fsp->h_u.tcp_ip4_spec.pdst = rule->src_port;
  fsp->h_u.tcp_ip4_spec.ip4src = rule->dst_ip[0];
  fsp->h_u.tcp_ip4_spec.ip4dst = rule->src_ip[0];
  if ((unsigned int )rule->dest_ctl == 0U) {
    fsp->ring_cookie = 0xffffffffffffffffULL;
  } else {
    fsp->ring_cookie = (__u64 )rule->q_index;
  }
  if ((int )rule->dest_vsi != (int )(*(pf->vsi + (unsigned long )pf->lan_vsi))->id) {
    vsi = i40e_find_vsi_from_id(pf, (int )rule->dest_vsi);
    if ((unsigned long )vsi != (unsigned long )((struct i40e_vsi *)0) && (unsigned int )vsi->type == 6U) {
      tmp___1 = __fswab32((__u32 )vsi->vf_id);
      fsp->h_ext.data[1] = tmp___1;
      fsp->m_ext.data[1] = 16777216U;
    } else {

    }
  } else {

  }
  return (0);
}
}
static int i40e_get_rxnfc(struct net_device *netdev , struct ethtool_rxnfc *cmd ,
                          u32 *rule_locs ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  int ret ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  ret = -95;
  switch (cmd->cmd) {
  case 45U: 
  cmd->data = (__u64 )vsi->alloc_queue_pairs;
  ret = 0;
  goto ldv_61602;
  case 41U: 
  ret = i40e_get_rss_hash_opts(pf, cmd);
  goto ldv_61602;
  case 46U: 
  cmd->rule_cnt = (__u32 )pf->fdir_pf_active_filters;
  tmp___0 = i40e_get_fd_cnt_all(pf);
  cmd->data = (__u64 )tmp___0;
  ret = 0;
  goto ldv_61602;
  case 47U: 
  ret = i40e_get_ethtool_fdir_entry(pf, cmd);
  goto ldv_61602;
  case 48U: 
  ret = i40e_get_ethtool_fdir_all(pf, cmd, rule_locs);
  goto ldv_61602;
  default: ;
  goto ldv_61602;
  }
  ldv_61602: ;
  return (ret);
}
}
static int i40e_set_rss_hash_opt(struct i40e_pf *pf , struct ethtool_rxnfc *nfc ) 
{ 
  struct i40e_hw *hw ;
  u64 hena ;
  unsigned int tmp ;
  unsigned int tmp___0 ;

  {
  hw = & pf->hw;
  tmp = readl((void const volatile   *)hw->hw_addr + 2382080U);
  tmp___0 = readl((void const volatile   *)hw->hw_addr + 2382208U);
  hena = (unsigned long long )tmp | ((unsigned long long )tmp___0 << 32);
  if ((nfc->data & 0xffffffffffffff0fULL) != 0ULL) {
    return (-22);
  } else {

  }
  if ((nfc->data & 16ULL) == 0ULL || (nfc->data & 32ULL) == 0ULL) {
    return (-22);
  } else {

  }
  switch (nfc->flow_type) {
  case 1U: ;
  switch (nfc->data & 192ULL) {
  case 0ULL: 
  hena = hena & 0xfffffffdffffffffULL;
  goto ldv_61616;
  case 192ULL: 
  hena = hena | 8589934592ULL;
  goto ldv_61616;
  default: ;
  return (-22);
  }
  ldv_61616: ;
  goto ldv_61619;
  case 5U: ;
  switch (nfc->data & 192ULL) {
  case 0ULL: 
  hena = hena & 0xfffff7ffffffffffULL;
  goto ldv_61622;
  case 192ULL: 
  hena = hena | 8796093022208ULL;
  goto ldv_61622;
  default: ;
  return (-22);
  }
  ldv_61622: ;
  goto ldv_61619;
  case 2U: ;
  switch (nfc->data & 192ULL) {
  case 0ULL: 
  hena = hena & 0xffffffef7fffffffULL;
  goto ldv_61627;
  case 192ULL: 
  hena = hena | 70866960384ULL;
  goto ldv_61627;
  default: ;
  return (-22);
  }
  ldv_61627: ;
  goto ldv_61619;
  case 6U: ;
  switch (nfc->data & 192ULL) {
  case 0ULL: 
  hena = hena & 0xffffbdffffffffffULL;
  goto ldv_61632;
  case 192ULL: 
  hena = hena | 72567767433216ULL;
  goto ldv_61632;
  default: ;
  return (-22);
  }
  ldv_61632: ;
  goto ldv_61619;
  case 4U: ;
  case 9U: ;
  case 10U: ;
  case 3U: ;
  if ((nfc->data & 64ULL) != 0ULL || (nfc->data & 128ULL) != 0ULL) {
    return (-22);
  } else {

  }
  hena = hena | 34359738368ULL;
  goto ldv_61619;
  case 8U: ;
  case 11U: ;
  case 12U: ;
  case 7U: ;
  if ((nfc->data & 64ULL) != 0ULL || (nfc->data & 128ULL) != 0ULL) {
    return (-22);
  } else {

  }
  hena = hena | 35184372088832ULL;
  goto ldv_61619;
  case 16U: 
  hena = hena | 103079215104ULL;
  goto ldv_61619;
  case 17U: 
  hena = hena | 105553116266496ULL;
  goto ldv_61619;
  default: ;
  return (-22);
  }
  ldv_61619: 
  writel((unsigned int )hena, (void volatile   *)hw->hw_addr + 2382080U);
  writel((unsigned int )(hena >> 32), (void volatile   *)hw->hw_addr + 2382208U);
  readl((void const volatile   *)hw->hw_addr + 745772U);
  (*(pf->vsi + (unsigned long )pf->lan_vsi))->rxnfc = *nfc;
  return (0);
}
}
static bool i40e_match_fdir_input_set(struct i40e_fdir_filter *rule , struct i40e_fdir_filter *input ) 
{ 


  {
  if (((rule->dst_ip[0] != input->dst_ip[0] || rule->src_ip[0] != input->src_ip[0]) || (int )rule->dst_port != (int )input->dst_port) || (int )rule->src_port != (int )input->src_port) {
    return (0);
  } else {

  }
  return (1);
}
}
static int i40e_update_ethtool_fdir_entry(struct i40e_vsi *vsi , struct i40e_fdir_filter *input ,
                                          u16 sw_idx , struct ethtool_rxnfc *cmd ) 
{ 
  struct i40e_fdir_filter *rule ;
  struct i40e_fdir_filter *parent ;
  struct i40e_pf *pf ;
  struct hlist_node *node2 ;
  int err ;
  struct hlist_node *____ptr ;
  struct hlist_node  const  *__mptr ;
  struct i40e_fdir_filter *tmp ;
  struct hlist_node *____ptr___0 ;
  struct hlist_node  const  *__mptr___0 ;
  struct i40e_fdir_filter *tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;

  {
  pf = vsi->back;
  err = -22;
  parent = (struct i40e_fdir_filter *)0;
  rule = (struct i40e_fdir_filter *)0;
  ____ptr = pf->fdir_filter_list.first;
  if ((unsigned long )____ptr != (unsigned long )((struct hlist_node *)0)) {
    __mptr = (struct hlist_node  const  *)____ptr;
    tmp = (struct i40e_fdir_filter *)__mptr;
  } else {
    tmp = (struct i40e_fdir_filter *)0;
  }
  rule = tmp;
  goto ldv_61672;
  ldv_61671: ;
  if (rule->fd_id >= (u32 )sw_idx) {
    goto ldv_61670;
  } else {

  }
  parent = rule;
  ____ptr___0 = node2;
  if ((unsigned long )____ptr___0 != (unsigned long )((struct hlist_node *)0)) {
    __mptr___0 = (struct hlist_node  const  *)____ptr___0;
    tmp___0 = (struct i40e_fdir_filter *)__mptr___0;
  } else {
    tmp___0 = (struct i40e_fdir_filter *)0;
  }
  rule = tmp___0;
  ldv_61672: ;
  if ((unsigned long )rule != (unsigned long )((struct i40e_fdir_filter *)0)) {
    node2 = rule->fdir_node.next;
    goto ldv_61671;
  } else {

  }
  ldv_61670: ;
  if ((unsigned long )rule != (unsigned long )((struct i40e_fdir_filter *)0) && rule->fd_id == (u32 )sw_idx) {
    if ((unsigned long )input != (unsigned long )((struct i40e_fdir_filter *)0)) {
      tmp___1 = i40e_match_fdir_input_set(rule, input);
      if (tmp___1) {
        tmp___2 = 0;
      } else {
        tmp___2 = 1;
      }
      if (tmp___2) {
        err = i40e_add_del_fdir(vsi, rule, 0);
      } else {
        goto _L;
      }
    } else
    _L: /* CIL Label */ 
    if ((unsigned long )input == (unsigned long )((struct i40e_fdir_filter *)0)) {
      err = i40e_add_del_fdir(vsi, rule, 0);
    } else {

    }
    hlist_del(& rule->fdir_node);
    kfree((void const   *)rule);
    pf->fdir_pf_active_filters = (u16 )((int )pf->fdir_pf_active_filters - 1);
  } else {

  }
  if ((unsigned long )input == (unsigned long )((struct i40e_fdir_filter *)0)) {
    return (err);
  } else {

  }
  INIT_HLIST_NODE(& input->fdir_node);
  if ((unsigned long )parent != (unsigned long )((struct i40e_fdir_filter *)0)) {
    hlist_add_behind(& input->fdir_node, & parent->fdir_node);
  } else {
    hlist_add_head(& input->fdir_node, & pf->fdir_filter_list);
  }
  pf->fdir_pf_active_filters = (u16 )((int )pf->fdir_pf_active_filters + 1);
  return (0);
}
}
static int i40e_del_fdir_entry(struct i40e_vsi *vsi , struct ethtool_rxnfc *cmd ) 
{ 
  struct ethtool_rx_flow_spec *fsp ;
  struct i40e_pf *pf ;
  int ret ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
  fsp = & cmd->fs;
  pf = vsi->back;
  ret = 0;
  tmp = constant_test_bit(9L, (unsigned long const volatile   *)(& pf->state));
  if (tmp != 0) {
    return (-16);
  } else {
    tmp___0 = constant_test_bit(10L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___0 != 0) {
      return (-16);
    } else {

    }
  }
  tmp___1 = constant_test_bit(22L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___1 != 0) {
    return (-16);
  } else {

  }
  ret = i40e_update_ethtool_fdir_entry(vsi, (struct i40e_fdir_filter *)0, (int )((u16 )fsp->location),
                                       cmd);
  i40e_fdir_check_and_reenable(pf);
  return (ret);
}
}
static int i40e_add_fdir_ethtool(struct i40e_vsi *vsi , struct ethtool_rxnfc *cmd ) 
{ 
  struct ethtool_rx_flow_spec *fsp ;
  struct i40e_fdir_filter *input ;
  struct i40e_pf *pf ;
  int ret ;
  u16 vf_id ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  void *tmp___2 ;
  __u32 tmp___3 ;
  __u32 tmp___4 ;
  __u32 tmp___5 ;

  {
  ret = -22;
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
    return (-22);
  } else {

  }
  pf = vsi->back;
  if ((pf->flags & 2097152ULL) == 0ULL) {
    return (-95);
  } else {

  }
  if ((pf->auto_disable_flags & 2097152ULL) != 0ULL) {
    return (-28);
  } else {

  }
  tmp = constant_test_bit(9L, (unsigned long const volatile   *)(& pf->state));
  if (tmp != 0) {
    return (-16);
  } else {
    tmp___0 = constant_test_bit(10L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___0 != 0) {
      return (-16);
    } else {

    }
  }
  tmp___1 = constant_test_bit(22L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___1 != 0) {
    return (-16);
  } else {

  }
  fsp = & cmd->fs;
  if (fsp->location >= pf->hw.func_caps.fd_filters_best_effort + pf->hw.func_caps.fd_filters_guaranteed) {
    return (-22);
  } else {

  }
  if (fsp->ring_cookie != 0xffffffffffffffffULL && fsp->ring_cookie >= (__u64 )vsi->num_queue_pairs) {
    return (-22);
  } else {

  }
  tmp___2 = kzalloc(80UL, 208U);
  input = (struct i40e_fdir_filter *)tmp___2;
  if ((unsigned long )input == (unsigned long )((struct i40e_fdir_filter *)0)) {
    return (-12);
  } else {

  }
  input->fd_id = fsp->location;
  if (fsp->ring_cookie == 0xffffffffffffffffULL) {
    input->dest_ctl = 0U;
  } else {
    input->dest_ctl = 1U;
  }
  input->q_index = (u16 )fsp->ring_cookie;
  input->flex_off = 0U;
  input->pctype = 0U;
  input->dest_vsi = vsi->id;
  input->fd_status = 1U;
  input->cnt_index = (unsigned int )((u16 )pf->hw.pf_id) * 3U + 1U;
  input->flow_type = (u8 )fsp->flow_type;
  input->ip4_proto = fsp->h_u.usr_ip4_spec.proto;
  input->dst_port = fsp->h_u.tcp_ip4_spec.psrc;
  input->src_port = fsp->h_u.tcp_ip4_spec.pdst;
  input->dst_ip[0] = fsp->h_u.tcp_ip4_spec.ip4src;
  input->src_ip[0] = fsp->h_u.tcp_ip4_spec.ip4dst;
  tmp___5 = __fswab32(fsp->m_ext.data[1]);
  if (tmp___5 != 0U) {
    tmp___3 = __fswab32(fsp->h_ext.data[1]);
    if (tmp___3 >= (unsigned int )pf->num_alloc_vfs) {
      if ((int )pf->msg_enable & 1) {
        netdev_info((struct net_device  const  *)vsi->netdev, "Invalid VF id\n");
      } else {

      }
      goto free_input;
    } else {

    }
    tmp___4 = __fswab32(fsp->h_ext.data[1]);
    vf_id = (u16 )tmp___4;
    input->dest_vsi = (u16 )(pf->vf + (unsigned long )vf_id)->lan_vsi_id;
    if ((int )input->q_index >= (int )((unsigned short )(pf->vf + (unsigned long )vf_id)->num_queue_pairs)) {
      if ((int )pf->msg_enable & 1) {
        netdev_info((struct net_device  const  *)vsi->netdev, "Invalid queue id\n");
      } else {

      }
      goto free_input;
    } else {

    }
  } else {

  }
  ret = i40e_add_del_fdir(vsi, input, 1);
  free_input: ;
  if (ret != 0) {
    kfree((void const   *)input);
  } else {
    i40e_update_ethtool_fdir_entry(vsi, input, (int )((u16 )fsp->location), (struct ethtool_rxnfc *)0);
  }
  return (ret);
}
}
static int i40e_set_rxnfc(struct net_device *netdev , struct ethtool_rxnfc *cmd ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  int ret ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  ret = -95;
  switch (cmd->cmd) {
  case 42U: 
  ret = i40e_set_rss_hash_opt(pf, cmd);
  goto ldv_61699;
  case 50U: 
  ret = i40e_add_fdir_ethtool(vsi, cmd);
  goto ldv_61699;
  case 49U: 
  ret = i40e_del_fdir_entry(vsi, cmd);
  goto ldv_61699;
  default: ;
  goto ldv_61699;
  }
  ldv_61699: ;
  return (ret);
}
}
static unsigned int i40e_max_channels(struct i40e_vsi *vsi ) 
{ 


  {
  return ((unsigned int )vsi->alloc_queue_pairs);
}
}
static void i40e_get_channels(struct net_device *dev , struct ethtool_channels *ch ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;

  {
  tmp = netdev_priv((struct net_device  const  *)dev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  ch->max_combined = i40e_max_channels(vsi);
  ch->other_count = (pf->flags & 2097152ULL) != 0ULL;
  ch->max_other = ch->other_count;
  ch->combined_count = (__u32 )vsi->num_queue_pairs;
  return;
}
}
static int i40e_set_channels(struct net_device *dev , struct ethtool_channels *ch ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  unsigned int count ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  int new_count ;
    klee_make_symbolic(&new_count, sizeof(int), "new_count");
  unsigned int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)dev);
  np = (struct i40e_netdev_priv *)tmp;
  count = ch->combined_count;
  vsi = np->vsi;
  pf = vsi->back;
  if ((unsigned int )vsi->type != 0U) {
    return (-22);
  } else {

  }
  if ((count == 0U || ch->rx_count != 0U) || ch->tx_count != 0U) {
    return (-22);
  } else {

  }
  if (ch->other_count != ((pf->flags & 2097152ULL) != 0ULL ? 1U : 0U)) {
    return (-22);
  } else {

  }
  tmp___0 = i40e_max_channels(vsi);
  if (tmp___0 < count) {
    return (-22);
  } else {

  }
  new_count = i40e_reconfig_rss_queues(pf, (int )count);
  if (new_count > 0) {
    return (0);
  } else {
    return (-22);
  }
}
}
static u32 i40e_get_rxfh_key_size(struct net_device *netdev ) 
{ 


  {
  return (52U);
}
}
static u32 i40e_get_rxfh_indir_size(struct net_device *netdev ) 
{ 


  {
  return (512U);
}
}
static int i40e_get_rxfh(struct net_device *netdev , u32 *indir , u8 *key , u8 *hfunc ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u32 reg_val ;
  int i ;
  int j ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  hw = & pf->hw;
  if ((unsigned long )hfunc != (unsigned long )((u8 *)0U)) {
    *hfunc = 1U;
  } else {

  }
  if ((unsigned long )indir == (unsigned long )((u32 *)0U)) {
    return (0);
  } else {

  }
  i = 0;
  j = 0;
  goto ldv_61742;
  ldv_61741: 
  reg_val = readl((void const volatile   *)hw->hw_addr + (unsigned long )((i + 18432) * 128));
  tmp___0 = j;
  j = j + 1;
  *(indir + (unsigned long )tmp___0) = reg_val & 255U;
  tmp___1 = j;
  j = j + 1;
  *(indir + (unsigned long )tmp___1) = (reg_val >> 8) & 255U;
  tmp___2 = j;
  j = j + 1;
  *(indir + (unsigned long )tmp___2) = (reg_val >> 16) & 255U;
  tmp___3 = j;
  j = j + 1;
  *(indir + (unsigned long )tmp___3) = reg_val >> 24;
  i = i + 1;
  ldv_61742: ;
  if (i <= 127) {
    goto ldv_61741;
  } else {

  }

  if ((unsigned long )key != (unsigned long )((u8 *)0U)) {
    i = 0;
    j = 0;
    goto ldv_61745;
    ldv_61744: 
    reg_val = readl((void const volatile   *)hw->hw_addr + (unsigned long )((i + 18576) * 128));
    tmp___4 = j;
    j = j + 1;
    *(key + (unsigned long )tmp___4) = (unsigned char )reg_val;
    tmp___5 = j;
    j = j + 1;
    *(key + (unsigned long )tmp___5) = (unsigned char )(reg_val >> 8);
    tmp___6 = j;
    j = j + 1;
    *(key + (unsigned long )tmp___6) = (unsigned char )(reg_val >> 16);
    tmp___7 = j;
    j = j + 1;
    *(key + (unsigned long )tmp___7) = (unsigned char )(reg_val >> 24);
    i = i + 1;
    ldv_61745: ;
    if (i <= 12) {
      goto ldv_61744;
    } else {

    }

  } else {

  }
  return (0);
}
}
static int i40e_set_rxfh(struct net_device *netdev , u32 const   *indir , u8 const   *key ,
                         u8 const   hfunc ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u32 reg_val ;
  int i ;
  int j ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  hw = & pf->hw;
  if ((unsigned int )((unsigned char )hfunc) != 0U && (unsigned int )((unsigned char )hfunc) != 1U) {
    return (-95);
  } else {

  }
  if ((unsigned long )indir == (unsigned long )((u32 const   *)0U)) {
    return (0);
  } else {

  }
  i = 0;
  j = 0;
  goto ldv_61761;
  ldv_61760: 
  tmp___0 = j;
  j = j + 1;
  reg_val = *(indir + (unsigned long )tmp___0);
  tmp___1 = j;
  j = j + 1;
  reg_val = (u32 )(*(indir + (unsigned long )tmp___1) << 8) | reg_val;
  tmp___2 = j;
  j = j + 1;
  reg_val = (u32 )(*(indir + (unsigned long )tmp___2) << 16) | reg_val;
  tmp___3 = j;
  j = j + 1;
  reg_val = (u32 )(*(indir + (unsigned long )tmp___3) << 24) | reg_val;
  writel(reg_val, (void volatile   *)hw->hw_addr + (unsigned long )((i + 18432) * 128));
  i = i + 1;
  ldv_61761: ;
  if (i <= 127) {
    goto ldv_61760;
  } else {

  }

  if ((unsigned long )key != (unsigned long )((u8 const   *)0U)) {
    i = 0;
    j = 0;
    goto ldv_61764;
    ldv_61763: 
    tmp___4 = j;
    j = j + 1;
    reg_val = (u32 )*(key + (unsigned long )tmp___4);
    tmp___5 = j;
    j = j + 1;
    reg_val = (u32 )((int )*(key + (unsigned long )tmp___5) << 8) | reg_val;
    tmp___6 = j;
    j = j + 1;
    reg_val = (u32 )((int )*(key + (unsigned long )tmp___6) << 16) | reg_val;
    tmp___7 = j;
    j = j + 1;
    reg_val = (u32 )((int )*(key + (unsigned long )tmp___7) << 24) | reg_val;
    writel(reg_val, (void volatile   *)hw->hw_addr + (unsigned long )((i + 18576) * 128));
    i = i + 1;
    ldv_61764: ;
    if (i <= 12) {
      goto ldv_61763;
    } else {

    }

  } else {

  }
  return (0);
}
}
static u32 i40e_get_priv_flags(struct net_device *dev ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  u32 ret_flags ;

  {
  tmp = netdev_priv((struct net_device  const  *)dev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  ret_flags = 0U;
  ret_flags = (pf->hw.func_caps.npar_enable != 0U ? 1U : 0U) | ret_flags;
  return (ret_flags);
}
}
static struct ethtool_ops  const  i40e_ethtool_ops  = 
     {& i40e_get_settings, & i40e_set_settings, & i40e_get_drvinfo, & i40e_get_regs_len,
    & i40e_get_regs, & i40e_get_wol, & i40e_set_wol, & i40e_get_msglevel, & i40e_set_msglevel,
    & i40e_nway_reset, & ethtool_op_get_link, & i40e_get_eeprom_len, & i40e_get_eeprom,
    & i40e_set_eeprom, & i40e_get_coalesce, & i40e_set_coalesce, & i40e_get_ringparam,
    & i40e_set_ringparam, & i40e_get_pauseparam, & i40e_set_pauseparam, & i40e_diag_test,
    & i40e_get_strings, & i40e_set_phys_id, & i40e_get_ethtool_stats, 0, 0, & i40e_get_priv_flags,
    0, & i40e_get_sset_count, & i40e_get_rxnfc, & i40e_set_rxnfc, 0, 0, & i40e_get_rxfh_key_size,
    & i40e_get_rxfh_indir_size, & i40e_get_rxfh, & i40e_set_rxfh, & i40e_get_channels,
    & i40e_set_channels, 0, 0, 0, & i40e_get_ts_info, 0, 0, 0, 0, 0, 0};
void i40e_set_ethtool_ops(struct net_device *netdev ) 
{ 


  {
  netdev->ethtool_ops = & i40e_ethtool_ops;
  return;
}
}
void ldv_initialize_ethtool_ops_11(void) 
{ 
  void *tmp ;
  void *tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  void *tmp___4 ;
  void *tmp___5 ;
  void *tmp___6 ;
  void *tmp___7 ;

  {
  tmp = ldv_init_zalloc(36UL);
  i40e_ethtool_ops_group0 = (struct ethtool_ringparam *)tmp;
  tmp___0 = ldv_init_zalloc(16UL);
  i40e_ethtool_ops_group2 = (struct ethtool_eeprom *)tmp___0;
  tmp___1 = ldv_init_zalloc(44UL);
  i40e_ethtool_ops_group1 = (struct ethtool_cmd *)tmp___1;
  tmp___2 = ldv_init_zalloc(16UL);
  i40e_ethtool_ops_group3 = (struct ethtool_pauseparam *)tmp___2;
  tmp___3 = ldv_init_zalloc(36UL);
  i40e_ethtool_ops_group4 = (struct ethtool_channels *)tmp___3;
  tmp___4 = ldv_init_zalloc(92UL);
  i40e_ethtool_ops_group5 = (struct ethtool_coalesce *)tmp___4;
  tmp___5 = ldv_init_zalloc(3008UL);
  i40e_ethtool_ops_group6 = (struct net_device *)tmp___5;
  tmp___6 = ldv_init_zalloc(192UL);
  i40e_ethtool_ops_group7 = (struct ethtool_rxnfc *)tmp___6;
  tmp___7 = ldv_init_zalloc(20UL);
  i40e_ethtool_ops_group8 = (struct ethtool_wolinfo *)tmp___7;
  return;
}
}
void ldv_main_exported_11(void) 
{ 
  u8 *ldvarg34 ;
  void *tmp ;
  u64 *ldvarg28 ;
  void *tmp___0 ;
  u8 *ldvarg19 ;
  void *tmp___1 ;
  struct ethtool_regs *ldvarg22 ;
  void *tmp___2 ;
  struct ethtool_drvinfo *ldvarg25 ;
  void *tmp___3 ;
  void *ldvarg21 ;
  void *tmp___4 ;
  u8 *ldvarg33 ;
  void *tmp___5 ;
  struct ethtool_ts_info *ldvarg30 ;
  void *tmp___6 ;
  u8 *ldvarg38 ;
  void *tmp___7 ;
  u32 *ldvarg35 ;
  void *tmp___8 ;
  u32 ldvarg27 ;
  u8 *ldvarg26 ;
  void *tmp___9 ;
  struct ethtool_stats *ldvarg24 ;
  void *tmp___10 ;
  u32 *ldvarg40 ;
  void *tmp___11 ;
  struct ethtool_test *ldvarg29 ;
  void *tmp___12 ;
  enum ethtool_phys_id_state ldvarg36 ;
  u8 ldvarg37 ;
  u64 *ldvarg23 ;
  void *tmp___13 ;
  u8 *ldvarg20 ;
  void *tmp___14 ;
  u32 ldvarg31 ;
  int ldvarg32 ;
    klee_make_symbolic(&ldvarg32, sizeof(int), "ldvarg32");
  u32 *ldvarg39 ;
  void *tmp___15 ;
  int tmp___16 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg34 = (u8 *)tmp;
  tmp___0 = ldv_init_zalloc(8UL);
  ldvarg28 = (u64 *)tmp___0;
  tmp___1 = ldv_init_zalloc(1UL);
  ldvarg19 = (u8 *)tmp___1;
  tmp___2 = ldv_init_zalloc(12UL);
  ldvarg22 = (struct ethtool_regs *)tmp___2;
  tmp___3 = ldv_init_zalloc(196UL);
  ldvarg25 = (struct ethtool_drvinfo *)tmp___3;
  tmp___4 = ldv_init_zalloc(1UL);
  ldvarg21 = tmp___4;
  tmp___5 = ldv_init_zalloc(1UL);
  ldvarg33 = (u8 *)tmp___5;
  tmp___6 = ldv_init_zalloc(44UL);
  ldvarg30 = (struct ethtool_ts_info *)tmp___6;
  tmp___7 = ldv_init_zalloc(1UL);
  ldvarg38 = (u8 *)tmp___7;
  tmp___8 = ldv_init_zalloc(4UL);
  ldvarg35 = (u32 *)tmp___8;
  tmp___9 = ldv_init_zalloc(1UL);
  ldvarg26 = (u8 *)tmp___9;
  tmp___10 = ldv_init_zalloc(8UL);
  ldvarg24 = (struct ethtool_stats *)tmp___10;
  tmp___11 = ldv_init_zalloc(4UL);
  ldvarg40 = (u32 *)tmp___11;
  tmp___12 = ldv_init_zalloc(16UL);
  ldvarg29 = (struct ethtool_test *)tmp___12;
  tmp___13 = ldv_init_zalloc(8UL);
  ldvarg23 = (u64 *)tmp___13;
  tmp___14 = ldv_init_zalloc(1UL);
  ldvarg20 = (u8 *)tmp___14;
  tmp___15 = ldv_init_zalloc(4UL);
  ldvarg39 = (u32 *)tmp___15;
  ldv_memset((void *)(& ldvarg27), 0, 4UL);
  ldv_memset((void *)(& ldvarg36), 0, 4UL);
  ldv_memset((void *)(& ldvarg37), 0, 1UL);
  ldv_memset((void *)(& ldvarg31), 0, 4UL);
  ldv_memset((void *)(& ldvarg32), 0, 4UL);
  tmp___16 = __VERIFIER_nondet_int();
  switch (tmp___16) {
  case 0: ;
  if (ldv_state_variable_11 == 1) {
    i40e_set_rxnfc(i40e_ethtool_ops_group6, i40e_ethtool_ops_group7);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 1: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_rxnfc(i40e_ethtool_ops_group6, i40e_ethtool_ops_group7, ldvarg40);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 2: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_ringparam(i40e_ethtool_ops_group6, i40e_ethtool_ops_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 3: ;
  if (ldv_state_variable_11 == 1) {
    i40e_set_rxfh(i40e_ethtool_ops_group6, (u32 const   *)ldvarg39, (u8 const   *)ldvarg38,
                  (int )ldvarg37);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 4: ;
  if (ldv_state_variable_11 == 1) {
    i40e_set_phys_id(i40e_ethtool_ops_group6, ldvarg36);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 5: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_pauseparam(i40e_ethtool_ops_group6, i40e_ethtool_ops_group3);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 6: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_rxfh(i40e_ethtool_ops_group6, ldvarg35, ldvarg34, ldvarg33);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 7: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_sset_count(i40e_ethtool_ops_group6, ldvarg32);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 8: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_settings(i40e_ethtool_ops_group6, i40e_ethtool_ops_group1);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 9: ;
  if (ldv_state_variable_11 == 1) {
    i40e_set_channels(i40e_ethtool_ops_group6, i40e_ethtool_ops_group4);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 10: ;
  if (ldv_state_variable_11 == 1) {
    i40e_set_coalesce(i40e_ethtool_ops_group6, i40e_ethtool_ops_group5);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 11: ;
  if (ldv_state_variable_11 == 1) {
    i40e_set_msglevel(i40e_ethtool_ops_group6, ldvarg31);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 12: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_ts_info(i40e_ethtool_ops_group6, ldvarg30);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 13: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_eeprom_len(i40e_ethtool_ops_group6);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 14: ;
  if (ldv_state_variable_11 == 1) {
    i40e_diag_test(i40e_ethtool_ops_group6, ldvarg29, ldvarg28);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 15: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_strings(i40e_ethtool_ops_group6, ldvarg27, ldvarg26);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 16: ;
  if (ldv_state_variable_11 == 1) {
    i40e_nway_reset(i40e_ethtool_ops_group6);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 17: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_rxfh_key_size(i40e_ethtool_ops_group6);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 18: ;
  if (ldv_state_variable_11 == 1) {
    ethtool_op_get_link(i40e_ethtool_ops_group6);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 19: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_channels(i40e_ethtool_ops_group6, i40e_ethtool_ops_group4);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 20: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_priv_flags(i40e_ethtool_ops_group6);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 21: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_drvinfo(i40e_ethtool_ops_group6, ldvarg25);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 22: ;
  if (ldv_state_variable_11 == 1) {
    i40e_set_pauseparam(i40e_ethtool_ops_group6, i40e_ethtool_ops_group3);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 23: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_ethtool_stats(i40e_ethtool_ops_group6, ldvarg24, ldvarg23);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 24: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_coalesce(i40e_ethtool_ops_group6, i40e_ethtool_ops_group5);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 25: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_regs(i40e_ethtool_ops_group6, ldvarg22, ldvarg21);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 26: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_rxfh_indir_size(i40e_ethtool_ops_group6);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 27: ;
  if (ldv_state_variable_11 == 1) {
    i40e_set_wol(i40e_ethtool_ops_group6, i40e_ethtool_ops_group8);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 28: ;
  if (ldv_state_variable_11 == 1) {
    i40e_set_settings(i40e_ethtool_ops_group6, i40e_ethtool_ops_group1);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 29: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_eeprom(i40e_ethtool_ops_group6, i40e_ethtool_ops_group2, ldvarg20);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 30: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_wol(i40e_ethtool_ops_group6, i40e_ethtool_ops_group8);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 31: ;
  if (ldv_state_variable_11 == 1) {
    i40e_set_eeprom(i40e_ethtool_ops_group6, i40e_ethtool_ops_group2, ldvarg19);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 32: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_msglevel(i40e_ethtool_ops_group6);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 33: ;
  if (ldv_state_variable_11 == 1) {
    i40e_get_regs_len(i40e_ethtool_ops_group6);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  case 34: ;
  if (ldv_state_variable_11 == 1) {
    i40e_set_ringparam(i40e_ethtool_ops_group6, i40e_ethtool_ops_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  goto ldv_61806;
  default: 
  ldv_stop();
  }
  ldv_61806: ;
  return;
}
}
bool ldv_queue_work_on_97(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_98(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_99(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_100(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_101(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_102(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_103(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_104(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_105(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_106(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_107(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_108(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_133(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_131(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_134(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_135(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_138(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_140(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_142(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_144(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_130(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_132(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_136(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_137(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_139(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_141(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_143(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_arq_mutex_of_i40e_adminq_info(struct mutex *lock ) ;
void ldv_mutex_unlock_arq_mutex_of_i40e_adminq_info(struct mutex *lock ) ;
void ldv_mutex_lock_asq_mutex_of_i40e_adminq_info(struct mutex *lock ) ;
void ldv_mutex_unlock_asq_mutex_of_i40e_adminq_info(struct mutex *lock ) ;
bool ldv_queue_work_on_125(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_127(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_126(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_129(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_128(struct workqueue_struct *ldv_func_arg1 ) ;
void i40e_fill_default_direct_cmd_desc(struct i40e_aq_desc *desc , u16 opcode ) ;
__inline static bool i40e_is_vf(struct i40e_hw *hw ) 
{ 


  {
  return ((unsigned int )hw->mac.type == 3U);
}
}
i40e_status i40e_asq_send_command(struct i40e_hw *hw , struct i40e_aq_desc *desc ,
                                  void *buff , u16 buff_size , struct i40e_asq_cmd_details *cmd_details ) ;
void i40e_debug_aq(struct i40e_hw *hw , enum i40e_debug_mask mask , void *desc , void *buffer ,
                   u16 buf_len ) ;
i40e_status i40e_aq_queue_shutdown(struct i40e_hw *hw , bool unloading ) ;
i40e_status i40e_aq_get_firmware_version(struct i40e_hw *hw , u16 *fw_major_version ,
                                         u16 *fw_minor_version , u32 *fw_build , u16 *api_major_version ,
                                         u16 *api_minor_version , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_release_resource(struct i40e_hw *hw , enum i40e_aq_resources_ids resource ,
                                     u8 sdp_number , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_set_hmc_resource_profile(struct i40e_hw *hw , enum i40e_aq_hmc_profile profile ,
                                             u8 pe_vf_enabled_count , struct i40e_asq_cmd_details *cmd_details ) ;
static void i40e_resume_aq(struct i40e_hw *hw ) ;
__inline static bool i40e_is_nvm_update_op(struct i40e_aq_desc *desc ) 
{ 


  {
  return ((bool )((unsigned int )desc->opcode == 1794U || (unsigned int )desc->opcode == 1795U));
}
}
static void i40e_adminq_init_regs(struct i40e_hw *hw ) 
{ 
  bool tmp ;

  {
  tmp = i40e_is_vf(hw);
  if ((int )tmp) {
    hw->aq.asq.tail = 33792U;
    hw->aq.asq.head = 25600U;
    hw->aq.asq.len = 26624U;
    hw->aq.asq.bal = 31744U;
    hw->aq.asq.bah = 30720U;
    hw->aq.arq.tail = 28672U;
    hw->aq.arq.head = 29696U;
    hw->aq.arq.len = 32768U;
    hw->aq.arq.bal = 27648U;
    hw->aq.arq.bah = 24576U;
  } else {
    hw->aq.asq.tail = 525312U;
    hw->aq.asq.head = 525056U;
    hw->aq.asq.len = 524800U;
    hw->aq.asq.bal = 524288U;
    hw->aq.asq.bah = 524544U;
    hw->aq.arq.tail = 525440U;
    hw->aq.arq.head = 525184U;
    hw->aq.arq.len = 524928U;
    hw->aq.arq.bal = 524416U;
    hw->aq.arq.bah = 524672U;
  }
  return;
}
}
static i40e_status i40e_alloc_adminq_asq_ring(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;

  {
  ret_code = i40e_allocate_dma_mem_d(hw, & hw->aq.asq.desc_buf, (u64 )((unsigned long )hw->aq.num_asq_entries * 32UL),
                                     4096U);
  if ((int )ret_code != 0) {
    return (ret_code);
  } else {

  }
  ret_code = i40e_allocate_virt_mem_d(hw, & hw->aq.asq.cmd_buf, (u32 )hw->aq.num_asq_entries * 24U);
  if ((int )ret_code != 0) {
    i40e_free_dma_mem_d(hw, & hw->aq.asq.desc_buf);
    return (ret_code);
  } else {

  }
  return (ret_code);
}
}
static i40e_status i40e_alloc_adminq_arq_ring(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;

  {
  ret_code = i40e_allocate_dma_mem_d(hw, & hw->aq.arq.desc_buf, (u64 )((unsigned long )hw->aq.num_arq_entries * 32UL),
                                     4096U);
  return (ret_code);
}
}
static void i40e_free_adminq_asq(struct i40e_hw *hw ) 
{ 


  {
  i40e_free_dma_mem_d(hw, & hw->aq.asq.desc_buf);
  return;
}
}
static void i40e_free_adminq_arq(struct i40e_hw *hw ) 
{ 


  {
  i40e_free_dma_mem_d(hw, & hw->aq.arq.desc_buf);
  return;
}
}
static i40e_status i40e_alloc_arq_bufs(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;
  struct i40e_aq_desc *desc ;
  struct i40e_dma_mem *bi ;
  int i ;

  {
  ret_code = i40e_allocate_virt_mem_d(hw, & hw->aq.arq.dma_head, (u32 )hw->aq.num_arq_entries * 20U);
  if ((int )ret_code != 0) {
    goto alloc_arq_bufs;
  } else {

  }
  hw->aq.arq.r.arq_bi = (struct i40e_dma_mem *)hw->aq.arq.dma_head.va;
  i = 0;
  goto ldv_52605;
  ldv_52604: 
  bi = hw->aq.arq.r.arq_bi + (unsigned long )i;
  ret_code = i40e_allocate_dma_mem_d(hw, bi, (u64 )hw->aq.arq_buf_size, 4096U);
  if ((int )ret_code != 0) {
    goto unwind_alloc_arq_bufs;
  } else {

  }
  desc = (struct i40e_aq_desc *)hw->aq.arq.desc_buf.va + (unsigned long )i;
  desc->flags = 4096U;
  if ((unsigned int )hw->aq.arq_buf_size > 512U) {
    desc->flags = (__le16 )((unsigned int )desc->flags | 512U);
  } else {

  }
  desc->opcode = 0U;
  desc->datalen = (unsigned short )bi->size;
  desc->retval = 0U;
  desc->cookie_high = 0U;
  desc->cookie_low = 0U;
  desc->params.external.addr_high = (unsigned int )(bi->pa >> 32ULL);
  desc->params.external.addr_low = (unsigned int )bi->pa;
  desc->params.external.param0 = 0U;
  desc->params.external.param1 = 0U;
  i = i + 1;
  ldv_52605: ;
  if ((int )hw->aq.num_arq_entries > i) {
    goto ldv_52604;
  } else {

  }

  alloc_arq_bufs: ;
  return (ret_code);
  unwind_alloc_arq_bufs: 
  i = i - 1;
  goto ldv_52608;
  ldv_52607: 
  i40e_free_dma_mem_d(hw, hw->aq.arq.r.arq_bi + (unsigned long )i);
  i = i - 1;
  ldv_52608: ;
  if (i >= 0) {
    goto ldv_52607;
  } else {

  }
  i40e_free_virt_mem_d(hw, & hw->aq.arq.dma_head);
  return (ret_code);
}
}
static i40e_status i40e_alloc_asq_bufs(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;
  struct i40e_dma_mem *bi ;
  int i ;

  {
  ret_code = i40e_allocate_virt_mem_d(hw, & hw->aq.asq.dma_head, (u32 )hw->aq.num_asq_entries * 20U);
  if ((int )ret_code != 0) {
    goto alloc_asq_bufs;
  } else {

  }
  hw->aq.asq.r.asq_bi = (struct i40e_dma_mem *)hw->aq.asq.dma_head.va;
  i = 0;
  goto ldv_52619;
  ldv_52618: 
  bi = hw->aq.asq.r.asq_bi + (unsigned long )i;
  ret_code = i40e_allocate_dma_mem_d(hw, bi, (u64 )hw->aq.asq_buf_size, 4096U);
  if ((int )ret_code != 0) {
    goto unwind_alloc_asq_bufs;
  } else {

  }
  i = i + 1;
  ldv_52619: ;
  if ((int )hw->aq.num_asq_entries > i) {
    goto ldv_52618;
  } else {

  }

  alloc_asq_bufs: ;
  return (ret_code);
  unwind_alloc_asq_bufs: 
  i = i - 1;
  goto ldv_52622;
  ldv_52621: 
  i40e_free_dma_mem_d(hw, hw->aq.asq.r.asq_bi + (unsigned long )i);
  i = i - 1;
  ldv_52622: ;
  if (i >= 0) {
    goto ldv_52621;
  } else {

  }
  i40e_free_virt_mem_d(hw, & hw->aq.asq.dma_head);
  return (ret_code);
}
}
static void i40e_free_arq_bufs(struct i40e_hw *hw ) 
{ 
  int i ;

  {
  i = 0;
  goto ldv_52629;
  ldv_52628: 
  i40e_free_dma_mem_d(hw, hw->aq.arq.r.arq_bi + (unsigned long )i);
  i = i + 1;
  ldv_52629: ;
  if ((int )hw->aq.num_arq_entries > i) {
    goto ldv_52628;
  } else {

  }
  i40e_free_dma_mem_d(hw, & hw->aq.arq.desc_buf);
  i40e_free_virt_mem_d(hw, & hw->aq.arq.dma_head);
  return;
}
}
static void i40e_free_asq_bufs(struct i40e_hw *hw ) 
{ 
  int i ;

  {
  i = 0;
  goto ldv_52636;
  ldv_52635: ;
  if ((hw->aq.asq.r.asq_bi + (unsigned long )i)->pa != 0ULL) {
    i40e_free_dma_mem_d(hw, hw->aq.asq.r.asq_bi + (unsigned long )i);
  } else {

  }
  i = i + 1;
  ldv_52636: ;
  if ((int )hw->aq.num_asq_entries > i) {
    goto ldv_52635;
  } else {

  }
  i40e_free_virt_mem_d(hw, & hw->aq.asq.cmd_buf);
  i40e_free_dma_mem_d(hw, & hw->aq.asq.desc_buf);
  i40e_free_virt_mem_d(hw, & hw->aq.asq.dma_head);
  return;
}
}
static i40e_status i40e_config_asq_regs(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;
  u32 reg ;

  {
  ret_code = 0;
  reg = 0U;
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.head);
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.tail);
  writel((unsigned int )((long )((int )hw->aq.num_asq_entries) | (-0x7FFFFFFF-1)),
         (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.len);
  writel((unsigned int )hw->aq.asq.desc_buf.pa, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.bal);
  writel((unsigned int )(hw->aq.asq.desc_buf.pa >> 32ULL), (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.bah);
  reg = readl((void const volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.bal);
  if ((u32 )hw->aq.asq.desc_buf.pa != reg) {
    ret_code = -53;
  } else {

  }
  return (ret_code);
}
}
static i40e_status i40e_config_arq_regs(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;
  u32 reg ;

  {
  ret_code = 0;
  reg = 0U;
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.arq.head);
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.arq.tail);
  writel((unsigned int )((long )((int )hw->aq.num_arq_entries) | (-0x7FFFFFFF-1)),
         (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.arq.len);
  writel((unsigned int )hw->aq.arq.desc_buf.pa, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.arq.bal);
  writel((unsigned int )(hw->aq.arq.desc_buf.pa >> 32ULL), (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.arq.bah);
  writel((unsigned int )((int )hw->aq.num_arq_entries + -1), (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.arq.tail);
  reg = readl((void const volatile   *)hw->hw_addr + (unsigned long )hw->aq.arq.bal);
  if ((u32 )hw->aq.arq.desc_buf.pa != reg) {
    ret_code = -53;
  } else {

  }
  return (ret_code);
}
}
static i40e_status i40e_init_asq(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;

  {
  ret_code = 0;
  if ((unsigned int )hw->aq.asq.count != 0U) {
    ret_code = -63;
    goto init_adminq_exit;
  } else {

  }
  if ((unsigned int )hw->aq.num_asq_entries == 0U || (unsigned int )hw->aq.asq_buf_size == 0U) {
    ret_code = -4;
    goto init_adminq_exit;
  } else {

  }
  hw->aq.asq.next_to_use = 0U;
  hw->aq.asq.next_to_clean = 0U;
  hw->aq.asq.count = hw->aq.num_asq_entries;
  ret_code = i40e_alloc_adminq_asq_ring(hw);
  if ((int )ret_code != 0) {
    goto init_adminq_exit;
  } else {

  }
  ret_code = i40e_alloc_asq_bufs(hw);
  if ((int )ret_code != 0) {
    goto init_adminq_free_rings;
  } else {

  }
  ret_code = i40e_config_asq_regs(hw);
  if ((int )ret_code != 0) {
    goto init_adminq_free_rings;
  } else {

  }
  goto init_adminq_exit;
  init_adminq_free_rings: 
  i40e_free_adminq_asq(hw);
  init_adminq_exit: ;
  return (ret_code);
}
}
static i40e_status i40e_init_arq(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;

  {
  ret_code = 0;
  if ((unsigned int )hw->aq.arq.count != 0U) {
    ret_code = -63;
    goto init_adminq_exit;
  } else {

  }
  if ((unsigned int )hw->aq.num_arq_entries == 0U || (unsigned int )hw->aq.arq_buf_size == 0U) {
    ret_code = -4;
    goto init_adminq_exit;
  } else {

  }
  hw->aq.arq.next_to_use = 0U;
  hw->aq.arq.next_to_clean = 0U;
  hw->aq.arq.count = hw->aq.num_arq_entries;
  ret_code = i40e_alloc_adminq_arq_ring(hw);
  if ((int )ret_code != 0) {
    goto init_adminq_exit;
  } else {

  }
  ret_code = i40e_alloc_arq_bufs(hw);
  if ((int )ret_code != 0) {
    goto init_adminq_free_rings;
  } else {

  }
  ret_code = i40e_config_arq_regs(hw);
  if ((int )ret_code != 0) {
    goto init_adminq_free_rings;
  } else {

  }
  goto init_adminq_exit;
  init_adminq_free_rings: 
  i40e_free_adminq_arq(hw);
  init_adminq_exit: ;
  return (ret_code);
}
}
static i40e_status i40e_shutdown_asq(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;

  {
  ret_code = 0;
  if ((unsigned int )hw->aq.asq.count == 0U) {
    return (-63);
  } else {

  }
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.head);
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.tail);
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.len);
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.bal);
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.bah);
  ldv_mutex_lock_137(& hw->aq.asq_mutex);
  hw->aq.asq.count = 0U;
  i40e_free_asq_bufs(hw);
  ldv_mutex_unlock_138(& hw->aq.asq_mutex);
  return (ret_code);
}
}
static i40e_status i40e_shutdown_arq(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;

  {
  ret_code = 0;
  if ((unsigned int )hw->aq.arq.count == 0U) {
    return (-63);
  } else {

  }
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.arq.head);
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.arq.tail);
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.arq.len);
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.arq.bal);
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.arq.bah);
  ldv_mutex_lock_139(& hw->aq.arq_mutex);
  hw->aq.arq.count = 0U;
  i40e_free_arq_bufs(hw);
  ldv_mutex_unlock_140(& hw->aq.arq_mutex);
  return (ret_code);
}
}
i40e_status i40e_init_adminq(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;
  u16 eetrack_lo ;
  u16 eetrack_hi ;
  int retry ;
    klee_make_symbolic(&retry, sizeof(int), "retry");
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;

  {
  retry = 0;
  if ((((unsigned int )hw->aq.num_arq_entries == 0U || (unsigned int )hw->aq.num_asq_entries == 0U) || (unsigned int )hw->aq.arq_buf_size == 0U) || (unsigned int )hw->aq.asq_buf_size == 0U) {
    ret_code = -4;
    goto init_adminq_exit;
  } else {

  }
  __mutex_init(& hw->aq.asq_mutex, "&hw->aq.asq_mutex", & __key);
  __mutex_init(& hw->aq.arq_mutex, "&hw->aq.arq_mutex", & __key___0);
  i40e_adminq_init_regs(hw);
  hw->aq.asq_cmd_timeout = 250U;
  ret_code = i40e_init_asq(hw);
  if ((int )ret_code != 0) {
    goto init_adminq_destroy_locks;
  } else {

  }
  ret_code = i40e_init_arq(hw);
  if ((int )ret_code != 0) {
    goto init_adminq_free_asq;
  } else {

  }
  ldv_52681: 
  ret_code = i40e_aq_get_firmware_version(hw, & hw->aq.fw_maj_ver, & hw->aq.fw_min_ver,
                                          & hw->aq.fw_build, & hw->aq.api_maj_ver,
                                          & hw->aq.api_min_ver, (struct i40e_asq_cmd_details *)0);
  if ((int )ret_code != -54) {
    goto ldv_52680;
  } else {

  }
  retry = retry + 1;
  msleep(100U);
  i40e_resume_aq(hw);
  if (retry <= 9) {
    goto ldv_52681;
  } else {

  }
  ldv_52680: ;
  if ((int )ret_code != 0) {
    goto init_adminq_free_arq;
  } else {

  }
  i40e_read_nvm_word(hw, 24, & hw->nvm.version);
  i40e_read_nvm_word(hw, 45, & eetrack_lo);
  i40e_read_nvm_word(hw, 46, & eetrack_hi);
  hw->nvm.eetrack = (u32 )(((int )eetrack_hi << 16) | (int )eetrack_lo);
  if ((unsigned int )hw->aq.api_maj_ver > 1U) {
    ret_code = -65;
    goto init_adminq_free_arq;
  } else {

  }
  i40e_aq_release_resource(hw, 1, 0, (struct i40e_asq_cmd_details *)0);
  hw->aq.nvm_release_on_done = 0;
  hw->nvmupd_state = 0;
  ret_code = i40e_aq_set_hmc_resource_profile(hw, 1, 0, (struct i40e_asq_cmd_details *)0);
  ret_code = 0;
  goto init_adminq_exit;
  init_adminq_free_arq: 
  i40e_shutdown_arq(hw);
  init_adminq_free_asq: 
  i40e_shutdown_asq(hw);
  init_adminq_destroy_locks: ;
  init_adminq_exit: ;
  return (ret_code);
}
}
i40e_status i40e_shutdown_adminq(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;
  bool tmp ;

  {
  ret_code = 0;
  tmp = i40e_check_asq_alive(hw);
  if ((int )tmp) {
    i40e_aq_queue_shutdown(hw, 1);
  } else {

  }
  i40e_shutdown_asq(hw);
  i40e_shutdown_arq(hw);
  return (ret_code);
}
}
static u16 i40e_clean_asq(struct i40e_hw *hw ) 
{ 
  struct i40e_adminq_ring *asq ;
  struct i40e_asq_cmd_details *details ;
  u16 ntc ;
  struct i40e_aq_desc desc_cb ;
  struct i40e_aq_desc *desc ;
  unsigned int tmp ;
  void (*cb_func)(struct i40e_hw * , struct i40e_aq_desc * ) ;
  unsigned int tmp___0 ;

  {
  asq = & hw->aq.asq;
  ntc = asq->next_to_clean;
  desc = (struct i40e_aq_desc *)asq->desc_buf.va + (unsigned long )ntc;
  details = (struct i40e_asq_cmd_details *)asq->cmd_buf.va + (unsigned long )ntc;
  goto ldv_52698;
  ldv_52697: ;
  if ((hw->debug_mask & 16777216U) != 0U) {
    tmp = readl((void const volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.head);
    printk("\016i40e %02x.%x %s: ntc %d head %d.\n", (int )hw->bus.device, (int )hw->bus.func,
           "i40e_clean_asq", (int )ntc, tmp);
  } else {

  }
  if ((unsigned long )details->callback != (unsigned long )((void *)0)) {
    cb_func = (void (*)(struct i40e_hw * , struct i40e_aq_desc * ))details->callback;
    desc_cb = *desc;
    (*cb_func)(hw, & desc_cb);
  } else {

  }
  memset((void *)desc, 0, 32UL);
  memset((void *)details, 0, 24UL);
  ntc = (u16 )((int )ntc + 1);
  if ((int )asq->count == (int )ntc) {
    ntc = 0U;
  } else {

  }
  desc = (struct i40e_aq_desc *)asq->desc_buf.va + (unsigned long )ntc;
  details = (struct i40e_asq_cmd_details *)asq->cmd_buf.va + (unsigned long )ntc;
  ldv_52698: 
  tmp___0 = readl((void const volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.head);
  if (tmp___0 != (unsigned int )ntc) {
    goto ldv_52697;
  } else {

  }
  asq->next_to_clean = ntc;
  return (((((int )asq->next_to_clean <= (int )asq->next_to_use ? asq->count : 0U) + (unsigned int )asq->next_to_clean) - (unsigned int )asq->next_to_use) + 65535U);
}
}
static bool i40e_asq_done(struct i40e_hw *hw ) 
{ 
  unsigned int tmp ;

  {
  tmp = readl((void const volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.head);
  return (tmp == (unsigned int )hw->aq.asq.next_to_use);
}
}
i40e_status i40e_asq_send_command(struct i40e_hw *hw , struct i40e_aq_desc *desc ,
                                  void *buff , u16 buff_size , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  i40e_status status ;
  struct i40e_dma_mem *dma_buff ;
  struct i40e_asq_cmd_details *details ;
  struct i40e_aq_desc *desc_on_ring ;
  bool cmd_completed ;
  u16 retval ;
  u32 val ;
  u16 tmp ;
  u32 total_delay ;
  bool tmp___0 ;
  bool tmp___1 ;

  {
  status = 0;
  dma_buff = (struct i40e_dma_mem *)0;
  cmd_completed = 0;
  retval = 0U;
  val = 0U;
  val = readl((void const volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.head);
  if ((u32 )hw->aq.num_asq_entries <= val) {
    if ((hw->debug_mask & 16777216U) != 0U) {
      printk("\016i40e %02x.%x AQTX: head overrun at %d\n", (int )hw->bus.device,
             (int )hw->bus.func, val);
    } else {

    }
    status = -32;
    goto asq_send_command_exit;
  } else {

  }
  if ((unsigned int )hw->aq.asq.count == 0U) {
    if ((hw->debug_mask & 16777216U) != 0U) {
      printk("\016i40e %02x.%x AQTX: Admin queue not initialized.\n", (int )hw->bus.device,
             (int )hw->bus.func);
    } else {

    }
    status = -32;
    goto asq_send_command_exit;
  } else {

  }
  details = (struct i40e_asq_cmd_details *)hw->aq.asq.cmd_buf.va + (unsigned long )hw->aq.asq.next_to_use;
  if ((unsigned long )cmd_details != (unsigned long )((struct i40e_asq_cmd_details *)0)) {
    *details = *cmd_details;
    if (details->cookie != 0ULL) {
      desc->cookie_high = (unsigned int )(details->cookie >> 32ULL);
      desc->cookie_low = (unsigned int )details->cookie;
    } else {

    }
  } else {
    memset((void *)details, 0, 24UL);
  }
  desc->flags = (__le16 )((int )((short )desc->flags) & ~ ((int )((short )details->flags_dis)));
  desc->flags = (__le16 )((int )desc->flags | (int )details->flags_ena);
  ldv_mutex_lock_141(& hw->aq.asq_mutex);
  if ((int )hw->aq.asq_buf_size < (int )buff_size) {
    if ((hw->debug_mask & 16777216U) != 0U) {
      printk("\016i40e %02x.%x AQTX: Invalid buffer size: %d.\n", (int )hw->bus.device,
             (int )hw->bus.func, (int )buff_size);
    } else {

    }
    status = -26;
    goto asq_send_command_error;
  } else {

  }
  if ((int )details->postpone && ! details->async) {
    if ((hw->debug_mask & 16777216U) != 0U) {
      printk("\016i40e %02x.%x AQTX: Async flag not set along with postpone flag",
             (int )hw->bus.device, (int )hw->bus.func);
    } else {

    }
    status = -5;
    goto asq_send_command_error;
  } else {

  }
  tmp = i40e_clean_asq(hw);
  if ((unsigned int )tmp == 0U) {
    if ((hw->debug_mask & 16777216U) != 0U) {
      printk("\016i40e %02x.%x AQTX: Error queue is full.\n", (int )hw->bus.device,
             (int )hw->bus.func);
    } else {

    }
    status = -56;
    goto asq_send_command_error;
  } else {

  }
  desc_on_ring = (struct i40e_aq_desc *)hw->aq.asq.desc_buf.va + (unsigned long )hw->aq.asq.next_to_use;
  *desc_on_ring = *desc;
  if ((unsigned long )buff != (unsigned long )((void *)0)) {
    dma_buff = hw->aq.asq.r.asq_bi + (unsigned long )hw->aq.asq.next_to_use;
    memcpy(dma_buff->va, (void const   *)buff, (size_t )buff_size);
    desc_on_ring->datalen = buff_size;
    desc_on_ring->params.external.addr_high = (unsigned int )(dma_buff->pa >> 32ULL);
    desc_on_ring->params.external.addr_low = (unsigned int )dma_buff->pa;
  } else {

  }
  if ((hw->debug_mask & 16777216U) != 0U) {
    printk("\016i40e %02x.%x AQTX: desc and buffer:\n", (int )hw->bus.device, (int )hw->bus.func);
  } else {

  }
  i40e_debug_aq(hw, 100663296, (void *)desc_on_ring, buff, (int )buff_size);
  hw->aq.asq.next_to_use = (u16 )((int )hw->aq.asq.next_to_use + 1);
  if ((int )hw->aq.asq.next_to_use == (int )hw->aq.asq.count) {
    hw->aq.asq.next_to_use = 0U;
  } else {

  }
  if (! details->postpone) {
    writel((unsigned int )hw->aq.asq.next_to_use, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.tail);
  } else {

  }
  if (! details->async && ! details->postpone) {
    total_delay = 0U;
    ldv_52721: 
    tmp___0 = i40e_asq_done(hw);
    if ((int )tmp___0) {
      goto ldv_52720;
    } else {

    }
    usleep_range(1000UL, 2000UL);
    total_delay = total_delay + 1U;
    if (hw->aq.asq_cmd_timeout > total_delay) {
      goto ldv_52721;
    } else {

    }
    ldv_52720: ;
  } else {

  }
  tmp___1 = i40e_asq_done(hw);
  if ((int )tmp___1) {
    *desc = *desc_on_ring;
    if ((unsigned long )buff != (unsigned long )((void *)0)) {
      memcpy(buff, (void const   *)dma_buff->va, (size_t )buff_size);
    } else {

    }
    retval = desc->retval;
    if ((unsigned int )retval != 0U) {
      if ((hw->debug_mask & 16777216U) != 0U) {
        printk("\016i40e %02x.%x AQTX: Command completed with error 0x%X.\n", (int )hw->bus.device,
               (int )hw->bus.func, (int )retval);
      } else {

      }
      retval = (unsigned int )retval & 255U;
    } else {

    }
    cmd_completed = 1;
    if ((unsigned int )retval == 0U) {
      status = 0;
    } else {
      status = -53;
    }
    hw->aq.asq_last_status = (enum i40e_admin_queue_err )retval;
  } else {

  }
  if ((hw->debug_mask & 16777216U) != 0U) {
    printk("\016i40e %02x.%x AQTX: desc and buffer writeback:\n", (int )hw->bus.device,
           (int )hw->bus.func);
  } else {

  }
  i40e_debug_aq(hw, 100663296, (void *)desc, buff, (int )buff_size);
  if (! cmd_completed && (! details->async && ! details->postpone)) {
    if ((hw->debug_mask & 16777216U) != 0U) {
      printk("\016i40e %02x.%x AQTX: Writeback timeout.\n", (int )hw->bus.device,
             (int )hw->bus.func);
    } else {

    }
    status = -54;
  } else {

  }
  asq_send_command_error: 
  ldv_mutex_unlock_142(& hw->aq.asq_mutex);
  asq_send_command_exit: ;
  return (status);
}
}
void i40e_fill_default_direct_cmd_desc(struct i40e_aq_desc *desc , u16 opcode ) 
{ 


  {
  memset((void *)desc, 0, 32UL);
  desc->opcode = opcode;
  desc->flags = 8192U;
  return;
}
}
i40e_status i40e_clean_arq_element(struct i40e_hw *hw , struct i40e_arq_event_info *e ,
                                   u16 *pending ) 
{ 
  i40e_status ret_code ;
  u16 ntc ;
  struct i40e_aq_desc *desc ;
  struct i40e_dma_mem *bi ;
  u16 desc_idx ;
  u16 datalen ;
  u16 flags ;
  u16 ntu ;
  unsigned int tmp ;
  u16 _min1 ;
  u16 _min2 ;
  bool tmp___0 ;

  {
  ret_code = 0;
  ntc = hw->aq.arq.next_to_clean;
  ldv_mutex_lock_143(& hw->aq.arq_mutex);
  tmp = readl((void const volatile   *)hw->hw_addr + (unsigned long )hw->aq.arq.head);
  ntu = (unsigned int )((u16 )tmp) & 1023U;
  if ((int )ntu == (int )ntc) {
    ret_code = -57;
    goto clean_arq_element_out;
  } else {

  }
  desc = (struct i40e_aq_desc *)hw->aq.arq.desc_buf.va + (unsigned long )ntc;
  desc_idx = ntc;
  flags = desc->flags;
  if (((int )flags & 4) != 0) {
    ret_code = -53;
    hw->aq.arq_last_status = (enum i40e_admin_queue_err )desc->retval;
    if ((hw->debug_mask & 16777216U) != 0U) {
      printk("\016i40e %02x.%x AQRX: Event received with error 0x%X.\n", (int )hw->bus.device,
             (int )hw->bus.func, (unsigned int )hw->aq.arq_last_status);
    } else {

    }
  } else {

  }
  e->desc = *desc;
  datalen = desc->datalen;
  _min1 = datalen;
  _min2 = e->buf_len;
  e->msg_len = (u16 )((int )_min1 < (int )_min2 ? _min1 : _min2);
  if ((unsigned long )e->msg_buf != (unsigned long )((u8 *)0U) && (unsigned int )e->msg_len != 0U) {
    memcpy((void *)e->msg_buf, (void const   *)(hw->aq.arq.r.arq_bi + (unsigned long )desc_idx)->va,
             (size_t )e->msg_len);
  } else {

  }
  if ((hw->debug_mask & 16777216U) != 0U) {
    printk("\016i40e %02x.%x AQRX: desc and buffer:\n", (int )hw->bus.device, (int )hw->bus.func);
  } else {

  }
  i40e_debug_aq(hw, 100663296, (void *)desc, (void *)e->msg_buf, (int )hw->aq.arq_buf_size);
  bi = hw->aq.arq.r.arq_bi + (unsigned long )ntc;
  memset((void *)desc, 0, 32UL);
  desc->flags = 4096U;
  if ((unsigned int )hw->aq.arq_buf_size > 512U) {
    desc->flags = (__le16 )((unsigned int )desc->flags | 512U);
  } else {

  }
  desc->datalen = (unsigned short )bi->size;
  desc->params.external.addr_high = (unsigned int )(bi->pa >> 32ULL);
  desc->params.external.addr_low = (unsigned int )bi->pa;
  writel((unsigned int )ntc, (void volatile   *)hw->hw_addr + (unsigned long )hw->aq.arq.tail);
  ntc = (u16 )((int )ntc + 1);
  if ((int )hw->aq.num_arq_entries == (int )ntc) {
    ntc = 0U;
  } else {

  }
  hw->aq.arq.next_to_clean = ntc;
  hw->aq.arq.next_to_use = ntu;
  clean_arq_element_out: ;
  if ((unsigned long )pending != (unsigned long )((u16 *)0U)) {
    *pending = ((int )ntc > (int )ntu ? hw->aq.arq.count : 0U) + (unsigned int )((int )ntu - (int )ntc);
  } else {

  }
  ldv_mutex_unlock_144(& hw->aq.arq_mutex);
  tmp___0 = i40e_is_nvm_update_op(& e->desc);
  if ((int )tmp___0) {
    if ((int )hw->aq.nvm_release_on_done) {
      i40e_release_nvm(hw);
      hw->aq.nvm_release_on_done = 0;
    } else {

    }
  } else {

  }
  return (ret_code);
}
}
static void i40e_resume_aq(struct i40e_hw *hw ) 
{ 


  {
  hw->aq.asq.next_to_use = 0U;
  hw->aq.asq.next_to_clean = 0U;
  i40e_config_asq_regs(hw);
  hw->aq.arq.next_to_use = 0U;
  hw->aq.arq.next_to_clean = 0U;
  i40e_config_arq_regs(hw);
  return;
}
}
bool ldv_queue_work_on_125(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_126(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_127(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_128(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_129(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_130(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_131(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_132(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_133(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_134(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_135(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_136(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_137(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_asq_mutex_of_i40e_adminq_info(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_138(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_asq_mutex_of_i40e_adminq_info(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_139(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_arq_mutex_of_i40e_adminq_info(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_140(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_arq_mutex_of_i40e_adminq_info(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_141(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_asq_mutex_of_i40e_adminq_info(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_142(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_asq_mutex_of_i40e_adminq_info(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_143(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_arq_mutex_of_i40e_adminq_info(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_144(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_arq_mutex_of_i40e_adminq_info(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_177(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_175(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_178(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_179(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_174(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_176(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_180(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_169(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_171(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_170(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_173(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_172(struct workqueue_struct *ldv_func_arg1 ) ;
i40e_status i40e_aq_debug_write_register(struct i40e_hw *hw , u32 reg_addr , u64 reg_val ,
                                         struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_debug_read_register(struct i40e_hw *hw , u32 reg_addr , u64 *reg_val ,
                                        struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_clear_pxe_mode(struct i40e_hw *hw , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_send_msg_to_vf(struct i40e_hw *hw , u16 vfid , u32 v_opcode ,
                                   u32 v_retval , u8 *msg , u16 msglen , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_request_resource(struct i40e_hw *hw , enum i40e_aq_resources_ids resource ,
                                     enum i40e_aq_resource_access_type access , u8 sdp_number ,
                                     u64 *timeout , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_erase_nvm(struct i40e_hw *hw , u8 module_pointer , u32 offset ,
                              u16 length , bool last_command , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_get_lldp_mib(struct i40e_hw *hw , u8 bridge_type , u8 mib_type ,
                                 void *buff , u16 buff_size , u16 *local_len , u16 *remote_len ,
                                 struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_cfg_lldp_mib_change_event(struct i40e_hw *hw , bool enable_update ,
                                              struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_start_lldp(struct i40e_hw *hw , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_get_cee_dcb_config(struct i40e_hw *hw , void *buff , u16 buff_size ,
                                       struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_config_vsi_bw_limit(struct i40e_hw *hw , u16 seid , u16 credit ,
                                        u8 max_credit , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_dcb_updated(struct i40e_hw *hw , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_config_switch_comp_ets(struct i40e_hw *hw , u16 seid , struct i40e_aqc_configure_switching_comp_ets_data *ets_data ,
                                           enum i40e_admin_queue_opc opcode , struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_query_port_ets_config(struct i40e_hw *hw , u16 seid , struct i40e_aqc_query_port_ets_config_resp *bw_data ,
                                          struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_read_pba_string(struct i40e_hw *hw , u8 *pba_num , u32 pba_num_size ) ;
i40e_status i40e_init_nvm(struct i40e_hw *hw ) ;
struct i40e_rx_ptype_decoded i40e_ptype_lookup[256U] ;
i40e_status i40e_aq_add_rem_control_packet_filter(struct i40e_hw *hw , u8 *mac_addr ,
                                                  u16 ethtype , u16 flags , u16 vsi_seid ,
                                                  u16 queue , bool is_add , struct i40e_control_filter_stats *stats ,
                                                  struct i40e_asq_cmd_details *cmd_details ) ;
i40e_status i40e_aq_debug_dump(struct i40e_hw *hw , u8 cluster_id , u8 table_id ,
                               u32 start_index , u16 buff_size , void *buff , u16 *ret_buff_size ,
                               u8 *ret_next_table , u32 *ret_next_index , struct i40e_asq_cmd_details *cmd_details ) ;
static i40e_status i40e_set_mac_type(struct i40e_hw *hw ) 
{ 
  i40e_status status ;

  {
  status = 0;
  if ((unsigned int )hw->vendor_id == 32902U) {
    switch ((int )hw->device_id) {
    case 5490: ;
    case 5492: ;
    case 5503: ;
    case 5504: ;
    case 5505: ;
    case 5507: ;
    case 5508: ;
    case 5509: ;
    case 5510: ;
    case 5511: 
    hw->mac.type = 2;
    goto ldv_52555;
    case 5452: ;
    case 5489: 
    hw->mac.type = 3;
    goto ldv_52555;
    default: 
    hw->mac.type = 4;
    goto ldv_52555;
    }
    ldv_52555: ;
  } else {
    status = -11;
  }
  return (status);
}
}
void i40e_debug_aq(struct i40e_hw *hw , enum i40e_debug_mask mask , void *desc , void *buffer ,
                   u16 buf_len ) 
{ 
  struct i40e_aq_desc *aq_desc ;
  u16 len ;
  u8 *buf ;
  u16 i ;
  char d_buf[80U] ;
  int j ;
  int tmp ;
  u16 tmp___0 ;
  int tmp___1 ;

  {
  aq_desc = (struct i40e_aq_desc *)desc;
  len = aq_desc->datalen;
  buf = (u8 *)buffer;
  i = 0U;
  if ((hw->debug_mask & (unsigned int )mask) == 0U || (unsigned long )desc == (unsigned long )((void *)0)) {
    return;
  } else {

  }
  if ((hw->debug_mask & (unsigned int )mask) != 0U) {
    printk("\016i40e %02x.%x AQ CMD: opcode 0x%04X, flags 0x%04X, datalen 0x%04X, retval 0x%04X\n",
           (int )hw->bus.device, (int )hw->bus.func, (int )aq_desc->opcode, (int )aq_desc->flags,
           (int )aq_desc->datalen, (int )aq_desc->retval);
  } else {

  }
  if ((hw->debug_mask & (unsigned int )mask) != 0U) {
    printk("\016i40e %02x.%x \tcookie (h,l) 0x%08X 0x%08X\n", (int )hw->bus.device,
           (int )hw->bus.func, aq_desc->cookie_high, aq_desc->cookie_low);
  } else {

  }
  if ((hw->debug_mask & (unsigned int )mask) != 0U) {
    printk("\016i40e %02x.%x \tparam (0,1)  0x%08X 0x%08X\n", (int )hw->bus.device,
           (int )hw->bus.func, aq_desc->params.internal.param0, aq_desc->params.internal.param1);
  } else {

  }
  if ((hw->debug_mask & (unsigned int )mask) != 0U) {
    printk("\016i40e %02x.%x \taddr (h,l)   0x%08X 0x%08X\n", (int )hw->bus.device,
           (int )hw->bus.func, aq_desc->params.external.addr_high, aq_desc->params.external.addr_low);
  } else {

  }
  if ((unsigned long )buffer != (unsigned long )((void *)0) && (unsigned int )aq_desc->datalen != 0U) {
    if ((hw->debug_mask & (unsigned int )mask) != 0U) {
      printk("\016i40e %02x.%x AQ CMD Buffer:\n", (int )hw->bus.device, (int )hw->bus.func);
    } else {

    }
    if ((int )buf_len < (int )len) {
      len = buf_len;
    } else {

    }
    i = 0U;
    goto ldv_52571;
    ldv_52570: ;
    if ((hw->debug_mask & (unsigned int )mask) != 0U) {
      printk("\016i40e %02x.%x \t0x%04X  %02X %02X %02X %02X %02X %02X %02X %02X %02X %02X %02X %02X %02X %02X %02X %02X\n",
             (int )hw->bus.device, (int )hw->bus.func, (int )i, (int )*(buf + (unsigned long )i),
             (int )*(buf + ((unsigned long )i + 1UL)), (int )*(buf + ((unsigned long )i + 2UL)),
             (int )*(buf + ((unsigned long )i + 3UL)), (int )*(buf + ((unsigned long )i + 4UL)),
             (int )*(buf + ((unsigned long )i + 5UL)), (int )*(buf + ((unsigned long )i + 6UL)),
             (int )*(buf + ((unsigned long )i + 7UL)), (int )*(buf + ((unsigned long )i + 8UL)),
             (int )*(buf + ((unsigned long )i + 9UL)), (int )*(buf + ((unsigned long )i + 10UL)),
             (int )*(buf + ((unsigned long )i + 11UL)), (int )*(buf + ((unsigned long )i + 12UL)),
             (int )*(buf + ((unsigned long )i + 13UL)), (int )*(buf + ((unsigned long )i + 14UL)),
             (int )*(buf + ((unsigned long )i + 15UL)));
    } else {

    }
    i = (unsigned int )i + 16U;
    ldv_52571: ;
    if ((int )i < (int )len + -16) {
      goto ldv_52570;
    } else {

    }

    if ((int )i < (int )len) {
      j = 0;
      memset((void *)(& d_buf), 0, 80UL);
      tmp = sprintf((char *)(& d_buf), "\t0x%04X ", (int )i);
      j = tmp + j;
      goto ldv_52576;
      ldv_52575: 
      tmp___0 = i;
      i = (u16 )((int )i + 1);
      tmp___1 = sprintf((char *)(& d_buf) + (unsigned long )j, " %02X", (int )*(buf + (unsigned long )tmp___0));
      j = tmp___1 + j;
      ldv_52576: ;
      if ((int )i < (int )len) {
        goto ldv_52575;
      } else {

      }

      if ((hw->debug_mask & (unsigned int )mask) != 0U) {
        printk("\016i40e %02x.%x %s\n", (int )hw->bus.device, (int )hw->bus.func,
               (char *)(& d_buf));
      } else {

      }
    } else {

    }
  } else {

  }
  return;
}
}
bool i40e_check_asq_alive(struct i40e_hw *hw ) 
{ 
  unsigned int tmp ;

  {
  if (hw->aq.asq.len != 0U) {
    tmp = readl((void const volatile   *)hw->hw_addr + (unsigned long )hw->aq.asq.len);
    return ((int )tmp < 0);
  } else {
    return (0);
  }
}
}
i40e_status i40e_aq_queue_shutdown(struct i40e_hw *hw , bool unloading ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_queue_shutdown *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_queue_shutdown *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 3);
  if ((int )unloading) {
    cmd->driver_unloading = 1U;
  } else {

  }
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, (struct i40e_asq_cmd_details *)0);
  return (status);
}
}
struct i40e_rx_ptype_decoded i40e_ptype_lookup[256U]  = 
  {      {0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {1U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 1U}, 
        {2U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 5U, 1U}, 
        {3U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 1U}, 
        {4U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {5U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {6U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 1U}, 
        {7U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 1U}, 
        {8U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {9U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {10U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 1U}, 
        {11U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {12U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 2U}, 
        {13U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 2U}, 
        {14U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 2U}, 
        {15U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 2U}, 
        {16U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 2U}, 
        {17U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 2U}, 
        {18U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 2U}, 
        {19U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 2U}, 
        {20U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 2U}, 
        {21U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 2U}, 
        {22U, 1U, 1U, 0U, 1U, 0U, 0U, 0U, 0U, 2U}, 
        {23U, 1U, 1U, 0U, 0U, 0U, 0U, 0U, 0U, 2U}, 
        {24U, 1U, 1U, 0U, 0U, 0U, 0U, 0U, 1U, 3U}, 
        {25U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {26U, 1U, 1U, 0U, 0U, 0U, 0U, 0U, 2U, 3U}, 
        {27U, 1U, 1U, 0U, 0U, 0U, 0U, 0U, 3U, 3U}, 
        {28U, 1U, 1U, 0U, 0U, 0U, 0U, 0U, 4U, 3U}, 
        {29U, 1U, 1U, 0U, 0U, 1U, 1U, 1U, 0U, 2U}, 
        {30U, 1U, 1U, 0U, 0U, 1U, 1U, 0U, 0U, 2U}, 
        {31U, 1U, 1U, 0U, 0U, 1U, 1U, 0U, 1U, 3U}, 
        {32U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {33U, 1U, 1U, 0U, 0U, 1U, 1U, 0U, 2U, 3U}, 
        {34U, 1U, 1U, 0U, 0U, 1U, 1U, 0U, 3U, 3U}, 
        {35U, 1U, 1U, 0U, 0U, 1U, 1U, 0U, 4U, 3U}, 
        {36U, 1U, 1U, 0U, 0U, 1U, 2U, 1U, 0U, 2U}, 
        {37U, 1U, 1U, 0U, 0U, 1U, 2U, 0U, 0U, 2U}, 
        {38U, 1U, 1U, 0U, 0U, 1U, 2U, 0U, 1U, 3U}, 
        {39U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {40U, 1U, 1U, 0U, 0U, 1U, 2U, 0U, 2U, 3U}, 
        {41U, 1U, 1U, 0U, 0U, 1U, 2U, 0U, 3U, 3U}, 
        {42U, 1U, 1U, 0U, 0U, 1U, 2U, 0U, 4U, 3U}, 
        {43U, 1U, 1U, 0U, 0U, 2U, 0U, 0U, 0U, 2U}, 
        {44U, 1U, 1U, 0U, 0U, 2U, 1U, 1U, 0U, 2U}, 
        {45U, 1U, 1U, 0U, 0U, 2U, 1U, 0U, 0U, 2U}, 
        {46U, 1U, 1U, 0U, 0U, 2U, 1U, 0U, 1U, 3U}, 
        {47U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {48U, 1U, 1U, 0U, 0U, 2U, 1U, 0U, 2U, 3U}, 
        {49U, 1U, 1U, 0U, 0U, 2U, 1U, 0U, 3U, 3U}, 
        {50U, 1U, 1U, 0U, 0U, 2U, 1U, 0U, 4U, 3U}, 
        {51U, 1U, 1U, 0U, 0U, 2U, 2U, 1U, 0U, 2U}, 
        {52U, 1U, 1U, 0U, 0U, 2U, 2U, 0U, 0U, 2U}, 
        {53U, 1U, 1U, 0U, 0U, 2U, 2U, 0U, 1U, 3U}, 
        {54U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {55U, 1U, 1U, 0U, 0U, 2U, 2U, 0U, 2U, 3U}, 
        {56U, 1U, 1U, 0U, 0U, 2U, 2U, 0U, 3U, 3U}, 
        {57U, 1U, 1U, 0U, 0U, 2U, 2U, 0U, 4U, 3U}, 
        {58U, 1U, 1U, 0U, 0U, 3U, 0U, 0U, 0U, 2U}, 
        {59U, 1U, 1U, 0U, 0U, 3U, 1U, 1U, 0U, 2U}, 
        {60U, 1U, 1U, 0U, 0U, 3U, 1U, 0U, 0U, 2U}, 
        {61U, 1U, 1U, 0U, 0U, 3U, 1U, 0U, 1U, 3U}, 
        {62U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {63U, 1U, 1U, 0U, 0U, 3U, 1U, 0U, 2U, 3U}, 
        {64U, 1U, 1U, 0U, 0U, 3U, 1U, 0U, 3U, 3U}, 
        {65U, 1U, 1U, 0U, 0U, 3U, 1U, 0U, 4U, 3U}, 
        {66U, 1U, 1U, 0U, 0U, 3U, 2U, 1U, 0U, 2U}, 
        {67U, 1U, 1U, 0U, 0U, 3U, 2U, 0U, 0U, 2U}, 
        {68U, 1U, 1U, 0U, 0U, 3U, 2U, 0U, 1U, 3U}, 
        {69U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {70U, 1U, 1U, 0U, 0U, 3U, 2U, 0U, 2U, 3U}, 
        {71U, 1U, 1U, 0U, 0U, 3U, 2U, 0U, 3U, 3U}, 
        {72U, 1U, 1U, 0U, 0U, 3U, 2U, 0U, 4U, 3U}, 
        {73U, 1U, 1U, 0U, 0U, 4U, 0U, 0U, 0U, 2U}, 
        {74U, 1U, 1U, 0U, 0U, 4U, 1U, 1U, 0U, 2U}, 
        {75U, 1U, 1U, 0U, 0U, 4U, 1U, 0U, 0U, 2U}, 
        {76U, 1U, 1U, 0U, 0U, 4U, 1U, 0U, 1U, 3U}, 
        {77U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {78U, 1U, 1U, 0U, 0U, 4U, 1U, 0U, 2U, 3U}, 
        {79U, 1U, 1U, 0U, 0U, 4U, 1U, 0U, 3U, 3U}, 
        {80U, 1U, 1U, 0U, 0U, 4U, 1U, 0U, 4U, 3U}, 
        {81U, 1U, 1U, 0U, 0U, 4U, 2U, 1U, 0U, 2U}, 
        {82U, 1U, 1U, 0U, 0U, 4U, 2U, 0U, 0U, 2U}, 
        {83U, 1U, 1U, 0U, 0U, 4U, 2U, 0U, 1U, 3U}, 
        {84U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {85U, 1U, 1U, 0U, 0U, 4U, 2U, 0U, 2U, 3U}, 
        {86U, 1U, 1U, 0U, 0U, 4U, 2U, 0U, 3U, 3U}, 
        {87U, 1U, 1U, 0U, 0U, 4U, 2U, 0U, 4U, 3U}, 
        {88U, 1U, 1U, 1U, 1U, 0U, 0U, 0U, 0U, 2U}, 
        {89U, 1U, 1U, 1U, 0U, 0U, 0U, 0U, 0U, 2U}, 
        {90U, 1U, 1U, 1U, 0U, 0U, 0U, 0U, 1U, 2U}, 
        {91U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {92U, 1U, 1U, 1U, 0U, 0U, 0U, 0U, 2U, 3U}, 
        {93U, 1U, 1U, 1U, 0U, 0U, 0U, 0U, 3U, 3U}, 
        {94U, 1U, 1U, 1U, 0U, 0U, 0U, 0U, 4U, 3U}, 
        {95U, 1U, 1U, 1U, 0U, 1U, 1U, 1U, 0U, 2U}, 
        {96U, 1U, 1U, 1U, 0U, 1U, 1U, 0U, 0U, 2U}, 
        {97U, 1U, 1U, 1U, 0U, 1U, 1U, 0U, 1U, 3U}, 
        {98U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {99U, 1U, 1U, 1U, 0U, 1U, 1U, 0U, 2U, 3U}, 
        {100U, 1U, 1U, 1U, 0U, 1U, 1U, 0U, 3U, 3U}, 
        {101U, 1U, 1U, 1U, 0U, 1U, 1U, 0U, 4U, 3U}, 
        {102U, 1U, 1U, 1U, 0U, 1U, 2U, 1U, 0U, 2U}, 
        {103U, 1U, 1U, 1U, 0U, 1U, 2U, 0U, 0U, 2U}, 
        {104U, 1U, 1U, 1U, 0U, 1U, 2U, 0U, 1U, 3U}, 
        {105U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {106U, 1U, 1U, 1U, 0U, 1U, 2U, 0U, 2U, 3U}, 
        {107U, 1U, 1U, 1U, 0U, 1U, 2U, 0U, 3U, 3U}, 
        {108U, 1U, 1U, 1U, 0U, 1U, 2U, 0U, 4U, 3U}, 
        {109U, 1U, 1U, 1U, 0U, 2U, 0U, 0U, 0U, 2U}, 
        {110U, 1U, 1U, 1U, 0U, 2U, 1U, 1U, 0U, 2U}, 
        {111U, 1U, 1U, 1U, 0U, 2U, 1U, 0U, 0U, 2U}, 
        {112U, 1U, 1U, 1U, 0U, 2U, 1U, 0U, 1U, 3U}, 
        {113U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {114U, 1U, 1U, 1U, 0U, 2U, 1U, 0U, 2U, 3U}, 
        {115U, 1U, 1U, 1U, 0U, 2U, 1U, 0U, 3U, 3U}, 
        {116U, 1U, 1U, 1U, 0U, 2U, 1U, 0U, 4U, 3U}, 
        {117U, 1U, 1U, 1U, 0U, 2U, 2U, 1U, 0U, 2U}, 
        {118U, 1U, 1U, 1U, 0U, 2U, 2U, 0U, 0U, 2U}, 
        {119U, 1U, 1U, 1U, 0U, 2U, 2U, 0U, 1U, 3U}, 
        {120U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {121U, 1U, 1U, 1U, 0U, 2U, 2U, 0U, 2U, 3U}, 
        {122U, 1U, 1U, 1U, 0U, 2U, 2U, 0U, 3U, 3U}, 
        {123U, 1U, 1U, 1U, 0U, 2U, 2U, 0U, 4U, 3U}, 
        {124U, 1U, 1U, 1U, 0U, 3U, 0U, 0U, 0U, 2U}, 
        {125U, 1U, 1U, 1U, 0U, 3U, 1U, 1U, 0U, 2U}, 
        {126U, 1U, 1U, 1U, 0U, 3U, 1U, 0U, 0U, 2U}, 
        {127U, 1U, 1U, 1U, 0U, 3U, 1U, 0U, 1U, 3U}, 
        {128U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {129U, 1U, 1U, 1U, 0U, 3U, 1U, 0U, 2U, 3U}, 
        {130U, 1U, 1U, 1U, 0U, 3U, 1U, 0U, 3U, 3U}, 
        {131U, 1U, 1U, 1U, 0U, 3U, 1U, 0U, 4U, 3U}, 
        {132U, 1U, 1U, 1U, 0U, 3U, 2U, 1U, 0U, 2U}, 
        {133U, 1U, 1U, 1U, 0U, 3U, 2U, 0U, 0U, 2U}, 
        {134U, 1U, 1U, 1U, 0U, 3U, 2U, 0U, 1U, 3U}, 
        {135U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {136U, 1U, 1U, 1U, 0U, 3U, 2U, 0U, 2U, 3U}, 
        {137U, 1U, 1U, 1U, 0U, 3U, 2U, 0U, 3U, 3U}, 
        {138U, 1U, 1U, 1U, 0U, 3U, 2U, 0U, 4U, 3U}, 
        {139U, 1U, 1U, 1U, 0U, 4U, 0U, 0U, 0U, 2U}, 
        {140U, 1U, 1U, 1U, 0U, 4U, 1U, 1U, 0U, 2U}, 
        {141U, 1U, 1U, 1U, 0U, 4U, 1U, 0U, 0U, 2U}, 
        {142U, 1U, 1U, 1U, 0U, 4U, 1U, 0U, 1U, 3U}, 
        {143U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {144U, 1U, 1U, 1U, 0U, 4U, 1U, 0U, 2U, 3U}, 
        {145U, 1U, 1U, 1U, 0U, 4U, 1U, 0U, 3U, 3U}, 
        {146U, 1U, 1U, 1U, 0U, 4U, 1U, 0U, 4U, 3U}, 
        {147U, 1U, 1U, 1U, 0U, 4U, 2U, 1U, 0U, 2U}, 
        {148U, 1U, 1U, 1U, 0U, 4U, 2U, 0U, 0U, 2U}, 
        {149U, 1U, 1U, 1U, 0U, 4U, 2U, 0U, 1U, 3U}, 
        {150U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {151U, 1U, 1U, 1U, 0U, 4U, 2U, 0U, 2U, 3U}, 
        {152U, 1U, 1U, 1U, 0U, 4U, 2U, 0U, 3U, 3U}, 
        {153U, 1U, 1U, 1U, 0U, 4U, 2U, 0U, 4U, 3U}, 
        {154U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {155U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {156U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {157U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {158U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {159U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {160U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {161U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {162U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {163U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {164U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {165U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {166U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {167U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {168U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {169U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {170U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {171U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {172U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {173U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {174U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {175U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {176U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {177U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {178U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {179U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {180U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {181U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {182U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {183U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {184U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {185U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {186U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {187U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {188U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {189U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {190U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {191U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {192U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {193U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {194U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {195U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {196U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {197U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {198U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {199U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {200U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {201U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {202U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {203U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {204U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {205U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {206U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {207U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {208U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {209U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {210U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {211U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {212U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {213U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {214U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {215U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {216U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {217U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {218U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {219U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {220U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {221U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {222U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {223U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {224U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {225U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {226U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {227U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {228U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {229U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {230U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {231U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {232U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {233U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {234U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {235U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {236U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {237U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {238U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {239U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {240U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {241U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {242U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {243U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {244U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {245U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {246U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {247U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {248U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {249U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {250U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {251U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {252U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {253U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {254U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}, 
        {255U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U, 0U}};
i40e_status i40e_init_shared_code(struct i40e_hw *hw ) 
{ 
  i40e_status status ;
  u32 port ;
  u32 ari ;
  u32 func_rid ;
  unsigned int tmp ;
  unsigned int tmp___0 ;

  {
  status = 0;
  i40e_set_mac_type(hw);
  switch ((unsigned int )hw->mac.type) {
  case 2U: ;
  goto ldv_52597;
  default: ;
  return (-11);
  }
  ldv_52597: 
  hw->phy.get_link_info = 1;
  tmp = readl((void const volatile   *)hw->hw_addr + 1836160U);
  port = tmp & 3U;
  hw->port = (unsigned char )port;
  tmp___0 = readl((void const volatile   *)hw->hw_addr + 779432U);
  ari = (tmp___0 & 16U) >> 4;
  func_rid = readl((void const volatile   *)hw->hw_addr + 638976U);
  if (ari != 0U) {
    hw->pf_id = (unsigned char )func_rid;
  } else {
    hw->pf_id = (unsigned int )((unsigned char )func_rid) & 7U;
  }
  status = i40e_init_nvm(hw);
  return (status);
}
}
static i40e_status i40e_aq_mac_address_read(struct i40e_hw *hw , u16 *flags , struct i40e_aqc_mac_address_read_data *addrs ,
                                            struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_mac_address_read *cmd_data ;
  i40e_status status ;

  {
  cmd_data = (struct i40e_aqc_mac_address_read *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 263);
  desc.flags = (__le16 )((unsigned int )desc.flags | 4096U);
  status = i40e_asq_send_command(hw, & desc, (void *)addrs, 24, cmd_details);
  *flags = cmd_data->command_flags;
  return (status);
}
}
i40e_status i40e_aq_mac_address_write(struct i40e_hw *hw , u16 flags , u8 *mac_addr ,
                                      struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_mac_address_write *cmd_data ;
  i40e_status status ;

  {
  cmd_data = (struct i40e_aqc_mac_address_write *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 264);
  cmd_data->command_flags = flags;
  cmd_data->mac_sah = (unsigned short )((int )((short )((int )*mac_addr << 8)) | (int )((short )*(mac_addr + 1UL)));
  cmd_data->mac_sal = ((((unsigned int )*(mac_addr + 2UL) << 24) | ((unsigned int )*(mac_addr + 3UL) << 16)) | ((unsigned int )*(mac_addr + 4UL) << 8)) | (unsigned int )*(mac_addr + 5UL);
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_get_mac_addr(struct i40e_hw *hw , u8 *mac_addr ) 
{ 
  struct i40e_aqc_mac_address_read_data addrs ;
  i40e_status status ;
  u16 flags ;

  {
  flags = 0U;
  status = i40e_aq_mac_address_read(hw, & flags, & addrs, (struct i40e_asq_cmd_details *)0);
  if (((int )flags & 16) != 0) {
    memcpy((void *)mac_addr, (void const   *)(& addrs.pf_lan_mac), 6UL);
  } else {

  }
  return (status);
}
}
i40e_status i40e_get_port_mac_addr(struct i40e_hw *hw , u8 *mac_addr ) 
{ 
  struct i40e_aqc_mac_address_read_data addrs ;
  i40e_status status ;
  u16 flags ;

  {
  flags = 0U;
  status = i40e_aq_mac_address_read(hw, & flags, & addrs, (struct i40e_asq_cmd_details *)0);
  if ((int )status != 0) {
    return (status);
  } else {

  }
  if (((int )flags & 64) != 0) {
    memcpy((void *)mac_addr, (void const   *)(& addrs.port_mac), 6UL);
  } else {
    status = -10;
  }
  return (status);
}
}
void i40e_pre_tx_queue_cfg(struct i40e_hw *hw , u32 queue , bool enable ) 
{ 
  u32 abs_queue_idx ;
  u32 reg_block ;
  u32 reg_val ;

  {
  abs_queue_idx = hw->func_caps.base_queue + queue;
  reg_block = 0U;
  if (abs_queue_idx > 127U) {
    reg_block = abs_queue_idx / 128U;
    abs_queue_idx = abs_queue_idx & 127U;
  } else {

  }
  reg_val = readl((void const volatile   *)hw->hw_addr + (unsigned long )((reg_block + 235840U) * 4U));
  reg_val = reg_val & 4294965248U;
  reg_val = reg_val | abs_queue_idx;
  if ((int )enable) {
    reg_val = reg_val | 2147483648U;
  } else {
    reg_val = reg_val | 1073741824U;
  }
  writel(reg_val, (void volatile   *)hw->hw_addr + (unsigned long )((reg_block + 235840U) * 4U));
  return;
}
}
i40e_status i40e_get_san_mac_addr(struct i40e_hw *hw , u8 *mac_addr ) 
{ 
  struct i40e_aqc_mac_address_read_data addrs ;
  i40e_status status ;
  u16 flags ;

  {
  flags = 0U;
  status = i40e_aq_mac_address_read(hw, & flags, & addrs, (struct i40e_asq_cmd_details *)0);
  if ((int )status != 0) {
    return (status);
  } else {

  }
  if (((int )flags & 32) != 0) {
    memcpy((void *)mac_addr, (void const   *)(& addrs.pf_san_mac), 6UL);
  } else {
    status = -10;
  }
  return (status);
}
}
i40e_status i40e_read_pba_string(struct i40e_hw *hw , u8 *pba_num , u32 pba_num_size ) 
{ 
  i40e_status status ;
  u16 pba_word ;
  u16 pba_size ;
  u16 pba_ptr ;
  u16 i ;

  {
  status = 0;
  pba_word = 0U;
  pba_size = 0U;
  pba_ptr = 0U;
  i = 0U;
  status = i40e_read_nvm_word(hw, 21, & pba_word);
  if ((int )status != 0 || (unsigned int )pba_word != 64250U) {
    return (status);
  } else {

  }
  status = i40e_read_nvm_word(hw, 22, & pba_ptr);
  if ((int )status != 0) {
    return (status);
  } else {

  }
  status = i40e_read_nvm_word(hw, (int )pba_ptr, & pba_size);
  if ((int )status != 0) {
    return (status);
  } else {

  }
  pba_size = (u16 )((int )pba_size - 1);
  if ((unsigned int )pba_size * 2U + 1U > pba_num_size) {
    return (-5);
  } else {

  }
  i = 0U;
  goto ldv_52657;
  ldv_52656: 
  status = i40e_read_nvm_word(hw, (int )((unsigned int )((int )pba_ptr + (int )i) + 1U),
                              & pba_word);
  if ((int )status != 0) {
    return (status);
  } else {

  }
  *(pba_num + (unsigned long )((int )i * 2)) = (u8 )((int )pba_word >> 8);
  *(pba_num + ((unsigned long )((int )i * 2) + 1UL)) = (u8 )pba_word;
  i = (u16 )((int )i + 1);
  ldv_52657: ;
  if ((int )i < (int )pba_size) {
    goto ldv_52656;
  } else {

  }
  *(pba_num + (unsigned long )((int )pba_size * 2)) = 0U;
  return (status);
}
}
static enum i40e_media_type i40e_get_media_type(struct i40e_hw *hw ) 
{ 
  enum i40e_media_type media ;

  {
  switch ((unsigned int )hw->phy.link_info.phy_type) {
  case 20U: ;
  case 21U: ;
  case 27U: ;
  case 28U: ;
  case 25U: ;
  case 26U: 
  media = 1;
  goto ldv_52669;
  case 17U: ;
  case 18U: ;
  case 19U: 
  media = 2;
  goto ldv_52669;
  case 11U: ;
  case 10U: ;
  case 23U: ;
  case 24U: ;
  case 22U: ;
  case 13U: ;
  case 12U: 
  media = 5;
  goto ldv_52669;
  case 1U: ;
  case 2U: ;
  case 3U: ;
  case 4U: ;
  case 30U: 
  media = 3;
  goto ldv_52669;
  case 0U: ;
  case 5U: ;
  case 6U: ;
  case 8U: ;
  case 9U: ;
  default: 
  media = 0;
  goto ldv_52669;
  }
  ldv_52669: ;
  return (media);
}
}
i40e_status i40e_pf_reset(struct i40e_hw *hw ) 
{ 
  u32 cnt ;
  u32 cnt1 ;
  u32 reg ;
  u32 grst_del ;
  unsigned int tmp ;

  {
  cnt = 0U;
  cnt1 = 0U;
  reg = 0U;
  tmp = readl((void const volatile   *)hw->hw_addr + 754048U);
  grst_del = tmp & 63U;
  cnt = 0U;
  goto ldv_52700;
  ldv_52699: 
  reg = readl((void const volatile   *)hw->hw_addr + 754056U);
  if ((reg & 3U) == 0U) {
    goto ldv_52698;
  } else {

  }
  msleep(100U);
  cnt = cnt + 1U;
  ldv_52700: ;
  if (grst_del + 2U > cnt) {
    goto ldv_52699;
  } else {

  }
  ldv_52698: ;
  if ((reg & 3U) != 0U) {
    return (-15);
  } else {

  }
  cnt1 = 0U;
  goto ldv_52703;
  ldv_52702: 
  reg = readl((void const volatile   *)hw->hw_addr + 745480U);
  reg = reg & 24U;
  if (reg == 24U) {
    goto ldv_52701;
  } else {

  }
  usleep_range(10000UL, 20000UL);
  cnt1 = cnt1 + 1U;
  ldv_52703: ;
  if (cnt1 <= 199U) {
    goto ldv_52702;
  } else {

  }
  ldv_52701: ;
  if ((reg & 24U) == 0U) {
    return (-15);
  } else {

  }
  if (cnt == 0U) {
    if ((unsigned int )hw->revision_id == 0U) {
      cnt = 200U;
    } else {
      cnt = 200U;
    }
    reg = readl((void const volatile   *)hw->hw_addr + 599040U);
    writel(reg | 1U, (void volatile   *)hw->hw_addr + 599040U);
    goto ldv_52706;
    ldv_52705: 
    reg = readl((void const volatile   *)hw->hw_addr + 599040U);
    if ((reg & 1U) == 0U) {
      goto ldv_52704;
    } else {

    }
    usleep_range(1000UL, 2000UL);
    cnt = cnt - 1U;
    ldv_52706: ;
    if (cnt != 0U) {
      goto ldv_52705;
    } else {

    }
    ldv_52704: ;
    if ((int )reg & 1) {
      return (-15);
    } else {

    }
  } else {

  }
  i40e_clear_pxe_mode(hw);
  return (0);
}
}
void i40e_clear_hw(struct i40e_hw *hw ) 
{ 
  u32 num_queues ;
  u32 base_queue ;
  u32 num_pf_int ;
  u32 num_vf_int ;
  u32 num_vfs ;
  u32 i ;
  u32 j ;
  u32 val ;
  u32 eol ;
  u32 abs_queue_idx ;
  u32 reg_block ;

  {
  eol = 2047U;
  val = readl((void const volatile   *)hw->hw_addr + 779412U);
  num_pf_int = (val & 8188U) >> 2;
  num_vf_int = (val & 16769024U) >> 13;
  val = readl((void const volatile   *)hw->hw_addr + 1836032U);
  base_queue = val & 2047U;
  j = (val & 134152192U) >> 16;
  if ((int )val < 0) {
    num_queues = (j - base_queue) + 1U;
  } else {
    num_queues = 0U;
  }
  val = readl((void const volatile   *)hw->hw_addr + 1836288U);
  i = val & 255U;
  j = (val & 65280U) >> 8;
  if ((int )val < 0) {
    num_vfs = (j - i) + 1U;
  } else {
    num_vfs = 0U;
  }
  writel(0U, (void volatile   *)hw->hw_addr + 231424U);
  val = 24U;
  i = 0U;
  goto ldv_52720;
  ldv_52719: 
  writel(val, (void volatile   *)hw->hw_addr + (unsigned long )((i + 53760U) * 4U));
  i = i + 1U;
  ldv_52720: ;
  if (num_pf_int - 2U > i) {
    goto ldv_52719;
  } else {

  }
  val = eol;
  writel(val, (void volatile   *)hw->hw_addr + 230656U);
  i = 0U;
  goto ldv_52723;
  ldv_52722: 
  writel(val, (void volatile   *)hw->hw_addr + (unsigned long )((i + 54272U) * 4U));
  i = i + 1U;
  ldv_52723: ;
  if (num_pf_int - 2U > i) {
    goto ldv_52722;
  } else {

  }
  val = eol;
  i = 0U;
  goto ldv_52726;
  ldv_52725: 
  writel(val, (void volatile   *)hw->hw_addr + (unsigned long )((i + 43520U) * 4U));
  i = i + 1U;
  ldv_52726: ;
  if (i < num_vfs) {
    goto ldv_52725;
  } else {

  }
  i = 0U;
  goto ldv_52729;
  ldv_52728: 
  writel(val, (void volatile   *)hw->hw_addr + (unsigned long )((i + 37888U) * 4U));
  i = i + 1U;
  ldv_52729: ;
  if (num_vf_int - 2U > i) {
    goto ldv_52728;
  } else {

  }
  i = 0U;
  goto ldv_52734;
  ldv_52733: 
  abs_queue_idx = base_queue + i;
  reg_block = 0U;
  if (abs_queue_idx > 127U) {
    reg_block = abs_queue_idx / 128U;
    abs_queue_idx = abs_queue_idx & 127U;
  } else {

  }
  val = readl((void const volatile   *)hw->hw_addr + (unsigned long )((reg_block + 235840U) * 4U));
  val = val & 4294965248U;
  val = val | abs_queue_idx;
  val = val | 1073741824U;
  writel(val, (void volatile   *)hw->hw_addr + (unsigned long )((reg_block + 235840U) * 4U));
  i = i + 1U;
  ldv_52734: ;
  if (i < num_queues) {
    goto ldv_52733;
  } else {

  }
  __const_udelay(1718000UL);
  i = 0U;
  goto ldv_52737;
  ldv_52736: 
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )((i + 61440U) * 4U));
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )((i + 262144U) * 4U));
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )((i + 59392U) * 4U));
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )((i + 294912U) * 4U));
  i = i + 1U;
  ldv_52737: ;
  if (i < num_queues) {
    goto ldv_52736;
  } else {

  }
  __const_udelay(214750UL);
  return;
}
}
void i40e_clear_pxe_mode(struct i40e_hw *hw ) 
{ 
  u32 reg ;
  bool tmp ;

  {
  tmp = i40e_check_asq_alive(hw);
  if ((int )tmp) {
    i40e_aq_clear_pxe_mode(hw, (struct i40e_asq_cmd_details *)0);
  } else {

  }
  reg = readl((void const volatile   *)hw->hw_addr + 1221888U);
  if ((unsigned int )hw->revision_id == 0U) {
    writel(reg & 4294967294U, (void volatile   *)hw->hw_addr + 1221888U);
  } else {
    writel(reg | 1U, (void volatile   *)hw->hw_addr + 1221888U);
  }
  return;
}
}
static u32 i40e_led_is_mine(struct i40e_hw *hw , int idx ) 
{ 
  u32 gpio_val ;
  u32 port ;

  {
  gpio_val = 0U;
  if (! hw->func_caps.led[idx]) {
    return (0U);
  } else {

  }
  gpio_val = readl((void const volatile   *)hw->hw_addr + (unsigned long )((idx + 139328) * 4));
  port = gpio_val & 3U;
  if ((gpio_val & 8U) != 0U || (u32 )hw->port != port) {
    return (0U);
  } else {

  }
  return (gpio_val);
}
}
u32 i40e_led_get(struct i40e_hw *hw ) 
{ 
  u32 current_mode ;
  u32 mode ;
  int i ;
  u32 gpio_val ;
  u32 tmp ;

  {
  current_mode = 0U;
  mode = 0U;
  i = 22;
  goto ldv_52764;
  ldv_52763: 
  tmp = i40e_led_is_mine(hw, i);
  gpio_val = tmp;
  if (gpio_val == 0U) {
    goto ldv_52756;
  } else {

  }
  current_mode = (gpio_val & 126976U) >> 12;
  switch (current_mode) {
  case 10U: ;
  case 14U: ;
  case 13U: ;
  goto ldv_52756;
  default: ;
  goto ldv_52761;
  }
  ldv_52761: 
  mode = (gpio_val & 126976U) >> 12;
  goto ldv_52762;
  ldv_52756: 
  i = i + 1;
  ldv_52764: ;
  if (i <= 29) {
    goto ldv_52763;
  } else {

  }
  ldv_52762: ;
  return (mode);
}
}
void i40e_led_set(struct i40e_hw *hw , u32 mode , bool blink ) 
{ 
  u32 current_mode ;
  int i ;
  u32 gpio_val ;
  u32 tmp ;

  {
  current_mode = 0U;
  i = 22;
  goto ldv_52781;
  ldv_52780: 
  tmp = i40e_led_is_mine(hw, i);
  gpio_val = tmp;
  if (gpio_val == 0U) {
    goto ldv_52773;
  } else {

  }
  current_mode = (gpio_val & 126976U) >> 12;
  switch (current_mode) {
  case 10U: ;
  case 14U: ;
  case 13U: ;
  goto ldv_52773;
  default: ;
  goto ldv_52778;
  }
  ldv_52778: 
  gpio_val = gpio_val & 4294840319U;
  gpio_val = ((mode << 12) & 126976U) | gpio_val;
  if (mode == 12U) {
    blink = 0;
  } else {

  }
  if ((int )blink) {
    gpio_val = gpio_val | 2048U;
  } else {
    gpio_val = gpio_val & 4294965247U;
  }
  writel(gpio_val, (void volatile   *)hw->hw_addr + (unsigned long )((i + 139328) * 4));
  goto ldv_52779;
  ldv_52773: 
  i = i + 1;
  ldv_52781: ;
  if (i <= 29) {
    goto ldv_52780;
  } else {

  }
  ldv_52779: ;
  return;
}
}
enum i40e_status_code i40e_aq_get_phy_capabilities(struct i40e_hw *hw , bool qualified_modules ,
                                                   bool report_init , struct i40e_aq_get_phy_abilities_resp *abilities ,
                                                   struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  i40e_status status ;
  u16 abilities_size ;

  {
  abilities_size = 536U;
  if ((unsigned long )abilities == (unsigned long )((struct i40e_aq_get_phy_abilities_resp *)0)) {
    return (-5);
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, 1536);
  desc.flags = (__le16 )((unsigned int )desc.flags | 4096U);
  if ((unsigned int )abilities_size > 512U) {
    desc.flags = (__le16 )((unsigned int )desc.flags | 512U);
  } else {

  }
  if ((int )qualified_modules) {
    desc.params.external.param0 = desc.params.external.param0 | 1U;
  } else {

  }
  if ((int )report_init) {
    desc.params.external.param0 = desc.params.external.param0 | 2U;
  } else {

  }
  status = i40e_asq_send_command(hw, & desc, (void *)abilities, (int )abilities_size,
                                 cmd_details);
  if ((unsigned int )hw->aq.asq_last_status == 5U) {
    status = -7;
  } else {

  }
  return (status);
}
}
enum i40e_status_code i40e_aq_set_phy_config(struct i40e_hw *hw , struct i40e_aq_set_phy_config *config ,
                                             struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aq_set_phy_config *cmd ;
  enum i40e_status_code status ;

  {
  cmd = (struct i40e_aq_set_phy_config *)(& desc.params.raw);
  if ((unsigned long )config == (unsigned long )((struct i40e_aq_set_phy_config *)0)) {
    return (-5);
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, 1537);
  *cmd = *config;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
enum i40e_status_code i40e_set_fc(struct i40e_hw *hw , u8 *aq_failures , bool atomic_restart ) 
{ 
  enum i40e_fc_mode fc_mode ;
  struct i40e_aq_get_phy_abilities_resp abilities ;
  struct i40e_aq_set_phy_config config ;
  enum i40e_status_code status ;
  u8 pause_mask ;

  {
  fc_mode = hw->fc.requested_mode;
  pause_mask = 0U;
  *aq_failures = 0U;
  switch ((unsigned int )fc_mode) {
  case 3U: 
  pause_mask = (u8 )((unsigned int )pause_mask | 1U);
  pause_mask = (u8 )((unsigned int )pause_mask | 2U);
  goto ldv_52811;
  case 1U: 
  pause_mask = (u8 )((unsigned int )pause_mask | 2U);
  goto ldv_52811;
  case 2U: 
  pause_mask = (u8 )((unsigned int )pause_mask | 1U);
  goto ldv_52811;
  default: ;
  goto ldv_52811;
  }
  ldv_52811: 
  status = i40e_aq_get_phy_capabilities(hw, 0, 0, & abilities, (struct i40e_asq_cmd_details *)0);
  if ((int )status != 0) {
    *aq_failures = (u8 )((unsigned int )*aq_failures | 1U);
    return (status);
  } else {

  }
  memset((void *)(& config), 0, 16UL);
  config.abilities = (unsigned int )abilities.abilities & 252U;
  config.abilities = (u8 )((int )config.abilities | (int )pause_mask);
  if ((int )config.abilities != (int )abilities.abilities) {
    if ((int )atomic_restart) {
      config.abilities = (u8 )((unsigned int )config.abilities | 32U);
    } else {

    }
    config.phy_type = abilities.phy_type;
    config.link_speed = abilities.link_speed;
    config.eee_capability = abilities.eee_capability;
    config.eeer = abilities.eeer_val;
    config.low_power_ctrl = abilities.d3_lpan;
    status = i40e_aq_set_phy_config(hw, & config, (struct i40e_asq_cmd_details *)0);
    if ((int )status != 0) {
      *aq_failures = (u8 )((unsigned int )*aq_failures | 2U);
    } else {

    }
  } else {

  }
  status = i40e_aq_get_link_info(hw, 1, (struct i40e_link_status *)0, (struct i40e_asq_cmd_details *)0);
  if ((int )status != 0) {
    msleep(1000U);
    status = i40e_aq_get_link_info(hw, 1, (struct i40e_link_status *)0, (struct i40e_asq_cmd_details *)0);
  } else {

  }
  if ((int )status != 0) {
    *aq_failures = (u8 )((unsigned int )*aq_failures | 4U);
  } else {

  }
  return (status);
}
}
i40e_status i40e_aq_clear_pxe_mode(struct i40e_hw *hw , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  i40e_status status ;
  struct i40e_aq_desc desc ;
  struct i40e_aqc_clear_pxe *cmd ;

  {
  cmd = (struct i40e_aqc_clear_pxe *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 272);
  cmd->rx_cnt = 2U;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  writel(1U, (void volatile   *)hw->hw_addr + 1221888U);
  return (status);
}
}
i40e_status i40e_aq_set_link_restart_an(struct i40e_hw *hw , bool enable_link , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_set_link_restart_an *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_set_link_restart_an *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 1541);
  cmd->command = 2U;
  if ((int )enable_link) {
    cmd->command = (u8 )((unsigned int )cmd->command | 4U);
  } else {
    cmd->command = (unsigned int )cmd->command & 251U;
  }
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_get_link_info(struct i40e_hw *hw , bool enable_lse , struct i40e_link_status *link ,
                                  struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_get_link_status *resp ;
  struct i40e_link_status *hw_link_info ;
  i40e_status status ;
  bool tx_pause ;
  bool rx_pause ;
  u16 command_flags ;

  {
  resp = (struct i40e_aqc_get_link_status *)(& desc.params.raw);
  hw_link_info = & hw->phy.link_info;
  i40e_fill_default_direct_cmd_desc(& desc, 1543);
  if ((int )enable_lse) {
    command_flags = 3U;
  } else {
    command_flags = 2U;
  }
  resp->command_flags = command_flags;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  if ((int )status != 0) {
    goto aq_get_link_info_exit;
  } else {

  }
  hw->phy.link_info_old = *hw_link_info;
  hw_link_info->phy_type = (enum i40e_aq_phy_type )resp->phy_type;
  hw->phy.media_type = i40e_get_media_type(hw);
  hw_link_info->link_speed = (enum i40e_aq_link_speed )resp->link_speed;
  hw_link_info->link_info = resp->link_info;
  hw_link_info->an_info = resp->an_info;
  hw_link_info->ext_info = resp->ext_info;
  hw_link_info->loopback = resp->loopback;
  hw_link_info->max_frame_size = resp->max_frame_size;
  hw_link_info->pacing = (unsigned int )resp->config & 120U;
  tx_pause = ((int )resp->an_info & 32) != 0;
  rx_pause = ((int )resp->an_info & 64) != 0;
  if (((int )tx_pause & (int )rx_pause) != 0) {
    hw->fc.current_mode = 3;
  } else
  if ((int )tx_pause) {
    hw->fc.current_mode = 2;
  } else
  if ((int )rx_pause) {
    hw->fc.current_mode = 1;
  } else {
    hw->fc.current_mode = 0;
  }
  if (((int )resp->config & 4) != 0) {
    hw_link_info->crc_enable = 1;
  } else {
    hw_link_info->crc_enable = 0;
  }
  if (((int )resp->command_flags & 3) != 0) {
    hw_link_info->lse_enable = 1;
  } else {
    hw_link_info->lse_enable = 0;
  }
  if (((unsigned int )hw->aq.fw_maj_ver <= 3U || ((unsigned int )hw->aq.fw_maj_ver == 4U && (unsigned int )hw->aq.fw_min_ver <= 39U)) && (unsigned int )hw_link_info->phy_type == 14U) {
    hw_link_info->phy_type = 22;
  } else {

  }
  if ((unsigned long )link != (unsigned long )((struct i40e_link_status *)0)) {
    *link = *hw_link_info;
  } else {

  }
  hw->phy.get_link_info = 0;
  aq_get_link_info_exit: ;
  return (status);
}
}
i40e_status i40e_aq_set_phy_int_mask(struct i40e_hw *hw , u16 mask , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_set_phy_int_mask *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_set_phy_int_mask *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 1555);
  cmd->event_mask = mask;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_add_vsi(struct i40e_hw *hw , struct i40e_vsi_context *vsi_ctx ,
                            struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_add_get_update_vsi *cmd ;
  struct i40e_aqc_add_get_update_vsi_completion *resp ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_add_get_update_vsi *)(& desc.params.raw);
  resp = (struct i40e_aqc_add_get_update_vsi_completion *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 528);
  cmd->uplink_seid = vsi_ctx->uplink_seid;
  cmd->connection_type = vsi_ctx->connection_type;
  cmd->vf_id = vsi_ctx->vf_num;
  cmd->vsi_flags = vsi_ctx->flags;
  desc.flags = (__le16 )((unsigned int )desc.flags | 5120U);
  status = i40e_asq_send_command(hw, & desc, (void *)(& vsi_ctx->info), 128, cmd_details);
  if ((int )status != 0) {
    goto aq_add_vsi_exit;
  } else {

  }
  vsi_ctx->seid = resp->seid;
  vsi_ctx->vsi_number = resp->vsi_number;
  vsi_ctx->vsis_allocated = resp->vsi_used;
  vsi_ctx->vsis_unallocated = resp->vsi_free;
  aq_add_vsi_exit: ;
  return (status);
}
}
i40e_status i40e_aq_set_vsi_unicast_promiscuous(struct i40e_hw *hw , u16 seid , bool set ,
                                                struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_set_vsi_promiscuous_modes *cmd ;
  i40e_status status ;
  u16 flags ;

  {
  cmd = (struct i40e_aqc_set_vsi_promiscuous_modes *)(& desc.params.raw);
  flags = 0U;
  i40e_fill_default_direct_cmd_desc(& desc, 596);
  if ((int )set) {
    flags = (u16 )((unsigned int )flags | 1U);
  } else {

  }
  cmd->promiscuous_flags = flags;
  cmd->valid_flags = 1U;
  cmd->seid = seid;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_set_vsi_multicast_promiscuous(struct i40e_hw *hw , u16 seid ,
                                                  bool set , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_set_vsi_promiscuous_modes *cmd ;
  i40e_status status ;
  u16 flags ;

  {
  cmd = (struct i40e_aqc_set_vsi_promiscuous_modes *)(& desc.params.raw);
  flags = 0U;
  i40e_fill_default_direct_cmd_desc(& desc, 596);
  if ((int )set) {
    flags = (u16 )((unsigned int )flags | 2U);
  } else {

  }
  cmd->promiscuous_flags = flags;
  cmd->valid_flags = 2U;
  cmd->seid = seid;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_set_vsi_broadcast(struct i40e_hw *hw , u16 seid , bool set_filter ,
                                      struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_set_vsi_promiscuous_modes *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_set_vsi_promiscuous_modes *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 596);
  if ((int )set_filter) {
    cmd->promiscuous_flags = (__le16 )((unsigned int )cmd->promiscuous_flags | 4U);
  } else {
    cmd->promiscuous_flags = (unsigned int )cmd->promiscuous_flags & 65531U;
  }
  cmd->valid_flags = 4U;
  cmd->seid = seid;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_get_vsi_params(struct i40e_hw *hw , struct i40e_vsi_context *vsi_ctx ,
                                   struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_add_get_update_vsi *cmd ;
  struct i40e_aqc_add_get_update_vsi_completion *resp ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_add_get_update_vsi *)(& desc.params.raw);
  resp = (struct i40e_aqc_add_get_update_vsi_completion *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 530);
  cmd->uplink_seid = vsi_ctx->seid;
  desc.flags = (__le16 )((unsigned int )desc.flags | 4096U);
  status = i40e_asq_send_command(hw, & desc, (void *)(& vsi_ctx->info), 128, (struct i40e_asq_cmd_details *)0);
  if ((int )status != 0) {
    goto aq_get_vsi_params_exit;
  } else {

  }
  vsi_ctx->seid = resp->seid;
  vsi_ctx->vsi_number = resp->vsi_number;
  vsi_ctx->vsis_allocated = resp->vsi_used;
  vsi_ctx->vsis_unallocated = resp->vsi_free;
  aq_get_vsi_params_exit: ;
  return (status);
}
}
i40e_status i40e_aq_update_vsi_params(struct i40e_hw *hw , struct i40e_vsi_context *vsi_ctx ,
                                      struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_add_get_update_vsi *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_add_get_update_vsi *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 529);
  cmd->uplink_seid = vsi_ctx->seid;
  desc.flags = (__le16 )((unsigned int )desc.flags | 5120U);
  status = i40e_asq_send_command(hw, & desc, (void *)(& vsi_ctx->info), 128, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_get_switch_config(struct i40e_hw *hw , struct i40e_aqc_get_switch_config_resp *buf ,
                                      u16 buf_size , u16 *start_seid , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_switch_seid *scfg ;
  i40e_status status ;

  {
  scfg = (struct i40e_aqc_switch_seid *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 512);
  desc.flags = (__le16 )((unsigned int )desc.flags | 4096U);
  if ((unsigned int )buf_size > 512U) {
    desc.flags = (__le16 )((unsigned int )desc.flags | 512U);
  } else {

  }
  scfg->seid = *start_seid;
  status = i40e_asq_send_command(hw, & desc, (void *)buf, (int )buf_size, cmd_details);
  *start_seid = scfg->seid;
  return (status);
}
}
i40e_status i40e_aq_get_firmware_version(struct i40e_hw *hw , u16 *fw_major_version ,
                                         u16 *fw_minor_version , u32 *fw_build , u16 *api_major_version ,
                                         u16 *api_minor_version , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_get_version *resp ;
  i40e_status status ;

  {
  resp = (struct i40e_aqc_get_version *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 1);
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  if ((int )status == 0) {
    if ((unsigned long )fw_major_version != (unsigned long )((u16 *)0U)) {
      *fw_major_version = resp->fw_major;
    } else {

    }
    if ((unsigned long )fw_minor_version != (unsigned long )((u16 *)0U)) {
      *fw_minor_version = resp->fw_minor;
    } else {

    }
    if ((unsigned long )fw_build != (unsigned long )((u32 *)0U)) {
      *fw_build = resp->fw_build;
    } else {

    }
    if ((unsigned long )api_major_version != (unsigned long )((u16 *)0U)) {
      *api_major_version = resp->api_major;
    } else {

    }
    if ((unsigned long )api_minor_version != (unsigned long )((u16 *)0U)) {
      *api_minor_version = resp->api_minor;
    } else {

    }
  } else {

  }
  return (status);
}
}
i40e_status i40e_aq_send_driver_version(struct i40e_hw *hw , struct i40e_driver_version *dv ,
                                        struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_driver_version *cmd ;
  i40e_status status ;
  u16 len ;

  {
  cmd = (struct i40e_aqc_driver_version *)(& desc.params.raw);
  if ((unsigned long )dv == (unsigned long )((struct i40e_driver_version *)0)) {
    return (-5);
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, 2);
  desc.flags = (__le16 )((unsigned int )desc.flags | 5120U);
  cmd->driver_major_ver = dv->major_version;
  cmd->driver_minor_ver = dv->minor_version;
  cmd->driver_build_ver = dv->build_version;
  cmd->driver_subbuild_ver = dv->subbuild_version;
  len = 0U;
  goto ldv_52941;
  ldv_52940: 
  len = (u16 )((int )len + 1);
  ldv_52941: ;
  if (((unsigned int )len <= 31U && (int )((signed char )dv->driver_string[(int )len]) >= 0) && (unsigned int )dv->driver_string[(int )len] != 0U) {
    goto ldv_52940;
  } else {

  }
  status = i40e_asq_send_command(hw, & desc, (void *)(& dv->driver_string), (int )len,
                                 cmd_details);
  return (status);
}
}
bool i40e_get_link_status(struct i40e_hw *hw ) 
{ 
  i40e_status status ;
  bool link_status ;

  {
  status = 0;
  link_status = 0;
  if ((int )hw->phy.get_link_info) {
    status = i40e_aq_get_link_info(hw, 1, (struct i40e_link_status *)0, (struct i40e_asq_cmd_details *)0);
    if ((int )status != 0) {
      goto i40e_get_link_status_exit;
    } else {

    }
  } else {

  }
  link_status = ((int )hw->phy.link_info.link_info & 1) != 0;
  i40e_get_link_status_exit: ;
  return (link_status);
}
}
i40e_status i40e_aq_add_veb(struct i40e_hw *hw , u16 uplink_seid , u16 downlink_seid ,
                            u8 enabled_tc , bool default_port , bool enable_l2_filtering ,
                            u16 *veb_seid , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_add_veb *cmd ;
  struct i40e_aqc_add_veb_completion *resp ;
  i40e_status status ;
  u16 veb_flags ;

  {
  cmd = (struct i40e_aqc_add_veb *)(& desc.params.raw);
  resp = (struct i40e_aqc_add_veb_completion *)(& desc.params.raw);
  veb_flags = 0U;
  if (((unsigned int )uplink_seid != 0U) ^ ((unsigned int )downlink_seid != 0U)) {
    return (-5);
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, 560);
  cmd->uplink_seid = uplink_seid;
  cmd->downlink_seid = downlink_seid;
  cmd->enable_tcs = enabled_tc;
  if ((unsigned int )uplink_seid == 0U) {
    veb_flags = (u16 )((unsigned int )veb_flags | 1U);
  } else {

  }
  if ((int )default_port) {
    veb_flags = (u16 )((unsigned int )veb_flags | 2U);
  } else {
    veb_flags = (u16 )((unsigned int )veb_flags | 4U);
  }
  if ((int )enable_l2_filtering) {
    veb_flags = (u16 )((unsigned int )veb_flags | 8U);
  } else {

  }
  cmd->veb_flags = veb_flags;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  if ((int )status == 0 && (unsigned long )veb_seid != (unsigned long )((u16 *)0U)) {
    *veb_seid = resp->veb_seid;
  } else {

  }
  return (status);
}
}
i40e_status i40e_aq_get_veb_parameters(struct i40e_hw *hw , u16 veb_seid , u16 *switch_id ,
                                       bool *floating , u16 *statistic_index , u16 *vebs_used ,
                                       u16 *vebs_free , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_get_veb_parameters_completion *cmd_resp ;
  i40e_status status ;
  u16 flags ;

  {
  cmd_resp = (struct i40e_aqc_get_veb_parameters_completion *)(& desc.params.raw);
  if ((unsigned int )veb_seid == 0U) {
    return (-5);
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, 562);
  cmd_resp->seid = veb_seid;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  if ((int )status != 0) {
    goto get_veb_exit;
  } else {

  }
  if ((unsigned long )switch_id != (unsigned long )((u16 *)0U)) {
    *switch_id = cmd_resp->switch_id;
  } else {

  }
  if ((unsigned long )statistic_index != (unsigned long )((u16 *)0U)) {
    *statistic_index = cmd_resp->statistic_index;
  } else {

  }
  if ((unsigned long )vebs_used != (unsigned long )((u16 *)0U)) {
    *vebs_used = cmd_resp->vebs_used;
  } else {

  }
  if ((unsigned long )vebs_free != (unsigned long )((u16 *)0U)) {
    *vebs_free = cmd_resp->vebs_free;
  } else {

  }
  if ((unsigned long )floating != (unsigned long )((bool *)0)) {
    flags = cmd_resp->veb_flags;
    if ((int )flags & 1) {
      *floating = 1;
    } else {
      *floating = 0;
    }
  } else {

  }
  get_veb_exit: ;
  return (status);
}
}
i40e_status i40e_aq_add_macvlan(struct i40e_hw *hw , u16 seid , struct i40e_aqc_add_macvlan_element_data *mv_list ,
                                u16 count , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_macvlan *cmd ;
  i40e_status status ;
  u16 buf_size ;

  {
  cmd = (struct i40e_aqc_macvlan *)(& desc.params.raw);
  if (((unsigned int )count == 0U || (unsigned long )mv_list == (unsigned long )((struct i40e_aqc_add_macvlan_element_data *)0)) || (unsigned long )hw == (unsigned long )((struct i40e_hw *)0)) {
    return (-5);
  } else {

  }
  buf_size = (unsigned int )count * 16U;
  i40e_fill_default_direct_cmd_desc(& desc, 592);
  cmd->num_addresses = count;
  cmd->seid[0] = (unsigned int )seid | 32768U;
  cmd->seid[1] = 0U;
  cmd->seid[2] = 0U;
  desc.flags = (__le16 )((unsigned int )desc.flags | 5120U);
  if ((unsigned int )buf_size > 512U) {
    desc.flags = (__le16 )((unsigned int )desc.flags | 512U);
  } else {

  }
  status = i40e_asq_send_command(hw, & desc, (void *)mv_list, (int )buf_size, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_remove_macvlan(struct i40e_hw *hw , u16 seid , struct i40e_aqc_remove_macvlan_element_data *mv_list ,
                                   u16 count , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_macvlan *cmd ;
  i40e_status status ;
  u16 buf_size ;

  {
  cmd = (struct i40e_aqc_macvlan *)(& desc.params.raw);
  if (((unsigned int )count == 0U || (unsigned long )mv_list == (unsigned long )((struct i40e_aqc_remove_macvlan_element_data *)0)) || (unsigned long )hw == (unsigned long )((struct i40e_hw *)0)) {
    return (-5);
  } else {

  }
  buf_size = (unsigned int )count * 16U;
  i40e_fill_default_direct_cmd_desc(& desc, 593);
  cmd->num_addresses = count;
  cmd->seid[0] = (unsigned int )seid | 32768U;
  cmd->seid[1] = 0U;
  cmd->seid[2] = 0U;
  desc.flags = (__le16 )((unsigned int )desc.flags | 5120U);
  if ((unsigned int )buf_size > 512U) {
    desc.flags = (__le16 )((unsigned int )desc.flags | 512U);
  } else {

  }
  status = i40e_asq_send_command(hw, & desc, (void *)mv_list, (int )buf_size, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_send_msg_to_vf(struct i40e_hw *hw , u16 vfid , u32 v_opcode ,
                                   u32 v_retval , u8 *msg , u16 msglen , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_pf_vf_message *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_pf_vf_message *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 2050);
  cmd->id = (unsigned int )vfid;
  desc.cookie_high = v_opcode;
  desc.cookie_low = v_retval;
  desc.flags = (__le16 )((unsigned int )desc.flags | 8192U);
  if ((unsigned int )msglen != 0U) {
    desc.flags = (__le16 )((unsigned int )desc.flags | 5120U);
    if ((unsigned int )msglen > 512U) {
      desc.flags = (__le16 )((unsigned int )desc.flags | 512U);
    } else {

    }
    desc.datalen = msglen;
  } else {

  }
  status = i40e_asq_send_command(hw, & desc, (void *)msg, (int )msglen, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_debug_read_register(struct i40e_hw *hw , u32 reg_addr , u64 *reg_val ,
                                        struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_debug_reg_read_write *cmd_resp ;
  i40e_status status ;

  {
  cmd_resp = (struct i40e_aqc_debug_reg_read_write *)(& desc.params.raw);
  if ((unsigned long )reg_val == (unsigned long )((u64 *)0ULL)) {
    return (-5);
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, 65283);
  cmd_resp->address = reg_addr;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  if ((int )status == 0) {
    *reg_val = ((unsigned long long )cmd_resp->value_high << 32) | (unsigned long long )cmd_resp->value_low;
  } else {

  }
  return (status);
}
}
i40e_status i40e_aq_debug_write_register(struct i40e_hw *hw , u32 reg_addr , u64 reg_val ,
                                         struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_debug_reg_read_write *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_debug_reg_read_write *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 65284);
  cmd->address = reg_addr;
  cmd->value_high = (unsigned int )(reg_val >> 32);
  cmd->value_low = (unsigned int )reg_val;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_set_hmc_resource_profile(struct i40e_hw *hw , enum i40e_aq_hmc_profile profile ,
                                             u8 pe_vf_enabled_count , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aq_get_set_hmc_resource_profile *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aq_get_set_hmc_resource_profile *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 1281);
  cmd->pm_profile = (unsigned char )profile;
  cmd->pe_vf_enabled = pe_vf_enabled_count;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_request_resource(struct i40e_hw *hw , enum i40e_aq_resources_ids resource ,
                                     enum i40e_aq_resource_access_type access , u8 sdp_number ,
                                     u64 *timeout , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_request_resource *cmd_resp ;
  i40e_status status ;

  {
  cmd_resp = (struct i40e_aqc_request_resource *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 8);
  cmd_resp->resource_id = (unsigned short )resource;
  cmd_resp->access_type = (unsigned short )access;
  cmd_resp->resource_number = (unsigned int )sdp_number;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  if ((int )status == 0 || (unsigned int )hw->aq.asq_last_status == 12U) {
    *timeout = (u64 )cmd_resp->timeout;
  } else {

  }
  return (status);
}
}
i40e_status i40e_aq_release_resource(struct i40e_hw *hw , enum i40e_aq_resources_ids resource ,
                                     u8 sdp_number , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_request_resource *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_request_resource *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 9);
  cmd->resource_id = (unsigned short )resource;
  cmd->resource_number = (unsigned int )sdp_number;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_read_nvm(struct i40e_hw *hw , u8 module_pointer , u32 offset ,
                             u16 length , void *data , bool last_command , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_nvm_update *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_nvm_update *)(& desc.params.raw);
  if ((offset & 4278190080U) != 0U) {
    status = -5;
    goto i40e_aq_read_nvm_exit;
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, 1793);
  if ((int )last_command) {
    cmd->command_flags = (u8 )((unsigned int )cmd->command_flags | 1U);
  } else {

  }
  cmd->module_pointer = module_pointer;
  cmd->offset = offset;
  cmd->length = length;
  desc.flags = (__le16 )((unsigned int )desc.flags | 4096U);
  if ((unsigned int )length > 512U) {
    desc.flags = (__le16 )((unsigned int )desc.flags | 512U);
  } else {

  }
  status = i40e_asq_send_command(hw, & desc, data, (int )length, cmd_details);
  i40e_aq_read_nvm_exit: ;
  return (status);
}
}
i40e_status i40e_aq_erase_nvm(struct i40e_hw *hw , u8 module_pointer , u32 offset ,
                              u16 length , bool last_command , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_nvm_update *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_nvm_update *)(& desc.params.raw);
  if ((offset & 4278190080U) != 0U) {
    status = -5;
    goto i40e_aq_erase_nvm_exit;
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, 1794);
  if ((int )last_command) {
    cmd->command_flags = (u8 )((unsigned int )cmd->command_flags | 1U);
  } else {

  }
  cmd->module_pointer = module_pointer;
  cmd->offset = offset;
  cmd->length = length;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  i40e_aq_erase_nvm_exit: ;
  return (status);
}
}
static void i40e_parse_discover_capabilities(struct i40e_hw *hw , void *buff , u32 cap_count ,
                                             enum i40e_admin_queue_opc list_type_opc ) 
{ 
  struct i40e_aqc_list_capabilities_element_resp *cap ;
  u32 valid_functions ;
  u32 num_functions ;
  u32 number ;
  u32 logical_id ;
  u32 phys_id ;
  struct i40e_hw_capabilities *p ;
  u32 i ;
  u16 id ;
  u32 port_cfg_reg ;
  u64 port_cfg ;

  {
  i = 0U;
  cap = (struct i40e_aqc_list_capabilities_element_resp *)buff;
  if ((unsigned int )list_type_opc == 11U) {
    p = & hw->dev_caps;
  } else
  if ((unsigned int )list_type_opc == 10U) {
    p = & hw->func_caps;
  } else {
    return;
  }
  i = 0U;
  goto ldv_53131;
  ldv_53130: 
  id = cap->id;
  number = cap->number;
  logical_id = cap->logical_id;
  phys_id = cap->phys_id;
  switch ((int )id) {
  case 1: 
  p->switch_mode = number;
  goto ldv_53101;
  case 2: 
  p->management_mode = number;
  goto ldv_53101;
  case 3: 
  p->npar_enable = number;
  goto ldv_53101;
  case 4: 
  p->os2bmc = number;
  goto ldv_53101;
  case 5: 
  p->valid_functions = number;
  goto ldv_53101;
  case 18: ;
  if (number == 1U) {
    p->sr_iov_1_1 = 1;
  } else {

  }
  goto ldv_53101;
  case 19: 
  p->num_vfs = number;
  p->vf_base_id = logical_id;
  goto ldv_53101;
  case 20: ;
  if (number == 1U) {
    p->vmdq = 1;
  } else {

  }
  goto ldv_53101;
  case 21: ;
  if (number == 1U) {
    p->evb_802_1_qbg = 1;
  } else {

  }
  goto ldv_53101;
  case 22: ;
  if (number == 1U) {
    p->evb_802_1_qbh = 1;
  } else {

  }
  goto ldv_53101;
  case 23: 
  p->num_vsis = number;
  goto ldv_53101;
  case 24: ;
  if (number == 1U) {
    p->dcb = 1;
    p->enabled_tcmap = logical_id;
    p->maxtc = phys_id;
  } else {

  }
  goto ldv_53101;
  case 33: ;
  if (number == 1U) {
    p->fcoe = 1;
  } else {

  }
  goto ldv_53101;
  case 34: ;
  if (number == 1U) {
    p->iscsi = 1;
  } else {

  }
  goto ldv_53101;
  case 64: 
  p->rss = 1;
  p->rss_table_size = number;
  p->rss_table_entry_width = logical_id;
  goto ldv_53101;
  case 65: 
  p->num_rx_qp = number;
  p->base_queue = phys_id;
  goto ldv_53101;
  case 66: 
  p->num_tx_qp = number;
  p->base_queue = phys_id;
  goto ldv_53101;
  case 67: 
  p->num_msix_vectors = number;
  goto ldv_53101;
  case 68: 
  p->num_msix_vectors_vf = number;
  goto ldv_53101;
  case 241: ;
  if (number == 1U) {
    p->mfp_mode_1 = 1;
  } else {

  }
  goto ldv_53101;
  case 242: ;
  if (number == 1U) {
    p->mgmt_cem = 1;
  } else {

  }
  goto ldv_53101;
  case 81: ;
  if (number == 1U) {
    p->iwarp = 1;
  } else {

  }
  goto ldv_53101;
  case 97: ;
  if (phys_id <= 29U) {
    p->led[phys_id] = 1;
  } else {

  }
  goto ldv_53101;
  case 98: ;
  if (phys_id <= 29U) {
    p->sdp[phys_id] = 1;
  } else {

  }
  goto ldv_53101;
  case 99: ;
  if (number == 1U) {
    p->mdio_port_num = phys_id;
    p->mdio_port_mode = logical_id;
  } else {

  }
  goto ldv_53101;
  case 70: ;
  if (number == 1U) {
    p->ieee_1588 = 1;
  } else {

  }
  goto ldv_53101;
  case 69: 
  p->fd = 1;
  p->fd_filters_guaranteed = number;
  p->fd_filters_best_effort = logical_id;
  goto ldv_53101;
  case 100: 
  p->wr_csr_prot = (unsigned long long )number;
  p->wr_csr_prot = p->wr_csr_prot | ((unsigned long long )logical_id << 32);
  goto ldv_53101;
  default: ;
  goto ldv_53101;
  }
  ldv_53101: 
  i = i + 1U;
  cap = cap + 1;
  ldv_53131: ;
  if (i < cap_count) {
    goto ldv_53130;
  } else {

  }

  if ((int )p->fcoe) {
    if (hw->debug_mask != 0U) {
      printk("\016i40e %02x.%x device is FCoE capable\n", (int )hw->bus.device, (int )hw->bus.func);
    } else {

    }
  } else {

  }
  if (p->npar_enable != 0U || (int )p->mfp_mode_1) {
    p->fcoe = 0;
  } else {

  }
  hw->num_ports = 0U;
  i = 0U;
  goto ldv_53136;
  ldv_53135: 
  port_cfg_reg = (i + 188488U) * 4U;
  port_cfg = 0ULL;
  i40e_aq_debug_read_register(hw, port_cfg_reg, & port_cfg, (struct i40e_asq_cmd_details *)0);
  if ((port_cfg & 1ULL) == 0ULL) {
    hw->num_ports = (u16 )((int )hw->num_ports + 1);
  } else {

  }
  i = i + 1U;
  ldv_53136: ;
  if (i <= 3U) {
    goto ldv_53135;
  } else {

  }
  valid_functions = p->valid_functions;
  num_functions = 0U;
  goto ldv_53139;
  ldv_53138: ;
  if ((int )valid_functions & 1) {
    num_functions = num_functions + 1U;
  } else {

  }
  valid_functions = valid_functions >> 1;
  ldv_53139: ;
  if (valid_functions != 0U) {
    goto ldv_53138;
  } else {

  }
  hw->partition_id = (unsigned int )((u16 )((int )hw->pf_id / (int )hw->num_ports)) + 1U;
  hw->num_partitions = (u16 )(num_functions / (u32 )hw->num_ports);
  p->rx_buf_chain_len = 5U;
  return;
}
}
i40e_status i40e_aq_discover_capabilities(struct i40e_hw *hw , void *buff , u16 buff_size ,
                                          u16 *data_size , enum i40e_admin_queue_opc list_type_opc ,
                                          struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aqc_list_capabilites *cmd ;
  struct i40e_aq_desc desc ;
  i40e_status status ;

  {
  status = 0;
  cmd = (struct i40e_aqc_list_capabilites *)(& desc.params.raw);
  if ((unsigned int )list_type_opc != 10U && (unsigned int )list_type_opc != 11U) {
    status = -5;
    goto exit;
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, (int )((u16 )list_type_opc));
  desc.flags = (__le16 )((unsigned int )desc.flags | 4096U);
  if ((unsigned int )buff_size > 512U) {
    desc.flags = (__le16 )((unsigned int )desc.flags | 512U);
  } else {

  }
  status = i40e_asq_send_command(hw, & desc, buff, (int )buff_size, cmd_details);
  *data_size = desc.datalen;
  if ((int )status != 0) {
    goto exit;
  } else {

  }
  i40e_parse_discover_capabilities(hw, buff, cmd->count, list_type_opc);
  exit: ;
  return (status);
}
}
i40e_status i40e_aq_update_nvm(struct i40e_hw *hw , u8 module_pointer , u32 offset ,
                               u16 length , void *data , bool last_command , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_nvm_update *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_nvm_update *)(& desc.params.raw);
  if ((offset & 4278190080U) != 0U) {
    status = -5;
    goto i40e_aq_update_nvm_exit;
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, 1795);
  if ((int )last_command) {
    cmd->command_flags = (u8 )((unsigned int )cmd->command_flags | 1U);
  } else {

  }
  cmd->module_pointer = module_pointer;
  cmd->offset = offset;
  cmd->length = length;
  desc.flags = (__le16 )((unsigned int )desc.flags | 5120U);
  if ((unsigned int )length > 512U) {
    desc.flags = (__le16 )((unsigned int )desc.flags | 512U);
  } else {

  }
  status = i40e_asq_send_command(hw, & desc, data, (int )length, cmd_details);
  i40e_aq_update_nvm_exit: ;
  return (status);
}
}
i40e_status i40e_aq_get_lldp_mib(struct i40e_hw *hw , u8 bridge_type , u8 mib_type ,
                                 void *buff , u16 buff_size , u16 *local_len , u16 *remote_len ,
                                 struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_lldp_get_mib *cmd ;
  struct i40e_aqc_lldp_get_mib *resp ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_lldp_get_mib *)(& desc.params.raw);
  resp = (struct i40e_aqc_lldp_get_mib *)(& desc.params.raw);
  if ((unsigned int )buff_size == 0U || (unsigned long )buff == (unsigned long )((void *)0)) {
    return (-5);
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, 2560);
  desc.flags = (__le16 )((unsigned int )desc.flags | 4096U);
  cmd->type = (unsigned int )mib_type & 3U;
  cmd->type = (u8 )((int )((signed char )cmd->type) | ((int )((signed char )((int )bridge_type << 2)) & 12));
  desc.datalen = buff_size;
  desc.flags = (__le16 )((unsigned int )desc.flags | 4096U);
  if ((unsigned int )buff_size > 512U) {
    desc.flags = (__le16 )((unsigned int )desc.flags | 512U);
  } else {

  }
  status = i40e_asq_send_command(hw, & desc, buff, (int )buff_size, cmd_details);
  if ((int )status == 0) {
    if ((unsigned long )local_len != (unsigned long )((u16 *)0U)) {
      *local_len = resp->local_len;
    } else {

    }
    if ((unsigned long )remote_len != (unsigned long )((u16 *)0U)) {
      *remote_len = resp->remote_len;
    } else {

    }
  } else {

  }
  return (status);
}
}
i40e_status i40e_aq_cfg_lldp_mib_change_event(struct i40e_hw *hw , bool enable_update ,
                                              struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_lldp_update_mib *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_lldp_update_mib *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 2561);
  if (! enable_update) {
    cmd->command = (u8 )((unsigned int )cmd->command | 1U);
  } else {

  }
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_stop_lldp(struct i40e_hw *hw , bool shutdown_agent , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_lldp_stop *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_lldp_stop *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 2565);
  if ((int )shutdown_agent) {
    cmd->command = (u8 )((unsigned int )cmd->command | 1U);
  } else {

  }
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_start_lldp(struct i40e_hw *hw , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_lldp_start *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_lldp_start *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 2566);
  cmd->command = 1U;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_get_cee_dcb_config(struct i40e_hw *hw , void *buff , u16 buff_size ,
                                       struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  i40e_status status ;

  {
  if ((unsigned int )buff_size == 0U || (unsigned long )buff == (unsigned long )((void *)0)) {
    return (-5);
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, 2567);
  desc.flags = (__le16 )((unsigned int )desc.flags | 4096U);
  status = i40e_asq_send_command(hw, & desc, buff, (int )buff_size, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_add_udp_tunnel(struct i40e_hw *hw , u16 udp_port , u8 protocol_index ,
                                   u8 *filter_index , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_add_udp_tunnel *cmd ;
  struct i40e_aqc_del_udp_tunnel_completion *resp ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_add_udp_tunnel *)(& desc.params.raw);
  resp = (struct i40e_aqc_del_udp_tunnel_completion *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 2816);
  cmd->udp_port = udp_port;
  cmd->protocol_type = protocol_index;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  if ((int )status == 0 && (unsigned long )filter_index != (unsigned long )((u8 *)0U)) {
    *filter_index = resp->index;
  } else {

  }
  return (status);
}
}
i40e_status i40e_aq_del_udp_tunnel(struct i40e_hw *hw , u8 index , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_remove_udp_tunnel *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_remove_udp_tunnel *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 2817);
  cmd->index = index;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_delete_element(struct i40e_hw *hw , u16 seid , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_switch_seid *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_switch_seid *)(& desc.params.raw);
  if ((unsigned int )seid == 0U) {
    return (-5);
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, 579);
  cmd->seid = seid;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_dcb_updated(struct i40e_hw *hw , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  i40e_status status ;

  {
  i40e_fill_default_direct_cmd_desc(& desc, 770);
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
static i40e_status i40e_aq_tx_sched_cmd(struct i40e_hw *hw , u16 seid , void *buff ,
                                        u16 buff_size , enum i40e_admin_queue_opc opcode ,
                                        struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_tx_sched_ind *cmd ;
  i40e_status status ;
  bool cmd_param_flag ;

  {
  cmd = (struct i40e_aqc_tx_sched_ind *)(& desc.params.raw);
  cmd_param_flag = 0;
  switch ((unsigned int )opcode) {
  case 1030U: ;
  case 1031U: ;
  case 1043U: ;
  case 1044U: ;
  case 1045U: ;
  case 1046U: ;
  case 1047U: 
  cmd_param_flag = 1;
  goto ldv_53263;
  case 1032U: ;
  case 1034U: ;
  case 1048U: ;
  case 1049U: ;
  case 1050U: 
  cmd_param_flag = 0;
  goto ldv_53263;
  default: ;
  return (-5);
  }
  ldv_53263: 
  i40e_fill_default_direct_cmd_desc(& desc, (int )((u16 )opcode));
  desc.flags = (__le16 )((unsigned int )desc.flags | 4096U);
  if ((int )cmd_param_flag) {
    desc.flags = (__le16 )((unsigned int )desc.flags | 1024U);
  } else {

  }
  if ((unsigned int )buff_size > 512U) {
    desc.flags = (__le16 )((unsigned int )desc.flags | 512U);
  } else {

  }
  desc.datalen = buff_size;
  cmd->vsi_seid = seid;
  status = i40e_asq_send_command(hw, & desc, buff, (int )buff_size, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_config_vsi_bw_limit(struct i40e_hw *hw , u16 seid , u16 credit ,
                                        u8 max_credit , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_configure_vsi_bw_limit *cmd ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_configure_vsi_bw_limit *)(& desc.params.raw);
  i40e_fill_default_direct_cmd_desc(& desc, 1024);
  cmd->vsi_seid = seid;
  cmd->credit = credit;
  cmd->max_credit = max_credit;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
i40e_status i40e_aq_config_vsi_tc_bw(struct i40e_hw *hw , u16 seid , struct i40e_aqc_configure_vsi_tc_bw_data *bw_data ,
                                     struct i40e_asq_cmd_details *cmd_details ) 
{ 
  i40e_status tmp ;

  {
  tmp = i40e_aq_tx_sched_cmd(hw, (int )seid, (void *)bw_data, 32, 1031, cmd_details);
  return (tmp);
}
}
i40e_status i40e_aq_config_switch_comp_ets(struct i40e_hw *hw , u16 seid , struct i40e_aqc_configure_switching_comp_ets_data *ets_data ,
                                           enum i40e_admin_queue_opc opcode , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  i40e_status tmp ;

  {
  tmp = i40e_aq_tx_sched_cmd(hw, (int )seid, (void *)ets_data, 128, opcode, cmd_details);
  return (tmp);
}
}
i40e_status i40e_aq_config_switch_comp_bw_config(struct i40e_hw *hw , u16 seid , struct i40e_aqc_configure_switching_comp_bw_config_data *bw_data ,
                                                 struct i40e_asq_cmd_details *cmd_details ) 
{ 
  i40e_status tmp ;

  {
  tmp = i40e_aq_tx_sched_cmd(hw, (int )seid, (void *)bw_data, 32, 1047, cmd_details);
  return (tmp);
}
}
i40e_status i40e_aq_query_vsi_bw_config(struct i40e_hw *hw , u16 seid , struct i40e_aqc_query_vsi_bw_config_resp *bw_data ,
                                        struct i40e_asq_cmd_details *cmd_details ) 
{ 
  i40e_status tmp ;

  {
  tmp = i40e_aq_tx_sched_cmd(hw, (int )seid, (void *)bw_data, 64, 1032, cmd_details);
  return (tmp);
}
}
i40e_status i40e_aq_query_vsi_ets_sla_config(struct i40e_hw *hw , u16 seid , struct i40e_aqc_query_vsi_ets_sla_config_resp *bw_data ,
                                             struct i40e_asq_cmd_details *cmd_details ) 
{ 
  i40e_status tmp ;

  {
  tmp = i40e_aq_tx_sched_cmd(hw, (int )seid, (void *)bw_data, 32, 1034, cmd_details);
  return (tmp);
}
}
i40e_status i40e_aq_query_switch_comp_ets_config(struct i40e_hw *hw , u16 seid , struct i40e_aqc_query_switching_comp_ets_config_resp *bw_data ,
                                                 struct i40e_asq_cmd_details *cmd_details ) 
{ 
  i40e_status tmp ;

  {
  tmp = i40e_aq_tx_sched_cmd(hw, (int )seid, (void *)bw_data, 64, 1048, cmd_details);
  return (tmp);
}
}
i40e_status i40e_aq_query_port_ets_config(struct i40e_hw *hw , u16 seid , struct i40e_aqc_query_port_ets_config_resp *bw_data ,
                                          struct i40e_asq_cmd_details *cmd_details ) 
{ 
  i40e_status tmp ;

  {
  tmp = i40e_aq_tx_sched_cmd(hw, (int )seid, (void *)bw_data, 68, 1049, cmd_details);
  return (tmp);
}
}
i40e_status i40e_aq_query_switch_comp_bw_config(struct i40e_hw *hw , u16 seid , struct i40e_aqc_query_switching_comp_bw_config_resp *bw_data ,
                                                struct i40e_asq_cmd_details *cmd_details ) 
{ 
  i40e_status tmp ;

  {
  tmp = i40e_aq_tx_sched_cmd(hw, (int )seid, (void *)bw_data, 32, 1050, cmd_details);
  return (tmp);
}
}
static i40e_status i40e_validate_filter_settings(struct i40e_hw *hw , struct i40e_filter_control_settings *settings ) 
{ 
  u32 fcoe_cntx_size ;
  u32 fcoe_filt_size ;
  u32 pe_cntx_size ;
  u32 pe_filt_size ;
  u32 fcoe_fmax ;
  u32 val ;

  {
  switch ((unsigned int )settings->fcoe_filt_num) {
  case 0U: ;
  case 1U: ;
  case 2U: ;
  case 3U: ;
  case 4U: ;
  case 5U: 
  fcoe_filt_size = 1024U;
  fcoe_filt_size = fcoe_filt_size << (int )settings->fcoe_filt_num;
  goto ldv_53345;
  default: ;
  return (-5);
  }
  ldv_53345: ;
  switch ((unsigned int )settings->fcoe_cntx_num) {
  case 0U: ;
  case 1U: ;
  case 2U: ;
  case 3U: 
  fcoe_cntx_size = 512U;
  fcoe_cntx_size = fcoe_cntx_size << (int )settings->fcoe_cntx_num;
  goto ldv_53351;
  default: ;
  return (-5);
  }
  ldv_53351: ;
  switch ((unsigned int )settings->pe_filt_num) {
  case 0U: ;
  case 1U: ;
  case 2U: ;
  case 3U: ;
  case 4U: ;
  case 5U: ;
  case 6U: ;
  case 7U: ;
  case 8U: ;
  case 9U: ;
  case 10U: 
  pe_filt_size = 1024U;
  pe_filt_size = pe_filt_size << (int )settings->pe_filt_num;
  goto ldv_53364;
  default: ;
  return (-5);
  }
  ldv_53364: ;
  switch ((unsigned int )settings->pe_cntx_num) {
  case 0U: ;
  case 1U: ;
  case 2U: ;
  case 3U: ;
  case 4U: ;
  case 5U: ;
  case 6U: ;
  case 7U: ;
  case 8U: ;
  case 9U: 
  pe_cntx_size = 512U;
  pe_cntx_size = pe_cntx_size << (int )settings->pe_cntx_num;
  goto ldv_53376;
  default: ;
  return (-5);
  }
  ldv_53376: 
  val = readl((void const volatile   *)hw->hw_addr + 794832U);
  fcoe_fmax = val & 65535U;
  if (fcoe_filt_size + fcoe_cntx_size > fcoe_fmax) {
    return (-26);
  } else {

  }
  return (0);
}
}
i40e_status i40e_set_filter_control(struct i40e_hw *hw , struct i40e_filter_control_settings *settings ) 
{ 
  i40e_status ret ;
  u32 hash_lut_size ;
  u32 val ;

  {
  ret = 0;
  hash_lut_size = 0U;
  if ((unsigned long )settings == (unsigned long )((struct i40e_filter_control_settings *)0)) {
    return (-5);
  } else {

  }
  ret = i40e_validate_filter_settings(hw, settings);
  if ((int )ret != 0) {
    return (ret);
  } else {

  }
  val = readl((void const volatile   *)hw->hw_addr + 1837760U);
  val = val & 4294967264U;
  val = ((u32 )settings->pe_filt_num & 31U) | val;
  val = val & 4294966303U;
  val = (((unsigned int )settings->pe_cntx_num << 5) & 992U) | val;
  val = val & 4294951935U;
  val = (((unsigned int )settings->fcoe_filt_num << 10) & 15360U) | val;
  val = val & 4294918143U;
  val = (((unsigned int )settings->fcoe_cntx_num << 14) & 65535U) | val;
  val = val & 4294901759U;
  if ((unsigned int )settings->hash_lut_size == 1U) {
    hash_lut_size = 1U;
  } else {

  }
  val = ((hash_lut_size << 16) & 65536U) | val;
  if ((int )settings->enable_fdir) {
    val = val | 131072U;
  } else {

  }
  if ((int )settings->enable_ethtype) {
    val = val | 262144U;
  } else {

  }
  if ((int )settings->enable_macvlan) {
    val = val | 524288U;
  } else {

  }
  writel(val, (void volatile   *)hw->hw_addr + 1837760U);
  return (0);
}
}
i40e_status i40e_aq_add_rem_control_packet_filter(struct i40e_hw *hw , u8 *mac_addr ,
                                                  u16 ethtype , u16 flags , u16 vsi_seid ,
                                                  u16 queue , bool is_add , struct i40e_control_filter_stats *stats ,
                                                  struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_add_remove_control_packet_filter *cmd ;
  struct i40e_aqc_add_remove_control_packet_filter_completion *resp ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_add_remove_control_packet_filter *)(& desc.params.raw);
  resp = (struct i40e_aqc_add_remove_control_packet_filter_completion *)(& desc.params.raw);
  if ((unsigned int )vsi_seid == 0U) {
    return (-5);
  } else {

  }
  if ((int )is_add) {
    i40e_fill_default_direct_cmd_desc(& desc, 602);
    cmd->queue = queue;
  } else {
    i40e_fill_default_direct_cmd_desc(& desc, 603);
  }
  if ((unsigned long )mac_addr != (unsigned long )((u8 *)0U)) {
    memcpy((void *)(& cmd->mac), (void const   *)mac_addr, 6UL);
  } else {

  }
  cmd->etype = ethtype;
  cmd->flags = flags;
  cmd->seid = vsi_seid;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  if ((int )status == 0 && (unsigned long )stats != (unsigned long )((struct i40e_control_filter_stats *)0)) {
    stats->mac_etype_used = resp->mac_etype_used;
    stats->etype_used = resp->etype_used;
    stats->mac_etype_free = resp->mac_etype_free;
    stats->etype_free = resp->etype_free;
  } else {

  }
  return (status);
}
}
static i40e_status i40e_aq_alternate_read(struct i40e_hw *hw , u32 reg_addr0 , u32 *reg_val0 ,
                                          u32 reg_addr1 , u32 *reg_val1 ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_alternate_write *cmd_resp ;
  i40e_status status ;

  {
  cmd_resp = (struct i40e_aqc_alternate_write *)(& desc.params.raw);
  if ((unsigned long )reg_val0 == (unsigned long )((u32 *)0U)) {
    return (-5);
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, 2306);
  cmd_resp->address0 = reg_addr0;
  cmd_resp->address1 = reg_addr1;
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, (struct i40e_asq_cmd_details *)0);
  if ((int )status == 0) {
    *reg_val0 = cmd_resp->data0;
    if ((unsigned long )reg_val1 != (unsigned long )((u32 *)0U)) {
      *reg_val1 = cmd_resp->data1;
    } else {

    }
  } else {

  }
  return (status);
}
}
i40e_status i40e_aq_resume_port_tx(struct i40e_hw *hw , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  i40e_status status ;

  {
  i40e_fill_default_direct_cmd_desc(& desc, 1052);
  status = i40e_asq_send_command(hw, & desc, (void *)0, 0, cmd_details);
  return (status);
}
}
void i40e_set_pci_config_data(struct i40e_hw *hw , u16 link_status ) 
{ 


  {
  hw->bus.type = 3;
  switch ((int )link_status & 1008) {
  case 16: 
  hw->bus.width = 1;
  goto ldv_53421;
  case 32: 
  hw->bus.width = 2;
  goto ldv_53421;
  case 64: 
  hw->bus.width = 4;
  goto ldv_53421;
  case 128: 
  hw->bus.width = 8;
  goto ldv_53421;
  default: 
  hw->bus.width = 0;
  goto ldv_53421;
  }
  ldv_53421: ;
  switch ((int )link_status & 15) {
  case 1: 
  hw->bus.speed = 2500;
  goto ldv_53427;
  case 2: 
  hw->bus.speed = 5000;
  goto ldv_53427;
  case 3: 
  hw->bus.speed = 8000;
  goto ldv_53427;
  default: 
  hw->bus.speed = 0;
  goto ldv_53427;
  }
  ldv_53427: ;
  return;
}
}
i40e_status i40e_aq_debug_dump(struct i40e_hw *hw , u8 cluster_id , u8 table_id ,
                               u32 start_index , u16 buff_size , void *buff , u16 *ret_buff_size ,
                               u8 *ret_next_table , u32 *ret_next_index , struct i40e_asq_cmd_details *cmd_details ) 
{ 
  struct i40e_aq_desc desc ;
  struct i40e_aqc_debug_dump_internals *cmd ;
  struct i40e_aqc_debug_dump_internals *resp ;
  i40e_status status ;

  {
  cmd = (struct i40e_aqc_debug_dump_internals *)(& desc.params.raw);
  resp = (struct i40e_aqc_debug_dump_internals *)(& desc.params.raw);
  if ((unsigned int )buff_size == 0U || (unsigned long )buff == (unsigned long )((void *)0)) {
    return (-5);
  } else {

  }
  i40e_fill_default_direct_cmd_desc(& desc, 65288);
  desc.flags = (__le16 )((unsigned int )desc.flags | 4096U);
  if ((unsigned int )buff_size > 512U) {
    desc.flags = (__le16 )((unsigned int )desc.flags | 512U);
  } else {

  }
  cmd->cluster_id = cluster_id;
  cmd->table_id = table_id;
  cmd->idx = start_index;
  desc.datalen = buff_size;
  status = i40e_asq_send_command(hw, & desc, buff, (int )buff_size, cmd_details);
  if ((int )status == 0) {
    if ((unsigned long )ret_buff_size != (unsigned long )((u16 *)0U)) {
      *ret_buff_size = desc.datalen;
    } else {

    }
    if ((unsigned long )ret_next_table != (unsigned long )((u8 *)0U)) {
      *ret_next_table = resp->table_id;
    } else {

    }
    if ((unsigned long )ret_next_index != (unsigned long )((u32 *)0U)) {
      *ret_next_index = resp->idx;
    } else {

    }
  } else {

  }
  return (status);
}
}
i40e_status i40e_read_bw_from_alt_ram(struct i40e_hw *hw , u32 *max_bw , u32 *min_bw ,
                                      bool *min_valid , bool *max_valid ) 
{ 
  i40e_status status ;
  u32 max_bw_addr ;
  u32 min_bw_addr ;

  {
  max_bw_addr = (u32 )((int )hw->pf_id * 64 + 15);
  min_bw_addr = (u32 )((int )hw->pf_id * 64 + 14);
  status = i40e_aq_alternate_read(hw, max_bw_addr, max_bw, min_bw_addr, min_bw);
  if ((int )*min_bw < 0) {
    *min_valid = 1;
  } else {
    *min_valid = 0;
  }
  if ((int )*max_bw < 0) {
    *max_valid = 1;
  } else {
    *max_valid = 0;
  }
  return (status);
}
}
i40e_status i40e_aq_configure_partition_bw(struct i40e_hw *hw , struct i40e_aqc_configure_partition_bw_data *bw_data ,
                                           struct i40e_asq_cmd_details *cmd_details ) 
{ 
  i40e_status status ;
  struct i40e_aq_desc desc ;
  u16 bwd_size ;

  {
  bwd_size = 34U;
  i40e_fill_default_direct_cmd_desc(& desc, 1053);
  desc.flags = (__le16 )((unsigned int )desc.flags | 4096U);
  desc.flags = (__le16 )((unsigned int )desc.flags | 1024U);
  if ((unsigned int )bwd_size > 512U) {
    desc.flags = (__le16 )((unsigned int )desc.flags | 512U);
  } else {

  }
  desc.datalen = bwd_size;
  status = i40e_asq_send_command(hw, & desc, (void *)bw_data, (int )bwd_size, cmd_details);
  return (status);
}
}
bool ldv_queue_work_on_169(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_170(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_171(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_172(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_173(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_174(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_175(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_176(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_177(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_178(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_179(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_180(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_205(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_203(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_206(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_207(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_202(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_204(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_208(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_197(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_199(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_198(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_201(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_200(struct workqueue_struct *ldv_func_arg1 ) ;
i40e_status i40e_add_sd_table_entry(struct i40e_hw *hw , struct i40e_hmc_info *hmc_info ,
                                    u32 sd_index , enum i40e_sd_entry_type type ,
                                    u64 direct_mode_sz ) ;
i40e_status i40e_add_pd_table_entry(struct i40e_hw *hw , struct i40e_hmc_info *hmc_info ,
                                    u32 pd_index ) ;
i40e_status i40e_remove_pd_bp(struct i40e_hw *hw , struct i40e_hmc_info *hmc_info ,
                              u32 idx ) ;
i40e_status i40e_prep_remove_sd_bp(struct i40e_hmc_info *hmc_info , u32 idx ) ;
i40e_status i40e_remove_sd_bp_new(struct i40e_hw *hw , struct i40e_hmc_info *hmc_info ,
                                  u32 idx , bool is_pf ) ;
i40e_status i40e_prep_remove_pd_page(struct i40e_hmc_info *hmc_info , u32 idx ) ;
i40e_status i40e_remove_pd_page_new(struct i40e_hw *hw , struct i40e_hmc_info *hmc_info ,
                                    u32 idx , bool is_pf ) ;
i40e_status i40e_add_sd_table_entry(struct i40e_hw *hw , struct i40e_hmc_info *hmc_info ,
                                    u32 sd_index , enum i40e_sd_entry_type type ,
                                    u64 direct_mode_sz ) 
{ 
  enum i40e_memory_type mem_type ;
  struct i40e_hmc_sd_entry *sd_entry ;
  bool dma_mem_alloc_done ;
  struct i40e_dma_mem mem ;
  i40e_status ret_code ;
  u64 alloc_len ;

  {
  dma_mem_alloc_done = 0;
  if ((unsigned long )hmc_info->sd_table.sd_entry == (unsigned long )((struct i40e_hmc_sd_entry *)0)) {
    ret_code = -19;
    goto exit;
  } else {

  }
  if (hmc_info->sd_table.sd_cnt <= sd_index) {
    ret_code = -45;
    goto exit;
  } else {

  }
  sd_entry = hmc_info->sd_table.sd_entry + (unsigned long )sd_index;
  if (! sd_entry->valid) {
    if ((unsigned int )type == 1U) {
      mem_type = 5;
      alloc_len = 4096ULL;
    } else {
      mem_type = 7;
      alloc_len = direct_mode_sz;
    }
    ret_code = i40e_allocate_dma_mem_d(hw, & mem, alloc_len, 4096U);
    if ((int )ret_code != 0) {
      goto exit;
    } else {

    }
    dma_mem_alloc_done = 1;
    if ((unsigned int )type == 1U) {
      ret_code = i40e_allocate_virt_mem_d(hw, & sd_entry->u.pd_table.pd_entry_virt_mem,
                                          20480U);
      if ((int )ret_code != 0) {
        goto exit;
      } else {

      }
      sd_entry->u.pd_table.pd_entry = (struct i40e_hmc_pd_entry *)sd_entry->u.pd_table.pd_entry_virt_mem.va;
      sd_entry->u.pd_table.pd_page_addr = mem;
    } else {
      sd_entry->u.bp.addr = mem;
      sd_entry->u.bp.sd_pd_index = sd_index;
    }
    (hmc_info->sd_table.sd_entry + (unsigned long )sd_index)->entry_type = type;
    hmc_info->sd_table.ref_cnt = hmc_info->sd_table.ref_cnt + 1U;
  } else {

  }
  if ((unsigned int )sd_entry->entry_type == 2U) {
    sd_entry->u.bp.ref_cnt = sd_entry->u.bp.ref_cnt + 1U;
  } else {

  }
  exit: ;
  if ((int )ret_code != 0) {
    if ((int )dma_mem_alloc_done) {
      i40e_free_dma_mem_d(hw, & mem);
    } else {

    }
  } else {

  }
  return (ret_code);
}
}
i40e_status i40e_add_pd_table_entry(struct i40e_hw *hw , struct i40e_hmc_info *hmc_info ,
                                    u32 pd_index ) 
{ 
  i40e_status ret_code ;
  struct i40e_hmc_pd_table *pd_table ;
  struct i40e_hmc_pd_entry *pd_entry ;
  struct i40e_dma_mem mem ;
  u32 sd_idx ;
  u32 rel_pd_idx ;
  u64 *pd_addr ;
  u64 page_desc ;

  {
  ret_code = 0;
  if (pd_index / 512U >= hmc_info->sd_table.sd_cnt) {
    ret_code = -46;
    goto exit;
  } else {

  }
  sd_idx = pd_index / 512U;
  if ((unsigned int )(hmc_info->sd_table.sd_entry + (unsigned long )sd_idx)->entry_type != 1U) {
    goto exit;
  } else {

  }
  rel_pd_idx = pd_index & 511U;
  pd_table = & (hmc_info->sd_table.sd_entry + (unsigned long )sd_idx)->u.pd_table;
  pd_entry = pd_table->pd_entry + (unsigned long )rel_pd_idx;
  if (! pd_entry->valid) {
    ret_code = i40e_allocate_dma_mem_d(hw, & mem, 4096ULL, 4096U);
    if ((int )ret_code != 0) {
      goto exit;
    } else {

    }
    pd_entry->bp.addr = mem;
    pd_entry->bp.sd_pd_index = pd_index;
    pd_entry->bp.entry_type = 1;
    page_desc = mem.pa | 1ULL;
    pd_addr = (u64 *)pd_table->pd_page_addr.va;
    pd_addr = pd_addr + (unsigned long )rel_pd_idx;
    memcpy((void *)pd_addr, (void const   *)(& page_desc), 8UL);
    pd_entry->sd_index = sd_idx;
    pd_entry->valid = 1;
    pd_table->ref_cnt = pd_table->ref_cnt + 1U;
  } else {

  }
  pd_entry->bp.ref_cnt = pd_entry->bp.ref_cnt + 1U;
  exit: ;
  return (ret_code);
}
}
i40e_status i40e_remove_pd_bp(struct i40e_hw *hw , struct i40e_hmc_info *hmc_info ,
                              u32 idx ) 
{ 
  i40e_status ret_code ;
  struct i40e_hmc_pd_entry *pd_entry ;
  struct i40e_hmc_pd_table *pd_table ;
  struct i40e_hmc_sd_entry *sd_entry ;
  u32 sd_idx ;
  u32 rel_pd_idx ;
  u64 *pd_addr ;

  {
  ret_code = 0;
  sd_idx = idx / 512U;
  rel_pd_idx = idx & 511U;
  if (hmc_info->sd_table.sd_cnt <= sd_idx) {
    ret_code = -46;
    goto exit;
  } else {

  }
  sd_entry = hmc_info->sd_table.sd_entry + (unsigned long )sd_idx;
  if ((unsigned int )sd_entry->entry_type != 1U) {
    ret_code = -47;
    goto exit;
  } else {

  }
  pd_table = & (hmc_info->sd_table.sd_entry + (unsigned long )sd_idx)->u.pd_table;
  pd_entry = pd_table->pd_entry + (unsigned long )rel_pd_idx;
  pd_entry->bp.ref_cnt = pd_entry->bp.ref_cnt - 1U;
  if (pd_entry->bp.ref_cnt != 0U) {
    goto exit;
  } else {

  }
  pd_entry->valid = 0;
  pd_table->ref_cnt = pd_table->ref_cnt - 1U;
  pd_addr = (u64 *)pd_table->pd_page_addr.va;
  pd_addr = pd_addr + (unsigned long )rel_pd_idx;
  memset((void *)pd_addr, 0, 8UL);
  writel((idx << 16) | sd_idx, (void volatile   *)hw->hw_addr + 787200U);
  ret_code = i40e_free_dma_mem_d(hw, & pd_entry->bp.addr);
  if ((int )ret_code != 0) {
    goto exit;
  } else {

  }
  if (pd_table->ref_cnt == 0U) {
    i40e_free_virt_mem_d(hw, & pd_table->pd_entry_virt_mem);
  } else {

  }
  exit: ;
  return (ret_code);
}
}
i40e_status i40e_prep_remove_sd_bp(struct i40e_hmc_info *hmc_info , u32 idx ) 
{ 
  i40e_status ret_code ;
  struct i40e_hmc_sd_entry *sd_entry ;

  {
  ret_code = 0;
  sd_entry = hmc_info->sd_table.sd_entry + (unsigned long )idx;
  sd_entry->u.bp.ref_cnt = sd_entry->u.bp.ref_cnt - 1U;
  if (sd_entry->u.bp.ref_cnt != 0U) {
    ret_code = -63;
    goto exit;
  } else {

  }
  hmc_info->sd_table.ref_cnt = hmc_info->sd_table.ref_cnt - 1U;
  sd_entry->valid = 0;
  exit: ;
  return (ret_code);
}
}
i40e_status i40e_remove_sd_bp_new(struct i40e_hw *hw , struct i40e_hmc_info *hmc_info ,
                                  u32 idx , bool is_pf ) 
{ 
  struct i40e_hmc_sd_entry *sd_entry ;
  i40e_status ret_code ;
  u32 val2 ;
  u32 val3 ;

  {
  ret_code = 0;
  sd_entry = hmc_info->sd_table.sd_entry + (unsigned long )idx;
  if ((int )is_pf) {
    val2 = 2050U;
    val3 = idx | 2147483648U;
    writel(0U, (void volatile   *)hw->hw_addr + 786944U);
    writel(val2, (void volatile   *)hw->hw_addr + 786688U);
    writel(val3, (void volatile   *)hw->hw_addr + 786432U);
  } else {
    ret_code = -64;
    goto exit;
  }
  ret_code = i40e_free_dma_mem_d(hw, & sd_entry->u.bp.addr);
  if ((int )ret_code != 0) {

  } else {

  }
  exit: ;
  return (ret_code);
}
}
i40e_status i40e_prep_remove_pd_page(struct i40e_hmc_info *hmc_info , u32 idx ) 
{ 
  i40e_status ret_code ;
  struct i40e_hmc_sd_entry *sd_entry ;

  {
  ret_code = 0;
  sd_entry = hmc_info->sd_table.sd_entry + (unsigned long )idx;
  if (sd_entry->u.pd_table.ref_cnt != 0U) {
    ret_code = -63;
    goto exit;
  } else {

  }
  sd_entry->valid = 0;
  hmc_info->sd_table.ref_cnt = hmc_info->sd_table.ref_cnt - 1U;
  exit: ;
  return (ret_code);
}
}
i40e_status i40e_remove_pd_page_new(struct i40e_hw *hw , struct i40e_hmc_info *hmc_info ,
                                    u32 idx , bool is_pf ) 
{ 
  i40e_status ret_code ;
  struct i40e_hmc_sd_entry *sd_entry ;
  u32 val2 ;
  u32 val3 ;

  {
  ret_code = 0;
  sd_entry = hmc_info->sd_table.sd_entry + (unsigned long )idx;
  if ((int )is_pf) {
    val2 = 2048U;
    val3 = idx | 2147483648U;
    writel(0U, (void volatile   *)hw->hw_addr + 786944U);
    writel(val2, (void volatile   *)hw->hw_addr + 786688U);
    writel(val3, (void volatile   *)hw->hw_addr + 786432U);
  } else {
    ret_code = -64;
    goto exit;
  }
  ret_code = i40e_free_dma_mem_d(hw, & sd_entry->u.pd_table.pd_page_addr);
  if ((int )ret_code != 0) {

  } else {

  }
  exit: ;
  return (ret_code);
}
}
bool ldv_queue_work_on_197(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_198(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_199(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_200(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_201(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_202(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_203(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_204(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_205(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_206(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_207(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_208(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_233(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_231(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_234(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_235(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_230(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_232(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_236(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_225(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_227(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_226(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_229(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_228(struct workqueue_struct *ldv_func_arg1 ) ;
static u64 i40e_align_l2obj_base(u64 offset ) 
{ 
  u64 aligned_offset ;

  {
  aligned_offset = offset;
  if ((offset & 511ULL) != 0ULL) {
    aligned_offset = (aligned_offset - (offset & 511ULL)) + 512ULL;
  } else {

  }
  return (aligned_offset);
}
}
static u64 i40e_calculate_l2fpm_size(u32 txq_num , u32 rxq_num , u32 fcoe_cntx_num ,
                                     u32 fcoe_filt_num ) 
{ 
  u64 fpm_size ;

  {
  fpm_size = 0ULL;
  fpm_size = (u64 )(txq_num * 128U);
  fpm_size = i40e_align_l2obj_base(fpm_size);
  fpm_size = (u64 )(rxq_num * 32U) + fpm_size;
  fpm_size = i40e_align_l2obj_base(fpm_size);
  fpm_size = (u64 )(fcoe_cntx_num * 64U) + fpm_size;
  fpm_size = i40e_align_l2obj_base(fpm_size);
  fpm_size = (u64 )(fcoe_filt_num * 64U) + fpm_size;
  fpm_size = i40e_align_l2obj_base(fpm_size);
  return (fpm_size);
}
}
i40e_status i40e_init_lan_hmc(struct i40e_hw *hw , u32 txq_num , u32 rxq_num , u32 fcoe_cntx_num ,
                              u32 fcoe_filt_num ) 
{ 
  struct i40e_hmc_obj_info *obj ;
  struct i40e_hmc_obj_info *full_obj ;
  i40e_status ret_code ;
  u64 l2fpm_size ;
  u32 size_exp ;

  {
  ret_code = 0;
  hw->hmc.signature = 1213027143U;
  hw->hmc.hmc_fn_id = hw->pf_id;
  ret_code = i40e_allocate_virt_mem_d(hw, & hw->hmc.hmc_obj_virt_mem, 120U);
  if ((int )ret_code != 0) {
    goto init_lan_hmc_out;
  } else {

  }
  hw->hmc.hmc_obj = (struct i40e_hmc_obj_info *)hw->hmc.hmc_obj_virt_mem.va;
  full_obj = hw->hmc.hmc_obj;
  full_obj->max_cnt = 0U;
  full_obj->cnt = 0U;
  full_obj->base = 0ULL;
  full_obj->size = 0ULL;
  obj = hw->hmc.hmc_obj + 1UL;
  obj->max_cnt = readl((void const volatile   *)hw->hw_addr + 794632U);
  obj->cnt = txq_num;
  obj->base = 0ULL;
  size_exp = readl((void const volatile   *)hw->hw_addr + 794628U);
  obj->size = 1ULL << (int )size_exp;
  if (obj->max_cnt < txq_num) {
    ret_code = -50;
    goto init_lan_hmc_out;
  } else {

  }
  full_obj->max_cnt = full_obj->max_cnt + obj->max_cnt;
  full_obj->cnt = full_obj->cnt + obj->cnt;
  obj = hw->hmc.hmc_obj + 2UL;
  obj->max_cnt = readl((void const volatile   *)hw->hw_addr + 794632U);
  obj->cnt = rxq_num;
  obj->base = (hw->hmc.hmc_obj + 1UL)->base + (u64 )(hw->hmc.hmc_obj + 1UL)->cnt * (hw->hmc.hmc_obj + 1UL)->size;
  obj->base = i40e_align_l2obj_base(obj->base);
  size_exp = readl((void const volatile   *)hw->hw_addr + 794636U);
  obj->size = 1ULL << (int )size_exp;
  if (obj->max_cnt < rxq_num) {
    ret_code = -50;
    goto init_lan_hmc_out;
  } else {

  }
  full_obj->max_cnt = full_obj->max_cnt + obj->max_cnt;
  full_obj->cnt = full_obj->cnt + obj->cnt;
  obj = hw->hmc.hmc_obj + 3UL;
  obj->max_cnt = readl((void const volatile   *)hw->hw_addr + 794644U);
  obj->cnt = fcoe_cntx_num;
  obj->base = (hw->hmc.hmc_obj + 2UL)->base + (u64 )(hw->hmc.hmc_obj + 2UL)->cnt * (hw->hmc.hmc_obj + 2UL)->size;
  obj->base = i40e_align_l2obj_base(obj->base);
  size_exp = readl((void const volatile   *)hw->hw_addr + 794640U);
  obj->size = 1ULL << (int )size_exp;
  if (obj->max_cnt < fcoe_cntx_num) {
    ret_code = -50;
    goto init_lan_hmc_out;
  } else {

  }
  full_obj->max_cnt = full_obj->max_cnt + obj->max_cnt;
  full_obj->cnt = full_obj->cnt + obj->cnt;
  obj = hw->hmc.hmc_obj + 4UL;
  obj->max_cnt = readl((void const volatile   *)hw->hw_addr + 794832U);
  obj->cnt = fcoe_filt_num;
  obj->base = (hw->hmc.hmc_obj + 3UL)->base + (u64 )(hw->hmc.hmc_obj + 3UL)->cnt * (hw->hmc.hmc_obj + 3UL)->size;
  obj->base = i40e_align_l2obj_base(obj->base);
  size_exp = readl((void const volatile   *)hw->hw_addr + 794648U);
  obj->size = 1ULL << (int )size_exp;
  if (obj->max_cnt < fcoe_filt_num) {
    ret_code = -50;
    goto init_lan_hmc_out;
  } else {

  }
  full_obj->max_cnt = full_obj->max_cnt + obj->max_cnt;
  full_obj->cnt = full_obj->cnt + obj->cnt;
  hw->hmc.first_sd_index = 0U;
  hw->hmc.sd_table.ref_cnt = 0U;
  l2fpm_size = i40e_calculate_l2fpm_size(txq_num, rxq_num, fcoe_cntx_num, fcoe_filt_num);
  if ((unsigned long )hw->hmc.sd_table.sd_entry == (unsigned long )((struct i40e_hmc_sd_entry *)0)) {
    hw->hmc.sd_table.sd_cnt = ((unsigned int )l2fpm_size + 2097151U) / 2097152U;
    ret_code = i40e_allocate_virt_mem_d(hw, & hw->hmc.sd_table.addr, hw->hmc.sd_table.sd_cnt * 64U);
    if ((int )ret_code != 0) {
      goto init_lan_hmc_out;
    } else {

    }
    hw->hmc.sd_table.sd_entry = (struct i40e_hmc_sd_entry *)hw->hmc.sd_table.addr.va;
  } else {

  }
  full_obj->size = l2fpm_size;
  init_lan_hmc_out: ;
  return (ret_code);
}
}
static i40e_status i40e_remove_pd_page(struct i40e_hw *hw , struct i40e_hmc_info *hmc_info ,
                                       u32 idx ) 
{ 
  i40e_status ret_code ;
  i40e_status tmp ;

  {
  ret_code = 0;
  tmp = i40e_prep_remove_pd_page(hmc_info, idx);
  if ((int )tmp == 0) {
    ret_code = i40e_remove_pd_page_new(hw, hmc_info, idx, 1);
  } else {

  }
  return (ret_code);
}
}
static i40e_status i40e_remove_sd_bp(struct i40e_hw *hw , struct i40e_hmc_info *hmc_info ,
                                     u32 idx ) 
{ 
  i40e_status ret_code ;
  i40e_status tmp ;

  {
  ret_code = 0;
  tmp = i40e_prep_remove_sd_bp(hmc_info, idx);
  if ((int )tmp == 0) {
    ret_code = i40e_remove_sd_bp_new(hw, hmc_info, idx, 1);
  } else {

  }
  return (ret_code);
}
}
static i40e_status i40e_create_lan_hmc_object(struct i40e_hw *hw , struct i40e_hmc_lan_create_obj_info *info ) 
{ 
  i40e_status ret_code ;
  struct i40e_hmc_sd_entry *sd_entry ;
  u32 pd_idx1 ;
  u32 pd_lmt1 ;
  u32 pd_idx ;
  u32 pd_lmt ;
  bool pd_error ;
  u32 sd_idx ;
  u32 sd_lmt ;
  u64 sd_size ;
  u32 i ;
  u32 j ;
  u64 fpm_addr ;
  u64 fpm_limit ;
  u64 fpm_adr ;
  u64 fpm_limit___0 ;
  u32 _max1 ;
  u32 _max2 ;
  u32 _min1 ;
  u32 _min2 ;
  u32 val1 ;
  u32 val2 ;
  u32 val3 ;
  u32 val1___0 ;
  u32 val2___0 ;
  u32 val3___0 ;
  u32 _max1___0 ;
  u32 _max2___0 ;
  u32 _min1___0 ;
  u32 _min2___0 ;

  {
  ret_code = 0;
  pd_idx1 = 0U;
  pd_lmt1 = 0U;
  pd_idx = 0U;
  pd_lmt = 0U;
  pd_error = 0;
  if ((unsigned long )info == (unsigned long )((struct i40e_hmc_lan_create_obj_info *)0)) {
    ret_code = -19;
    goto exit;
  } else {

  }
  if ((unsigned long )info->hmc_info == (unsigned long )((struct i40e_hmc_info *)0)) {
    ret_code = -19;
    goto exit;
  } else {

  }
  if ((info->hmc_info)->signature != 1213027143U) {
    ret_code = -19;
    goto exit;
  } else {

  }
  if (info->start_idx >= ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->cnt) {
    ret_code = -49;
    goto exit;
  } else {

  }
  if (info->start_idx + info->count > ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->cnt) {
    ret_code = -50;
    goto exit;
  } else {

  }
  fpm_addr = ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->base + ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->size * (u64 )info->start_idx;
  fpm_limit = ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->size * (u64 )info->count + fpm_addr;
  sd_idx = (unsigned int )(fpm_addr / 2097152ULL);
  sd_lmt = (unsigned int )((fpm_limit - 1ULL) / 2097152ULL);
  sd_lmt = sd_lmt + 1U;
  if ((info->hmc_info)->sd_table.sd_cnt <= sd_idx || (info->hmc_info)->sd_table.sd_cnt < sd_lmt) {
    ret_code = -45;
    goto exit;
  } else {

  }
  fpm_adr = ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->base + ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->size * (u64 )info->start_idx;
  fpm_limit___0 = ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->size * (u64 )info->count + fpm_adr;
  pd_idx = (unsigned int )(fpm_adr / 4096ULL);
  pd_lmt = (unsigned int )((fpm_limit___0 - 1ULL) / 4096ULL);
  pd_lmt = pd_lmt + 1U;
  if (info->direct_mode_sz == 0ULL) {
    sd_size = 2097152ULL;
  } else {
    sd_size = info->direct_mode_sz;
  }
  j = sd_idx;
  goto ldv_52622;
  ldv_52621: 
  ret_code = i40e_add_sd_table_entry(hw, info->hmc_info, j, info->entry_type, sd_size);
  if ((int )ret_code != 0) {
    goto exit_sd_error;
  } else {

  }
  sd_entry = (info->hmc_info)->sd_table.sd_entry + (unsigned long )j;
  if ((unsigned int )sd_entry->entry_type == 1U) {
    _max1 = pd_idx;
    _max2 = j * 512U;
    pd_idx1 = _max1 > _max2 ? _max1 : _max2;
    _min1 = pd_lmt;
    _min2 = (j + 1U) * 512U;
    pd_lmt1 = _min1 < _min2 ? _min1 : _min2;
    i = pd_idx1;
    goto ldv_52607;
    ldv_52606: 
    ret_code = i40e_add_pd_table_entry(hw, info->hmc_info, i);
    if ((int )ret_code != 0) {
      pd_error = 1;
      goto ldv_52605;
    } else {

    }
    i = i + 1U;
    ldv_52607: ;
    if (i < pd_lmt1) {
      goto ldv_52606;
    } else {

    }
    ldv_52605: ;
    if ((int )pd_error) {
      goto ldv_52609;
      ldv_52608: 
      i40e_remove_pd_bp(hw, info->hmc_info, i - 1U);
      i = i - 1U;
      ldv_52609: ;
      if (i != 0U && i > pd_idx1) {
        goto ldv_52608;
      } else {

      }

    } else {

    }
  } else {

  }
  if (! sd_entry->valid) {
    sd_entry->valid = 1;
    switch ((unsigned int )sd_entry->entry_type) {
    case 1U: 
    val1 = (unsigned int )(sd_entry->u.pd_table.pd_page_addr.pa >> 32ULL);
    val2 = ((unsigned int )sd_entry->u.pd_table.pd_page_addr.pa | ((unsigned int )sd_entry->entry_type != 1U ? 2U : 0U)) | 2049U;
    val3 = j | 2147483648U;
    writel(val1, (void volatile   *)hw->hw_addr + 786944U);
    writel(val2, (void volatile   *)hw->hw_addr + 786688U);
    writel(val3, (void volatile   *)hw->hw_addr + 786432U);
    goto ldv_52615;
    case 2U: 
    val1___0 = (unsigned int )(sd_entry->u.bp.addr.pa >> 32ULL);
    val2___0 = ((unsigned int )sd_entry->u.bp.addr.pa | ((unsigned int )sd_entry->entry_type != 1U ? 2U : 0U)) | 2049U;
    val3___0 = j | 2147483648U;
    writel(val1___0, (void volatile   *)hw->hw_addr + 786944U);
    writel(val2___0, (void volatile   *)hw->hw_addr + 786688U);
    writel(val3___0, (void volatile   *)hw->hw_addr + 786432U);
    goto ldv_52615;
    default: 
    ret_code = -47;
    goto exit;
    }
    ldv_52615: ;
  } else {

  }
  j = j + 1U;
  ldv_52622: ;
  if (j < sd_lmt) {
    goto ldv_52621;
  } else {

  }

  goto exit;
  exit_sd_error: ;
  goto ldv_52638;
  ldv_52637: 
  sd_entry = (info->hmc_info)->sd_table.sd_entry + (unsigned long )(j - 1U);
  switch ((unsigned int )sd_entry->entry_type) {
  case 1U: 
  _max1___0 = pd_idx;
  _max2___0 = (j + 8388607U) * 512U;
  pd_idx1 = _max1___0 > _max2___0 ? _max1___0 : _max2___0;
  _min1___0 = pd_lmt;
  _min2___0 = j * 512U;
  pd_lmt1 = _min1___0 < _min2___0 ? _min1___0 : _min2___0;
  i = pd_idx1;
  goto ldv_52632;
  ldv_52631: 
  i40e_remove_pd_bp(hw, info->hmc_info, i);
  i = i + 1U;
  ldv_52632: ;
  if (i < pd_lmt1) {
    goto ldv_52631;
  } else {

  }
  i40e_remove_pd_page(hw, info->hmc_info, j - 1U);
  goto ldv_52634;
  case 2U: 
  i40e_remove_sd_bp(hw, info->hmc_info, j - 1U);
  goto ldv_52634;
  default: 
  ret_code = -47;
  goto ldv_52634;
  }
  ldv_52634: 
  j = j - 1U;
  ldv_52638: ;
  if (j != 0U && j > sd_idx) {
    goto ldv_52637;
  } else {

  }

  exit: ;
  return (ret_code);
}
}
i40e_status i40e_configure_lan_hmc(struct i40e_hw *hw , enum i40e_hmc_model model ) 
{ 
  struct i40e_hmc_lan_create_obj_info info ;
  i40e_status ret_code ;
  u8 hmc_fn_id ;
  struct i40e_hmc_obj_info *obj ;

  {
  ret_code = 0;
  hmc_fn_id = hw->hmc.hmc_fn_id;
  info.hmc_info = & hw->hmc;
  info.rsrc_type = 0U;
  info.start_idx = 0U;
  info.direct_mode_sz = (hw->hmc.hmc_obj)->size;
  switch ((unsigned int )model) {
  case 0U: ;
  case 1U: 
  info.entry_type = 2;
  info.count = 1U;
  ret_code = i40e_create_lan_hmc_object(hw, & info);
  if ((int )ret_code != 0 && (unsigned int )model == 0U) {
    goto try_type_paged;
  } else
  if ((int )ret_code != 0) {
    goto configure_lan_hmc_out;
  } else {

  }
  goto ldv_52652;
  case 2U: ;
  try_type_paged: 
  info.entry_type = 1;
  info.count = 1U;
  ret_code = i40e_create_lan_hmc_object(hw, & info);
  if ((int )ret_code != 0) {
    goto configure_lan_hmc_out;
  } else {

  }
  goto ldv_52652;
  default: 
  ret_code = -47;
  goto configure_lan_hmc_out;
  }
  ldv_52652: 
  obj = hw->hmc.hmc_obj + 1UL;
  writel((unsigned int )((obj->base & 16777215ULL) / 512ULL), (void volatile   *)hw->hw_addr + (unsigned long )(((int )hmc_fn_id + 202880) * 4));
  writel(obj->cnt, (void volatile   *)hw->hw_addr + (unsigned long )(((int )hmc_fn_id + 202944) * 4));
  obj = hw->hmc.hmc_obj + 2UL;
  writel((unsigned int )((obj->base & 16777215ULL) / 512ULL), (void volatile   *)hw->hw_addr + (unsigned long )(((int )hmc_fn_id + 203008) * 4));
  writel(obj->cnt, (void volatile   *)hw->hw_addr + (unsigned long )(((int )hmc_fn_id + 203072) * 4));
  obj = hw->hmc.hmc_obj + 3UL;
  writel((unsigned int )((obj->base & 16777215ULL) / 512ULL), (void volatile   *)hw->hw_addr + (unsigned long )(((int )hmc_fn_id + 203136) * 4));
  writel(obj->cnt, (void volatile   *)hw->hw_addr + (unsigned long )(((int )hmc_fn_id + 203200) * 4));
  obj = hw->hmc.hmc_obj + 4UL;
  writel((unsigned int )((obj->base & 16777215ULL) / 512ULL), (void volatile   *)hw->hw_addr + (unsigned long )(((int )hmc_fn_id + 203264) * 4));
  writel(obj->cnt, (void volatile   *)hw->hw_addr + (unsigned long )(((int )hmc_fn_id + 203328) * 4));
  configure_lan_hmc_out: ;
  return (ret_code);
}
}
static i40e_status i40e_delete_lan_hmc_object(struct i40e_hw *hw , struct i40e_hmc_lan_delete_obj_info *info ) 
{ 
  i40e_status ret_code ;
  struct i40e_hmc_pd_table *pd_table ;
  u32 pd_idx ;
  u32 pd_lmt ;
  u32 rel_pd_idx ;
  u32 sd_idx ;
  u32 sd_lmt ;
  u32 i ;
  u32 j ;
  u64 fpm_adr ;
  u64 fpm_limit ;
  u64 fpm_addr ;
  u64 fpm_limit___0 ;

  {
  ret_code = 0;
  if ((unsigned long )info == (unsigned long )((struct i40e_hmc_lan_delete_obj_info *)0)) {
    ret_code = -19;
    goto exit;
  } else {

  }
  if ((unsigned long )info->hmc_info == (unsigned long )((struct i40e_hmc_info *)0)) {
    ret_code = -19;
    goto exit;
  } else {

  }
  if ((info->hmc_info)->signature != 1213027143U) {
    ret_code = -19;
    goto exit;
  } else {

  }
  if ((unsigned long )(info->hmc_info)->sd_table.sd_entry == (unsigned long )((struct i40e_hmc_sd_entry *)0)) {
    ret_code = -19;
    goto exit;
  } else {

  }
  if ((unsigned long )(info->hmc_info)->hmc_obj == (unsigned long )((struct i40e_hmc_obj_info *)0)) {
    ret_code = -19;
    goto exit;
  } else {

  }
  if (info->start_idx >= ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->cnt) {
    ret_code = -49;
    goto exit;
  } else {

  }
  if (info->start_idx + info->count > ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->cnt) {
    ret_code = -50;
    goto exit;
  } else {

  }
  fpm_adr = ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->base + ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->size * (u64 )info->start_idx;
  fpm_limit = ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->size * (u64 )info->count + fpm_adr;
  pd_idx = (unsigned int )(fpm_adr / 4096ULL);
  pd_lmt = (unsigned int )((fpm_limit - 1ULL) / 4096ULL);
  pd_lmt = pd_lmt + 1U;
  j = pd_idx;
  goto ldv_52673;
  ldv_52672: 
  sd_idx = j / 512U;
  if ((unsigned int )((info->hmc_info)->sd_table.sd_entry + (unsigned long )sd_idx)->entry_type != 1U) {
    goto ldv_52671;
  } else {

  }
  rel_pd_idx = j & 511U;
  pd_table = & ((info->hmc_info)->sd_table.sd_entry + (unsigned long )sd_idx)->u.pd_table;
  if ((int )(pd_table->pd_entry + (unsigned long )rel_pd_idx)->valid) {
    ret_code = i40e_remove_pd_bp(hw, info->hmc_info, j);
    if ((int )ret_code != 0) {
      goto exit;
    } else {

    }
  } else {

  }
  ldv_52671: 
  j = j + 1U;
  ldv_52673: ;
  if (j < pd_lmt) {
    goto ldv_52672;
  } else {

  }
  fpm_addr = ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->base + ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->size * (u64 )info->start_idx;
  fpm_limit___0 = ((info->hmc_info)->hmc_obj + (unsigned long )info->rsrc_type)->size * (u64 )info->count + fpm_addr;
  sd_idx = (unsigned int )(fpm_addr / 2097152ULL);
  sd_lmt = (unsigned int )((fpm_limit___0 - 1ULL) / 2097152ULL);
  sd_lmt = sd_lmt + 1U;
  if ((info->hmc_info)->sd_table.sd_cnt <= sd_idx || (info->hmc_info)->sd_table.sd_cnt < sd_lmt) {
    ret_code = -45;
    goto exit;
  } else {

  }
  i = sd_idx;
  goto ldv_52683;
  ldv_52682: ;
  if (! ((info->hmc_info)->sd_table.sd_entry + (unsigned long )i)->valid) {
    goto ldv_52677;
  } else {

  }
  switch ((unsigned int )((info->hmc_info)->sd_table.sd_entry + (unsigned long )i)->entry_type) {
  case 2U: 
  ret_code = i40e_remove_sd_bp(hw, info->hmc_info, i);
  if ((int )ret_code != 0) {
    goto exit;
  } else {

  }
  goto ldv_52679;
  case 1U: 
  ret_code = i40e_remove_pd_page(hw, info->hmc_info, i);
  if ((int )ret_code != 0) {
    goto exit;
  } else {

  }
  goto ldv_52679;
  default: ;
  goto ldv_52679;
  }
  ldv_52679: ;
  ldv_52677: 
  i = i + 1U;
  ldv_52683: ;
  if (i < sd_lmt) {
    goto ldv_52682;
  } else {

  }

  exit: ;
  return (ret_code);
}
}
i40e_status i40e_shutdown_lan_hmc(struct i40e_hw *hw ) 
{ 
  struct i40e_hmc_lan_delete_obj_info info ;
  i40e_status ret_code ;

  {
  info.hmc_info = & hw->hmc;
  info.rsrc_type = 0U;
  info.start_idx = 0U;
  info.count = 1U;
  ret_code = i40e_delete_lan_hmc_object(hw, & info);
  i40e_free_virt_mem_d(hw, & hw->hmc.sd_table.addr);
  hw->hmc.sd_table.sd_cnt = 0U;
  hw->hmc.sd_table.sd_entry = (struct i40e_hmc_sd_entry *)0;
  i40e_free_virt_mem_d(hw, & hw->hmc.hmc_obj_virt_mem);
  hw->hmc.hmc_obj = (struct i40e_hmc_obj_info *)0;
  return (ret_code);
}
}
static struct i40e_context_ele i40e_hmc_txq_ce_info[19U]  = 
  {      {0U, 2U, 13U, 0U}, 
        {2U, 1U, 1U, 30U}, 
        {8U, 8U, 57U, 32U}, 
        {16U, 1U, 1U, 89U}, 
        {17U, 1U, 1U, 90U}, 
        {18U, 1U, 1U, 91U}, 
        {19U, 1U, 1U, 92U}, 
        {22U, 1U, 8U, 96U}, 
        {20U, 2U, 13U, 128U}, 
        {23U, 1U, 1U, 160U}, 
        {24U, 2U, 13U, 161U}, 
        {26U, 1U, 1U, 174U}, 
        {27U, 1U, 1U, 175U}, 
        {28U, 1U, 1U, 176U}, 
        {32U, 8U, 64U, 192U}, 
        {40U, 4U, 32U, 896U}, 
        {44U, 2U, 10U, 980U}, 
        {46U, 1U, 1U, 990U}, 
        {0U, (unsigned short)0, (unsigned short)0, (unsigned short)0}};
static struct i40e_context_ele i40e_hmc_rxq_ce_info[22U]  = 
  {      {0U, 2U, 13U, 0U}, 
        {2U, 2U, 8U, 13U}, 
        {8U, 8U, 57U, 32U}, 
        {16U, 2U, 13U, 89U}, 
        {18U, 2U, 7U, 102U}, 
        {20U, 2U, 5U, 109U}, 
        {22U, 1U, 2U, 114U}, 
        {23U, 1U, 1U, 116U}, 
        {24U, 1U, 1U, 117U}, 
        {25U, 1U, 1U, 118U}, 
        {26U, 1U, 1U, 119U}, 
        {27U, 1U, 4U, 120U}, 
        {28U, 1U, 2U, 124U}, 
        {29U, 1U, 1U, 127U}, 
        {32U, 4U, 14U, 174U}, 
        {36U, 1U, 1U, 193U}, 
        {37U, 1U, 1U, 194U}, 
        {38U, 1U, 1U, 195U}, 
        {39U, 1U, 1U, 196U}, 
        {40U, 2U, 3U, 198U}, 
        {42U, 1U, 1U, 201U}, 
        {0U, (unsigned short)0, (unsigned short)0, (unsigned short)0}};
static void i40e_write_byte(u8 *hmc_bits , struct i40e_context_ele *ce_info , u8 *src ) 
{ 
  u8 src_byte ;
  u8 dest_byte ;
  u8 mask ;
  u8 *from ;
  u8 *dest ;
  u16 shift_width ;

  {
  from = src + (unsigned long )ce_info->offset;
  shift_width = (unsigned int )ce_info->lsb & 7U;
  mask = (unsigned int )((u8 )(1 << (int )ce_info->width)) + 255U;
  src_byte = *from;
  src_byte = (u8 )((int )src_byte & (int )mask);
  mask = (u8 )((int )mask << (int )shift_width);
  src_byte = (u8 )((int )src_byte << (int )shift_width);
  dest = hmc_bits + (unsigned long )((unsigned int )ce_info->lsb / 8U);
  memcpy((void *)(& dest_byte), (void const   *)dest, 1UL);
  dest_byte = (u8 )(~ ((int )((signed char )mask)) & (int )((signed char )dest_byte));
  dest_byte = (u8 )((int )dest_byte | (int )src_byte);
  memcpy((void *)dest, (void const   *)(& dest_byte), 1UL);
  return;
}
}
static void i40e_write_word(u8 *hmc_bits , struct i40e_context_ele *ce_info , u8 *src ) 
{ 
  u16 src_word ;
  u16 mask ;
  u8 *from ;
  u8 *dest ;
  u16 shift_width ;
  __le16 dest_word ;

  {
  from = src + (unsigned long )ce_info->offset;
  shift_width = (unsigned int )ce_info->lsb & 7U;
  mask = (unsigned int )((u16 )(1 << (int )ce_info->width)) + 65535U;
  src_word = *((u16 *)from);
  src_word = (u16 )((int )src_word & (int )mask);
  mask = (u16 )((int )mask << (int )shift_width);
  src_word = (u16 )((int )src_word << (int )shift_width);
  dest = hmc_bits + (unsigned long )((unsigned int )ce_info->lsb / 8U);
  memcpy((void *)(& dest_word), (void const   *)dest, 2UL);
  dest_word = (__le16 )(~ ((int )((short )mask)) & (int )((short )dest_word));
  dest_word = (__le16 )((int )dest_word | (int )src_word);
  memcpy((void *)dest, (void const   *)(& dest_word), 2UL);
  return;
}
}
static void i40e_write_dword(u8 *hmc_bits , struct i40e_context_ele *ce_info , u8 *src ) 
{ 
  u32 src_dword ;
  u32 mask ;
  u8 *from ;
  u8 *dest ;
  u16 shift_width ;
  __le32 dest_dword ;

  {
  from = src + (unsigned long )ce_info->offset;
  shift_width = (unsigned int )ce_info->lsb & 7U;
  if ((unsigned int )ce_info->width <= 31U) {
    mask = (1U << (int )ce_info->width) - 1U;
  } else {
    mask = 4294967295U;
  }
  src_dword = *((u32 *)from);
  src_dword = src_dword & mask;
  mask = mask << (int )shift_width;
  src_dword = src_dword << (int )shift_width;
  dest = hmc_bits + (unsigned long )((unsigned int )ce_info->lsb / 8U);
  memcpy((void *)(& dest_dword), (void const   *)dest, 4UL);
  dest_dword = ~ mask & dest_dword;
  dest_dword = dest_dword | src_dword;
  memcpy((void *)dest, (void const   *)(& dest_dword), 4UL);
  return;
}
}
static void i40e_write_qword(u8 *hmc_bits , struct i40e_context_ele *ce_info , u8 *src ) 
{ 
  u64 src_qword ;
  u64 mask ;
  u8 *from ;
  u8 *dest ;
  u16 shift_width ;
  __le64 dest_qword ;

  {
  from = src + (unsigned long )ce_info->offset;
  shift_width = (unsigned int )ce_info->lsb & 7U;
  if ((unsigned int )ce_info->width <= 63U) {
    mask = (1ULL << (int )ce_info->width) - 1ULL;
  } else {
    mask = 0xffffffffffffffffULL;
  }
  src_qword = *((u64 *)from);
  src_qword = src_qword & mask;
  mask = mask << (int )shift_width;
  src_qword = src_qword << (int )shift_width;
  dest = hmc_bits + (unsigned long )((unsigned int )ce_info->lsb / 8U);
  memcpy((void *)(& dest_qword), (void const   *)dest, 8UL);
  dest_qword = ~ mask & dest_qword;
  dest_qword = dest_qword | src_qword;
  memcpy((void *)dest, (void const   *)(& dest_qword), 8UL);
  return;
}
}
static i40e_status i40e_clear_hmc_context(struct i40e_hw *hw , u8 *context_bytes ,
                                          enum i40e_hmc_lan_rsrc_type hmc_type ) 
{ 


  {
  memset((void *)context_bytes, 0, (size_t )((unsigned int )(hw->hmc.hmc_obj + (unsigned long )hmc_type)->size));
  return (0);
}
}
static i40e_status i40e_set_hmc_context(u8 *context_bytes , struct i40e_context_ele *ce_info ,
                                        u8 *dest ) 
{ 
  int f ;
    klee_make_symbolic(&f, sizeof(int), "f");

  {
  f = 0;
  goto ldv_52758;
  ldv_52757: ;
  switch ((int )(ce_info + (unsigned long )f)->size_of) {
  case 1: 
  i40e_write_byte(context_bytes, ce_info + (unsigned long )f, dest);
  goto ldv_52753;
  case 2: 
  i40e_write_word(context_bytes, ce_info + (unsigned long )f, dest);
  goto ldv_52753;
  case 4: 
  i40e_write_dword(context_bytes, ce_info + (unsigned long )f, dest);
  goto ldv_52753;
  case 8: 
  i40e_write_qword(context_bytes, ce_info + (unsigned long )f, dest);
  goto ldv_52753;
  }
  ldv_52753: 
  f = f + 1;
  ldv_52758: ;
  if ((unsigned int )(ce_info + (unsigned long )f)->width != 0U) {
    goto ldv_52757;
  } else {

  }

  return (0);
}
}
static i40e_status i40e_hmc_get_object_va(struct i40e_hmc_info *hmc_info , u8 **object_base ,
                                          enum i40e_hmc_lan_rsrc_type rsrc_type ,
                                          u32 obj_idx ) 
{ 
  u32 obj_offset_in_sd ;
  u32 obj_offset_in_pd ;
  i40e_status ret_code ;
  struct i40e_hmc_sd_entry *sd_entry ;
  struct i40e_hmc_pd_entry *pd_entry ;
  u32 pd_idx ;
  u32 pd_lmt ;
  u32 rel_pd_idx ;
  u64 obj_offset_in_fpm ;
  u32 sd_idx ;
  u32 sd_lmt ;
  u64 fpm_addr ;
  u64 fpm_limit ;
  u64 fpm_adr ;
  u64 fpm_limit___0 ;

  {
  ret_code = 0;
  if ((unsigned long )hmc_info == (unsigned long )((struct i40e_hmc_info *)0)) {
    ret_code = -19;
    goto exit;
  } else {

  }
  if ((unsigned long )hmc_info->hmc_obj == (unsigned long )((struct i40e_hmc_obj_info *)0)) {
    ret_code = -19;
    goto exit;
  } else {

  }
  if ((unsigned long )object_base == (unsigned long )((u8 **)0U)) {
    ret_code = -19;
    goto exit;
  } else {

  }
  if (hmc_info->signature != 1213027143U) {
    ret_code = -19;
    goto exit;
  } else {

  }
  if ((hmc_info->hmc_obj + (unsigned long )rsrc_type)->cnt <= obj_idx) {
    ret_code = -49;
    goto exit;
  } else {

  }
  fpm_addr = (hmc_info->hmc_obj + (unsigned long )rsrc_type)->base + (hmc_info->hmc_obj + (unsigned long )rsrc_type)->size * (u64 )obj_idx;
  fpm_limit = (hmc_info->hmc_obj + (unsigned long )rsrc_type)->size + fpm_addr;
  sd_idx = (unsigned int )(fpm_addr / 2097152ULL);
  sd_lmt = (unsigned int )((fpm_limit - 1ULL) / 2097152ULL);
  sd_lmt = sd_lmt + 1U;
  sd_entry = hmc_info->sd_table.sd_entry + (unsigned long )sd_idx;
  obj_offset_in_fpm = (hmc_info->hmc_obj + (unsigned long )rsrc_type)->base + (hmc_info->hmc_obj + (unsigned long )rsrc_type)->size * (u64 )obj_idx;
  if ((unsigned int )sd_entry->entry_type == 1U) {
    fpm_adr = (hmc_info->hmc_obj + (unsigned long )rsrc_type)->base + (hmc_info->hmc_obj + (unsigned long )rsrc_type)->size * (u64 )obj_idx;
    fpm_limit___0 = (hmc_info->hmc_obj + (unsigned long )rsrc_type)->size + fpm_adr;
    pd_idx = (unsigned int )(fpm_adr / 4096ULL);
    pd_lmt = (unsigned int )((fpm_limit___0 - 1ULL) / 4096ULL);
    pd_lmt = pd_lmt + 1U;
    rel_pd_idx = pd_idx & 511U;
    pd_entry = sd_entry->u.pd_table.pd_entry + (unsigned long )rel_pd_idx;
    obj_offset_in_pd = (unsigned int )obj_offset_in_fpm & 4095U;
    *object_base = (u8 *)pd_entry->bp.addr.va + (unsigned long )obj_offset_in_pd;
  } else {
    obj_offset_in_sd = (unsigned int )obj_offset_in_fpm & 2097151U;
    *object_base = (u8 *)sd_entry->u.bp.addr.va + (unsigned long )obj_offset_in_sd;
  }
  exit: ;
  return (ret_code);
}
}
i40e_status i40e_clear_lan_tx_queue_context(struct i40e_hw *hw , u16 queue ) 
{ 
  i40e_status err ;
  u8 *context_bytes ;
  i40e_status tmp ;

  {
  err = i40e_hmc_get_object_va(& hw->hmc, & context_bytes, 1, (u32 )queue);
  if ((int )err < 0) {
    return (err);
  } else {

  }
  tmp = i40e_clear_hmc_context(hw, context_bytes, 1);
  return (tmp);
}
}
i40e_status i40e_set_lan_tx_queue_context(struct i40e_hw *hw , u16 queue , struct i40e_hmc_obj_txq *s ) 
{ 
  i40e_status err ;
  u8 *context_bytes ;
  i40e_status tmp ;

  {
  err = i40e_hmc_get_object_va(& hw->hmc, & context_bytes, 1, (u32 )queue);
  if ((int )err < 0) {
    return (err);
  } else {

  }
  tmp = i40e_set_hmc_context(context_bytes, (struct i40e_context_ele *)(& i40e_hmc_txq_ce_info),
                             (u8 *)s);
  return (tmp);
}
}
i40e_status i40e_clear_lan_rx_queue_context(struct i40e_hw *hw , u16 queue ) 
{ 
  i40e_status err ;
  u8 *context_bytes ;
  i40e_status tmp ;

  {
  err = i40e_hmc_get_object_va(& hw->hmc, & context_bytes, 2, (u32 )queue);
  if ((int )err < 0) {
    return (err);
  } else {

  }
  tmp = i40e_clear_hmc_context(hw, context_bytes, 2);
  return (tmp);
}
}
i40e_status i40e_set_lan_rx_queue_context(struct i40e_hw *hw , u16 queue , struct i40e_hmc_obj_rxq *s ) 
{ 
  i40e_status err ;
  u8 *context_bytes ;
  i40e_status tmp ;

  {
  err = i40e_hmc_get_object_va(& hw->hmc, & context_bytes, 2, (u32 )queue);
  if ((int )err < 0) {
    return (err);
  } else {

  }
  tmp = i40e_set_hmc_context(context_bytes, (struct i40e_context_ele *)(& i40e_hmc_rxq_ce_info),
                             (u8 *)s);
  return (tmp);
}
}
bool ldv_queue_work_on_225(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_226(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_227(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_228(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_229(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_230(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_231(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_232(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_233(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_234(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_235(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_236(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_261(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_259(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_262(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_263(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_258(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_260(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_264(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_253(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_255(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_254(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_257(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_256(struct workqueue_struct *ldv_func_arg1 ) ;
__inline static int i40e_aq_rc_to_posix(u32 aq_ret , u16 aq_rc ) 
{ 
  int aq_to_posix[23U] ;

  {
  aq_to_posix[0] = 0;
  aq_to_posix[1] = -1;
  aq_to_posix[2] = -2;
  aq_to_posix[3] = -3;
  aq_to_posix[4] = -4;
  aq_to_posix[5] = -5;
  aq_to_posix[6] = -6;
  aq_to_posix[7] = -7;
  aq_to_posix[8] = -11;
  aq_to_posix[9] = -12;
  aq_to_posix[10] = -13;
  aq_to_posix[11] = -14;
  aq_to_posix[12] = -16;
  aq_to_posix[13] = -17;
  aq_to_posix[14] = -22;
  aq_to_posix[15] = -25;
  aq_to_posix[16] = -28;
  aq_to_posix[17] = -38;
  aq_to_posix[18] = -34;
  aq_to_posix[19] = -32;
  aq_to_posix[20] = -29;
  aq_to_posix[21] = -30;
  aq_to_posix[22] = -27;
  if (aq_ret == 4294967242U) {
    return (-11);
  } else {

  }
  if ((unsigned int )aq_rc > 22U) {
    return (-34);
  } else {

  }
  return (aq_to_posix[(int )aq_rc]);
}
}
i40e_status i40e_read_nvm_buffer(struct i40e_hw *hw , u16 offset , u16 *words , u16 *data ) ;
i40e_status i40e_update_nvm_checksum(struct i40e_hw *hw ) ;
i40e_status i40e_validate_nvm_checksum(struct i40e_hw *hw , u16 *checksum ) ;
i40e_status i40e_init_nvm(struct i40e_hw *hw ) 
{ 
  struct i40e_nvm_info *nvm ;
  i40e_status ret_code ;
  u32 fla ;
  u32 gens ;
  u8 sr_size ;

  {
  nvm = & hw->nvm;
  ret_code = 0;
  gens = readl((void const volatile   *)hw->hw_addr + 745728U);
  sr_size = (u8 )((gens & 224U) >> 5);
  nvm->sr_size = (u16 )(512 << (int )sr_size);
  fla = readl((void const volatile   *)hw->hw_addr + 745736U);
  if ((fla & 64U) != 0U) {
    nvm->timeout = 18000U;
    nvm->blank_nvm_mode = 0;
  } else {
    nvm->blank_nvm_mode = 1;
    ret_code = -59;
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x NVM init error: unsupported blank mode.\n", (int )hw->bus.device,
             (int )hw->bus.func);
    } else {

    }
  }
  return (ret_code);
}
}
i40e_status i40e_acquire_nvm(struct i40e_hw *hw , enum i40e_aq_resource_access_type access ) 
{ 
  i40e_status ret_code ;
  u64 gtime ;
  u64 timeout ;
  u64 time_left ;
  unsigned int tmp ;
  unsigned int tmp___0 ;

  {
  ret_code = 0;
  time_left = 0ULL;
  if ((int )hw->nvm.blank_nvm_mode) {
    goto i40e_i40e_acquire_nvm_exit;
  } else {

  }
  ret_code = i40e_aq_request_resource(hw, 1, access, 0, & time_left, (struct i40e_asq_cmd_details *)0);
  tmp = readl((void const volatile   *)hw->hw_addr + 557500U);
  gtime = (u64 )tmp;
  hw->nvm.hw_semaphore_timeout = time_left * 1000ULL + gtime;
  if ((int )ret_code != 0) {
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x NVM acquire type %d failed time_left=%llu ret=%d aq_err=%d\n",
             (int )hw->bus.device, (int )hw->bus.func, (unsigned int )access, time_left,
             (int )ret_code, (unsigned int )hw->aq.asq_last_status);
    } else {

    }
  } else {

  }
  if ((int )ret_code != 0 && time_left != 0ULL) {
    timeout = gtime + 18000000ULL;
    goto ldv_52560;
    ldv_52559: 
    usleep_range(10000UL, 20000UL);
    tmp___0 = readl((void const volatile   *)hw->hw_addr + 557500U);
    gtime = (u64 )tmp___0;
    ret_code = i40e_aq_request_resource(hw, 1, access, 0, & time_left, (struct i40e_asq_cmd_details *)0);
    if ((int )ret_code == 0) {
      hw->nvm.hw_semaphore_timeout = time_left * 1000ULL + gtime;
      goto ldv_52558;
    } else {

    }
    ldv_52560: ;
    if (gtime < timeout && time_left != 0ULL) {
      goto ldv_52559;
    } else {

    }
    ldv_52558: ;
    if ((int )ret_code != 0) {
      hw->nvm.hw_semaphore_timeout = 0ULL;
      if ((hw->debug_mask & 128U) != 0U) {
        printk("\016i40e %02x.%x NVM acquire timed out, wait %llu ms before trying again. status=%d aq_err=%d\n",
               (int )hw->bus.device, (int )hw->bus.func, time_left, (int )ret_code,
               (unsigned int )hw->aq.asq_last_status);
      } else {

      }
    } else {

    }
  } else {

  }
  i40e_i40e_acquire_nvm_exit: ;
  return (ret_code);
}
}
void i40e_release_nvm(struct i40e_hw *hw ) 
{ 


  {
  if (! hw->nvm.blank_nvm_mode) {
    i40e_aq_release_resource(hw, 1, 0, (struct i40e_asq_cmd_details *)0);
  } else {

  }
  return;
}
}
static i40e_status i40e_poll_sr_srctl_done_bit(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;
  u32 srctl ;
  u32 wait_cnt ;

  {
  ret_code = -37;
  wait_cnt = 0U;
  goto ldv_52572;
  ldv_52571: 
  srctl = readl((void const volatile   *)hw->hw_addr + 745744U);
  if ((int )srctl < 0) {
    ret_code = 0;
    goto ldv_52570;
  } else {

  }
  __const_udelay(21475UL);
  wait_cnt = wait_cnt + 1U;
  ldv_52572: ;
  if (wait_cnt <= 99999U) {
    goto ldv_52571;
  } else {

  }
  ldv_52570: ;
  if ((int )ret_code == -37) {
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x Done bit in GLNVM_SRCTL not set", (int )hw->bus.device,
             (int )hw->bus.func);
    } else {

    }
  } else {

  }
  return (ret_code);
}
}
static i40e_status i40e_read_nvm_word_srctl(struct i40e_hw *hw , u16 offset , u16 *data ) 
{ 
  i40e_status ret_code ;
  u32 sr_reg ;

  {
  ret_code = -37;
  if ((int )hw->nvm.sr_size <= (int )offset) {
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x NVM read error: offset %d beyond Shadow RAM limit %d\n",
             (int )hw->bus.device, (int )hw->bus.func, (int )offset, (int )hw->nvm.sr_size);
    } else {

    }
    ret_code = -5;
    goto read_nvm_exit;
  } else {

  }
  ret_code = i40e_poll_sr_srctl_done_bit(hw);
  if ((int )ret_code == 0) {
    sr_reg = (unsigned int )((int )offset << 14) | 1073741824U;
    writel(sr_reg, (void volatile   *)hw->hw_addr + 745744U);
    ret_code = i40e_poll_sr_srctl_done_bit(hw);
    if ((int )ret_code == 0) {
      sr_reg = readl((void const volatile   *)hw->hw_addr + 745748U);
      *data = (unsigned short )(sr_reg >> 16);
    } else {

    }
  } else {

  }
  if ((int )ret_code != 0) {
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x NVM read error: Couldn\'t access Shadow RAM address: 0x%x\n",
             (int )hw->bus.device, (int )hw->bus.func, (int )offset);
    } else {

    }
  } else {

  }
  read_nvm_exit: ;
  return (ret_code);
}
}
i40e_status i40e_read_nvm_word(struct i40e_hw *hw , u16 offset , u16 *data ) 
{ 
  i40e_status tmp ;

  {
  tmp = i40e_read_nvm_word_srctl(hw, (int )offset, data);
  return (tmp);
}
}
static i40e_status i40e_read_nvm_buffer_srctl(struct i40e_hw *hw , u16 offset , u16 *words ,
                                              u16 *data ) 
{ 
  i40e_status ret_code ;
  u16 index ;
  u16 word ;

  {
  ret_code = 0;
  word = 0U;
  goto ldv_52597;
  ldv_52596: 
  index = (int )offset + (int )word;
  ret_code = i40e_read_nvm_word_srctl(hw, (int )index, data + (unsigned long )word);
  if ((int )ret_code != 0) {
    goto ldv_52595;
  } else {

  }
  word = (u16 )((int )word + 1);
  ldv_52597: ;
  if ((int )*words > (int )word) {
    goto ldv_52596;
  } else {

  }
  ldv_52595: 
  *words = word;
  return (ret_code);
}
}
i40e_status i40e_read_nvm_buffer(struct i40e_hw *hw , u16 offset , u16 *words , u16 *data ) 
{ 
  i40e_status tmp ;

  {
  tmp = i40e_read_nvm_buffer_srctl(hw, (int )offset, words, data);
  return (tmp);
}
}
static i40e_status i40e_write_nvm_aq(struct i40e_hw *hw , u8 module_pointer , u32 offset ,
                                     u16 words , void *data , bool last_command ) 
{ 
  i40e_status ret_code ;

  {
  ret_code = -1;
  if ((u32 )words + offset > (u32 )hw->nvm.sr_size) {
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x NVM write error: offset %d beyond Shadow RAM limit %d\n",
             (int )hw->bus.device, (int )hw->bus.func, (u32 )words + offset, (int )hw->nvm.sr_size);
    } else {

    }
  } else
  if ((unsigned int )words > 2048U) {
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x NVM write fail error: tried to write %d words, limit is %d.\n",
             (int )hw->bus.device, (int )hw->bus.func, (int )words, 2048);
    } else {

    }
  } else
  if ((((u32 )words + offset) + 4294967295U) / 2048U != offset / 2048U) {
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x NVM write error: cannot spread over two sectors in a single write offset=%d words=%d\n",
             (int )hw->bus.device, (int )hw->bus.func, offset, (int )words);
    } else {

    }
  } else {
    ret_code = i40e_aq_update_nvm(hw, (int )module_pointer, offset * 2U, (int )((unsigned int )words * 2U),
                                  data, (int )last_command, (struct i40e_asq_cmd_details *)0);
  }
  return (ret_code);
}
}
static i40e_status i40e_calc_nvm_checksum(struct i40e_hw *hw , u16 *checksum ) 
{ 
  i40e_status ret_code ;
  struct i40e_virt_mem vmem ;
  u16 pcie_alt_module ;
  u16 checksum_local ;
  u16 vpd_module ;
  u16 *data ;
  u16 i ;
  u16 words ;

  {
  ret_code = 0;
  pcie_alt_module = 0U;
  checksum_local = 0U;
  vpd_module = 0U;
  i = 0U;
  ret_code = i40e_allocate_virt_mem_d(hw, & vmem, 4096U);
  if ((int )ret_code != 0) {
    goto i40e_calc_nvm_checksum_exit;
  } else {

  }
  data = (u16 *)vmem.va;
  ret_code = i40e_read_nvm_word(hw, 47, & vpd_module);
  if ((int )ret_code != 0) {
    ret_code = -2;
    goto i40e_calc_nvm_checksum_exit;
  } else {

  }
  ret_code = i40e_read_nvm_word(hw, 62, & pcie_alt_module);
  if ((int )ret_code != 0) {
    ret_code = -2;
    goto i40e_calc_nvm_checksum_exit;
  } else {

  }
  i = 0U;
  goto ldv_52628;
  ldv_52627: ;
  if (((unsigned int )i & 2047U) == 0U) {
    words = 2048U;
    ret_code = i40e_read_nvm_buffer(hw, (int )i, & words, data);
    if ((int )ret_code != 0) {
      ret_code = -2;
      goto i40e_calc_nvm_checksum_exit;
    } else {

    }
  } else {

  }
  if ((unsigned int )i == 63U) {
    goto ldv_52626;
  } else {

  }
  if ((int )i >= (int )vpd_module && (unsigned int )i < (unsigned int )vpd_module + 512U) {
    goto ldv_52626;
  } else {

  }
  if ((int )i >= (int )pcie_alt_module && (unsigned int )i < (unsigned int )pcie_alt_module + 512U) {
    goto ldv_52626;
  } else {

  }
  checksum_local = (int )*(data + ((unsigned long )i & 2047UL)) + (int )checksum_local;
  ldv_52626: 
  i = (u16 )((int )i + 1);
  ldv_52628: ;
  if ((int )hw->nvm.sr_size > (int )i) {
    goto ldv_52627;
  } else {

  }
  *checksum = 47802U - (unsigned int )checksum_local;
  i40e_calc_nvm_checksum_exit: 
  i40e_free_virt_mem_d(hw, & vmem);
  return (ret_code);
}
}
i40e_status i40e_update_nvm_checksum(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;
  u16 checksum ;

  {
  ret_code = 0;
  ret_code = i40e_calc_nvm_checksum(hw, & checksum);
  if ((int )ret_code == 0) {
    ret_code = i40e_write_nvm_aq(hw, 0, 63U, 1, (void *)(& checksum), 1);
  } else {

  }
  return (ret_code);
}
}
i40e_status i40e_validate_nvm_checksum(struct i40e_hw *hw , u16 *checksum ) 
{ 
  i40e_status ret_code ;
  u16 checksum_sr ;
  u16 checksum_local ;

  {
  ret_code = 0;
  checksum_sr = 0U;
  checksum_local = 0U;
  ret_code = i40e_calc_nvm_checksum(hw, & checksum_local);
  if ((int )ret_code != 0) {
    goto i40e_validate_nvm_checksum_exit;
  } else {

  }
  i40e_read_nvm_word(hw, 63, & checksum_sr);
  if ((int )checksum_local != (int )checksum_sr) {
    ret_code = -2;
  } else {

  }
  if ((unsigned long )checksum != (unsigned long )((u16 *)0U)) {
    *checksum = checksum_local;
  } else {

  }
  i40e_validate_nvm_checksum_exit: ;
  return (ret_code);
}
}
static i40e_status i40e_nvmupd_state_init(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                          u8 *bytes , int *errno ) ;
static i40e_status i40e_nvmupd_state_reading(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                             u8 *bytes , int *errno ) ;
static i40e_status i40e_nvmupd_state_writing(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                             u8 *bytes , int *errno ) ;
static enum i40e_nvmupd_cmd i40e_nvmupd_validate_command(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                                         int *errno ) ;
static i40e_status i40e_nvmupd_nvm_erase(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                         int *errno ) ;
static i40e_status i40e_nvmupd_nvm_write(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                         u8 *bytes , int *errno ) ;
static i40e_status i40e_nvmupd_nvm_read(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                        u8 *bytes , int *errno ) ;
__inline static u8 i40e_nvmupd_get_module(u32 val ) 
{ 


  {
  return ((u8 )val);
}
}
__inline static u8 i40e_nvmupd_get_transaction(u32 val ) 
{ 


  {
  return ((u8 )((val & 3840U) >> 8));
}
}
static char *i40e_nvm_update_state_str[13U]  = 
  {      (char *)"I40E_NVMUPD_INVALID",      (char *)"I40E_NVMUPD_READ_CON",      (char *)"I40E_NVMUPD_READ_SNT",      (char *)"I40E_NVMUPD_READ_LCB", 
        (char *)"I40E_NVMUPD_READ_SA",      (char *)"I40E_NVMUPD_WRITE_ERA",      (char *)"I40E_NVMUPD_WRITE_CON",      (char *)"I40E_NVMUPD_WRITE_SNT", 
        (char *)"I40E_NVMUPD_WRITE_LCB",      (char *)"I40E_NVMUPD_WRITE_SA",      (char *)"I40E_NVMUPD_CSUM_CON",      (char *)"I40E_NVMUPD_CSUM_SA", 
        (char *)"I40E_NVMUPD_CSUM_LCB"};
i40e_status i40e_nvmupd_command(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                u8 *bytes , int *errno ) 
{ 
  i40e_status status ;

  {
  *errno = 0;
  switch ((unsigned int )hw->nvmupd_state) {
  case 0U: 
  status = i40e_nvmupd_state_init(hw, cmd, bytes, errno);
  goto ldv_52691;
  case 1U: 
  status = i40e_nvmupd_state_reading(hw, cmd, bytes, errno);
  goto ldv_52691;
  case 2U: 
  status = i40e_nvmupd_state_writing(hw, cmd, bytes, errno);
  goto ldv_52691;
  default: ;
  if ((hw->debug_mask & 128U) != 0U) {
    printk("\016i40e %02x.%x NVMUPD: no such state %d\n", (int )hw->bus.device, (int )hw->bus.func,
           (unsigned int )hw->nvmupd_state);
  } else {

  }
  status = -64;
  *errno = -3;
  goto ldv_52691;
  }
  ldv_52691: ;
  return (status);
}
}
static i40e_status i40e_nvmupd_state_init(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                          u8 *bytes , int *errno ) 
{ 
  i40e_status status ;
  enum i40e_nvmupd_cmd upd_cmd ;
  int tmp ;

  {
  status = 0;
  upd_cmd = i40e_nvmupd_validate_command(hw, cmd, errno);
  switch ((unsigned int )upd_cmd) {
  case 4U: 
  status = i40e_acquire_nvm(hw, 1);
  if ((int )status != 0) {
    *errno = i40e_aq_rc_to_posix((u32 )status, (int )((u16 )hw->aq.asq_last_status));
  } else {
    status = i40e_nvmupd_nvm_read(hw, cmd, bytes, errno);
    i40e_release_nvm(hw);
  }
  goto ldv_52704;
  case 2U: 
  status = i40e_acquire_nvm(hw, 1);
  if ((int )status != 0) {
    *errno = i40e_aq_rc_to_posix((u32 )status, (int )((u16 )hw->aq.asq_last_status));
  } else {
    status = i40e_nvmupd_nvm_read(hw, cmd, bytes, errno);
    if ((int )status != 0) {
      i40e_release_nvm(hw);
    } else {
      hw->nvmupd_state = 1;
    }
  }
  goto ldv_52704;
  case 5U: 
  status = i40e_acquire_nvm(hw, 2);
  if ((int )status != 0) {
    *errno = i40e_aq_rc_to_posix((u32 )status, (int )((u16 )hw->aq.asq_last_status));
  } else {
    status = i40e_nvmupd_nvm_erase(hw, cmd, errno);
    if ((int )status != 0) {
      i40e_release_nvm(hw);
    } else {
      hw->aq.nvm_release_on_done = 1;
    }
  }
  goto ldv_52704;
  case 9U: 
  status = i40e_acquire_nvm(hw, 2);
  if ((int )status != 0) {
    *errno = i40e_aq_rc_to_posix((u32 )status, (int )((u16 )hw->aq.asq_last_status));
  } else {
    status = i40e_nvmupd_nvm_write(hw, cmd, bytes, errno);
    if ((int )status != 0) {
      i40e_release_nvm(hw);
    } else {
      hw->aq.nvm_release_on_done = 1;
    }
  }
  goto ldv_52704;
  case 7U: 
  status = i40e_acquire_nvm(hw, 2);
  if ((int )status != 0) {
    *errno = i40e_aq_rc_to_posix((u32 )status, (int )((u16 )hw->aq.asq_last_status));
  } else {
    status = i40e_nvmupd_nvm_write(hw, cmd, bytes, errno);
    if ((int )status != 0) {
      i40e_release_nvm(hw);
    } else {
      hw->nvmupd_state = 2;
    }
  }
  goto ldv_52704;
  case 11U: 
  status = i40e_acquire_nvm(hw, 2);
  if ((int )status != 0) {
    *errno = i40e_aq_rc_to_posix((u32 )status, (int )((u16 )hw->aq.asq_last_status));
  } else {
    status = i40e_update_nvm_checksum(hw);
    if ((int )status != 0) {
      if ((unsigned int )hw->aq.asq_last_status != 0U) {
        tmp = i40e_aq_rc_to_posix((u32 )status, (int )((u16 )hw->aq.asq_last_status));
        *errno = tmp;
      } else {
        *errno = -5;
      }
      i40e_release_nvm(hw);
    } else {
      hw->aq.nvm_release_on_done = 1;
    }
  }
  goto ldv_52704;
  default: ;
  if ((hw->debug_mask & 128U) != 0U) {
    printk("\016i40e %02x.%x NVMUPD: bad cmd %s in init state\n", (int )hw->bus.device,
           (int )hw->bus.func, i40e_nvm_update_state_str[(unsigned int )upd_cmd]);
  } else {

  }
  status = -1;
  *errno = -3;
  goto ldv_52704;
  }
  ldv_52704: ;
  return (status);
}
}
static i40e_status i40e_nvmupd_state_reading(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                             u8 *bytes , int *errno ) 
{ 
  i40e_status status ;
  enum i40e_nvmupd_cmd upd_cmd ;

  {
  upd_cmd = i40e_nvmupd_validate_command(hw, cmd, errno);
  switch ((unsigned int )upd_cmd) {
  case 4U: ;
  case 1U: 
  status = i40e_nvmupd_nvm_read(hw, cmd, bytes, errno);
  goto ldv_52721;
  case 3U: 
  status = i40e_nvmupd_nvm_read(hw, cmd, bytes, errno);
  i40e_release_nvm(hw);
  hw->nvmupd_state = 0;
  goto ldv_52721;
  default: ;
  if ((hw->debug_mask & 128U) != 0U) {
    printk("\016i40e %02x.%x NVMUPD: bad cmd %s in reading state.\n", (int )hw->bus.device,
           (int )hw->bus.func, i40e_nvm_update_state_str[(unsigned int )upd_cmd]);
  } else {

  }
  status = -64;
  *errno = -3;
  goto ldv_52721;
  }
  ldv_52721: ;
  return (status);
}
}
static i40e_status i40e_nvmupd_state_writing(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                             u8 *bytes , int *errno ) 
{ 
  i40e_status status ;
  enum i40e_nvmupd_cmd upd_cmd ;
  bool retry_attempt ;
  int tmp ;
  int tmp___0 ;
  i40e_status old_status ;
  u32 old_asq_status ;
  u32 gtime ;

  {
  retry_attempt = 0;
  upd_cmd = i40e_nvmupd_validate_command(hw, cmd, errno);
  retry: ;
  switch ((unsigned int )upd_cmd) {
  case 6U: 
  status = i40e_nvmupd_nvm_write(hw, cmd, bytes, errno);
  goto ldv_52735;
  case 8U: 
  status = i40e_nvmupd_nvm_write(hw, cmd, bytes, errno);
  if ((int )status == 0) {
    hw->aq.nvm_release_on_done = 1;
  } else {

  }
  hw->nvmupd_state = 0;
  goto ldv_52735;
  case 10U: 
  status = i40e_update_nvm_checksum(hw);
  if ((int )status != 0) {
    if ((unsigned int )hw->aq.asq_last_status != 0U) {
      tmp = i40e_aq_rc_to_posix((u32 )status, (int )((u16 )hw->aq.asq_last_status));
      *errno = tmp;
    } else {
      *errno = -5;
    }
    hw->nvmupd_state = 0;
  } else {

  }
  goto ldv_52735;
  case 12U: 
  status = i40e_update_nvm_checksum(hw);
  if ((int )status != 0) {
    if ((unsigned int )hw->aq.asq_last_status != 0U) {
      tmp___0 = i40e_aq_rc_to_posix((u32 )status, (int )((u16 )hw->aq.asq_last_status));
      *errno = tmp___0;
    } else {
      *errno = -5;
    }
  } else {
    hw->aq.nvm_release_on_done = 1;
  }
  hw->nvmupd_state = 0;
  goto ldv_52735;
  default: ;
  if ((hw->debug_mask & 128U) != 0U) {
    printk("\016i40e %02x.%x NVMUPD: bad cmd %s in writing state.\n", (int )hw->bus.device,
           (int )hw->bus.func, i40e_nvm_update_state_str[(unsigned int )upd_cmd]);
  } else {

  }
  status = -64;
  *errno = -3;
  goto ldv_52735;
  }
  ldv_52735: ;
  if (((int )status != 0 && (unsigned int )hw->aq.asq_last_status == 12U) && ! retry_attempt) {
    old_status = status;
    old_asq_status = hw->aq.asq_last_status;
    gtime = readl((void const volatile   *)hw->hw_addr + 557500U);
    if ((u64 )gtime >= hw->nvm.hw_semaphore_timeout) {
      if (hw->debug_mask != 0U) {
        printk("\016i40e %02x.%x NVMUPD: write semaphore expired (%d >= %lld), retrying\n",
               (int )hw->bus.device, (int )hw->bus.func, gtime, hw->nvm.hw_semaphore_timeout);
      } else {

      }
      i40e_release_nvm(hw);
      status = i40e_acquire_nvm(hw, 2);
      if ((int )status != 0) {
        if (hw->debug_mask != 0U) {
          printk("\016i40e %02x.%x NVMUPD: write semaphore reacquire failed aq_err = %d\n",
                 (int )hw->bus.device, (int )hw->bus.func, (unsigned int )hw->aq.asq_last_status);
        } else {

        }
        status = old_status;
        hw->aq.asq_last_status = (enum i40e_admin_queue_err )old_asq_status;
      } else {
        retry_attempt = 1;
        goto retry;
      }
    } else {

    }
  } else {

  }
  return (status);
}
}
static enum i40e_nvmupd_cmd i40e_nvmupd_validate_command(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                                         int *errno ) 
{ 
  enum i40e_nvmupd_cmd upd_cmd ;
  u8 transaction ;

  {
  upd_cmd = 0;
  transaction = i40e_nvmupd_get_transaction(cmd->config);
  if (cmd->data_size == 0U || cmd->data_size > 4096U) {
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x i40e_nvmupd_validate_command data_size %d\n", (int )hw->bus.device,
             (int )hw->bus.func, cmd->data_size);
    } else {

    }
    *errno = -14;
    return (0);
  } else {

  }
  switch (cmd->command) {
  case 11U: ;
  switch ((int )transaction) {
  case 0: 
  upd_cmd = 1;
  goto ldv_52752;
  case 1: 
  upd_cmd = 2;
  goto ldv_52752;
  case 2: 
  upd_cmd = 3;
  goto ldv_52752;
  case 3: 
  upd_cmd = 4;
  goto ldv_52752;
  }
  ldv_52752: ;
  goto ldv_52756;
  case 12U: ;
  switch ((int )transaction) {
  case 0: 
  upd_cmd = 6;
  goto ldv_52759;
  case 1: 
  upd_cmd = 7;
  goto ldv_52759;
  case 2: 
  upd_cmd = 8;
  goto ldv_52759;
  case 3: 
  upd_cmd = 9;
  goto ldv_52759;
  case 4: 
  upd_cmd = 5;
  goto ldv_52759;
  case 8: 
  upd_cmd = 10;
  goto ldv_52759;
  case 11: 
  upd_cmd = 11;
  goto ldv_52759;
  case 10: 
  upd_cmd = 12;
  goto ldv_52759;
  }
  ldv_52759: ;
  goto ldv_52756;
  }
  ldv_52756: ;
  if ((hw->debug_mask & 128U) != 0U) {
    printk("\016i40e %02x.%x %s state %d nvm_release_on_hold %d\n", (int )hw->bus.device,
           (int )hw->bus.func, i40e_nvm_update_state_str[(unsigned int )upd_cmd],
           (unsigned int )hw->nvmupd_state, (int )hw->aq.nvm_release_on_done);
  } else {

  }
  if ((unsigned int )upd_cmd == 0U) {
    *errno = -14;
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x i40e_nvmupd_validate_command returns %d errno %d\n",
             (int )hw->bus.device, (int )hw->bus.func, (unsigned int )upd_cmd, *errno);
    } else {

    }
  } else {

  }
  return (upd_cmd);
}
}
static i40e_status i40e_nvmupd_nvm_read(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                        u8 *bytes , int *errno ) 
{ 
  i40e_status status ;
  u8 module ;
  u8 transaction ;
  bool last ;

  {
  transaction = i40e_nvmupd_get_transaction(cmd->config);
  module = i40e_nvmupd_get_module(cmd->config);
  last = (bool )((unsigned int )transaction == 2U || (unsigned int )transaction == 3U);
  status = i40e_aq_read_nvm(hw, (int )module, cmd->offset, (int )((unsigned short )cmd->data_size),
                            (void *)bytes, (int )last, (struct i40e_asq_cmd_details *)0);
  if ((int )status != 0) {
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x i40e_nvmupd_nvm_read mod 0x%x  off 0x%x  len 0x%x\n",
             (int )hw->bus.device, (int )hw->bus.func, (int )module, cmd->offset,
             cmd->data_size);
    } else {

    }
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x i40e_nvmupd_nvm_read status %d aq %d\n", (int )hw->bus.device,
             (int )hw->bus.func, (int )status, (unsigned int )hw->aq.asq_last_status);
    } else {

    }
    *errno = i40e_aq_rc_to_posix((u32 )status, (int )((u16 )hw->aq.asq_last_status));
  } else {

  }
  return (status);
}
}
static i40e_status i40e_nvmupd_nvm_erase(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                         int *errno ) 
{ 
  i40e_status status ;
  u8 module ;
  u8 transaction ;
  bool last ;

  {
  status = 0;
  transaction = i40e_nvmupd_get_transaction(cmd->config);
  module = i40e_nvmupd_get_module(cmd->config);
  last = ((int )transaction & 2) != 0;
  status = i40e_aq_erase_nvm(hw, (int )module, cmd->offset, (int )((unsigned short )cmd->data_size),
                             (int )last, (struct i40e_asq_cmd_details *)0);
  if ((int )status != 0) {
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x i40e_nvmupd_nvm_erase mod 0x%x  off 0x%x len 0x%x\n",
             (int )hw->bus.device, (int )hw->bus.func, (int )module, cmd->offset,
             cmd->data_size);
    } else {

    }
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x i40e_nvmupd_nvm_erase status %d aq %d\n", (int )hw->bus.device,
             (int )hw->bus.func, (int )status, (unsigned int )hw->aq.asq_last_status);
    } else {

    }
    *errno = i40e_aq_rc_to_posix((u32 )status, (int )((u16 )hw->aq.asq_last_status));
  } else {

  }
  return (status);
}
}
static i40e_status i40e_nvmupd_nvm_write(struct i40e_hw *hw , struct i40e_nvm_access *cmd ,
                                         u8 *bytes , int *errno ) 
{ 
  i40e_status status ;
  u8 module ;
  u8 transaction ;
  bool last ;

  {
  status = 0;
  transaction = i40e_nvmupd_get_transaction(cmd->config);
  module = i40e_nvmupd_get_module(cmd->config);
  last = ((int )transaction & 2) != 0;
  status = i40e_aq_update_nvm(hw, (int )module, cmd->offset, (int )((unsigned short )cmd->data_size),
                              (void *)bytes, (int )last, (struct i40e_asq_cmd_details *)0);
  if ((int )status != 0) {
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x i40e_nvmupd_nvm_write mod 0x%x off 0x%x len 0x%x\n",
             (int )hw->bus.device, (int )hw->bus.func, (int )module, cmd->offset,
             cmd->data_size);
    } else {

    }
    if ((hw->debug_mask & 128U) != 0U) {
      printk("\016i40e %02x.%x i40e_nvmupd_nvm_write status %d aq %d\n", (int )hw->bus.device,
             (int )hw->bus.func, (int )status, (unsigned int )hw->aq.asq_last_status);
    } else {

    }
    *errno = i40e_aq_rc_to_posix((u32 )status, (int )((u16 )hw->aq.asq_last_status));
  } else {

  }
  return (status);
}
}
bool ldv_queue_work_on_253(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_254(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_255(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_256(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_257(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_258(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_259(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_260(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_261(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_262(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_263(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_264(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
extern void print_hex_dump(char const   * , char const   * , int  , int  , int  ,
                           void const   * , size_t  , bool  ) ;
extern void __might_fault(char const   * , int  ) ;
extern int kstrtol_from_user(char const   * , size_t  , unsigned int  , long * ) ;
extern int sscanf(char const   * , char const   *  , ...) ;
extern int strncmp(char const   * , char const   * , __kernel_size_t  ) ;
extern char *strchr(char const   * , int  ) ;
extern void *kmemdup(void const   * , size_t  , gfp_t  ) ;
int ldv_mutex_trylock_291(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_286(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_289(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_292(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_294(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_295(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_297(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_298(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_287(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_288(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_290(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_293(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_296(struct mutex *ldv_func_arg1 ) ;
__inline static void __preempt_count_add___1(int val ) 
{ 
  int pao_ID__ ;

  {
  pao_ID__ = 0;
  switch (4UL) {
  case 1UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incb %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decb %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addb %1, %%gs:%0": "+m" (__preempt_count): "qi" (val));
  }
  goto ldv_6633;
  case 2UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incw %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decw %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addw %1, %%gs:%0": "+m" (__preempt_count): "ri" (val));
  }
  goto ldv_6633;
  case 4UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incl %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decl %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addl %1, %%gs:%0": "+m" (__preempt_count): "ri" (val));
  }
  goto ldv_6633;
  case 8UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incq %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decq %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addq %1, %%gs:%0": "+m" (__preempt_count): "re" (val));
  }
  goto ldv_6633;
  default: 
  __bad_percpu_size();
  }
  ldv_6633: ;
  return;
}
}
__inline static void __preempt_count_sub___1(int val ) 
{ 
  int pao_ID__ ;

  {
  pao_ID__ = 0;
  switch (4UL) {
  case 1UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incb %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decb %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addb %1, %%gs:%0": "+m" (__preempt_count): "qi" (- val));
  }
  goto ldv_6645;
  case 2UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incw %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decw %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addw %1, %%gs:%0": "+m" (__preempt_count): "ri" (- val));
  }
  goto ldv_6645;
  case 4UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incl %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decl %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addl %1, %%gs:%0": "+m" (__preempt_count): "ri" (- val));
  }
  goto ldv_6645;
  case 8UL: ;
  if (pao_ID__ == 1) {
    __asm__  ("incq %%gs:%0": "+m" (__preempt_count));
  } else
  if (pao_ID__ == -1) {
    __asm__  ("decq %%gs:%0": "+m" (__preempt_count));
  } else {
    __asm__  ("addq %1, %%gs:%0": "+m" (__preempt_count): "re" (- val));
  }
  goto ldv_6645;
  default: 
  __bad_percpu_size();
  }
  ldv_6645: ;
  return;
}
}
__inline static void __rcu_read_lock___1(void) 
{ 


  {
  __preempt_count_add___1(1);
  __asm__  volatile   ("": : : "memory");
  return;
}
}
__inline static void __rcu_read_unlock___1(void) 
{ 


  {
  __asm__  volatile   ("": : : "memory");
  __preempt_count_sub___1(1);
  return;
}
}
__inline static void rcu_read_lock___1(void) 
{ 
  bool __warned ;
  int tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  __rcu_read_lock___1();
  rcu_lock_acquire(& rcu_lock_map);
  tmp = debug_lockdep_rcu_enabled();
  if (tmp != 0 && ! __warned) {
    tmp___0 = rcu_is_watching();
    if (tmp___0) {
      tmp___1 = 0;
    } else {
      tmp___1 = 1;
    }
    if (tmp___1) {
      __warned = 1;
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 849, "rcu_read_lock() used illegally while idle");
    } else {

    }
  } else {

  }
  return;
}
}
__inline static void rcu_read_unlock___1(void) 
{ 
  bool __warned ;
  int tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  tmp = debug_lockdep_rcu_enabled();
  if (tmp != 0 && ! __warned) {
    tmp___0 = rcu_is_watching();
    if (tmp___0) {
      tmp___1 = 0;
    } else {
      tmp___1 = 1;
    }
    if (tmp___1) {
      __warned = 1;
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 900, "rcu_read_unlock() used illegally while idle");
    } else {

    }
  } else {

  }
  __rcu_read_unlock___1();
  rcu_lock_release(& rcu_lock_map);
  return;
}
}
bool ldv_queue_work_on_281(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_283(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_282(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_285(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_284(struct workqueue_struct *ldv_func_arg1 ) ;
extern int simple_open(struct inode * , struct file * ) ;
extern struct dentry *debugfs_create_file(char const   * , umode_t  , struct dentry * ,
                                          void * , struct file_operations  const  * ) ;
extern struct dentry *debugfs_create_dir(char const   * , struct dentry * ) ;
extern void debugfs_remove_recursive(struct dentry * ) ;
extern unsigned long _copy_from_user(void * , void const   * , unsigned int  ) ;
extern unsigned long _copy_to_user(void * , void const   * , unsigned int  ) ;
extern void __copy_from_user_overflow(void) ;
extern void __copy_to_user_overflow(void) ;
__inline static unsigned long copy_from_user(void *to , void const   *from , unsigned long n ) 
{ 
  int sz ;
    klee_make_symbolic(&sz, sizeof(int), "sz");
  unsigned long tmp ;
  long tmp___0 ;

  {
  tmp = __builtin_object_size((void const   *)to, 0);
  sz = (int )tmp;
  __might_fault("./arch/x86/include/asm/uaccess.h", 697);
  tmp___0 = ldv__builtin_expect((long )(sz < 0 || (unsigned long )sz >= n), 1L);
  if (tmp___0 != 0L) {
    n = _copy_from_user(to, from, (unsigned int )n);
  } else {
    __copy_from_user_overflow();
  }
  return (n);
}
}
__inline static unsigned long copy_to_user(void *to , void const   *from , unsigned long n ) 
{ 
  int sz ;
  unsigned long tmp ;
  long tmp___0 ;

  {
  tmp = __builtin_object_size(from, 0);
  sz = (int )tmp;
  __might_fault("./arch/x86/include/asm/uaccess.h", 732);
  tmp___0 = ldv__builtin_expect((long )(sz < 0 || (unsigned long )sz >= n), 1L);
  if (tmp___0 != 0L) {
    n = _copy_to_user(to, from, (unsigned int )n);
  } else {
    __copy_to_user_overflow();
  }
  return (n);
}
}
extern int rtnl_trylock(void) ;
int i40e_program_fdir_filter(struct i40e_fdir_filter *fdir_data , u8 *raw_packet ,
                             struct i40e_pf *pf , bool add ) ;
static struct dentry *i40e_dbg_root  ;
static struct i40e_vsi *i40e_dbg_find_vsi(struct i40e_pf *pf , int seid ) 
{ 
  int i ;

  {
  if (seid < 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%d: bad seid\n", seid);
  } else {
    i = 0;
    goto ldv_61145;
    ldv_61144: ;
    if ((unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0) && (int )(*(pf->vsi + (unsigned long )i))->seid == seid) {
      return (*(pf->vsi + (unsigned long )i));
    } else {

    }
    i = i + 1;
    ldv_61145: ;
    if ((int )pf->num_alloc_vsi > i) {
      goto ldv_61144;
    } else {

    }

  }
  return ((struct i40e_vsi *)0);
}
}
static struct i40e_veb *i40e_dbg_find_veb(struct i40e_pf *pf , int seid ) 
{ 
  int i ;

  {
  if (seid <= 287 || seid > 304) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%d: bad seid\n", seid);
  } else {
    i = 0;
    goto ldv_61153;
    ldv_61152: ;
    if ((unsigned long )pf->veb[i] != (unsigned long )((struct i40e_veb *)0) && (int )(pf->veb[i])->seid == seid) {
      return (pf->veb[i]);
    } else {

    }
    i = i + 1;
    ldv_61153: ;
    if (i <= 15) {
      goto ldv_61152;
    } else {

    }

  }
  return ((struct i40e_veb *)0);
}
}
static char *i40e_dbg_dump_buf  ;
static ssize_t i40e_dbg_dump_data_len  ;
static ssize_t i40e_dbg_dump_buffer_len  ;
static ssize_t i40e_dbg_dump_read(struct file *filp , char *buffer , size_t count ,
                                  loff_t *ppos ) 
{ 
  int bytes_not_copied ;
    klee_make_symbolic(&bytes_not_copied, sizeof(int), "bytes_not_copied");
  int len ;
  int __min1 ;
  int __min2 ;
  unsigned long tmp ;

  {
  if (*ppos >= (long long )i40e_dbg_dump_data_len || (unsigned long )i40e_dbg_dump_buf == (unsigned long )((char *)0)) {
    return (0L);
  } else {

  }
  __min1 = (int )count;
  __min2 = (int )((unsigned int )i40e_dbg_dump_data_len - (unsigned int )*ppos);
  len = __min1 < __min2 ? __min1 : __min2;
  tmp = copy_to_user((void *)buffer, (void const   *)i40e_dbg_dump_buf + (unsigned long )*ppos,
                     (unsigned long )len);
  bytes_not_copied = (int )tmp;
  if (bytes_not_copied < 0) {
    return ((ssize_t )bytes_not_copied);
  } else {

  }
  *ppos = *ppos + (loff_t )len;
  return ((ssize_t )len);
}
}
static int i40e_dbg_prep_dump_buf(struct i40e_pf *pf , int buflen ) 
{ 
  void *tmp ;

  {
  if (i40e_dbg_dump_buffer_len != 0L && (ssize_t )buflen > i40e_dbg_dump_buffer_len) {
    kfree((void const   *)i40e_dbg_dump_buf);
    i40e_dbg_dump_buffer_len = 0L;
    i40e_dbg_dump_buf = (char *)0;
  } else {

  }
  if ((unsigned long )i40e_dbg_dump_buf == (unsigned long )((char *)0)) {
    tmp = kzalloc((size_t )buflen, 208U);
    i40e_dbg_dump_buf = (char *)tmp;
    if ((unsigned long )i40e_dbg_dump_buf != (unsigned long )((char *)0)) {
      i40e_dbg_dump_buffer_len = (ssize_t )buflen;
    } else {

    }
  } else {

  }
  return ((int )i40e_dbg_dump_buffer_len);
}
}
static ssize_t i40e_dbg_dump_write(struct file *filp , char const   *buffer , size_t count ,
                                   loff_t *ppos ) 
{ 
  struct i40e_pf *pf ;
  bool seid_found ;
  long seid ;
    klee_make_symbolic(&seid, sizeof(long), "seid");
  int buflen ;
  int i ;
  int ret ;
  int len ;
  u8 *p ;
  int tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_mac_filter *f ;
  int filter_count ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;
  struct list_head  const  *__mptr___2 ;
  int tmp___0 ;
  struct i40e_veb *veb ;
  int tmp___1 ;

  {
  pf = (struct i40e_pf *)filp->private_data;
  seid_found = 0;
  seid = -1L;
  buflen = 0;
  if (*ppos != 0LL) {
    return (0L);
  } else {

  }
  ret = kstrtol_from_user(buffer, count, 0U, & seid);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "bad seid value\n");
  } else
  if (seid == 0L) {
    seid_found = 1;
    kfree((void const   *)i40e_dbg_dump_buf);
    i40e_dbg_dump_buffer_len = 0L;
    i40e_dbg_dump_data_len = 0L;
    i40e_dbg_dump_buf = (char *)0;
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "debug buffer freed\n");
  } else
  if ((long )pf->pf_seid == seid || seid == 1L) {
    seid_found = 1;
    buflen = 135240;
    buflen = (int )((unsigned int )((unsigned long )((int )pf->hw.aq.num_arq_entries + (int )pf->hw.aq.num_asq_entries)) * 32U + (unsigned int )buflen);
    tmp = i40e_dbg_prep_dump_buf(pf, buflen);
    if (tmp != 0) {
      p = (u8 *)i40e_dbg_dump_buf;
      len = 135240;
      memcpy((void *)p, (void const   *)pf, (size_t )len);
      p = p + (unsigned long )len;
      len = (int )((unsigned int )pf->hw.aq.num_asq_entries * 32U);
      memcpy((void *)p, (void const   *)pf->hw.aq.asq.desc_buf.va, (size_t )len);
      p = p + (unsigned long )len;
      len = (int )((unsigned int )pf->hw.aq.num_arq_entries * 32U);
      memcpy((void *)p, (void const   *)pf->hw.aq.arq.desc_buf.va, (size_t )len);
      p = p + (unsigned long )len;
      i40e_dbg_dump_data_len = (ssize_t )buflen;
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "PF seid %ld dumped %d bytes\n",
                seid, (int )i40e_dbg_dump_data_len);
    } else {

    }
  } else
  if (seid > 511L) {
    vsi = (struct i40e_vsi *)0;
    filter_count = 0;
    ldv_mutex_lock_293(& pf->switch_mutex);
    vsi = i40e_dbg_find_vsi(pf, (int )seid);
    if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
      ldv_mutex_unlock_294(& pf->switch_mutex);
      goto write_exit;
    } else {

    }
    buflen = 4096;
    buflen = (int )((unsigned int )((unsigned long )vsi->num_q_vectors) * 4096U + (unsigned int )buflen);
    buflen = (int )((unsigned int )vsi->num_queue_pairs * 8192U + (unsigned int )buflen);
    buflen = (int )((unsigned int )vsi->num_queue_pairs * 40U + (unsigned int )buflen);
    buflen = (int )((unsigned int )vsi->num_queue_pairs * 48U + (unsigned int )buflen);
    __mptr = (struct list_head  const  *)vsi->mac_filter_list.next;
    f = (struct i40e_mac_filter *)__mptr;
    goto ldv_61196;
    ldv_61195: 
    filter_count = filter_count + 1;
    __mptr___0 = (struct list_head  const  *)f->list.next;
    f = (struct i40e_mac_filter *)__mptr___0;
    ldv_61196: ;
    if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
      goto ldv_61195;
    } else {

    }
    buflen = (int )((unsigned int )((unsigned long )filter_count) * 32U + (unsigned int )buflen);
    tmp___0 = i40e_dbg_prep_dump_buf(pf, buflen);
    if (tmp___0 != 0) {
      p = (u8 *)i40e_dbg_dump_buf;
      seid_found = 1;
      len = 4096;
      memcpy((void *)p, (void const   *)vsi, (size_t )len);
      p = p + (unsigned long )len;
      if (vsi->num_q_vectors != 0) {
        len = (int )((unsigned int )vsi->num_q_vectors * 4096U);
        memcpy((void *)p, (void const   *)vsi->q_vectors, (size_t )len);
        p = p + (unsigned long )len;
      } else {

      }
      if ((unsigned int )vsi->num_queue_pairs != 0U) {
        len = (int )((unsigned int )vsi->num_queue_pairs * 4096U);
        memcpy((void *)p, (void const   *)vsi->tx_rings, (size_t )len);
        p = p + (unsigned long )len;
        memcpy((void *)p, (void const   *)vsi->rx_rings, (size_t )len);
        p = p + (unsigned long )len;
      } else {

      }
      if ((unsigned long )*(vsi->tx_rings) != (unsigned long )((struct i40e_ring *)0)) {
        len = 40;
        i = 0;
        goto ldv_61199;
        ldv_61198: 
        memcpy((void *)p, (void const   *)(*(vsi->tx_rings + (unsigned long )i))->__annonCompField121.tx_bi,
                 (size_t )len);
        p = p + (unsigned long )len;
        i = i + 1;
        ldv_61199: ;
        if ((int )vsi->num_queue_pairs > i) {
          goto ldv_61198;
        } else {

        }
        len = 48;
        i = 0;
        goto ldv_61202;
        ldv_61201: 
        memcpy((void *)p, (void const   *)(*(vsi->rx_rings + (unsigned long )i))->__annonCompField121.rx_bi,
                 (size_t )len);
        p = p + (unsigned long )len;
        i = i + 1;
        ldv_61202: ;
        if ((int )vsi->num_queue_pairs > i) {
          goto ldv_61201;
        } else {

        }

      } else {

      }
      len = 32;
      __mptr___1 = (struct list_head  const  *)vsi->mac_filter_list.next;
      f = (struct i40e_mac_filter *)__mptr___1;
      goto ldv_61209;
      ldv_61208: 
      memcpy((void *)p, (void const   *)f, (size_t )len);
      p = p + (unsigned long )len;
      __mptr___2 = (struct list_head  const  *)f->list.next;
      f = (struct i40e_mac_filter *)__mptr___2;
      ldv_61209: ;
      if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
        goto ldv_61208;
      } else {

      }
      i40e_dbg_dump_data_len = (ssize_t )buflen;
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "VSI seid %ld dumped %d bytes\n",
                seid, (int )i40e_dbg_dump_data_len);
    } else {

    }
    ldv_mutex_unlock_295(& pf->switch_mutex);
  } else
  if (seid > 287L) {
    veb = (struct i40e_veb *)0;
    ldv_mutex_lock_296(& pf->switch_mutex);
    veb = i40e_dbg_find_veb(pf, (int )seid);
    if ((unsigned long )veb == (unsigned long )((struct i40e_veb *)0)) {
      ldv_mutex_unlock_297(& pf->switch_mutex);
      goto write_exit;
    } else {

    }
    buflen = 272;
    tmp___1 = i40e_dbg_prep_dump_buf(pf, buflen);
    if (tmp___1 != 0) {
      seid_found = 1;
      memcpy((void *)i40e_dbg_dump_buf, (void const   *)veb, (size_t )buflen);
      i40e_dbg_dump_data_len = (ssize_t )buflen;
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "VEB seid %ld dumped %d bytes\n",
                seid, (int )i40e_dbg_dump_data_len);
    } else {

    }
    ldv_mutex_unlock_298(& pf->switch_mutex);
  } else {

  }
  write_exit: ;
  if (! seid_found) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "unknown seid %ld\n",
              seid);
  } else {

  }
  return ((ssize_t )count);
}
}
static struct file_operations  const  i40e_dbg_dump_fops  = 
     {& __this_module, 0, & i40e_dbg_dump_read, & i40e_dbg_dump_write, 0, 0, 0, 0, 0,
    0, 0, 0, & simple_open, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static char i40e_dbg_command_buf[256U]  = {      '\000'};
static ssize_t i40e_dbg_command_read(struct file *filp , char *buffer , size_t count ,
                                     loff_t *ppos ) 
{ 
  struct i40e_pf *pf ;
  int bytes_not_copied ;
  int buf_size ;
    klee_make_symbolic(&buf_size, sizeof(int), "buf_size");
  char *buf ;
  int len ;
  void *tmp ;
  unsigned long tmp___0 ;

  {
  pf = (struct i40e_pf *)filp->private_data;
  buf_size = 256;
  if (*ppos != 0LL) {
    return (0L);
  } else {

  }
  if ((size_t )buf_size > count) {
    return (-28L);
  } else {

  }
  tmp = kzalloc((size_t )buf_size, 208U);
  buf = (char *)tmp;
  if ((unsigned long )buf == (unsigned long )((char *)0)) {
    return (-28L);
  } else {

  }
  len = snprintf(buf, (size_t )buf_size, "%s: %s\n", (char *)(& ((*(pf->vsi + (unsigned long )pf->lan_vsi))->netdev)->name),
                 (char *)(& i40e_dbg_command_buf));
  tmp___0 = copy_to_user((void *)buffer, (void const   *)buf, (unsigned long )len);
  bytes_not_copied = (int )tmp___0;
  kfree((void const   *)buf);
  if (bytes_not_copied < 0) {
    return ((ssize_t )bytes_not_copied);
  } else {

  }
  *ppos = (loff_t )len;
  return ((ssize_t )len);
}
}
static void i40e_dbg_dump_vsi_seid(struct i40e_pf *pf , int seid ) 
{ 
  struct rtnl_link_stats64 *nstat ;
  struct i40e_mac_filter *f ;
  struct i40e_vsi *vsi ;
  int i ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct i40e_ring *rx_ring ;
  struct i40e_ring *__var ;
  struct i40e_ring *tx_ring ;
  struct i40e_ring *__var___0 ;

  {
  vsi = i40e_dbg_find_vsi(pf, seid);
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "dump %d: seid not found\n",
              seid);
    return;
  } else {

  }
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "vsi seid %d\n", seid);
  if ((unsigned long )vsi->netdev != (unsigned long )((struct net_device *)0)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    netdev: name = %s\n",
              (char *)(& (vsi->netdev)->name));
  } else {

  }
  if ((unsigned long )(& vsi->active_vlans) != (unsigned long )((unsigned long (*)[64])0)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    vlgrp: & = %p\n",
              (unsigned long *)(& vsi->active_vlans));
  } else {

  }
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    netdev_registered = %i, current_netdev_flags = 0x%04x, state = %li flags = 0x%08lx\n",
            (int )vsi->netdev_registered, vsi->current_netdev_flags, vsi->state, vsi->flags);
  if ((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) == (unsigned long )vsi) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "MAC address: %pM SAN MAC: %pM Port MAC: %pM\n",
              (u8 *)(& pf->hw.mac.addr), (u8 *)(& pf->hw.mac.san_addr), (u8 *)(& pf->hw.mac.port_addr));
  } else {

  }
  __mptr = (struct list_head  const  *)vsi->mac_filter_list.next;
  f = (struct i40e_mac_filter *)__mptr;
  goto ldv_61238;
  ldv_61237: 
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    mac_filter_list: %pM vid=%d, is_netdev=%d is_vf=%d counter=%d\n",
            (u8 *)(& f->macaddr), (int )f->vlan, (int )f->is_netdev, (int )f->is_vf,
            (int )f->counter);
  __mptr___0 = (struct list_head  const  *)f->list.next;
  f = (struct i40e_mac_filter *)__mptr___0;
  ldv_61238: ;
  if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
    goto ldv_61237;
  } else {

  }
  nstat = i40e_get_vsi_stats_struct(vsi);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats: rx_packets = %lu, rx_bytes = %lu, rx_errors = %lu, rx_dropped = %lu\n",
            (unsigned long )nstat->rx_packets, (unsigned long )nstat->rx_bytes, (unsigned long )nstat->rx_errors,
            (unsigned long )nstat->rx_dropped);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats: tx_packets = %lu, tx_bytes = %lu, tx_errors = %lu, tx_dropped = %lu\n",
            (unsigned long )nstat->tx_packets, (unsigned long )nstat->tx_bytes, (unsigned long )nstat->tx_errors,
            (unsigned long )nstat->tx_dropped);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats: multicast = %lu, collisions = %lu\n",
            (unsigned long )nstat->multicast, (unsigned long )nstat->collisions);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats: rx_length_errors = %lu, rx_over_errors = %lu, rx_crc_errors = %lu\n",
            (unsigned long )nstat->rx_length_errors, (unsigned long )nstat->rx_over_errors,
            (unsigned long )nstat->rx_crc_errors);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats: rx_frame_errors = %lu, rx_fifo_errors = %lu, rx_missed_errors = %lu\n",
            (unsigned long )nstat->rx_frame_errors, (unsigned long )nstat->rx_fifo_errors,
            (unsigned long )nstat->rx_missed_errors);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats: tx_aborted_errors = %lu, tx_carrier_errors = %lu, tx_fifo_errors = %lu\n",
            (unsigned long )nstat->tx_aborted_errors, (unsigned long )nstat->tx_carrier_errors,
            (unsigned long )nstat->tx_fifo_errors);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats: tx_heartbeat_errors = %lu, tx_window_errors = %lu\n",
            (unsigned long )nstat->tx_heartbeat_errors, (unsigned long )nstat->tx_window_errors);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats: rx_compressed = %lu, tx_compressed = %lu\n",
            (unsigned long )nstat->rx_compressed, (unsigned long )nstat->tx_compressed);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats_offsets: rx_packets = %lu, rx_bytes = %lu, rx_errors = %lu, rx_dropped = %lu\n",
            (unsigned long )vsi->net_stats_offsets.rx_packets, (unsigned long )vsi->net_stats_offsets.rx_bytes,
            (unsigned long )vsi->net_stats_offsets.rx_errors, (unsigned long )vsi->net_stats_offsets.rx_dropped);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats_offsets: tx_packets = %lu, tx_bytes = %lu, tx_errors = %lu, tx_dropped = %lu\n",
            (unsigned long )vsi->net_stats_offsets.tx_packets, (unsigned long )vsi->net_stats_offsets.tx_bytes,
            (unsigned long )vsi->net_stats_offsets.tx_errors, (unsigned long )vsi->net_stats_offsets.tx_dropped);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats_offsets: multicast = %lu, collisions = %lu\n",
            (unsigned long )vsi->net_stats_offsets.multicast, (unsigned long )vsi->net_stats_offsets.collisions);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats_offsets: rx_length_errors = %lu, rx_over_errors = %lu, rx_crc_errors = %lu\n",
            (unsigned long )vsi->net_stats_offsets.rx_length_errors, (unsigned long )vsi->net_stats_offsets.rx_over_errors,
            (unsigned long )vsi->net_stats_offsets.rx_crc_errors);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats_offsets: rx_frame_errors = %lu, rx_fifo_errors = %lu, rx_missed_errors = %lu\n",
            (unsigned long )vsi->net_stats_offsets.rx_frame_errors, (unsigned long )vsi->net_stats_offsets.rx_fifo_errors,
            (unsigned long )vsi->net_stats_offsets.rx_missed_errors);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats_offsets: tx_aborted_errors = %lu, tx_carrier_errors = %lu, tx_fifo_errors = %lu\n",
            (unsigned long )vsi->net_stats_offsets.tx_aborted_errors, (unsigned long )vsi->net_stats_offsets.tx_carrier_errors,
            (unsigned long )vsi->net_stats_offsets.tx_fifo_errors);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats_offsets: tx_heartbeat_errors = %lu, tx_window_errors = %lu\n",
            (unsigned long )vsi->net_stats_offsets.tx_heartbeat_errors, (unsigned long )vsi->net_stats_offsets.tx_window_errors);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    net_stats_offsets: rx_compressed = %lu, tx_compressed = %lu\n",
            (unsigned long )vsi->net_stats_offsets.rx_compressed, (unsigned long )vsi->net_stats_offsets.tx_compressed);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tx_restart = %d, tx_busy = %d, rx_buf_failed = %d, rx_page_failed = %d\n",
            vsi->tx_restart, vsi->tx_busy, vsi->rx_buf_failed, vsi->rx_page_failed);
  rcu_read_lock___1();
  i = 0;
  goto ldv_61245;
  ldv_61244: 
  __var = (struct i40e_ring *)0;
  rx_ring = *((struct i40e_ring * volatile  *)vsi->rx_rings + (unsigned long )i);
  if ((unsigned long )rx_ring == (unsigned long )((struct i40e_ring *)0)) {
    goto ldv_61243;
  } else {

  }
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    rx_rings[%i]: desc = %p\n",
            i, rx_ring->desc);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    rx_rings[%i]: dev = %p, netdev = %p, rx_bi = %p\n",
            i, rx_ring->dev, rx_ring->netdev, rx_ring->__annonCompField121.rx_bi);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    rx_rings[%i]: state = %li, queue_index = %d, reg_idx = %d\n",
            i, rx_ring->state, (int )rx_ring->queue_index, (int )rx_ring->reg_idx);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    rx_rings[%i]: rx_hdr_len = %d, rx_buf_len = %d, dtype = %d\n",
            i, (int )rx_ring->rx_hdr_len, (int )rx_ring->rx_buf_len, (int )rx_ring->dtype);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    rx_rings[%i]: hsplit = %d, next_to_use = %d, next_to_clean = %d, ring_active = %i\n",
            i, (int )rx_ring->hsplit, (int )rx_ring->next_to_use, (int )rx_ring->next_to_clean,
            (int )rx_ring->ring_active);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    rx_rings[%i]: rx_stats: packets = %lld, bytes = %lld, non_eop_descs = %lld\n",
            i, rx_ring->stats.packets, rx_ring->stats.bytes, rx_ring->__annonCompField122.rx_stats.non_eop_descs);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    rx_rings[%i]: rx_stats: alloc_page_failed = %lld, alloc_buff_failed = %lld\n",
            i, rx_ring->__annonCompField122.rx_stats.alloc_page_failed, rx_ring->__annonCompField122.rx_stats.alloc_buff_failed);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    rx_rings[%i]: size = %i, dma = 0x%08lx\n",
            i, rx_ring->size, (unsigned long )rx_ring->dma);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    rx_rings[%i]: vsi = %p, q_vector = %p\n",
            i, rx_ring->vsi, rx_ring->q_vector);
  ldv_61243: 
  i = i + 1;
  ldv_61245: ;
  if ((int )vsi->num_queue_pairs > i) {
    goto ldv_61244;
  } else {

  }
  i = 0;
  goto ldv_61252;
  ldv_61251: 
  __var___0 = (struct i40e_ring *)0;
  tx_ring = *((struct i40e_ring * volatile  *)vsi->tx_rings + (unsigned long )i);
  if ((unsigned long )tx_ring == (unsigned long )((struct i40e_ring *)0)) {
    goto ldv_61250;
  } else {

  }
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tx_rings[%i]: desc = %p\n",
            i, tx_ring->desc);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tx_rings[%i]: dev = %p, netdev = %p, tx_bi = %p\n",
            i, tx_ring->dev, tx_ring->netdev, tx_ring->__annonCompField121.tx_bi);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tx_rings[%i]: state = %li, queue_index = %d, reg_idx = %d\n",
            i, tx_ring->state, (int )tx_ring->queue_index, (int )tx_ring->reg_idx);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tx_rings[%i]: dtype = %d\n",
            i, (int )tx_ring->dtype);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tx_rings[%i]: hsplit = %d, next_to_use = %d, next_to_clean = %d, ring_active = %i\n",
            i, (int )tx_ring->hsplit, (int )tx_ring->next_to_use, (int )tx_ring->next_to_clean,
            (int )tx_ring->ring_active);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tx_rings[%i]: tx_stats: packets = %lld, bytes = %lld, restart_queue = %lld\n",
            i, tx_ring->stats.packets, tx_ring->stats.bytes, tx_ring->__annonCompField122.tx_stats.restart_queue);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tx_rings[%i]: tx_stats: tx_busy = %lld, tx_done_old = %lld\n",
            i, tx_ring->__annonCompField122.tx_stats.tx_busy, tx_ring->__annonCompField122.tx_stats.tx_done_old);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tx_rings[%i]: size = %i, dma = 0x%08lx\n",
            i, tx_ring->size, (unsigned long )tx_ring->dma);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tx_rings[%i]: vsi = %p, q_vector = %p\n",
            i, tx_ring->vsi, tx_ring->q_vector);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tx_rings[%i]: DCB tc = %d\n",
            i, (int )tx_ring->dcb_tc);
  ldv_61250: 
  i = i + 1;
  ldv_61252: ;
  if ((int )vsi->num_queue_pairs > i) {
    goto ldv_61251;
  } else {

  }
  rcu_read_unlock___1();
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    work_limit = %d, rx_itr_setting = %d (%s), tx_itr_setting = %d (%s)\n",
            (int )vsi->work_limit, (int )vsi->rx_itr_setting, (int )((short )vsi->rx_itr_setting) < 0 ? (char *)"dynamic" : (char *)"fixed",
            (int )vsi->tx_itr_setting, (int )((short )vsi->tx_itr_setting) < 0 ? (char *)"dynamic" : (char *)"fixed");
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    max_frame = %d, rx_hdr_len = %d, rx_buf_len = %d dtype = %d\n",
            (int )vsi->max_frame, (int )vsi->rx_hdr_len, (int )vsi->rx_buf_len, (int )vsi->dtype);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    num_q_vectors = %i, base_vector = %i\n",
            vsi->num_q_vectors, vsi->base_vector);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    seid = %d, id = %d, uplink_seid = %d\n",
            (int )vsi->seid, (int )vsi->id, (int )vsi->uplink_seid);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    base_queue = %d, num_queue_pairs = %d, num_desc = %d\n",
            (int )vsi->base_queue, (int )vsi->num_queue_pairs, (int )vsi->num_desc);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    type = %i\n", (unsigned int )vsi->type);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: valid_sections = 0x%04x, switch_id = 0x%04x\n",
            (int )vsi->info.valid_sections, (int )vsi->info.switch_id);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: sw_reserved[] = 0x%02x 0x%02x\n",
            (int )vsi->info.sw_reserved[0], (int )vsi->info.sw_reserved[1]);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: sec_flags = 0x%02x, sec_reserved = 0x%02x\n",
            (int )vsi->info.sec_flags, (int )vsi->info.sec_reserved);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: pvid = 0x%04x, fcoe_pvid = 0x%04x, port_vlan_flags = 0x%02x\n",
            (int )vsi->info.pvid, (int )vsi->info.fcoe_pvid, (int )vsi->info.port_vlan_flags);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: pvlan_reserved[] = 0x%02x 0x%02x 0x%02x\n",
            (int )vsi->info.pvlan_reserved[0], (int )vsi->info.pvlan_reserved[1],
            (int )vsi->info.pvlan_reserved[2]);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: ingress_table = 0x%08x, egress_table = 0x%08x\n",
            vsi->info.ingress_table, vsi->info.egress_table);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: cas_pv_stag = 0x%04x, cas_pv_flags= 0x%02x, cas_pv_reserved = 0x%02x\n",
            (int )vsi->info.cas_pv_tag, (int )vsi->info.cas_pv_flags, (int )vsi->info.cas_pv_reserved);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: queue_mapping[0..7 ] = 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x\n",
            (int )vsi->info.queue_mapping[0], (int )vsi->info.queue_mapping[1], (int )vsi->info.queue_mapping[2],
            (int )vsi->info.queue_mapping[3], (int )vsi->info.queue_mapping[4], (int )vsi->info.queue_mapping[5],
            (int )vsi->info.queue_mapping[6], (int )vsi->info.queue_mapping[7]);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: queue_mapping[8..15] = 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x\n",
            (int )vsi->info.queue_mapping[8], (int )vsi->info.queue_mapping[9], (int )vsi->info.queue_mapping[10],
            (int )vsi->info.queue_mapping[11], (int )vsi->info.queue_mapping[12],
            (int )vsi->info.queue_mapping[13], (int )vsi->info.queue_mapping[14],
            (int )vsi->info.queue_mapping[15]);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: tc_mapping[] = 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x\n",
            (int )vsi->info.tc_mapping[0], (int )vsi->info.tc_mapping[1], (int )vsi->info.tc_mapping[2],
            (int )vsi->info.tc_mapping[3], (int )vsi->info.tc_mapping[4], (int )vsi->info.tc_mapping[5],
            (int )vsi->info.tc_mapping[6], (int )vsi->info.tc_mapping[7]);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: queueing_opt_flags = 0x%02x  queueing_opt_reserved[0..2] = 0x%02x 0x%02x 0x%02x\n",
            (int )vsi->info.queueing_opt_flags, (int )vsi->info.queueing_opt_reserved[0],
            (int )vsi->info.queueing_opt_reserved[1], (int )vsi->info.queueing_opt_reserved[2]);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: up_enable_bits = 0x%02x\n",
            (int )vsi->info.up_enable_bits);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: sched_reserved = 0x%02x, outer_up_table = 0x%04x\n",
            (int )vsi->info.sched_reserved, vsi->info.outer_up_table);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: cmd_reserved[] = 0x%02x 0x%02x 0x%02x 0x0%02x 0x%02x 0x%02x 0x%02x 0x0%02x\n",
            (int )vsi->info.cmd_reserved[0], (int )vsi->info.cmd_reserved[1], (int )vsi->info.cmd_reserved[2],
            (int )vsi->info.cmd_reserved[3], (int )vsi->info.cmd_reserved[4], (int )vsi->info.cmd_reserved[5],
            (int )vsi->info.cmd_reserved[6], (int )vsi->info.cmd_reserved[7]);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: qs_handle[] = 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x 0x%04x\n",
            (int )vsi->info.qs_handle[0], (int )vsi->info.qs_handle[1], (int )vsi->info.qs_handle[2],
            (int )vsi->info.qs_handle[3], (int )vsi->info.qs_handle[4], (int )vsi->info.qs_handle[5],
            (int )vsi->info.qs_handle[6], (int )vsi->info.qs_handle[7]);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: stat_counter_idx = 0x%04x, sched_id = 0x%04x\n",
            (int )vsi->info.stat_counter_idx, (int )vsi->info.sched_id);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    info: resp_reserved[] = 0x%02x 0x%02x 0x%02x 0x%02x 0x%02x 0x%02x 0x%02x 0x%02x 0x%02x 0x%02x 0x%02x 0x%02x\n",
            (int )vsi->info.resp_reserved[0], (int )vsi->info.resp_reserved[1], (int )vsi->info.resp_reserved[2],
            (int )vsi->info.resp_reserved[3], (int )vsi->info.resp_reserved[4], (int )vsi->info.resp_reserved[5],
            (int )vsi->info.resp_reserved[6], (int )vsi->info.resp_reserved[7], (int )vsi->info.resp_reserved[8],
            (int )vsi->info.resp_reserved[9], (int )vsi->info.resp_reserved[10], (int )vsi->info.resp_reserved[11]);
  if ((unsigned long )vsi->back != (unsigned long )((struct i40e_pf *)0)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    PF = %p\n", vsi->back);
  } else {

  }
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    idx = %d\n", (int )vsi->idx);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tc_config: numtc = %d, enabled_tc = 0x%x\n",
            (int )vsi->tc_config.numtc, (int )vsi->tc_config.enabled_tc);
  i = 0;
  goto ldv_61255;
  ldv_61254: 
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tc_config: tc = %d, qoffset = %d, qcount = %d, netdev_tc = %d\n",
            i, (int )vsi->tc_config.tc_info[i].qoffset, (int )vsi->tc_config.tc_info[i].qcount,
            (int )vsi->tc_config.tc_info[i].netdev_tc);
  i = i + 1;
  ldv_61255: ;
  if (i <= 7) {
    goto ldv_61254;
  } else {

  }
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    bw: bw_limit = %d, bw_max_quanta = %d\n",
            (int )vsi->bw_limit, (int )vsi->bw_max_quanta);
  i = 0;
  goto ldv_61258;
  ldv_61257: 
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    bw[%d]: ets_share_credits = %d, ets_limit_credits = %d, max_quanta = %d\n",
            i, (int )vsi->bw_ets_share_credits[i], (int )vsi->bw_ets_limit_credits[i],
            (int )vsi->bw_ets_max_quanta[i]);
  i = i + 1;
  ldv_61258: ;
  if (i <= 7) {
    goto ldv_61257;
  } else {

  }

  if ((unsigned int )vsi->type == 4U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    fcoe_stats: rx_packets = %llu, rx_dwords = %llu, rx_dropped = %llu\n",
              vsi->fcoe_stats.rx_fcoe_packets, vsi->fcoe_stats.rx_fcoe_dwords, vsi->fcoe_stats.rx_fcoe_dropped);
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    fcoe_stats: tx_packets = %llu, tx_dwords = %llu\n",
              vsi->fcoe_stats.tx_fcoe_packets, vsi->fcoe_stats.tx_fcoe_dwords);
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    fcoe_stats: bad_crc = %llu, last_error = %llu\n",
              vsi->fcoe_stats.fcoe_bad_fccrc, vsi->fcoe_stats.fcoe_last_error);
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    fcoe_stats: ddp_count = %llu\n",
              vsi->fcoe_stats.fcoe_ddp_count);
  } else {

  }
  return;
}
}
static void i40e_dbg_dump_aq_desc(struct i40e_pf *pf ) 
{ 
  struct i40e_adminq_ring *ring ;
  struct i40e_hw *hw ;
  char hdr[32U] ;
  int i ;
  char const   *tmp ;
  char const   *tmp___0 ;
  struct i40e_aq_desc *d ;
  struct i40e_aq_desc *d___0 ;

  {
  hw = & pf->hw;
  tmp = dev_name((struct device  const  *)(& (pf->pdev)->dev));
  tmp___0 = dev_driver_string((struct device  const  *)(& (pf->pdev)->dev));
  snprintf((char *)(& hdr), 32UL, "%s %s:         ", tmp___0, tmp);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "AdminQ Tx Ring\n");
  ring = & hw->aq.asq;
  i = 0;
  goto ldv_61269;
  ldv_61268: 
  d = (struct i40e_aq_desc *)ring->desc_buf.va + (unsigned long )i;
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "   at[%02d] flags=0x%04x op=0x%04x dlen=0x%04x ret=0x%04x cookie_h=0x%08x cookie_l=0x%08x\n",
            i, (int )d->flags, (int )d->opcode, (int )d->datalen, (int )d->retval,
            d->cookie_high, d->cookie_low);
  print_hex_dump("\016", (char const   *)(& hdr), 0, 16, 1, (void const   *)(& d->params.raw),
                 16UL, 0);
  i = i + 1;
  ldv_61269: ;
  if ((int )ring->count > i) {
    goto ldv_61268;
  } else {

  }
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "AdminQ Rx Ring\n");
  ring = & hw->aq.arq;
  i = 0;
  goto ldv_61273;
  ldv_61272: 
  d___0 = (struct i40e_aq_desc *)ring->desc_buf.va + (unsigned long )i;
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "   ar[%02d] flags=0x%04x op=0x%04x dlen=0x%04x ret=0x%04x cookie_h=0x%08x cookie_l=0x%08x\n",
            i, (int )d___0->flags, (int )d___0->opcode, (int )d___0->datalen, (int )d___0->retval,
            d___0->cookie_high, d___0->cookie_low);
  print_hex_dump("\016", (char const   *)(& hdr), 0, 16, 1, (void const   *)(& d___0->params.raw),
                 16UL, 0);
  i = i + 1;
  ldv_61273: ;
  if ((int )ring->count > i) {
    goto ldv_61272;
  } else {

  }

  return;
}
}
static void i40e_dbg_dump_desc(int cnt , int vsi_seid , int ring_id , int desc_n ,
                               struct i40e_pf *pf , bool is_rx_ring ) 
{ 
  struct i40e_tx_desc *txd ;
  union i40e_32byte_rx_desc *rxd ;
  struct i40e_ring *ring ;
  struct i40e_vsi *vsi ;
  int i ;
  void *tmp ;

  {
  vsi = i40e_dbg_find_vsi(pf, vsi_seid);
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "vsi %d not found\n",
              vsi_seid);
    return;
  } else {

  }
  if ((int )vsi->num_queue_pairs <= ring_id || ring_id < 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ring %d not found\n",
              ring_id);
    return;
  } else {

  }
  if ((unsigned long )vsi->tx_rings == (unsigned long )((struct i40e_ring **)0) || (unsigned long )(*(vsi->tx_rings))->desc == (unsigned long )((void *)0)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "descriptor rings have not been allocated for vsi %d\n",
              vsi_seid);
    return;
  } else {

  }
  tmp = kmemdup((void const   *)((int )is_rx_ring ? *(vsi->rx_rings + (unsigned long )ring_id) : *(vsi->tx_rings + (unsigned long )ring_id)),
                4096UL, 208U);
  ring = (struct i40e_ring *)tmp;
  if ((unsigned long )ring == (unsigned long )((struct i40e_ring *)0)) {
    return;
  } else {

  }
  if (cnt == 2) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "vsi = %02i %s ring = %02i\n",
              vsi_seid, (int )is_rx_ring ? (char *)"rx" : (char *)"tx", ring_id);
    i = 0;
    goto ldv_61289;
    ldv_61288: ;
    if (! is_rx_ring) {
      txd = (struct i40e_tx_desc *)ring->desc + (unsigned long )i;
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "   d[%03i] = 0x%016llx 0x%016llx\n",
                i, txd->buffer_addr, txd->cmd_type_offset_bsz);
    } else {
      constant_test_bit(5L, (unsigned long const volatile   *)(& ring->state));
      rxd = (union i40e_32byte_rx_desc *)ring->desc + (unsigned long )i;
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "   d[%03i] = 0x%016llx 0x%016llx 0x%016llx 0x%016llx\n",
                i, rxd->read.pkt_addr, rxd->read.hdr_addr, rxd->read.rsvd1, rxd->read.rsvd2);
    }
    i = i + 1;
    ldv_61289: ;
    if ((int )ring->count > i) {
      goto ldv_61288;
    } else {

    }

  } else
  if (cnt == 3) {
    if ((int )ring->count <= desc_n || desc_n < 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "descriptor %d not found\n",
                desc_n);
      goto out;
    } else {

    }
    if (! is_rx_ring) {
      txd = (struct i40e_tx_desc *)ring->desc + (unsigned long )desc_n;
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "vsi = %02i tx ring = %02i d[%03i] = 0x%016llx 0x%016llx\n",
                vsi_seid, ring_id, desc_n, txd->buffer_addr, txd->cmd_type_offset_bsz);
    } else {
      constant_test_bit(5L, (unsigned long const volatile   *)(& ring->state));
      rxd = (union i40e_32byte_rx_desc *)ring->desc + (unsigned long )desc_n;
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "vsi = %02i rx ring = %02i d[%03i] = 0x%016llx 0x%016llx 0x%016llx 0x%016llx\n",
                vsi_seid, ring_id, desc_n, rxd->read.pkt_addr, rxd->read.hdr_addr,
                rxd->read.rsvd1, rxd->read.rsvd2);
    }
  } else {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "dump desc rx/tx <vsi_seid> <ring_id> [<desc_n>]\n");
  }
  out: 
  kfree((void const   *)ring);
  return;
}
}
static void i40e_dbg_dump_vsi_no_seid(struct i40e_pf *pf ) 
{ 
  int i ;

  {
  i = 0;
  goto ldv_61297;
  ldv_61296: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "dump vsi[%d]: %d\n",
              i, (int )(*(pf->vsi + (unsigned long )i))->seid);
  } else {

  }
  i = i + 1;
  ldv_61297: ;
  if ((int )pf->num_alloc_vsi > i) {
    goto ldv_61296;
  } else {

  }

  return;
}
}
static void i40e_dbg_dump_eth_stats(struct i40e_pf *pf , struct i40e_eth_stats *estats ) 
{ 


  {
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "  ethstats:\n");
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    rx_bytes = \t%lld \trx_unicast = \t\t%lld \trx_multicast = \t%lld\n",
            estats->rx_bytes, estats->rx_unicast, estats->rx_multicast);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    rx_broadcast = \t%lld \trx_discards = \t\t%lld\n",
            estats->rx_broadcast, estats->rx_discards);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    rx_unknown_protocol = \t%lld \ttx_bytes = \t%lld\n",
            estats->rx_unknown_protocol, estats->tx_bytes);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tx_unicast = \t%lld \ttx_multicast = \t\t%lld \ttx_broadcast = \t%lld\n",
            estats->tx_unicast, estats->tx_multicast, estats->tx_broadcast);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "    tx_discards = \t%lld \ttx_errors = \t\t%lld\n",
            estats->tx_discards, estats->tx_errors);
  return;
}
}
static void i40e_dbg_dump_veb_seid(struct i40e_pf *pf , int seid ) 
{ 
  struct i40e_veb *veb ;

  {
  if (seid <= 287 || seid > 303) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%d: bad seid\n", seid);
    return;
  } else {

  }
  veb = i40e_dbg_find_veb(pf, seid);
  if ((unsigned long )veb == (unsigned long )((struct i40e_veb *)0)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "can\'t find veb %d\n",
              seid);
    return;
  } else {

  }
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "veb idx=%d,%d stats_ic=%d  seid=%d uplink=%d mode=%s\n",
            (int )veb->idx, (int )veb->veb_idx, (int )veb->stats_idx, (int )veb->seid,
            (int )veb->uplink_seid, (unsigned int )veb->bridge_mode == 1U ? (char *)"VEPA" : (char *)"VEB");
  i40e_dbg_dump_eth_stats(pf, & veb->stats);
  return;
}
}
static void i40e_dbg_dump_veb_all(struct i40e_pf *pf ) 
{ 
  struct i40e_veb *veb ;
  int i ;

  {
  i = 0;
  goto ldv_61314;
  ldv_61313: 
  veb = pf->veb[i];
  if ((unsigned long )veb != (unsigned long )((struct i40e_veb *)0)) {
    i40e_dbg_dump_veb_seid(pf, (int )veb->seid);
  } else {

  }
  i = i + 1;
  ldv_61314: ;
  if (i <= 15) {
    goto ldv_61313;
  } else {

  }

  return;
}
}
static void i40e_dbg_cmd_fd_ctrl(struct i40e_pf *pf , u64 flag , bool enable ) 
{ 


  {
  if ((int )enable) {
    pf->flags = pf->flags | flag;
  } else {
    pf->flags = pf->flags & ~ flag;
    pf->auto_disable_flags = pf->auto_disable_flags | flag;
  }
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "requesting a PF reset\n");
  i40e_do_reset_safe(pf, 4096U);
  return;
}
}
static ssize_t i40e_dbg_command_write(struct file *filp , char const   *buffer , size_t count ,
                                      loff_t *ppos ) 
{ 
  struct i40e_pf *pf ;
  char *cmd_buf ;
  char *cmd_buf_tmp ;
  int bytes_not_copied ;
  struct i40e_vsi *vsi ;
  int vsi_seid ;
    klee_make_symbolic(&vsi_seid, sizeof(int), "vsi_seid");
  int veb_seid ;
    klee_make_symbolic(&veb_seid, sizeof(int), "veb_seid");
  int cnt ;
  void *tmp ;
  unsigned long tmp___0 ;
  struct i40e_veb *veb ;
  int uplink_seid ;
    klee_make_symbolic(&uplink_seid, sizeof(int), "uplink_seid");
  int i ;
  int i___0 ;
    klee_make_symbolic(&i___0, sizeof(int), "i___0");
  struct i40e_mac_filter *f ;
  int vlan ;
    klee_make_symbolic(&vlan, sizeof(int), "vlan");
  u8 ma[6U] ;
  int ret ;
  int vlan___0 ;
    klee_make_symbolic(&vlan___0, sizeof(int), "vlan___0");
  u8 ma___0[6U] ;
  int ret___0 ;
    klee_make_symbolic(&ret___0, sizeof(int), "ret___0");
  i40e_status ret___1 ;
  u16 vid ;
  unsigned int v ;
  int ring_id ;
    klee_make_symbolic(&ring_id, sizeof(int), "ring_id");
  int desc_n ;
    klee_make_symbolic(&desc_n, sizeof(int), "desc_n");
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  struct i40e_aqc_query_port_ets_config_resp *bw_data ;
  struct i40e_dcbx_config *cfg ;
  struct i40e_dcbx_config *r_cfg ;
  int i___1 ;
    klee_make_symbolic(&i___1, sizeof(int), "i___1");
  int ret___2 ;
    klee_make_symbolic(&ret___2, sizeof(int), "ret___2");
  void *tmp___4 ;
  i40e_status tmp___5 ;
  int cluster_id ;
    klee_make_symbolic(&cluster_id, sizeof(int), "cluster_id");
  int table_id ;
    klee_make_symbolic(&table_id, sizeof(int), "table_id");
  int index ;
  int ret___3 ;
    klee_make_symbolic(&ret___3, sizeof(int), "ret___3");
  u16 buff_len ;
  u32 next_index ;
  u8 next_table ;
  u8 *buff ;
  u16 rlen ;
  void *tmp___6 ;
  i40e_status tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;
  int tmp___10 ;
  int tmp___11 ;
  int tmp___12 ;
  int tmp___13 ;
  int tmp___14 ;
  u32 level ;
  u32 address ;
  u32 value ;
  u32 address___0 ;
  u32 value___0 ;
  int i___2 ;
    klee_make_symbolic(&i___2, sizeof(int), "i___2");
  int tmp___15 ;
    klee_make_symbolic(&tmp___15, sizeof(int), "tmp___15");
  int tmp___16 ;
  struct i40e_aq_desc *desc ;
  i40e_status ret___4 ;
  void *tmp___17 ;
  struct i40e_aq_desc *desc___0 ;
  i40e_status ret___5 ;
  u16 buffer_len ;
  u8 *buff___0 ;
  void *tmp___18 ;
  void *tmp___19 ;
  struct i40e_fdir_filter fd_data ;
  u16 packet_len ;
  u16 i___3 ;
  u16 j ;
  char *asc_packet ;
  u8 *raw_packet ;
  bool add ;
  int ret___6 ;
    klee_make_symbolic(&ret___6, sizeof(int), "ret___6");
  int tmp___20 ;
    klee_make_symbolic(&tmp___20, sizeof(int), "tmp___20");
  void *tmp___21 ;
  void *tmp___22 ;
  u16 __min1 ;
  u16 __min2 ;
  u32 tmp___23 ;
  int ret___7 ;
    klee_make_symbolic(&ret___7, sizeof(int), "ret___7");
  i40e_status tmp___24 ;
  i40e_status tmp___25 ;
  int ret___8 ;
    klee_make_symbolic(&ret___8, sizeof(int), "ret___8");
  i40e_status tmp___26 ;
  i40e_status tmp___27 ;
  u16 llen ;
  u16 rlen___0 ;
  int ret___9 ;
    klee_make_symbolic(&ret___9, sizeof(int), "ret___9");
  u8 *buff___1 ;
  void *tmp___28 ;
  i40e_status tmp___29 ;
  u16 llen___0 ;
  u16 rlen___1 ;
  int ret___10 ;
    klee_make_symbolic(&ret___10, sizeof(int), "ret___10");
  u8 *buff___2 ;
  void *tmp___30 ;
  i40e_status tmp___31 ;
  int ret___11 ;
    klee_make_symbolic(&ret___11, sizeof(int), "ret___11");
  i40e_status tmp___32 ;
  int ret___12 ;
    klee_make_symbolic(&ret___12, sizeof(int), "ret___12");
  i40e_status tmp___33 ;
  int tmp___34 ;
    klee_make_symbolic(&tmp___34, sizeof(int), "tmp___34");
  int tmp___35 ;
    klee_make_symbolic(&tmp___35, sizeof(int), "tmp___35");
  int tmp___36 ;
    klee_make_symbolic(&tmp___36, sizeof(int), "tmp___36");
  int tmp___37 ;
    klee_make_symbolic(&tmp___37, sizeof(int), "tmp___37");
  int tmp___38 ;
    klee_make_symbolic(&tmp___38, sizeof(int), "tmp___38");
  int tmp___39 ;
    klee_make_symbolic(&tmp___39, sizeof(int), "tmp___39");
  u16 buffer_len___0 ;
  u16 bytes ;
  u16 module ;
  u32 offset ;
  u16 *buff___3 ;
  int ret___13 ;
    klee_make_symbolic(&ret___13, sizeof(int), "ret___13");
  u16 __min1___0 ;
  u16 __min2___0 ;
  unsigned short _min1 ;
    klee_make_symbolic(&_min1, sizeof(short), "_min1");
  u16 _max1 ;
  unsigned short _max2 ;
    klee_make_symbolic(&_max2, sizeof(short), "_max2");
  unsigned short _min2 ;
    klee_make_symbolic(&_min2, sizeof(short), "_min2");
  void *tmp___40 ;
  i40e_status tmp___41 ;
  i40e_status tmp___42 ;
  int tmp___43 ;
    klee_make_symbolic(&tmp___43, sizeof(int), "tmp___43");
  int tmp___44 ;
    klee_make_symbolic(&tmp___44, sizeof(int), "tmp___44");
  int tmp___45 ;
    klee_make_symbolic(&tmp___45, sizeof(int), "tmp___45");
  int tmp___46 ;
    klee_make_symbolic(&tmp___46, sizeof(int), "tmp___46");
  int tmp___47 ;
    klee_make_symbolic(&tmp___47, sizeof(int), "tmp___47");
  int tmp___48 ;
    klee_make_symbolic(&tmp___48, sizeof(int), "tmp___48");
  int tmp___49 ;
    klee_make_symbolic(&tmp___49, sizeof(int), "tmp___49");
  int tmp___50 ;
    klee_make_symbolic(&tmp___50, sizeof(int), "tmp___50");
  int tmp___51 ;
    klee_make_symbolic(&tmp___51, sizeof(int), "tmp___51");
  int tmp___52 ;
    klee_make_symbolic(&tmp___52, sizeof(int), "tmp___52");
  int tmp___53 ;
    klee_make_symbolic(&tmp___53, sizeof(int), "tmp___53");
  int tmp___54 ;
    klee_make_symbolic(&tmp___54, sizeof(int), "tmp___54");
  int tmp___55 ;
    klee_make_symbolic(&tmp___55, sizeof(int), "tmp___55");
  int tmp___56 ;
    klee_make_symbolic(&tmp___56, sizeof(int), "tmp___56");
  int tmp___57 ;
    klee_make_symbolic(&tmp___57, sizeof(int), "tmp___57");
  int tmp___58 ;
    klee_make_symbolic(&tmp___58, sizeof(int), "tmp___58");
  int tmp___59 ;
    klee_make_symbolic(&tmp___59, sizeof(int), "tmp___59");
  int tmp___60 ;
    klee_make_symbolic(&tmp___60, sizeof(int), "tmp___60");
  int tmp___61 ;
    klee_make_symbolic(&tmp___61, sizeof(int), "tmp___61");
  int tmp___62 ;
    klee_make_symbolic(&tmp___62, sizeof(int), "tmp___62");
  int tmp___63 ;
    klee_make_symbolic(&tmp___63, sizeof(int), "tmp___63");
  int tmp___64 ;
    klee_make_symbolic(&tmp___64, sizeof(int), "tmp___64");
  int tmp___65 ;
    klee_make_symbolic(&tmp___65, sizeof(int), "tmp___65");
  int tmp___66 ;
    klee_make_symbolic(&tmp___66, sizeof(int), "tmp___66");
  int tmp___67 ;
    klee_make_symbolic(&tmp___67, sizeof(int), "tmp___67");
  int tmp___68 ;
    klee_make_symbolic(&tmp___68, sizeof(int), "tmp___68");

  {
  pf = (struct i40e_pf *)filp->private_data;
  if (*ppos != 0LL) {
    return (0L);
  } else {

  }
  tmp = kzalloc(count + 1UL, 208U);
  cmd_buf = (char *)tmp;
  if ((unsigned long )cmd_buf == (unsigned long )((char *)0)) {
    return ((ssize_t )count);
  } else {

  }
  tmp___0 = copy_from_user((void *)cmd_buf, (void const   *)buffer, count);
  bytes_not_copied = (int )tmp___0;
  if (bytes_not_copied < 0) {
    kfree((void const   *)cmd_buf);
    return ((ssize_t )bytes_not_copied);
  } else {

  }
  if (bytes_not_copied > 0) {
    count = count - (size_t )bytes_not_copied;
  } else {

  }
  *(cmd_buf + count) = 0;
  cmd_buf_tmp = strchr((char const   *)cmd_buf, 10);
  if ((unsigned long )cmd_buf_tmp != (unsigned long )((char *)0)) {
    *cmd_buf_tmp = 0;
    count = (size_t )(((long )cmd_buf_tmp - (long )cmd_buf) + 1L);
  } else {

  }
  tmp___68 = strncmp((char const   *)cmd_buf, "add vsi", 7UL);
  if (tmp___68 == 0) {
    vsi_seid = -1;
    cnt = sscanf((char const   *)cmd_buf + 7U, "%i", & vsi_seid);
    if (cnt == 0) {
      vsi_seid = (int )(*(pf->vsi + (unsigned long )pf->lan_vsi))->seid;
    } else
    if (vsi_seid < 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add VSI %d: bad vsi seid\n",
                vsi_seid);
      goto command_write_done;
    } else {

    }
    if ((pf->flags & 1099511627776ULL) == 0ULL) {
      pf->flags = pf->flags | 1099511627776ULL;
      i40e_do_reset_safe(pf, 4096U);
    } else {

    }
    vsi = i40e_vsi_setup(pf, 2, (int )((u16 )vsi_seid), 0U);
    if ((unsigned long )vsi != (unsigned long )((struct i40e_vsi *)0)) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "added VSI %d to relay %d\n",
                (int )vsi->seid, (int )vsi->uplink_seid);
    } else {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "\'%s\' failed\n", cmd_buf);
    }
  } else {
    tmp___67 = strncmp((char const   *)cmd_buf, "del vsi", 7UL);
    if (tmp___67 == 0) {
      sscanf((char const   *)cmd_buf + 7U, "%i", & vsi_seid);
      vsi = i40e_dbg_find_vsi(pf, vsi_seid);
      if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "del VSI %d: seid not found\n",
                  vsi_seid);
        goto command_write_done;
      } else {

      }
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "deleting VSI %d\n",
                vsi_seid);
      i40e_vsi_release(vsi);
    } else {
      tmp___66 = strncmp((char const   *)cmd_buf, "add relay", 9UL);
      if (tmp___66 == 0) {
        cnt = sscanf((char const   *)cmd_buf + 9U, "%i %i", & uplink_seid, & vsi_seid);
        if (cnt != 2) {
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add relay: bad command string, cnt=%d\n",
                    cnt);
          goto command_write_done;
        } else
        if (uplink_seid < 0) {
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add relay %d: bad uplink seid\n",
                    uplink_seid);
          goto command_write_done;
        } else {

        }
        vsi = i40e_dbg_find_vsi(pf, vsi_seid);
        if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add relay: VSI %d not found\n",
                    vsi_seid);
          goto command_write_done;
        } else {

        }
        i = 0;
        goto ldv_61341;
        ldv_61340: ;
        if ((unsigned long )pf->veb[i] != (unsigned long )((struct i40e_veb *)0) && (int )(pf->veb[i])->seid == uplink_seid) {
          goto ldv_61339;
        } else {

        }
        i = i + 1;
        ldv_61341: ;
        if (i <= 15) {
          goto ldv_61340;
        } else {

        }
        ldv_61339: ;
        if ((i > 15 && uplink_seid != 0) && (int )pf->mac_seid != uplink_seid) {
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add relay: relay uplink %d not found\n",
                    uplink_seid);
          goto command_write_done;
        } else {

        }
        veb = i40e_veb_setup(pf, 0, (int )((u16 )uplink_seid), (int )((u16 )vsi_seid),
                             (int )vsi->tc_config.enabled_tc);
        if ((unsigned long )veb != (unsigned long )((struct i40e_veb *)0)) {
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "added relay %d\n",
                    (int )veb->seid);
        } else {
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add relay failed\n");
        }
      } else {
        tmp___65 = strncmp((char const   *)cmd_buf, "del relay", 9UL);
        if (tmp___65 == 0) {
          cnt = sscanf((char const   *)cmd_buf + 9U, "%i", & veb_seid);
          if (cnt != 1) {
            _dev_info((struct device  const  *)(& (pf->pdev)->dev), "del relay: bad command string, cnt=%d\n",
                      cnt);
            goto command_write_done;
          } else
          if (veb_seid < 0) {
            _dev_info((struct device  const  *)(& (pf->pdev)->dev), "del relay %d: bad relay seid\n",
                      veb_seid);
            goto command_write_done;
          } else {

          }
          i___0 = 0;
          goto ldv_61345;
          ldv_61344: ;
          if ((unsigned long )pf->veb[i___0] != (unsigned long )((struct i40e_veb *)0) && (int )(pf->veb[i___0])->seid == veb_seid) {
            goto ldv_61343;
          } else {

          }
          i___0 = i___0 + 1;
          ldv_61345: ;
          if (i___0 <= 15) {
            goto ldv_61344;
          } else {

          }
          ldv_61343: ;
          if (i___0 > 15) {
            _dev_info((struct device  const  *)(& (pf->pdev)->dev), "del relay: relay %d not found\n",
                      veb_seid);
            goto command_write_done;
          } else {

          }
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "deleting relay %d\n",
                    veb_seid);
          i40e_veb_release(pf->veb[i___0]);
        } else {
          tmp___64 = strncmp((char const   *)cmd_buf, "add macaddr", 11UL);
          if (tmp___64 == 0) {
            vlan = 0;
            cnt = sscanf((char const   *)cmd_buf + 11U, "%i %hhx:%hhx:%hhx:%hhx:%hhx:%hhx %i",
                         & vsi_seid, (u8 *)(& ma), (u8 *)(& ma) + 1UL, (u8 *)(& ma) + 2UL,
                         (u8 *)(& ma) + 3UL, (u8 *)(& ma) + 4UL, (u8 *)(& ma) + 5UL,
                         & vlan);
            if (cnt == 7) {
              vlan = 0;
            } else
            if (cnt != 8) {
              _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add macaddr: bad command string, cnt=%d\n",
                        cnt);
              goto command_write_done;
            } else {

            }
            vsi = i40e_dbg_find_vsi(pf, vsi_seid);
            if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
              _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add macaddr: VSI %d not found\n",
                        vsi_seid);
              goto command_write_done;
            } else {

            }
            f = i40e_add_filter(vsi, (u8 *)(& ma), (int )((s16 )vlan), 0, 0);
            ret = i40e_sync_vsi_filters(vsi);
            if ((unsigned long )f != (unsigned long )((struct i40e_mac_filter *)0) && ret == 0) {
              _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add macaddr: %pM vlan=%d added to VSI %d\n",
                        (u8 *)(& ma), vlan, vsi_seid);
            } else {
              _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add macaddr: %pM vlan=%d to VSI %d failed, f=%p ret=%d\n",
                        (u8 *)(& ma), vlan, vsi_seid, f, ret);
            }
          } else {
            tmp___63 = strncmp((char const   *)cmd_buf, "del macaddr", 11UL);
            if (tmp___63 == 0) {
              vlan___0 = 0;
              cnt = sscanf((char const   *)cmd_buf + 11U, "%i %hhx:%hhx:%hhx:%hhx:%hhx:%hhx %i",
                           & vsi_seid, (u8 *)(& ma___0), (u8 *)(& ma___0) + 1UL, (u8 *)(& ma___0) + 2UL,
                           (u8 *)(& ma___0) + 3UL, (u8 *)(& ma___0) + 4UL, (u8 *)(& ma___0) + 5UL,
                           & vlan___0);
              if (cnt == 7) {
                vlan___0 = 0;
              } else
              if (cnt != 8) {
                _dev_info((struct device  const  *)(& (pf->pdev)->dev), "del macaddr: bad command string, cnt=%d\n",
                          cnt);
                goto command_write_done;
              } else {

              }
              vsi = i40e_dbg_find_vsi(pf, vsi_seid);
              if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
                _dev_info((struct device  const  *)(& (pf->pdev)->dev), "del macaddr: VSI %d not found\n",
                          vsi_seid);
                goto command_write_done;
              } else {

              }
              i40e_del_filter(vsi, (u8 *)(& ma___0), (int )((s16 )vlan___0), 0, 0);
              ret___0 = i40e_sync_vsi_filters(vsi);
              if (ret___0 == 0) {
                _dev_info((struct device  const  *)(& (pf->pdev)->dev), "del macaddr: %pM vlan=%d removed from VSI %d\n",
                          (u8 *)(& ma___0), vlan___0, vsi_seid);
              } else {
                _dev_info((struct device  const  *)(& (pf->pdev)->dev), "del macaddr: %pM vlan=%d from VSI %d failed, ret=%d\n",
                          (u8 *)(& ma___0), vlan___0, vsi_seid, ret___0);
              }
            } else {
              tmp___62 = strncmp((char const   *)cmd_buf, "add pvid", 8UL);
              if (tmp___62 == 0) {
                cnt = sscanf((char const   *)cmd_buf + 8U, "%i %u", & vsi_seid, & v);
                if (cnt != 2) {
                  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add pvid: bad command string, cnt=%d\n",
                            cnt);
                  goto command_write_done;
                } else {

                }
                vsi = i40e_dbg_find_vsi(pf, vsi_seid);
                if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
                  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add pvid: VSI %d not found\n",
                            vsi_seid);
                  goto command_write_done;
                } else {

                }
                vid = (u16 )v;
                ret___1 = i40e_vsi_add_pvid(vsi, (int )vid);
                if ((int )ret___1 == 0) {
                  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add pvid: %d added to VSI %d\n",
                            (int )vid, vsi_seid);
                } else {
                  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "add pvid: %d to VSI %d failed, ret=%d\n",
                            (int )vid, vsi_seid, (int )ret___1);
                }
              } else {
                tmp___61 = strncmp((char const   *)cmd_buf, "del pvid", 8UL);
                if (tmp___61 == 0) {
                  cnt = sscanf((char const   *)cmd_buf + 8U, "%i", & vsi_seid);
                  if (cnt != 1) {
                    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "del pvid: bad command string, cnt=%d\n",
                              cnt);
                    goto command_write_done;
                  } else {

                  }
                  vsi = i40e_dbg_find_vsi(pf, vsi_seid);
                  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
                    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "del pvid: VSI %d not found\n",
                              vsi_seid);
                    goto command_write_done;
                  } else {

                  }
                  i40e_vsi_remove_pvid(vsi);
                  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "del pvid: removed from VSI %d\n",
                            vsi_seid);
                } else {
                  tmp___60 = strncmp((char const   *)cmd_buf, "dump", 4UL);
                  if (tmp___60 == 0) {
                    tmp___14 = strncmp((char const   *)cmd_buf + 5U, "switch", 6UL);
                    if (tmp___14 == 0) {
                      i40e_fetch_switch_configuration(pf, 1);
                    } else {
                      tmp___13 = strncmp((char const   *)cmd_buf + 5U, "vsi", 3UL);
                      if (tmp___13 == 0) {
                        cnt = sscanf((char const   *)cmd_buf + 8U, "%i", & vsi_seid);
                        if (cnt > 0) {
                          i40e_dbg_dump_vsi_seid(pf, vsi_seid);
                        } else {
                          i40e_dbg_dump_vsi_no_seid(pf);
                        }
                      } else {
                        tmp___12 = strncmp((char const   *)cmd_buf + 5U, "veb", 3UL);
                        if (tmp___12 == 0) {
                          cnt = sscanf((char const   *)cmd_buf + 8U, "%i", & vsi_seid);
                          if (cnt > 0) {
                            i40e_dbg_dump_veb_seid(pf, vsi_seid);
                          } else {
                            i40e_dbg_dump_veb_all(pf);
                          }
                        } else {
                          tmp___11 = strncmp((char const   *)cmd_buf + 5U, "desc",
                                             4UL);
                          if (tmp___11 == 0) {
                            tmp___3 = strncmp((char const   *)cmd_buf + 10U, "rx",
                                              2UL);
                            if (tmp___3 == 0) {
                              cnt = sscanf((char const   *)cmd_buf + 12U, "%i %i %i",
                                           & vsi_seid, & ring_id, & desc_n);
                              i40e_dbg_dump_desc(cnt, vsi_seid, ring_id, desc_n, pf,
                                                 1);
                            } else {
                              tmp___2 = strncmp((char const   *)cmd_buf + 10U, "tx",
                                                2UL);
                              if (tmp___2 == 0) {
                                cnt = sscanf((char const   *)cmd_buf + 12U, "%i %i %i",
                                             & vsi_seid, & ring_id, & desc_n);
                                i40e_dbg_dump_desc(cnt, vsi_seid, ring_id, desc_n,
                                                   pf, 0);
                              } else {
                                tmp___1 = strncmp((char const   *)cmd_buf + 10U, "aq",
                                                  2UL);
                                if (tmp___1 == 0) {
                                  i40e_dbg_dump_aq_desc(pf);
                                } else {
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "dump desc tx <vsi_seid> <ring_id> [<desc_n>]\n");
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "dump desc rx <vsi_seid> <ring_id> [<desc_n>]\n");
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "dump desc aq\n");
                                }
                              }
                            }
                          } else {
                            tmp___10 = strncmp((char const   *)cmd_buf + 5U, "reset stats",
                                               11UL);
                            if (tmp___10 == 0) {
                              _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                        "core reset count: %d\n", (int )pf->corer_count);
                              _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                        "global reset count: %d\n", (int )pf->globr_count);
                              _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                        "emp reset count: %d\n", (int )pf->empr_count);
                              _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                        "pf reset count: %d\n", (int )pf->pfr_count);
                              _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                        "pf tx sluggish count: %d\n", pf->tx_sluggish_count);
                            } else {
                              tmp___9 = strncmp((char const   *)cmd_buf + 5U, "port",
                                                4UL);
                              if (tmp___9 == 0) {
                                cfg = & pf->hw.local_dcbx_config;
                                r_cfg = & pf->hw.remote_dcbx_config;
                                tmp___4 = kzalloc(68UL, 208U);
                                bw_data = (struct i40e_aqc_query_port_ets_config_resp *)tmp___4;
                                if ((unsigned long )bw_data == (unsigned long )((struct i40e_aqc_query_port_ets_config_resp *)0)) {
                                  ret___2 = -12;
                                  goto command_write_done;
                                } else {

                                }
                                tmp___5 = i40e_aq_query_port_ets_config(& pf->hw,
                                                                        (int )pf->mac_seid,
                                                                        bw_data, (struct i40e_asq_cmd_details *)0);
                                ret___2 = (int )tmp___5;
                                if (ret___2 != 0) {
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "Query Port ETS Config AQ command failed =0x%x\n",
                                            (unsigned int )pf->hw.aq.asq_last_status);
                                  kfree((void const   *)bw_data);
                                  bw_data = (struct i40e_aqc_query_port_ets_config_resp *)0;
                                  goto command_write_done;
                                } else {

                                }
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "port bw: tc_valid=0x%x tc_strict_prio=0x%x, tc_bw_max=0x%04x,0x%04x\n",
                                          (int )bw_data->tc_valid_bits, (int )bw_data->tc_strict_priority_bits,
                                          (int )bw_data->tc_bw_max[0], (int )bw_data->tc_bw_max[1]);
                                i___1 = 0;
                                goto ldv_61364;
                                ldv_61363: 
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "port bw: tc_bw_share=%d tc_bw_limit=%d\n",
                                          (int )bw_data->tc_bw_share_credits[i___1],
                                          (int )bw_data->tc_bw_limits[i___1]);
                                i___1 = i___1 + 1;
                                ldv_61364: ;
                                if (i___1 <= 7) {
                                  goto ldv_61363;
                                } else {

                                }
                                kfree((void const   *)bw_data);
                                bw_data = (struct i40e_aqc_query_port_ets_config_resp *)0;
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "port dcbx_mode=%d\n", (int )cfg->dcbx_mode);
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "port ets_cfg: willing=%d cbs=%d, maxtcs=%d\n",
                                          (int )cfg->etscfg.willing, (int )cfg->etscfg.cbs,
                                          (int )cfg->etscfg.maxtcs);
                                i___1 = 0;
                                goto ldv_61367;
                                ldv_61366: 
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "port ets_cfg: %d prio_tc=%d tcbw=%d tctsa=%d\n",
                                          i___1, (int )cfg->etscfg.prioritytable[i___1],
                                          (int )cfg->etscfg.tcbwtable[i___1], (int )cfg->etscfg.tsatable[i___1]);
                                i___1 = i___1 + 1;
                                ldv_61367: ;
                                if (i___1 <= 7) {
                                  goto ldv_61366;
                                } else {

                                }
                                i___1 = 0;
                                goto ldv_61370;
                                ldv_61369: 
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "port ets_rec: %d prio_tc=%d tcbw=%d tctsa=%d\n",
                                          i___1, (int )cfg->etsrec.prioritytable[i___1],
                                          (int )cfg->etsrec.tcbwtable[i___1], (int )cfg->etsrec.tsatable[i___1]);
                                i___1 = i___1 + 1;
                                ldv_61370: ;
                                if (i___1 <= 7) {
                                  goto ldv_61369;
                                } else {

                                }
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "port pfc_cfg: willing=%d mbc=%d, pfccap=%d pfcenable=0x%x\n",
                                          (int )cfg->pfc.willing, (int )cfg->pfc.mbc,
                                          (int )cfg->pfc.pfccap, (int )cfg->pfc.pfcenable);
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "port app_table: num_apps=%d\n", cfg->numapps);
                                i___1 = 0;
                                goto ldv_61373;
                                ldv_61372: 
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "port app_table: %d prio=%d selector=%d protocol=0x%x\n",
                                          i___1, (int )cfg->app[i___1].priority, (int )cfg->app[i___1].selector,
                                          (int )cfg->app[i___1].protocolid);
                                i___1 = i___1 + 1;
                                ldv_61373: ;
                                if ((u32 )i___1 < cfg->numapps) {
                                  goto ldv_61372;
                                } else {

                                }
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "remote port ets_cfg: willing=%d cbs=%d, maxtcs=%d\n",
                                          (int )r_cfg->etscfg.willing, (int )r_cfg->etscfg.cbs,
                                          (int )r_cfg->etscfg.maxtcs);
                                i___1 = 0;
                                goto ldv_61376;
                                ldv_61375: 
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "remote port ets_cfg: %d prio_tc=%d tcbw=%d tctsa=%d\n",
                                          i___1, (int )r_cfg->etscfg.prioritytable[i___1],
                                          (int )r_cfg->etscfg.tcbwtable[i___1], (int )r_cfg->etscfg.tsatable[i___1]);
                                i___1 = i___1 + 1;
                                ldv_61376: ;
                                if (i___1 <= 7) {
                                  goto ldv_61375;
                                } else {

                                }
                                i___1 = 0;
                                goto ldv_61379;
                                ldv_61378: 
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "remote port ets_rec: %d prio_tc=%d tcbw=%d tctsa=%d\n",
                                          i___1, (int )r_cfg->etsrec.prioritytable[i___1],
                                          (int )r_cfg->etsrec.tcbwtable[i___1], (int )r_cfg->etsrec.tsatable[i___1]);
                                i___1 = i___1 + 1;
                                ldv_61379: ;
                                if (i___1 <= 7) {
                                  goto ldv_61378;
                                } else {

                                }
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "remote port pfc_cfg: willing=%d mbc=%d, pfccap=%d pfcenable=0x%x\n",
                                          (int )r_cfg->pfc.willing, (int )r_cfg->pfc.mbc,
                                          (int )r_cfg->pfc.pfccap, (int )r_cfg->pfc.pfcenable);
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "remote port app_table: num_apps=%d\n",
                                          r_cfg->numapps);
                                i___1 = 0;
                                goto ldv_61382;
                                ldv_61381: 
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "remote port app_table: %d prio=%d selector=%d protocol=0x%x\n",
                                          i___1, (int )r_cfg->app[i___1].priority,
                                          (int )r_cfg->app[i___1].selector, (int )r_cfg->app[i___1].protocolid);
                                i___1 = i___1 + 1;
                                ldv_61382: ;
                                if ((u32 )i___1 < r_cfg->numapps) {
                                  goto ldv_61381;
                                } else {

                                }

                              } else {
                                tmp___8 = strncmp((char const   *)cmd_buf + 5U, "debug fwdata",
                                                  12UL);
                                if (tmp___8 == 0) {
                                  buff_len = 4096U;
                                  cnt = sscanf((char const   *)cmd_buf + 18U, "%i %i %i",
                                               & cluster_id, & table_id, & index);
                                  if (cnt != 3) {
                                    _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                              "dump debug fwdata <cluster_id> <table_id> <index>\n");
                                    goto command_write_done;
                                  } else {

                                  }
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "AQ debug dump fwdata params %x %x %x %x\n",
                                            cluster_id, table_id, index, (int )buff_len);
                                  tmp___6 = kzalloc((size_t )buff_len, 208U);
                                  buff = (u8 *)tmp___6;
                                  if ((unsigned long )buff == (unsigned long )((u8 *)0U)) {
                                    goto command_write_done;
                                  } else {

                                  }
                                  tmp___7 = i40e_aq_debug_dump(& pf->hw, (int )((u8 )cluster_id),
                                                               (int )((u8 )table_id),
                                                               (u32 )index, (int )buff_len,
                                                               (void *)buff, & rlen,
                                                               & next_table, & next_index,
                                                               (struct i40e_asq_cmd_details *)0);
                                  ret___3 = (int )tmp___7;
                                  if (ret___3 != 0) {
                                    _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                              "debug dump fwdata AQ Failed %d 0x%x\n",
                                              ret___3, (unsigned int )pf->hw.aq.asq_last_status);
                                    kfree((void const   *)buff);
                                    buff = (u8 *)0U;
                                    goto command_write_done;
                                  } else {

                                  }
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "AQ debug dump fwdata rlen=0x%x next_table=0x%x next_index=0x%x\n",
                                            (int )rlen, (int )next_table, next_index);
                                  print_hex_dump("\016", "AQ buffer WB: ", 2, 16,
                                                 1, (void const   *)buff, (size_t )rlen,
                                                 1);
                                  kfree((void const   *)buff);
                                  buff = (u8 *)0U;
                                } else {
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "dump desc tx <vsi_seid> <ring_id> [<desc_n>], dump desc rx <vsi_seid> <ring_id> [<desc_n>],\n");
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "dump switch\n");
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "dump vsi [seid]\n");
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "dump reset stats\n");
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "dump port\n");
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "dump debug fwdata <cluster_id> <table_id> <index>\n");
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  } else {
                    tmp___59 = strncmp((char const   *)cmd_buf, "msg_enable", 10UL);
                    if (tmp___59 == 0) {
                      cnt = sscanf((char const   *)cmd_buf + 10U, "%i", & level);
                      if (cnt != 0) {
                        if ((level & 4026531840U) != 0U) {
                          pf->hw.debug_mask = level;
                          _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                    "set hw.debug_mask = 0x%08x\n", pf->hw.debug_mask);
                        } else {

                        }
                        pf->msg_enable = level;
                        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "set msg_enable = 0x%08x\n",
                                  pf->msg_enable);
                      } else {
                        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "msg_enable = 0x%08x\n",
                                  pf->msg_enable);
                      }
                    } else {
                      tmp___58 = strncmp((char const   *)cmd_buf, "pfr", 3UL);
                      if (tmp___58 == 0) {
                        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "debugfs: forcing PFR\n");
                        i40e_do_reset_safe(pf, 4096U);
                      } else {
                        tmp___57 = strncmp((char const   *)cmd_buf, "corer", 5UL);
                        if (tmp___57 == 0) {
                          _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                    "debugfs: forcing CoreR\n");
                          i40e_do_reset_safe(pf, 8192U);
                        } else {
                          tmp___56 = strncmp((char const   *)cmd_buf, "globr", 5UL);
                          if (tmp___56 == 0) {
                            _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                      "debugfs: forcing GlobR\n");
                            i40e_do_reset_safe(pf, 16384U);
                          } else {
                            tmp___55 = strncmp((char const   *)cmd_buf, "empr", 4UL);
                            if (tmp___55 == 0) {
                              _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                        "debugfs: forcing EMPR\n");
                              i40e_do_reset_safe(pf, 32768U);
                            } else {
                              tmp___54 = strncmp((char const   *)cmd_buf, "read",
                                                 4UL);
                              if (tmp___54 == 0) {
                                cnt = sscanf((char const   *)cmd_buf + 4U, "%i", & address);
                                if (cnt != 1) {
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "read <reg>\n");
                                  goto command_write_done;
                                } else {

                                }
                                if (address > 8388607U) {
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "read reg address 0x%08x too large\n",
                                            address);
                                  goto command_write_done;
                                } else {

                                }
                                value = readl((void const volatile   *)pf->hw.hw_addr + (unsigned long )address);
                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                          "read: 0x%08x = 0x%08x\n", address, value);
                              } else {
                                tmp___53 = strncmp((char const   *)cmd_buf, "write",
                                                   5UL);
                                if (tmp___53 == 0) {
                                  cnt = sscanf((char const   *)cmd_buf + 5U, "%i %i",
                                               & address___0, & value___0);
                                  if (cnt != 2) {
                                    _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                              "write <reg> <value>\n");
                                    goto command_write_done;
                                  } else {

                                  }
                                  if (address___0 > 8388607U) {
                                    _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                              "write reg address 0x%08x too large\n",
                                              address___0);
                                    goto command_write_done;
                                  } else {

                                  }
                                  writel(value___0, (void volatile   *)pf->hw.hw_addr + (unsigned long )address___0);
                                  value___0 = readl((void const volatile   *)pf->hw.hw_addr + (unsigned long )address___0);
                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                            "write: 0x%08x = 0x%08x\n", address___0,
                                            value___0);
                                } else {
                                  tmp___52 = strncmp((char const   *)cmd_buf, "clear_stats",
                                                     11UL);
                                  if (tmp___52 == 0) {
                                    tmp___16 = strncmp((char const   *)cmd_buf + 12U,
                                                       "vsi", 3UL);
                                    if (tmp___16 == 0) {
                                      cnt = sscanf((char const   *)cmd_buf + 15U,
                                                   "%i", & vsi_seid);
                                      if (cnt == 0) {
                                        i___2 = 0;
                                        goto ldv_61400;
                                        ldv_61399: 
                                        i40e_vsi_reset_stats(*(pf->vsi + (unsigned long )i___2));
                                        i___2 = i___2 + 1;
                                        ldv_61400: ;
                                        if ((int )pf->num_alloc_vsi > i___2) {
                                          goto ldv_61399;
                                        } else {

                                        }
                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                  "vsi clear stats called for all vsi\'s\n");
                                      } else
                                      if (cnt == 1) {
                                        vsi = i40e_dbg_find_vsi(pf, vsi_seid);
                                        if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
                                          _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                    "clear_stats vsi: bad vsi %d\n",
                                                    vsi_seid);
                                          goto command_write_done;
                                        } else {

                                        }
                                        i40e_vsi_reset_stats(vsi);
                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                  "vsi clear stats called for vsi %d\n",
                                                  vsi_seid);
                                      } else {
                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                  "clear_stats vsi [seid]\n");
                                      }
                                    } else {
                                      tmp___15 = strncmp((char const   *)cmd_buf + 12U,
                                                         "port", 4UL);
                                      if (tmp___15 == 0) {
                                        if ((unsigned int )pf->hw.partition_id == 1U) {
                                          i40e_pf_reset_stats(pf);
                                          _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                    "port stats cleared\n");
                                        } else {
                                          _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                    "clear port stats not allowed on this port partition\n");
                                        }
                                      } else {
                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                  "clear_stats vsi [seid] or clear_stats port\n");
                                      }
                                    }
                                  } else {
                                    tmp___51 = strncmp((char const   *)cmd_buf, "send aq_cmd",
                                                       11UL);
                                    if (tmp___51 == 0) {
                                      tmp___17 = kzalloc(32UL, 208U);
                                      desc = (struct i40e_aq_desc *)tmp___17;
                                      if ((unsigned long )desc == (unsigned long )((struct i40e_aq_desc *)0)) {
                                        goto command_write_done;
                                      } else {

                                      }
                                      cnt = sscanf((char const   *)cmd_buf + 11U,
                                                   "%hi %hi %hi %hi %i %i %i %i %i %i",
                                                   & desc->flags, & desc->opcode,
                                                   & desc->datalen, & desc->retval,
                                                   & desc->cookie_high, & desc->cookie_low,
                                                   & desc->params.internal.param0,
                                                   & desc->params.internal.param1,
                                                   & desc->params.internal.param2,
                                                   & desc->params.internal.param3);
                                      if (cnt != 10) {
                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                  "send aq_cmd: bad command string, cnt=%d\n",
                                                  cnt);
                                        kfree((void const   *)desc);
                                        desc = (struct i40e_aq_desc *)0;
                                        goto command_write_done;
                                      } else {

                                      }
                                      ret___4 = i40e_asq_send_command(& pf->hw, desc,
                                                                      (void *)0, 0,
                                                                      (struct i40e_asq_cmd_details *)0);
                                      if ((int )ret___4 == 0) {
                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                  "AQ command sent Status : Success\n");
                                      } else
                                      if ((int )ret___4 == -53) {
                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                  "AQ command send failed Opcode %x AQ Error: %d\n",
                                                  (int )desc->opcode, (unsigned int )pf->hw.aq.asq_last_status);
                                      } else {
                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                  "AQ command send failed Opcode %x Status: %d\n",
                                                  (int )desc->opcode, (int )ret___4);
                                      }
                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                "AQ desc WB 0x%04x 0x%04x 0x%04x 0x%04x 0x%08x 0x%08x 0x%08x 0x%08x 0x%08x 0x%08x\n",
                                                (int )desc->flags, (int )desc->opcode,
                                                (int )desc->datalen, (int )desc->retval,
                                                desc->cookie_high, desc->cookie_low,
                                                desc->params.internal.param0, desc->params.internal.param1,
                                                desc->params.internal.param2, desc->params.internal.param3);
                                      kfree((void const   *)desc);
                                      desc = (struct i40e_aq_desc *)0;
                                    } else {
                                      tmp___50 = strncmp((char const   *)cmd_buf,
                                                         "send indirect aq_cmd", 20UL);
                                      if (tmp___50 == 0) {
                                        tmp___18 = kzalloc(32UL, 208U);
                                        desc___0 = (struct i40e_aq_desc *)tmp___18;
                                        if ((unsigned long )desc___0 == (unsigned long )((struct i40e_aq_desc *)0)) {
                                          goto command_write_done;
                                        } else {

                                        }
                                        cnt = sscanf((char const   *)cmd_buf + 20U,
                                                     "%hi %hi %hi %hi %i %i %i %i %i %i %hi",
                                                     & desc___0->flags, & desc___0->opcode,
                                                     & desc___0->datalen, & desc___0->retval,
                                                     & desc___0->cookie_high, & desc___0->cookie_low,
                                                     & desc___0->params.internal.param0,
                                                     & desc___0->params.internal.param1,
                                                     & desc___0->params.internal.param2,
                                                     & desc___0->params.internal.param3,
                                                     & buffer_len);
                                        if (cnt != 11) {
                                          _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                    "send indirect aq_cmd: bad command string, cnt=%d\n",
                                                    cnt);
                                          kfree((void const   *)desc___0);
                                          desc___0 = (struct i40e_aq_desc *)0;
                                          goto command_write_done;
                                        } else {

                                        }
                                        if ((unsigned int )buffer_len == 0U) {
                                          buffer_len = 1280U;
                                        } else {

                                        }
                                        tmp___19 = kzalloc((size_t )buffer_len, 208U);
                                        buff___0 = (u8 *)tmp___19;
                                        if ((unsigned long )buff___0 == (unsigned long )((u8 *)0U)) {
                                          kfree((void const   *)desc___0);
                                          desc___0 = (struct i40e_aq_desc *)0;
                                          goto command_write_done;
                                        } else {

                                        }
                                        desc___0->flags = (__le16 )((unsigned int )desc___0->flags | 4096U);
                                        ret___5 = i40e_asq_send_command(& pf->hw,
                                                                        desc___0,
                                                                        (void *)buff___0,
                                                                        (int )buffer_len,
                                                                        (struct i40e_asq_cmd_details *)0);
                                        if ((int )ret___5 == 0) {
                                          _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                    "AQ command sent Status : Success\n");
                                        } else
                                        if ((int )ret___5 == -53) {
                                          _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                    "AQ command send failed Opcode %x AQ Error: %d\n",
                                                    (int )desc___0->opcode, (unsigned int )pf->hw.aq.asq_last_status);
                                        } else {
                                          _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                    "AQ command send failed Opcode %x Status: %d\n",
                                                    (int )desc___0->opcode, (int )ret___5);
                                        }
                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                  "AQ desc WB 0x%04x 0x%04x 0x%04x 0x%04x 0x%08x 0x%08x 0x%08x 0x%08x 0x%08x 0x%08x\n",
                                                  (int )desc___0->flags, (int )desc___0->opcode,
                                                  (int )desc___0->datalen, (int )desc___0->retval,
                                                  desc___0->cookie_high, desc___0->cookie_low,
                                                  desc___0->params.internal.param0,
                                                  desc___0->params.internal.param1,
                                                  desc___0->params.internal.param2,
                                                  desc___0->params.internal.param3);
                                        print_hex_dump("\016", "AQ buffer WB: ", 2,
                                                       16, 1, (void const   *)buff___0,
                                                       (size_t )buffer_len, 1);
                                        kfree((void const   *)buff___0);
                                        buff___0 = (u8 *)0U;
                                        kfree((void const   *)desc___0);
                                        desc___0 = (struct i40e_aq_desc *)0;
                                      } else {
                                        tmp___48 = strncmp((char const   *)cmd_buf,
                                                           "add fd_filter", 13UL);
                                        if (tmp___48 == 0) {
                                          goto _L;
                                        } else {
                                          tmp___49 = strncmp((char const   *)cmd_buf,
                                                             "rem fd_filter", 13UL);
                                          if (tmp___49 == 0) {
                                            _L: /* CIL Label */ 
                                            j = 0U;
                                            add = 0;
                                            if ((pf->flags & 2097152ULL) == 0ULL) {
                                              goto command_write_done;
                                            } else {

                                            }
                                            tmp___20 = strncmp((char const   *)cmd_buf,
                                                               "add", 3UL);
                                            if (tmp___20 == 0) {
                                              add = 1;
                                            } else {

                                            }
                                            if ((int )add && (pf->auto_disable_flags & 2097152ULL) != 0ULL) {
                                              goto command_write_done;
                                            } else {

                                            }
                                            tmp___21 = kzalloc(512UL, 208U);
                                            asc_packet = (char *)tmp___21;
                                            if ((unsigned long )asc_packet == (unsigned long )((char *)0)) {
                                              goto command_write_done;
                                            } else {

                                            }
                                            tmp___22 = kzalloc(512UL, 208U);
                                            raw_packet = (u8 *)tmp___22;
                                            if ((unsigned long )raw_packet == (unsigned long )((u8 *)0U)) {
                                              kfree((void const   *)asc_packet);
                                              asc_packet = (char *)0;
                                              goto command_write_done;
                                            } else {

                                            }
                                            cnt = sscanf((char const   *)cmd_buf + 13U,
                                                         "%hx %2hhx %2hhx %hx %2hhx %2hhx %hx %x %hd %511s",
                                                         & fd_data.q_index, & fd_data.flex_off,
                                                         & fd_data.pctype, & fd_data.dest_vsi,
                                                         & fd_data.dest_ctl, & fd_data.fd_status,
                                                         & fd_data.cnt_index, & fd_data.fd_id,
                                                         & packet_len, asc_packet);
                                            if (cnt != 10) {
                                              _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                        "program fd_filter: bad command string, cnt=%d\n",
                                                        cnt);
                                              kfree((void const   *)asc_packet);
                                              asc_packet = (char *)0;
                                              kfree((void const   *)raw_packet);
                                              goto command_write_done;
                                            } else {

                                            }
                                            if ((unsigned int )packet_len == 0U) {
                                              packet_len = 512U;
                                            } else {

                                            }
                                            __min1 = packet_len;
                                            __min2 = 512U;
                                            packet_len = (u16 )((int )__min1 < (int )__min2 ? __min1 : __min2);
                                            i___3 = 0U;
                                            goto ldv_61420;
                                            ldv_61419: 
                                            sscanf((char const   *)asc_packet + (unsigned long )j,
                                                   "%2hhx ", raw_packet + (unsigned long )i___3);
                                            j = (unsigned int )j + 3U;
                                            i___3 = (u16 )((int )i___3 + 1);
                                            ldv_61420: ;
                                            if ((int )i___3 < (int )packet_len) {
                                              goto ldv_61419;
                                            } else {

                                            }
                                            _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                      "FD raw packet dump\n");
                                            print_hex_dump("\016", "FD raw packet: ",
                                                           2, 16, 1, (void const   *)raw_packet,
                                                           (size_t )packet_len, 1);
                                            ret___6 = i40e_program_fdir_filter(& fd_data,
                                                                               raw_packet,
                                                                               pf,
                                                                               (int )add);
                                            if (ret___6 == 0) {
                                              _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                        "Filter command send Status : Success\n");
                                            } else {
                                              _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                        "Filter command send failed %d\n",
                                                        ret___6);
                                            }
                                            kfree((void const   *)raw_packet);
                                            raw_packet = (u8 *)0U;
                                            kfree((void const   *)asc_packet);
                                            asc_packet = (char *)0;
                                          } else {
                                            tmp___47 = strncmp((char const   *)cmd_buf,
                                                               "fd-atr off", 10UL);
                                            if (tmp___47 == 0) {
                                              i40e_dbg_cmd_fd_ctrl(pf, 4194304ULL,
                                                                   0);
                                            } else {
                                              tmp___46 = strncmp((char const   *)cmd_buf,
                                                                 "fd-atr on", 9UL);
                                              if (tmp___46 == 0) {
                                                i40e_dbg_cmd_fd_ctrl(pf, 4194304ULL,
                                                                     1);
                                              } else {
                                                tmp___45 = strncmp((char const   *)cmd_buf,
                                                                   "fd current cnt",
                                                                   14UL);
                                                if (tmp___45 == 0) {
                                                  tmp___23 = i40e_get_current_fd_count(pf);
                                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                            "FD current total filter count for this interface: %d\n",
                                                            tmp___23);
                                                } else {
                                                  tmp___44 = strncmp((char const   *)cmd_buf,
                                                                     "lldp", 4UL);
                                                  if (tmp___44 == 0) {
                                                    tmp___39 = strncmp((char const   *)cmd_buf + 5U,
                                                                       "stop", 4UL);
                                                    if (tmp___39 == 0) {
                                                      tmp___24 = i40e_aq_stop_lldp(& pf->hw,
                                                                                   0,
                                                                                   (struct i40e_asq_cmd_details *)0);
                                                      ret___7 = (int )tmp___24;
                                                      if (ret___7 != 0) {
                                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                  "Stop LLDP AQ command failed =0x%x\n",
                                                                  (unsigned int )pf->hw.aq.asq_last_status);
                                                        goto command_write_done;
                                                      } else {

                                                      }
                                                      tmp___25 = i40e_aq_add_rem_control_packet_filter(& pf->hw,
                                                                                                       (u8 *)(& pf->hw.mac.addr),
                                                                                                       35020,
                                                                                                       0,
                                                                                                       (int )(*(pf->vsi + (unsigned long )pf->lan_vsi))->seid,
                                                                                                       0,
                                                                                                       1,
                                                                                                       (struct i40e_control_filter_stats *)0,
                                                                                                       (struct i40e_asq_cmd_details *)0);
                                                      ret___7 = (int )tmp___25;
                                                      if (ret___7 != 0) {
                                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                  "%s: Add Control Packet Filter AQ command failed =0x%x\n",
                                                                  "i40e_dbg_command_write",
                                                                  (unsigned int )pf->hw.aq.asq_last_status);
                                                        goto command_write_done;
                                                      } else {

                                                      }
                                                      pf->dcbx_cap = 9U;
                                                    } else {
                                                      tmp___38 = strncmp((char const   *)cmd_buf + 5U,
                                                                         "start",
                                                                         5UL);
                                                      if (tmp___38 == 0) {
                                                        tmp___26 = i40e_aq_add_rem_control_packet_filter(& pf->hw,
                                                                                                         (u8 *)(& pf->hw.mac.addr),
                                                                                                         35020,
                                                                                                         0,
                                                                                                         (int )(*(pf->vsi + (unsigned long )pf->lan_vsi))->seid,
                                                                                                         0,
                                                                                                         0,
                                                                                                         (struct i40e_control_filter_stats *)0,
                                                                                                         (struct i40e_asq_cmd_details *)0);
                                                        ret___8 = (int )tmp___26;
                                                        if (ret___8 != 0) {
                                                          _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                    "%s: Remove Control Packet Filter AQ command failed =0x%x\n",
                                                                    "i40e_dbg_command_write",
                                                                    (unsigned int )pf->hw.aq.asq_last_status);
                                                        } else {

                                                        }
                                                        tmp___27 = i40e_aq_start_lldp(& pf->hw,
                                                                                      (struct i40e_asq_cmd_details *)0);
                                                        ret___8 = (int )tmp___27;
                                                        if (ret___8 != 0) {
                                                          _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                    "Start LLDP AQ command failed =0x%x\n",
                                                                    (unsigned int )pf->hw.aq.asq_last_status);
                                                          goto command_write_done;
                                                        } else {

                                                        }
                                                        pf->dcbx_cap = 10U;
                                                      } else {
                                                        tmp___37 = strncmp((char const   *)cmd_buf + 5U,
                                                                           "get local",
                                                                           9UL);
                                                        if (tmp___37 == 0) {
                                                          tmp___28 = kzalloc(1500UL,
                                                                             208U);
                                                          buff___1 = (u8 *)tmp___28;
                                                          if ((unsigned long )buff___1 == (unsigned long )((u8 *)0U)) {
                                                            goto command_write_done;
                                                          } else {

                                                          }
                                                          tmp___29 = i40e_aq_get_lldp_mib(& pf->hw,
                                                                                          0,
                                                                                          0,
                                                                                          (void *)buff___1,
                                                                                          1500,
                                                                                          & llen,
                                                                                          & rlen___0,
                                                                                          (struct i40e_asq_cmd_details *)0);
                                                          ret___9 = (int )tmp___29;
                                                          if (ret___9 != 0) {
                                                            _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                      "Get LLDP MIB (local) AQ command failed =0x%x\n",
                                                                      (unsigned int )pf->hw.aq.asq_last_status);
                                                            kfree((void const   *)buff___1);
                                                            buff___1 = (u8 *)0U;
                                                            goto command_write_done;
                                                          } else {

                                                          }
                                                          _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                    "LLDP MIB (local)\n");
                                                          print_hex_dump("\016", "LLDP MIB (local): ",
                                                                         2, 16, 1,
                                                                         (void const   *)buff___1,
                                                                         1500UL, 1);
                                                          kfree((void const   *)buff___1);
                                                          buff___1 = (u8 *)0U;
                                                        } else {
                                                          tmp___36 = strncmp((char const   *)cmd_buf + 5U,
                                                                             "get remote",
                                                                             10UL);
                                                          if (tmp___36 == 0) {
                                                            tmp___30 = kzalloc(1500UL,
                                                                               208U);
                                                            buff___2 = (u8 *)tmp___30;
                                                            if ((unsigned long )buff___2 == (unsigned long )((u8 *)0U)) {
                                                              goto command_write_done;
                                                            } else {

                                                            }
                                                            tmp___31 = i40e_aq_get_lldp_mib(& pf->hw,
                                                                                            0,
                                                                                            1,
                                                                                            (void *)buff___2,
                                                                                            1500,
                                                                                            & llen___0,
                                                                                            & rlen___1,
                                                                                            (struct i40e_asq_cmd_details *)0);
                                                            ret___10 = (int )tmp___31;
                                                            if (ret___10 != 0) {
                                                              _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                        "Get LLDP MIB (remote) AQ command failed =0x%x\n",
                                                                        (unsigned int )pf->hw.aq.asq_last_status);
                                                              kfree((void const   *)buff___2);
                                                              buff___2 = (u8 *)0U;
                                                              goto command_write_done;
                                                            } else {

                                                            }
                                                            _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                      "LLDP MIB (remote)\n");
                                                            print_hex_dump("\016",
                                                                           "LLDP MIB (remote): ",
                                                                           2, 16,
                                                                           1, (void const   *)buff___2,
                                                                           1500UL,
                                                                           1);
                                                            kfree((void const   *)buff___2);
                                                            buff___2 = (u8 *)0U;
                                                          } else {
                                                            tmp___35 = strncmp((char const   *)cmd_buf + 5U,
                                                                               "event on",
                                                                               8UL);
                                                            if (tmp___35 == 0) {
                                                              tmp___32 = i40e_aq_cfg_lldp_mib_change_event(& pf->hw,
                                                                                                           1,
                                                                                                           (struct i40e_asq_cmd_details *)0);
                                                              ret___11 = (int )tmp___32;
                                                              if (ret___11 != 0) {
                                                                _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                          "Config LLDP MIB Change Event (on) AQ command failed =0x%x\n",
                                                                          (unsigned int )pf->hw.aq.asq_last_status);
                                                                goto command_write_done;
                                                              } else {

                                                              }
                                                            } else {
                                                              tmp___34 = strncmp((char const   *)cmd_buf + 5U,
                                                                                 "event off",
                                                                                 9UL);
                                                              if (tmp___34 == 0) {
                                                                tmp___33 = i40e_aq_cfg_lldp_mib_change_event(& pf->hw,
                                                                                                             0,
                                                                                                             (struct i40e_asq_cmd_details *)0);
                                                                ret___12 = (int )tmp___33;
                                                                if (ret___12 != 0) {
                                                                  _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                            "Config LLDP MIB Change Event (off) AQ command failed =0x%x\n",
                                                                            (unsigned int )pf->hw.aq.asq_last_status);
                                                                  goto command_write_done;
                                                                } else {

                                                                }
                                                              } else {

                                                              }
                                                            }
                                                          }
                                                        }
                                                      }
                                                    }
                                                  } else {
                                                    tmp___43 = strncmp((char const   *)cmd_buf,
                                                                       "nvm read",
                                                                       8UL);
                                                    if (tmp___43 == 0) {
                                                      cnt = sscanf((char const   *)cmd_buf + 8U,
                                                                   "%hx %x %hx", & module,
                                                                   & offset, & buffer_len___0);
                                                      if (cnt == 0) {
                                                        module = 0U;
                                                        offset = 0U;
                                                        buffer_len___0 = 0U;
                                                      } else
                                                      if (cnt == 1) {
                                                        offset = 0U;
                                                        buffer_len___0 = 0U;
                                                      } else
                                                      if (cnt == 2) {
                                                        buffer_len___0 = 0U;
                                                      } else
                                                      if (cnt > 3) {
                                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                  "nvm read: bad command string, cnt=%d\n",
                                                                  cnt);
                                                        goto command_write_done;
                                                      } else {

                                                      }
                                                      __min1___0 = buffer_len___0;
                                                      __min2___0 = 2048U;
                                                      buffer_len___0 = (u16 )((int )__min1___0 < (int )__min2___0 ? __min1___0 : __min2___0);
                                                      bytes = (unsigned int )buffer_len___0 * 2U;
                                                      _max1 = bytes;
                                                      _max2 = 1024U;
                                                      _min1 = (unsigned short )((int )_max1 > (int )_max2 ? (int )_max1 : (int )_max2);
                                                      _min2 = 4096U;
                                                      bytes = (u16 )((int )_min1 < (int )_min2 ? (int )_min1 : (int )_min2);
                                                      tmp___40 = kzalloc((size_t )bytes,
                                                                         208U);
                                                      buff___3 = (u16 *)tmp___40;
                                                      if ((unsigned long )buff___3 == (unsigned long )((u16 *)0U)) {
                                                        goto command_write_done;
                                                      } else {

                                                      }
                                                      tmp___41 = i40e_acquire_nvm(& pf->hw,
                                                                                  1);
                                                      ret___13 = (int )tmp___41;
                                                      if (ret___13 != 0) {
                                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                  "Failed Acquiring NVM resource for read err=%d status=0x%x\n",
                                                                  ret___13, (unsigned int )pf->hw.aq.asq_last_status);
                                                        kfree((void const   *)buff___3);
                                                        goto command_write_done;
                                                      } else {

                                                      }
                                                      tmp___42 = i40e_aq_read_nvm(& pf->hw,
                                                                                  (int )((u8 )module),
                                                                                  offset * 2U,
                                                                                  (int )bytes,
                                                                                  (void *)buff___3,
                                                                                  1,
                                                                                  (struct i40e_asq_cmd_details *)0);
                                                      ret___13 = (int )tmp___42;
                                                      i40e_release_nvm(& pf->hw);
                                                      if (ret___13 != 0) {
                                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                  "Read NVM AQ failed err=%d status=0x%x\n",
                                                                  ret___13, (unsigned int )pf->hw.aq.asq_last_status);
                                                      } else {
                                                        _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                  "Read NVM module=0x%x offset=0x%x words=%d\n",
                                                                  (int )module, offset,
                                                                  (int )buffer_len___0);
                                                        if ((unsigned int )bytes != 0U) {
                                                          print_hex_dump("\016", "NVM Dump: ",
                                                                         2, 16, 2,
                                                                         (void const   *)buff___3,
                                                                         (size_t )bytes,
                                                                         1);
                                                        } else {

                                                        }
                                                      }
                                                      kfree((void const   *)buff___3);
                                                      buff___3 = (u16 *)0U;
                                                    } else {
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "unknown command \'%s\'\n",
                                                                cmd_buf);
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "available commands\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  add vsi [relay_seid]\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  del vsi [vsi_seid]\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  add relay <uplink_seid> <vsi_seid>\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  del relay <relay_seid>\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  add macaddr <vsi_seid> <aa:bb:cc:dd:ee:ff> [vlan]\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  del macaddr <vsi_seid> <aa:bb:cc:dd:ee:ff> [vlan]\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  add pvid <vsi_seid> <vid>\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  del pvid <vsi_seid>\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  dump switch\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  dump vsi [seid]\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  dump desc tx <vsi_seid> <ring_id> [<desc_n>]\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  dump desc rx <vsi_seid> <ring_id> [<desc_n>]\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  dump desc aq\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  dump reset stats\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  dump debug fwdata <cluster_id> <table_id> <index>\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  msg_enable [level]\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  read <reg>\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  write <reg> <value>\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  clear_stats vsi [seid]\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  clear_stats port\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  pfr\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  corer\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  globr\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  send aq_cmd <flags> <opcode> <datalen> <retval> <cookie_h> <cookie_l> <param0> <param1> <param2> <param3>\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  send indirect aq_cmd <flags> <opcode> <datalen> <retval> <cookie_h> <cookie_l> <param0> <param1> <param2> <param3> <buffer_len>\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  add fd_filter <dest q_index> <flex_off> <pctype> <dest_vsi> <dest_ctl> <fd_status> <cnt_index> <fd_id> <packet_len> <packet>\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  rem fd_filter <dest q_index> <flex_off> <pctype> <dest_vsi> <dest_ctl> <fd_status> <cnt_index> <fd_id> <packet_len> <packet>\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  fd-atr off\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  fd-atr on\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  fd current cnt");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  lldp start\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  lldp stop\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  lldp get local\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  lldp get remote\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  lldp event on\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  lldp event off\n");
                                                      _dev_info((struct device  const  *)(& (pf->pdev)->dev),
                                                                "  nvm read [module] [word_offset] [word_count]\n");
                                                    }
                                                  }
                                                }
                                              }
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  }
  command_write_done: 
  kfree((void const   *)cmd_buf);
  cmd_buf = (char *)0;
  return ((ssize_t )count);
}
}
static struct file_operations  const  i40e_dbg_command_fops  = 
     {& __this_module, 0, & i40e_dbg_command_read, & i40e_dbg_command_write, 0, 0, 0,
    0, 0, 0, 0, 0, & simple_open, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static char i40e_dbg_netdev_ops_buf[256U]  = {      '\000'};
static ssize_t i40e_dbg_netdev_ops_read(struct file *filp , char *buffer , size_t count ,
                                        loff_t *ppos ) 
{ 
  struct i40e_pf *pf ;
  int bytes_not_copied ;
  int buf_size ;
  char *buf ;
  int len ;
  void *tmp ;
  unsigned long tmp___0 ;

  {
  pf = (struct i40e_pf *)filp->private_data;
  buf_size = 256;
  if (*ppos != 0LL) {
    return (0L);
  } else {

  }
  if ((size_t )buf_size > count) {
    return (-28L);
  } else {

  }
  tmp = kzalloc((size_t )buf_size, 208U);
  buf = (char *)tmp;
  if ((unsigned long )buf == (unsigned long )((char *)0)) {
    return (-28L);
  } else {

  }
  len = snprintf(buf, (size_t )buf_size, "%s: %s\n", (char *)(& ((*(pf->vsi + (unsigned long )pf->lan_vsi))->netdev)->name),
                 (char *)(& i40e_dbg_netdev_ops_buf));
  tmp___0 = copy_to_user((void *)buffer, (void const   *)buf, (unsigned long )len);
  bytes_not_copied = (int )tmp___0;
  kfree((void const   *)buf);
  if (bytes_not_copied < 0) {
    return ((ssize_t )bytes_not_copied);
  } else {

  }
  *ppos = (loff_t )len;
  return ((ssize_t )len);
}
}
static ssize_t i40e_dbg_netdev_ops_write(struct file *filp , char const   *buffer ,
                                         size_t count , loff_t *ppos ) 
{ 
  struct i40e_pf *pf ;
  int bytes_not_copied ;
  struct i40e_vsi *vsi ;
  char *buf_tmp ;
  int vsi_seid ;
  int i ;
  int cnt ;
  unsigned long tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int mtu ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;

  {
  pf = (struct i40e_pf *)filp->private_data;
  if (*ppos != 0LL) {
    return (0L);
  } else {

  }
  if (count > 255UL) {
    return (-28L);
  } else {

  }
  memset((void *)(& i40e_dbg_netdev_ops_buf), 0, 256UL);
  tmp = copy_from_user((void *)(& i40e_dbg_netdev_ops_buf), (void const   *)buffer,
                       count);
  bytes_not_copied = (int )tmp;
  if (bytes_not_copied < 0) {
    return ((ssize_t )bytes_not_copied);
  } else
  if (bytes_not_copied > 0) {
    count = count - (size_t )bytes_not_copied;
  } else {

  }
  i40e_dbg_netdev_ops_buf[count] = 0;
  buf_tmp = strchr((char const   *)(& i40e_dbg_netdev_ops_buf), 10);
  if ((unsigned long )buf_tmp != (unsigned long )((char *)0)) {
    *buf_tmp = 0;
    count = (size_t )((long )buf_tmp + (1L - (long )(& i40e_dbg_netdev_ops_buf)));
  } else {

  }
  tmp___7 = strncmp((char const   *)(& i40e_dbg_netdev_ops_buf), "tx_timeout", 10UL);
  if (tmp___7 == 0) {
    cnt = sscanf((char const   *)(& i40e_dbg_netdev_ops_buf) + 11U, "%i", & vsi_seid);
    if (cnt != 1) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "tx_timeout <vsi_seid>\n");
      goto netdev_ops_write_done;
    } else {

    }
    vsi = i40e_dbg_find_vsi(pf, vsi_seid);
    if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "tx_timeout: VSI %d not found\n",
                vsi_seid);
    } else
    if ((unsigned long )vsi->netdev == (unsigned long )((struct net_device *)0)) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "tx_timeout: no netdev for VSI %d\n",
                vsi_seid);
    } else {
      tmp___1 = constant_test_bit(3L, (unsigned long const volatile   *)(& vsi->state));
      if (tmp___1 != 0) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "tx_timeout: VSI %d not UP\n",
                  vsi_seid);
      } else {
        tmp___0 = rtnl_trylock();
        if (tmp___0 != 0) {
          (*(((vsi->netdev)->netdev_ops)->ndo_tx_timeout))(vsi->netdev);
          rtnl_unlock();
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "tx_timeout called\n");
        } else {
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Could not acquire RTNL - please try again\n");
        }
      }
    }
  } else {
    tmp___6 = strncmp((char const   *)(& i40e_dbg_netdev_ops_buf), "change_mtu", 10UL);
    if (tmp___6 == 0) {
      cnt = sscanf((char const   *)(& i40e_dbg_netdev_ops_buf) + 11U, "%i %i", & vsi_seid,
                   & mtu);
      if (cnt != 2) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "change_mtu <vsi_seid> <mtu>\n");
        goto netdev_ops_write_done;
      } else {

      }
      vsi = i40e_dbg_find_vsi(pf, vsi_seid);
      if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "change_mtu: VSI %d not found\n",
                  vsi_seid);
      } else
      if ((unsigned long )vsi->netdev == (unsigned long )((struct net_device *)0)) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "change_mtu: no netdev for VSI %d\n",
                  vsi_seid);
      } else {
        tmp___2 = rtnl_trylock();
        if (tmp___2 != 0) {
          (*(((vsi->netdev)->netdev_ops)->ndo_change_mtu))(vsi->netdev, mtu);
          rtnl_unlock();
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "change_mtu called\n");
        } else {
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Could not acquire RTNL - please try again\n");
        }
      }
    } else {
      tmp___5 = strncmp((char const   *)(& i40e_dbg_netdev_ops_buf), "set_rx_mode",
                        11UL);
      if (tmp___5 == 0) {
        cnt = sscanf((char const   *)(& i40e_dbg_netdev_ops_buf) + 11U, "%i", & vsi_seid);
        if (cnt != 1) {
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "set_rx_mode <vsi_seid>\n");
          goto netdev_ops_write_done;
        } else {

        }
        vsi = i40e_dbg_find_vsi(pf, vsi_seid);
        if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "set_rx_mode: VSI %d not found\n",
                    vsi_seid);
        } else
        if ((unsigned long )vsi->netdev == (unsigned long )((struct net_device *)0)) {
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "set_rx_mode: no netdev for VSI %d\n",
                    vsi_seid);
        } else {
          tmp___3 = rtnl_trylock();
          if (tmp___3 != 0) {
            (*(((vsi->netdev)->netdev_ops)->ndo_set_rx_mode))(vsi->netdev);
            rtnl_unlock();
            _dev_info((struct device  const  *)(& (pf->pdev)->dev), "set_rx_mode called\n");
          } else {
            _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Could not acquire RTNL - please try again\n");
          }
        }
      } else {
        tmp___4 = strncmp((char const   *)(& i40e_dbg_netdev_ops_buf), "napi", 4UL);
        if (tmp___4 == 0) {
          cnt = sscanf((char const   *)(& i40e_dbg_netdev_ops_buf) + 4U, "%i", & vsi_seid);
          if (cnt != 1) {
            _dev_info((struct device  const  *)(& (pf->pdev)->dev), "napi <vsi_seid>\n");
            goto netdev_ops_write_done;
          } else {

          }
          vsi = i40e_dbg_find_vsi(pf, vsi_seid);
          if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
            _dev_info((struct device  const  *)(& (pf->pdev)->dev), "napi: VSI %d not found\n",
                      vsi_seid);
          } else
          if ((unsigned long )vsi->netdev == (unsigned long )((struct net_device *)0)) {
            _dev_info((struct device  const  *)(& (pf->pdev)->dev), "napi: no netdev for VSI %d\n",
                      vsi_seid);
          } else {
            i = 0;
            goto ldv_61482;
            ldv_61481: 
            napi_schedule(& (*(vsi->q_vectors + (unsigned long )i))->napi);
            i = i + 1;
            ldv_61482: ;
            if (vsi->num_q_vectors > i) {
              goto ldv_61481;
            } else {

            }
            _dev_info((struct device  const  *)(& (pf->pdev)->dev), "napi called\n");
          }
        } else {
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "unknown command \'%s\'\n",
                    (char *)(& i40e_dbg_netdev_ops_buf));
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "available commands\n");
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "  tx_timeout <vsi_seid>\n");
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "  change_mtu <vsi_seid> <mtu>\n");
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "  set_rx_mode <vsi_seid>\n");
          _dev_info((struct device  const  *)(& (pf->pdev)->dev), "  napi <vsi_seid>\n");
        }
      }
    }
  }
  netdev_ops_write_done: ;
  return ((ssize_t )count);
}
}
static struct file_operations  const  i40e_dbg_netdev_ops_fops  = 
     {& __this_module, 0, & i40e_dbg_netdev_ops_read, & i40e_dbg_netdev_ops_write, 0,
    0, 0, 0, 0, 0, 0, 0, & simple_open, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0};
void i40e_dbg_pf_init(struct i40e_pf *pf ) 
{ 
  struct dentry *pfile ;
  char const   *name ;
  char const   *tmp ;
  struct device  const  *dev ;

  {
  tmp = pci_name((struct pci_dev  const  *)pf->pdev);
  name = tmp;
  dev = (struct device  const  *)(& (pf->pdev)->dev);
  pf->i40e_dbg_pf = debugfs_create_dir(name, i40e_dbg_root);
  if ((unsigned long )pf->i40e_dbg_pf == (unsigned long )((struct dentry *)0)) {
    return;
  } else {

  }
  pfile = debugfs_create_file("command", 384, pf->i40e_dbg_pf, (void *)pf, & i40e_dbg_command_fops);
  if ((unsigned long )pfile == (unsigned long )((struct dentry *)0)) {
    goto create_failed;
  } else {

  }
  pfile = debugfs_create_file("dump", 384, pf->i40e_dbg_pf, (void *)pf, & i40e_dbg_dump_fops);
  if ((unsigned long )pfile == (unsigned long )((struct dentry *)0)) {
    goto create_failed;
  } else {

  }
  pfile = debugfs_create_file("netdev_ops", 384, pf->i40e_dbg_pf, (void *)pf, & i40e_dbg_netdev_ops_fops);
  if ((unsigned long )pfile == (unsigned long )((struct dentry *)0)) {
    goto create_failed;
  } else {

  }
  return;
  create_failed: 
  _dev_info(dev, "debugfs dir/file for %s failed\n", name);
  debugfs_remove_recursive(pf->i40e_dbg_pf);
  return;
}
}
void i40e_dbg_pf_exit(struct i40e_pf *pf ) 
{ 


  {
  debugfs_remove_recursive(pf->i40e_dbg_pf);
  pf->i40e_dbg_pf = (struct dentry *)0;
  kfree((void const   *)i40e_dbg_dump_buf);
  i40e_dbg_dump_buf = (char *)0;
  return;
}
}
void i40e_dbg_init(void) 
{ 


  {
  i40e_dbg_root = debugfs_create_dir((char const   *)(& i40e_driver_name), (struct dentry *)0);
  if ((unsigned long )i40e_dbg_root == (unsigned long )((struct dentry *)0)) {
    printk("\016init of debugfs failed\n");
  } else {

  }
  return;
}
}
void i40e_dbg_exit(void) 
{ 


  {
  debugfs_remove_recursive(i40e_dbg_root);
  i40e_dbg_root = (struct dentry *)0;
  return;
}
}
extern int ldv_release_8(void) ;
int ldv_retval_12  ;
    klee_make_symbolic(&ldv_retval_12, sizeof(int), "ldv_retval_12");
extern int ldv_release_9(void) ;
int ldv_retval_10  ;
    klee_make_symbolic(&ldv_retval_10, sizeof(int), "ldv_retval_10");
int ldv_retval_2  ;
    klee_make_symbolic(&ldv_retval_2, sizeof(int), "ldv_retval_2");
extern int ldv_release_10(void) ;
void ldv_file_operations_9(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
  tmp = ldv_init_zalloc(1000UL);
  i40e_dbg_command_fops_group1 = (struct inode *)tmp;
  tmp___0 = ldv_init_zalloc(504UL);
  i40e_dbg_command_fops_group2 = (struct file *)tmp___0;
  return;
}
}
void ldv_file_operations_10(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
  tmp = ldv_init_zalloc(1000UL);
  i40e_dbg_dump_fops_group1 = (struct inode *)tmp;
  tmp___0 = ldv_init_zalloc(504UL);
  i40e_dbg_dump_fops_group2 = (struct file *)tmp___0;
  return;
}
}
void ldv_file_operations_8(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
  tmp = ldv_init_zalloc(1000UL);
  i40e_dbg_netdev_ops_fops_group1 = (struct inode *)tmp;
  tmp___0 = ldv_init_zalloc(504UL);
  i40e_dbg_netdev_ops_fops_group2 = (struct file *)tmp___0;
  return;
}
}
void ldv_main_exported_8(void) 
{ 
  size_t ldvarg90 ;
  loff_t *ldvarg89 ;
  void *tmp ;
  loff_t *ldvarg92 ;
  void *tmp___0 ;
  char *ldvarg91 ;
  void *tmp___1 ;
  char *ldvarg94 ;
  void *tmp___2 ;
  size_t ldvarg93 ;
  int tmp___3 ;

  {
  tmp = ldv_init_zalloc(8UL);
  ldvarg89 = (loff_t *)tmp;
  tmp___0 = ldv_init_zalloc(8UL);
  ldvarg92 = (loff_t *)tmp___0;
  tmp___1 = ldv_init_zalloc(1UL);
  ldvarg91 = (char *)tmp___1;
  tmp___2 = ldv_init_zalloc(1UL);
  ldvarg94 = (char *)tmp___2;
  ldv_memset((void *)(& ldvarg90), 0, 8UL);
  ldv_memset((void *)(& ldvarg93), 0, 8UL);
  tmp___3 = __VERIFIER_nondet_int();
  switch (tmp___3) {
  case 0: ;
  if (ldv_state_variable_8 == 1) {
    ldv_retval_10 = simple_open(i40e_dbg_netdev_ops_fops_group1, i40e_dbg_netdev_ops_fops_group2);
    if (ldv_retval_10 == 0) {
      ldv_state_variable_8 = 2;
      ref_cnt = ref_cnt + 1;
    } else {

    }
  } else {

  }
  goto ldv_61529;
  case 1: ;
  if (ldv_state_variable_8 == 1) {
    i40e_dbg_netdev_ops_write(i40e_dbg_netdev_ops_fops_group2, (char const   *)ldvarg94,
                              ldvarg93, ldvarg92);
    ldv_state_variable_8 = 1;
  } else {

  }
  if (ldv_state_variable_8 == 2) {
    i40e_dbg_netdev_ops_write(i40e_dbg_netdev_ops_fops_group2, (char const   *)ldvarg94,
                              ldvarg93, ldvarg92);
    ldv_state_variable_8 = 2;
  } else {

  }
  goto ldv_61529;
  case 2: ;
  if (ldv_state_variable_8 == 2) {
    i40e_dbg_netdev_ops_read(i40e_dbg_netdev_ops_fops_group2, ldvarg91, ldvarg90,
                             ldvarg89);
    ldv_state_variable_8 = 2;
  } else {

  }
  goto ldv_61529;
  case 3: ;
  if (ldv_state_variable_8 == 2) {
    ldv_release_8();
    ldv_state_variable_8 = 1;
    ref_cnt = ref_cnt - 1;
  } else {

  }
  goto ldv_61529;
  default: 
  ldv_stop();
  }
  ldv_61529: ;
  return;
}
}
void ldv_main_exported_10(void) 
{ 
  loff_t *ldvarg99 ;
  void *tmp ;
  loff_t *ldvarg96 ;
  void *tmp___0 ;
  size_t ldvarg100 ;
  char *ldvarg101 ;
  void *tmp___1 ;
  size_t ldvarg97 ;
  char *ldvarg98 ;
  void *tmp___2 ;
  int tmp___3 ;

  {
  tmp = ldv_init_zalloc(8UL);
  ldvarg99 = (loff_t *)tmp;
  tmp___0 = ldv_init_zalloc(8UL);
  ldvarg96 = (loff_t *)tmp___0;
  tmp___1 = ldv_init_zalloc(1UL);
  ldvarg101 = (char *)tmp___1;
  tmp___2 = ldv_init_zalloc(1UL);
  ldvarg98 = (char *)tmp___2;
  ldv_memset((void *)(& ldvarg100), 0, 8UL);
  ldv_memset((void *)(& ldvarg97), 0, 8UL);
  tmp___3 = __VERIFIER_nondet_int();
  switch (tmp___3) {
  case 0: ;
  if (ldv_state_variable_10 == 1) {
    ldv_retval_12 = simple_open(i40e_dbg_dump_fops_group1, i40e_dbg_dump_fops_group2);
    if (ldv_retval_12 == 0) {
      ldv_state_variable_10 = 2;
      ref_cnt = ref_cnt + 1;
    } else {

    }
  } else {

  }
  goto ldv_61544;
  case 1: ;
  if (ldv_state_variable_10 == 1) {
    i40e_dbg_dump_write(i40e_dbg_dump_fops_group2, (char const   *)ldvarg101, ldvarg100,
                        ldvarg99);
    ldv_state_variable_10 = 1;
  } else {

  }
  if (ldv_state_variable_10 == 2) {
    i40e_dbg_dump_write(i40e_dbg_dump_fops_group2, (char const   *)ldvarg101, ldvarg100,
                        ldvarg99);
    ldv_state_variable_10 = 2;
  } else {

  }
  goto ldv_61544;
  case 2: ;
  if (ldv_state_variable_10 == 2) {
    i40e_dbg_dump_read(i40e_dbg_dump_fops_group2, ldvarg98, ldvarg97, ldvarg96);
    ldv_state_variable_10 = 2;
  } else {

  }
  goto ldv_61544;
  case 3: ;
  if (ldv_state_variable_10 == 2) {
    ldv_release_10();
    ldv_state_variable_10 = 1;
    ref_cnt = ref_cnt - 1;
  } else {

  }
  goto ldv_61544;
  default: 
  ldv_stop();
  }
  ldv_61544: ;
  return;
}
}
void ldv_main_exported_9(void) 
{ 
  char *ldvarg46 ;
  void *tmp ;
  loff_t *ldvarg47 ;
  void *tmp___0 ;
  loff_t *ldvarg44 ;
  void *tmp___1 ;
  char *ldvarg49 ;
  void *tmp___2 ;
  size_t ldvarg45 ;
  size_t ldvarg48 ;
  int tmp___3 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg46 = (char *)tmp;
  tmp___0 = ldv_init_zalloc(8UL);
  ldvarg47 = (loff_t *)tmp___0;
  tmp___1 = ldv_init_zalloc(8UL);
  ldvarg44 = (loff_t *)tmp___1;
  tmp___2 = ldv_init_zalloc(1UL);
  ldvarg49 = (char *)tmp___2;
  ldv_memset((void *)(& ldvarg45), 0, 8UL);
  ldv_memset((void *)(& ldvarg48), 0, 8UL);
  tmp___3 = __VERIFIER_nondet_int();
  switch (tmp___3) {
  case 0: ;
  if (ldv_state_variable_9 == 1) {
    ldv_retval_2 = simple_open(i40e_dbg_command_fops_group1, i40e_dbg_command_fops_group2);
    if (ldv_retval_2 == 0) {
      ldv_state_variable_9 = 2;
      ref_cnt = ref_cnt + 1;
    } else {

    }
  } else {

  }
  goto ldv_61559;
  case 1: ;
  if (ldv_state_variable_9 == 1) {
    i40e_dbg_command_write(i40e_dbg_command_fops_group2, (char const   *)ldvarg49,
                           ldvarg48, ldvarg47);
    ldv_state_variable_9 = 1;
  } else {

  }
  if (ldv_state_variable_9 == 2) {
    i40e_dbg_command_write(i40e_dbg_command_fops_group2, (char const   *)ldvarg49,
                           ldvarg48, ldvarg47);
    ldv_state_variable_9 = 2;
  } else {

  }
  goto ldv_61559;
  case 2: ;
  if (ldv_state_variable_9 == 2) {
    i40e_dbg_command_read(i40e_dbg_command_fops_group2, ldvarg46, ldvarg45, ldvarg44);
    ldv_state_variable_9 = 2;
  } else {

  }
  goto ldv_61559;
  case 3: ;
  if (ldv_state_variable_9 == 2) {
    ldv_release_9();
    ldv_state_variable_9 = 1;
    ref_cnt = ref_cnt - 1;
  } else {

  }
  goto ldv_61559;
  default: 
  ldv_stop();
  }
  ldv_61559: ;
  return;
}
}
bool ldv_queue_work_on_281(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_282(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_283(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_284(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_285(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_286(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_287(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_288(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_289(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_290(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_291(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_292(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_293(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_switch_mutex_of_i40e_pf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_294(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_switch_mutex_of_i40e_pf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_295(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_switch_mutex_of_i40e_pf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_296(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_switch_mutex_of_i40e_pf(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_297(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_switch_mutex_of_i40e_pf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_298(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_switch_mutex_of_i40e_pf(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_329(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_327(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_330(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_331(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_326(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_328(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_332(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_321(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_323(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_322(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_325(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_324(struct workqueue_struct *ldv_func_arg1 ) ;
static i40e_status i40e_diag_reg_pattern_test(struct i40e_hw *hw , u32 reg , u32 mask ) 
{ 
  u32 patterns[4U] ;
  u32 pat ;
  u32 val ;
  u32 orig_val ;
  int i ;

  {
  patterns[0] = 1515870810U;
  patterns[1] = 2779096485U;
  patterns[2] = 0U;
  patterns[3] = 4294967295U;
  orig_val = readl((void const volatile   *)hw->hw_addr + (unsigned long )reg);
  i = 0;
  goto ldv_52570;
  ldv_52569: 
  pat = patterns[i];
  writel(pat & mask, (void volatile   *)hw->hw_addr + (unsigned long )reg);
  val = readl((void const volatile   *)hw->hw_addr + (unsigned long )reg);
  if (((val ^ pat) & mask) != 0U) {
    if ((hw->debug_mask & 2048U) != 0U) {
      printk("\016i40e %02x.%x %s: reg pattern test failed - reg 0x%08x pat 0x%08x val 0x%08x\n",
             (int )hw->bus.device, (int )hw->bus.func, "i40e_diag_reg_pattern_test",
             reg, pat, val);
    } else {

    }
    return (-62);
  } else {

  }
  i = i + 1;
  ldv_52570: ;
  if ((unsigned int )i <= 3U) {
    goto ldv_52569;
  } else {

  }
  writel(orig_val, (void volatile   *)hw->hw_addr + (unsigned long )reg);
  val = readl((void const volatile   *)hw->hw_addr + (unsigned long )reg);
  if (val != orig_val) {
    if ((hw->debug_mask & 2048U) != 0U) {
      printk("\016i40e %02x.%x %s: reg restore test failed - reg 0x%08x orig_val 0x%08x val 0x%08x\n",
             (int )hw->bus.device, (int )hw->bus.func, "i40e_diag_reg_pattern_test",
             reg, orig_val, val);
    } else {

    }
    return (-62);
  } else {

  }
  return (0);
}
}
struct i40e_diag_reg_test_info i40e_reg_list[12U]  = 
  {      {1064960U, 65471U, 1U, 4U}, 
        {229376U, 4095U, 3U, 128U}, 
        {196608U, 4095U, 1U, 4U}, 
        {198656U, 4095U, 1U, 4U}, 
        {200704U, 4095U, 1U, 4U}, 
        {230400U, 12U, 1U, 0U}, 
        {230656U, 8191U, 1U, 0U}, 
        {217088U, 2047U, 1U, 4U}, 
        {245760U, 255U, 1U, 4U}, 
        {237568U, 255U, 1U, 4U}, 
        {231424U, 4159832064U, 1U, 0U}, 
        {0U, 0U, 0U, 0U}};
i40e_status i40e_diag_reg_test(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;
  u32 reg ;
  u32 mask ;
  u32 i ;
  u32 j ;

  {
  ret_code = 0;
  i = 0U;
  goto ldv_52585;
  ldv_52584: ;
  if (i40e_reg_list[i].offset == 1064960U && hw->func_caps.num_tx_qp != 0U) {
    i40e_reg_list[i].elements = hw->func_caps.num_tx_qp;
  } else {

  }
  if (((((i40e_reg_list[i].offset == 196608U || i40e_reg_list[i].offset == 198656U) || i40e_reg_list[i].offset == 200704U) || i40e_reg_list[i].offset == 245760U) || i40e_reg_list[i].offset == 237568U) && hw->func_caps.num_msix_vectors != 0U) {
    i40e_reg_list[i].elements = hw->func_caps.num_msix_vectors - 1U;
  } else {

  }
  mask = i40e_reg_list[i].mask;
  j = 0U;
  goto ldv_52582;
  ldv_52581: 
  reg = i40e_reg_list[i].offset + i40e_reg_list[i].stride * j;
  ret_code = i40e_diag_reg_pattern_test(hw, reg, mask);
  j = j + 1U;
  ldv_52582: ;
  if (i40e_reg_list[i].elements > j && (int )ret_code == 0) {
    goto ldv_52581;
  } else {

  }
  i = i + 1U;
  ldv_52585: ;
  if (i40e_reg_list[i].offset != 0U && (int )ret_code == 0) {
    goto ldv_52584;
  } else {

  }

  return (ret_code);
}
}
i40e_status i40e_diag_eeprom_test(struct i40e_hw *hw ) 
{ 
  i40e_status ret_code ;
  u16 reg_val ;

  {
  ret_code = i40e_read_nvm_word(hw, 0, & reg_val);
  if ((int )ret_code == 0 && ((int )reg_val & 192) == 64) {
    ret_code = i40e_validate_nvm_checksum(hw, (u16 *)0U);
  } else {
    ret_code = -62;
  }
  return (ret_code);
}
}
bool ldv_queue_work_on_321(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_322(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_323(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_324(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_325(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_326(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_327(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_328(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_329(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_330(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_331(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_332(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void __builtin_prefetch(void const   *  , ...) ;
__inline static long ldv__builtin_expect(long exp , long c ) ;
__inline static int test_and_set_bit_lock(long nr , unsigned long volatile   *addr ) 
{ 
  int tmp ;

  {
  tmp = test_and_set_bit(nr, addr);
  return (tmp);
}
}
extern unsigned long __phys_addr(unsigned long  ) ;
__inline static int atomic_read(atomic_t const   *v ) 
{ 
  int __var ;
    klee_make_symbolic(&__var, sizeof(int), "__var");

  {
  __var = 0;
  return ((int )*((int const volatile   *)(& v->counter)));
}
}
__inline static void atomic_inc(atomic_t *v ) 
{ 


  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; incl %0": "+m" (v->counter));
  return;
}
}
int ldv_mutex_trylock_357(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_355(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_358(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_359(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_354(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_356(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_360(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_349(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_351(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_350(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_353(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_352(struct workqueue_struct *ldv_func_arg1 ) ;
extern void dump_page(struct page * , char const   * ) ;
extern int numa_node ;
__inline static int numa_node_id(void) 
{ 
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;

  {
  __vpp_verify = (void const   *)0;
  switch (4UL) {
  case 1UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (numa_node));
  goto ldv_13659;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (numa_node));
  goto ldv_13659;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (numa_node));
  goto ldv_13659;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (numa_node));
  goto ldv_13659;
  default: 
  __bad_percpu_size();
  }
  ldv_13659: 
  pscr_ret__ = pfo_ret__;
  goto ldv_13665;
  case 2UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (numa_node));
  goto ldv_13669;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (numa_node));
  goto ldv_13669;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (numa_node));
  goto ldv_13669;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (numa_node));
  goto ldv_13669;
  default: 
  __bad_percpu_size();
  }
  ldv_13669: 
  pscr_ret__ = pfo_ret_____0;
  goto ldv_13665;
  case 4UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (numa_node));
  goto ldv_13678;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (numa_node));
  goto ldv_13678;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (numa_node));
  goto ldv_13678;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (numa_node));
  goto ldv_13678;
  default: 
  __bad_percpu_size();
  }
  ldv_13678: 
  pscr_ret__ = pfo_ret_____1;
  goto ldv_13665;
  case 8UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (numa_node));
  goto ldv_13687;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (numa_node));
  goto ldv_13687;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (numa_node));
  goto ldv_13687;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (numa_node));
  goto ldv_13687;
  default: 
  __bad_percpu_size();
  }
  ldv_13687: 
  pscr_ret__ = pfo_ret_____2;
  goto ldv_13665;
  default: 
  __bad_size_call_parameter();
  goto ldv_13665;
  }
  ldv_13665: ;
  return (pscr_ret__);
}
}
extern struct page *alloc_pages_current(gfp_t  , unsigned int  ) ;
__inline static struct page *alloc_pages(gfp_t gfp_mask , unsigned int order ) 
{ 
  struct page *tmp ;

  {
  tmp = alloc_pages_current(gfp_mask, order);
  return (tmp);
}
}
extern void __free_pages(struct page * , unsigned int  ) ;
extern unsigned long msleep_interruptible(unsigned int  ) ;
__inline static int PageTail(struct page  const  *page ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(15L, (unsigned long const volatile   *)(& page->flags));
  return (tmp);
}
}
__inline static struct page *compound_head_by_tail(struct page *tail ) 
{ 
  struct page *head ;
  int tmp ;
  long tmp___0 ;

  {
  head = tail->__annonCompField46.first_page;
  __asm__  volatile   ("": : : "memory");
  tmp = PageTail((struct page  const  *)tail);
  tmp___0 = ldv__builtin_expect(tmp != 0, 1L);
  if (tmp___0 != 0L) {
    return (head);
  } else {

  }
  return (tail);
}
}
__inline static struct page *compound_head(struct page *page ) 
{ 
  struct page *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp___0 = PageTail((struct page  const  *)page);
  tmp___1 = ldv__builtin_expect(tmp___0 != 0, 0L);
  if (tmp___1 != 0L) {
    tmp = compound_head_by_tail(page);
    return (tmp);
  } else {

  }
  return (page);
}
}
__inline static int page_count(struct page *page ) 
{ 
  struct page *tmp ;
  int tmp___0 ;

  {
  tmp = compound_head(page);
  tmp___0 = atomic_read((atomic_t const   *)(& tmp->__annonCompField42.__annonCompField41.__annonCompField40._count));
  return (tmp___0);
}
}
extern bool __get_page_tail(struct page * ) ;
__inline static void get_page(struct page *page ) 
{ 
  bool tmp ;
  long tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;
  int tmp___3 ;
  long tmp___4 ;

  {
  tmp___1 = PageTail((struct page  const  *)page);
  tmp___2 = ldv__builtin_expect(tmp___1 != 0, 0L);
  if (tmp___2 != 0L) {
    tmp = __get_page_tail(page);
    tmp___0 = ldv__builtin_expect((long )tmp, 1L);
    if (tmp___0 != 0L) {
      return;
    } else {

    }
  } else {

  }
  tmp___3 = atomic_read((atomic_t const   *)(& page->__annonCompField42.__annonCompField41.__annonCompField40._count));
  tmp___4 = ldv__builtin_expect(tmp___3 <= 0, 0L);
  if (tmp___4 != 0L) {
    dump_page(page, "VM_BUG_ON_PAGE(atomic_read(&page->_count) <= 0)");
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/mm.h"),
                         "i" (543), "i" (12UL));
    ldv_22188: ;
    goto ldv_22188;
  } else {

  }
  atomic_inc(& page->__annonCompField42.__annonCompField41.__annonCompField40._count);
  return;
}
}
__inline static int page_to_nid(struct page  const  *page ) 
{ 


  {
  return ((int )(page->flags >> 54));
}
}
__inline static void *lowmem_page_address(struct page  const  *page ) 
{ 


  {
  return ((void *)((unsigned long )((unsigned long long )(((long )page + 24189255811072L) / 64L) << 12) + 0xffff880000000000UL));
}
}
__inline static void dql_queued(struct dql *dql , unsigned int count ) 
{ 
  long tmp ;

  {
  tmp = ldv__builtin_expect(count > 268435455U, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/dynamic_queue_limits.h"),
                         "i" (74), "i" (12UL));
    ldv_24441: ;
    goto ldv_24441;
  } else {

  }
  dql->last_obj_cnt = count;
  __asm__  volatile   ("": : : "memory");
  dql->num_queued = dql->num_queued + count;
  return;
}
}
__inline static int dql_avail(struct dql  const  *dql ) 
{ 
  unsigned int __var ;
  unsigned int __var___0 ;
    klee_make_symbolic(&__var___0, sizeof(int), "__var___0");

  {
  __var = 0U;
  __var___0 = 0U;
  return ((int )((unsigned int )*((unsigned int const volatile   *)(& dql->adj_limit)) - (unsigned int )*((unsigned int const volatile   *)(& dql->num_queued))));
}
}
extern void dql_completed(struct dql * , unsigned int  ) ;
extern void dql_reset(struct dql * ) ;
__inline static void kmemcheck_mark_initialized(void *address , unsigned int n ) 
{ 


  {
  return;
}
}
__inline static __sum16 csum_fold(__wsum sum ) 
{ 


  {
  __asm__  ("  addl %1,%0\n  adcl $0xffff,%0": "=r" (sum): "r" (sum << 16), "0" (sum & 4294901760U));
  return ((__sum16 )(~ sum >> 16));
}
}
__inline static __wsum csum_tcpudp_nofold(__be32 saddr , __be32 daddr , unsigned short len ,
                                          unsigned short proto , __wsum sum ) 
{ 


  {
  __asm__  ("  addl %1, %0\n  adcl %2, %0\n  adcl %3, %0\n  adcl $0, %0\n": "=r" (sum): "g" (daddr),
            "g" (saddr), "g" (((int )len + (int )proto) << 8), "0" (sum));
  return (sum);
}
}
__inline static __sum16 csum_tcpudp_magic(__be32 saddr , __be32 daddr , unsigned short len ,
                                          unsigned short proto , __wsum sum ) 
{ 
  __wsum tmp ;
  __sum16 tmp___0 ;

  {
  tmp = csum_tcpudp_nofold(saddr, daddr, (int )len, (int )proto, sum);
  tmp___0 = csum_fold(tmp);
  return (tmp___0);
}
}
extern __wsum csum_partial(void const   * , int  , __wsum  ) ;
extern __sum16 csum_ipv6_magic(struct in6_addr  const  * , struct in6_addr  const  * ,
                               __u32  , unsigned short  , __wsum  ) ;
__inline static unsigned int add32_with_carry(unsigned int a , unsigned int b ) 
{ 


  {
  __asm__  ("addl %2,%0\n\tadcl $0,%0": "=r" (a): "0" (a), "rm" (b));
  return (a);
}
}
__inline static __wsum csum_add(__wsum csum , __wsum addend ) 
{ 
  unsigned int tmp ;

  {
  tmp = add32_with_carry(csum, addend);
  return (tmp);
}
}
extern void debug_dma_map_page(struct device * , struct page * , size_t  , size_t  ,
                               int  , dma_addr_t  , bool  ) ;
extern void debug_dma_mapping_error(struct device * , dma_addr_t  ) ;
extern void debug_dma_sync_single_range_for_cpu(struct device * , dma_addr_t  , unsigned long  ,
                                                size_t  , int  ) ;
extern void debug_dma_sync_single_range_for_device(struct device * , dma_addr_t  ,
                                                   unsigned long  , size_t  , int  ) ;
__inline static dma_addr_t dma_map_single_attrs(struct device *dev , void *ptr , size_t size ,
                                                enum dma_data_direction dir , struct dma_attrs *attrs ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  dma_addr_t addr ;
  int tmp___0 ;
  long tmp___1 ;
  unsigned long tmp___2 ;
  unsigned long tmp___3 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  kmemcheck_mark_initialized(ptr, (unsigned int )size);
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (19), "i" (12UL));
    ldv_30732: ;
    goto ldv_30732;
  } else {

  }
  tmp___2 = __phys_addr((unsigned long )ptr);
  addr = (*(ops->map_page))(dev, (struct page *)-24189255811072L + (tmp___2 >> 12),
                            (unsigned long )ptr & 4095UL, size, dir, attrs);
  tmp___3 = __phys_addr((unsigned long )ptr);
  debug_dma_map_page(dev, (struct page *)-24189255811072L + (tmp___3 >> 12), (unsigned long )ptr & 4095UL,
                     size, (int )dir, addr, 1);
  return (addr);
}
}
__inline static void dma_unmap_single_attrs___0(struct device *dev , dma_addr_t addr ,
                                                size_t size , enum dma_data_direction dir ,
                                                struct dma_attrs *attrs ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (36), "i" (12UL));
    ldv_30741: ;
    goto ldv_30741;
  } else {

  }
  if ((unsigned long )ops->unmap_page != (unsigned long )((void (*)(struct device * ,
                                                                    dma_addr_t  ,
                                                                    size_t  , enum dma_data_direction  ,
                                                                    struct dma_attrs * ))0)) {
    (*(ops->unmap_page))(dev, addr, size, dir, attrs);
  } else {

  }
  debug_dma_unmap_page(dev, addr, size, (int )dir, 1);
  return;
}
}
__inline static dma_addr_t dma_map_page(struct device *dev , struct page *page , size_t offset ,
                                        size_t size , enum dma_data_direction dir ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  dma_addr_t addr ;
  void *tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = lowmem_page_address((struct page  const  *)page);
  kmemcheck_mark_initialized(tmp___0 + offset, (unsigned int )size);
  tmp___1 = valid_dma_direction((int )dir);
  tmp___2 = ldv__builtin_expect(tmp___1 == 0, 0L);
  if (tmp___2 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (84), "i" (12UL));
    ldv_30776: ;
    goto ldv_30776;
  } else {

  }
  addr = (*(ops->map_page))(dev, page, offset, size, dir, (struct dma_attrs *)0);
  debug_dma_map_page(dev, page, offset, size, (int )dir, addr, 0);
  return (addr);
}
}
__inline static void dma_unmap_page(struct device *dev , dma_addr_t addr , size_t size ,
                                    enum dma_data_direction dir ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (96), "i" (12UL));
    ldv_30784: ;
    goto ldv_30784;
  } else {

  }
  if ((unsigned long )ops->unmap_page != (unsigned long )((void (*)(struct device * ,
                                                                    dma_addr_t  ,
                                                                    size_t  , enum dma_data_direction  ,
                                                                    struct dma_attrs * ))0)) {
    (*(ops->unmap_page))(dev, addr, size, dir, (struct dma_attrs *)0);
  } else {

  }
  debug_dma_unmap_page(dev, addr, size, (int )dir, 0);
  return;
}
}
__inline static void dma_sync_single_range_for_cpu(struct device *dev , dma_addr_t addr ,
                                                   unsigned long offset , size_t size ,
                                                   enum dma_data_direction dir ) 
{ 
  struct dma_map_ops  const  *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp = get_dma_ops(dev);
  ops = (struct dma_map_ops  const  *)tmp;
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (134), "i" (12UL));
    ldv_30809: ;
    goto ldv_30809;
  } else {

  }
  if ((unsigned long )ops->sync_single_for_cpu != (unsigned long )((void (*/* const  */)(struct device * ,
                                                                                         dma_addr_t  ,
                                                                                         size_t  ,
                                                                                         enum dma_data_direction  ))0)) {
    (*(ops->sync_single_for_cpu))(dev, addr + (unsigned long long )offset, size, dir);
  } else {

  }
  debug_dma_sync_single_range_for_cpu(dev, addr, offset, size, (int )dir);
  return;
}
}
__inline static void dma_sync_single_range_for_device(struct device *dev , dma_addr_t addr ,
                                                      unsigned long offset , size_t size ,
                                                      enum dma_data_direction dir ) 
{ 
  struct dma_map_ops  const  *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp = get_dma_ops(dev);
  ops = (struct dma_map_ops  const  *)tmp;
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (148), "i" (12UL));
    ldv_30818: ;
    goto ldv_30818;
  } else {

  }
  if ((unsigned long )ops->sync_single_for_device != (unsigned long )((void (*/* const  */)(struct device * ,
                                                                                            dma_addr_t  ,
                                                                                            size_t  ,
                                                                                            enum dma_data_direction  ))0)) {
    (*(ops->sync_single_for_device))(dev, addr + (unsigned long long )offset, size,
                                     dir);
  } else {

  }
  debug_dma_sync_single_range_for_device(dev, addr, offset, size, (int )dir);
  return;
}
}
__inline static int dma_mapping_error(struct device *dev , dma_addr_t dma_addr ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  debug_dma_mapping_error(dev, dma_addr);
  if ((unsigned long )ops->mapping_error != (unsigned long )((int (*)(struct device * ,
                                                                      dma_addr_t  ))0)) {
    tmp___0 = (*(ops->mapping_error))(dev, dma_addr);
    return (tmp___0);
  } else {

  }
  return (dma_addr == 0ULL);
}
}
__inline static unsigned int skb_frag_size(skb_frag_t const   *frag ) 
{ 


  {
  return ((unsigned int )frag->size);
}
}
__inline static void skb_frag_size_set(skb_frag_t *frag , unsigned int size ) 
{ 


  {
  frag->size = size;
  return;
}
}
extern void consume_skb(struct sk_buff * ) ;
extern int pskb_expand_head(struct sk_buff * , int  , int  , gfp_t  ) ;
extern int skb_pad(struct sk_buff * , int  ) ;
__inline static void skb_set_hash(struct sk_buff *skb , __u32 hash , enum pkt_hash_types type ) 
{ 


  {
  skb->l4_hash = (unsigned int )type == 3U;
  skb->sw_hash = 0U;
  skb->hash = hash;
  return;
}
}
__inline static unsigned char *skb_end_pointer(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->end);
}
}
__inline static struct sk_buff *skb_get(struct sk_buff *skb ) 
{ 


  {
  atomic_inc(& skb->users);
  return (skb);
}
}
__inline static int skb_header_cloned(struct sk_buff  const  *skb ) 
{ 
  int dataref ;
    klee_make_symbolic(&dataref, sizeof(int), "dataref");
  unsigned char *tmp ;

  {
  if ((unsigned int )*((unsigned char *)skb + 142UL) == 0U) {
    return (0);
  } else {

  }
  tmp = skb_end_pointer(skb);
  dataref = atomic_read((atomic_t const   *)(& ((struct skb_shared_info *)tmp)->dataref));
  dataref = (dataref & 65535) - (dataref >> 16);
  return (dataref != 1);
}
}
__inline static bool skb_is_nonlinear(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned int )skb->data_len != 0U);
}
}
__inline static unsigned int skb_headlen(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned int )skb->len - (unsigned int )skb->data_len);
}
}
__inline static void __skb_fill_page_desc(struct sk_buff *skb , int i , struct page *page ,
                                          int off , int size ) 
{ 
  skb_frag_t *frag ;
  unsigned char *tmp ;

  {
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  frag = (skb_frag_t *)(& ((struct skb_shared_info *)tmp)->frags) + (unsigned long )i;
  frag->page.p = page;
  frag->page_offset = (__u32 )off;
  skb_frag_size_set(frag, (unsigned int )size);
  page = compound_head(page);
  if ((int )page->__annonCompField42.__annonCompField37.pfmemalloc && (unsigned long )page->__annonCompField36.mapping == (unsigned long )((struct address_space *)0)) {
    skb->pfmemalloc = 1U;
  } else {

  }
  return;
}
}
__inline static void skb_fill_page_desc(struct sk_buff *skb , int i , struct page *page ,
                                        int off , int size ) 
{ 
  unsigned char *tmp ;

  {
  __skb_fill_page_desc(skb, i, page, off, size);
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  ((struct skb_shared_info *)tmp)->nr_frags = (unsigned int )((unsigned char )i) + 1U;
  return;
}
}
__inline static unsigned char *skb_tail_pointer(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->tail);
}
}
extern unsigned char *skb_put(struct sk_buff * , unsigned int  ) ;
__inline static unsigned char *__skb_put(struct sk_buff *skb , unsigned int len ) 
{ 
  unsigned char *tmp ;
  unsigned char *tmp___0 ;
  bool tmp___1 ;
  long tmp___2 ;

  {
  tmp___0 = skb_tail_pointer((struct sk_buff  const  *)skb);
  tmp = tmp___0;
  tmp___1 = skb_is_nonlinear((struct sk_buff  const  *)skb);
  tmp___2 = ldv__builtin_expect((long )tmp___1, 0L);
  if (tmp___2 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/skbuff.h"),
                         "i" (1696), "i" (12UL));
    ldv_32080: ;
    goto ldv_32080;
  } else {

  }
  skb->tail = skb->tail + len;
  skb->len = skb->len + len;
  return (tmp);
}
}
extern unsigned char *__pskb_pull_tail(struct sk_buff * , int  ) ;
__inline static int pskb_may_pull(struct sk_buff *skb , unsigned int len ) 
{ 
  unsigned int tmp ;
  long tmp___0 ;
  long tmp___1 ;
  unsigned int tmp___2 ;
  unsigned char *tmp___3 ;

  {
  tmp = skb_headlen((struct sk_buff  const  *)skb);
  tmp___0 = ldv__builtin_expect(tmp >= len, 1L);
  if (tmp___0 != 0L) {
    return (1);
  } else {

  }
  tmp___1 = ldv__builtin_expect(skb->len < len, 0L);
  if (tmp___1 != 0L) {
    return (0);
  } else {

  }
  tmp___2 = skb_headlen((struct sk_buff  const  *)skb);
  tmp___3 = __pskb_pull_tail(skb, (int )(len - tmp___2));
  return ((unsigned long )tmp___3 != (unsigned long )((unsigned char *)0U));
}
}
__inline static unsigned int skb_headroom(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned int )((long )skb->data) - (unsigned int )((long )skb->head));
}
}
__inline static unsigned char *skb_inner_transport_header(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->inner_transport_header);
}
}
__inline static unsigned char *skb_inner_network_header(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->inner_network_header);
}
}
__inline static unsigned char *skb_transport_header(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->transport_header);
}
}
__inline static unsigned char *skb_network_header(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->network_header);
}
}
__inline static int skb_transport_offset(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_transport_header(skb);
  return ((int )((unsigned int )((long )tmp) - (unsigned int )((long )skb->data)));
}
}
__inline static u32 skb_network_header_len(struct sk_buff  const  *skb ) 
{ 


  {
  return ((u32 )((int )skb->transport_header - (int )skb->network_header));
}
}
__inline static u32 skb_inner_network_header_len(struct sk_buff  const  *skb ) 
{ 


  {
  return ((u32 )((int )skb->inner_transport_header - (int )skb->inner_network_header));
}
}
__inline static int skb_network_offset(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_network_header(skb);
  return ((int )((unsigned int )((long )tmp) - (unsigned int )((long )skb->data)));
}
}
__inline static int skb_inner_network_offset(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_inner_network_header(skb);
  return ((int )((unsigned int )((long )tmp) - (unsigned int )((long )skb->data)));
}
}
extern struct sk_buff *__netdev_alloc_skb(struct net_device * , unsigned int  , gfp_t  ) ;
__inline static struct sk_buff *__netdev_alloc_skb_ip_align(struct net_device *dev ,
                                                            unsigned int length ,
                                                            gfp_t gfp ) 
{ 
  struct sk_buff *skb ;
  struct sk_buff *tmp ;

  {
  tmp = __netdev_alloc_skb(dev, length, gfp);
  skb = tmp;
  return (skb);
}
}
__inline static struct sk_buff *netdev_alloc_skb_ip_align(struct net_device *dev ,
                                                          unsigned int length ) 
{ 
  struct sk_buff *tmp ;

  {
  tmp = __netdev_alloc_skb_ip_align(dev, length, 32U);
  return (tmp);
}
}
__inline static struct page *skb_frag_page(skb_frag_t const   *frag ) 
{ 


  {
  return ((struct page *)frag->page.p);
}
}
__inline static dma_addr_t skb_frag_dma_map(struct device *dev , skb_frag_t const   *frag ,
                                            size_t offset , size_t size , enum dma_data_direction dir ) 
{ 
  struct page *tmp ;
  dma_addr_t tmp___0 ;

  {
  tmp = skb_frag_page(frag);
  tmp___0 = dma_map_page(dev, tmp, (size_t )frag->page_offset + offset, size, dir);
  return (tmp___0);
}
}
__inline static int __skb_cow(struct sk_buff *skb , unsigned int headroom , int cloned ) 
{ 
  int delta ;
    klee_make_symbolic(&delta, sizeof(int), "delta");
  unsigned int tmp ;
  unsigned int tmp___0 ;
  int _max1 ;
    klee_make_symbolic(&_max1, sizeof(int), "_max1");
  int _max2 ;
  int _max1___0 ;
    klee_make_symbolic(&_max1___0, sizeof(int), "_max1___0");
  int _max2___0 ;
    klee_make_symbolic(&_max2___0, sizeof(int), "_max2___0");
  int tmp___1 ;

  {
  delta = 0;
  tmp___0 = skb_headroom((struct sk_buff  const  *)skb);
  if (tmp___0 < headroom) {
    tmp = skb_headroom((struct sk_buff  const  *)skb);
    delta = (int )(headroom - tmp);
  } else {

  }
  if (delta != 0 || cloned != 0) {
    _max1 = 32;
    _max2 = 64;
    _max1___0 = 32;
    _max2___0 = 64;
    tmp___1 = pskb_expand_head(skb, (((_max1 > _max2 ? _max1 : _max2) + -1) + delta) & - (_max1___0 > _max2___0 ? _max1___0 : _max2___0),
                               0, 32U);
    return (tmp___1);
  } else {

  }
  return (0);
}
}
__inline static int skb_cow_head(struct sk_buff *skb , unsigned int headroom ) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp = skb_header_cloned((struct sk_buff  const  *)skb);
  tmp___0 = __skb_cow(skb, headroom, tmp);
  return (tmp___0);
}
}
__inline static int skb_put_padto(struct sk_buff *skb , unsigned int len ) 
{ 
  unsigned int size ;
  int tmp ;
  long tmp___0 ;

  {
  size = skb->len;
  tmp___0 = ldv__builtin_expect(size < len, 0L);
  if (tmp___0 != 0L) {
    len = len - size;
    tmp = skb_pad(skb, (int )len);
    if (tmp != 0) {
      return (-12);
    } else {

    }
    __skb_put(skb, len);
  } else {

  }
  return (0);
}
}
__inline static int __skb_linearize(struct sk_buff *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = __pskb_pull_tail(skb, (int )skb->data_len);
  return ((unsigned long )tmp != (unsigned long )((unsigned char *)0U) ? 0 : -12);
}
}
__inline static int skb_linearize(struct sk_buff *skb ) 
{ 
  int tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;

  {
  tmp___2 = skb_is_nonlinear((struct sk_buff  const  *)skb);
  if ((int )tmp___2) {
    tmp___0 = __skb_linearize(skb);
    tmp___1 = tmp___0;
  } else {
    tmp___1 = 0;
  }
  return (tmp___1);
}
}
extern int skb_copy_bits(struct sk_buff  const  * , int  , void * , int  ) ;
__inline static void *__skb_header_pointer(struct sk_buff  const  *skb , int offset ,
                                           int len , void *data , int hlen , void *buffer ) 
{ 
  int tmp ;

  {
  if (hlen - offset >= len) {
    return (data + (unsigned long )offset);
  } else {

  }
  if ((unsigned long )skb == (unsigned long )((struct sk_buff  const  *)0)) {
    return ((void *)0);
  } else {
    tmp = skb_copy_bits(skb, offset, buffer, len);
    if (tmp < 0) {
      return ((void *)0);
    } else {

    }
  }
  return (buffer);
}
}
__inline static void *skb_header_pointer(struct sk_buff  const  *skb , int offset ,
                                         int len , void *buffer ) 
{ 
  unsigned int tmp ;
  void *tmp___0 ;

  {
  tmp = skb_headlen(skb);
  tmp___0 = __skb_header_pointer(skb, offset, len, (void *)skb->data, (int )tmp, buffer);
  return (tmp___0);
}
}
extern void skb_clone_tx_timestamp(struct sk_buff * ) ;
extern void skb_tstamp_tx(struct sk_buff * , struct skb_shared_hwtstamps * ) ;
__inline static void sw_tx_timestamp(struct sk_buff *skb ) 
{ 
  unsigned char *tmp ;
  unsigned char *tmp___0 ;

  {
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  if (((int )((struct skb_shared_info *)tmp)->tx_flags & 2) != 0) {
    tmp___0 = skb_end_pointer((struct sk_buff  const  *)skb);
    if (((int )((struct skb_shared_info *)tmp___0)->tx_flags & 4) == 0) {
      skb_tstamp_tx(skb, (struct skb_shared_hwtstamps *)0);
    } else {

    }
  } else {

  }
  return;
}
}
__inline static void skb_tx_timestamp(struct sk_buff *skb ) 
{ 


  {
  skb_clone_tx_timestamp(skb);
  sw_tx_timestamp(skb);
  return;
}
}
__inline static void skb_record_rx_queue(struct sk_buff *skb , u16 rx_queue ) 
{ 


  {
  skb->queue_mapping = (unsigned int )rx_queue + 1U;
  return;
}
}
__inline static bool skb_is_gso(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_end_pointer(skb);
  return ((unsigned int )((struct skb_shared_info *)tmp)->gso_size != 0U);
}
}
__inline static void u64_stats_init(struct u64_stats_sync *syncp ) 
{ 


  {
  return;
}
}
__inline static void napi_complete(struct napi_struct *n ) 
{ 


  {
  return;
}
}
extern void netif_schedule_queue(struct netdev_queue * ) ;
__inline static bool netif_tx_queue_stopped(struct netdev_queue  const  *dev_queue ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(0L, (unsigned long const volatile   *)(& dev_queue->state));
  return (tmp != 0);
}
}
__inline static bool netif_xmit_stopped(struct netdev_queue  const  *dev_queue ) 
{ 


  {
  return (((unsigned long )dev_queue->state & 3UL) != 0UL);
}
}
__inline static void netdev_tx_sent_queue(struct netdev_queue *dev_queue , unsigned int bytes ) 
{ 
  int tmp ;
  long tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;

  {
  dql_queued(& dev_queue->dql, bytes);
  tmp = dql_avail((struct dql  const  *)(& dev_queue->dql));
  tmp___0 = ldv__builtin_expect(tmp >= 0, 1L);
  if (tmp___0 != 0L) {
    return;
  } else {

  }
  set_bit(1L, (unsigned long volatile   *)(& dev_queue->state));
  __asm__  volatile   ("mfence": : : "memory");
  tmp___1 = dql_avail((struct dql  const  *)(& dev_queue->dql));
  tmp___2 = ldv__builtin_expect(tmp___1 >= 0, 0L);
  if (tmp___2 != 0L) {
    clear_bit(1L, (unsigned long volatile   *)(& dev_queue->state));
  } else {

  }
  return;
}
}
__inline static void netdev_tx_completed_queue(struct netdev_queue *dev_queue , unsigned int pkts ,
                                               unsigned int bytes ) 
{ 
  long tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
  tmp = ldv__builtin_expect(bytes == 0U, 0L);
  if (tmp != 0L) {
    return;
  } else {

  }
  dql_completed(& dev_queue->dql, bytes);
  __asm__  volatile   ("mfence": : : "memory");
  tmp___0 = dql_avail((struct dql  const  *)(& dev_queue->dql));
  if (tmp___0 < 0) {
    return;
  } else {

  }
  tmp___1 = test_and_clear_bit(1L, (unsigned long volatile   *)(& dev_queue->state));
  if (tmp___1 != 0) {
    netif_schedule_queue(dev_queue);
  } else {

  }
  return;
}
}
__inline static void netdev_tx_reset_queue(struct netdev_queue *q ) 
{ 


  {
  clear_bit(1L, (unsigned long volatile   *)(& q->state));
  dql_reset(& q->dql);
  return;
}
}
__inline static void netif_start_subqueue(struct net_device *dev , u16 queue_index ) 
{ 
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, (unsigned int )queue_index);
  txq = tmp;
  netif_tx_start_queue(txq);
  return;
}
}
__inline static void netif_stop_subqueue(struct net_device *dev , u16 queue_index ) 
{ 
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, (unsigned int )queue_index);
  txq = tmp;
  netif_tx_stop_queue(txq);
  return;
}
}
__inline static bool __netif_subqueue_stopped(struct net_device  const  *dev , u16 queue_index ) 
{ 
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;
  bool tmp___0 ;

  {
  tmp = netdev_get_tx_queue(dev, (unsigned int )queue_index);
  txq = tmp;
  tmp___0 = netif_tx_queue_stopped((struct netdev_queue  const  *)txq);
  return (tmp___0);
}
}
extern void netif_wake_subqueue(struct net_device * , u16  ) ;
extern void __dev_kfree_skb_any(struct sk_buff * , enum skb_free_reason  ) ;
__inline static void dev_kfree_skb_any(struct sk_buff *skb ) 
{ 


  {
  __dev_kfree_skb_any(skb, 1);
  return;
}
}
__inline static void dev_consume_skb_any(struct sk_buff *skb ) 
{ 


  {
  __dev_kfree_skb_any(skb, 0);
  return;
}
}
extern int netif_rx(struct sk_buff * ) ;
extern gro_result_t napi_gro_receive(struct napi_struct * , struct sk_buff * ) ;
__inline static struct iphdr *ip_hdr(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_network_header(skb);
  return ((struct iphdr *)tmp);
}
}
__inline static struct iphdr *inner_ip_hdr(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_inner_network_header(skb);
  return ((struct iphdr *)tmp);
}
}
__inline static struct tcphdr *tcp_hdr(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_transport_header(skb);
  return ((struct tcphdr *)tmp);
}
}
__inline static unsigned int tcp_hdrlen(struct sk_buff  const  *skb ) 
{ 
  struct tcphdr *tmp ;

  {
  tmp = tcp_hdr(skb);
  return ((unsigned int )((int )tmp->doff * 4));
}
}
__inline static struct tcphdr *inner_tcp_hdr(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_inner_transport_header(skb);
  return ((struct tcphdr *)tmp);
}
}
__inline static unsigned int inner_tcp_hdrlen(struct sk_buff  const  *skb ) 
{ 
  struct tcphdr *tmp ;

  {
  tmp = inner_tcp_hdr(skb);
  return ((unsigned int )((int )tmp->doff * 4));
}
}
__inline static struct udphdr *udp_hdr(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_transport_header(skb);
  return ((struct udphdr *)tmp);
}
}
__inline static struct ipv6hdr *ipv6_hdr(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_network_header(skb);
  return ((struct ipv6hdr *)tmp);
}
}
__inline static struct ipv6hdr *inner_ipv6_hdr(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_inner_network_header(skb);
  return ((struct ipv6hdr *)tmp);
}
}
__inline static void skb_mark_napi_id(struct sk_buff *skb , struct napi_struct *napi ) 
{ 


  {
  skb->__annonCompField70.napi_id = napi->napi_id;
  return;
}
}
__inline static __wsum udp_csum(struct sk_buff *skb ) 
{ 
  __wsum csum ;
  unsigned char *tmp ;
  __wsum tmp___0 ;
  unsigned char *tmp___1 ;

  {
  tmp = skb_transport_header((struct sk_buff  const  *)skb);
  tmp___0 = csum_partial((void const   *)tmp, 8, skb->__annonCompField69.csum);
  csum = tmp___0;
  tmp___1 = skb_end_pointer((struct sk_buff  const  *)skb);
  skb = ((struct skb_shared_info *)tmp___1)->frag_list;
  goto ldv_52207;
  ldv_52206: 
  csum = csum_add(csum, skb->__annonCompField69.csum);
  skb = skb->__annonCompField67.__annonCompField66.next;
  ldv_52207: ;
  if ((unsigned long )skb != (unsigned long )((struct sk_buff *)0)) {
    goto ldv_52206;
  } else {

  }

  return (csum);
}
}
extern __be16 eth_type_trans(struct sk_buff * , struct net_device * ) ;
__inline static void __vlan_hwaccel_put_tag(struct sk_buff *skb , __be16 vlan_proto ,
                                            u16 vlan_tci ) 
{ 


  {
  skb->vlan_proto = vlan_proto;
  skb->vlan_tci = (__u16 )((unsigned int )vlan_tci | 4096U);
  return;
}
}
__inline static __be16 __vlan_get_protocol(struct sk_buff *skb , __be16 type , int *depth ) 
{ 
  unsigned int vlan_depth ;
    klee_make_symbolic(&vlan_depth, sizeof(int), "vlan_depth");
  int __ret_warn_on ;
  long tmp ;
  long tmp___0 ;
  struct vlan_hdr *vh ;
  int tmp___1 ;
  long tmp___2 ;

  {
  vlan_depth = (unsigned int )skb->mac_len;
  if ((unsigned int )type == 129U || (unsigned int )type == 43144U) {
    if (vlan_depth != 0U) {
      __ret_warn_on = vlan_depth <= 3U;
      tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
      if (tmp != 0L) {
        warn_slowpath_null("include/linux/if_vlan.h", 492);
      } else {

      }
      tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
      if (tmp___0 != 0L) {
        return (0U);
      } else {

      }
      vlan_depth = vlan_depth - 4U;
    } else {
      vlan_depth = 14U;
    }
    ldv_57111: 
    tmp___1 = pskb_may_pull(skb, vlan_depth + 4U);
    tmp___2 = ldv__builtin_expect(tmp___1 == 0, 0L);
    if (tmp___2 != 0L) {
      return (0U);
    } else {

    }
    vh = (struct vlan_hdr *)skb->data + (unsigned long )vlan_depth;
    type = vh->h_vlan_encapsulated_proto;
    vlan_depth = vlan_depth + 4U;
    if ((unsigned int )type == 129U || (unsigned int )type == 43144U) {
      goto ldv_57111;
    } else {

    }

  } else {

  }
  if ((unsigned long )depth != (unsigned long )((int *)0)) {
    *depth = (int )vlan_depth;
  } else {

  }
  return (type);
}
}
__inline static __be16 vlan_get_protocol(struct sk_buff *skb ) 
{ 
  __be16 tmp ;

  {
  tmp = __vlan_get_protocol(skb, (int )skb->protocol, (int *)0);
  return (tmp);
}
}
__inline static struct i40e_rx_ptype_decoded decode_rx_desc_ptype(u8 ptype ) 
{ 


  {
  return (i40e_ptype_lookup[(int )ptype]);
}
}
__inline void i40e_tx_map(struct i40e_ring *tx_ring , struct sk_buff *skb , struct i40e_tx_buffer *first ,
                          u32 tx_flags , u8 const   hdr_len , u32 td_cmd , u32 td_offset ) ;
__inline int i40e_maybe_stop_tx(struct i40e_ring *tx_ring , int size ) ;
__inline int i40e_xmit_descriptor_count(struct sk_buff *skb , struct i40e_ring *tx_ring ) ;
__inline int i40e_tx_prepare_vlan_flags(struct sk_buff *skb , struct i40e_ring *tx_ring ,
                                        u32 *flags ) ;
__inline static bool i40e_rx_is_programming_status(u64 qw ) 
{ 


  {
  return (qw >> 38 == 33554432ULL);
}
}
int i40e_fcoe_handle_offload(struct i40e_ring *rx_ring , union i40e_32byte_rx_desc *rx_desc ,
                             struct sk_buff *skb ) ;
void i40e_fcoe_handle_status(struct i40e_ring *rx_ring , union i40e_32byte_rx_desc *rx_desc ,
                             u8 prog_id ) ;
void i40e_ptp_rx_hwtstamp(struct i40e_pf *pf , struct sk_buff *skb , u8 index ) ;
__inline static __le64 build_ctob(u32 td_cmd , u32 td_offset , unsigned int size ,
                                  u32 td_tag ) 
{ 


  {
  return (((((unsigned long long )td_cmd << 4) | ((unsigned long long )td_offset << 16)) | ((unsigned long long )size << 34)) | ((unsigned long long )td_tag << 48));
}
}
int i40e_program_fdir_filter(struct i40e_fdir_filter *fdir_data , u8 *raw_packet ,
                             struct i40e_pf *pf , bool add ) 
{ 
  struct i40e_filter_program_desc *fdir_desc ;
  struct i40e_tx_buffer *tx_buf ;
  struct i40e_tx_buffer *first ;
  struct i40e_tx_desc *tx_desc ;
  struct i40e_ring *tx_ring ;
  unsigned int fpt ;
    klee_make_symbolic(&fpt, sizeof(int), "fpt");
  unsigned int dcc ;
    klee_make_symbolic(&dcc, sizeof(int), "dcc");
  struct i40e_vsi *vsi ;
  struct device *dev ;
  dma_addr_t dma ;
  u32 td_cmd ;
  u16 delay ;
  u16 i ;
  int tmp ;

  {
  td_cmd = 0U;
  delay = 0U;
  vsi = (struct i40e_vsi *)0;
  i = 0U;
  goto ldv_61100;
  ldv_61099: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )i) != (unsigned long )((struct i40e_vsi *)0) && (unsigned int )(*(pf->vsi + (unsigned long )i))->type == 7U) {
    vsi = *(pf->vsi + (unsigned long )i);
  } else {

  }
  i = (u16 )((int )i + 1);
  ldv_61100: ;
  if ((int )pf->num_alloc_vsi > (int )i) {
    goto ldv_61099;
  } else {

  }

  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
    return (-2);
  } else {

  }
  tx_ring = *(vsi->tx_rings);
  dev = tx_ring->dev;
  ldv_61103: ;
  if (((((int )tx_ring->next_to_clean <= (int )tx_ring->next_to_use ? (int )tx_ring->count : 0) + (int )tx_ring->next_to_clean) - (int )tx_ring->next_to_use) + -1 > 1) {
    goto ldv_61102;
  } else {

  }
  msleep_interruptible(1U);
  delay = (u16 )((int )delay + 1);
  if ((unsigned int )delay <= 9U) {
    goto ldv_61103;
  } else {

  }
  ldv_61102: ;
  if (((((int )tx_ring->next_to_clean <= (int )tx_ring->next_to_use ? (int )tx_ring->count : 0) + (int )tx_ring->next_to_clean) - (int )tx_ring->next_to_use) + -1 <= 1) {
    return (-11);
  } else {

  }
  dma = dma_map_single_attrs(dev, (void *)raw_packet, 512UL, 1, (struct dma_attrs *)0);
  tmp = dma_mapping_error(dev, dma);
  if (tmp != 0) {
    goto dma_fail;
  } else {

  }
  i = tx_ring->next_to_use;
  fdir_desc = (struct i40e_filter_program_desc *)tx_ring->desc + (unsigned long )i;
  first = tx_ring->__annonCompField121.tx_bi + (unsigned long )i;
  memset((void *)first, 0, 40UL);
  tx_ring->next_to_use = (int )i + 1 < (int )tx_ring->count ? (unsigned int )i + 1U : 0U;
  fpt = (unsigned int )fdir_data->q_index & 2047U;
  fpt = ((unsigned int )((int )fdir_data->flex_off << 11) & 14336U) | fpt;
  fpt = ((unsigned int )((int )fdir_data->pctype << 17) & 8257536U) | fpt;
  if ((unsigned int )fdir_data->dest_vsi == 0U) {
    fpt = (unsigned int )((int )(*(pf->vsi + (unsigned long )pf->lan_vsi))->id << 23) | fpt;
  } else {
    fpt = ((unsigned int )fdir_data->dest_vsi << 23) | fpt;
  }
  dcc = 8U;
  if ((int )add) {
    dcc = dcc | 16U;
  } else {
    dcc = dcc | 32U;
  }
  dcc = ((unsigned int )((int )fdir_data->dest_ctl << 7) & 384U) | dcc;
  dcc = ((unsigned int )((int )fdir_data->fd_status << 13) & 24576U) | dcc;
  if ((unsigned int )fdir_data->cnt_index != 0U) {
    dcc = dcc | 2048U;
    dcc = (((unsigned int )fdir_data->cnt_index << 20) & 535822336U) | dcc;
  } else {

  }
  fdir_desc->qindex_flex_ptype_vsi = fpt;
  fdir_desc->rsvd = 0U;
  fdir_desc->dtype_cmd_cntindex = dcc;
  fdir_desc->fd_id = fdir_data->fd_id;
  i = tx_ring->next_to_use;
  tx_desc = (struct i40e_tx_desc *)tx_ring->desc + (unsigned long )i;
  tx_buf = tx_ring->__annonCompField121.tx_bi + (unsigned long )i;
  tx_ring->next_to_use = (int )i + 1 < (int )tx_ring->count ? (unsigned int )i + 1U : 0U;
  memset((void *)tx_buf, 0, 40UL);
  tx_buf->len = 512U;
  tx_buf->dma = dma;
  tx_desc->buffer_addr = dma;
  td_cmd = 19U;
  tx_buf->tx_flags = 512U;
  tx_buf->__annonCompField120.raw_buf = (void *)raw_packet;
  tx_desc->cmd_type_offset_bsz = build_ctob(td_cmd, 0U, 512U, 0U);
  __asm__  volatile   ("sfence": : : "memory");
  first->next_to_watch = tx_desc;
  writel((unsigned int )tx_ring->next_to_use, (void volatile   *)tx_ring->tail);
  return (0);
  dma_fail: ;
  return (-1);
}
}
static int i40e_add_del_fdir_udpv4(struct i40e_vsi *vsi , struct i40e_fdir_filter *fd_data ,
                                   bool add ) 
{ 
  struct i40e_pf *pf ;
  struct udphdr *udp ;
  struct iphdr *ip ;
  bool err ;
  u8 *raw_packet ;
  int ret ;
  char packet[42U] ;
  void *tmp ;

  {
  pf = vsi->back;
  err = 0;
  packet[0] = 0;
  packet[1] = 0;
  packet[2] = 0;
  packet[3] = 0;
  packet[4] = 0;
  packet[5] = 0;
  packet[6] = 0;
  packet[7] = 0;
  packet[8] = 0;
  packet[9] = 0;
  packet[10] = 0;
  packet[11] = 0;
  packet[12] = 8;
  packet[13] = 0;
  packet[14] = 69;
  packet[15] = 0;
  packet[16] = 0;
  packet[17] = 28;
  packet[18] = 0;
  packet[19] = 0;
  packet[20] = 64;
  packet[21] = 0;
  packet[22] = 64;
  packet[23] = 17;
  packet[24] = 0;
  packet[25] = 0;
  packet[26] = 0;
  packet[27] = 0;
  packet[28] = 0;
  packet[29] = 0;
  packet[30] = 0;
  packet[31] = 0;
  packet[32] = 0;
  packet[33] = 0;
  packet[34] = 0;
  packet[35] = 0;
  packet[36] = 0;
  packet[37] = 0;
  packet[38] = 0;
  packet[39] = 0;
  packet[40] = 0;
  packet[41] = 0;
  tmp = kzalloc(512UL, 208U);
  raw_packet = (u8 *)tmp;
  if ((unsigned long )raw_packet == (unsigned long )((u8 *)0U)) {
    return (-12);
  } else {

  }
  memcpy((void *)raw_packet, (void const   *)(& packet), 42UL);
  ip = (struct iphdr *)raw_packet + 14U;
  udp = (struct udphdr *)raw_packet + 34U;
  ip->daddr = fd_data->dst_ip[0];
  udp->dest = fd_data->dst_port;
  ip->saddr = fd_data->src_ip[0];
  udp->source = fd_data->src_port;
  fd_data->pctype = 31U;
  ret = i40e_program_fdir_filter(fd_data, raw_packet, pf, (int )add);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "PCTYPE:%d, Filter command send failed for fd_id:%d (ret = %d)\n",
              (int )fd_data->pctype, fd_data->fd_id, ret);
    err = 1;
  } else
  if ((pf->hw.debug_mask & 4096U) != 0U) {
    if ((int )add) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Filter OK for PCTYPE %d loc = %d\n",
                (int )fd_data->pctype, fd_data->fd_id);
    } else {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Filter deleted for PCTYPE %d loc = %d\n",
                (int )fd_data->pctype, fd_data->fd_id);
    }
  } else {

  }
  return ((int )err ? -95 : 0);
}
}
static int i40e_add_del_fdir_tcpv4(struct i40e_vsi *vsi , struct i40e_fdir_filter *fd_data ,
                                   bool add ) 
{ 
  struct i40e_pf *pf ;
  struct tcphdr *tcp ;
  struct iphdr *ip ;
  bool err ;
  u8 *raw_packet ;
  int ret ;
  char packet[54U] ;
  void *tmp ;

  {
  pf = vsi->back;
  err = 0;
  packet[0] = 0;
  packet[1] = 0;
  packet[2] = 0;
  packet[3] = 0;
  packet[4] = 0;
  packet[5] = 0;
  packet[6] = 0;
  packet[7] = 0;
  packet[8] = 0;
  packet[9] = 0;
  packet[10] = 0;
  packet[11] = 0;
  packet[12] = 8;
  packet[13] = 0;
  packet[14] = 69;
  packet[15] = 0;
  packet[16] = 0;
  packet[17] = 40;
  packet[18] = 0;
  packet[19] = 0;
  packet[20] = 64;
  packet[21] = 0;
  packet[22] = 64;
  packet[23] = 6;
  packet[24] = 0;
  packet[25] = 0;
  packet[26] = 0;
  packet[27] = 0;
  packet[28] = 0;
  packet[29] = 0;
  packet[30] = 0;
  packet[31] = 0;
  packet[32] = 0;
  packet[33] = 0;
  packet[34] = 0;
  packet[35] = 0;
  packet[36] = 0;
  packet[37] = 0;
  packet[38] = 0;
  packet[39] = 0;
  packet[40] = 0;
  packet[41] = 0;
  packet[42] = 0;
  packet[43] = 0;
  packet[44] = 0;
  packet[45] = 0;
  packet[46] = -128;
  packet[47] = 17;
  packet[48] = 0;
  packet[49] = 114;
  packet[50] = 0;
  packet[51] = 0;
  packet[52] = 0;
  packet[53] = 0;
  tmp = kzalloc(512UL, 208U);
  raw_packet = (u8 *)tmp;
  if ((unsigned long )raw_packet == (unsigned long )((u8 *)0U)) {
    return (-12);
  } else {

  }
  memcpy((void *)raw_packet, (void const   *)(& packet), 54UL);
  ip = (struct iphdr *)raw_packet + 14U;
  tcp = (struct tcphdr *)raw_packet + 34U;
  ip->daddr = fd_data->dst_ip[0];
  tcp->dest = fd_data->dst_port;
  ip->saddr = fd_data->src_ip[0];
  tcp->source = fd_data->src_port;
  if ((int )add) {
    pf->fd_tcp_rule = pf->fd_tcp_rule + 1U;
    if ((pf->flags & 4194304ULL) != 0ULL) {
      if ((pf->hw.debug_mask & 4096U) != 0U) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Forcing ATR off, sideband rules for TCP/IPv4 flow being applied\n");
      } else {

      }
      pf->flags = pf->flags & 0xffffffffffbfffffULL;
    } else {

    }
  } else {
    pf->fd_tcp_rule = pf->fd_tcp_rule != 0U ? pf->fd_tcp_rule - 1U : 0U;
    if (pf->fd_tcp_rule == 0U) {
      pf->flags = pf->flags | 4194304ULL;
      if ((pf->hw.debug_mask & 4096U) != 0U) {
        _dev_info((struct device  const  *)(& (pf->pdev)->dev), "ATR re-enabled due to no sideband TCP/IPv4 rules\n");
      } else {

      }
    } else {

    }
  }
  fd_data->pctype = 33U;
  ret = i40e_program_fdir_filter(fd_data, raw_packet, pf, (int )add);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "PCTYPE:%d, Filter command send failed for fd_id:%d (ret = %d)\n",
              (int )fd_data->pctype, fd_data->fd_id, ret);
    err = 1;
  } else
  if ((pf->hw.debug_mask & 4096U) != 0U) {
    if ((int )add) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Filter OK for PCTYPE %d loc = %d)\n",
                (int )fd_data->pctype, fd_data->fd_id);
    } else {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Filter deleted for PCTYPE %d loc = %d\n",
                (int )fd_data->pctype, fd_data->fd_id);
    }
  } else {

  }
  return ((int )err ? -95 : 0);
}
}
static int i40e_add_del_fdir_sctpv4(struct i40e_vsi *vsi , struct i40e_fdir_filter *fd_data ,
                                    bool add ) 
{ 


  {
  return (-95);
}
}
static int i40e_add_del_fdir_ipv4(struct i40e_vsi *vsi , struct i40e_fdir_filter *fd_data ,
                                  bool add ) 
{ 
  struct i40e_pf *pf ;
  struct iphdr *ip ;
  bool err ;
  u8 *raw_packet ;
  int ret ;
  int i ;
  char packet[34U] ;
  void *tmp ;

  {
  pf = vsi->back;
  err = 0;
  packet[0] = 0;
  packet[1] = 0;
  packet[2] = 0;
  packet[3] = 0;
  packet[4] = 0;
  packet[5] = 0;
  packet[6] = 0;
  packet[7] = 0;
  packet[8] = 0;
  packet[9] = 0;
  packet[10] = 0;
  packet[11] = 0;
  packet[12] = 8;
  packet[13] = 0;
  packet[14] = 69;
  packet[15] = 0;
  packet[16] = 0;
  packet[17] = 20;
  packet[18] = 0;
  packet[19] = 0;
  packet[20] = 64;
  packet[21] = 0;
  packet[22] = 64;
  packet[23] = 16;
  packet[24] = 0;
  packet[25] = 0;
  packet[26] = 0;
  packet[27] = 0;
  packet[28] = 0;
  packet[29] = 0;
  packet[30] = 0;
  packet[31] = 0;
  packet[32] = 0;
  packet[33] = 0;
  i = 35;
  goto ldv_61147;
  ldv_61146: 
  tmp = kzalloc(512UL, 208U);
  raw_packet = (u8 *)tmp;
  if ((unsigned long )raw_packet == (unsigned long )((u8 *)0U)) {
    return (-12);
  } else {

  }
  memcpy((void *)raw_packet, (void const   *)(& packet), 34UL);
  ip = (struct iphdr *)raw_packet + 14U;
  ip->saddr = fd_data->src_ip[0];
  ip->daddr = fd_data->dst_ip[0];
  ip->protocol = 0U;
  fd_data->pctype = (u8 )i;
  ret = i40e_program_fdir_filter(fd_data, raw_packet, pf, (int )add);
  if (ret != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "PCTYPE:%d, Filter command send failed for fd_id:%d (ret = %d)\n",
              (int )fd_data->pctype, fd_data->fd_id, ret);
    err = 1;
  } else
  if ((pf->hw.debug_mask & 4096U) != 0U) {
    if ((int )add) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Filter OK for PCTYPE %d loc = %d\n",
                (int )fd_data->pctype, fd_data->fd_id);
    } else {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Filter deleted for PCTYPE %d loc = %d\n",
                (int )fd_data->pctype, fd_data->fd_id);
    }
  } else {

  }
  i = i + 1;
  ldv_61147: ;
  if (i <= 36) {
    goto ldv_61146;
  } else {

  }

  return ((int )err ? -95 : 0);
}
}
int i40e_add_del_fdir(struct i40e_vsi *vsi , struct i40e_fdir_filter *input , bool add ) 
{ 
  struct i40e_pf *pf ;
  int ret ;

  {
  pf = vsi->back;
  switch ((unsigned int )input->flow_type) {
  case 1U: 
  ret = i40e_add_del_fdir_tcpv4(vsi, input, (int )add);
  goto ldv_61157;
  case 2U: 
  ret = i40e_add_del_fdir_udpv4(vsi, input, (int )add);
  goto ldv_61157;
  case 3U: 
  ret = i40e_add_del_fdir_sctpv4(vsi, input, (int )add);
  goto ldv_61157;
  case 16U: 
  ret = i40e_add_del_fdir_ipv4(vsi, input, (int )add);
  goto ldv_61157;
  case 13U: ;
  switch ((int )input->ip4_proto) {
  case 6: 
  ret = i40e_add_del_fdir_tcpv4(vsi, input, (int )add);
  goto ldv_61163;
  case 17: 
  ret = i40e_add_del_fdir_udpv4(vsi, input, (int )add);
  goto ldv_61163;
  case 132: 
  ret = i40e_add_del_fdir_sctpv4(vsi, input, (int )add);
  goto ldv_61163;
  default: 
  ret = i40e_add_del_fdir_ipv4(vsi, input, (int )add);
  goto ldv_61163;
  }
  ldv_61163: ;
  goto ldv_61157;
  default: 
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Could not specify spec type %d\n",
            (int )input->flow_type);
  ret = -22;
  }
  ldv_61157: ;
  return (ret);
}
}
static void i40e_fd_handle_status(struct i40e_ring *rx_ring , union i40e_32byte_rx_desc *rx_desc ,
                                  u8 prog_id ) 
{ 
  struct i40e_pf *pf ;
  struct pci_dev *pdev ;
  u32 fcnt_prog ;
  u32 fcnt_avail ;
  u32 error ;
  u64 qw ;
  int tmp ;

  {
  pf = (rx_ring->vsi)->back;
  pdev = pf->pdev;
  qw = rx_desc->wb.qword1.status_error_len;
  error = (u32 )((qw & 33030144ULL) >> 19);
  if (error == 1U) {
    if (rx_desc->wb.qword0.hi_dword.fd_id != 0U || (pf->hw.debug_mask & 4096U) != 0U) {
      dev_warn((struct device  const  *)(& pdev->dev), "ntuple filter loc = %d, could not be added\n",
               rx_desc->wb.qword0.hi_dword.fd_id);
    } else {

    }
    tmp = constant_test_bit(22L, (unsigned long const volatile   *)(& pf->state));
    if (tmp != 0) {
      return;
    } else {

    }
    pf->fd_add_err = pf->fd_add_err + 1U;
    pf->fd_atr_cnt = i40e_get_current_atr_cnt(pf);
    if (rx_desc->wb.qword0.hi_dword.fd_id == 0U && (pf->auto_disable_flags & 2097152ULL) != 0ULL) {
      pf->auto_disable_flags = pf->auto_disable_flags | 4194304ULL;
      set_bit(22L, (unsigned long volatile   *)(& pf->state));
    } else {

    }
    fcnt_prog = i40e_get_global_fd_count(pf);
    fcnt_avail = (u32 )pf->fdir_pf_filter_count;
    if (fcnt_avail - 10U <= fcnt_prog) {
      if ((pf->flags & 2097152ULL) != 0ULL && (pf->auto_disable_flags & 2097152ULL) == 0ULL) {
        if ((pf->hw.debug_mask & 4096U) != 0U) {
          dev_warn((struct device  const  *)(& pdev->dev), "FD filter space full, new ntuple rules will not be added\n");
        } else {

        }
        pf->auto_disable_flags = pf->auto_disable_flags | 2097152ULL;
      } else {

      }
    } else {
      _dev_info((struct device  const  *)(& pdev->dev), "FD filter programming failed due to incorrect filter parameters\n");
    }
  } else
  if (error == 2U) {
    if ((pf->hw.debug_mask & 4096U) != 0U) {
      _dev_info((struct device  const  *)(& pdev->dev), "ntuple filter fd_id = %d, could not be removed\n",
                rx_desc->wb.qword0.hi_dword.fd_id);
    } else {

    }
  } else {

  }
  return;
}
}
static void i40e_unmap_and_free_tx_resource(struct i40e_ring *ring , struct i40e_tx_buffer *tx_buffer ) 
{ 


  {
  if ((unsigned long )tx_buffer->__annonCompField120.skb != (unsigned long )((struct sk_buff *)0)) {
    if ((tx_buffer->tx_flags & 512U) != 0U) {
      kfree((void const   *)tx_buffer->__annonCompField120.raw_buf);
    } else {
      dev_kfree_skb_any(tx_buffer->__annonCompField120.skb);
    }
    if (tx_buffer->len != 0U) {
      dma_unmap_single_attrs___0(ring->dev, tx_buffer->dma, (size_t )tx_buffer->len,
                                 1, (struct dma_attrs *)0);
    } else {

    }
  } else
  if (tx_buffer->len != 0U) {
    dma_unmap_page(ring->dev, tx_buffer->dma, (size_t )tx_buffer->len, 1);
  } else {

  }
  tx_buffer->next_to_watch = (struct i40e_tx_desc *)0;
  tx_buffer->__annonCompField120.skb = (struct sk_buff *)0;
  tx_buffer->len = 0U;
  return;
}
}
void i40e_clean_tx_ring(struct i40e_ring *tx_ring ) 
{ 
  unsigned long bi_size ;
  u16 i ;
  struct netdev_queue *tmp ;

  {
  if ((unsigned long )tx_ring->__annonCompField121.tx_bi == (unsigned long )((struct i40e_tx_buffer *)0)) {
    return;
  } else {

  }
  i = 0U;
  goto ldv_61189;
  ldv_61188: 
  i40e_unmap_and_free_tx_resource(tx_ring, tx_ring->__annonCompField121.tx_bi + (unsigned long )i);
  i = (u16 )((int )i + 1);
  ldv_61189: ;
  if ((int )tx_ring->count > (int )i) {
    goto ldv_61188;
  } else {

  }
  bi_size = (unsigned long )tx_ring->count * 40UL;
  memset((void *)tx_ring->__annonCompField121.tx_bi, 0, bi_size);
  memset(tx_ring->desc, 0, (size_t )tx_ring->size);
  tx_ring->next_to_use = 0U;
  tx_ring->next_to_clean = 0U;
  if ((unsigned long )tx_ring->netdev == (unsigned long )((struct net_device *)0)) {
    return;
  } else {

  }
  tmp = netdev_get_tx_queue((struct net_device  const  *)tx_ring->netdev, (unsigned int )tx_ring->queue_index);
  netdev_tx_reset_queue(tmp);
  return;
}
}
void i40e_free_tx_resources(struct i40e_ring *tx_ring ) 
{ 


  {
  i40e_clean_tx_ring(tx_ring);
  kfree((void const   *)tx_ring->__annonCompField121.tx_bi);
  tx_ring->__annonCompField121.tx_bi = (struct i40e_tx_buffer *)0;
  if ((unsigned long )tx_ring->desc != (unsigned long )((void *)0)) {
    dma_free_attrs(tx_ring->dev, (size_t )tx_ring->size, tx_ring->desc, tx_ring->dma,
                   (struct dma_attrs *)0);
    tx_ring->desc = (void *)0;
  } else {

  }
  return;
}
}
__inline static u32 i40e_get_head(struct i40e_ring *tx_ring ) 
{ 
  void *head ;

  {
  head = tx_ring->desc + (unsigned long )tx_ring->count;
  return ((u32 )*((__le32 volatile   *)head));
}
}
static u32 i40e_get_tx_pending(struct i40e_ring *ring ) 
{ 
  u32 head ;
  u32 tail ;

  {
  head = i40e_get_head(ring);
  tail = readl((void const volatile   *)ring->tail);
  if (head != tail) {
    return (head < tail ? tail - head : ((u32 )ring->count + tail) - head);
  } else {

  }
  return (0U);
}
}
static bool i40e_check_tx_hang(struct i40e_ring *tx_ring ) 
{ 
  u32 tx_done ;
  u32 tx_done_old ;
  u32 tx_pending ;
  u32 tmp ;
  struct i40e_pf *pf ;
  bool ret ;
  int tmp___0 ;

  {
  tx_done = (u32 )tx_ring->stats.packets;
  tx_done_old = (u32 )tx_ring->__annonCompField122.tx_stats.tx_done_old;
  tmp = i40e_get_tx_pending(tx_ring);
  tx_pending = tmp;
  pf = (tx_ring->vsi)->back;
  ret = 0;
  clear_bit(2L, (unsigned long volatile   *)(& tx_ring->state));
  if (tx_done_old == tx_done && tx_pending != 0U) {
    tmp___0 = test_and_set_bit(3L, (unsigned long volatile   *)(& tx_ring->state));
    ret = tmp___0 != 0;
  } else
  if ((tx_done_old == tx_done && tx_pending <= 3U) && tx_pending != 0U) {
    if ((pf->hw.debug_mask & 512U) != 0U) {
      _dev_info((struct device  const  *)tx_ring->dev, "HW needs some more descs to do a cacheline flush. tx_pending %d, queue %d",
                tx_pending, (int )tx_ring->queue_index);
    } else {

    }
    pf->tx_sluggish_count = pf->tx_sluggish_count + 1U;
  } else {
    tx_ring->__annonCompField122.tx_stats.tx_done_old = (u64 )tx_done;
    clear_bit(3L, (unsigned long volatile   *)(& tx_ring->state));
  }
  return (ret);
}
}
static bool i40e_clean_tx_irq(struct i40e_ring *tx_ring , int budget ) 
{ 
  u16 i ;
  struct i40e_tx_buffer *tx_buf ;
  struct i40e_tx_desc *tx_head ;
  struct i40e_tx_desc *tx_desc ;
  unsigned int total_packets ;
  unsigned int total_bytes ;
  u32 tmp ;
  struct i40e_tx_desc *eop_desc ;
  long tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  bool tmp___5 ;
  struct netdev_queue *tmp___6 ;
  bool tmp___7 ;
  int tmp___8 ;
  bool tmp___9 ;
  int tmp___10 ;
  long tmp___11 ;

  {
  i = tx_ring->next_to_clean;
  total_packets = 0U;
  total_bytes = 0U;
  tx_buf = tx_ring->__annonCompField121.tx_bi + (unsigned long )i;
  tx_desc = (struct i40e_tx_desc *)tx_ring->desc + (unsigned long )i;
  i = (int )i - (int )tx_ring->count;
  tmp = i40e_get_head(tx_ring);
  tx_head = (struct i40e_tx_desc *)tx_ring->desc + (unsigned long )tmp;
  ldv_61226: 
  eop_desc = tx_buf->next_to_watch;
  if ((unsigned long )eop_desc == (unsigned long )((struct i40e_tx_desc *)0)) {
    goto ldv_61222;
  } else {

  }
  if ((unsigned long )tx_head == (unsigned long )tx_desc) {
    goto ldv_61222;
  } else {

  }
  tx_buf->next_to_watch = (struct i40e_tx_desc *)0;
  total_bytes = tx_buf->bytecount + total_bytes;
  total_packets = (unsigned int )tx_buf->gso_segs + total_packets;
  dev_consume_skb_any(tx_buf->__annonCompField120.skb);
  dma_unmap_single_attrs___0(tx_ring->dev, tx_buf->dma, (size_t )tx_buf->len, 1, (struct dma_attrs *)0);
  tx_buf->__annonCompField120.skb = (struct sk_buff *)0;
  tx_buf->len = 0U;
  goto ldv_61224;
  ldv_61223: 
  tx_buf = tx_buf + 1;
  tx_desc = tx_desc + 1;
  i = (u16 )((int )i + 1);
  tmp___0 = ldv__builtin_expect((unsigned int )i == 0U, 0L);
  if (tmp___0 != 0L) {
    i = (int )i - (int )tx_ring->count;
    tx_buf = tx_ring->__annonCompField121.tx_bi;
    tx_desc = (struct i40e_tx_desc *)tx_ring->desc;
  } else {

  }
  if (tx_buf->len != 0U) {
    dma_unmap_page(tx_ring->dev, tx_buf->dma, (size_t )tx_buf->len, 1);
    tx_buf->len = 0U;
  } else {

  }
  ldv_61224: ;
  if ((unsigned long )tx_desc != (unsigned long )eop_desc) {
    goto ldv_61223;
  } else {

  }
  tx_buf = tx_buf + 1;
  tx_desc = tx_desc + 1;
  i = (u16 )((int )i + 1);
  tmp___1 = ldv__builtin_expect((unsigned int )i == 0U, 0L);
  if (tmp___1 != 0L) {
    i = (int )i - (int )tx_ring->count;
    tx_buf = tx_ring->__annonCompField121.tx_bi;
    tx_desc = (struct i40e_tx_desc *)tx_ring->desc;
  } else {

  }
  __builtin_prefetch((void const   *)tx_desc);
  budget = budget - 1;
  tmp___2 = ldv__builtin_expect(budget != 0, 1L);
  if (tmp___2 != 0L) {
    goto ldv_61226;
  } else {

  }
  ldv_61222: 
  i = (int )tx_ring->count + (int )i;
  tx_ring->next_to_clean = i;
  u64_stats_init(& tx_ring->syncp);
  tx_ring->stats.bytes = tx_ring->stats.bytes + (u64 )total_bytes;
  tx_ring->stats.packets = tx_ring->stats.packets + (u64 )total_packets;
  u64_stats_init(& tx_ring->syncp);
  (tx_ring->q_vector)->tx.total_bytes = (tx_ring->q_vector)->tx.total_bytes + total_bytes;
  (tx_ring->q_vector)->tx.total_packets = (tx_ring->q_vector)->tx.total_packets + total_packets;
  if (budget != 0 && ((int )i & 3) != 3) {
    tmp___3 = constant_test_bit(3L, (unsigned long const volatile   *)(& (tx_ring->vsi)->state));
    if (tmp___3 == 0) {
      if (((((int )tx_ring->next_to_clean <= (int )tx_ring->next_to_use ? (int )tx_ring->count : 0) + (int )tx_ring->next_to_clean) - (int )tx_ring->next_to_use) + -1 != (int )tx_ring->count) {
        tx_ring->arm_wb = 1;
      } else {
        tx_ring->arm_wb = 0;
      }
    } else {
      tx_ring->arm_wb = 0;
    }
  } else {
    tx_ring->arm_wb = 0;
  }
  tmp___4 = constant_test_bit(2L, (unsigned long const volatile   *)(& tx_ring->state));
  if (tmp___4 != 0) {
    tmp___5 = i40e_check_tx_hang(tx_ring);
    if ((int )tmp___5) {
      _dev_info((struct device  const  *)tx_ring->dev, "Detected Tx Unit Hang\n  VSI                  <%d>\n  Tx Queue             <%d>\n  next_to_use          <%x>\n  next_to_clean        <%x>\n",
                (int )(tx_ring->vsi)->seid, (int )tx_ring->queue_index, (int )tx_ring->next_to_use,
                (int )i);
      netif_stop_subqueue(tx_ring->netdev, (int )tx_ring->queue_index);
      _dev_info((struct device  const  *)tx_ring->dev, "tx hang detected on queue %d, reset requested\n",
                (int )tx_ring->queue_index);
      budget = 1;
    } else {

    }
  } else {

  }
  tmp___6 = netdev_get_tx_queue((struct net_device  const  *)tx_ring->netdev, (unsigned int )tx_ring->queue_index);
  netdev_tx_completed_queue(tmp___6, total_packets, total_bytes);
  if (total_packets != 0U) {
    tmp___9 = netif_carrier_ok((struct net_device  const  *)tx_ring->netdev);
    if ((int )tmp___9) {
      if ((unsigned int )(((((int )tx_ring->next_to_clean <= (int )tx_ring->next_to_use ? (int )tx_ring->count : 0) + (int )tx_ring->next_to_clean) - (int )tx_ring->next_to_use) + -1) > 41U) {
        tmp___10 = 1;
      } else {
        tmp___10 = 0;
      }
    } else {
      tmp___10 = 0;
    }
  } else {
    tmp___10 = 0;
  }
  tmp___11 = ldv__builtin_expect((long )tmp___10, 0L);
  if (tmp___11 != 0L) {
    __asm__  volatile   ("mfence": : : "memory");
    tmp___7 = __netif_subqueue_stopped((struct net_device  const  *)tx_ring->netdev,
                                       (int )tx_ring->queue_index);
    if ((int )tmp___7) {
      tmp___8 = constant_test_bit(3L, (unsigned long const volatile   *)(& (tx_ring->vsi)->state));
      if (tmp___8 == 0) {
        netif_wake_subqueue(tx_ring->netdev, (int )tx_ring->queue_index);
        tx_ring->__annonCompField122.tx_stats.restart_queue = tx_ring->__annonCompField122.tx_stats.restart_queue + 1ULL;
      } else {

      }
    } else {

    }
  } else {

  }
  return (budget != 0);
}
}
static void i40e_force_wb(struct i40e_vsi *vsi , struct i40e_q_vector *q_vector ) 
{ 
  u32 val ;

  {
  val = 16777245U;
  writel(val, (void volatile   *)(vsi->back)->hw.hw_addr + (unsigned long )((((int )q_vector->v_idx + vsi->base_vector) + 53759) * 4));
  return;
}
}
static void i40e_set_new_dynamic_itr(struct i40e_ring_container *rc ) 
{ 
  enum i40e_latency_range new_latency_range ;
  u32 new_itr ;
  int bytes_per_int ;
    klee_make_symbolic(&bytes_per_int, sizeof(int), "bytes_per_int");

  {
  new_latency_range = rc->latency_range;
  new_itr = (u32 )rc->itr;
  if (rc->total_packets == 0U || (unsigned int )rc->itr == 0U) {
    return;
  } else {

  }
  bytes_per_int = (int )(rc->total_bytes / (unsigned int )rc->itr);
  switch ((int )rc->itr) {
  case 0: ;
  if (bytes_per_int > 10) {
    new_latency_range = 1;
  } else {

  }
  goto ldv_61239;
  case 1: ;
  if (bytes_per_int > 20) {
    new_latency_range = 2;
  } else
  if (bytes_per_int <= 10) {
    new_latency_range = 0;
  } else {

  }
  goto ldv_61239;
  case 2: ;
  if (bytes_per_int <= 20) {
    rc->latency_range = 1;
  } else {

  }
  goto ldv_61239;
  }
  ldv_61239: ;
  switch ((unsigned int )new_latency_range) {
  case 0U: 
  new_itr = 5U;
  goto ldv_61243;
  case 1U: 
  new_itr = 25U;
  goto ldv_61243;
  case 2U: 
  new_itr = 62U;
  goto ldv_61243;
  default: ;
  goto ldv_61243;
  }
  ldv_61243: ;
  if ((u32 )rc->itr != new_itr) {
    new_itr = (((u32 )rc->itr * new_itr) * 10U) / (new_itr * 9U + (u32 )rc->itr);
    rc->itr = (unsigned int )((u16 )new_itr) & 4080U;
  } else {

  }
  rc->total_bytes = 0U;
  rc->total_packets = 0U;
  return;
}
}
static void i40e_update_dynamic_itr(struct i40e_q_vector *q_vector ) 
{ 
  u16 vector ;
  struct i40e_hw *hw ;
  u32 reg_addr ;
  u16 old_itr ;

  {
  vector = (int )((u16 )(q_vector->vsi)->base_vector) + (int )q_vector->v_idx;
  hw = & ((q_vector->vsi)->back)->hw;
  reg_addr = (u32 )(((int )vector + 49151) * 4);
  old_itr = q_vector->rx.itr;
  i40e_set_new_dynamic_itr(& q_vector->rx);
  if ((int )q_vector->rx.itr != (int )old_itr) {
    writel((unsigned int )q_vector->rx.itr, (void volatile   *)hw->hw_addr + (unsigned long )reg_addr);
  } else {

  }
  reg_addr = (u32 )(((int )vector + 49663) * 4);
  old_itr = q_vector->tx.itr;
  i40e_set_new_dynamic_itr(& q_vector->tx);
  if ((int )q_vector->tx.itr != (int )old_itr) {
    writel((unsigned int )q_vector->tx.itr, (void volatile   *)hw->hw_addr + (unsigned long )reg_addr);
  } else {

  }
  return;
}
}
static void i40e_clean_programming_status(struct i40e_ring *rx_ring , union i40e_32byte_rx_desc *rx_desc ) 
{ 
  u64 qw ;
  u8 id ;

  {
  qw = rx_desc->wb.qword1.status_error_len;
  id = (u8 )((qw & 28ULL) >> 2);
  if ((unsigned int )id == 1U) {
    i40e_fd_handle_status(rx_ring, rx_desc, (int )id);
  } else
  if ((unsigned int )id == 2U || (unsigned int )id == 4U) {
    i40e_fcoe_handle_status(rx_ring, rx_desc, (int )id);
  } else {

  }
  return;
}
}
int i40e_setup_tx_descriptors(struct i40e_ring *tx_ring ) 
{ 
  struct device *dev ;
  int bi_size ;
  void *tmp ;

  {
  dev = tx_ring->dev;
  if ((unsigned long )dev == (unsigned long )((struct device *)0)) {
    return (-12);
  } else {

  }
  bi_size = (int )((unsigned int )tx_ring->count * 40U);
  tmp = kzalloc((size_t )bi_size, 208U);
  tx_ring->__annonCompField121.tx_bi = (struct i40e_tx_buffer *)tmp;
  if ((unsigned long )tx_ring->__annonCompField121.tx_bi == (unsigned long )((struct i40e_tx_buffer *)0)) {
    goto err;
  } else {

  }
  tx_ring->size = (unsigned int )tx_ring->count * 16U;
  tx_ring->size = tx_ring->size + 4U;
  tx_ring->size = (tx_ring->size + 4095U) & 4294963200U;
  tx_ring->desc = dma_alloc_attrs(dev, (size_t )tx_ring->size, & tx_ring->dma, 208U,
                                  (struct dma_attrs *)0);
  if ((unsigned long )tx_ring->desc == (unsigned long )((void *)0)) {
    _dev_info((struct device  const  *)dev, "Unable to allocate memory for the Tx descriptor ring, size=%d\n",
              tx_ring->size);
    goto err;
  } else {

  }
  tx_ring->next_to_use = 0U;
  tx_ring->next_to_clean = 0U;
  return (0);
  err: 
  kfree((void const   *)tx_ring->__annonCompField121.tx_bi);
  tx_ring->__annonCompField121.tx_bi = (struct i40e_tx_buffer *)0;
  return (-12);
}
}
void i40e_clean_rx_ring(struct i40e_ring *rx_ring ) 
{ 
  struct device *dev ;
  struct i40e_rx_buffer *rx_bi ;
  unsigned long bi_size ;
  u16 i ;
  int bufsz ;
    klee_make_symbolic(&bufsz, sizeof(int), "bufsz");
  int tmp ;

  {
  dev = rx_ring->dev;
  if ((unsigned long )rx_ring->__annonCompField121.rx_bi == (unsigned long )((struct i40e_rx_buffer *)0)) {
    return;
  } else {

  }
  tmp = constant_test_bit(4L, (unsigned long const volatile   *)(& rx_ring->state));
  if (tmp != 0) {
    bufsz = (((int )rx_ring->rx_hdr_len + 255) & -256) * (int )rx_ring->count;
    rx_bi = rx_ring->__annonCompField121.rx_bi;
    if ((unsigned long )rx_bi->hdr_buf != (unsigned long )((void *)0)) {
      dma_free_attrs(dev, (size_t )bufsz, rx_bi->hdr_buf, rx_bi->dma, (struct dma_attrs *)0);
      i = 0U;
      goto ldv_61275;
      ldv_61274: 
      rx_bi = rx_ring->__annonCompField121.rx_bi + (unsigned long )i;
      rx_bi->dma = 0ULL;
      rx_bi->hdr_buf = (void *)0;
      i = (u16 )((int )i + 1);
      ldv_61275: ;
      if ((int )rx_ring->count > (int )i) {
        goto ldv_61274;
      } else {

      }

    } else {

    }
  } else {

  }
  i = 0U;
  goto ldv_61278;
  ldv_61277: 
  rx_bi = rx_ring->__annonCompField121.rx_bi + (unsigned long )i;
  if (rx_bi->dma != 0ULL) {
    dma_unmap_single_attrs___0(dev, rx_bi->dma, (size_t )rx_ring->rx_buf_len, 2, (struct dma_attrs *)0);
    rx_bi->dma = 0ULL;
  } else {

  }
  if ((unsigned long )rx_bi->skb != (unsigned long )((struct sk_buff *)0)) {
    consume_skb(rx_bi->skb);
    rx_bi->skb = (struct sk_buff *)0;
  } else {

  }
  if ((unsigned long )rx_bi->page != (unsigned long )((struct page *)0)) {
    if (rx_bi->page_dma != 0ULL) {
      dma_unmap_page(dev, rx_bi->page_dma, 2048UL, 2);
      rx_bi->page_dma = 0ULL;
    } else {

    }
    __free_pages(rx_bi->page, 0U);
    rx_bi->page = (struct page *)0;
    rx_bi->page_offset = 0U;
  } else {

  }
  i = (u16 )((int )i + 1);
  ldv_61278: ;
  if ((int )rx_ring->count > (int )i) {
    goto ldv_61277;
  } else {

  }
  bi_size = (unsigned long )rx_ring->count * 48UL;
  memset((void *)rx_ring->__annonCompField121.rx_bi, 0, bi_size);
  memset(rx_ring->desc, 0, (size_t )rx_ring->size);
  rx_ring->next_to_clean = 0U;
  rx_ring->next_to_use = 0U;
  return;
}
}
void i40e_free_rx_resources(struct i40e_ring *rx_ring ) 
{ 


  {
  i40e_clean_rx_ring(rx_ring);
  kfree((void const   *)rx_ring->__annonCompField121.rx_bi);
  rx_ring->__annonCompField121.rx_bi = (struct i40e_rx_buffer *)0;
  if ((unsigned long )rx_ring->desc != (unsigned long )((void *)0)) {
    dma_free_attrs(rx_ring->dev, (size_t )rx_ring->size, rx_ring->desc, rx_ring->dma,
                   (struct dma_attrs *)0);
    rx_ring->desc = (void *)0;
  } else {

  }
  return;
}
}
void i40e_alloc_rx_headers(struct i40e_ring *rx_ring ) 
{ 
  struct device *dev ;
  struct i40e_rx_buffer *rx_bi ;
  dma_addr_t dma ;
  void *buffer ;
  int buf_size ;
  int i ;

  {
  dev = rx_ring->dev;
  if ((unsigned long )(rx_ring->__annonCompField121.rx_bi)->hdr_buf != (unsigned long )((void *)0)) {
    return;
  } else {

  }
  buf_size = ((int )rx_ring->rx_hdr_len + 255) & -256;
  buffer = dma_alloc_attrs(dev, (size_t )((int )rx_ring->count * buf_size), & dma,
                           208U, (struct dma_attrs *)0);
  if ((unsigned long )buffer == (unsigned long )((void *)0)) {
    return;
  } else {

  }
  i = 0;
  goto ldv_61293;
  ldv_61292: 
  rx_bi = rx_ring->__annonCompField121.rx_bi + (unsigned long )i;
  rx_bi->dma = (dma_addr_t )(i * buf_size) + dma;
  rx_bi->hdr_buf = buffer + (unsigned long )(i * buf_size);
  i = i + 1;
  ldv_61293: ;
  if ((int )rx_ring->count > i) {
    goto ldv_61292;
  } else {

  }

  return;
}
}
int i40e_setup_rx_descriptors(struct i40e_ring *rx_ring ) 
{ 
  struct device *dev ;
  int bi_size ;
  void *tmp ;
  int tmp___0 ;

  {
  dev = rx_ring->dev;
  bi_size = (int )((unsigned int )rx_ring->count * 48U);
  tmp = kzalloc((size_t )bi_size, 208U);
  rx_ring->__annonCompField121.rx_bi = (struct i40e_rx_buffer *)tmp;
  if ((unsigned long )rx_ring->__annonCompField121.rx_bi == (unsigned long )((struct i40e_rx_buffer *)0)) {
    goto err;
  } else {

  }
  u64_stats_init(& rx_ring->syncp);
  tmp___0 = constant_test_bit(5L, (unsigned long const volatile   *)(& rx_ring->state));
  rx_ring->size = tmp___0 != 0 ? (unsigned int )rx_ring->count * 16U : (unsigned int )rx_ring->count * 32U;
  rx_ring->size = (rx_ring->size + 4095U) & 4294963200U;
  rx_ring->desc = dma_alloc_attrs(dev, (size_t )rx_ring->size, & rx_ring->dma, 208U,
                                  (struct dma_attrs *)0);
  if ((unsigned long )rx_ring->desc == (unsigned long )((void *)0)) {
    _dev_info((struct device  const  *)dev, "Unable to allocate memory for the Rx descriptor ring, size=%d\n",
              rx_ring->size);
    goto err;
  } else {

  }
  rx_ring->next_to_clean = 0U;
  rx_ring->next_to_use = 0U;
  return (0);
  err: 
  kfree((void const   *)rx_ring->__annonCompField121.rx_bi);
  rx_ring->__annonCompField121.rx_bi = (struct i40e_rx_buffer *)0;
  return (-12);
}
}
__inline static void i40e_release_rx_desc(struct i40e_ring *rx_ring , u32 val ) 
{ 


  {
  rx_ring->next_to_use = (u16 )val;
  __asm__  volatile   ("sfence": : : "memory");
  writel(val, (void volatile   *)rx_ring->tail);
  return;
}
}
void i40e_alloc_rx_buffers_ps(struct i40e_ring *rx_ring , u16 cleaned_count ) 
{ 
  u16 i ;
  union i40e_32byte_rx_desc *rx_desc ;
  struct i40e_rx_buffer *bi ;
  int tmp ;
  u16 tmp___0 ;

  {
  i = rx_ring->next_to_use;
  if ((unsigned long )rx_ring->netdev == (unsigned long )((struct net_device *)0) || (unsigned int )cleaned_count == 0U) {
    return;
  } else {

  }
  goto ldv_61314;
  ldv_61313: 
  constant_test_bit(5L, (unsigned long const volatile   *)(& rx_ring->state));
  rx_desc = (union i40e_32byte_rx_desc *)rx_ring->desc + (unsigned long )i;
  bi = rx_ring->__annonCompField121.rx_bi + (unsigned long )i;
  if ((unsigned long )bi->skb != (unsigned long )((struct sk_buff *)0)) {
    goto no_buffers;
  } else {

  }
  if ((unsigned long )bi->page == (unsigned long )((struct page *)0)) {
    bi->page = alloc_pages(32U, 0U);
    if ((unsigned long )bi->page == (unsigned long )((struct page *)0)) {
      rx_ring->__annonCompField122.rx_stats.alloc_page_failed = rx_ring->__annonCompField122.rx_stats.alloc_page_failed + 1ULL;
      goto no_buffers;
    } else {

    }
  } else {

  }
  if (bi->page_dma == 0ULL) {
    bi->page_offset = bi->page_offset ^ 2048U;
    bi->page_dma = dma_map_page(rx_ring->dev, bi->page, (size_t )bi->page_offset,
                                2048UL, 2);
    tmp = dma_mapping_error(rx_ring->dev, bi->page_dma);
    if (tmp != 0) {
      rx_ring->__annonCompField122.rx_stats.alloc_page_failed = rx_ring->__annonCompField122.rx_stats.alloc_page_failed + 1ULL;
      bi->page_dma = 0ULL;
      goto no_buffers;
    } else {

    }
  } else {

  }
  dma_sync_single_range_for_device(rx_ring->dev, bi->dma, 0UL, (size_t )rx_ring->rx_hdr_len,
                                   2);
  rx_desc->read.pkt_addr = bi->page_dma;
  rx_desc->read.hdr_addr = bi->dma;
  i = (u16 )((int )i + 1);
  if ((int )rx_ring->count == (int )i) {
    i = 0U;
  } else {

  }
  ldv_61314: 
  tmp___0 = cleaned_count;
  cleaned_count = (u16 )((int )cleaned_count - 1);
  if ((unsigned int )tmp___0 != 0U) {
    goto ldv_61313;
  } else {

  }

  no_buffers: ;
  if ((int )rx_ring->next_to_use != (int )i) {
    i40e_release_rx_desc(rx_ring, (u32 )i);
  } else {

  }
  return;
}
}
void i40e_alloc_rx_buffers_1buf(struct i40e_ring *rx_ring , u16 cleaned_count ) 
{ 
  u16 i ;
  union i40e_32byte_rx_desc *rx_desc ;
  struct i40e_rx_buffer *bi ;
  struct sk_buff *skb ;
  int tmp ;
  u16 tmp___0 ;

  {
  i = rx_ring->next_to_use;
  if ((unsigned long )rx_ring->netdev == (unsigned long )((struct net_device *)0) || (unsigned int )cleaned_count == 0U) {
    return;
  } else {

  }
  goto ldv_61326;
  ldv_61325: 
  constant_test_bit(5L, (unsigned long const volatile   *)(& rx_ring->state));
  rx_desc = (union i40e_32byte_rx_desc *)rx_ring->desc + (unsigned long )i;
  bi = rx_ring->__annonCompField121.rx_bi + (unsigned long )i;
  skb = bi->skb;
  if ((unsigned long )skb == (unsigned long )((struct sk_buff *)0)) {
    skb = netdev_alloc_skb_ip_align(rx_ring->netdev, (unsigned int )rx_ring->rx_buf_len);
    if ((unsigned long )skb == (unsigned long )((struct sk_buff *)0)) {
      rx_ring->__annonCompField122.rx_stats.alloc_buff_failed = rx_ring->__annonCompField122.rx_stats.alloc_buff_failed + 1ULL;
      goto no_buffers;
    } else {

    }
    skb_record_rx_queue(skb, (int )rx_ring->queue_index);
    bi->skb = skb;
  } else {

  }
  if (bi->dma == 0ULL) {
    bi->dma = dma_map_single_attrs(rx_ring->dev, (void *)skb->data, (size_t )rx_ring->rx_buf_len,
                                   2, (struct dma_attrs *)0);
    tmp = dma_mapping_error(rx_ring->dev, bi->dma);
    if (tmp != 0) {
      rx_ring->__annonCompField122.rx_stats.alloc_buff_failed = rx_ring->__annonCompField122.rx_stats.alloc_buff_failed + 1ULL;
      bi->dma = 0ULL;
      goto no_buffers;
    } else {

    }
  } else {

  }
  rx_desc->read.pkt_addr = bi->dma;
  rx_desc->read.hdr_addr = 0ULL;
  i = (u16 )((int )i + 1);
  if ((int )rx_ring->count == (int )i) {
    i = 0U;
  } else {

  }
  ldv_61326: 
  tmp___0 = cleaned_count;
  cleaned_count = (u16 )((int )cleaned_count - 1);
  if ((unsigned int )tmp___0 != 0U) {
    goto ldv_61325;
  } else {

  }

  no_buffers: ;
  if ((int )rx_ring->next_to_use != (int )i) {
    i40e_release_rx_desc(rx_ring, (u32 )i);
  } else {

  }
  return;
}
}
static void i40e_receive_skb(struct i40e_ring *rx_ring , struct sk_buff *skb , u16 vlan_tag ) 
{ 
  struct i40e_q_vector *q_vector ;
  struct i40e_vsi *vsi ;
  u64 flags ;

  {
  q_vector = rx_ring->q_vector;
  vsi = rx_ring->vsi;
  flags = (vsi->back)->flags;
  if (((int )vlan_tag & 4095) != 0) {
    __vlan_hwaccel_put_tag(skb, 129, (int )vlan_tag);
  } else {

  }
  if ((flags & 4096ULL) != 0ULL) {
    netif_rx(skb);
  } else {
    napi_gro_receive(& q_vector->napi, skb);
  }
  return;
}
}
__inline static void i40e_rx_checksum(struct i40e_vsi *vsi , struct sk_buff *skb ,
                                      u32 rx_status , u32 rx_error , u16 rx_ptype ) 
{ 
  struct i40e_rx_ptype_decoded decoded ;
  struct i40e_rx_ptype_decoded tmp ;
  bool ipv4 ;
  bool ipv6 ;
  bool ipv4_tunnel ;
  bool ipv6_tunnel ;
  __wsum rx_udp_csum ;
  struct iphdr *iph ;
  __sum16 csum ;
  struct iphdr *tmp___0 ;
  int tmp___1 ;
  struct udphdr *tmp___2 ;
  struct iphdr *tmp___3 ;
  struct udphdr *tmp___4 ;

  {
  tmp = decode_rx_desc_ptype((int )((u8 )rx_ptype));
  decoded = tmp;
  ipv4 = 0;
  ipv6 = 0;
  ipv4_tunnel = (bool )((unsigned int )rx_ptype > 57U && (unsigned int )rx_ptype <= 87U);
  ipv6_tunnel = (bool )((unsigned int )rx_ptype > 123U && (unsigned int )rx_ptype <= 153U);
  skb->ip_summed = 0U;
  if (((vsi->netdev)->features & 17179869184ULL) == 0ULL) {
    return;
  } else {

  }
  if ((rx_status & 8U) == 0U) {
    return;
  } else {

  }
  if ((unsigned int )*((unsigned char *)(& decoded) + 1UL) == 0U || (unsigned int )*((unsigned char *)(& decoded) + 1UL) == 0U) {
    return;
  } else {

  }
  if ((unsigned int )*((unsigned char *)(& decoded) + 1UL) != 0U && (unsigned int )*((unsigned char *)(& decoded) + 1UL) == 0U) {
    ipv4 = 1;
  } else
  if ((unsigned int )*((unsigned char *)(& decoded) + 1UL) != 0U && (unsigned int )*((unsigned char *)(& decoded) + 1UL) != 0U) {
    ipv6 = 1;
  } else {

  }
  if ((int )ipv4 && (rx_error & 40U) != 0U) {
    goto checksum_fail;
  } else {

  }
  if ((int )ipv6 && (rx_status & 32768U) != 0U) {
    return;
  } else {

  }
  if ((rx_error & 16U) != 0U) {
    goto checksum_fail;
  } else {

  }
  if ((rx_error & 128U) != 0U) {
    return;
  } else {

  }
  if ((int )ipv4_tunnel) {
    tmp___0 = ip_hdr((struct sk_buff  const  *)skb);
    skb->transport_header = ((unsigned int )skb->mac_header + (unsigned int )((__u16 )tmp___0->ihl) * 4U) + 14U;
    skb->transport_header = (unsigned int )skb->transport_header + ((unsigned int )skb->protocol == 129U || (unsigned int )skb->protocol == 43144U ? 4U : 0U);
    tmp___3 = ip_hdr((struct sk_buff  const  *)skb);
    if ((unsigned int )tmp___3->protocol == 17U) {
      tmp___4 = udp_hdr((struct sk_buff  const  *)skb);
      if ((unsigned int )tmp___4->check != 0U) {
        rx_udp_csum = udp_csum(skb);
        iph = ip_hdr((struct sk_buff  const  *)skb);
        tmp___1 = skb_transport_offset((struct sk_buff  const  *)skb);
        csum = csum_tcpudp_magic(iph->saddr, iph->daddr, (int )((unsigned short )skb->len) - (int )((unsigned short )tmp___1),
                                 17, rx_udp_csum);
        tmp___2 = udp_hdr((struct sk_buff  const  *)skb);
        if ((int )tmp___2->check != (int )csum) {
          goto checksum_fail;
        } else {

        }
      } else {

      }
    } else {

    }
  } else {

  }
  skb->ip_summed = 1U;
  skb->csum_level = (unsigned char )((int )ipv4_tunnel || (int )ipv6_tunnel);
  return;
  checksum_fail: 
  (vsi->back)->hw_csum_rx_error = (vsi->back)->hw_csum_rx_error + 1U;
  return;
}
}
__inline static u32 i40e_rx_hash(struct i40e_ring *ring , union i40e_32byte_rx_desc *rx_desc ) 
{ 
  __le64 rss_mask ;

  {
  rss_mask = 12288ULL;
  if (((ring->netdev)->features & 8589934592ULL) != 0ULL && (rx_desc->wb.qword1.status_error_len & rss_mask) == rss_mask) {
    return (rx_desc->wb.qword0.hi_dword.rss);
  } else {
    return (0U);
  }
}
}
__inline static enum pkt_hash_types i40e_ptype_to_hash(u8 ptype ) 
{ 
  struct i40e_rx_ptype_decoded decoded ;
  struct i40e_rx_ptype_decoded tmp ;

  {
  tmp = decode_rx_desc_ptype((int )ptype);
  decoded = tmp;
  if ((unsigned int )*((unsigned char *)(& decoded) + 1UL) == 0U) {
    return (0);
  } else {

  }
  if ((unsigned int )*((unsigned char *)(& decoded) + 1UL) != 0U && (unsigned int )*((unsigned short *)(& decoded) + 1UL) == 192U) {
    return (3);
  } else
  if ((unsigned int )*((unsigned char *)(& decoded) + 1UL) != 0U && (unsigned int )*((unsigned short *)(& decoded) + 1UL) == 128U) {
    return (2);
  } else {
    return (1);
  }
}
}
static int i40e_clean_rx_irq_ps(struct i40e_ring *rx_ring , int budget ) 
{ 
  unsigned int total_rx_bytes ;
    klee_make_symbolic(&total_rx_bytes, sizeof(int), "total_rx_bytes");
  unsigned int total_rx_packets ;
    klee_make_symbolic(&total_rx_packets, sizeof(int), "total_rx_packets");
  u16 rx_packet_len ;
  u16 rx_header_len ;
  u16 rx_sph ;
  u16 rx_hbo ;
  u16 cleaned_count ;
  int current_node ;
    klee_make_symbolic(&current_node, sizeof(int), "current_node");
  int tmp ;
  struct i40e_vsi *vsi ;
  u16 i ;
  union i40e_32byte_rx_desc *rx_desc ;
  u32 rx_error ;
  u32 rx_status ;
  u8 rx_ptype ;
  u64 qword ;
  struct i40e_rx_buffer *rx_bi ;
  struct sk_buff *skb ;
  u16 vlan_tag ;
  bool tmp___0 ;
  long tmp___1 ;
  int len ;
  unsigned char *tmp___2 ;
  int len___0 ;
    klee_make_symbolic(&len___0, sizeof(int), "len___0");
  unsigned int tmp___4 ;
  unsigned int tmp___5 ;
  unsigned char *tmp___6 ;
  unsigned char *tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;
  struct i40e_rx_buffer *next_buffer ;
  long tmp___10 ;
  long tmp___11 ;
  enum pkt_hash_types tmp___12 ;
  u32 tmp___13 ;
  long tmp___14 ;
  int tmp___15 ;
  long tmp___16 ;

  {
  total_rx_bytes = 0U;
  total_rx_packets = 0U;
  cleaned_count = ((((int )rx_ring->next_to_clean <= (int )rx_ring->next_to_use ? rx_ring->count : 0U) + (unsigned int )rx_ring->next_to_clean) - (unsigned int )rx_ring->next_to_use) + 65535U;
  tmp = numa_node_id();
  current_node = tmp;
  vsi = rx_ring->vsi;
  i = rx_ring->next_to_clean;
  if (budget <= 0) {
    return (0);
  } else {

  }
  ldv_61388: ;
  if ((unsigned int )cleaned_count > 15U) {
    i40e_alloc_rx_buffers_ps(rx_ring, (int )cleaned_count);
    cleaned_count = 0U;
  } else {

  }
  i = rx_ring->next_to_clean;
  constant_test_bit(5L, (unsigned long const volatile   *)(& rx_ring->state));
  rx_desc = (union i40e_32byte_rx_desc *)rx_ring->desc + (unsigned long )i;
  qword = rx_desc->wb.qword1.status_error_len;
  rx_status = (u32 )qword & 524287U;
  if ((rx_status & 1U) == 0U) {
    goto ldv_61383;
  } else {

  }
  __asm__  volatile   ("": : : "memory");
  tmp___0 = i40e_rx_is_programming_status(qword);
  if ((int )tmp___0) {
    i40e_clean_programming_status(rx_ring, rx_desc);
    i = (u16 )((int )i + 1);
    if ((int )rx_ring->count == (int )i) {
      i = 0U;
    } else {

    }
    rx_ring->next_to_clean = i;
    goto ldv_61384;
  } else {

  }
  rx_bi = rx_ring->__annonCompField121.rx_bi + (unsigned long )i;
  skb = rx_bi->skb;
  tmp___1 = ldv__builtin_expect((unsigned long )skb == (unsigned long )((struct sk_buff *)0),
                             1L);
  if (tmp___1 != 0L) {
    skb = netdev_alloc_skb_ip_align(rx_ring->netdev, (unsigned int )rx_ring->rx_hdr_len);
    if ((unsigned long )skb == (unsigned long )((struct sk_buff *)0)) {
      rx_ring->__annonCompField122.rx_stats.alloc_buff_failed = rx_ring->__annonCompField122.rx_stats.alloc_buff_failed + 1ULL;
      goto ldv_61383;
    } else {

    }
    skb_record_rx_queue(skb, (int )rx_ring->queue_index);
    dma_sync_single_range_for_cpu(rx_ring->dev, rx_bi->dma, 0UL, (size_t )rx_ring->rx_hdr_len,
                                  2);
  } else {

  }
  rx_packet_len = (u16 )((qword & 4503324749463552ULL) >> 38);
  rx_header_len = (u16 )((qword & 9218868437227405312ULL) >> 52);
  rx_sph = (u16 )(qword >> 63);
  rx_error = (u32 )((qword & 133693440ULL) >> 19);
  rx_hbo = (unsigned int )((u16 )rx_error) & 4U;
  rx_error = rx_error & 4294967291U;
  rx_ptype = (u8 )((qword & 273804165120ULL) >> 30);
  __builtin_prefetch((void const   *)rx_bi->page);
  rx_bi->skb = (struct sk_buff *)0;
  cleaned_count = (u16 )((int )cleaned_count + 1);
  if ((unsigned int )rx_hbo != 0U || (unsigned int )rx_sph != 0U) {
    if ((unsigned int )rx_hbo != 0U) {
      len = 512;
    } else {
      len = (int )rx_header_len;
    }
    tmp___2 = __skb_put(skb, (unsigned int )len);
    memcpy((void *)tmp___2, (void const   *)rx_bi->hdr_buf, (size_t )len);
  } else
  if (skb->len == 0U) {
    tmp___5 = skb_headlen((struct sk_buff  const  *)skb);
    if ((unsigned int )rx_packet_len > tmp___5) {
      tmp___4 = skb_headlen((struct sk_buff  const  *)skb);
      len___0 = (int )tmp___4;
    } else {
      len___0 = (int )rx_packet_len;
    }
    tmp___6 = __skb_put(skb, (unsigned int )len___0);
    memcpy((void *)tmp___6, (void const   *)rx_bi->page + (unsigned long )rx_bi->page_offset,
             (size_t )len___0);
    rx_bi->page_offset = rx_bi->page_offset + (unsigned int )len___0;
    rx_packet_len = (int )rx_packet_len - (int )((u16 )len___0);
  } else {

  }
  if ((unsigned int )rx_packet_len != 0U) {
    tmp___7 = skb_end_pointer((struct sk_buff  const  *)skb);
    skb_fill_page_desc(skb, (int )((struct skb_shared_info *)tmp___7)->nr_frags, rx_bi->page,
                       (int )rx_bi->page_offset, (int )rx_packet_len);
    skb->len = skb->len + (unsigned int )rx_packet_len;
    skb->data_len = skb->data_len + (unsigned int )rx_packet_len;
    skb->truesize = skb->truesize + (unsigned int )rx_packet_len;
    tmp___8 = page_count(rx_bi->page);
    if (tmp___8 == 1) {
      tmp___9 = page_to_nid((struct page  const  *)rx_bi->page);
      if (tmp___9 == current_node) {
        get_page(rx_bi->page);
      } else {
        rx_bi->page = (struct page *)0;
      }
    } else {
      rx_bi->page = (struct page *)0;
    }
    dma_unmap_page(rx_ring->dev, rx_bi->page_dma, 2048UL, 2);
    rx_bi->page_dma = 0ULL;
  } else {

  }
  i = (u16 )((int )i + 1);
  if ((int )rx_ring->count == (int )i) {
    i = 0U;
  } else {

  }
  rx_ring->next_to_clean = i;
  tmp___10 = ldv__builtin_expect((rx_status & 2U) == 0U, 0L);
  if (tmp___10 != 0L) {
    next_buffer = rx_ring->__annonCompField121.rx_bi + (unsigned long )i;
    next_buffer->skb = skb;
    rx_ring->__annonCompField122.rx_stats.non_eop_descs = rx_ring->__annonCompField122.rx_stats.non_eop_descs + 1ULL;
    goto ldv_61384;
  } else {

  }
  tmp___11 = ldv__builtin_expect((long )((int )rx_error) & 1L, 0L);
  if (tmp___11 != 0L) {
    dev_kfree_skb_any(skb);
    goto ldv_61384;
  } else {

  }
  tmp___12 = i40e_ptype_to_hash((int )rx_ptype);
  tmp___13 = i40e_rx_hash(rx_ring, rx_desc);
  skb_set_hash(skb, tmp___13, tmp___12);
  tmp___14 = ldv__builtin_expect(((unsigned long )rx_status & 128UL) != 0UL, 0L);
  if (tmp___14 != 0L) {
    i40e_ptp_rx_hwtstamp(vsi->back, skb, (int )((u8 )(((unsigned long )rx_status & 96UL) >> 5)));
    rx_ring->last_rx_timestamp = jiffies;
  } else {

  }
  total_rx_bytes = skb->len + total_rx_bytes;
  total_rx_packets = total_rx_packets + 1U;
  skb->protocol = eth_type_trans(skb, rx_ring->netdev);
  i40e_rx_checksum(vsi, skb, rx_status, rx_error, (int )rx_ptype);
  vlan_tag = (rx_status & 4U) != 0U ? rx_desc->wb.qword0.lo_dword.l2tag1 : 0U;
  tmp___15 = i40e_fcoe_handle_offload(rx_ring, rx_desc, skb);
  if (tmp___15 == 0) {
    dev_kfree_skb_any(skb);
    goto ldv_61384;
  } else {

  }
  skb_mark_napi_id(skb, & (rx_ring->q_vector)->napi);
  i40e_receive_skb(rx_ring, skb, (int )vlan_tag);
  rx_desc->wb.qword1.status_error_len = 0ULL;
  ldv_61384: 
  tmp___16 = ldv__builtin_expect((unsigned int )budget > total_rx_packets, 1L);
  if (tmp___16 != 0L) {
    goto ldv_61388;
  } else {

  }
  ldv_61383: 
  u64_stats_init(& rx_ring->syncp);
  rx_ring->stats.packets = rx_ring->stats.packets + (u64 )total_rx_packets;
  rx_ring->stats.bytes = rx_ring->stats.bytes + (u64 )total_rx_bytes;
  u64_stats_init(& rx_ring->syncp);
  (rx_ring->q_vector)->rx.total_packets = (rx_ring->q_vector)->rx.total_packets + total_rx_packets;
  (rx_ring->q_vector)->rx.total_bytes = (rx_ring->q_vector)->rx.total_bytes + total_rx_bytes;
  return ((int )total_rx_packets);
}
}
static int i40e_clean_rx_irq_1buf(struct i40e_ring *rx_ring , int budget ) 
{ 
  unsigned int total_rx_bytes ;
  unsigned int total_rx_packets ;
  u16 cleaned_count ;
  struct i40e_vsi *vsi ;
  union i40e_32byte_rx_desc *rx_desc ;
  u32 rx_error ;
  u32 rx_status ;
  u16 rx_packet_len ;
  u8 rx_ptype ;
  u64 qword ;
  u16 i ;
  struct i40e_rx_buffer *rx_bi ;
  struct sk_buff *skb ;
  u16 vlan_tag ;
  bool tmp ;
  long tmp___0 ;
  long tmp___1 ;
  enum pkt_hash_types tmp___2 ;
  u32 tmp___3 ;
  long tmp___4 ;
  int tmp___5 ;
  long tmp___6 ;

  {
  total_rx_bytes = 0U;
  total_rx_packets = 0U;
  cleaned_count = ((((int )rx_ring->next_to_clean <= (int )rx_ring->next_to_use ? rx_ring->count : 0U) + (unsigned int )rx_ring->next_to_clean) - (unsigned int )rx_ring->next_to_use) + 65535U;
  vsi = rx_ring->vsi;
  ldv_61409: ;
  if ((unsigned int )cleaned_count > 15U) {
    i40e_alloc_rx_buffers_1buf(rx_ring, (int )cleaned_count);
    cleaned_count = 0U;
  } else {

  }
  i = rx_ring->next_to_clean;
  constant_test_bit(5L, (unsigned long const volatile   *)(& rx_ring->state));
  rx_desc = (union i40e_32byte_rx_desc *)rx_ring->desc + (unsigned long )i;
  qword = rx_desc->wb.qword1.status_error_len;
  rx_status = (u32 )qword & 524287U;
  if ((rx_status & 1U) == 0U) {
    goto ldv_61407;
  } else {

  }
  __asm__  volatile   ("": : : "memory");
  tmp = i40e_rx_is_programming_status(qword);
  if ((int )tmp) {
    i40e_clean_programming_status(rx_ring, rx_desc);
    i = (u16 )((int )i + 1);
    if ((int )rx_ring->count == (int )i) {
      i = 0U;
    } else {

    }
    rx_ring->next_to_clean = i;
    goto ldv_61408;
  } else {

  }
  rx_bi = rx_ring->__annonCompField121.rx_bi + (unsigned long )i;
  skb = rx_bi->skb;
  __builtin_prefetch((void const   *)skb->data);
  rx_packet_len = (u16 )((qword & 4503324749463552ULL) >> 38);
  rx_error = (u32 )((qword & 133693440ULL) >> 19);
  rx_error = rx_error & 4294967291U;
  rx_ptype = (u8 )((qword & 273804165120ULL) >> 30);
  rx_bi->skb = (struct sk_buff *)0;
  cleaned_count = (u16 )((int )cleaned_count + 1);
  skb_put(skb, (unsigned int )rx_packet_len);
  dma_unmap_single_attrs___0(rx_ring->dev, rx_bi->dma, (size_t )rx_ring->rx_buf_len,
                             2, (struct dma_attrs *)0);
  rx_bi->dma = 0ULL;
  i = (u16 )((int )i + 1);
  if ((int )rx_ring->count == (int )i) {
    i = 0U;
  } else {

  }
  rx_ring->next_to_clean = i;
  tmp___0 = ldv__builtin_expect((rx_status & 2U) == 0U, 0L);
  if (tmp___0 != 0L) {
    rx_ring->__annonCompField122.rx_stats.non_eop_descs = rx_ring->__annonCompField122.rx_stats.non_eop_descs + 1ULL;
    goto ldv_61408;
  } else {

  }
  tmp___1 = ldv__builtin_expect((long )((int )rx_error) & 1L, 0L);
  if (tmp___1 != 0L) {
    dev_kfree_skb_any(skb);
    goto ldv_61408;
  } else {

  }
  tmp___2 = i40e_ptype_to_hash((int )rx_ptype);
  tmp___3 = i40e_rx_hash(rx_ring, rx_desc);
  skb_set_hash(skb, tmp___3, tmp___2);
  tmp___4 = ldv__builtin_expect(((unsigned long )rx_status & 128UL) != 0UL, 0L);
  if (tmp___4 != 0L) {
    i40e_ptp_rx_hwtstamp(vsi->back, skb, (int )((u8 )(((unsigned long )rx_status & 96UL) >> 5)));
    rx_ring->last_rx_timestamp = jiffies;
  } else {

  }
  total_rx_bytes = skb->len + total_rx_bytes;
  total_rx_packets = total_rx_packets + 1U;
  skb->protocol = eth_type_trans(skb, rx_ring->netdev);
  i40e_rx_checksum(vsi, skb, rx_status, rx_error, (int )rx_ptype);
  vlan_tag = (rx_status & 4U) != 0U ? rx_desc->wb.qword0.lo_dword.l2tag1 : 0U;
  tmp___5 = i40e_fcoe_handle_offload(rx_ring, rx_desc, skb);
  if (tmp___5 == 0) {
    dev_kfree_skb_any(skb);
    goto ldv_61408;
  } else {

  }
  i40e_receive_skb(rx_ring, skb, (int )vlan_tag);
  rx_desc->wb.qword1.status_error_len = 0ULL;
  ldv_61408: 
  tmp___6 = ldv__builtin_expect((unsigned int )budget > total_rx_packets, 1L);
  if (tmp___6 != 0L) {
    goto ldv_61409;
  } else {

  }
  ldv_61407: 
  u64_stats_init(& rx_ring->syncp);
  rx_ring->stats.packets = rx_ring->stats.packets + (u64 )total_rx_packets;
  rx_ring->stats.bytes = rx_ring->stats.bytes + (u64 )total_rx_bytes;
  u64_stats_init(& rx_ring->syncp);
  (rx_ring->q_vector)->rx.total_packets = (rx_ring->q_vector)->rx.total_packets + total_rx_packets;
  (rx_ring->q_vector)->rx.total_bytes = (rx_ring->q_vector)->rx.total_bytes + total_rx_bytes;
  return ((int )total_rx_packets);
}
}
int i40e_napi_poll(struct napi_struct *napi , int budget ) 
{ 
  struct i40e_q_vector *q_vector ;
  struct napi_struct  const  *__mptr ;
  struct i40e_vsi *vsi ;
  struct i40e_ring *ring ;
  bool clean_complete ;
  bool arm_wb ;
  int budget_per_ring ;
    klee_make_symbolic(&budget_per_ring, sizeof(int), "budget_per_ring");
  int cleaned ;
    klee_make_symbolic(&cleaned, sizeof(int), "cleaned");
  int tmp ;
  bool tmp___0 ;
  int _max1 ;
  int _max2 ;
  int tmp___1 ;
  struct i40e_hw *hw ;
  u32 qval ;
  unsigned int tmp___2 ;
  int tmp___3 ;

  {
  __mptr = (struct napi_struct  const  *)napi;
  q_vector = (struct i40e_q_vector *)__mptr + 0xfffffffffffffff0UL;
  vsi = q_vector->vsi;
  clean_complete = 1;
  arm_wb = 0;
  tmp = constant_test_bit(3L, (unsigned long const volatile   *)(& vsi->state));
  if (tmp != 0) {
    napi_complete(napi);
    return (0);
  } else {

  }
  ring = q_vector->tx.ring;
  goto ldv_61424;
  ldv_61423: 
  tmp___0 = i40e_clean_tx_irq(ring, (int )vsi->work_limit);
  clean_complete = ((int )clean_complete & (int )tmp___0) != 0;
  arm_wb = ((int )arm_wb | (int )ring->arm_wb) != 0;
  ring = ring->next;
  ldv_61424: ;
  if ((unsigned long )ring != (unsigned long )((struct i40e_ring *)0)) {
    goto ldv_61423;
  } else {

  }
  _max1 = budget / (int )q_vector->num_ringpairs;
  _max2 = 1;
  budget_per_ring = _max1 > _max2 ? _max1 : _max2;
  ring = q_vector->rx.ring;
  goto ldv_61430;
  ldv_61429: 
  tmp___1 = constant_test_bit(4L, (unsigned long const volatile   *)(& ring->state));
  if (tmp___1 != 0) {
    cleaned = i40e_clean_rx_irq_ps(ring, budget_per_ring);
  } else {
    cleaned = i40e_clean_rx_irq_1buf(ring, budget_per_ring);
  }
  clean_complete = ((int )clean_complete & (budget_per_ring != cleaned)) != 0;
  ring = ring->next;
  ldv_61430: ;
  if ((unsigned long )ring != (unsigned long )((struct i40e_ring *)0)) {
    goto ldv_61429;
  } else {

  }

  if (! clean_complete) {
    if ((int )arm_wb) {
      i40e_force_wb(vsi, q_vector);
    } else {

    }
    return (budget);
  } else {

  }
  napi_complete(napi);
  if ((int )((short )vsi->rx_itr_setting) < 0 || (int )((short )vsi->tx_itr_setting) < 0) {
    i40e_update_dynamic_itr(q_vector);
  } else {

  }
  tmp___3 = constant_test_bit(3L, (unsigned long const volatile   *)(& vsi->state));
  if (tmp___3 == 0) {
    if (((vsi->back)->flags & 8ULL) != 0ULL) {
      i40e_irq_dynamic_enable(vsi, (int )q_vector->v_idx + vsi->base_vector);
    } else {
      hw = & (vsi->back)->hw;
      tmp___2 = readl((void const volatile   *)hw->hw_addr + 237568U);
      qval = tmp___2;
      qval = qval | 1073741824U;
      writel(qval, (void volatile   *)hw->hw_addr + 237568U);
      qval = readl((void const volatile   *)hw->hw_addr + 245760U);
      qval = qval | 1073741824U;
      writel(qval, (void volatile   *)hw->hw_addr + 245760U);
      i40e_irq_dynamic_enable_icr0(vsi->back);
    }
  } else {

  }
  return (0);
}
}
static void i40e_atr(struct i40e_ring *tx_ring , struct sk_buff *skb , u32 tx_flags ,
                     __be16 protocol ) 
{ 
  struct i40e_filter_program_desc *fdir_desc ;
  struct i40e_pf *pf ;
  union __anonunion_hdr_459 hdr ;
  struct tcphdr *th ;
  unsigned int hlen ;
    klee_make_symbolic(&hlen, sizeof(int), "hlen");
  u32 flex_ptype ;
  u32 dtype_cmd ;
  u16 i ;

  {
  pf = (tx_ring->vsi)->back;
  if ((pf->flags & 4194304ULL) == 0ULL) {
    return;
  } else {

  }
  if ((pf->auto_disable_flags & 4194304ULL) != 0ULL) {
    return;
  } else {

  }
  if ((unsigned int )tx_ring->atr_sample_rate == 0U) {
    return;
  } else {

  }
  if ((tx_flags & 48U) == 0U) {
    return;
  } else {

  }
  if ((tx_flags & 1024U) == 0U) {
    hdr.network = skb_network_header((struct sk_buff  const  *)skb);
    if ((tx_flags & 16U) != 0U) {
      hlen = (unsigned int )(((int )*(hdr.network) & 15) << 2);
    } else
    if ((unsigned int )protocol == 56710U) {
      hlen = 40U;
    } else {
      return;
    }
  } else {
    hdr.network = skb_inner_network_header((struct sk_buff  const  *)skb);
    hlen = skb_inner_network_header_len((struct sk_buff  const  *)skb);
  }
  if ((tx_flags & 16U) != 0U && (unsigned int )(hdr.ipv4)->protocol != 6U) {
    return;
  } else
  if ((tx_flags & 32U) != 0U && (unsigned int )(hdr.ipv6)->nexthdr != 6U) {
    return;
  } else {

  }
  th = (struct tcphdr *)hdr.network + (unsigned long )hlen;
  if ((unsigned int )*((unsigned char *)th + 13UL) != 0U && (pf->auto_disable_flags & 4194304ULL) != 0ULL) {
    return;
  } else {

  }
  tx_ring->atr_count = (u8 )((int )tx_ring->atr_count + 1);
  if ((((unsigned int )*((unsigned char *)th + 13UL) == 0U && (unsigned int )*((unsigned char *)th + 13UL) == 0U) && (unsigned int )*((unsigned char *)th + 13UL) == 0U) && (int )tx_ring->atr_count < (int )tx_ring->atr_sample_rate) {
    return;
  } else {

  }
  tx_ring->atr_count = 0U;
  i = tx_ring->next_to_use;
  fdir_desc = (struct i40e_filter_program_desc *)tx_ring->desc + (unsigned long )i;
  i = (u16 )((int )i + 1);
  tx_ring->next_to_use = (int )tx_ring->count > (int )i ? i : 0U;
  flex_ptype = (u32 )tx_ring->queue_index & 2047U;
  flex_ptype = ((unsigned int )protocol == 8U ? 4325376U : 5636096U) | flex_ptype;
  flex_ptype = (u32 )((int )(tx_ring->vsi)->id << 23) | flex_ptype;
  dtype_cmd = 8U;
  dtype_cmd = ((unsigned int )*((unsigned char *)th + 13UL) != 0U || (unsigned int )*((unsigned char *)th + 13UL) != 0U ? 32U : 16U) | dtype_cmd;
  dtype_cmd = dtype_cmd | 128U;
  dtype_cmd = dtype_cmd | 8192U;
  dtype_cmd = dtype_cmd | 2048U;
  if ((tx_flags & 1024U) == 0U) {
    dtype_cmd = (((unsigned int )((int )pf->hw.pf_id * 3) << 20) & 535822336U) | dtype_cmd;
  } else {
    dtype_cmd = (((unsigned int )((int )pf->hw.pf_id * 3 + 2) << 20) & 535822336U) | dtype_cmd;
  }
  fdir_desc->qindex_flex_ptype_vsi = flex_ptype;
  fdir_desc->rsvd = 0U;
  fdir_desc->dtype_cmd_cntindex = dtype_cmd;
  fdir_desc->fd_id = 0U;
  return;
}
}
__inline int i40e_tx_prepare_vlan_flags(struct sk_buff *skb , struct i40e_ring *tx_ring ,
                                        u32 *flags ) 
{ 
  __be16 protocol ;
  u32 tx_flags ;
  struct vlan_hdr *vhdr ;
  struct vlan_hdr _vhdr ;
  void *tmp ;
  __u16 tmp___0 ;
  struct vlan_ethhdr *vhdr___0 ;
  int rc ;
  __u16 tmp___1 ;

  {
  protocol = skb->protocol;
  tx_flags = 0U;
  if ((unsigned int )protocol == 129U && ((tx_ring->netdev)->features & 128ULL) == 0ULL) {
    skb->protocol = vlan_get_protocol(skb);
    goto out;
  } else {

  }
  if (((int )skb->vlan_tci & 4096) != 0) {
    tx_flags = (u32 )(((int )skb->vlan_tci & -4097) << 16) | tx_flags;
    tx_flags = tx_flags | 2U;
  } else
  if ((unsigned int )protocol == 129U) {
    tmp = skb_header_pointer((struct sk_buff  const  *)skb, 14, 4, (void *)(& _vhdr));
    vhdr = (struct vlan_hdr *)tmp;
    if ((unsigned long )vhdr == (unsigned long )((struct vlan_hdr *)0)) {
      return (-22);
    } else {

    }
    protocol = vhdr->h_vlan_encapsulated_proto;
    tmp___0 = __fswab16((int )vhdr->h_vlan_TCI);
    tx_flags = (u32 )((int )tmp___0 << 16) | tx_flags;
    tx_flags = tx_flags | 4U;
  } else {

  }
  if ((((tx_ring->vsi)->back)->flags & 1048576ULL) == 0ULL) {
    goto out;
  } else {

  }
  if ((tx_flags & 6U) != 0U || skb->priority != 7U) {
    tx_flags = tx_flags & 536870911U;
    tx_flags = (skb->priority << 29) | tx_flags;
    if ((tx_flags & 4U) != 0U) {
      rc = skb_cow_head(skb, 0U);
      if (rc < 0) {
        return (rc);
      } else {

      }
      vhdr___0 = (struct vlan_ethhdr *)skb->data;
      tmp___1 = __fswab16((int )((__u16 )(tx_flags >> 16)));
      vhdr___0->h_vlan_TCI = tmp___1;
    } else {
      tx_flags = tx_flags | 2U;
    }
  } else {

  }
  out: 
  *flags = tx_flags;
  return (0);
}
}
static int i40e_tso(struct i40e_ring *tx_ring , struct sk_buff *skb , u8 *hdr_len ,
                    u64 *cd_type_cmd_tso_mss , u32 *cd_tunneling ) 
{ 
  u32 cd_cmd ;
  u32 cd_tso_len ;
  u32 cd_mss ;
  struct ipv6hdr *ipv6h ;
  struct tcphdr *tcph ;
  struct iphdr *iph ;
  u32 l4len ;
  int err ;
  bool tmp ;
  int tmp___0 ;
  struct iphdr *tmp___1 ;
  struct iphdr *tmp___2 ;
  struct ipv6hdr *tmp___3 ;
  struct ipv6hdr *tmp___4 ;
  struct tcphdr *tmp___5 ;
  struct tcphdr *tmp___6 ;
  __sum16 tmp___7 ;
  struct tcphdr *tmp___8 ;
  struct tcphdr *tmp___9 ;
  __sum16 tmp___10 ;
  unsigned int tmp___11 ;
  unsigned int tmp___12 ;
  unsigned char *tmp___13 ;
  int tmp___14 ;
  int tmp___15 ;
  unsigned char *tmp___16 ;

  {
  tmp = skb_is_gso((struct sk_buff  const  *)skb);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (0);
  } else {

  }
  err = skb_cow_head(skb, 0U);
  if (err < 0) {
    return (err);
  } else {

  }
  if ((unsigned int )*((unsigned char *)skb + 146UL) != 0U) {
    tmp___1 = inner_ip_hdr((struct sk_buff  const  *)skb);
    iph = tmp___1;
  } else {
    tmp___2 = ip_hdr((struct sk_buff  const  *)skb);
    iph = tmp___2;
  }
  if ((unsigned int )*((unsigned char *)skb + 146UL) != 0U) {
    tmp___3 = inner_ipv6_hdr((struct sk_buff  const  *)skb);
    ipv6h = tmp___3;
  } else {
    tmp___4 = ipv6_hdr((struct sk_buff  const  *)skb);
    ipv6h = tmp___4;
  }
  if ((unsigned int )*((unsigned char *)iph + 0UL) == 64U) {
    if ((unsigned int )*((unsigned char *)skb + 146UL) != 0U) {
      tmp___5 = inner_tcp_hdr((struct sk_buff  const  *)skb);
      tcph = tmp___5;
    } else {
      tmp___6 = tcp_hdr((struct sk_buff  const  *)skb);
      tcph = tmp___6;
    }
    iph->tot_len = 0U;
    iph->check = 0U;
    tmp___7 = csum_tcpudp_magic(iph->saddr, iph->daddr, 0, 6, 0U);
    tcph->check = ~ ((int )tmp___7);
  } else
  if ((unsigned int )*((unsigned char *)ipv6h + 0UL) == 96U) {
    if ((unsigned int )*((unsigned char *)skb + 146UL) != 0U) {
      tmp___8 = inner_tcp_hdr((struct sk_buff  const  *)skb);
      tcph = tmp___8;
    } else {
      tmp___9 = tcp_hdr((struct sk_buff  const  *)skb);
      tcph = tmp___9;
    }
    ipv6h->payload_len = 0U;
    tmp___10 = csum_ipv6_magic((struct in6_addr  const  *)(& ipv6h->saddr), (struct in6_addr  const  *)(& ipv6h->daddr),
                               0U, 6, 0U);
    tcph->check = ~ ((int )tmp___10);
  } else {

  }
  if ((unsigned int )*((unsigned char *)skb + 146UL) != 0U) {
    tmp___11 = inner_tcp_hdrlen((struct sk_buff  const  *)skb);
    l4len = tmp___11;
  } else {
    tmp___12 = tcp_hdrlen((struct sk_buff  const  *)skb);
    l4len = tmp___12;
  }
  if ((unsigned int )*((unsigned char *)skb + 146UL) != 0U) {
    tmp___13 = skb_inner_transport_header((struct sk_buff  const  *)skb);
    tmp___15 = (int )((u8 )((long )tmp___13)) - (int )((u8 )((long )skb->data));
  } else {
    tmp___14 = skb_transport_offset((struct sk_buff  const  *)skb);
    tmp___15 = (u8 )tmp___14;
  }
  *hdr_len = tmp___15 + (int )((u8 )l4len);
  cd_cmd = 1U;
  cd_tso_len = skb->len - (unsigned int )*hdr_len;
  tmp___16 = skb_end_pointer((struct sk_buff  const  *)skb);
  cd_mss = (u32 )((struct skb_shared_info *)tmp___16)->gso_size;
  *cd_type_cmd_tso_mss = *cd_type_cmd_tso_mss | ((((unsigned long long )cd_cmd << 4) | ((unsigned long long )cd_tso_len << 30)) | ((unsigned long long )cd_mss << 50));
  return (1);
}
}
static int i40e_tsyn(struct i40e_ring *tx_ring , struct sk_buff *skb , u32 tx_flags ,
                     u64 *cd_type_cmd_tso_mss ) 
{ 
  struct i40e_pf *pf ;
  unsigned char *tmp ;
  long tmp___0 ;
  unsigned char *tmp___1 ;
  unsigned char *tmp___2 ;
  int tmp___3 ;

  {
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  tmp___0 = ldv__builtin_expect(((int )((struct skb_shared_info *)tmp)->tx_flags & 1) == 0,
                             1L);
  if (tmp___0 != 0L) {
    return (0);
  } else {

  }
  if ((tx_flags & 8U) != 0U) {
    return (0);
  } else {

  }
  pf = i40e_netdev_to_pf(tx_ring->netdev);
  if ((pf->flags & 33554432ULL) == 0ULL) {
    return (0);
  } else {

  }
  if ((int )pf->ptp_tx) {
    tmp___3 = test_and_set_bit_lock(19L, (unsigned long volatile   *)(& pf->state));
    if (tmp___3 == 0) {
      tmp___1 = skb_end_pointer((struct sk_buff  const  *)skb);
      tmp___2 = skb_end_pointer((struct sk_buff  const  *)skb);
      ((struct skb_shared_info *)tmp___1)->tx_flags = (__u8 )((unsigned int )((struct skb_shared_info *)tmp___2)->tx_flags | 4U);
      pf->ptp_tx_skb = skb_get(skb);
    } else {
      return (0);
    }
  } else {
    return (0);
  }
  *cd_type_cmd_tso_mss = *cd_type_cmd_tso_mss | 32ULL;
  return (1);
}
}
static void i40e_tx_enable_csum(struct sk_buff *skb , u32 *tx_flags , u32 *td_cmd ,
                                u32 *td_offset , struct i40e_ring *tx_ring , u32 *cd_tunneling ) 
{ 
  struct ipv6hdr *this_ipv6_hdr ;
  unsigned int this_tcp_hdrlen ;
    klee_make_symbolic(&this_tcp_hdrlen, sizeof(int), "this_tcp_hdrlen");
  struct iphdr *this_ip_hdr ;
  u32 network_hdr_len ;
  u8 l4_hdr ;
  u32 l4_tunnel ;
  struct iphdr *tmp ;
  struct iphdr *tmp___0 ;
  struct iphdr *tmp___1 ;
  u32 tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;

  {
  l4_hdr = 0U;
  l4_tunnel = 0U;
  if ((unsigned int )*((unsigned char *)skb + 146UL) != 0U) {
    tmp = ip_hdr((struct sk_buff  const  *)skb);
    switch ((int )tmp->protocol) {
    case 17: 
    l4_tunnel = 512U;
    *tx_flags = *tx_flags | 1024U;
    goto ldv_61501;
    default: ;
    return;
    }
    ldv_61501: 
    network_hdr_len = skb_inner_network_header_len((struct sk_buff  const  *)skb);
    this_ip_hdr = inner_ip_hdr((struct sk_buff  const  *)skb);
    this_ipv6_hdr = inner_ipv6_hdr((struct sk_buff  const  *)skb);
    this_tcp_hdrlen = inner_tcp_hdrlen((struct sk_buff  const  *)skb);
    if ((*tx_flags & 16U) != 0U) {
      if ((*tx_flags & 8U) != 0U) {
        *cd_tunneling = *cd_tunneling | 3U;
        tmp___0 = ip_hdr((struct sk_buff  const  *)skb);
        tmp___0->check = 0U;
      } else {
        *cd_tunneling = *cd_tunneling | 2U;
      }
    } else
    if ((*tx_flags & 32U) != 0U) {
      *cd_tunneling = *cd_tunneling | 1U;
      if ((*tx_flags & 8U) != 0U) {
        tmp___1 = ip_hdr((struct sk_buff  const  *)skb);
        tmp___1->check = 0U;
      } else {

      }
    } else {

    }
    tmp___2 = skb_network_header_len((struct sk_buff  const  *)skb);
    tmp___3 = skb_inner_network_offset((struct sk_buff  const  *)skb);
    tmp___4 = skb_transport_offset((struct sk_buff  const  *)skb);
    *cd_tunneling = *cd_tunneling | (((tmp___2 & 4294967292U) | l4_tunnel) | (u32 )(((tmp___3 - tmp___4) >> 1) << 12));
    if ((unsigned int )*((unsigned char *)this_ip_hdr + 0UL) == 96U) {
      *tx_flags = *tx_flags & 4294967279U;
      *tx_flags = *tx_flags | 32U;
    } else {

    }
  } else {
    network_hdr_len = skb_network_header_len((struct sk_buff  const  *)skb);
    this_ip_hdr = ip_hdr((struct sk_buff  const  *)skb);
    this_ipv6_hdr = ipv6_hdr((struct sk_buff  const  *)skb);
    this_tcp_hdrlen = tcp_hdrlen((struct sk_buff  const  *)skb);
  }
  if ((*tx_flags & 16U) != 0U) {
    l4_hdr = this_ip_hdr->protocol;
    if ((*tx_flags & 8U) != 0U) {
      *td_cmd = *td_cmd | 96U;
      this_ip_hdr->check = 0U;
    } else {
      *td_cmd = *td_cmd | 64U;
    }
    *td_offset = (network_hdr_len >> 2) << 7;
  } else
  if ((*tx_flags & 32U) != 0U) {
    l4_hdr = this_ipv6_hdr->nexthdr;
    *td_cmd = *td_cmd | 32U;
    *td_offset = (network_hdr_len >> 2) << 7;
  } else {

  }
  tmp___5 = skb_network_offset((struct sk_buff  const  *)skb);
  *td_offset = *td_offset | (u32 )(tmp___5 >> 1);
  switch ((int )l4_hdr) {
  case 6: 
  *td_cmd = *td_cmd | 256U;
  *td_offset = *td_offset | ((this_tcp_hdrlen >> 2) << 14);
  goto ldv_61504;
  case 132: 
  *td_cmd = *td_cmd | 512U;
  *td_offset = *td_offset | 49152U;
  goto ldv_61504;
  case 17: 
  *td_cmd = *td_cmd | 768U;
  *td_offset = *td_offset | 32768U;
  goto ldv_61504;
  default: ;
  goto ldv_61504;
  }
  ldv_61504: ;
  return;
}
}
static void i40e_create_tx_ctx(struct i40e_ring *tx_ring , u64 const   cd_type_cmd_tso_mss ,
                               u32 const   cd_tunneling , u32 const   cd_l2tag2 ) 
{ 
  struct i40e_tx_context_desc *context_desc ;
  int i ;

  {
  i = (int )tx_ring->next_to_use;
  if (((unsigned long long )cd_type_cmd_tso_mss == 1ULL && (unsigned int )cd_tunneling == 0U) && (unsigned int )cd_l2tag2 == 0U) {
    return;
  } else {

  }
  context_desc = (struct i40e_tx_context_desc *)tx_ring->desc + (unsigned long )i;
  i = i + 1;
  tx_ring->next_to_use = (int )tx_ring->count > i ? (u16 )i : 0U;
  context_desc->tunneling_params = cd_tunneling;
  context_desc->l2tag2 = (unsigned short )cd_l2tag2;
  context_desc->rsvd = 0U;
  context_desc->type_cmd_tso_mss = cd_type_cmd_tso_mss;
  return;
}
}
__inline static int __i40e_maybe_stop_tx(struct i40e_ring *tx_ring , int size ) 
{ 
  long tmp ;

  {
  netif_stop_subqueue(tx_ring->netdev, (int )tx_ring->queue_index);
  __asm__  volatile   ("mfence": : : "memory");
  tmp = ldv__builtin_expect(((((int )tx_ring->next_to_clean <= (int )tx_ring->next_to_use ? (int )tx_ring->count : 0) + (int )tx_ring->next_to_clean) - (int )tx_ring->next_to_use) + -1 < size,
                         1L);
  if (tmp != 0L) {
    return (-16);
  } else {

  }
  netif_start_subqueue(tx_ring->netdev, (int )tx_ring->queue_index);
  tx_ring->__annonCompField122.tx_stats.restart_queue = tx_ring->__annonCompField122.tx_stats.restart_queue + 1ULL;
  return (0);
}
}
__inline int i40e_maybe_stop_tx(struct i40e_ring *tx_ring , int size ) 
{ 
  long tmp ;
  int tmp___0 ;

  {
  tmp = ldv__builtin_expect(((((int )tx_ring->next_to_clean <= (int )tx_ring->next_to_use ? (int )tx_ring->count : 0) + (int )tx_ring->next_to_clean) - (int )tx_ring->next_to_use) + -1 >= size,
                         1L);
  if (tmp != 0L) {
    return (0);
  } else {

  }
  tmp___0 = __i40e_maybe_stop_tx(tx_ring, size);
  return (tmp___0);
}
}
static bool i40e_chk_linearize(struct sk_buff *skb , u32 tx_flags ) 
{ 
  struct skb_frag_struct *frag ;
  bool linearize ;
  unsigned int size ;
  u16 num_frags ;
  u16 gso_segs ;
  unsigned char *tmp ;
  unsigned char *tmp___0 ;
  u16 j ;
  unsigned char *tmp___1 ;
  unsigned int tmp___2 ;
  unsigned char *tmp___3 ;
  unsigned char *tmp___4 ;

  {
  linearize = 0;
  size = 0U;
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  num_frags = (u16 )((struct skb_shared_info *)tmp)->nr_frags;
  tmp___0 = skb_end_pointer((struct sk_buff  const  *)skb);
  gso_segs = ((struct skb_shared_info *)tmp___0)->gso_segs;
  if ((tx_flags & 136U) != 0U) {
    j = 0U;
    if ((unsigned int )num_frags <= 7U) {
      goto linearize_chk_done;
    } else {

    }
    if (((((int )num_frags + (int )gso_segs) + (int )gso_segs) + -1) / (int )gso_segs > 8) {
      linearize = 1;
      goto linearize_chk_done;
    } else {

    }
    tmp___1 = skb_end_pointer((struct sk_buff  const  *)skb);
    frag = (struct skb_frag_struct *)(& ((struct skb_shared_info *)tmp___1)->frags);
    ldv_61536: 
    tmp___2 = skb_frag_size((skb_frag_t const   *)frag);
    size = tmp___2 + size;
    frag = frag + 1;
    j = (u16 )((int )j + 1);
    tmp___4 = skb_end_pointer((struct sk_buff  const  *)skb);
    if ((unsigned int )((struct skb_shared_info *)tmp___4)->gso_size <= size && (unsigned int )j <= 7U) {
      tmp___3 = skb_end_pointer((struct sk_buff  const  *)skb);
      size = size % (unsigned int )((struct skb_shared_info *)tmp___3)->gso_size;
      j = size != 0U;
    } else {

    }
    if ((unsigned int )j == 8U) {
      linearize = 1;
      goto ldv_61535;
    } else {

    }
    num_frags = (u16 )((int )num_frags - 1);
    if ((unsigned int )num_frags != 0U) {
      goto ldv_61536;
    } else {

    }
    ldv_61535: ;
  } else
  if ((unsigned int )num_frags > 7U) {
    linearize = 1;
  } else {

  }
  linearize_chk_done: ;
  return (linearize);
}
}
__inline void i40e_tx_map(struct i40e_ring *tx_ring , struct sk_buff *skb , struct i40e_tx_buffer *first ,
                          u32 tx_flags , u8 const   hdr_len , u32 td_cmd , u32 td_offset ) 
{ 
  unsigned int data_len ;
  unsigned int size ;
  unsigned int tmp ;
  struct skb_frag_struct *frag ;
  struct i40e_tx_buffer *tx_bi ;
  struct i40e_tx_desc *tx_desc ;
  u16 i ;
  u32 td_tag ;
  dma_addr_t dma ;
  u16 gso_segs ;
  unsigned char *tmp___0 ;
  unsigned char *tmp___1 ;
  int tmp___2 ;
  long tmp___3 ;
  long tmp___4 ;
  __le64 tmp___5 ;
  __le64 tmp___6 ;
  struct netdev_queue *tmp___7 ;
  struct netdev_queue *tmp___8 ;
  bool tmp___9 ;

  {
  data_len = skb->data_len;
  tmp = skb_headlen((struct sk_buff  const  *)skb);
  size = tmp;
  i = tx_ring->next_to_use;
  td_tag = 0U;
  if ((tx_flags & 2U) != 0U) {
    td_cmd = td_cmd | 8U;
    td_tag = tx_flags >> 16;
  } else {

  }
  if ((tx_flags & 136U) != 0U) {
    tmp___0 = skb_end_pointer((struct sk_buff  const  *)skb);
    gso_segs = ((struct skb_shared_info *)tmp___0)->gso_segs;
  } else {
    gso_segs = 1U;
  }
  first->bytecount = (skb->len - (unsigned int )hdr_len) + (unsigned int )((int )gso_segs * (int )hdr_len);
  first->gso_segs = gso_segs;
  first->__annonCompField120.skb = skb;
  first->tx_flags = tx_flags;
  dma = dma_map_single_attrs(tx_ring->dev, (void *)skb->data, (size_t )size, 1, (struct dma_attrs *)0);
  tx_desc = (struct i40e_tx_desc *)tx_ring->desc + (unsigned long )i;
  tx_bi = first;
  tmp___1 = skb_end_pointer((struct sk_buff  const  *)skb);
  frag = (struct skb_frag_struct *)(& ((struct skb_shared_info *)tmp___1)->frags);
  ldv_61560: 
  tmp___2 = dma_mapping_error(tx_ring->dev, dma);
  if (tmp___2 != 0) {
    goto dma_error;
  } else {

  }
  tx_bi->len = size;
  tx_bi->dma = dma;
  tx_desc->buffer_addr = dma;
  goto ldv_61557;
  ldv_61556: 
  tx_desc->cmd_type_offset_bsz = build_ctob(td_cmd, td_offset, 8192U, td_tag);
  tx_desc = tx_desc + 1;
  i = (u16 )((int )i + 1);
  if ((int )tx_ring->count == (int )i) {
    tx_desc = (struct i40e_tx_desc *)tx_ring->desc;
    i = 0U;
  } else {

  }
  dma = dma + 8192ULL;
  size = size - 8192U;
  tx_desc->buffer_addr = dma;
  ldv_61557: 
  tmp___3 = ldv__builtin_expect(size > 8192U, 0L);
  if (tmp___3 != 0L) {
    goto ldv_61556;
  } else {

  }
  tmp___4 = ldv__builtin_expect(data_len == 0U, 1L);
  if (tmp___4 != 0L) {
    goto ldv_61559;
  } else {

  }
  tx_desc->cmd_type_offset_bsz = build_ctob(td_cmd, td_offset, size, td_tag);
  tx_desc = tx_desc + 1;
  i = (u16 )((int )i + 1);
  if ((int )tx_ring->count == (int )i) {
    tx_desc = (struct i40e_tx_desc *)tx_ring->desc;
    i = 0U;
  } else {

  }
  size = skb_frag_size((skb_frag_t const   *)frag);
  data_len = data_len - size;
  dma = skb_frag_dma_map(tx_ring->dev, (skb_frag_t const   *)frag, 0UL, (size_t )size,
                         1);
  tx_bi = tx_ring->__annonCompField121.tx_bi + (unsigned long )i;
  frag = frag + 1;
  goto ldv_61560;
  ldv_61559: ;
  if ((((int )i & 3) != 3 && (unsigned long )(tx_ring->__annonCompField121.tx_bi + (unsigned long )i) >= (unsigned long )first) && (unsigned long )(tx_ring->__annonCompField121.tx_bi + (unsigned long )((int )i & -4)) <= (unsigned long )first) {
    tmp___5 = build_ctob(td_cmd, td_offset, size, td_tag);
    tx_desc->cmd_type_offset_bsz = tmp___5 | 16ULL;
  } else {
    tmp___6 = build_ctob(td_cmd, td_offset, size, td_tag);
    tx_desc->cmd_type_offset_bsz = tmp___6 | 48ULL;
  }
  tmp___7 = netdev_get_tx_queue((struct net_device  const  *)tx_ring->netdev, (unsigned int )tx_ring->queue_index);
  netdev_tx_sent_queue(tmp___7, first->bytecount);
  __asm__  volatile   ("sfence": : : "memory");
  first->next_to_watch = tx_desc;
  i = (u16 )((int )i + 1);
  if ((int )tx_ring->count == (int )i) {
    i = 0U;
  } else {

  }
  tx_ring->next_to_use = i;
  i40e_maybe_stop_tx(tx_ring, 21);
  if ((unsigned int )*((unsigned char *)skb + 142UL) == 0U) {
    writel((unsigned int )i, (void volatile   *)tx_ring->tail);
  } else {
    tmp___8 = netdev_get_tx_queue((struct net_device  const  *)tx_ring->netdev, (unsigned int )tx_ring->queue_index);
    tmp___9 = netif_xmit_stopped((struct netdev_queue  const  *)tmp___8);
    if ((int )tmp___9) {
      writel((unsigned int )i, (void volatile   *)tx_ring->tail);
    } else {

    }
  }
  return;
  dma_error: 
  _dev_info((struct device  const  *)tx_ring->dev, "TX DMA map failed\n");
  ldv_61562: 
  tx_bi = tx_ring->__annonCompField121.tx_bi + (unsigned long )i;
  i40e_unmap_and_free_tx_resource(tx_ring, tx_bi);
  if ((unsigned long )tx_bi == (unsigned long )first) {
    goto ldv_61561;
  } else {

  }
  if ((unsigned int )i == 0U) {
    i = tx_ring->count;
  } else {

  }
  i = (u16 )((int )i - 1);
  goto ldv_61562;
  ldv_61561: 
  tx_ring->next_to_use = i;
  return;
}
}
__inline int i40e_xmit_descriptor_count(struct sk_buff *skb , struct i40e_ring *tx_ring ) 
{ 
  unsigned int f ;
  int count ;
  unsigned char *tmp ;
  unsigned char *tmp___0 ;
  unsigned int tmp___1 ;
  int tmp___2 ;

  {
  count = 0;
  f = 0U;
  goto ldv_61570;
  ldv_61569: 
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  count = (int )((((struct skb_shared_info *)tmp)->frags[f].size + 8191U) / 8192U + (__u32 )count);
  f = f + 1U;
  ldv_61570: 
  tmp___0 = skb_end_pointer((struct sk_buff  const  *)skb);
  if ((unsigned int )((struct skb_shared_info *)tmp___0)->nr_frags > f) {
    goto ldv_61569;
  } else {

  }
  tmp___1 = skb_headlen((struct sk_buff  const  *)skb);
  count = (int )((tmp___1 + 8191U) / 8192U + (unsigned int )count);
  tmp___2 = i40e_maybe_stop_tx(tx_ring, count + 5);
  if (tmp___2 != 0) {
    tx_ring->__annonCompField122.tx_stats.tx_busy = tx_ring->__annonCompField122.tx_stats.tx_busy + 1ULL;
    return (0);
  } else {

  }
  return (count);
}
}
static netdev_tx_t i40e_xmit_frame_ring(struct sk_buff *skb , struct i40e_ring *tx_ring ) 
{ 
  u64 cd_type_cmd_tso_mss ;
  u32 cd_tunneling ;
  u32 cd_l2tag2 ;
  struct i40e_tx_buffer *first ;
  u32 td_offset ;
  u32 tx_flags ;
  __be16 protocol ;
  u32 td_cmd ;
  u8 hdr_len ;
  int tsyn ;
    klee_make_symbolic(&tsyn, sizeof(int), "tsyn");
  int tso ;
    klee_make_symbolic(&tso, sizeof(int), "tso");
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;

  {
  cd_type_cmd_tso_mss = 1ULL;
  cd_tunneling = 0U;
  cd_l2tag2 = 0U;
  td_offset = 0U;
  tx_flags = 0U;
  td_cmd = 0U;
  hdr_len = 0U;
  tmp = i40e_xmit_descriptor_count(skb, tx_ring);
  if (tmp == 0) {
    return (16);
  } else {

  }
  tmp___0 = i40e_tx_prepare_vlan_flags(skb, tx_ring, & tx_flags);
  if (tmp___0 != 0) {
    goto out_drop;
  } else {

  }
  protocol = vlan_get_protocol(skb);
  first = tx_ring->__annonCompField121.tx_bi + (unsigned long )tx_ring->next_to_use;
  if ((unsigned int )protocol == 8U) {
    tx_flags = tx_flags | 16U;
  } else
  if ((unsigned int )protocol == 56710U) {
    tx_flags = tx_flags | 32U;
  } else {

  }
  tso = i40e_tso(tx_ring, skb, & hdr_len, & cd_type_cmd_tso_mss, & cd_tunneling);
  if (tso < 0) {
    goto out_drop;
  } else
  if (tso != 0) {
    tx_flags = tx_flags | 8U;
  } else {

  }
  tsyn = i40e_tsyn(tx_ring, skb, tx_flags, & cd_type_cmd_tso_mss);
  if (tsyn != 0) {
    tx_flags = tx_flags | 256U;
  } else {

  }
  tmp___2 = i40e_chk_linearize(skb, tx_flags);
  if ((int )tmp___2) {
    tmp___1 = skb_linearize(skb);
    if (tmp___1 != 0) {
      goto out_drop;
    } else {

    }
  } else {

  }
  skb_tx_timestamp(skb);
  td_cmd = td_cmd | 4U;
  if ((unsigned int )*((unsigned char *)skb + 145UL) == 6U) {
    tx_flags = tx_flags | 1U;
    i40e_tx_enable_csum(skb, & tx_flags, & td_cmd, & td_offset, tx_ring, & cd_tunneling);
  } else {

  }
  i40e_create_tx_ctx(tx_ring, cd_type_cmd_tso_mss, cd_tunneling, cd_l2tag2);
  i40e_atr(tx_ring, skb, tx_flags, (int )protocol);
  i40e_tx_map(tx_ring, skb, first, tx_flags, (int )hdr_len, td_cmd, td_offset);
  return (0);
  out_drop: 
  dev_kfree_skb_any(skb);
  return (0);
}
}
netdev_tx_t i40e_lan_xmit_frame(struct sk_buff *skb , struct net_device *netdev ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_ring *tx_ring ;
  int tmp___0 ;
  netdev_tx_t tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  tx_ring = *(vsi->tx_rings + (unsigned long )skb->queue_mapping);
  tmp___0 = skb_put_padto(skb, 17U);
  if (tmp___0 != 0) {
    return (0);
  } else {

  }
  tmp___1 = i40e_xmit_frame_ring(skb, tx_ring);
  return (tmp___1);
}
}
bool ldv_queue_work_on_349(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_350(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_351(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_352(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_353(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_354(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_355(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_356(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_357(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_358(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_359(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_360(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
__inline static void clear_bit_unlock(long nr , unsigned long volatile   *addr ) 
{ 


  {
  __asm__  volatile   ("": : : "memory");
  clear_bit(nr, addr);
  return;
}
}
bool ldv_is_err(void const   *ptr ) ;
bool ldv_is_err_or_null(void const   *ptr ) ;
long ldv_ptr_err(void const   *ptr ) ;
__inline static u64 div_u64_rem(u64 dividend , u32 divisor , u32 *remainder ) 
{ 


  {
  *remainder = (u32 )(dividend % (u64 )divisor);
  return (dividend / (u64 )divisor);
}
}
__inline static u64 div_u64(u64 dividend , u32 divisor ) 
{ 
  u32 remainder ;
  u64 tmp ;

  {
  tmp = div_u64_rem(dividend, divisor, & remainder);
  return (tmp);
}
}
__inline static long PTR_ERR(void const   *ptr ) ;
__inline static bool IS_ERR(void const   *ptr ) ;
__inline static bool IS_ERR_OR_NULL(void const   *ptr ) ;
int ldv_mutex_trylock_385(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_383(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_386(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_387(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_382(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_384(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_388(struct mutex *ldv_func_arg1 ) ;
extern void __raw_spin_lock_init(raw_spinlock_t * , char const   * , struct lock_class_key * ) ;
extern unsigned long _raw_spin_lock_irqsave(raw_spinlock_t * ) ;
extern void _raw_spin_unlock_irqrestore(raw_spinlock_t * , unsigned long  ) ;
__inline static raw_spinlock_t *spinlock_check(spinlock_t *lock ) 
{ 


  {
  return (& lock->__annonCompField17.rlock);
}
}
__inline static void spin_unlock_irqrestore(spinlock_t *lock , unsigned long flags ) 
{ 


  {
  _raw_spin_unlock_irqrestore(& lock->__annonCompField17.rlock, flags);
  return;
}
}
extern void set_normalized_timespec(struct timespec * , time_t  , s64  ) ;
__inline static struct timespec timespec_add(struct timespec lhs , struct timespec rhs ) 
{ 
  struct timespec ts_delta ;

  {
  set_normalized_timespec(& ts_delta, lhs.tv_sec + rhs.tv_sec, (s64 )(lhs.tv_nsec + rhs.tv_nsec));
  return (ts_delta);
}
}
__inline static s64 timespec_to_ns(struct timespec  const  *ts ) 
{ 


  {
  return ((long long )ts->tv_sec * 1000000000LL + (long long )ts->tv_nsec);
}
}
extern struct timespec ns_to_timespec(s64 const    ) ;
__inline static ktime_t ns_to_ktime(u64 ns ) 
{ 
  ktime_t ktime_zero ;
  ktime_t __constr_expr_0 ;

  {
  ktime_zero.tv64 = 0LL;
  __constr_expr_0.tv64 = (long long )((unsigned long long )ktime_zero.tv64 + ns);
  return (__constr_expr_0);
}
}
extern ktime_t ktime_get_with_offset(enum tk_offsets  ) ;
__inline static ktime_t ktime_get_real(void) 
{ 
  ktime_t tmp ;

  {
  tmp = ktime_get_with_offset(0);
  return (tmp);
}
}
bool ldv_queue_work_on_377(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_379(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_378(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_381(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_380(struct workqueue_struct *ldv_func_arg1 ) ;
__inline static struct skb_shared_hwtstamps *skb_hwtstamps(struct sk_buff *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  return (& ((struct skb_shared_info *)tmp)->hwtstamps);
}
}
extern struct ptp_clock *ptp_clock_register(struct ptp_clock_info * , struct device * ) ;
extern int ptp_clock_unregister(struct ptp_clock * ) ;
static void i40e_ptp_read(struct i40e_pf *pf , struct timespec *ts ) 
{ 
  struct i40e_hw *hw ;
  u32 hi ;
  u32 lo ;
  u64 ns ;

  {
  hw = & pf->hw;
  lo = readl((void const volatile   *)hw->hw_addr + 1982720U);
  hi = readl((void const volatile   *)hw->hw_addr + 1982752U);
  ns = ((unsigned long long )hi << 32) | (unsigned long long )lo;
  *ts = ns_to_timespec((s64 const   )ns);
  return;
}
}
static void i40e_ptp_write(struct i40e_pf *pf , struct timespec  const  *ts ) 
{ 
  struct i40e_hw *hw ;
  u64 ns ;
  s64 tmp ;

  {
  hw = & pf->hw;
  tmp = timespec_to_ns(ts);
  ns = (u64 )tmp;
  writel((unsigned int )ns, (void volatile   *)hw->hw_addr + 1982720U);
  writel((unsigned int )(ns >> 32), (void volatile   *)hw->hw_addr + 1982752U);
  return;
}
}
static void i40e_ptp_convert_to_hwtstamp(struct skb_shared_hwtstamps *hwtstamps ,
                                         u64 timestamp ) 
{ 


  {
  memset((void *)hwtstamps, 0, 8UL);
  hwtstamps->hwtstamp = ns_to_ktime(timestamp);
  return;
}
}
static int i40e_ptp_adjfreq(struct ptp_clock_info *ptp , s32 ppb ) 
{ 
  struct i40e_pf *pf ;
  struct ptp_clock_info  const  *__mptr ;
  struct i40e_hw *hw ;
  u64 adj ;
  u64 freq ;
  u64 diff ;
  int neg_adj ;
    klee_make_symbolic(&neg_adj, sizeof(int), "neg_adj");
  u64 __var ;

  {
  __mptr = (struct ptp_clock_info  const  *)ptp;
  pf = (struct i40e_pf *)__mptr + 0xfffffffffffdf0a8UL;
  hw = & pf->hw;
  neg_adj = 0;
  if (ppb < 0) {
    neg_adj = 1;
    ppb = - ppb;
  } else {

  }
  __asm__  volatile   ("mfence": : : "memory");
  __var = 0ULL;
  adj = *((u64 volatile   *)(& pf->ptp_base_adj));
  freq = adj;
  freq = (u64 )ppb * freq;
  diff = div_u64(freq, 1000000000U);
  if (neg_adj != 0) {
    adj = adj - diff;
  } else {
    adj = adj + diff;
  }
  writel((unsigned int )adj, (void volatile   *)hw->hw_addr + 1982528U);
  writel((unsigned int )(adj >> 32), (void volatile   *)hw->hw_addr + 1982560U);
  return (0);
}
}
static int i40e_ptp_adjtime(struct ptp_clock_info *ptp , s64 delta ) 
{ 
  struct i40e_pf *pf ;
  struct ptp_clock_info  const  *__mptr ;
  struct timespec now ;
  struct timespec then ;
  struct timespec tmp ;
  unsigned long flags ;
  raw_spinlock_t *tmp___0 ;

  {
  __mptr = (struct ptp_clock_info  const  *)ptp;
  pf = (struct i40e_pf *)__mptr + 0xfffffffffffdf0a8UL;
  tmp = ns_to_timespec(delta);
  then = tmp;
  tmp___0 = spinlock_check(& pf->tmreg_lock);
  flags = _raw_spin_lock_irqsave(tmp___0);
  i40e_ptp_read(pf, & now);
  now = timespec_add(now, then);
  i40e_ptp_write(pf, (struct timespec  const  *)(& now));
  spin_unlock_irqrestore(& pf->tmreg_lock, flags);
  return (0);
}
}
static int i40e_ptp_gettime(struct ptp_clock_info *ptp , struct timespec *ts ) 
{ 
  struct i40e_pf *pf ;
  struct ptp_clock_info  const  *__mptr ;
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
  __mptr = (struct ptp_clock_info  const  *)ptp;
  pf = (struct i40e_pf *)__mptr + 0xfffffffffffdf0a8UL;
  tmp = spinlock_check(& pf->tmreg_lock);
  flags = _raw_spin_lock_irqsave(tmp);
  i40e_ptp_read(pf, ts);
  spin_unlock_irqrestore(& pf->tmreg_lock, flags);
  return (0);
}
}
static int i40e_ptp_settime(struct ptp_clock_info *ptp , struct timespec  const  *ts ) 
{ 
  struct i40e_pf *pf ;
  struct ptp_clock_info  const  *__mptr ;
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
  __mptr = (struct ptp_clock_info  const  *)ptp;
  pf = (struct i40e_pf *)__mptr + 0xfffffffffffdf0a8UL;
  tmp = spinlock_check(& pf->tmreg_lock);
  flags = _raw_spin_lock_irqsave(tmp);
  i40e_ptp_write(pf, ts);
  spin_unlock_irqrestore(& pf->tmreg_lock, flags);
  return (0);
}
}
static int i40e_ptp_feature_enable(struct ptp_clock_info *ptp , struct ptp_clock_request *rq ,
                                   int on ) 
{ 


  {
  return (-95);
}
}
void i40e_ptp_rx_hang(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  struct i40e_ring *rx_ring ;
  unsigned long rx_event ;
    klee_make_symbolic(&rx_event, sizeof(long), "rx_event");
  u32 prttsyn_stat ;
  int n ;

  {
  pf = vsi->back;
  hw = & pf->hw;
  if ((pf->flags & 33554432ULL) == 0ULL || ! pf->ptp_rx) {
    return;
  } else {

  }
  prttsyn_stat = readl((void const volatile   *)hw->hw_addr + 545088U);
  if ((prttsyn_stat & 85U) == 0U) {
    pf->last_rx_ptp_check = jiffies;
    return;
  } else {

  }
  rx_event = pf->last_rx_ptp_check;
  n = 0;
  goto ldv_61073;
  ldv_61072: 
  rx_ring = *(vsi->rx_rings + (unsigned long )n);
  if ((long )(rx_event - rx_ring->last_rx_timestamp) < 0L) {
    rx_event = rx_ring->last_rx_timestamp;
  } else {

  }
  n = n + 1;
  ldv_61073: ;
  if ((int )vsi->num_queue_pairs > n) {
    goto ldv_61072;
  } else {

  }

  if ((long )((rx_event - (unsigned long )jiffies) + 1250UL) < 0L) {
    readl((void const volatile   *)hw->hw_addr + 544832U);
    readl((void const volatile   *)hw->hw_addr + 544864U);
    readl((void const volatile   *)hw->hw_addr + 544896U);
    readl((void const volatile   *)hw->hw_addr + 544928U);
    pf->last_rx_ptp_check = jiffies;
    pf->rx_hwtstamp_cleared = pf->rx_hwtstamp_cleared + 1U;
    dev_warn((struct device  const  *)(& ((vsi->back)->pdev)->dev), "%s: clearing Rx timestamp hang\n",
             "i40e_ptp_rx_hang");
  } else {

  }
  return;
}
}
void i40e_ptp_tx_hwtstamp(struct i40e_pf *pf ) 
{ 
  struct skb_shared_hwtstamps shhwtstamps ;
  struct i40e_hw *hw ;
  u32 hi ;
  u32 lo ;
  u64 ns ;

  {
  hw = & pf->hw;
  if ((pf->flags & 33554432ULL) == 0ULL || ! pf->ptp_tx) {
    return;
  } else {

  }
  if ((unsigned long )pf->ptp_tx_skb == (unsigned long )((struct sk_buff *)0)) {
    return;
  } else {

  }
  lo = readl((void const volatile   *)hw->hw_addr + 1982912U);
  hi = readl((void const volatile   *)hw->hw_addr + 1982944U);
  ns = ((unsigned long long )hi << 32) | (unsigned long long )lo;
  i40e_ptp_convert_to_hwtstamp(& shhwtstamps, ns);
  skb_tstamp_tx(pf->ptp_tx_skb, & shhwtstamps);
  dev_kfree_skb_any(pf->ptp_tx_skb);
  pf->ptp_tx_skb = (struct sk_buff *)0;
  clear_bit_unlock(19L, (unsigned long volatile   *)(& pf->state));
  return;
}
}
void i40e_ptp_rx_hwtstamp(struct i40e_pf *pf , struct sk_buff *skb , u8 index ) 
{ 
  u32 prttsyn_stat ;
  u32 hi ;
  u32 lo ;
  struct i40e_hw *hw ;
  u64 ns ;
  struct skb_shared_hwtstamps *tmp ;

  {
  if ((pf->flags & 33554432ULL) == 0ULL || ! pf->ptp_rx) {
    return;
  } else {

  }
  hw = & pf->hw;
  prttsyn_stat = readl((void const volatile   *)hw->hw_addr + 545088U);
  if (((u32 )(1 << (int )index) & prttsyn_stat) == 0U) {
    return;
  } else {

  }
  lo = readl((void const volatile   *)hw->hw_addr + (unsigned long )(((int )index + 17030) * 32));
  hi = readl((void const volatile   *)hw->hw_addr + (unsigned long )(((int )index + 17026) * 32));
  ns = ((unsigned long long )hi << 32) | (unsigned long long )lo;
  tmp = skb_hwtstamps(skb);
  i40e_ptp_convert_to_hwtstamp(tmp, ns);
  return;
}
}
void i40e_ptp_set_increment(struct i40e_pf *pf ) 
{ 
  struct i40e_link_status *hw_link_info ;
  struct i40e_hw *hw ;
  u64 incval ;
  int warn_once ;
    klee_make_symbolic(&warn_once, sizeof(int), "warn_once");
  u64 __var ;

  {
  hw = & pf->hw;
  hw_link_info = & hw->phy.link_info;
  i40e_aq_get_link_info(& pf->hw, 1, (struct i40e_link_status *)0, (struct i40e_asq_cmd_details *)0);
  switch ((unsigned int )hw_link_info->link_speed) {
  case 8U: 
  incval = 13743895347ULL;
  goto ldv_61107;
  case 4U: 
  incval = 137438953472ULL;
  goto ldv_61107;
  case 2U: ;
  if (warn_once == 0) {
    dev_warn((struct device  const  *)(& (pf->pdev)->dev), "1588 functionality is not supported at 100 Mbps. Stopping the PHC.\n");
    warn_once = warn_once + 1;
  } else {

  }
  incval = 0ULL;
  goto ldv_61107;
  case 16U: ;
  default: 
  incval = 6871947673ULL;
  goto ldv_61107;
  }
  ldv_61107: 
  writel((unsigned int )incval, (void volatile   *)hw->hw_addr + 1982528U);
  writel((unsigned int )(incval >> 32), (void volatile   *)hw->hw_addr + 1982560U);
  __var = 0ULL;
  *((u64 volatile   *)(& pf->ptp_base_adj)) = incval;
  __asm__  volatile   ("mfence": : : "memory");
  return;
}
}
int i40e_ptp_get_ts_config(struct i40e_pf *pf , struct ifreq *ifr ) 
{ 
  struct hwtstamp_config *config ;
  unsigned long tmp ;

  {
  config = & pf->tstamp_config;
  if ((pf->flags & 33554432ULL) == 0ULL) {
    return (-95);
  } else {

  }
  tmp = copy_to_user(ifr->ifr_ifru.ifru_data, (void const   *)config, 12UL);
  return (tmp != 0UL ? -14 : 0);
}
}
static int i40e_ptp_set_timestamp_mode(struct i40e_pf *pf , struct hwtstamp_config *config ) 
{ 
  struct i40e_hw *hw ;
  u32 tsyntype ;
  u32 regval ;

  {
  hw = & pf->hw;
  if (config->flags != 0) {
    return (-22);
  } else {

  }
  switch (config->tx_type) {
  case 0: 
  pf->ptp_tx = 0;
  goto ldv_61128;
  case 1: 
  pf->ptp_tx = 1;
  goto ldv_61128;
  default: ;
  return (-34);
  }
  ldv_61128: ;
  switch (config->rx_filter) {
  case 0: 
  pf->ptp_rx = 0;
  tsyntype = 16777216U;
  goto ldv_61132;
  case 4: ;
  case 5: ;
  case 3: 
  pf->ptp_rx = 1;
  tsyntype = 218104063U;
  config->rx_filter = 3;
  goto ldv_61132;
  case 12: ;
  case 9: ;
  case 6: ;
  case 13: ;
  case 10: ;
  case 7: ;
  case 14: ;
  case 11: ;
  case 8: 
  pf->ptp_rx = 1;
  tsyntype = 235864064U;
  config->rx_filter = 12;
  goto ldv_61132;
  case 1: ;
  default: ;
  return (-34);
  }
  ldv_61132: 
  readl((void const volatile   *)hw->hw_addr + 1983008U);
  readl((void const volatile   *)hw->hw_addr + 1982944U);
  readl((void const volatile   *)hw->hw_addr + 544832U);
  readl((void const volatile   *)hw->hw_addr + 544864U);
  readl((void const volatile   *)hw->hw_addr + 544896U);
  readl((void const volatile   *)hw->hw_addr + 544928U);
  regval = readl((void const volatile   *)hw->hw_addr + 1982976U);
  if ((int )pf->ptp_tx) {
    regval = regval | 2U;
  } else {
    regval = regval & 4294967293U;
  }
  writel(regval, (void volatile   *)hw->hw_addr + 1982976U);
  regval = readl((void const volatile   *)hw->hw_addr + 231424U);
  if ((int )pf->ptp_tx) {
    regval = regval | 8388608U;
  } else {
    regval = regval & 4286578687U;
  }
  writel(regval, (void volatile   *)hw->hw_addr + 231424U);
  regval = readl((void const volatile   *)hw->hw_addr + 544800U);
  regval = regval & 2147483648U;
  regval = regval | tsyntype;
  writel(regval, (void volatile   *)hw->hw_addr + 544800U);
  return (0);
}
}
int i40e_ptp_set_ts_config(struct i40e_pf *pf , struct ifreq *ifr ) 
{ 
  struct hwtstamp_config config ;
  int err ;
  unsigned long tmp ;
  unsigned long tmp___0 ;

  {
  if ((pf->flags & 33554432ULL) == 0ULL) {
    return (-95);
  } else {

  }
  tmp = copy_from_user((void *)(& config), (void const   *)ifr->ifr_ifru.ifru_data,
                       12UL);
  if (tmp != 0UL) {
    return (-14);
  } else {

  }
  err = i40e_ptp_set_timestamp_mode(pf, & config);
  if (err != 0) {
    return (err);
  } else {

  }
  pf->tstamp_config = config;
  tmp___0 = copy_to_user(ifr->ifr_ifru.ifru_data, (void const   *)(& config), 12UL);
  return (tmp___0 != 0UL ? -14 : 0);
}
}
static long i40e_ptp_create_clock(struct i40e_pf *pf ) 
{ 
  bool tmp ;
  int tmp___0 ;
  long tmp___1 ;
  bool tmp___2 ;

  {
  tmp = IS_ERR_OR_NULL((void const   *)pf->ptp_clock);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (0L);
  } else {

  }
  strncpy((char *)(& pf->ptp_caps.name), (char const   *)(& i40e_driver_name), 16UL);
  pf->ptp_caps.owner = & __this_module;
  pf->ptp_caps.max_adj = 999999999;
  pf->ptp_caps.n_ext_ts = 0;
  pf->ptp_caps.pps = 0;
  pf->ptp_caps.adjfreq = & i40e_ptp_adjfreq;
  pf->ptp_caps.adjtime = & i40e_ptp_adjtime;
  pf->ptp_caps.gettime64 = & i40e_ptp_gettime;
  pf->ptp_caps.settime64 = & i40e_ptp_settime;
  pf->ptp_caps.enable = & i40e_ptp_feature_enable;
  pf->ptp_clock = ptp_clock_register(& pf->ptp_caps, & (pf->pdev)->dev);
  tmp___2 = IS_ERR((void const   *)pf->ptp_clock);
  if ((int )tmp___2) {
    tmp___1 = PTR_ERR((void const   *)pf->ptp_clock);
    return (tmp___1);
  } else {

  }
  pf->tstamp_config.rx_filter = 0;
  pf->tstamp_config.tx_type = 0;
  return (0L);
}
}
void i40e_ptp_init(struct i40e_pf *pf ) 
{ 
  struct net_device *netdev ;
  struct i40e_hw *hw ;
  u32 pf_id ;
  long err ;
  unsigned int tmp ;
  struct lock_class_key __key ;
  struct timespec ts ;
  u32 regval ;
  ktime_t tmp___0 ;

  {
  netdev = (*(pf->vsi + (unsigned long )pf->lan_vsi))->netdev;
  hw = & pf->hw;
  tmp = readl((void const volatile   *)hw->hw_addr + 1982976U);
  pf_id = (tmp & 3840U) >> 8;
  if ((u32 )hw->pf_id != pf_id) {
    pf->flags = pf->flags & 0xfffffffffdffffffULL;
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%s: PTP not supported on %s\n",
              "i40e_ptp_init", (char *)(& netdev->name));
    return;
  } else {

  }
  spinlock_check(& pf->tmreg_lock);
  __raw_spin_lock_init(& pf->tmreg_lock.__annonCompField17.rlock, "&(&pf->tmreg_lock)->rlock",
                       & __key);
  err = i40e_ptp_create_clock(pf);
  if (err != 0L) {
    pf->ptp_clock = (struct ptp_clock *)0;
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "%s: ptp_clock_register failed\n",
            "i40e_ptp_init");
  } else {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%s: added PHC on %s\n",
              "i40e_ptp_init", (char *)(& netdev->name));
    pf->flags = pf->flags | 33554432ULL;
    regval = readl((void const volatile   *)hw->hw_addr + 1982976U);
    regval = regval | 2147483648U;
    writel(regval, (void volatile   *)hw->hw_addr + 1982976U);
    regval = readl((void const volatile   *)hw->hw_addr + 544800U);
    regval = regval | 2147483648U;
    writel(regval, (void volatile   *)hw->hw_addr + 544800U);
    i40e_ptp_set_increment(pf);
    i40e_ptp_set_timestamp_mode(pf, & pf->tstamp_config);
    tmp___0 = ktime_get_real();
    ts = ns_to_timespec(tmp___0.tv64);
    i40e_ptp_settime(& pf->ptp_caps, (struct timespec  const  *)(& ts));
  }
  return;
}
}
void i40e_ptp_stop(struct i40e_pf *pf ) 
{ 


  {
  pf->flags = pf->flags & 0xfffffffffdffffffULL;
  pf->ptp_tx = 0;
  pf->ptp_rx = 0;
  if ((unsigned long )pf->ptp_tx_skb != (unsigned long )((struct sk_buff *)0)) {
    dev_kfree_skb_any(pf->ptp_tx_skb);
    pf->ptp_tx_skb = (struct sk_buff *)0;
    clear_bit_unlock(19L, (unsigned long volatile   *)(& pf->state));
  } else {

  }
  if ((unsigned long )pf->ptp_clock != (unsigned long )((struct ptp_clock *)0)) {
    ptp_clock_unregister(pf->ptp_clock);
    pf->ptp_clock = (struct ptp_clock *)0;
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%s: removed PHC on %s\n",
              "i40e_ptp_stop", (char *)(& ((*(pf->vsi + (unsigned long )pf->lan_vsi))->netdev)->name));
  } else {

  }
  return;
}
}
__inline static long PTR_ERR(void const   *ptr ) 
{ 
  long tmp ;

  {
  tmp = ldv_ptr_err(ptr);
  return (tmp);
}
}
__inline static bool IS_ERR(void const   *ptr ) 
{ 
  bool tmp ;

  {
  tmp = ldv_is_err(ptr);
  return (tmp);
}
}
__inline static bool IS_ERR_OR_NULL(void const   *ptr ) 
{ 
  bool tmp ;

  {
  tmp = ldv_is_err_or_null(ptr);
  return (tmp);
}
}
bool ldv_queue_work_on_377(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_378(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_379(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_380(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_381(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_382(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_383(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_384(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_385(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_386(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_387(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_388(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_413(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_411(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_414(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_415(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_410(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_412(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_416(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_405(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_407(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_406(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_409(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_408(struct workqueue_struct *ldv_func_arg1 ) ;
extern int pci_enable_sriov(struct pci_dev * , int  ) ;
extern void pci_disable_sriov(struct pci_dev * ) ;
extern int pci_vfs_assigned(struct pci_dev * ) ;
__inline static bool is_broadcast_ether_addr(u8 const   *addr ) 
{ 


  {
  return ((unsigned int )(((int )((unsigned short )*((u16 const   *)addr)) & (int )((unsigned short )*((u16 const   *)addr + 2U))) & (int )((unsigned short )*((u16 const   *)addr + 4U))) == 65535U);
}
}
static void i40e_vc_vf_broadcast(struct i40e_pf *pf , enum i40e_virtchnl_ops v_opcode ,
                                 i40e_status v_retval , u8 *msg , u16 msglen ) 
{ 
  struct i40e_hw *hw ;
  struct i40e_vf *vf ;
  int i ;
  int abs_vf_id ;
    klee_make_symbolic(&abs_vf_id, sizeof(int), "abs_vf_id");
  int tmp ;
  int tmp___0 ;

  {
  hw = & pf->hw;
  vf = pf->vf;
  i = 0;
  goto ldv_60994;
  ldv_60993: 
  abs_vf_id = (int )((u32 )vf->vf_id + hw->func_caps.vf_base_id);
  tmp = constant_test_bit(0L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp == 0) {
    tmp___0 = constant_test_bit(1L, (unsigned long const volatile   *)(& vf->vf_states));
    if (tmp___0 == 0) {
      goto ldv_60992;
    } else {

    }
  } else {

  }
  i40e_aq_send_msg_to_vf(hw, (int )((u16 )abs_vf_id), (u32 )v_opcode, (u32 )v_retval,
                         msg, (int )msglen, (struct i40e_asq_cmd_details *)0);
  ldv_60992: 
  i = i + 1;
  vf = vf + 1;
  ldv_60994: ;
  if (pf->num_alloc_vfs > i) {
    goto ldv_60993;
  } else {

  }

  return;
}
}
static void i40e_vc_notify_vf_link_state(struct i40e_vf *vf ) 
{ 
  struct i40e_virtchnl_pf_event pfe ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  struct i40e_link_status *ls ;
  int abs_vf_id ;

  {
  pf = vf->pf;
  hw = & pf->hw;
  ls = & pf->hw.phy.link_info;
  abs_vf_id = (int )((u32 )vf->vf_id + hw->func_caps.vf_base_id);
  pfe.event = 1;
  pfe.severity = 0;
  if ((int )vf->link_forced) {
    pfe.event_data.link_event.link_status = vf->link_up;
    pfe.event_data.link_event.link_speed = (int )vf->link_up ? 16 : 0;
  } else {
    pfe.event_data.link_event.link_status = ((int )ls->link_info & 1) != 0;
    pfe.event_data.link_event.link_speed = ls->link_speed;
  }
  i40e_aq_send_msg_to_vf(hw, (int )((u16 )abs_vf_id), 17U, 0U, (u8 *)(& pfe), 16,
                         (struct i40e_asq_cmd_details *)0);
  return;
}
}
void i40e_vc_notify_link_state(struct i40e_pf *pf ) 
{ 
  int i ;

  {
  i = 0;
  goto ldv_61009;
  ldv_61008: 
  i40e_vc_notify_vf_link_state(pf->vf + (unsigned long )i);
  i = i + 1;
  ldv_61009: ;
  if (pf->num_alloc_vfs > i) {
    goto ldv_61008;
  } else {

  }

  return;
}
}
void i40e_vc_notify_reset(struct i40e_pf *pf ) 
{ 
  struct i40e_virtchnl_pf_event pfe ;

  {
  pfe.event = 2;
  pfe.severity = 255;
  i40e_vc_vf_broadcast(pf, 17, 0, (u8 *)(& pfe), 16);
  return;
}
}
void i40e_vc_notify_vf_reset(struct i40e_vf *vf ) 
{ 
  struct i40e_virtchnl_pf_event pfe ;
  int abs_vf_id ;
  int tmp ;
  int tmp___0 ;

  {
  if ((unsigned long )vf == (unsigned long )((struct i40e_vf *)0) || (int )vf->vf_id >= (vf->pf)->num_alloc_vfs) {
    return;
  } else {

  }
  tmp = constant_test_bit(0L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp == 0) {
    tmp___0 = constant_test_bit(1L, (unsigned long const volatile   *)(& vf->vf_states));
    if (tmp___0 == 0) {
      return;
    } else {

    }
  } else {

  }
  abs_vf_id = (int )((u32 )vf->vf_id + (vf->pf)->hw.func_caps.vf_base_id);
  pfe.event = 2;
  pfe.severity = 255;
  i40e_aq_send_msg_to_vf(& (vf->pf)->hw, (int )((u16 )abs_vf_id), 17U, 0U, (u8 *)(& pfe),
                         16, (struct i40e_asq_cmd_details *)0);
  return;
}
}
__inline static void i40e_vc_disable_vf(struct i40e_pf *pf , struct i40e_vf *vf ) 
{ 
  struct i40e_hw *hw ;
  u32 reg ;

  {
  hw = & pf->hw;
  reg = readl((void const volatile   *)hw->hw_addr + (unsigned long )(((int )vf->vf_id + 148992) * 4));
  reg = reg | 1U;
  writel(reg, (void volatile   *)hw->hw_addr + (unsigned long )(((int )vf->vf_id + 148992) * 4));
  readl((void const volatile   *)hw->hw_addr + 745772U);
  return;
}
}
__inline static bool i40e_vc_isvalid_vsi_id(struct i40e_vf *vf , u16 vsi_id ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_vsi *vsi ;
  struct i40e_vsi *tmp ;

  {
  pf = vf->pf;
  tmp = i40e_find_vsi_from_id(pf, (int )vsi_id);
  vsi = tmp;
  return ((bool )((unsigned long )vsi != (unsigned long )((struct i40e_vsi *)0) && (int )vsi->vf_id == (int )vf->vf_id));
}
}
__inline static bool i40e_vc_isvalid_queue_id(struct i40e_vf *vf , u16 vsi_id , u8 qid ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_vsi *vsi ;
  struct i40e_vsi *tmp ;

  {
  pf = vf->pf;
  tmp = i40e_find_vsi_from_id(pf, (int )vsi_id);
  vsi = tmp;
  return ((bool )((unsigned long )vsi != (unsigned long )((struct i40e_vsi *)0) && (int )((unsigned short )qid) < (int )vsi->alloc_queue_pairs));
}
}
__inline static bool i40e_vc_isvalid_vector_id(struct i40e_vf *vf , u8 vector_id ) 
{ 
  struct i40e_pf *pf ;

  {
  pf = vf->pf;
  return ((u32 )vector_id < pf->hw.func_caps.num_msix_vectors_vf);
}
}
static u16 i40e_vc_get_pf_queue_id(struct i40e_vf *vf , u16 vsi_id , u8 vsi_queue_id ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_vsi *vsi ;
  struct i40e_vsi *tmp ;
  u16 pf_queue_id ;

  {
  pf = vf->pf;
  tmp = i40e_find_vsi_from_id(pf, (int )vsi_id);
  vsi = tmp;
  pf_queue_id = 2047U;
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
    return (pf_queue_id);
  } else {

  }
  if ((int )vsi->info.mapping_flags & 1) {
    pf_queue_id = vsi->info.queue_mapping[(int )vsi_queue_id];
  } else {
    pf_queue_id = (int )vsi->info.queue_mapping[0] + (int )((u16 )vsi_queue_id);
  }
  return (pf_queue_id);
}
}
static void i40e_config_irq_link_list(struct i40e_vf *vf , u16 vsi_id , struct i40e_virtchnl_vector_map *vecmap ) 
{ 
  unsigned long linklistmap ;
    klee_make_symbolic(&linklistmap, sizeof(long), "linklistmap");
  unsigned long tempmap ;
    klee_make_symbolic(&tempmap, sizeof(long), "tempmap");
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u16 vsi_queue_id ;
  u16 pf_queue_id ;
  enum i40e_queue_type qtype ;
  u16 next_q ;
  u16 vector_id ;
  u32 reg ;
  u32 reg_idx ;
  u16 itr_idx ;
  unsigned long tmp ;
  unsigned long tmp___0 ;
  unsigned long tmp___1 ;
  unsigned long tmp___2 ;
  unsigned long tmp___3 ;
  unsigned long tmp___4 ;

  {
  linklistmap = 0UL;
  pf = vf->pf;
  hw = & pf->hw;
  itr_idx = 0U;
  vector_id = vecmap->vector_id;
  if ((unsigned int )vector_id == 0U) {
    reg_idx = (u32 )(((int )vf->vf_id + 43520) * 4);
  } else {
    reg_idx = (((pf->hw.func_caps.num_msix_vectors_vf - 1U) * (u32 )vf->vf_id + (u32 )vector_id) + 37887U) * 4U;
  }
  if ((unsigned int )vecmap->rxq_map == 0U && (unsigned int )vecmap->txq_map == 0U) {
    writel(2047U, (void volatile   *)hw->hw_addr + (unsigned long )reg_idx);
    goto irq_list_done;
  } else {

  }
  tempmap = (unsigned long )vecmap->rxq_map;
  tmp = find_first_bit((unsigned long const   *)(& tempmap), 16UL);
  vsi_queue_id = (u16 )tmp;
  goto ldv_61071;
  ldv_61070: 
  linklistmap = (unsigned long )(1 << (int )vsi_queue_id * 2) | linklistmap;
  tmp___0 = find_next_bit((unsigned long const   *)(& tempmap), 16UL, (unsigned long )((int )vsi_queue_id + 1));
  vsi_queue_id = (u16 )tmp___0;
  ldv_61071: ;
  if ((unsigned int )vsi_queue_id <= 15U) {
    goto ldv_61070;
  } else {

  }
  tempmap = (unsigned long )vecmap->txq_map;
  tmp___1 = find_first_bit((unsigned long const   *)(& tempmap), 16UL);
  vsi_queue_id = (u16 )tmp___1;
  goto ldv_61074;
  ldv_61073: 
  linklistmap = (unsigned long )(1 << ((int )vsi_queue_id * 2 + 1)) | linklistmap;
  tmp___2 = find_next_bit((unsigned long const   *)(& tempmap), 16UL, (unsigned long )((int )vsi_queue_id + 1));
  vsi_queue_id = (u16 )tmp___2;
  ldv_61074: ;
  if ((unsigned int )vsi_queue_id <= 15U) {
    goto ldv_61073;
  } else {

  }
  tmp___3 = find_first_bit((unsigned long const   *)(& linklistmap), 32UL);
  next_q = (u16 )tmp___3;
  vsi_queue_id = (u16 )((unsigned int )next_q / 2U);
  qtype = (enum i40e_queue_type )((int )next_q & 1);
  pf_queue_id = i40e_vc_get_pf_queue_id(vf, (int )vsi_id, (int )((u8 )vsi_queue_id));
  reg = ((unsigned int )qtype << 11) | (unsigned int )pf_queue_id;
  writel(reg, (void volatile   *)hw->hw_addr + (unsigned long )reg_idx);
  goto ldv_61081;
  ldv_61080: ;
  switch ((unsigned int )qtype) {
  case 0U: 
  reg_idx = (u32 )(((int )pf_queue_id + 59392) * 4);
  itr_idx = vecmap->rxitr_idx;
  goto ldv_61077;
  case 1U: 
  reg_idx = (u32 )(((int )pf_queue_id + 61440) * 4);
  itr_idx = vecmap->txitr_idx;
  goto ldv_61077;
  default: ;
  goto ldv_61077;
  }
  ldv_61077: 
  tmp___4 = find_next_bit((unsigned long const   *)(& linklistmap), 32UL, (unsigned long )((int )next_q + 1));
  next_q = (u16 )tmp___4;
  if ((unsigned int )next_q <= 31U) {
    vsi_queue_id = (u16 )((unsigned int )next_q / 2U);
    qtype = (enum i40e_queue_type )((int )next_q & 1);
    pf_queue_id = i40e_vc_get_pf_queue_id(vf, (int )vsi_id, (int )((u8 )vsi_queue_id));
  } else {
    pf_queue_id = 2047U;
    qtype = 0;
  }
  reg = ((((unsigned int )vector_id | ((unsigned int )qtype << 27)) | (unsigned int )((int )pf_queue_id << 16)) | (unsigned int )((int )itr_idx << 11)) | 1073741824U;
  writel(reg, (void volatile   *)hw->hw_addr + (unsigned long )reg_idx);
  ldv_61081: ;
  if ((unsigned int )next_q <= 31U) {
    goto ldv_61080;
  } else {

  }

  irq_list_done: 
  readl((void const volatile   *)hw->hw_addr + 745772U);
  return;
}
}
static int i40e_config_vsi_tx_queue(struct i40e_vf *vf , u16 vsi_id , u16 vsi_queue_id ,
                                    struct i40e_virtchnl_txq_info *info ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  struct i40e_hmc_obj_txq tx_ctx ;
  struct i40e_vsi *vsi ;
  u16 pf_queue_id ;
  u32 qtx_ctl ;
  int ret ;
  i40e_status tmp ;
  i40e_status tmp___0 ;

  {
  pf = vf->pf;
  hw = & pf->hw;
  ret = 0;
  pf_queue_id = i40e_vc_get_pf_queue_id(vf, (int )vsi_id, (int )((u8 )vsi_queue_id));
  vsi = i40e_find_vsi_from_id(pf, (int )vsi_id);
  memset((void *)(& tx_ctx), 0, 48UL);
  tx_ctx.base = info->dma_ring_addr / 128ULL;
  tx_ctx.qlen = info->ring_len;
  tx_ctx.rdylist = vsi->info.qs_handle[0];
  tx_ctx.rdylist_act = 0U;
  tx_ctx.head_wb_ena = (u8 )info->headwb_enabled;
  tx_ctx.head_wb_addr = info->dma_headwb_addr;
  tmp = i40e_clear_lan_tx_queue_context(hw, (int )pf_queue_id);
  ret = (int )tmp;
  if (ret != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Failed to clear VF LAN Tx queue context %d, error: %d\n",
            (int )pf_queue_id, ret);
    ret = -2;
    goto error_context;
  } else {

  }
  tmp___0 = i40e_set_lan_tx_queue_context(hw, (int )pf_queue_id, & tx_ctx);
  ret = (int )tmp___0;
  if (ret != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Failed to set VF LAN Tx queue context %d error: %d\n",
            (int )pf_queue_id, ret);
    ret = -2;
    goto error_context;
  } else {

  }
  qtx_ctl = 0U;
  qtx_ctl = ((u32 )((int )hw->pf_id << 2) & 60U) | qtx_ctl;
  qtx_ctl = ((((u32 )vf->vf_id + hw->func_caps.vf_base_id) << 7) & 65535U) | qtx_ctl;
  writel(qtx_ctl, (void volatile   *)hw->hw_addr + (unsigned long )(((int )pf_queue_id + 266240) * 4));
  readl((void const volatile   *)hw->hw_addr + 745772U);
  error_context: ;
  return (ret);
}
}
static int i40e_config_vsi_rx_queue(struct i40e_vf *vf , u16 vsi_id , u16 vsi_queue_id ,
                                    struct i40e_virtchnl_rxq_info *info ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  struct i40e_hmc_obj_rxq rx_ctx ;
  u16 pf_queue_id ;
  int ret ;
  i40e_status tmp ;
  i40e_status tmp___0 ;

  {
  pf = vf->pf;
  hw = & pf->hw;
  ret = 0;
  pf_queue_id = i40e_vc_get_pf_queue_id(vf, (int )vsi_id, (int )((u8 )vsi_queue_id));
  memset((void *)(& rx_ctx), 0, 48UL);
  rx_ctx.base = info->dma_ring_addr / 128ULL;
  rx_ctx.qlen = (u16 )info->ring_len;
  if ((unsigned int )info->splithdr_enabled != 0U) {
    rx_ctx.hsplit_0 = 15U;
    if ((unsigned int )info->hdr_size > 1984U) {
      ret = -22;
      goto error_param;
    } else {

    }
    rx_ctx.hbuff = (u16 )((int )info->hdr_size >> 6);
    rx_ctx.dtype = 2U;
  } else {

  }
  if (info->databuffer_size > 16256U) {
    ret = -22;
    goto error_param;
  } else {

  }
  rx_ctx.dbuff = (u16 )(info->databuffer_size >> 7);
  if (info->max_pkt_size > 16383U || info->max_pkt_size <= 63U) {
    ret = -22;
    goto error_param;
  } else {

  }
  rx_ctx.rxmax = info->max_pkt_size;
  rx_ctx.dsize = 1U;
  rx_ctx.lrxqthresh = 2U;
  rx_ctx.crcstrip = 1U;
  rx_ctx.prefena = 1U;
  rx_ctx.l2tsel = 1U;
  tmp = i40e_clear_lan_rx_queue_context(hw, (int )pf_queue_id);
  ret = (int )tmp;
  if (ret != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Failed to clear VF LAN Rx queue context %d, error: %d\n",
            (int )pf_queue_id, ret);
    ret = -2;
    goto error_param;
  } else {

  }
  tmp___0 = i40e_set_lan_rx_queue_context(hw, (int )pf_queue_id, & rx_ctx);
  ret = (int )tmp___0;
  if (ret != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Failed to set VF LAN Rx queue context %d error: %d\n",
            (int )pf_queue_id, ret);
    ret = -2;
    goto error_param;
  } else {

  }
  error_param: ;
  return (ret);
}
}
static int i40e_alloc_vsi_res(struct i40e_vf *vf , enum i40e_vsi_type type ) 
{ 
  struct i40e_mac_filter *f ;
  struct i40e_pf *pf ;
  struct i40e_vsi *vsi ;
  int ret ;
  u8 brdcast[6U] ;
  i40e_status tmp ;

  {
  f = (struct i40e_mac_filter *)0;
  pf = vf->pf;
  ret = 0;
  vsi = i40e_vsi_setup(pf, (int )((u8 )type), (int )(*(pf->vsi + (unsigned long )pf->lan_vsi))->seid,
                       (u32 )vf->vf_id);
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "add vsi failed for VF %d, aq_err %d\n",
            (int )vf->vf_id, (unsigned int )pf->hw.aq.asq_last_status);
    ret = -2;
    goto error_alloc_vsi_res;
  } else {

  }
  if ((unsigned int )type == 6U) {
    brdcast[0] = 255U;
    brdcast[1] = 255U;
    brdcast[2] = 255U;
    brdcast[3] = 255U;
    brdcast[4] = 255U;
    brdcast[5] = 255U;
    vf->lan_vsi_idx = (u8 )vsi->idx;
    vf->lan_vsi_id = (u8 )vsi->id;
    if ((unsigned int )vf->port_vlan_id != 0U) {
      i40e_vsi_add_pvid(vsi, (int )vf->port_vlan_id);
    } else {

    }
    f = i40e_add_filter(vsi, (u8 *)(& vf->default_lan_addr.addr), (int )((s16 )vf->port_vlan_id),
                        1, 0);
    if ((unsigned long )f == (unsigned long )((struct i40e_mac_filter *)0)) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Could not allocate VF MAC addr\n");
    } else {

    }
    f = i40e_add_filter(vsi, (u8 *)(& brdcast), (int )((s16 )vf->port_vlan_id), 1,
                        0);
    if ((unsigned long )f == (unsigned long )((struct i40e_mac_filter *)0)) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Could not allocate VF broadcast filter\n");
    } else {

    }
  } else {

  }
  ret = i40e_sync_vsi_filters(vsi);
  if (ret != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Unable to program ucast filters\n");
  } else {

  }
  if (vf->tx_rate != 0U) {
    tmp = i40e_aq_config_vsi_bw_limit(& pf->hw, (int )vsi->seid, (int )((u16 )(vf->tx_rate / 50U)),
                                      0, (struct i40e_asq_cmd_details *)0);
    ret = (int )tmp;
    if (ret != 0) {
      dev_err((struct device  const  *)(& (pf->pdev)->dev), "Unable to set tx rate, VF %d, error code %d.\n",
              (int )vf->vf_id, ret);
    } else {

    }
  } else {

  }
  error_alloc_vsi_res: ;
  return (ret);
}
}
static void i40e_enable_vf_mappings(struct i40e_vf *vf ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u32 reg ;
  u32 total_queue_pairs ;
  int j ;
  u16 qid ;
  u16 tmp ;
  u16 qid___0 ;
  u16 tmp___0 ;

  {
  pf = vf->pf;
  hw = & pf->hw;
  total_queue_pairs = 0U;
  writel(2048U, (void volatile   *)hw->hw_addr + (unsigned long )(((int )vf->lan_vsi_id + 537088) * 4));
  reg = 1U;
  writel(reg, (void volatile   *)hw->hw_addr + (unsigned long )(((int )vf->vf_id + 118784) * 4));
  j = 0;
  goto ldv_61129;
  ldv_61128: 
  tmp = i40e_vc_get_pf_queue_id(vf, (int )vf->lan_vsi_id, (int )((u8 )j));
  qid = tmp;
  reg = (u32 )qid & 2047U;
  writel(reg, (void volatile   *)hw->hw_addr + (unsigned long )(((total_queue_pairs * 256U + (u32 )vf->vf_id) + 114688U) * 4U));
  total_queue_pairs = total_queue_pairs + 1U;
  j = j + 1;
  ldv_61129: ;
  if ((int )(*(pf->vsi + (unsigned long )vf->lan_vsi_idx))->alloc_queue_pairs > j) {
    goto ldv_61128;
  } else {

  }
  j = 0;
  goto ldv_61133;
  ldv_61132: ;
  if (j * 2 >= (int )(*(pf->vsi + (unsigned long )vf->lan_vsi_idx))->alloc_queue_pairs) {
    reg = 134154239U;
  } else {
    tmp___0 = i40e_vc_get_pf_queue_id(vf, (int )vf->lan_vsi_id, (int )((unsigned int )((u8 )j) * 2U));
    qid___0 = tmp___0;
    reg = (u32 )qid___0;
    qid___0 = i40e_vc_get_pf_queue_id(vf, (int )vf->lan_vsi_id, (int )((unsigned int )((u8 )j) * 2U + 1U));
    reg = (u32 )((int )qid___0 << 16) | reg;
  }
  writel(reg, (void volatile   *)hw->hw_addr + (unsigned long )(((j * 512 + (int )vf->lan_vsi_id) + 524288) * 4));
  j = j + 1;
  ldv_61133: ;
  if (j <= 6) {
    goto ldv_61132;
  } else {

  }
  readl((void const volatile   *)hw->hw_addr + 745772U);
  return;
}
}
static void i40e_disable_vf_mappings(struct i40e_vf *vf ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  int i ;

  {
  pf = vf->pf;
  hw = & pf->hw;
  writel(0U, (void volatile   *)hw->hw_addr + (unsigned long )(((int )vf->vf_id + 118784) * 4));
  i = 0;
  goto ldv_61142;
  ldv_61141: 
  writel(2047U, (void volatile   *)hw->hw_addr + (unsigned long )(((i * 256 + (int )vf->vf_id) + 114688) * 4));
  i = i + 1;
  ldv_61142: ;
  if (i <= 15) {
    goto ldv_61141;
  } else {

  }
  readl((void const volatile   *)hw->hw_addr + 745772U);
  return;
}
}
static void i40e_free_vf_res(struct i40e_vf *vf ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u32 reg_idx ;
  u32 reg ;
  int i ;
  int msix_vf ;
    klee_make_symbolic(&msix_vf, sizeof(int), "msix_vf");

  {
  pf = vf->pf;
  hw = & pf->hw;
  if ((unsigned int )vf->lan_vsi_idx != 0U) {
    i40e_vsi_release(*(pf->vsi + (unsigned long )vf->lan_vsi_idx));
    vf->lan_vsi_idx = 0U;
    vf->lan_vsi_id = 0U;
  } else {

  }
  msix_vf = (int )pf->hw.func_caps.num_msix_vectors_vf;
  i = 0;
  goto ldv_61154;
  ldv_61153: ;
  if (i == 0) {
    reg_idx = (u32 )(((int )vf->vf_id + 43264) * 4);
  } else {
    reg_idx = (u32 )((((msix_vf + -1) * 4) * (int )vf->vf_id + (i + -1) * 4) + 149504);
  }
  writel(2U, (void volatile   *)hw->hw_addr + (unsigned long )reg_idx);
  readl((void const volatile   *)hw->hw_addr + 745772U);
  i = i + 1;
  ldv_61154: ;
  if (i < msix_vf) {
    goto ldv_61153;
  } else {

  }
  i = 0;
  goto ldv_61157;
  ldv_61156: ;
  if (i == 0) {
    reg_idx = (u32 )(((int )vf->vf_id + 43520) * 4);
  } else {
    reg_idx = (u32 )((((msix_vf + -1) * 4) * (int )vf->vf_id + (i + -1) * 4) + 151552);
  }
  reg = 8191U;
  writel(reg, (void volatile   *)hw->hw_addr + (unsigned long )reg_idx);
  readl((void const volatile   *)hw->hw_addr + 745772U);
  i = i + 1;
  ldv_61157: ;
  if (i < msix_vf) {
    goto ldv_61156;
  } else {

  }
  vf->num_queue_pairs = 0U;
  vf->vf_states = 0UL;
  return;
}
}
static int i40e_alloc_vf_res(struct i40e_vf *vf ) 
{ 
  struct i40e_pf *pf ;
  int total_queue_pairs ;
    klee_make_symbolic(&total_queue_pairs, sizeof(int), "total_queue_pairs");
  int ret ;

  {
  pf = vf->pf;
  total_queue_pairs = 0;
  ret = i40e_alloc_vsi_res(vf, 6);
  if (ret != 0) {
    goto error_alloc;
  } else {

  }
  total_queue_pairs = (int )(*(pf->vsi + (unsigned long )vf->lan_vsi_idx))->alloc_queue_pairs + total_queue_pairs;
  set_bit(0L, (unsigned long volatile   *)(& vf->vf_caps));
  vf->num_queue_pairs = (u8 )total_queue_pairs;
  set_bit(0L, (unsigned long volatile   *)(& vf->vf_states));
  error_alloc: ;
  if (ret != 0) {
    i40e_free_vf_res(vf);
  } else {

  }
  return (ret);
}
}
static int i40e_quiesce_vf_pci(struct i40e_vf *vf ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  int vf_abs_id ;
    klee_make_symbolic(&vf_abs_id, sizeof(int), "vf_abs_id");
  int i ;
  u32 reg ;

  {
  pf = vf->pf;
  hw = & pf->hw;
  vf_abs_id = (int )((u32 )vf->vf_id + hw->func_caps.vf_base_id);
  writel((unsigned int )((vf_abs_id << 12) | 170), (void volatile   *)hw->hw_addr + 639104U);
  i = 0;
  goto ldv_61175;
  ldv_61174: 
  reg = readl((void const volatile   *)hw->hw_addr + 639232U);
  if ((reg & 32U) == 0U) {
    return (0);
  } else {

  }
  __const_udelay(4295UL);
  i = i + 1;
  ldv_61175: ;
  if (i <= 99) {
    goto ldv_61174;
  } else {

  }

  return (-5);
}
}
void i40e_reset_vf(struct i40e_vf *vf , bool flr ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  bool rsd ;
  int i ;
  u32 reg ;
  int tmp ;
  int tmp___0 ;

  {
  pf = vf->pf;
  hw = & pf->hw;
  rsd = 0;
  tmp = test_and_set_bit(25L, (unsigned long volatile   *)(& pf->state));
  if (tmp != 0) {
    return;
  } else {

  }
  clear_bit(1L, (unsigned long volatile   *)(& vf->vf_states));
  if (! flr) {
    reg = readl((void const volatile   *)hw->hw_addr + (unsigned long )(((int )vf->vf_id + 148992) * 4));
    reg = reg | 1U;
    writel(reg, (void volatile   *)hw->hw_addr + (unsigned long )(((int )vf->vf_id + 148992) * 4));
    readl((void const volatile   *)hw->hw_addr + 745772U);
  } else {

  }
  tmp___0 = i40e_quiesce_vf_pci(vf);
  if (tmp___0 != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "VF %d PCI transactions stuck\n",
            (int )vf->vf_id);
  } else {

  }
  i = 0;
  goto ldv_61188;
  ldv_61187: 
  usleep_range(10000UL, 20000UL);
  reg = readl((void const volatile   *)hw->hw_addr + (unsigned long )(((int )vf->vf_id + 149248) * 4));
  if ((int )reg & 1) {
    rsd = 1;
    goto ldv_61186;
  } else {

  }
  i = i + 1;
  ldv_61188: ;
  if (i <= 9) {
    goto ldv_61187;
  } else {

  }
  ldv_61186: ;
  if ((int )flr) {
    usleep_range(10000UL, 20000UL);
  } else {

  }
  if (! rsd) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "VF reset check timeout on VF %d\n",
            (int )vf->vf_id);
  } else {

  }
  writel(1U, (void volatile   *)hw->hw_addr + (unsigned long )(((int )vf->vf_id + 119040) * 4));
  reg = readl((void const volatile   *)hw->hw_addr + (unsigned long )(((int )vf->vf_id + 148992) * 4));
  reg = reg & 4294967294U;
  writel(reg, (void volatile   *)hw->hw_addr + (unsigned long )(((int )vf->vf_id + 148992) * 4));
  if ((unsigned int )vf->lan_vsi_idx == 0U) {
    goto complete_reset;
  } else {

  }
  i40e_vsi_control_rings(*(pf->vsi + (unsigned long )vf->lan_vsi_idx), 0);
  complete_reset: 
  i40e_free_vf_res(vf);
  i40e_alloc_vf_res(vf);
  i40e_enable_vf_mappings(vf);
  set_bit(1L, (unsigned long volatile   *)(& vf->vf_states));
  writel(2U, (void volatile   *)hw->hw_addr + (unsigned long )(((int )vf->vf_id + 119040) * 4));
  readl((void const volatile   *)hw->hw_addr + 745772U);
  clear_bit(25L, (unsigned long volatile   *)(& pf->state));
  return;
}
}
void i40e_free_vfs(struct i40e_pf *pf ) 
{ 
  struct i40e_hw *hw ;
  u32 reg_idx ;
  u32 bit_idx ;
  int i ;
  int tmp ;
  int vf_id ;
    klee_make_symbolic(&vf_id, sizeof(int), "vf_id");
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;

  {
  hw = & pf->hw;
  if ((unsigned long )pf->vf == (unsigned long )((struct i40e_vf *)0)) {
    return;
  } else {

  }
  goto ldv_61200;
  ldv_61199: 
  usleep_range(1000UL, 2000UL);
  ldv_61200: 
  tmp___0 = test_and_set_bit(25L, (unsigned long volatile   *)(& pf->state));
  if (tmp___0 != 0) {
    goto ldv_61199;
  } else {

  }
  i = 0;
  goto ldv_61203;
  ldv_61202: 
  tmp___1 = constant_test_bit(0L, (unsigned long const volatile   *)(& (pf->vf + (unsigned long )i)->vf_states));
  if (tmp___1 != 0) {
    i40e_vsi_control_rings(*(pf->vsi + (unsigned long )(pf->vf + (unsigned long )i)->lan_vsi_idx),
                           0);
  } else {

  }
  i = i + 1;
  ldv_61203: ;
  if (pf->num_alloc_vfs > i) {
    goto ldv_61202;
  } else {

  }
  tmp___2 = pci_vfs_assigned(pf->pdev);
  if (tmp___2 == 0) {
    pci_disable_sriov(pf->pdev);
  } else {
    dev_warn((struct device  const  *)(& (pf->pdev)->dev), "VFs are assigned - not disabling SR-IOV\n");
  }
  msleep(20U);
  tmp = pf->num_alloc_vfs;
  pf->num_alloc_vfs = 0;
  i = 0;
  goto ldv_61206;
  ldv_61205: 
  tmp___3 = constant_test_bit(0L, (unsigned long const volatile   *)(& (pf->vf + (unsigned long )i)->vf_states));
  if (tmp___3 != 0) {
    i40e_free_vf_res(pf->vf + (unsigned long )i);
  } else {

  }
  i40e_disable_vf_mappings(pf->vf + (unsigned long )i);
  i = i + 1;
  ldv_61206: ;
  if (i < tmp) {
    goto ldv_61205;
  } else {

  }
  kfree((void const   *)pf->vf);
  pf->vf = (struct i40e_vf *)0;
  tmp___4 = pci_vfs_assigned(pf->pdev);
  if (tmp___4 == 0) {
    vf_id = 0;
    goto ldv_61209;
    ldv_61208: 
    reg_idx = (hw->func_caps.vf_base_id + (u32 )vf_id) / 32U;
    bit_idx = (hw->func_caps.vf_base_id + (u32 )vf_id) & 31U;
    writel((unsigned int )(1 << (int )bit_idx), (void volatile   *)hw->hw_addr + (unsigned long )((reg_idx + 149888U) * 4U));
    vf_id = vf_id + 1;
    ldv_61209: ;
    if (vf_id < tmp) {
      goto ldv_61208;
    } else {

    }

  } else {

  }
  clear_bit(25L, (unsigned long volatile   *)(& pf->state));
  return;
}
}
int i40e_alloc_vfs(struct i40e_pf *pf , u16 num_alloc_vfs ) 
{ 
  struct i40e_vf *vfs ;
  int i ;
  int ret ;
  int tmp ;
  void *tmp___0 ;

  {
  ret = 0;
  i40e_irq_dynamic_disable_icr0(pf);
  tmp = pci_num_vf(pf->pdev);
  if (tmp != (int )num_alloc_vfs) {
    ret = pci_enable_sriov(pf->pdev, (int )num_alloc_vfs);
    if (ret != 0) {
      dev_err((struct device  const  *)(& (pf->pdev)->dev), "Failed to enable SR-IOV, error %d.\n",
              ret);
      pf->num_alloc_vfs = 0;
      goto err_iov;
    } else {

    }
  } else {

  }
  tmp___0 = kcalloc((size_t )num_alloc_vfs, 88UL, 208U);
  vfs = (struct i40e_vf *)tmp___0;
  if ((unsigned long )vfs == (unsigned long )((struct i40e_vf *)0)) {
    ret = -12;
    goto err_alloc;
  } else {

  }
  pf->vf = vfs;
  i = 0;
  goto ldv_61221;
  ldv_61220: 
  (vfs + (unsigned long )i)->pf = pf;
  (vfs + (unsigned long )i)->parent_type = 17;
  (vfs + (unsigned long )i)->vf_id = (u16 )i;
  set_bit(1L, (unsigned long volatile   *)(& (vfs + (unsigned long )i)->vf_caps));
  (vfs + (unsigned long )i)->spoofchk = 1;
  i40e_reset_vf(vfs + (unsigned long )i, 0);
  i40e_enable_vf_mappings(vfs + (unsigned long )i);
  i = i + 1;
  ldv_61221: ;
  if ((int )num_alloc_vfs > i) {
    goto ldv_61220;
  } else {

  }
  pf->num_alloc_vfs = (int )num_alloc_vfs;
  err_alloc: ;
  if (ret != 0) {
    i40e_free_vfs(pf);
  } else {

  }
  err_iov: 
  i40e_irq_dynamic_enable_icr0(pf);
  return (ret);
}
}
static int i40e_pci_sriov_enable(struct pci_dev *pdev , int num_vfs ) 
{ 
  struct i40e_pf *pf ;
  void *tmp ;
  int pre_existing_vfs ;
    klee_make_symbolic(&pre_existing_vfs, sizeof(int), "pre_existing_vfs");
  int tmp___0 ;
  int err ;

  {
  tmp = pci_get_drvdata(pdev);
  pf = (struct i40e_pf *)tmp;
  tmp___0 = pci_num_vf(pdev);
  pre_existing_vfs = tmp___0;
  err = 0;
  _dev_info((struct device  const  *)(& pdev->dev), "Allocating %d VFs.\n", num_vfs);
  if (pre_existing_vfs != 0 && pre_existing_vfs != num_vfs) {
    i40e_free_vfs(pf);
  } else
  if (pre_existing_vfs != 0 && pre_existing_vfs == num_vfs) {
    goto out;
  } else {

  }
  if ((int )pf->num_req_vfs < num_vfs) {
    err = -1;
    goto err_out;
  } else {

  }
  err = i40e_alloc_vfs(pf, (int )((u16 )num_vfs));
  if (err != 0) {
    dev_warn((struct device  const  *)(& pdev->dev), "Failed to enable SR-IOV: %d\n",
             err);
    goto err_out;
  } else {

  }
  out: ;
  return (num_vfs);
  err_out: ;
  return (err);
  return (0);
}
}
int i40e_pci_sriov_configure(struct pci_dev *pdev , int num_vfs ) 
{ 
  struct i40e_pf *pf ;
  void *tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
  tmp = pci_get_drvdata(pdev);
  pf = (struct i40e_pf *)tmp;
  if (num_vfs != 0) {
    if ((pf->flags & 1099511627776ULL) == 0ULL) {
      pf->flags = pf->flags | 1099511627776ULL;
      i40e_do_reset_safe(pf, 4096U);
    } else {

    }
    tmp___0 = i40e_pci_sriov_enable(pdev, num_vfs);
    return (tmp___0);
  } else {

  }
  tmp___1 = pci_vfs_assigned(pf->pdev);
  if (tmp___1 == 0) {
    i40e_free_vfs(pf);
    pf->flags = pf->flags & 0xfffffeffffffffffULL;
    i40e_do_reset_safe(pf, 4096U);
  } else {
    dev_warn((struct device  const  *)(& pdev->dev), "Unable to free VFs because some are assigned to VMs.\n");
    return (-22);
  }
  return (0);
}
}
static int i40e_vc_send_msg_to_vf(struct i40e_vf *vf , u32 v_opcode , u32 v_retval ,
                                  u8 *msg , u16 msglen ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  int abs_vf_id ;
  i40e_status aq_ret ;

  {
  if ((unsigned long )vf == (unsigned long )((struct i40e_vf *)0) || (int )vf->vf_id >= (vf->pf)->num_alloc_vfs) {
    return (-22);
  } else {

  }
  pf = vf->pf;
  hw = & pf->hw;
  abs_vf_id = (int )((u32 )vf->vf_id + hw->func_caps.vf_base_id);
  if (v_retval != 0U) {
    vf->num_invalid_msgs = vf->num_invalid_msgs + 1ULL;
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Failed opcode %d Error: %d\n",
            v_opcode, v_retval);
    if (vf->num_invalid_msgs > 10ULL) {
      dev_err((struct device  const  *)(& (pf->pdev)->dev), "Number of invalid messages exceeded for VF %d\n",
              (int )vf->vf_id);
      dev_err((struct device  const  *)(& (pf->pdev)->dev), "Use PF Control I/F to enable the VF\n");
      set_bit(3L, (unsigned long volatile   *)(& vf->vf_states));
    } else {

    }
  } else {
    vf->num_valid_msgs = vf->num_valid_msgs + 1ULL;
  }
  aq_ret = i40e_aq_send_msg_to_vf(hw, (int )((u16 )abs_vf_id), v_opcode, v_retval,
                                  msg, (int )msglen, (struct i40e_asq_cmd_details *)0);
  if ((int )aq_ret != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Unable to send the message to VF %d aq_err %d\n",
            (int )vf->vf_id, (unsigned int )pf->hw.aq.asq_last_status);
    return (-5);
  } else {

  }
  return (0);
}
}
static int i40e_vc_send_resp_to_vf(struct i40e_vf *vf , enum i40e_virtchnl_ops opcode ,
                                   i40e_status retval ) 
{ 
  int tmp ;

  {
  tmp = i40e_vc_send_msg_to_vf(vf, (u32 )opcode, (u32 )retval, (u8 *)0U, 0);
  return (tmp);
}
}
static int i40e_vc_get_version_msg(struct i40e_vf *vf ) 
{ 
  struct i40e_virtchnl_version_info info ;
  int tmp ;

  {
  info.major = 1U;
  info.minor = 0U;
  tmp = i40e_vc_send_msg_to_vf(vf, 1U, 0U, (u8 *)(& info), 8);
  return (tmp);
}
}
static int i40e_vc_get_vf_resources_msg(struct i40e_vf *vf ) 
{ 
  struct i40e_virtchnl_vf_resource *vfres ;
  struct i40e_pf *pf ;
  i40e_status aq_ret ;
  struct i40e_vsi *vsi ;
  int i ;
  int len ;
  int num_vsis ;
    klee_make_symbolic(&num_vsis, sizeof(int), "num_vsis");
  int ret ;
  int tmp ;
  void *tmp___0 ;

  {
  vfres = (struct i40e_virtchnl_vf_resource *)0;
  pf = vf->pf;
  aq_ret = 0;
  i = 0;
  len = 0;
  num_vsis = 1;
  tmp = constant_test_bit(0L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp == 0) {
    aq_ret = -5;
    goto err;
  } else {

  }
  len = (int )((unsigned int )((unsigned long )num_vsis) * 16U + 36U);
  tmp___0 = kzalloc((size_t )len, 208U);
  vfres = (struct i40e_virtchnl_vf_resource *)tmp___0;
  if ((unsigned long )vfres == (unsigned long )((struct i40e_virtchnl_vf_resource *)0)) {
    aq_ret = -18;
    len = 0;
    goto err;
  } else {

  }
  vfres->vf_offload_flags = 1U;
  vsi = *(pf->vsi + (unsigned long )vf->lan_vsi_idx);
  if ((unsigned int )vsi->info.pvid == 0U) {
    vfres->vf_offload_flags = vfres->vf_offload_flags | 65536U;
  } else {

  }
  vfres->num_vsis = (u16 )num_vsis;
  vfres->num_queue_pairs = (u16 )vf->num_queue_pairs;
  vfres->max_vectors = (u16 )pf->hw.func_caps.num_msix_vectors_vf;
  if ((unsigned int )vf->lan_vsi_idx != 0U) {
    vfres->vsi_res[i].vsi_id = (u16 )vf->lan_vsi_id;
    vfres->vsi_res[i].vsi_type = 6;
    vfres->vsi_res[i].num_queue_pairs = (*(pf->vsi + (unsigned long )vf->lan_vsi_idx))->alloc_queue_pairs;
    memcpy((void *)(& vfres->vsi_res[i].default_mac_addr), (void const   *)(& vf->default_lan_addr.addr),
             6UL);
    i = i + 1;
  } else {

  }
  set_bit(1L, (unsigned long volatile   *)(& vf->vf_states));
  err: 
  ret = i40e_vc_send_msg_to_vf(vf, 3U, (u32 )aq_ret, (u8 *)vfres, (int )((u16 )len));
  kfree((void const   *)vfres);
  return (ret);
}
}
static void i40e_vc_reset_vf_msg(struct i40e_vf *vf ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp != 0) {
    i40e_reset_vf(vf, 0);
  } else {

  }
  return;
}
}
static int i40e_vc_config_promiscuous_mode_msg(struct i40e_vf *vf , u8 *msg , u16 msglen ) 
{ 
  struct i40e_virtchnl_promisc_info *info ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  struct i40e_vsi *vsi ;
  bool allmulti ;
  i40e_status aq_ret ;
  int tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
  info = (struct i40e_virtchnl_promisc_info *)msg;
  pf = vf->pf;
  hw = & pf->hw;
  allmulti = 0;
  vsi = i40e_find_vsi_from_id(pf, (int )info->vsi_id);
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp == 0) {
    aq_ret = -5;
    goto error_param;
  } else {
    tmp___0 = constant_test_bit(0L, (unsigned long const volatile   *)(& vf->vf_caps));
    if (tmp___0 == 0) {
      aq_ret = -5;
      goto error_param;
    } else {
      tmp___1 = i40e_vc_isvalid_vsi_id(vf, (int )info->vsi_id);
      if (tmp___1) {
        tmp___2 = 0;
      } else {
        tmp___2 = 1;
      }
      if (tmp___2) {
        aq_ret = -5;
        goto error_param;
      } else
      if ((unsigned int )vsi->type != 4U) {
        aq_ret = -5;
        goto error_param;
      } else {

      }
    }
  }
  if (((int )info->flags & 2) != 0) {
    allmulti = 1;
  } else {

  }
  aq_ret = i40e_aq_set_vsi_multicast_promiscuous(hw, (int )vsi->seid, (int )allmulti,
                                                 (struct i40e_asq_cmd_details *)0);
  error_param: 
  tmp___3 = i40e_vc_send_resp_to_vf(vf, 14, aq_ret);
  return (tmp___3);
}
}
static int i40e_vc_config_queues_msg(struct i40e_vf *vf , u8 *msg , u16 msglen ) 
{ 
  struct i40e_virtchnl_vsi_queue_config_info *qci ;
  struct i40e_virtchnl_queue_pair_info *qpi ;
  struct i40e_pf *pf ;
  u16 vsi_id ;
  u16 vsi_queue_id ;
  i40e_status aq_ret ;
  int i ;
  int tmp ;
  bool tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;

  {
  qci = (struct i40e_virtchnl_vsi_queue_config_info *)msg;
  pf = vf->pf;
  aq_ret = 0;
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp == 0) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  vsi_id = qci->vsi_id;
  tmp___0 = i40e_vc_isvalid_vsi_id(vf, (int )vsi_id);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  i = 0;
  goto ldv_61298;
  ldv_61297: 
  qpi = (struct i40e_virtchnl_queue_pair_info *)(& qci->qpair) + (unsigned long )i;
  vsi_queue_id = qpi->txq.queue_id;
  if (((int )qpi->txq.vsi_id != (int )vsi_id || (int )qpi->rxq.vsi_id != (int )vsi_id) || (int )qpi->rxq.queue_id != (int )vsi_queue_id) {
    aq_ret = -5;
    goto error_param;
  } else {
    tmp___2 = i40e_vc_isvalid_queue_id(vf, (int )vsi_id, (int )((u8 )vsi_queue_id));
    if (tmp___2) {
      tmp___3 = 0;
    } else {
      tmp___3 = 1;
    }
    if (tmp___3) {
      aq_ret = -5;
      goto error_param;
    } else {

    }
  }
  tmp___4 = i40e_config_vsi_rx_queue(vf, (int )vsi_id, (int )vsi_queue_id, & qpi->rxq);
  if (tmp___4 != 0) {
    aq_ret = -5;
    goto error_param;
  } else {
    tmp___5 = i40e_config_vsi_tx_queue(vf, (int )vsi_id, (int )vsi_queue_id, & qpi->txq);
    if (tmp___5 != 0) {
      aq_ret = -5;
      goto error_param;
    } else {

    }
  }
  i = i + 1;
  ldv_61298: ;
  if ((int )qci->num_queue_pairs > i) {
    goto ldv_61297;
  } else {

  }
  (*(pf->vsi + (unsigned long )vf->lan_vsi_idx))->num_queue_pairs = qci->num_queue_pairs;
  error_param: 
  tmp___6 = i40e_vc_send_resp_to_vf(vf, 6, aq_ret);
  return (tmp___6);
}
}
static int i40e_vc_config_irq_map_msg(struct i40e_vf *vf , u8 *msg , u16 msglen ) 
{ 
  struct i40e_virtchnl_irq_map_info *irqmap_info ;
  struct i40e_virtchnl_vector_map *map ;
  u16 vsi_id ;
  u16 vsi_queue_id ;
  u16 vector_id ;
  i40e_status aq_ret ;
  unsigned long tempmap ;
  int i ;
  int tmp ;
  bool tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  unsigned long tmp___4 ;
  bool tmp___5 ;
  int tmp___6 ;
  unsigned long tmp___7 ;
  unsigned long tmp___8 ;
  bool tmp___9 ;
  int tmp___10 ;
  unsigned long tmp___11 ;
  int tmp___12 ;

  {
  irqmap_info = (struct i40e_virtchnl_irq_map_info *)msg;
  aq_ret = 0;
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp == 0) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  i = 0;
  goto ldv_61321;
  ldv_61320: 
  map = (struct i40e_virtchnl_vector_map *)(& irqmap_info->vecmap) + (unsigned long )i;
  vector_id = map->vector_id;
  vsi_id = map->vsi_id;
  tmp___0 = i40e_vc_isvalid_vector_id(vf, (int )((u8 )vector_id));
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    aq_ret = -5;
    goto error_param;
  } else {
    tmp___2 = i40e_vc_isvalid_vsi_id(vf, (int )vsi_id);
    if (tmp___2) {
      tmp___3 = 0;
    } else {
      tmp___3 = 1;
    }
    if (tmp___3) {
      aq_ret = -5;
      goto error_param;
    } else {

    }
  }
  tempmap = (unsigned long )map->rxq_map;
  tmp___4 = find_first_bit((unsigned long const   *)(& tempmap), 16UL);
  vsi_queue_id = (u16 )tmp___4;
  goto ldv_61315;
  ldv_61314: 
  tmp___5 = i40e_vc_isvalid_queue_id(vf, (int )vsi_id, (int )((u8 )vsi_queue_id));
  if (tmp___5) {
    tmp___6 = 0;
  } else {
    tmp___6 = 1;
  }
  if (tmp___6) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  tmp___7 = find_next_bit((unsigned long const   *)(& tempmap), 16UL, (unsigned long )((int )vsi_queue_id + 1));
  vsi_queue_id = (u16 )tmp___7;
  ldv_61315: ;
  if ((unsigned int )vsi_queue_id <= 15U) {
    goto ldv_61314;
  } else {

  }
  tempmap = (unsigned long )map->txq_map;
  tmp___8 = find_first_bit((unsigned long const   *)(& tempmap), 16UL);
  vsi_queue_id = (u16 )tmp___8;
  goto ldv_61318;
  ldv_61317: 
  tmp___9 = i40e_vc_isvalid_queue_id(vf, (int )vsi_id, (int )((u8 )vsi_queue_id));
  if (tmp___9) {
    tmp___10 = 0;
  } else {
    tmp___10 = 1;
  }
  if (tmp___10) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  tmp___11 = find_next_bit((unsigned long const   *)(& tempmap), 16UL, (unsigned long )((int )vsi_queue_id + 1));
  vsi_queue_id = (u16 )tmp___11;
  ldv_61318: ;
  if ((unsigned int )vsi_queue_id <= 15U) {
    goto ldv_61317;
  } else {

  }
  i40e_config_irq_link_list(vf, (int )vsi_id, map);
  i = i + 1;
  ldv_61321: ;
  if ((int )irqmap_info->num_vectors > i) {
    goto ldv_61320;
  } else {

  }

  error_param: 
  tmp___12 = i40e_vc_send_resp_to_vf(vf, 7, aq_ret);
  return (tmp___12);
}
}
static int i40e_vc_enable_queues_msg(struct i40e_vf *vf , u8 *msg , u16 msglen ) 
{ 
  struct i40e_virtchnl_queue_select *vqs ;
  struct i40e_pf *pf ;
  u16 vsi_id ;
  i40e_status aq_ret ;
  int tmp ;
  bool tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
  vqs = (struct i40e_virtchnl_queue_select *)msg;
  pf = vf->pf;
  vsi_id = vqs->vsi_id;
  aq_ret = 0;
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp == 0) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  tmp___0 = i40e_vc_isvalid_vsi_id(vf, (int )vsi_id);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  if (vqs->rx_queues == 0U && vqs->tx_queues == 0U) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  tmp___2 = i40e_vsi_control_rings(*(pf->vsi + (unsigned long )vf->lan_vsi_idx), 1);
  if (tmp___2 != 0) {
    aq_ret = -37;
  } else {

  }
  error_param: 
  tmp___3 = i40e_vc_send_resp_to_vf(vf, 8, aq_ret);
  return (tmp___3);
}
}
static int i40e_vc_disable_queues_msg(struct i40e_vf *vf , u8 *msg , u16 msglen ) 
{ 
  struct i40e_virtchnl_queue_select *vqs ;
  struct i40e_pf *pf ;
  i40e_status aq_ret ;
  int tmp ;
  bool tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
  vqs = (struct i40e_virtchnl_queue_select *)msg;
  pf = vf->pf;
  aq_ret = 0;
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp == 0) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  tmp___0 = i40e_vc_isvalid_vsi_id(vf, (int )vqs->vsi_id);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  if (vqs->rx_queues == 0U && vqs->tx_queues == 0U) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  tmp___2 = i40e_vsi_control_rings(*(pf->vsi + (unsigned long )vf->lan_vsi_idx), 0);
  if (tmp___2 != 0) {
    aq_ret = -37;
  } else {

  }
  error_param: 
  tmp___3 = i40e_vc_send_resp_to_vf(vf, 9, aq_ret);
  return (tmp___3);
}
}
static int i40e_vc_get_stats_msg(struct i40e_vf *vf , u8 *msg , u16 msglen ) 
{ 
  struct i40e_virtchnl_queue_select *vqs ;
  struct i40e_pf *pf ;
  struct i40e_eth_stats stats ;
  i40e_status aq_ret ;
  struct i40e_vsi *vsi ;
  int tmp ;
  bool tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
  vqs = (struct i40e_virtchnl_queue_select *)msg;
  pf = vf->pf;
  aq_ret = 0;
  memset((void *)(& stats), 0, 96UL);
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp == 0) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  tmp___0 = i40e_vc_isvalid_vsi_id(vf, (int )vqs->vsi_id);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  vsi = *(pf->vsi + (unsigned long )vf->lan_vsi_idx);
  if ((unsigned long )vsi == (unsigned long )((struct i40e_vsi *)0)) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  i40e_update_eth_stats(vsi);
  stats = vsi->eth_stats;
  error_param: 
  tmp___2 = i40e_vc_send_msg_to_vf(vf, 15U, (u32 )aq_ret, (u8 *)(& stats), 96);
  return (tmp___2);
}
}
__inline static int i40e_check_vf_permission(struct i40e_vf *vf , u8 *macaddr ) 
{ 
  struct i40e_pf *pf ;
  int ret ;
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  bool tmp___3 ;
  bool tmp___4 ;

  {
  pf = vf->pf;
  ret = 0;
  tmp___3 = is_broadcast_ether_addr((u8 const   *)macaddr);
  if ((int )tmp___3) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "invalid VF MAC addr %pM\n",
            macaddr);
    ret = -10;
  } else {
    tmp___4 = is_zero_ether_addr((u8 const   *)macaddr);
    if ((int )tmp___4) {
      dev_err((struct device  const  *)(& (pf->pdev)->dev), "invalid VF MAC addr %pM\n",
              macaddr);
      ret = -10;
    } else
    if ((int )vf->pf_set_mac) {
      tmp = is_multicast_ether_addr((u8 const   *)macaddr);
      if (tmp) {
        tmp___0 = 0;
      } else {
        tmp___0 = 1;
      }
      if (tmp___0) {
        tmp___1 = ether_addr_equal((u8 const   *)macaddr, (u8 const   *)(& vf->default_lan_addr.addr));
        if (tmp___1) {
          tmp___2 = 0;
        } else {
          tmp___2 = 1;
        }
        if (tmp___2) {
          dev_err((struct device  const  *)(& (pf->pdev)->dev), "VF attempting to override administratively set MAC address\nPlease reload the VF driver to resume normal operation\n");
          ret = -1;
        } else {

        }
      } else {

      }
    } else {

    }
  }
  return (ret);
}
}
static int i40e_vc_add_mac_addr_msg(struct i40e_vf *vf , u8 *msg , u16 msglen ) 
{ 
  struct i40e_virtchnl_ether_addr_list *al ;
  struct i40e_pf *pf ;
  struct i40e_vsi *vsi ;
  u16 vsi_id ;
  i40e_status ret ;
  int i ;
  int tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  struct i40e_mac_filter *f ;
  bool tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;

  {
  al = (struct i40e_virtchnl_ether_addr_list *)msg;
  pf = vf->pf;
  vsi = (struct i40e_vsi *)0;
  vsi_id = al->vsi_id;
  ret = 0;
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp == 0) {
    ret = -5;
    goto error_param;
  } else {
    tmp___0 = constant_test_bit(0L, (unsigned long const volatile   *)(& vf->vf_caps));
    if (tmp___0 == 0) {
      ret = -5;
      goto error_param;
    } else {
      tmp___1 = i40e_vc_isvalid_vsi_id(vf, (int )vsi_id);
      if (tmp___1) {
        tmp___2 = 0;
      } else {
        tmp___2 = 1;
      }
      if (tmp___2) {
        ret = -5;
        goto error_param;
      } else {

      }
    }
  }
  i = 0;
  goto ldv_61372;
  ldv_61371: 
  tmp___3 = i40e_check_vf_permission(vf, (u8 *)(& al->list[i].addr));
  ret = (i40e_status )tmp___3;
  if ((int )ret != 0) {
    goto error_param;
  } else {

  }
  i = i + 1;
  ldv_61372: ;
  if ((int )al->num_elements > i) {
    goto ldv_61371;
  } else {

  }
  vsi = *(pf->vsi + (unsigned long )vf->lan_vsi_idx);
  i = 0;
  goto ldv_61376;
  ldv_61375: 
  f = i40e_find_mac(vsi, (u8 *)(& al->list[i].addr), 1, 0);
  if ((unsigned long )f == (unsigned long )((struct i40e_mac_filter *)0)) {
    tmp___4 = i40e_is_vsi_in_vlan(vsi);
    if ((int )tmp___4) {
      f = i40e_put_mac_in_vlan(vsi, (u8 *)(& al->list[i].addr), 1, 0);
    } else {
      f = i40e_add_filter(vsi, (u8 *)(& al->list[i].addr), -1, 1, 0);
    }
  } else {

  }
  if ((unsigned long )f == (unsigned long )((struct i40e_mac_filter *)0)) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Unable to add VF MAC filter\n");
    ret = -5;
    goto error_param;
  } else {

  }
  i = i + 1;
  ldv_61376: ;
  if ((int )al->num_elements > i) {
    goto ldv_61375;
  } else {

  }
  tmp___5 = i40e_sync_vsi_filters(vsi);
  if (tmp___5 != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Unable to program VF MAC filters\n");
  } else {

  }
  error_param: 
  tmp___6 = i40e_vc_send_resp_to_vf(vf, 10, ret);
  return (tmp___6);
}
}
static int i40e_vc_del_mac_addr_msg(struct i40e_vf *vf , u8 *msg , u16 msglen ) 
{ 
  struct i40e_virtchnl_ether_addr_list *al ;
  struct i40e_pf *pf ;
  struct i40e_vsi *vsi ;
  u16 vsi_id ;
  i40e_status ret ;
  int i ;
  int tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  bool tmp___3 ;
  bool tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;

  {
  al = (struct i40e_virtchnl_ether_addr_list *)msg;
  pf = vf->pf;
  vsi = (struct i40e_vsi *)0;
  vsi_id = al->vsi_id;
  ret = 0;
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp == 0) {
    ret = -5;
    goto error_param;
  } else {
    tmp___0 = constant_test_bit(0L, (unsigned long const volatile   *)(& vf->vf_caps));
    if (tmp___0 == 0) {
      ret = -5;
      goto error_param;
    } else {
      tmp___1 = i40e_vc_isvalid_vsi_id(vf, (int )vsi_id);
      if (tmp___1) {
        tmp___2 = 0;
      } else {
        tmp___2 = 1;
      }
      if (tmp___2) {
        ret = -5;
        goto error_param;
      } else {

      }
    }
  }
  i = 0;
  goto ldv_61391;
  ldv_61390: 
  tmp___3 = is_broadcast_ether_addr((u8 const   *)(& al->list[i].addr));
  if ((int )tmp___3) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "invalid VF MAC addr %pM\n",
            (u8 *)(& al->list[i].addr));
    ret = -10;
    goto error_param;
  } else {
    tmp___4 = is_zero_ether_addr((u8 const   *)(& al->list[i].addr));
    if ((int )tmp___4) {
      dev_err((struct device  const  *)(& (pf->pdev)->dev), "invalid VF MAC addr %pM\n",
              (u8 *)(& al->list[i].addr));
      ret = -10;
      goto error_param;
    } else {

    }
  }
  i = i + 1;
  ldv_61391: ;
  if ((int )al->num_elements > i) {
    goto ldv_61390;
  } else {

  }
  vsi = *(pf->vsi + (unsigned long )vf->lan_vsi_idx);
  i = 0;
  goto ldv_61394;
  ldv_61393: 
  i40e_del_filter(vsi, (u8 *)(& al->list[i].addr), -1, 1, 0);
  i = i + 1;
  ldv_61394: ;
  if ((int )al->num_elements > i) {
    goto ldv_61393;
  } else {

  }
  tmp___5 = i40e_sync_vsi_filters(vsi);
  if (tmp___5 != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Unable to program VF MAC filters\n");
  } else {

  }
  error_param: 
  tmp___6 = i40e_vc_send_resp_to_vf(vf, 11, ret);
  return (tmp___6);
}
}
static int i40e_vc_add_vlan_msg(struct i40e_vf *vf , u8 *msg , u16 msglen ) 
{ 
  struct i40e_virtchnl_vlan_filter_list *vfl ;
  struct i40e_pf *pf ;
  struct i40e_vsi *vsi ;
  u16 vsi_id ;
  i40e_status aq_ret ;
  int i ;
  int tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int ret ;
  int tmp___3 ;
  int tmp___4 ;

  {
  vfl = (struct i40e_virtchnl_vlan_filter_list *)msg;
  pf = vf->pf;
  vsi = (struct i40e_vsi *)0;
  vsi_id = vfl->vsi_id;
  aq_ret = 0;
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp == 0) {
    aq_ret = -5;
    goto error_param;
  } else {
    tmp___0 = constant_test_bit(0L, (unsigned long const volatile   *)(& vf->vf_caps));
    if (tmp___0 == 0) {
      aq_ret = -5;
      goto error_param;
    } else {
      tmp___1 = i40e_vc_isvalid_vsi_id(vf, (int )vsi_id);
      if (tmp___1) {
        tmp___2 = 0;
      } else {
        tmp___2 = 1;
      }
      if (tmp___2) {
        aq_ret = -5;
        goto error_param;
      } else {

      }
    }
  }
  i = 0;
  goto ldv_61409;
  ldv_61408: ;
  if ((unsigned int )vfl->vlan_id[i] > 4095U) {
    aq_ret = -5;
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "invalid VF VLAN id %d\n",
            (int )vfl->vlan_id[i]);
    goto error_param;
  } else {

  }
  i = i + 1;
  ldv_61409: ;
  if ((int )vfl->num_elements > i) {
    goto ldv_61408;
  } else {

  }
  vsi = *(pf->vsi + (unsigned long )vf->lan_vsi_idx);
  if ((unsigned int )vsi->info.pvid != 0U) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  i40e_vlan_stripping_enable(vsi);
  i = 0;
  goto ldv_61413;
  ldv_61412: 
  tmp___3 = i40e_vsi_add_vlan(vsi, (int )((s16 )vfl->vlan_id[i]));
  ret = tmp___3;
  if (ret != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Unable to add VF vlan filter %d, error %d\n",
            (int )vfl->vlan_id[i], ret);
  } else {

  }
  i = i + 1;
  ldv_61413: ;
  if ((int )vfl->num_elements > i) {
    goto ldv_61412;
  } else {

  }

  error_param: 
  tmp___4 = i40e_vc_send_resp_to_vf(vf, 12, aq_ret);
  return (tmp___4);
}
}
static int i40e_vc_remove_vlan_msg(struct i40e_vf *vf , u8 *msg , u16 msglen ) 
{ 
  struct i40e_virtchnl_vlan_filter_list *vfl ;
  struct i40e_pf *pf ;
  struct i40e_vsi *vsi ;
  u16 vsi_id ;
  i40e_status aq_ret ;
  int i ;
  int tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int ret ;
  int tmp___3 ;
  int tmp___4 ;

  {
  vfl = (struct i40e_virtchnl_vlan_filter_list *)msg;
  pf = vf->pf;
  vsi = (struct i40e_vsi *)0;
  vsi_id = vfl->vsi_id;
  aq_ret = 0;
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp == 0) {
    aq_ret = -5;
    goto error_param;
  } else {
    tmp___0 = constant_test_bit(0L, (unsigned long const volatile   *)(& vf->vf_caps));
    if (tmp___0 == 0) {
      aq_ret = -5;
      goto error_param;
    } else {
      tmp___1 = i40e_vc_isvalid_vsi_id(vf, (int )vsi_id);
      if (tmp___1) {
        tmp___2 = 0;
      } else {
        tmp___2 = 1;
      }
      if (tmp___2) {
        aq_ret = -5;
        goto error_param;
      } else {

      }
    }
  }
  i = 0;
  goto ldv_61428;
  ldv_61427: ;
  if ((unsigned int )vfl->vlan_id[i] > 4095U) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  i = i + 1;
  ldv_61428: ;
  if ((int )vfl->num_elements > i) {
    goto ldv_61427;
  } else {

  }
  vsi = *(pf->vsi + (unsigned long )vf->lan_vsi_idx);
  if ((unsigned int )vsi->info.pvid != 0U) {
    aq_ret = -5;
    goto error_param;
  } else {

  }
  i = 0;
  goto ldv_61432;
  ldv_61431: 
  tmp___3 = i40e_vsi_kill_vlan(vsi, (int )((s16 )vfl->vlan_id[i]));
  ret = tmp___3;
  if (ret != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Unable to delete VF vlan filter %d, error %d\n",
            (int )vfl->vlan_id[i], ret);
  } else {

  }
  i = i + 1;
  ldv_61432: ;
  if ((int )vfl->num_elements > i) {
    goto ldv_61431;
  } else {

  }

  error_param: 
  tmp___4 = i40e_vc_send_resp_to_vf(vf, 13, aq_ret);
  return (tmp___4);
}
}
static int i40e_vc_validate_vf_msg(struct i40e_vf *vf , u32 v_opcode , u32 v_retval ,
                                   u8 *msg , u16 msglen ) 
{ 
  bool err_msg_format ;
  int valid_len ;
    klee_make_symbolic(&valid_len, sizeof(int), "valid_len");
  int tmp ;
  struct i40e_virtchnl_vsi_queue_config_info *vqc ;
  struct i40e_virtchnl_irq_map_info *vimi ;
  struct i40e_virtchnl_ether_addr_list *veal ;
  struct i40e_virtchnl_vlan_filter_list *vfl ;

  {
  err_msg_format = 0;
  tmp = constant_test_bit(3L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp != 0) {
    return (-5);
  } else {

  }
  switch (v_opcode) {
  case 1U: 
  valid_len = 8;
  goto ldv_61444;
  case 2U: ;
  case 3U: 
  valid_len = 0;
  goto ldv_61444;
  case 4U: 
  valid_len = 24;
  goto ldv_61444;
  case 5U: 
  valid_len = 40;
  goto ldv_61444;
  case 6U: 
  valid_len = 72;
  if ((int )msglen >= valid_len) {
    vqc = (struct i40e_virtchnl_vsi_queue_config_info *)msg;
    valid_len = (int )((unsigned int )vqc->num_queue_pairs * 64U + (unsigned int )valid_len);
    if ((unsigned int )vqc->num_queue_pairs == 0U) {
      err_msg_format = 1;
    } else {

    }
  } else {

  }
  goto ldv_61444;
  case 7U: 
  valid_len = 14;
  if ((int )msglen >= valid_len) {
    vimi = (struct i40e_virtchnl_irq_map_info *)msg;
    valid_len = (int )((unsigned int )vimi->num_vectors * 12U + (unsigned int )valid_len);
    if ((unsigned int )vimi->num_vectors == 0U) {
      err_msg_format = 1;
    } else {

    }
  } else {

  }
  goto ldv_61444;
  case 8U: ;
  case 9U: 
  valid_len = 12;
  goto ldv_61444;
  case 10U: ;
  case 11U: 
  valid_len = 12;
  if ((int )msglen >= valid_len) {
    veal = (struct i40e_virtchnl_ether_addr_list *)msg;
    valid_len = (int )((unsigned int )veal->num_elements * 8U + (unsigned int )valid_len);
    if ((unsigned int )veal->num_elements == 0U) {
      err_msg_format = 1;
    } else {

    }
  } else {

  }
  goto ldv_61444;
  case 12U: ;
  case 13U: 
  valid_len = 6;
  if ((int )msglen >= valid_len) {
    vfl = (struct i40e_virtchnl_vlan_filter_list *)msg;
    valid_len = (int )((unsigned int )vfl->num_elements * 2U + (unsigned int )valid_len);
    if ((unsigned int )vfl->num_elements == 0U) {
      err_msg_format = 1;
    } else {

    }
  } else {

  }
  goto ldv_61444;
  case 14U: 
  valid_len = 4;
  goto ldv_61444;
  case 15U: 
  valid_len = 12;
  goto ldv_61444;
  case 17U: ;
  case 0U: ;
  default: ;
  return (-1);
  }
  ldv_61444: ;
  if ((int )msglen != valid_len || (int )err_msg_format) {
    i40e_vc_send_resp_to_vf(vf, (enum i40e_virtchnl_ops )v_opcode, -5);
    return (-22);
  } else {
    return (0);
  }
}
}
int i40e_vc_process_vf_msg(struct i40e_pf *pf , u16 vf_id , u32 v_opcode , u32 v_retval ,
                           u8 *msg , u16 msglen ) 
{ 
  struct i40e_hw *hw ;
  unsigned int local_vf_id ;
    klee_make_symbolic(&local_vf_id, sizeof(int), "local_vf_id");
  struct i40e_vf *vf ;
  int ret ;

  {
  hw = & pf->hw;
  local_vf_id = (u32 )vf_id - hw->func_caps.vf_base_id;
  pf->vf_aq_requests = pf->vf_aq_requests + 1U;
  if ((unsigned int )pf->num_alloc_vfs <= local_vf_id) {
    return (-22);
  } else {

  }
  vf = pf->vf + (unsigned long )local_vf_id;
  ret = i40e_vc_validate_vf_msg(vf, v_opcode, v_retval, msg, (int )msglen);
  if (ret != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Invalid message from VF %d, opcode %d, len %d\n",
            local_vf_id, v_opcode, (int )msglen);
    return (ret);
  } else {

  }
  switch (v_opcode) {
  case 1U: 
  ret = i40e_vc_get_version_msg(vf);
  goto ldv_61479;
  case 3U: 
  ret = i40e_vc_get_vf_resources_msg(vf);
  goto ldv_61479;
  case 2U: 
  i40e_vc_reset_vf_msg(vf);
  ret = 0;
  goto ldv_61479;
  case 14U: 
  ret = i40e_vc_config_promiscuous_mode_msg(vf, msg, (int )msglen);
  goto ldv_61479;
  case 6U: 
  ret = i40e_vc_config_queues_msg(vf, msg, (int )msglen);
  goto ldv_61479;
  case 7U: 
  ret = i40e_vc_config_irq_map_msg(vf, msg, (int )msglen);
  goto ldv_61479;
  case 8U: 
  ret = i40e_vc_enable_queues_msg(vf, msg, (int )msglen);
  i40e_vc_notify_vf_link_state(vf);
  goto ldv_61479;
  case 9U: 
  ret = i40e_vc_disable_queues_msg(vf, msg, (int )msglen);
  goto ldv_61479;
  case 10U: 
  ret = i40e_vc_add_mac_addr_msg(vf, msg, (int )msglen);
  goto ldv_61479;
  case 11U: 
  ret = i40e_vc_del_mac_addr_msg(vf, msg, (int )msglen);
  goto ldv_61479;
  case 12U: 
  ret = i40e_vc_add_vlan_msg(vf, msg, (int )msglen);
  goto ldv_61479;
  case 13U: 
  ret = i40e_vc_remove_vlan_msg(vf, msg, (int )msglen);
  goto ldv_61479;
  case 15U: 
  ret = i40e_vc_get_stats_msg(vf, msg, (int )msglen);
  goto ldv_61479;
  case 0U: ;
  default: 
  dev_err((struct device  const  *)(& (pf->pdev)->dev), "Unsupported opcode %d from VF %d\n",
          v_opcode, local_vf_id);
  ret = i40e_vc_send_resp_to_vf(vf, (enum i40e_virtchnl_ops )v_opcode, -60);
  goto ldv_61479;
  }
  ldv_61479: ;
  return (ret);
}
}
int i40e_vc_process_vflr_event(struct i40e_pf *pf ) 
{ 
  u32 reg ;
  u32 reg_idx ;
  u32 bit_idx ;
  u32 vf_id ;
  struct i40e_hw *hw ;
  struct i40e_vf *vf ;
  int tmp ;
  int tmp___0 ;

  {
  hw = & pf->hw;
  tmp = constant_test_bit(8L, (unsigned long const volatile   *)(& pf->state));
  if (tmp == 0) {
    return (0);
  } else {

  }
  reg = readl((void const volatile   *)hw->hw_addr + 231424U);
  reg = reg | 536870912U;
  writel(reg, (void volatile   *)hw->hw_addr + 231424U);
  readl((void const volatile   *)hw->hw_addr + 745772U);
  clear_bit(8L, (unsigned long volatile   *)(& pf->state));
  vf_id = 0U;
  goto ldv_61504;
  ldv_61503: 
  reg_idx = (hw->func_caps.vf_base_id + vf_id) / 32U;
  bit_idx = (hw->func_caps.vf_base_id + vf_id) & 31U;
  vf = pf->vf + (unsigned long )vf_id;
  reg = readl((void const volatile   *)hw->hw_addr + (unsigned long )((reg_idx + 149888U) * 4U));
  if (((u32 )(1 << (int )bit_idx) & reg) != 0U) {
    writel((unsigned int )(1 << (int )bit_idx), (void volatile   *)hw->hw_addr + (unsigned long )((reg_idx + 149888U) * 4U));
    tmp___0 = constant_test_bit(3L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___0 == 0) {
      i40e_reset_vf(vf, 1);
    } else {

    }
  } else {

  }
  vf_id = vf_id + 1U;
  ldv_61504: ;
  if ((u32 )pf->num_alloc_vfs > vf_id) {
    goto ldv_61503;
  } else {

  }

  return (0);
}
}
int i40e_ndo_set_vf_mac(struct net_device *netdev , int vf_id , u8 *mac ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  struct i40e_mac_filter *f ;
  struct i40e_vf *vf ;
  int ret ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  int tmp___3 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  ret = 0;
  if (pf->num_alloc_vfs <= vf_id) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Invalid VF Identifier %d\n",
            vf_id);
    ret = -22;
    goto error_param;
  } else {

  }
  vf = pf->vf + (unsigned long )vf_id;
  vsi = *(pf->vsi + (unsigned long )vf->lan_vsi_idx);
  tmp___0 = constant_test_bit(0L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp___0 == 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Uninitialized VF %d\n",
            vf_id);
    ret = -22;
    goto error_param;
  } else {

  }
  tmp___1 = is_valid_ether_addr((u8 const   *)mac);
  if (tmp___1) {
    tmp___2 = 0;
  } else {
    tmp___2 = 1;
  }
  if (tmp___2) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Invalid VF ethernet address\n");
    ret = -22;
    goto error_param;
  } else {

  }
  i40e_del_filter(vsi, (u8 *)(& vf->default_lan_addr.addr), (int )((s16 )vf->port_vlan_id),
                  1, 0);
  __mptr = (struct list_head  const  *)vsi->mac_filter_list.next;
  f = (struct i40e_mac_filter *)__mptr;
  goto ldv_61523;
  ldv_61522: 
  i40e_del_filter(vsi, (u8 *)(& f->macaddr), (int )f->vlan, 1, 0);
  __mptr___0 = (struct list_head  const  *)f->list.next;
  f = (struct i40e_mac_filter *)__mptr___0;
  ldv_61523: ;
  if ((unsigned long )(& f->list) != (unsigned long )(& vsi->mac_filter_list)) {
    goto ldv_61522;
  } else {

  }
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Setting MAC %pM on VF %d\n",
            mac, vf_id);
  tmp___3 = i40e_sync_vsi_filters(vsi);
  if (tmp___3 != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Unable to program ucast filters\n");
    ret = -5;
    goto error_param;
  } else {

  }
  ether_addr_copy((u8 *)(& vf->default_lan_addr.addr), (u8 const   *)mac);
  vf->pf_set_mac = 1;
  i40e_vc_disable_vf(pf, vf);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Reload the VF driver to make this change effective.\n");
  error_param: ;
  return (ret);
}
}
int i40e_ndo_set_vf_port_vlan(struct net_device *netdev , int vf_id , u16 vlan_id ,
                              u8 qos ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  struct i40e_vsi *vsi ;
  struct i40e_vf *vf ;
  int ret ;
  int tmp___0 ;
  bool tmp___1 ;
  i40e_status tmp___2 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  ret = 0;
  if (pf->num_alloc_vfs <= vf_id) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Invalid VF Identifier %d\n",
            vf_id);
    ret = -22;
    goto error_pvid;
  } else {

  }
  if ((unsigned int )vlan_id > 4095U || (unsigned int )qos > 7U) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Invalid VF Parameters\n");
    ret = -22;
    goto error_pvid;
  } else {

  }
  vf = pf->vf + (unsigned long )vf_id;
  vsi = *(pf->vsi + (unsigned long )vf->lan_vsi_idx);
  tmp___0 = constant_test_bit(0L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp___0 == 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Uninitialized VF %d\n",
            vf_id);
    ret = -22;
    goto error_pvid;
  } else {

  }
  if ((unsigned int )vsi->info.pvid == 0U) {
    tmp___1 = i40e_is_vsi_in_vlan(vsi);
    if ((int )tmp___1) {
      dev_err((struct device  const  *)(& (pf->pdev)->dev), "VF %d has already configured VLAN filters and the administrator is requesting a port VLAN override.\nPlease unload and reload the VF driver for this change to take effect.\n",
              vf_id);
      i40e_vc_disable_vf(pf, vf);
    } else {

    }
  } else {

  }
  if ((((unsigned int )vlan_id == 0U && (unsigned int )qos == 0U) || ((int )vlan_id | (int )qos) != (int )vsi->info.pvid) && (unsigned int )vsi->info.pvid != 0U) {
    ret = i40e_vsi_add_vlan(vsi, -1);
  } else {

  }
  if ((unsigned int )vsi->info.pvid != 0U) {
    ret = i40e_vsi_kill_vlan(vsi, (int )((s16 )vsi->info.pvid) & 4095);
    if (ret != 0) {
      _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "remove VLAN failed, ret=%d, aq_err=%d\n",
                ret, (unsigned int )pf->hw.aq.asq_last_status);
    } else {

    }
  } else {

  }
  if ((unsigned int )vlan_id != 0U || (unsigned int )qos != 0U) {
    tmp___2 = i40e_vsi_add_pvid(vsi, (int )((u16 )((int )((short )((int )qos << 12)) | (int )((short )vlan_id))));
    ret = (int )tmp___2;
  } else {
    i40e_vsi_remove_pvid(vsi);
  }
  if ((unsigned int )vlan_id != 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Setting VLAN %d, QOS 0x%x on VF %d\n",
              (int )vlan_id, (int )qos, vf_id);
    ret = i40e_vsi_add_vlan(vsi, (int )((s16 )vlan_id));
    if (ret != 0) {
      _dev_info((struct device  const  *)(& ((vsi->back)->pdev)->dev), "add VF VLAN failed, ret=%d aq_err=%d\n",
                ret, (unsigned int )(vsi->back)->hw.aq.asq_last_status);
      goto error_pvid;
    } else {

    }
    i40e_vsi_kill_vlan(vsi, -1);
  } else {

  }
  if (ret != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Unable to update VF vsi context\n");
    goto error_pvid;
  } else {

  }
  vf->port_vlan_id = vsi->info.pvid;
  ret = 0;
  error_pvid: ;
  return (ret);
}
}
int i40e_ndo_set_vf_bw(struct net_device *netdev , int vf_id , int min_tx_rate , int max_tx_rate ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  struct i40e_vsi *vsi ;
  struct i40e_vf *vf ;
  int speed ;
  int ret ;
  int tmp___0 ;
  i40e_status tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  speed = 0;
  ret = 0;
  if (pf->num_alloc_vfs <= vf_id) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Invalid VF Identifier %d.\n",
            vf_id);
    ret = -22;
    goto error;
  } else {

  }
  if (min_tx_rate != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Invalid min tx rate (%d) (greater than 0) specified for VF %d.\n",
            min_tx_rate, vf_id);
    return (-22);
  } else {

  }
  vf = pf->vf + (unsigned long )vf_id;
  vsi = *(pf->vsi + (unsigned long )vf->lan_vsi_idx);
  tmp___0 = constant_test_bit(0L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp___0 == 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Uninitialized VF %d.\n",
            vf_id);
    ret = -22;
    goto error;
  } else {

  }
  switch ((unsigned int )pf->hw.phy.link_info.link_speed) {
  case 16U: 
  speed = 40000;
  goto ldv_61551;
  case 8U: 
  speed = 10000;
  goto ldv_61551;
  case 4U: 
  speed = 1000;
  goto ldv_61551;
  default: ;
  goto ldv_61551;
  }
  ldv_61551: ;
  if (max_tx_rate > speed) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Invalid max tx rate %d specified for VF %d.",
            max_tx_rate, (int )vf->vf_id);
    ret = -22;
    goto error;
  } else {

  }
  if (max_tx_rate <= 49 && max_tx_rate > 0) {
    dev_warn((struct device  const  *)(& (pf->pdev)->dev), "Setting max Tx rate to minimum usable value of 50Mbps.\n");
    max_tx_rate = 50;
  } else {

  }
  tmp___1 = i40e_aq_config_vsi_bw_limit(& pf->hw, (int )vsi->seid, (int )((u16 )(max_tx_rate / 50)),
                                        4, (struct i40e_asq_cmd_details *)0);
  ret = (int )tmp___1;
  if (ret != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Unable to set max tx rate, error code %d.\n",
            ret);
    ret = -5;
    goto error;
  } else {

  }
  vf->tx_rate = (unsigned int )max_tx_rate;
  error: ;
  return (ret);
}
}
int i40e_ndo_get_vf_config(struct net_device *netdev , int vf_id , struct ifla_vf_info *ivi ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  struct i40e_vf *vf ;
  int ret ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  ret = 0;
  if (pf->num_alloc_vfs <= vf_id) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Invalid VF Identifier %d\n",
            vf_id);
    ret = -22;
    goto error_param;
  } else {

  }
  vf = pf->vf + (unsigned long )vf_id;
  vsi = *(pf->vsi + (unsigned long )vf->lan_vsi_idx);
  tmp___0 = constant_test_bit(0L, (unsigned long const volatile   *)(& vf->vf_states));
  if (tmp___0 == 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Uninitialized VF %d\n",
            vf_id);
    ret = -22;
    goto error_param;
  } else {

  }
  ivi->vf = (__u32 )vf_id;
  memcpy((void *)(& ivi->mac), (void const   *)(& vf->default_lan_addr.addr), 6UL);
  ivi->max_tx_rate = vf->tx_rate;
  ivi->min_tx_rate = 0U;
  ivi->vlan = (__u32 )vsi->info.pvid & 4095U;
  ivi->qos = (__u32 )(((int )vsi->info.pvid & 28672) >> 12);
  if (! vf->link_forced) {
    ivi->linkstate = 0U;
  } else
  if ((int )vf->link_up) {
    ivi->linkstate = 1U;
  } else {
    ivi->linkstate = 2U;
  }
  ivi->spoofchk = (__u32 )vf->spoofchk;
  ret = 0;
  error_param: ;
  return (ret);
}
}
int i40e_ndo_set_vf_link_state(struct net_device *netdev , int vf_id , int link ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  struct i40e_virtchnl_pf_event pfe ;
  struct i40e_hw *hw ;
  struct i40e_vf *vf ;
  int abs_vf_id ;
  int ret ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  hw = & pf->hw;
  ret = 0;
  if (pf->num_alloc_vfs <= vf_id) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Invalid VF Identifier %d\n",
            vf_id);
    ret = -22;
    goto error_out;
  } else {

  }
  vf = pf->vf + (unsigned long )vf_id;
  abs_vf_id = (int )((u32 )vf->vf_id + hw->func_caps.vf_base_id);
  pfe.event = 1;
  pfe.severity = 0;
  switch (link) {
  case 0: 
  vf->link_forced = 0;
  pfe.event_data.link_event.link_status = ((int )pf->hw.phy.link_info.link_info & 1) != 0;
  pfe.event_data.link_event.link_speed = pf->hw.phy.link_info.link_speed;
  goto ldv_61580;
  case 1: 
  vf->link_forced = 1;
  vf->link_up = 1;
  pfe.event_data.link_event.link_status = 1;
  pfe.event_data.link_event.link_speed = 16;
  goto ldv_61580;
  case 2: 
  vf->link_forced = 1;
  vf->link_up = 0;
  pfe.event_data.link_event.link_status = 0;
  pfe.event_data.link_event.link_speed = 0;
  goto ldv_61580;
  default: 
  ret = -22;
  goto error_out;
  }
  ldv_61580: 
  i40e_aq_send_msg_to_vf(hw, (int )((u16 )abs_vf_id), 17U, 0U, (u8 *)(& pfe), 16,
                         (struct i40e_asq_cmd_details *)0);
  error_out: ;
  return (ret);
}
}
int i40e_ndo_set_vf_spoofchk(struct net_device *netdev , int vf_id , bool enable ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  struct i40e_vsi_context ctxt ;
  struct i40e_hw *hw ;
  struct i40e_vf *vf ;
  int ret ;
  i40e_status tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  hw = & pf->hw;
  ret = 0;
  if (pf->num_alloc_vfs <= vf_id) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Invalid VF Identifier %d\n",
            vf_id);
    ret = -22;
    goto out;
  } else {

  }
  vf = pf->vf + (unsigned long )vf_id;
  if ((int )vf->spoofchk == (int )enable) {
    goto out;
  } else {

  }
  vf->spoofchk = enable;
  memset((void *)(& ctxt), 0, 144UL);
  ctxt.seid = (*(pf->vsi + (unsigned long )vf->lan_vsi_idx))->seid;
  ctxt.pf_num = pf->hw.pf_id;
  ctxt.info.valid_sections = 2U;
  if ((int )enable) {
    ctxt.info.sec_flags = (u8 )((unsigned int )ctxt.info.sec_flags | 6U);
  } else {

  }
  tmp___0 = i40e_aq_update_vsi_params(hw, & ctxt, (struct i40e_asq_cmd_details *)0);
  ret = (int )tmp___0;
  if (ret != 0) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Error %d updating VSI parameters\n",
            ret);
    ret = -5;
  } else {

  }
  out: ;
  return (ret);
}
}
bool ldv_queue_work_on_405(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_406(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_407(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_408(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_409(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_410(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_411(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_412(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_413(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_414(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_415(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_416(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_441(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_439(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_442(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_443(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_438(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_440(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_444(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_433(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_435(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_434(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_437(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_436(struct workqueue_struct *ldv_func_arg1 ) ;
i40e_status i40e_read_lldp_cfg(struct i40e_hw *hw , struct i40e_lldp_variables *lldp_cfg ) ;
i40e_status i40e_get_dcbx_status(struct i40e_hw *hw , u16 *status ) ;
i40e_status i40e_lldp_to_dcb_config(u8 *lldpmib , struct i40e_dcbx_config *dcbcfg ) ;
i40e_status i40e_get_dcbx_status(struct i40e_hw *hw , u16 *status ) 
{ 
  u32 reg ;

  {
  if ((unsigned long )status == (unsigned long )((u16 *)0U)) {
    return (-5);
  } else {

  }
  reg = readl((void const volatile   *)hw->hw_addr + 536608U);
  *status = (unsigned int )((unsigned short )reg) & 7U;
  return (0);
}
}
static void i40e_parse_ieee_etscfg_tlv(struct i40e_lldp_org_tlv *tlv , struct i40e_dcbx_config *dcbcfg ) 
{ 
  struct i40e_dcb_ets_config *etscfg ;
  u8 *buf ;
  u16 offset ;
  u8 priority ;
  int i ;
  u16 tmp ;
  u16 tmp___0 ;

  {
  buf = (u8 *)(& tlv->tlvinfo);
  offset = 0U;
  etscfg = & dcbcfg->etscfg;
  etscfg->willing = (unsigned char )((int )*(buf + (unsigned long )offset) >> 7);
  etscfg->cbs = (unsigned char )(((int )*(buf + (unsigned long )offset) & 64) >> 6);
  etscfg->maxtcs = (unsigned int )*(buf + (unsigned long )offset) & 7U;
  offset = (u16 )((int )offset + 1);
  i = 0;
  goto ldv_52575;
  ldv_52574: 
  priority = (unsigned char )(((int )*(buf + (unsigned long )offset) & 112) >> 4);
  etscfg->prioritytable[i * 2] = priority;
  priority = (unsigned int )*(buf + (unsigned long )offset) & 7U;
  etscfg->prioritytable[i * 2 + 1] = priority;
  offset = (u16 )((int )offset + 1);
  i = i + 1;
  ldv_52575: ;
  if (i <= 3) {
    goto ldv_52574;
  } else {

  }
  i = 0;
  goto ldv_52578;
  ldv_52577: 
  tmp = offset;
  offset = (u16 )((int )offset + 1);
  etscfg->tcbwtable[i] = *(buf + (unsigned long )tmp);
  i = i + 1;
  ldv_52578: ;
  if (i <= 7) {
    goto ldv_52577;
  } else {

  }
  i = 0;
  goto ldv_52581;
  ldv_52580: 
  tmp___0 = offset;
  offset = (u16 )((int )offset + 1);
  etscfg->tsatable[i] = *(buf + (unsigned long )tmp___0);
  i = i + 1;
  ldv_52581: ;
  if (i <= 7) {
    goto ldv_52580;
  } else {

  }

  return;
}
}
static void i40e_parse_ieee_etsrec_tlv(struct i40e_lldp_org_tlv *tlv , struct i40e_dcbx_config *dcbcfg ) 
{ 
  u8 *buf ;
  u16 offset ;
  u8 priority ;
  int i ;
  u16 tmp ;
  u16 tmp___0 ;

  {
  buf = (u8 *)(& tlv->tlvinfo);
  offset = 0U;
  offset = (u16 )((int )offset + 1);
  i = 0;
  goto ldv_52592;
  ldv_52591: 
  priority = (unsigned char )(((int )*(buf + (unsigned long )offset) & 112) >> 4);
  dcbcfg->etsrec.prioritytable[i * 2] = priority;
  priority = (unsigned int )*(buf + (unsigned long )offset) & 7U;
  dcbcfg->etsrec.prioritytable[i * 2 + 1] = priority;
  offset = (u16 )((int )offset + 1);
  i = i + 1;
  ldv_52592: ;
  if (i <= 3) {
    goto ldv_52591;
  } else {

  }
  i = 0;
  goto ldv_52595;
  ldv_52594: 
  tmp = offset;
  offset = (u16 )((int )offset + 1);
  dcbcfg->etsrec.tcbwtable[i] = *(buf + (unsigned long )tmp);
  i = i + 1;
  ldv_52595: ;
  if (i <= 7) {
    goto ldv_52594;
  } else {

  }
  i = 0;
  goto ldv_52598;
  ldv_52597: 
  tmp___0 = offset;
  offset = (u16 )((int )offset + 1);
  dcbcfg->etsrec.tsatable[i] = *(buf + (unsigned long )tmp___0);
  i = i + 1;
  ldv_52598: ;
  if (i <= 7) {
    goto ldv_52597;
  } else {

  }

  return;
}
}
static void i40e_parse_ieee_pfccfg_tlv(struct i40e_lldp_org_tlv *tlv , struct i40e_dcbx_config *dcbcfg ) 
{ 
  u8 *buf ;

  {
  buf = (u8 *)(& tlv->tlvinfo);
  dcbcfg->pfc.willing = (unsigned char )((int )*buf >> 7);
  dcbcfg->pfc.mbc = (unsigned char )(((int )*buf & 64) >> 6);
  dcbcfg->pfc.pfccap = (unsigned int )*buf & 15U;
  dcbcfg->pfc.pfcenable = *(buf + 1UL);
  return;
}
}
static void i40e_parse_ieee_app_tlv(struct i40e_lldp_org_tlv *tlv , struct i40e_dcbx_config *dcbcfg ) 
{ 
  u16 typelength ;
  u16 offset ;
  u16 length ;
  int i ;
  u8 *buf ;
  __u16 tmp ;

  {
  offset = 0U;
  i = 0;
  tmp = __fswab16((int )tlv->typelength);
  typelength = tmp;
  length = (unsigned int )typelength & 511U;
  buf = (u8 *)(& tlv->tlvinfo);
  length = (unsigned int )length - 5U;
  offset = (u16 )((int )offset + 1);
  goto ldv_52616;
  ldv_52615: 
  dcbcfg->app[i].priority = (unsigned char )((int )*(buf + (unsigned long )offset) >> 5);
  dcbcfg->app[i].selector = (unsigned int )*(buf + (unsigned long )offset) & 7U;
  dcbcfg->app[i].protocolid = (u16 )((int )((short )((int )*(buf + ((unsigned long )offset + 1UL)) << 8)) | (int )((short )*(buf + ((unsigned long )offset + 2UL))));
  offset = (unsigned int )offset + 3U;
  i = i + 1;
  if (i > 31) {
    goto ldv_52614;
  } else {

  }
  ldv_52616: ;
  if ((int )offset < (int )length) {
    goto ldv_52615;
  } else {

  }
  ldv_52614: 
  dcbcfg->numapps = (u32 )i;
  return;
}
}
static void i40e_parse_ieee_tlv(struct i40e_lldp_org_tlv *tlv , struct i40e_dcbx_config *dcbcfg ) 
{ 
  u32 ouisubtype ;
  u8 subtype ;
  __u32 tmp ;

  {
  tmp = __fswab32(tlv->ouisubtype);
  ouisubtype = tmp;
  subtype = (unsigned char )ouisubtype;
  switch ((int )subtype) {
  case 9: 
  i40e_parse_ieee_etscfg_tlv(tlv, dcbcfg);
  goto ldv_52624;
  case 10: 
  i40e_parse_ieee_etsrec_tlv(tlv, dcbcfg);
  goto ldv_52624;
  case 11: 
  i40e_parse_ieee_pfccfg_tlv(tlv, dcbcfg);
  goto ldv_52624;
  case 12: 
  i40e_parse_ieee_app_tlv(tlv, dcbcfg);
  goto ldv_52624;
  default: ;
  goto ldv_52624;
  }
  ldv_52624: ;
  return;
}
}
static void i40e_parse_org_tlv(struct i40e_lldp_org_tlv *tlv , struct i40e_dcbx_config *dcbcfg ) 
{ 
  u32 ouisubtype ;
  u32 oui ;
  __u32 tmp ;

  {
  tmp = __fswab32(tlv->ouisubtype);
  ouisubtype = tmp;
  oui = ouisubtype >> 8;
  switch (oui) {
  case 32962U: 
  i40e_parse_ieee_tlv(tlv, dcbcfg);
  goto ldv_52636;
  default: ;
  goto ldv_52636;
  }
  ldv_52636: ;
  return;
}
}
i40e_status i40e_lldp_to_dcb_config(u8 *lldpmib , struct i40e_dcbx_config *dcbcfg ) 
{ 
  i40e_status ret ;
  struct i40e_lldp_org_tlv *tlv ;
  u16 type ;
  u16 length ;
  u16 typelength ;
  u16 offset ;
  __u16 tmp ;

  {
  ret = 0;
  offset = 0U;
  if ((unsigned long )lldpmib == (unsigned long )((u8 *)0U) || (unsigned long )dcbcfg == (unsigned long )((struct i40e_dcbx_config *)0)) {
    return (-5);
  } else {

  }
  lldpmib = lldpmib + 14UL;
  tlv = (struct i40e_lldp_org_tlv *)lldpmib;
  ldv_52652: 
  tmp = __fswab16((int )tlv->typelength);
  typelength = tmp;
  type = (unsigned short )((int )typelength >> 9);
  length = (unsigned int )typelength & 511U;
  offset = (unsigned int )((int )offset + (int )length) + 2U;
  if ((unsigned int )type == 0U || (unsigned int )offset > 1500U) {
    goto ldv_52648;
  } else {

  }
  switch ((int )type) {
  case 127: 
  i40e_parse_org_tlv(tlv, dcbcfg);
  goto ldv_52650;
  default: ;
  goto ldv_52650;
  }
  ldv_52650: 
  tlv = tlv + ((unsigned long )length + 2UL);
  goto ldv_52652;
  ldv_52648: ;
  return (ret);
}
}
i40e_status i40e_aq_get_dcb_config(struct i40e_hw *hw , u8 mib_type , u8 bridgetype ,
                                   struct i40e_dcbx_config *dcbcfg ) 
{ 
  i40e_status ret ;
  struct i40e_virt_mem mem ;
  u8 *lldpmib ;

  {
  ret = 0;
  ret = i40e_allocate_virt_mem_d(hw, & mem, 1500U);
  if ((int )ret != 0) {
    return (ret);
  } else {

  }
  lldpmib = (u8 *)mem.va;
  ret = i40e_aq_get_lldp_mib(hw, (int )bridgetype, (int )mib_type, (void *)lldpmib,
                             1500, (u16 *)0U, (u16 *)0U, (struct i40e_asq_cmd_details *)0);
  if ((int )ret != 0) {
    goto free_mem;
  } else {

  }
  ret = i40e_lldp_to_dcb_config(lldpmib, dcbcfg);
  free_mem: 
  i40e_free_virt_mem_d(hw, & mem);
  return (ret);
}
}
static void i40e_cee_to_dcb_v1_config(struct i40e_aqc_get_cee_dcb_cfg_v1_resp *cee_cfg ,
                                      struct i40e_dcbx_config *dcbcfg ) 
{ 
  u16 status ;
  u16 tlv_status ;
  u16 app_prio ;
  u8 i ;
  u8 tc ;
  u8 err ;

  {
  tlv_status = cee_cfg->tlv_status;
  app_prio = cee_cfg->oper_app_prio;
  dcbcfg->etscfg.maxtcs = cee_cfg->oper_num_tc;
  i = 0U;
  goto ldv_52674;
  ldv_52673: 
  tc = (unsigned char )((int )cee_cfg->oper_prio_tc[(int )i] >> 4);
  dcbcfg->etscfg.prioritytable[(int )i * 2] = tc;
  tc = (unsigned int )cee_cfg->oper_prio_tc[(int )i] & 15U;
  dcbcfg->etscfg.prioritytable[(int )i * 2 + 1] = tc;
  i = (u8 )((int )i + 1);
  ldv_52674: ;
  if ((unsigned int )i <= 3U) {
    goto ldv_52673;
  } else {

  }
  i = 0U;
  goto ldv_52677;
  ldv_52676: 
  dcbcfg->etscfg.tcbwtable[(int )i] = cee_cfg->oper_tc_bw[(int )i];
  i = (u8 )((int )i + 1);
  ldv_52677: ;
  if ((unsigned int )i <= 7U) {
    goto ldv_52676;
  } else {

  }
  i = 0U;
  goto ldv_52680;
  ldv_52679: ;
  if ((unsigned int )dcbcfg->etscfg.prioritytable[(int )i] == 15U) {
    dcbcfg->etscfg.prioritytable[(int )i] = (unsigned int )cee_cfg->oper_num_tc + 255U;
    dcbcfg->etscfg.tsatable[(int )i] = 0U;
  } else {
    dcbcfg->etscfg.tsatable[(int )i] = 2U;
  }
  i = (u8 )((int )i + 1);
  ldv_52680: ;
  if ((unsigned int )i <= 7U) {
    goto ldv_52679;
  } else {

  }
  dcbcfg->pfc.pfcenable = cee_cfg->oper_pfc_en;
  dcbcfg->pfc.pfccap = 8U;
  status = (u16 )(((int )tlv_status & 1792) >> 8);
  err = ((int )status & 4) != 0;
  if ((unsigned int )err == 0U) {
    dcbcfg->numapps = 3U;
    dcbcfg->app[0].priority = (unsigned int )((u8 )app_prio) & 7U;
    dcbcfg->app[0].selector = 1U;
    dcbcfg->app[0].protocolid = 35078U;
    dcbcfg->app[1].priority = (u8 )(((int )app_prio & 56) >> 3);
    dcbcfg->app[1].selector = 2U;
    dcbcfg->app[1].protocolid = 3260U;
    dcbcfg->app[2].priority = (u8 )(((int )app_prio & 1792) >> 8);
    dcbcfg->app[2].selector = 1U;
    dcbcfg->app[2].protocolid = 35092U;
  } else {

  }
  return;
}
}
static void i40e_cee_to_dcb_config(struct i40e_aqc_get_cee_dcb_cfg_resp *cee_cfg ,
                                   struct i40e_dcbx_config *dcbcfg ) 
{ 
  u32 status ;
  u32 tlv_status ;
  u16 app_prio ;
  u8 i ;
  u8 tc ;
  u8 err ;
  u8 sync ;
  u8 oper ;

  {
  tlv_status = cee_cfg->tlv_status;
  app_prio = cee_cfg->oper_app_prio;
  dcbcfg->etscfg.maxtcs = cee_cfg->oper_num_tc;
  i = 0U;
  goto ldv_52695;
  ldv_52694: 
  tc = (unsigned char )((int )cee_cfg->oper_prio_tc[(int )i] >> 4);
  dcbcfg->etscfg.prioritytable[(int )i * 2] = tc;
  tc = (unsigned int )cee_cfg->oper_prio_tc[(int )i] & 15U;
  dcbcfg->etscfg.prioritytable[(int )i * 2 + 1] = tc;
  i = (u8 )((int )i + 1);
  ldv_52695: ;
  if ((unsigned int )i <= 3U) {
    goto ldv_52694;
  } else {

  }
  i = 0U;
  goto ldv_52698;
  ldv_52697: 
  dcbcfg->etscfg.tcbwtable[(int )i] = cee_cfg->oper_tc_bw[(int )i];
  i = (u8 )((int )i + 1);
  ldv_52698: ;
  if ((unsigned int )i <= 7U) {
    goto ldv_52697;
  } else {

  }
  i = 0U;
  goto ldv_52701;
  ldv_52700: ;
  if ((unsigned int )dcbcfg->etscfg.prioritytable[(int )i] == 15U) {
    dcbcfg->etscfg.prioritytable[(int )i] = (unsigned int )cee_cfg->oper_num_tc + 255U;
    dcbcfg->etscfg.tsatable[(int )i] = 0U;
  } else {
    dcbcfg->etscfg.tsatable[(int )i] = 2U;
  }
  i = (u8 )((int )i + 1);
  ldv_52701: ;
  if ((unsigned int )i <= 7U) {
    goto ldv_52700;
  } else {

  }
  dcbcfg->pfc.pfcenable = cee_cfg->oper_pfc_en;
  dcbcfg->pfc.pfccap = 8U;
  status = (tlv_status & 1792U) >> 8;
  err = (status & 4U) != 0U;
  sync = (status & 2U) != 0U;
  oper = (unsigned int )((u8 )status) & 1U;
  if (((unsigned int )err == 0U && (unsigned int )sync != 0U) && (unsigned int )oper != 0U) {
    dcbcfg->numapps = 3U;
    dcbcfg->app[0].priority = (unsigned int )((u8 )app_prio) & 7U;
    dcbcfg->app[0].selector = 1U;
    dcbcfg->app[0].protocolid = 35078U;
    dcbcfg->app[1].priority = (u8 )(((int )app_prio & 56) >> 3);
    dcbcfg->app[1].selector = 2U;
    dcbcfg->app[1].protocolid = 3260U;
    dcbcfg->app[2].priority = (u8 )(((int )app_prio & 1792) >> 8);
    dcbcfg->app[2].selector = 1U;
    dcbcfg->app[2].protocolid = 35092U;
  } else {

  }
  return;
}
}
i40e_status i40e_get_dcb_config(struct i40e_hw *hw ) 
{ 
  i40e_status ret ;
  struct i40e_aqc_get_cee_dcb_cfg_resp cee_cfg ;
  struct i40e_aqc_get_cee_dcb_cfg_v1_resp cee_v1_cfg ;

  {
  ret = 0;
  if (((unsigned int )hw->aq.fw_maj_ver == 4U && (unsigned int )hw->aq.fw_min_ver <= 32U) || (unsigned int )hw->aq.fw_maj_ver <= 3U) {
    goto ieee;
  } else {

  }
  if ((unsigned int )hw->aq.fw_maj_ver == 4U && (unsigned int )hw->aq.fw_min_ver == 33U) {
    ret = i40e_aq_get_cee_dcb_config(hw, (void *)(& cee_v1_cfg), 24, (struct i40e_asq_cmd_details *)0);
    if ((int )ret == 0) {
      hw->local_dcbx_config.dcbx_mode = 1U;
      i40e_cee_to_dcb_v1_config(& cee_v1_cfg, & hw->local_dcbx_config);
    } else {

    }
  } else {
    ret = i40e_aq_get_cee_dcb_config(hw, (void *)(& cee_cfg), 32, (struct i40e_asq_cmd_details *)0);
    if ((int )ret == 0) {
      hw->local_dcbx_config.dcbx_mode = 1U;
      i40e_cee_to_dcb_config(& cee_cfg, & hw->local_dcbx_config);
    } else {

    }
  }
  if ((unsigned int )hw->aq.asq_last_status == 2U) {
    goto ieee;
  } else {
    goto out;
  }
  ieee: 
  hw->local_dcbx_config.dcbx_mode = 2U;
  ret = i40e_aq_get_dcb_config(hw, 0, 0, & hw->local_dcbx_config);
  if ((int )ret != 0) {
    goto out;
  } else {

  }
  ret = i40e_aq_get_dcb_config(hw, 1, 0, & hw->remote_dcbx_config);
  if ((unsigned int )hw->aq.asq_last_status == 2U) {
    ret = 0;
  } else {

  }
  out: ;
  return (ret);
}
}
i40e_status i40e_init_dcb(struct i40e_hw *hw ) 
{ 
  i40e_status ret ;
  struct i40e_lldp_variables lldp_cfg ;
  u8 adminstatus ;

  {
  ret = 0;
  adminstatus = 0U;
  if (! hw->func_caps.dcb) {
    return (ret);
  } else {

  }
  ret = i40e_read_lldp_cfg(hw, & lldp_cfg);
  if ((int )ret != 0) {
    return (ret);
  } else {

  }
  adminstatus = (u8 )((int )lldp_cfg.adminstatus >> (int )hw->port * 4);
  adminstatus = (unsigned int )adminstatus & 15U;
  if ((unsigned int )adminstatus == 0U) {
    hw->dcbx_status = 7U;
    return (ret);
  } else {

  }
  ret = i40e_get_dcbx_status(hw, & hw->dcbx_status);
  if ((int )ret != 0) {
    return (ret);
  } else {

  }
  switch ((int )hw->dcbx_status) {
  case 2: ;
  case 1: 
  ret = i40e_get_dcb_config(hw);
  if ((int )ret != 0) {
    return (ret);
  } else {

  }
  goto ldv_52719;
  case 7: ;
  return (ret);
  case 0: ;
  case 3: ;
  default: ;
  goto ldv_52719;
  }
  ldv_52719: 
  ret = i40e_aq_cfg_lldp_mib_change_event(hw, 1, (struct i40e_asq_cmd_details *)0);
  if ((int )ret != 0) {
    return (ret);
  } else {

  }
  return (ret);
}
}
i40e_status i40e_read_lldp_cfg(struct i40e_hw *hw , struct i40e_lldp_variables *lldp_cfg ) 
{ 
  i40e_status ret ;
  u32 offset ;

  {
  ret = 0;
  offset = 26U;
  if ((unsigned long )lldp_cfg == (unsigned long )((struct i40e_lldp_variables *)0)) {
    return (-5);
  } else {

  }
  ret = i40e_acquire_nvm(hw, 1);
  if ((int )ret != 0) {
    goto err_lldp_cfg;
  } else {

  }
  ret = i40e_aq_read_nvm(hw, 15, offset, 14, (void *)lldp_cfg, 1, (struct i40e_asq_cmd_details *)0);
  i40e_release_nvm(hw);
  err_lldp_cfg: ;
  return (ret);
}
}
bool ldv_queue_work_on_433(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_434(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_435(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_436(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_437(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_438(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_439(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_440(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_441(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_442(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_443(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_444(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_469(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_467(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_470(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_471(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_466(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_468(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_472(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_461(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_463(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_462(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_465(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_464(struct workqueue_struct *ldv_func_arg1 ) ;
extern int dcb_ieee_setapp(struct net_device * , struct dcb_app * ) ;
extern int dcb_ieee_delapp(struct net_device * , struct dcb_app * ) ;
extern int dcbnl_ieee_notify(struct net_device * , int  , int  , u32  , u32  ) ;
static void i40e_get_pfc_delay(struct i40e_hw *hw , u16 *delay ) 
{ 
  u32 val ;

  {
  val = readl((void const volatile   *)hw->hw_addr + 536576U);
  *delay = (unsigned short )(val >> 16);
  return;
}
}
static int i40e_dcbnl_ieee_getets(struct net_device *dev , struct ieee_ets *ets ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_pf *tmp ;
  struct i40e_dcbx_config *dcbxcfg ;
  struct i40e_hw *hw ;

  {
  tmp = i40e_netdev_to_pf(dev);
  pf = tmp;
  hw = & pf->hw;
  if (((int )pf->dcbx_cap & 8) == 0) {
    return (-22);
  } else {

  }
  dcbxcfg = & hw->local_dcbx_config;
  ets->willing = dcbxcfg->etscfg.willing;
  ets->ets_cap = dcbxcfg->etscfg.maxtcs;
  ets->cbs = dcbxcfg->etscfg.cbs;
  memmove((void *)(& ets->tc_tx_bw), (void const   *)(& dcbxcfg->etscfg.tcbwtable),
           8UL);
  memmove((void *)(& ets->tc_rx_bw), (void const   *)(& dcbxcfg->etscfg.tcbwtable),
           8UL);
  memmove((void *)(& ets->tc_tsa), (void const   *)(& dcbxcfg->etscfg.tsatable),
           8UL);
  memmove((void *)(& ets->prio_tc), (void const   *)(& dcbxcfg->etscfg.prioritytable),
           8UL);
  memmove((void *)(& ets->tc_reco_bw), (void const   *)(& dcbxcfg->etsrec.tcbwtable),
           8UL);
  memmove((void *)(& ets->tc_reco_tsa), (void const   *)(& dcbxcfg->etsrec.tsatable),
           8UL);
  memmove((void *)(& ets->reco_prio_tc), (void const   *)(& dcbxcfg->etscfg.prioritytable),
           8UL);
  return (0);
}
}
static int i40e_dcbnl_ieee_getpfc(struct net_device *dev , struct ieee_pfc *pfc ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_pf *tmp ;
  struct i40e_dcbx_config *dcbxcfg ;
  struct i40e_hw *hw ;
  int i ;

  {
  tmp = i40e_netdev_to_pf(dev);
  pf = tmp;
  hw = & pf->hw;
  if (((int )pf->dcbx_cap & 8) == 0) {
    return (-22);
  } else {

  }
  dcbxcfg = & hw->local_dcbx_config;
  pfc->pfc_cap = dcbxcfg->pfc.pfccap;
  pfc->pfc_en = dcbxcfg->pfc.pfcenable;
  pfc->mbc = dcbxcfg->pfc.mbc;
  i40e_get_pfc_delay(hw, & pfc->delay);
  i = 0;
  goto ldv_61002;
  ldv_61001: 
  pfc->requests[i] = pf->stats.priority_xoff_tx[i];
  pfc->indications[i] = pf->stats.priority_xoff_rx[i];
  i = i + 1;
  ldv_61002: ;
  if (i <= 7) {
    goto ldv_61001;
  } else {

  }

  return (0);
}
}
static u8 i40e_dcbnl_getdcbx(struct net_device *dev ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_pf *tmp ;

  {
  tmp = i40e_netdev_to_pf(dev);
  pf = tmp;
  return ((u8 )pf->dcbx_cap);
}
}
static void i40e_dcbnl_get_perm_hw_addr(struct net_device *dev , u8 *perm_addr ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_pf *tmp ;
  int i ;
  int j ;

  {
  tmp = i40e_netdev_to_pf(dev);
  pf = tmp;
  memset((void *)perm_addr, 255, 32UL);
  i = 0;
  goto ldv_61016;
  ldv_61015: 
  *(perm_addr + (unsigned long )i) = pf->hw.mac.perm_addr[i];
  i = i + 1;
  ldv_61016: ;
  if ((int )dev->addr_len > i) {
    goto ldv_61015;
  } else {

  }
  j = 0;
  goto ldv_61019;
  ldv_61018: 
  *(perm_addr + (unsigned long )i) = pf->hw.mac.san_addr[j];
  j = j + 1;
  i = i + 1;
  ldv_61019: ;
  if ((int )dev->addr_len > j) {
    goto ldv_61018;
  } else {

  }

  return;
}
}
static struct dcbnl_rtnl_ops  const  dcbnl_ops  = 
     {& i40e_dcbnl_ieee_getets, 0, 0, 0, 0, 0, 0, & i40e_dcbnl_ieee_getpfc, 0, 0, 0,
    0, 0, 0, 0, 0, & i40e_dcbnl_get_perm_hw_addr, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, & i40e_dcbnl_getdcbx, 0, 0, 0, 0, 0};
void i40e_dcbnl_set_all(struct i40e_vsi *vsi ) 
{ 
  struct net_device *dev ;
  struct i40e_pf *pf ;
  struct i40e_pf *tmp ;
  struct i40e_dcbx_config *dcbxcfg ;
  struct i40e_hw *hw ;
  struct dcb_app sapp ;
  u8 prio ;
  u8 tc_map ;
  int i ;

  {
  dev = vsi->netdev;
  tmp = i40e_netdev_to_pf(dev);
  pf = tmp;
  hw = & pf->hw;
  if ((pf->flags & 1048576ULL) == 0ULL) {
    return;
  } else {

  }
  if ((pf->flags & 67108864ULL) != 0ULL && ! pf->hw.func_caps.iscsi) {
    return;
  } else {

  }
  dcbxcfg = & hw->local_dcbx_config;
  i = 0;
  goto ldv_61034;
  ldv_61033: 
  prio = dcbxcfg->app[i].priority;
  tc_map = (u8 )(1 << (int )dcbxcfg->etscfg.prioritytable[(int )prio]);
  if ((unsigned int )((int )vsi->tc_config.enabled_tc & (int )tc_map) != 0U) {
    sapp.selector = dcbxcfg->app[i].selector;
    sapp.protocol = dcbxcfg->app[i].protocolid;
    sapp.priority = prio;
    dcb_ieee_setapp(dev, & sapp);
  } else {

  }
  i = i + 1;
  ldv_61034: ;
  if ((u32 )i < dcbxcfg->numapps) {
    goto ldv_61033;
  } else {

  }
  dcbnl_ieee_notify(dev, 79, 20, 0U, 0U);
  return;
}
}
static int i40e_dcbnl_vsi_del_app(struct i40e_vsi *vsi , struct i40e_dcb_app_priority_table *app ) 
{ 
  struct net_device *dev ;
  struct dcb_app sapp ;
  int tmp ;

  {
  dev = vsi->netdev;
  if ((unsigned long )dev == (unsigned long )((struct net_device *)0)) {
    return (-22);
  } else {

  }
  sapp.selector = app->selector;
  sapp.protocol = app->protocolid;
  sapp.priority = app->priority;
  tmp = dcb_ieee_delapp(dev, & sapp);
  return (tmp);
}
}
static void i40e_dcbnl_del_app(struct i40e_pf *pf , struct i40e_dcb_app_priority_table *app ) 
{ 
  int v ;
  int err ;

  {
  v = 0;
  goto ldv_61050;
  ldv_61049: ;
  if ((unsigned long )*(pf->vsi + (unsigned long )v) != (unsigned long )((struct i40e_vsi *)0) && (unsigned long )(*(pf->vsi + (unsigned long )v))->netdev != (unsigned long )((struct net_device *)0)) {
    err = i40e_dcbnl_vsi_del_app(*(pf->vsi + (unsigned long )v), app);
    if (err != 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "%s: Failed deleting app for VSI seid=%d err=%d sel=%d proto=0x%x prio=%d\n",
                "i40e_dcbnl_del_app", (int )(*(pf->vsi + (unsigned long )v))->seid,
                err, (int )app->selector, (int )app->protocolid, (int )app->priority);
    } else {

    }
  } else {

  }
  v = v + 1;
  ldv_61050: ;
  if ((int )pf->num_alloc_vsi > v) {
    goto ldv_61049;
  } else {

  }

  return;
}
}
static bool i40e_dcbnl_find_app(struct i40e_dcbx_config *cfg , struct i40e_dcb_app_priority_table *app ) 
{ 
  int i ;

  {
  i = 0;
  goto ldv_61058;
  ldv_61057: ;
  if (((int )app->selector == (int )cfg->app[i].selector && (int )app->protocolid == (int )cfg->app[i].protocolid) && (int )app->priority == (int )cfg->app[i].priority) {
    return (1);
  } else {

  }
  i = i + 1;
  ldv_61058: ;
  if ((u32 )i < cfg->numapps) {
    goto ldv_61057;
  } else {

  }

  return (0);
}
}
void i40e_dcbnl_flush_apps(struct i40e_pf *pf , struct i40e_dcbx_config *old_cfg ,
                           struct i40e_dcbx_config *new_cfg ) 
{ 
  struct i40e_dcb_app_priority_table app ;
  int i ;
  bool tmp ;
  int tmp___0 ;

  {
  if ((pf->flags & 67108864ULL) != 0ULL && ! pf->hw.func_caps.iscsi) {
    return;
  } else {

  }
  i = 0;
  goto ldv_61068;
  ldv_61067: 
  app = old_cfg->app[i];
  tmp = i40e_dcbnl_find_app(new_cfg, & app);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    i40e_dcbnl_del_app(pf, & app);
  } else {

  }
  i = i + 1;
  ldv_61068: ;
  if ((u32 )i < old_cfg->numapps) {
    goto ldv_61067;
  } else {

  }

  return;
}
}
void i40e_dcbnl_setup(struct i40e_vsi *vsi ) 
{ 
  struct net_device *dev ;
  struct i40e_pf *pf ;
  struct i40e_pf *tmp ;

  {
  dev = vsi->netdev;
  tmp = i40e_netdev_to_pf(dev);
  pf = tmp;
  if ((pf->flags & 536870912ULL) == 0ULL) {
    return;
  } else {

  }
  dev->dcbnl_ops = & dcbnl_ops;
  i40e_dcbnl_set_all(vsi);
  return;
}
}
void ldv_initialize_dcbnl_rtnl_ops_7(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(3008UL);
  dcbnl_ops_group0 = (struct net_device *)tmp;
  return;
}
}
void ldv_main_exported_7(void) 
{ 
  u8 *ldvarg42 ;
  void *tmp ;
  struct ieee_ets *ldvarg43 ;
  void *tmp___0 ;
  struct ieee_pfc *ldvarg41 ;
  void *tmp___1 ;
  int tmp___2 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg42 = (u8 *)tmp;
  tmp___0 = ldv_init_zalloc(59UL);
  ldvarg43 = (struct ieee_ets *)tmp___0;
  tmp___1 = ldv_init_zalloc(136UL);
  ldvarg41 = (struct ieee_pfc *)tmp___1;
  tmp___2 = __VERIFIER_nondet_int();
  switch (tmp___2) {
  case 0: ;
  if (ldv_state_variable_7 == 1) {
    i40e_dcbnl_ieee_getets(dcbnl_ops_group0, ldvarg43);
    ldv_state_variable_7 = 1;
  } else {

  }
  goto ldv_61085;
  case 1: ;
  if (ldv_state_variable_7 == 1) {
    i40e_dcbnl_get_perm_hw_addr(dcbnl_ops_group0, ldvarg42);
    ldv_state_variable_7 = 1;
  } else {

  }
  goto ldv_61085;
  case 2: ;
  if (ldv_state_variable_7 == 1) {
    i40e_dcbnl_getdcbx(dcbnl_ops_group0);
    ldv_state_variable_7 = 1;
  } else {

  }
  goto ldv_61085;
  case 3: ;
  if (ldv_state_variable_7 == 1) {
    i40e_dcbnl_ieee_getpfc(dcbnl_ops_group0, ldvarg41);
    ldv_state_variable_7 = 1;
  } else {

  }
  goto ldv_61085;
  default: 
  ldv_stop();
  }
  ldv_61085: ;
  return;
}
}
bool ldv_queue_work_on_461(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_462(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_463(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_464(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_465(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_466(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_467(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_468(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_469(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_470(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_471(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_472(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
extern unsigned long __per_cpu_offset[8192U] ;
extern struct cpumask  const  * const  cpu_possible_mask ;
__inline static unsigned int cpumask_check___0(unsigned int cpu ) 
{ 
  bool __warned ;
  int __ret_warn_once ;
  int __ret_warn_on ;
  long tmp ;
  long tmp___0 ;
  long tmp___1 ;

  {
  __ret_warn_once = (unsigned int )nr_cpu_ids <= cpu;
  tmp___1 = ldv__builtin_expect(__ret_warn_once != 0, 0L);
  if (tmp___1 != 0L) {
    __ret_warn_on = ! __warned;
    tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp != 0L) {
      warn_slowpath_null("include/linux/cpumask.h", 117);
    } else {

    }
    tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___0 != 0L) {
      __warned = 1;
    } else {

    }
  } else {

  }
  ldv__builtin_expect(__ret_warn_once != 0, 0L);
  return (cpu);
}
}
__inline static unsigned int cpumask_next(int n , struct cpumask  const  *srcp ) 
{ 
  unsigned long tmp ;

  {
  if (n != -1) {
    cpumask_check___0((unsigned int )n);
  } else {

  }
  tmp = find_next_bit((unsigned long const   *)(& srcp->bits), (unsigned long )nr_cpu_ids,
                      (unsigned long )(n + 1));
  return ((unsigned int )tmp);
}
}
__inline static int atomic_dec_and_test(atomic_t *v ) 
{ 
  char c ;

  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; decl %0; sete %1": "+m" (v->counter),
                       "=qm" (c): : "memory");
  return ((int )((signed char )c) != 0);
}
}
int ldv_mutex_trylock_497(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_495(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_498(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_unlock_499(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_494(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_496(struct mutex *ldv_func_arg1 ) ;
void ldv_mutex_lock_500(struct mutex *ldv_func_arg1 ) ;
bool ldv_queue_work_on_489(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_491(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_490(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_493(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_492(struct workqueue_struct *ldv_func_arg1 ) ;
extern void *__alloc_percpu(size_t  , size_t  ) ;
extern void free_percpu(void * ) ;
__inline static struct page *sg_page(struct scatterlist *sg ) 
{ 
  long tmp ;
  long tmp___0 ;

  {
  tmp = ldv__builtin_expect(sg->sg_magic != 2271560481UL, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/scatterlist.h"),
                         "i" (123), "i" (12UL));
    ldv_24681: ;
    goto ldv_24681;
  } else {

  }
  tmp___0 = ldv__builtin_expect((long )((int )sg->page_link) & 1L, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/scatterlist.h"),
                         "i" (124), "i" (12UL));
    ldv_24682: ;
    goto ldv_24682;
  } else {

  }
  return ((struct page *)(sg->page_link & 0xfffffffffffffffcUL));
}
}
__inline static void *sg_virt(struct scatterlist *sg ) 
{ 
  struct page *tmp ;
  void *tmp___0 ;

  {
  tmp = sg_page(sg);
  tmp___0 = lowmem_page_address((struct page  const  *)tmp);
  return (tmp___0 + (unsigned long )sg->offset);
}
}
extern struct scatterlist *sg_next(struct scatterlist * ) ;
extern void debug_dma_map_sg(struct device * , struct scatterlist * , int  , int  ,
                             int  ) ;
extern void debug_dma_unmap_sg(struct device * , struct scatterlist * , int  , int  ) ;
__inline static int dma_map_sg_attrs(struct device *dev , struct scatterlist *sg ,
                                     int nents , enum dma_data_direction dir , struct dma_attrs *attrs ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int i ;
  int ents ;
    klee_make_symbolic(&ents, sizeof(int), "ents");
  struct scatterlist *s ;
  void *tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;
  long tmp___3 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  i = 0;
  s = sg;
  goto ldv_25200;
  ldv_25199: 
  tmp___0 = sg_virt(s);
  kmemcheck_mark_initialized(tmp___0, s->length);
  i = i + 1;
  s = sg_next(s);
  ldv_25200: ;
  if (i < nents) {
    goto ldv_25199;
  } else {

  }
  tmp___1 = valid_dma_direction((int )dir);
  tmp___2 = ldv__builtin_expect(tmp___1 == 0, 0L);
  if (tmp___2 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (56), "i" (12UL));
    ldv_25202: ;
    goto ldv_25202;
  } else {

  }
  ents = (*(ops->map_sg))(dev, sg, nents, dir, attrs);
  tmp___3 = ldv__builtin_expect(ents < 0, 0L);
  if (tmp___3 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (58), "i" (12UL));
    ldv_25203: ;
    goto ldv_25203;
  } else {

  }
  debug_dma_map_sg(dev, sg, nents, ents, (int )dir);
  return (ents);
}
}
__inline static void dma_unmap_sg_attrs(struct device *dev , struct scatterlist *sg ,
                                        int nents , enum dma_data_direction dir ,
                                        struct dma_attrs *attrs ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (70), "i" (12UL));
    ldv_25212: ;
    goto ldv_25212;
  } else {

  }
  debug_dma_unmap_sg(dev, sg, nents, (int )dir);
  if ((unsigned long )ops->unmap_sg != (unsigned long )((void (*)(struct device * ,
                                                                  struct scatterlist * ,
                                                                  int  , enum dma_data_direction  ,
                                                                  struct dma_attrs * ))0)) {
    (*(ops->unmap_sg))(dev, sg, nents, dir, attrs);
  } else {

  }
  return;
}
}
__inline static void skb_reset_tail_pointer(struct sk_buff *skb ) 
{ 


  {
  skb->tail = (sk_buff_data_t )((long )skb->data) - (sk_buff_data_t )((long )skb->head);
  return;
}
}
__inline static void skb_set_tail_pointer(struct sk_buff *skb , int const   offset ) 
{ 


  {
  skb_reset_tail_pointer(skb);
  skb->tail = skb->tail + (sk_buff_data_t )offset;
  return;
}
}
__inline static void skb_reset_transport_header(struct sk_buff *skb ) 
{ 


  {
  skb->transport_header = (int )((__u16 )((long )skb->data)) - (int )((__u16 )((long )skb->head));
  return;
}
}
__inline static void skb_set_transport_header(struct sk_buff *skb , int const   offset ) 
{ 


  {
  skb_reset_transport_header(skb);
  skb->transport_header = (int )skb->transport_header + (int )((__u16 )offset);
  return;
}
}
__inline static void skb_reset_network_header(struct sk_buff *skb ) 
{ 


  {
  skb->network_header = (int )((__u16 )((long )skb->data)) - (int )((__u16 )((long )skb->head));
  return;
}
}
__inline static void skb_set_network_header(struct sk_buff *skb , int const   offset ) 
{ 


  {
  skb_reset_network_header(skb);
  skb->network_header = (int )skb->network_header + (int )((__u16 )offset);
  return;
}
}
__inline static unsigned char *skb_mac_header(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->mac_header);
}
}
__inline static void skb_reset_mac_header(struct sk_buff *skb ) 
{ 


  {
  skb->mac_header = (int )((__u16 )((long )skb->data)) - (int )((__u16 )((long )skb->head));
  return;
}
}
extern int ___pskb_trim(struct sk_buff * , unsigned int  ) ;
__inline static void __skb_trim(struct sk_buff *skb , unsigned int len ) 
{ 
  int __ret_warn_on ;
  long tmp ;
  bool tmp___0 ;
  long tmp___1 ;

  {
  tmp___0 = skb_is_nonlinear((struct sk_buff  const  *)skb);
  tmp___1 = ldv__builtin_expect((long )tmp___0, 0L);
  if (tmp___1 != 0L) {
    __ret_warn_on = 1;
    tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp != 0L) {
      warn_slowpath_null("include/linux/skbuff.h", 2054);
    } else {

    }
    ldv__builtin_expect(__ret_warn_on != 0, 0L);
    return;
  } else {

  }
  skb->len = len;
  skb_set_tail_pointer(skb, (int const   )len);
  return;
}
}
__inline static int __pskb_trim(struct sk_buff *skb , unsigned int len ) 
{ 
  int tmp ;

  {
  if (skb->data_len != 0U) {
    tmp = ___pskb_trim(skb, len);
    return (tmp);
  } else {

  }
  __skb_trim(skb, len);
  return (0);
}
}
__inline static int pskb_trim(struct sk_buff *skb , unsigned int len ) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  if (skb->len > len) {
    tmp = __pskb_trim(skb, len);
    tmp___0 = tmp;
  } else {
    tmp___0 = 0;
  }
  return (tmp___0);
}
}
__inline static struct ethhdr *eth_hdr(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_mac_header(skb);
  return ((struct ethhdr *)tmp);
}
}
__inline static u32 ntoh24(u8 const   *p ) 
{ 


  {
  return ((u32 )((((int )*p << 16) | ((int )*(p + 1UL) << 8)) | (int )*(p + 2UL)));
}
}
extern struct dma_pool *dma_pool_create(char const   * , struct device * , size_t  ,
                                        size_t  , size_t  ) ;
extern void dma_pool_destroy(struct dma_pool * ) ;
extern void *dma_pool_alloc(struct dma_pool * , gfp_t  , dma_addr_t * ) ;
extern void dma_pool_free(struct dma_pool * , void * , dma_addr_t  ) ;
__inline static bool i40e_rx_is_fcoe(u16 ptype ) 
{ 


  {
  return ((bool )((unsigned int )ptype > 11U && (unsigned int )ptype <= 21U));
}
}
__inline static bool i40e_fcoe_sof_is_class2(u8 sof ) 
{ 


  {
  return ((bool )((unsigned int )sof == 45U || (unsigned int )sof == 53U));
}
}
__inline static bool i40e_fcoe_sof_is_class3(u8 sof ) 
{ 


  {
  return ((bool )((unsigned int )sof == 46U || (unsigned int )sof == 54U));
}
}
__inline static bool i40e_fcoe_sof_is_supported(u8 sof ) 
{ 
  bool tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  tmp = i40e_fcoe_sof_is_class2((int )sof);
  if ((int )tmp) {
    tmp___1 = 1;
  } else {
    tmp___0 = i40e_fcoe_sof_is_class3((int )sof);
    if ((int )tmp___0) {
      tmp___1 = 1;
    } else {
      tmp___1 = 0;
    }
  }
  return ((bool )tmp___1);
}
}
__inline static int i40e_fcoe_fc_sof(struct sk_buff *skb , u8 *sof ) 
{ 
  unsigned char *tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  tmp = skb_network_header((struct sk_buff  const  *)skb);
  *sof = ((struct fcoe_hdr *)tmp)->fcoe_sof;
  tmp___0 = i40e_fcoe_sof_is_supported((int )*sof);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    return (-22);
  } else {

  }
  return (0);
}
}
__inline static bool i40e_fcoe_eof_is_supported(u8 eof ) 
{ 


  {
  return ((bool )((((unsigned int )eof == 65U || (unsigned int )eof == 66U) || (unsigned int )eof == 73U) || (unsigned int )eof == 80U));
}
}
__inline static int i40e_fcoe_fc_eof(struct sk_buff *skb , u8 *eof ) 
{ 
  bool tmp ;
  int tmp___0 ;

  {
  skb_copy_bits((struct sk_buff  const  *)skb, (int )(skb->len - 4U), (void *)eof,
                1);
  tmp = i40e_fcoe_eof_is_supported((int )*eof);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (-22);
  } else {

  }
  return (0);
}
}
__inline static u32 i40e_fcoe_ctxt_eof(u8 eof ) 
{ 
  int __ret_warn_on ;
  long tmp ;

  {
  switch ((int )eof) {
  case 65: ;
  return (0U);
  case 66: ;
  return (256U);
  case 73: ;
  return (512U);
  case 80: ;
  return (768U);
  default: 
  __ret_warn_on = 1;
  tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_fcoe.c",
                       139);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  return (4294967274U);
  }
}
}
__inline static bool i40e_fcoe_xid_is_valid(u16 xid ) 
{ 


  {
  return ((bool )((unsigned int )xid != 65535U && (unsigned int )xid <= 2047U));
}
}
__inline static void i40e_fcoe_ddp_unmap(struct i40e_pf *pf , struct i40e_fcoe_ddp *ddp ) 
{ 
  int tmp ;

  {
  tmp = test_and_set_bit(7L, (unsigned long volatile   *)(& ddp->flags));
  if (tmp != 0) {
    return;
  } else {

  }
  if ((unsigned long )ddp->sgl != (unsigned long )((struct scatterlist *)0)) {
    dma_unmap_sg_attrs(& (pf->pdev)->dev, ddp->sgl, (int )ddp->sgc, 2, (struct dma_attrs *)0);
    ddp->sgl = (struct scatterlist *)0;
    ddp->sgc = 0U;
  } else {

  }
  if ((unsigned long )ddp->pool != (unsigned long )((struct dma_pool *)0)) {
    dma_pool_free(ddp->pool, (void *)ddp->udl, ddp->udp);
    ddp->pool = (struct dma_pool *)0;
  } else {

  }
  return;
}
}
__inline static void i40e_fcoe_ddp_clear(struct i40e_fcoe_ddp *ddp ) 
{ 


  {
  memset((void *)ddp, 0, 64UL);
  ddp->xid = 65535U;
  ddp->flags = 1UL;
  return;
}
}
__inline static bool i40e_fcoe_progid_is_fcoe(u8 id ) 
{ 


  {
  return ((bool )((unsigned int )id == 2U || (unsigned int )id == 4U));
}
}
__inline static u16 i40e_fcoe_fc_get_xid(struct fc_frame_header *fh ) 
{ 
  u32 f_ctl ;
  u32 tmp ;
  __u16 tmp___0 ;
  __u16 tmp___1 ;
  int tmp___2 ;

  {
  tmp = ntoh24((u8 const   *)(& fh->fh_f_ctl));
  f_ctl = tmp;
  if ((f_ctl & 8388608U) != 0U) {
    tmp___0 = __fswab16((int )fh->fh_ox_id);
    tmp___2 = tmp___0;
  } else {
    tmp___1 = __fswab16((int )fh->fh_rx_id);
    tmp___2 = tmp___1;
  }
  return (tmp___2);
}
}
__inline static struct fc_frame_header *i40e_fcoe_fc_frame_header(struct sk_buff *skb ) 
{ 
  void *fh ;
  struct ethhdr *tmp ;

  {
  fh = (void *)skb->data + 14U;
  tmp = eth_hdr((struct sk_buff  const  *)skb);
  if ((unsigned int )tmp->h_proto == 129U) {
    fh = fh + 4UL;
  } else {

  }
  return ((struct fc_frame_header *)fh);
}
}
static int i40e_fcoe_ddp_put(struct net_device *netdev , u16 xid ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_pf *pf ;
  struct i40e_fcoe *fcoe ;
  int len ;
  struct i40e_fcoe_ddp *ddp ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  fcoe = & pf->fcoe;
  len = 0;
  ddp = (struct i40e_fcoe_ddp *)(& fcoe->ddp) + (unsigned long )xid;
  if ((unsigned long )fcoe == (unsigned long )((struct i40e_fcoe *)0) || (unsigned long )ddp == (unsigned long )((struct i40e_fcoe_ddp *)0)) {
    goto out;
  } else {

  }
  tmp___0 = constant_test_bit(5L, (unsigned long const volatile   *)(& ddp->flags));
  if (tmp___0 != 0) {
    len = ddp->len;
  } else {

  }
  i40e_fcoe_ddp_unmap(pf, ddp);
  out: ;
  return (len);
}
}
int i40e_init_pf_fcoe(struct i40e_pf *pf ) 
{ 
  struct i40e_hw *hw ;
  u32 val ;

  {
  hw = & pf->hw;
  pf->flags = pf->flags & 0xfffffffffffff7ffULL;
  pf->num_fcoe_qps = 0U;
  pf->fcoe_hmc_cntx_num = 0U;
  pf->fcoe_hmc_filt_num = 0U;
  if (! pf->hw.func_caps.fcoe) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "FCoE capability is disabled\n");
    return (0);
  } else {

  }
  if (! pf->hw.func_caps.dcb) {
    dev_warn((struct device  const  *)(& (pf->pdev)->dev), "Hardware is not DCB capable not enabling FCoE.\n");
    return (0);
  } else {

  }
  val = readl((void const volatile   *)hw->hw_addr + 2382208U);
  val = val | 65536U;
  val = val | 131072U;
  val = val;
  writel(val, (void volatile   *)hw->hw_addr + 2382208U);
  pf->flags = pf->flags | 2048ULL;
  pf->num_fcoe_qps = 8U;
  pf->fcoe_hmc_cntx_num = 4096U;
  pf->fcoe_hmc_filt_num = pf->fcoe_hmc_cntx_num + 16384U;
  pf->filter_settings.fcoe_filt_num = 4;
  pf->filter_settings.fcoe_cntx_num = 3;
  val = readl((void const volatile   *)hw->hw_addr + 2530196U);
  val = val & 3221291007U;
  val = val | 142868480U;
  writel(val, (void volatile   *)hw->hw_addr + 2530196U);
  _dev_info((struct device  const  *)(& (pf->pdev)->dev), "FCoE is supported.\n");
  return (0);
}
}
u8 i40e_get_fcoe_tc_map(struct i40e_pf *pf ) 
{ 
  struct i40e_dcb_app_priority_table app ;
  struct i40e_hw *hw ;
  u8 enabled_tc ;
  u8 tc ;
  u8 i ;
  struct i40e_dcbx_config *dcbcfg ;

  {
  hw = & pf->hw;
  enabled_tc = 0U;
  dcbcfg = & hw->local_dcbx_config;
  i = 0U;
  goto ldv_67694;
  ldv_67693: 
  app = dcbcfg->app[(int )i];
  if ((unsigned int )app.selector == 1U && (unsigned int )app.protocolid == 35078U) {
    tc = dcbcfg->etscfg.prioritytable[(int )app.priority];
    enabled_tc = (u8 )((int )((signed char )(1 << (int )tc)) | (int )((signed char )enabled_tc));
    goto ldv_67692;
  } else {

  }
  i = (u8 )((int )i + 1);
  ldv_67694: ;
  if ((u32 )i < dcbcfg->numapps) {
    goto ldv_67693;
  } else {

  }
  ldv_67692: 
  enabled_tc = (unsigned int )enabled_tc != 0U ? enabled_tc : 1U;
  return (enabled_tc);
}
}
int i40e_fcoe_vsi_init(struct i40e_vsi *vsi , struct i40e_vsi_context *ctxt ) 
{ 
  struct i40e_aqc_vsi_properties_data *info ;
  struct i40e_pf *pf ;
  struct i40e_hw *hw ;
  u8 enabled_tc ;
  int tmp ;

  {
  info = & ctxt->info;
  pf = vsi->back;
  hw = & pf->hw;
  enabled_tc = 0U;
  if ((pf->flags & 2048ULL) == 0ULL) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "FCoE is not enabled for this device\n");
    return (-1);
  } else {

  }
  ctxt->pf_num = hw->pf_id;
  ctxt->vf_num = 0U;
  ctxt->uplink_seid = vsi->uplink_seid;
  ctxt->connection_type = 1U;
  ctxt->flags = 2U;
  info->valid_sections = (__le16 )((unsigned int )info->valid_sections | 128U);
  info->valid_sections = (unsigned int )info->valid_sections & 65473U;
  tmp = i40e_is_vsi_uplink_mode_veb(vsi);
  if (tmp != 0) {
    info->valid_sections = (__le16 )((unsigned int )info->valid_sections | 1U);
    info->switch_id = 8192U;
  } else {

  }
  enabled_tc = i40e_get_fcoe_tc_map(pf);
  i40e_vsi_setup_queue_map(vsi, ctxt, (int )enabled_tc, 1);
  info->queueing_opt_flags = 32U;
  return (0);
}
}
int i40e_fcoe_enable(struct net_device *netdev ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  struct i40e_fcoe *fcoe ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  fcoe = & pf->fcoe;
  if ((pf->flags & 2048ULL) == 0ULL) {
    netdev_err((struct net_device  const  *)netdev, "HW does not support FCoE.\n");
    return (-19);
  } else {

  }
  if ((unsigned int )vsi->type != 4U) {
    netdev_err((struct net_device  const  *)netdev, "interface does not support FCoE.\n");
    return (-16);
  } else {

  }
  atomic_inc(& fcoe->refcnt);
  return (0);
}
}
int i40e_fcoe_disable(struct net_device *netdev ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_pf *pf ;
  struct i40e_fcoe *fcoe ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  pf = vsi->back;
  fcoe = & pf->fcoe;
  if ((pf->flags & 2048ULL) == 0ULL) {
    netdev_err((struct net_device  const  *)netdev, "device does not support FCoE\n");
    return (-19);
  } else {

  }
  if ((unsigned int )vsi->type != 4U) {
    return (-16);
  } else {

  }
  tmp___0 = atomic_dec_and_test(& fcoe->refcnt);
  if (tmp___0 == 0) {
    return (-22);
  } else {

  }
  netdev_info((struct net_device  const  *)netdev, "FCoE disabled\n");
  return (0);
}
}
static void i40e_fcoe_dma_pool_free(struct i40e_fcoe *fcoe , struct device *dev ,
                                    unsigned int cpu ) 
{ 
  struct i40e_fcoe_ddp_pool *ddp_pool ;
  void const   *__vpp_verify ;
  unsigned long __ptr ;
    klee_make_symbolic(&__ptr, sizeof(long), "__ptr");

  {
  __vpp_verify = (void const   *)0;
  __asm__  ("": "=r" (__ptr): "0" (fcoe->ddp_pool));
  ddp_pool = (struct i40e_fcoe_ddp_pool *)(__per_cpu_offset[cpu] + __ptr);
  if ((unsigned long )ddp_pool->pool == (unsigned long )((struct dma_pool *)0)) {
    dev_warn((struct device  const  *)dev, "DDP pool already freed for cpu %d\n",
             cpu);
    return;
  } else {

  }
  dma_pool_destroy(ddp_pool->pool);
  ddp_pool->pool = (struct dma_pool *)0;
  return;
}
}
static int i40e_fcoe_dma_pool_create(struct i40e_fcoe *fcoe , struct device *dev ,
                                     unsigned int cpu ) 
{ 
  struct i40e_fcoe_ddp_pool *ddp_pool ;
  struct dma_pool *pool ;
  char pool_name[32U] ;
  void const   *__vpp_verify ;
  unsigned long __ptr ;

  {
  __vpp_verify = (void const   *)0;
  __asm__  ("": "=r" (__ptr): "0" (fcoe->ddp_pool));
  ddp_pool = (struct i40e_fcoe_ddp_pool *)(__per_cpu_offset[cpu] + __ptr);
  if ((unsigned long )ddp_pool != (unsigned long )((struct i40e_fcoe_ddp_pool *)0) && (unsigned long )ddp_pool->pool != (unsigned long )((struct dma_pool *)0)) {
    dev_warn((struct device  const  *)dev, "DDP pool already allocated for cpu %d\n",
             cpu);
    return (0);
  } else {

  }
  snprintf((char *)(& pool_name), 32UL, "i40e_fcoe_ddp_%d", cpu);
  pool = dma_pool_create((char const   *)(& pool_name), dev, 4096UL, 16UL, 4096UL);
  if ((unsigned long )pool == (unsigned long )((struct dma_pool *)0)) {
    dev_err((struct device  const  *)dev, "dma_pool_create %s failed\n", (char *)(& pool_name));
    return (-12);
  } else {

  }
  ddp_pool->pool = pool;
  return (0);
}
}
void i40e_fcoe_free_ddp_resources(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_fcoe *fcoe ;
  int cpu ;
  int i ;
  unsigned int tmp ;

  {
  pf = vsi->back;
  fcoe = & pf->fcoe;
  if ((unsigned int )vsi->type != 4U) {
    return;
  } else {

  }
  if ((unsigned long )fcoe->ddp_pool == (unsigned long )((struct i40e_fcoe_ddp_pool *)0)) {
    return;
  } else {

  }
  i = 0;
  goto ldv_67747;
  ldv_67746: 
  i40e_fcoe_ddp_put(vsi->netdev, (int )((u16 )i));
  i = i + 1;
  ldv_67747: ;
  if (i <= 2047) {
    goto ldv_67746;
  } else {

  }
  cpu = -1;
  goto ldv_67750;
  ldv_67749: 
  i40e_fcoe_dma_pool_free(fcoe, & (pf->pdev)->dev, (unsigned int )cpu);
  ldv_67750: 
  tmp = cpumask_next(cpu, cpu_possible_mask);
  cpu = (int )tmp;
  if (cpu < nr_cpu_ids) {
    goto ldv_67749;
  } else {

  }
  free_percpu((void *)fcoe->ddp_pool);
  fcoe->ddp_pool = (struct i40e_fcoe_ddp_pool *)0;
  netdev_info((struct net_device  const  *)vsi->netdev, "VSI %d,%d FCoE DDP resources released\n",
              (int )vsi->id, (int )vsi->seid);
  return;
}
}
int i40e_fcoe_setup_ddp_resources(struct i40e_vsi *vsi ) 
{ 
  struct i40e_pf *pf ;
  struct device *dev ;
  struct i40e_fcoe *fcoe ;
  unsigned int cpu ;
  int i ;
  void *tmp ;
  int tmp___0 ;

  {
  pf = vsi->back;
  dev = & (pf->pdev)->dev;
  fcoe = & pf->fcoe;
  if ((unsigned int )vsi->type != 4U) {
    return (-19);
  } else {

  }
  if ((unsigned long )fcoe->ddp_pool != (unsigned long )((struct i40e_fcoe_ddp_pool *)0)) {
    return (-17);
  } else {

  }
  tmp = __alloc_percpu(8UL, 8UL);
  fcoe->ddp_pool = (struct i40e_fcoe_ddp_pool *)tmp;
  if ((unsigned long )fcoe->ddp_pool == (unsigned long )((struct i40e_fcoe_ddp_pool *)0)) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "failed to allocate percpu DDP\n");
    return (-12);
  } else {

  }
  cpu = 4294967295U;
  goto ldv_67760;
  ldv_67761: 
  tmp___0 = i40e_fcoe_dma_pool_create(fcoe, dev, cpu);
  if (tmp___0 == 0) {
    goto ldv_67760;
  } else {

  }
  dev_err((struct device  const  *)dev, "failed to alloc DDP pool on cpu:%d\n", cpu);
  i40e_fcoe_free_ddp_resources(vsi);
  return (-12);
  ldv_67760: 
  cpu = cpumask_next((int )cpu, cpu_possible_mask);
  if ((unsigned int )nr_cpu_ids > cpu) {
    goto ldv_67761;
  } else {

  }
  i = 0;
  goto ldv_67764;
  ldv_67763: 
  i40e_fcoe_ddp_clear((struct i40e_fcoe_ddp *)(& fcoe->ddp) + (unsigned long )i);
  i = i + 1;
  ldv_67764: ;
  if (i <= 2047) {
    goto ldv_67763;
  } else {

  }
  netdev_info((struct net_device  const  *)vsi->netdev, "VSI %d,%d FCoE DDP resources allocated\n",
              (int )vsi->id, (int )vsi->seid);
  return (0);
}
}
void i40e_fcoe_handle_status(struct i40e_ring *rx_ring , union i40e_32byte_rx_desc *rx_desc ,
                             u8 prog_id ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_fcoe *fcoe ;
  struct i40e_fcoe_ddp *ddp ;
  u32 error ;
  u16 xid ;
  u64 qw ;
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int __ret_warn_on ;
  long tmp___3 ;

  {
  pf = (rx_ring->vsi)->back;
  fcoe = & pf->fcoe;
  tmp = i40e_fcoe_progid_is_fcoe((int )prog_id);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return;
  } else {

  }
  xid = (unsigned int )((u16 )rx_desc->wb.qword0.hi_dword.fcoe_param) & 2047U;
  tmp___1 = i40e_fcoe_xid_is_valid((int )xid);
  if (tmp___1) {
    tmp___2 = 0;
  } else {
    tmp___2 = 1;
  }
  if (tmp___2) {
    return;
  } else {

  }
  ddp = (struct i40e_fcoe_ddp *)(& fcoe->ddp) + (unsigned long )xid;
  __ret_warn_on = (int )ddp->xid != (int )xid;
  tmp___3 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___3 != 0L) {
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_fcoe.c",
                       643);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  qw = rx_desc->wb.qword1.status_error_len;
  error = (u32 )((qw & 33030144ULL) >> 19);
  if ((unsigned int )prog_id == 2U) {
    if ((error & 4U) != 0U) {
      dev_err((struct device  const  *)(& (pf->pdev)->dev), "xid %x ddp->xid %x TABLE FULL\n",
              (int )xid, (int )ddp->xid);
      ddp->prerr = (u8 )((unsigned int )ddp->prerr | 4U);
    } else {

    }
    if ((error & 8U) != 0U) {
      dev_err((struct device  const  *)(& (pf->pdev)->dev), "xid %x ddp->xid %x CONFLICT\n",
              (int )xid, (int )ddp->xid);
      ddp->prerr = (u8 )((unsigned int )ddp->prerr | 8U);
    } else {

    }
  } else {

  }
  if ((unsigned int )prog_id == 4U) {
    if ((error & 8U) != 0U) {
      dev_err((struct device  const  *)(& (pf->pdev)->dev), "xid %x ddp->xid %x INVALIDATION FAILURE\n",
              (int )xid, (int )ddp->xid);
      ddp->prerr = (u8 )((unsigned int )ddp->prerr | 8U);
    } else {

    }
    clear_bit(6L, (unsigned long volatile   *)(& ddp->flags));
  } else {

  }
  i40e_fcoe_ddp_unmap(pf, ddp);
  i40e_fcoe_ddp_clear(ddp);
  return;
}
}
int i40e_fcoe_handle_offload(struct i40e_ring *rx_ring , union i40e_32byte_rx_desc *rx_desc ,
                             struct sk_buff *skb ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_fcoe *fcoe ;
  struct fc_frame_header *fh ;
  struct i40e_fcoe_ddp *ddp ;
  u32 status ;
  u32 fltstat ;
  u32 error ;
  u32 fcerr ;
  int rc ;
  u16 ptype ;
  u16 xid ;
  u64 qw ;
  bool tmp ;
  int tmp___0 ;
  long tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  u32 f_ctl ;
  u32 tmp___4 ;
  struct fcoe_crc_eof *crc ;
  unsigned char *tmp___5 ;
  int pkts ;
    klee_make_symbolic(&pkts, sizeof(int), "pkts");

  {
  pf = (rx_ring->vsi)->back;
  fcoe = & pf->fcoe;
  fh = (struct fc_frame_header *)0;
  ddp = (struct i40e_fcoe_ddp *)0;
  rc = -22;
  qw = rx_desc->wb.qword1.status_error_len;
  ptype = (u16 )((qw & 273804165120ULL) >> 30);
  tmp = i40e_rx_is_fcoe((int )ptype);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    goto out_no_ddp;
  } else {

  }
  error = (u32 )((qw & 133693440ULL) >> 19);
  fcerr = (error >> 3) & 7U;
  tmp___1 = ldv__builtin_expect(fcerr == 1U, 0L);
  if (tmp___1 != 0L) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "Protocol Error\n");
    skb->ip_summed = 0U;
  } else {
    skb->ip_summed = 1U;
  }
  status = (u32 )qw & 524287U;
  fltstat = (status >> 12) & 3U;
  fh = i40e_fcoe_fc_frame_header(skb);
  xid = i40e_fcoe_fc_get_xid(fh);
  tmp___2 = i40e_fcoe_xid_is_valid((int )xid);
  if (tmp___2) {
    tmp___3 = 0;
  } else {
    tmp___3 = 1;
  }
  if (tmp___3) {
    goto out_no_ddp;
  } else {

  }
  if (fltstat == 0U) {
    goto out_no_ddp;
  } else {

  }
  ddp = (struct i40e_fcoe_ddp *)(& fcoe->ddp) + (unsigned long )xid;
  if ((unsigned long )ddp->sgl == (unsigned long )((struct scatterlist *)0)) {
    goto out_no_ddp;
  } else {

  }
  xid = rx_desc->wb.qword0.lo_dword.mirr_fcoe.fcoe_ctx_id;
  if ((int )ddp->xid != (int )xid) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "xid 0x%x does not match ctx_xid 0x%x\n",
            (int )ddp->xid, (int )xid);
    goto out_put_ddp;
  } else {

  }
  if ((unsigned int )ddp->fcerr != 0U) {
    dev_err((struct device  const  *)(& (pf->pdev)->dev), "xid 0x%x fcerr 0x%x reported fcer 0x%x\n",
            (int )xid, (int )ddp->fcerr, fcerr);
    goto out_put_ddp;
  } else {

  }
  ddp->len = (int )rx_desc->wb.qword0.hi_dword.fcoe_param;
  ddp->fcerr = (u8 )fcerr;
  if (fltstat == 2U) {
    tmp___4 = ntoh24((u8 const   *)(& fh->fh_f_ctl));
    f_ctl = tmp___4;
    if ((f_ctl & 524288U) != 0U && (unsigned int )fh->fh_r_ctl == 1U) {
      crc = (struct fcoe_crc_eof *)0;
      tmp___5 = skb_put(skb, 8U);
      crc = (struct fcoe_crc_eof *)tmp___5;
      crc->fcoe_eof = 66U;
    } else {
      rc = 0;
      goto out_no_ddp;
    }
  } else {

  }
  out_put_ddp: 
  i40e_fcoe_ddp_unmap(pf, ddp);
  if (ddp->len != 0 && (unsigned int )ddp->fcerr == 0U) {
    rc = ddp->len;
    i40e_fcoe_ddp_clear(ddp);
    ddp->len = rc;
    pkts = (rc + 2047) / 2048;
    rx_ring->stats.bytes = rx_ring->stats.bytes + (u64 )rc;
    rx_ring->stats.packets = rx_ring->stats.packets + (u64 )pkts;
    (rx_ring->q_vector)->rx.total_bytes = (rx_ring->q_vector)->rx.total_bytes + (unsigned int )rc;
    (rx_ring->q_vector)->rx.total_packets = (rx_ring->q_vector)->rx.total_packets + (unsigned int )pkts;
    set_bit(5L, (unsigned long volatile   *)(& ddp->flags));
  } else {

  }
  out_no_ddp: ;
  return (rc);
}
}
static int i40e_fcoe_ddp_setup(struct net_device *netdev , u16 xid , struct scatterlist *sgl ,
                               unsigned int sgc , int target_mode ) 
{ 
  unsigned int bufflen ;
    klee_make_symbolic(&bufflen, sizeof(int), "bufflen");
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_fcoe_ddp_pool *ddp_pool ;
  struct i40e_pf *pf ;
  struct i40e_fcoe *fcoe ;
  unsigned int i ;
  unsigned int j ;
  unsigned int dmacount ;
    klee_make_symbolic(&dmacount, sizeof(int), "dmacount");
  struct i40e_fcoe_ddp *ddp ;
  unsigned int firstoff ;
    klee_make_symbolic(&firstoff, sizeof(int), "firstoff");
  unsigned int thisoff ;
    klee_make_symbolic(&thisoff, sizeof(int), "thisoff");
  unsigned int thislen ;
    klee_make_symbolic(&thislen, sizeof(int), "thislen");
  struct scatterlist *sg ;
  dma_addr_t addr ;
  unsigned int len ;
  int tmp___0 ;
  int tmp___1 ;
  void const   *__vpp_verify ;
  unsigned long __ptr ;
  int pscr_ret__ ;
  void const   *__vpp_verify___0 ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  int tmp___2 ;
  void *tmp___3 ;
  unsigned int __min1 ;
  unsigned int __min2 ;

  {
  bufflen = 4096U;
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  pf = (np->vsi)->back;
  fcoe = & pf->fcoe;
  firstoff = 0U;
  thisoff = 0U;
  thislen = 0U;
  addr = 0ULL;
  if ((unsigned int )xid > 2047U) {
    dev_warn((struct device  const  *)(& (pf->pdev)->dev), "xid=0x%x out-of-range\n",
             (int )xid);
    return (0);
  } else {

  }
  tmp___0 = constant_test_bit(3L, (unsigned long const volatile   *)(& pf->state));
  if (tmp___0 != 0) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "xid=0x%x device in reset/down\n",
              (int )xid);
    return (0);
  } else {
    tmp___1 = constant_test_bit(4L, (unsigned long const volatile   *)(& pf->state));
    if (tmp___1 != 0) {
      _dev_info((struct device  const  *)(& (pf->pdev)->dev), "xid=0x%x device in reset/down\n",
                (int )xid);
      return (0);
    } else {

    }
  }
  ddp = (struct i40e_fcoe_ddp *)(& fcoe->ddp) + (unsigned long )xid;
  if ((unsigned long )ddp->sgl != (unsigned long )((struct scatterlist *)0)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "xid 0x%x w/ non-null sgl=%p nents=%d\n",
              (int )xid, ddp->sgl, ddp->sgc);
    return (0);
  } else {

  }
  i40e_fcoe_ddp_clear(ddp);
  if ((unsigned long )fcoe->ddp_pool == (unsigned long )((struct i40e_fcoe_ddp_pool *)0)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "No DDP pool, xid 0x%x\n",
              (int )xid);
    return (0);
  } else {

  }
  __vpp_verify = (void const   *)0;
  __asm__  ("": "=r" (__ptr): "0" (fcoe->ddp_pool));
  __preempt_count_add___0(1);
  __asm__  volatile   ("": : : "memory");
  __vpp_verify___0 = (void const   *)0;
  switch (4UL) {
  case 1UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret__): "m" (cpu_number));
  goto ldv_67830;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_67830;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_67830;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret__): "m" (cpu_number));
  goto ldv_67830;
  default: 
  __bad_percpu_size();
  }
  ldv_67830: 
  pscr_ret__ = pfo_ret__;
  goto ldv_67836;
  case 2UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_67840;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_67840;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_67840;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
  goto ldv_67840;
  default: 
  __bad_percpu_size();
  }
  ldv_67840: 
  pscr_ret__ = pfo_ret_____0;
  goto ldv_67836;
  case 4UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_67849;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_67849;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_67849;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
  goto ldv_67849;
  default: 
  __bad_percpu_size();
  }
  ldv_67849: 
  pscr_ret__ = pfo_ret_____1;
  goto ldv_67836;
  case 8UL: ;
  switch (4UL) {
  case 1UL: 
  __asm__  ("movb %%gs:%1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_67858;
  case 2UL: 
  __asm__  ("movw %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_67858;
  case 4UL: 
  __asm__  ("movl %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_67858;
  case 8UL: 
  __asm__  ("movq %%gs:%1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
  goto ldv_67858;
  default: 
  __bad_percpu_size();
  }
  ldv_67858: 
  pscr_ret__ = pfo_ret_____2;
  goto ldv_67836;
  default: 
  __bad_size_call_parameter();
  goto ldv_67836;
  }
  ldv_67836: 
  ddp_pool = (struct i40e_fcoe_ddp_pool *)(__per_cpu_offset[pscr_ret__] + __ptr);
  if ((unsigned long )ddp_pool->pool == (unsigned long )((struct dma_pool *)0)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "No percpu ddp pool, xid 0x%x\n",
              (int )xid);
    goto out_noddp;
  } else {

  }
  tmp___2 = dma_map_sg_attrs(& (pf->pdev)->dev, sgl, (int )sgc, 2, (struct dma_attrs *)0);
  dmacount = (unsigned int )tmp___2;
  if (dmacount == 0U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "dma_map_sg for sgl %p, sgc %d failed\n",
              sgl, sgc);
    goto out_noddp_unmap;
  } else {

  }
  tmp___3 = dma_pool_alloc(ddp_pool->pool, 32U, & ddp->udp);
  ddp->udl = (u64 *)tmp___3;
  if ((unsigned long )ddp->udl == (unsigned long )((u64 *)0ULL)) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Failed allocated ddp context, xid 0x%x\n",
              (int )xid);
    goto out_noddp_unmap;
  } else {

  }
  j = 0U;
  ddp->len = 0;
  i = 0U;
  sg = sgl;
  goto ldv_67879;
  ldv_67878: 
  addr = sg->dma_address;
  len = sg->dma_length;
  ddp->len = (int )((unsigned int )ddp->len + len);
  goto ldv_67876;
  ldv_67875: ;
  if (j > 511U) {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "xid=%x:%d,%d,%d:addr=%llx not enough descriptors\n",
              (int )xid, i, j, dmacount, addr);
    goto out_noddp_free;
  } else {

  }
  thisoff = (bufflen - 1U) & (unsigned int )addr;
  __min1 = bufflen - thisoff;
  __min2 = len;
  thislen = __min1 < __min2 ? __min1 : __min2;
  if (j != 0U && thisoff != 0U) {
    goto out_noddp_free;
  } else {

  }
  if ((dmacount - 1U != i || thislen != len) && thislen + thisoff != bufflen) {
    goto out_noddp_free;
  } else {

  }
  *(ddp->udl + (unsigned long )j) = addr - (dma_addr_t )thisoff;
  if (j == 0U) {
    firstoff = thisoff;
  } else {

  }
  len = len - thislen;
  addr = (dma_addr_t )thislen + addr;
  j = j + 1U;
  ldv_67876: ;
  if (len != 0U) {
    goto ldv_67875;
  } else {

  }
  i = i + 1U;
  sg = sg_next(sg);
  ldv_67879: ;
  if (i < dmacount) {
    goto ldv_67878;
  } else {

  }
  ddp->lastsize = (int )((u16 )thisoff) + (int )((u16 )thislen);
  ddp->firstoff = (u16 )firstoff;
  ddp->list_len = (u16 )j;
  ddp->pool = ddp_pool->pool;
  ddp->sgl = sgl;
  ddp->sgc = sgc;
  ddp->xid = xid;
  if (target_mode != 0) {
    set_bit(2L, (unsigned long volatile   *)(& ddp->flags));
  } else {

  }
  set_bit(3L, (unsigned long volatile   *)(& ddp->flags));
  __asm__  volatile   ("": : : "memory");
  __preempt_count_sub___0(1);
  return (1);
  out_noddp_free: 
  dma_pool_free(ddp->pool, (void *)ddp->udl, ddp->udp);
  i40e_fcoe_ddp_clear(ddp);
  out_noddp_unmap: 
  dma_unmap_sg_attrs(& (pf->pdev)->dev, sgl, (int )sgc, 2, (struct dma_attrs *)0);
  out_noddp: 
  __asm__  volatile   ("": : : "memory");
  __preempt_count_sub___0(1);
  return (0);
}
}
static int i40e_fcoe_ddp_get(struct net_device *netdev , u16 xid , struct scatterlist *sgl ,
                             unsigned int sgc ) 
{ 
  int tmp ;

  {
  tmp = i40e_fcoe_ddp_setup(netdev, (int )xid, sgl, sgc, 0);
  return (tmp);
}
}
static int i40e_fcoe_ddp_target(struct net_device *netdev , u16 xid , struct scatterlist *sgl ,
                                unsigned int sgc ) 
{ 
  int tmp ;

  {
  tmp = i40e_fcoe_ddp_setup(netdev, (int )xid, sgl, sgc, 1);
  return (tmp);
}
}
static void i40e_fcoe_program_ddp(struct i40e_ring *tx_ring , struct sk_buff *skb ,
                                  struct i40e_fcoe_ddp *ddp , u8 sof ) 
{ 
  struct i40e_fcoe_filter_context_desc *filter_desc ;
  struct i40e_fcoe_queue_context_desc *queue_desc ;
  struct i40e_fcoe_ddp_context_desc *ddp_desc ;
  struct i40e_pf *pf ;
  u16 i ;
  struct fc_frame_header *fh ;
  u64 flags_rsvd_lanq ;
  bool target_mode ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  u16 tmp___2 ;
  unsigned char *tmp___3 ;
  __u32 tmp___4 ;
  __u16 tmp___5 ;

  {
  filter_desc = (struct i40e_fcoe_filter_context_desc *)0;
  queue_desc = (struct i40e_fcoe_queue_context_desc *)0;
  ddp_desc = (struct i40e_fcoe_ddp_context_desc *)0;
  pf = (tx_ring->vsi)->back;
  i = tx_ring->next_to_use;
  flags_rsvd_lanq = 0ULL;
  tmp = constant_test_bit(6L, (unsigned long const volatile   *)(& ddp->flags));
  if (tmp != 0) {
    dev_warn((struct device  const  *)(& (pf->pdev)->dev), "DDP abort is still pending xid:%hx and ddp->flags:%lx:\n",
             (int )ddp->xid, ddp->flags);
    return;
  } else {

  }
  tmp___0 = test_and_set_bit(4L, (unsigned long volatile   *)(& ddp->flags));
  if (tmp___0 != 0) {
    dev_warn((struct device  const  *)(& (pf->pdev)->dev), "DDP is already programmed for xid:%hx and ddp->flags:%lx:\n",
             (int )ddp->xid, ddp->flags);
    return;
  } else {

  }
  ddp_desc = (struct i40e_fcoe_ddp_context_desc *)tx_ring->desc + (unsigned long )i;
  i = (u16 )((int )i + 1);
  if ((int )tx_ring->count == (int )i) {
    i = 0U;
  } else {

  }
  ddp_desc->type_cmd_foff_lsize = (((unsigned long long )ddp->firstoff << 16) | ((unsigned long long )ddp->lastsize << 32)) | 25ULL;
  ddp_desc->rsvd = 0ULL;
  tmp___1 = constant_test_bit(2L, (unsigned long const volatile   *)(& ddp->flags));
  target_mode = tmp___1 != 0;
  if ((int )target_mode) {
    ddp_desc->type_cmd_foff_lsize = ddp_desc->type_cmd_foff_lsize | 8ULL;
  } else {

  }
  tmp___2 = i;
  i = (u16 )((int )i + 1);
  queue_desc = (struct i40e_fcoe_queue_context_desc *)tx_ring->desc + (unsigned long )tmp___2;
  if ((int )tx_ring->count == (int )i) {
    i = 0U;
  } else {

  }
  queue_desc->dmaindx_fbase = (dma_addr_t )ddp->xid | ddp->udp;
  queue_desc->flen_tph = (unsigned long long )((unsigned int )ddp->list_len | 24576U);
  filter_desc = (struct i40e_fcoe_filter_context_desc *)tx_ring->desc + (unsigned long )i;
  i = (u16 )((int )i + 1);
  if ((int )tx_ring->count == (int )i) {
    i = 0U;
  } else {

  }
  tmp___3 = skb_transport_header((struct sk_buff  const  *)skb);
  fh = (struct fc_frame_header *)tmp___3;
  tmp___4 = __fswab32(fh->fh_parm_offset);
  filter_desc->param = tmp___4;
  tmp___5 = __fswab16((int )fh->fh_seq_cnt);
  filter_desc->seqn = tmp___5;
  filter_desc->rsvd_dmaindx = (int )ddp->xid << 4U;
  flags_rsvd_lanq = 0ULL;
  flags_rsvd_lanq = ((int )target_mode ? 2ULL : 0ULL) | flags_rsvd_lanq;
  flags_rsvd_lanq = ((unsigned int )sof == 45U || (unsigned int )sof == 53U ? 0ULL : 4ULL) | flags_rsvd_lanq;
  flags_rsvd_lanq = ((unsigned long long )skb->queue_mapping << 53) | flags_rsvd_lanq;
  filter_desc->flags_rsvd_lanq = flags_rsvd_lanq;
  tx_ring->next_to_use = i;
  return;
}
}
static void i40e_fcoe_invalidate_ddp(struct i40e_ring *tx_ring , struct sk_buff *skb ,
                                     struct i40e_fcoe_ddp *ddp ) 
{ 
  struct i40e_tx_context_desc *context_desc ;
  int i ;
  int tmp ;

  {
  tmp = test_and_set_bit(6L, (unsigned long volatile   *)(& ddp->flags));
  if (tmp != 0) {
    return;
  } else {

  }
  i = (int )tx_ring->next_to_use;
  context_desc = (struct i40e_tx_context_desc *)tx_ring->desc + (unsigned long )i;
  i = i + 1;
  if ((int )tx_ring->count == i) {
    i = 0;
  } else {

  }
  context_desc->tunneling_params = 0U;
  context_desc->l2tag2 = 0U;
  context_desc->rsvd = 0U;
  context_desc->type_cmd_tso_mss = 130ULL;
  tx_ring->next_to_use = (u16 )i;
  return;
}
}
static void i40e_fcoe_handle_ddp(struct i40e_ring *tx_ring , struct sk_buff *skb ,
                                 u8 sof ) 
{ 
  struct i40e_pf *pf ;
  struct i40e_fcoe *fcoe ;
  struct fc_frame_header *fh ;
  struct i40e_fcoe_ddp *ddp ;
  u32 f_ctl ;
  u8 r_ctl ;
  u16 xid ;
  unsigned char *tmp ;
  __u16 tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;
  __u16 tmp___3 ;
  int tmp___4 ;
  bool tmp___5 ;
  __u16 tmp___6 ;
  int tmp___7 ;
  bool tmp___8 ;

  {
  pf = (tx_ring->vsi)->back;
  fcoe = & pf->fcoe;
  tmp = skb_transport_header((struct sk_buff  const  *)skb);
  fh = (struct fc_frame_header *)tmp;
  f_ctl = ntoh24((u8 const   *)(& fh->fh_f_ctl));
  r_ctl = fh->fh_r_ctl;
  ddp = (struct i40e_fcoe_ddp *)0;
  if ((unsigned int )r_ctl == 5U && (f_ctl & 8388608U) != 0U) {
    tmp___0 = __fswab16((int )fh->fh_rx_id);
    xid = tmp___0;
    tmp___2 = i40e_fcoe_xid_is_valid((int )xid);
    if ((int )tmp___2) {
      ddp = (struct i40e_fcoe_ddp *)(& fcoe->ddp) + (unsigned long )xid;
      if ((int )ddp->xid == (int )xid) {
        tmp___1 = constant_test_bit(2L, (unsigned long const volatile   *)(& ddp->flags));
        if (tmp___1 != 0) {
          i40e_fcoe_program_ddp(tx_ring, skb, ddp, (int )sof);
        } else {

        }
      } else {

      }
    } else {

    }
  } else
  if ((unsigned int )r_ctl == 6U) {
    tmp___3 = __fswab16((int )fh->fh_ox_id);
    xid = tmp___3;
    tmp___5 = i40e_fcoe_xid_is_valid((int )xid);
    if ((int )tmp___5) {
      ddp = (struct i40e_fcoe_ddp *)(& fcoe->ddp) + (unsigned long )xid;
      if ((int )ddp->xid == (int )xid) {
        tmp___4 = constant_test_bit(2L, (unsigned long const volatile   *)(& ddp->flags));
        if (tmp___4 == 0) {
          i40e_fcoe_program_ddp(tx_ring, skb, ddp, (int )sof);
        } else {

        }
      } else {

      }
    } else {

    }
  } else
  if ((unsigned int )r_ctl == 129U) {
    tmp___6 = __fswab16((int )fh->fh_ox_id);
    xid = tmp___6;
    tmp___8 = i40e_fcoe_xid_is_valid((int )xid);
    if ((int )tmp___8) {
      ddp = (struct i40e_fcoe_ddp *)(& fcoe->ddp) + (unsigned long )xid;
      if ((int )ddp->xid == (int )xid) {
        tmp___7 = constant_test_bit(2L, (unsigned long const volatile   *)(& ddp->flags));
        if (tmp___7 == 0) {
          i40e_fcoe_invalidate_ddp(tx_ring, skb, ddp);
        } else {

        }
      } else {

      }
    } else {

    }
  } else {

  }
  return;
}
}
static int i40e_fcoe_tso(struct i40e_ring *tx_ring , struct sk_buff *skb , u32 tx_flags ,
                         u8 *hdr_len , u8 sof ) 
{ 
  struct i40e_tx_context_desc *context_desc ;
  u32 cd_type ;
  u32 cd_cmd ;
  u32 cd_tso_len ;
  u32 cd_mss ;
  struct fc_frame_header *fh ;
  u64 cd_type_cmd_tso_mss ;
  bool tmp ;
  int tmp___0 ;
  unsigned char *tmp___1 ;
  unsigned char *tmp___2 ;
  int tmp___3 ;
  bool tmp___4 ;
  long tmp___5 ;
  unsigned char *tmp___6 ;
  unsigned char *tmp___7 ;

  {
  tmp = skb_is_gso((struct sk_buff  const  *)skb);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (0);
  } else {

  }
  tmp___2 = skb_end_pointer((struct sk_buff  const  *)skb);
  if ((unsigned int )((struct skb_shared_info *)tmp___2)->gso_type != 32U) {
    tmp___1 = skb_end_pointer((struct sk_buff  const  *)skb);
    netdev_err((struct net_device  const  *)skb->dev, "wrong gso type %d:expecting SKB_GSO_FCOE\n",
               (int )((struct skb_shared_info *)tmp___1)->gso_type);
    return (-22);
  } else {

  }
  tmp___3 = skb_transport_offset((struct sk_buff  const  *)skb);
  *hdr_len = (unsigned int )((u8 )tmp___3) + 32U;
  tmp___4 = i40e_fcoe_sof_is_class3((int )sof);
  tmp___5 = ldv__builtin_expect((long )tmp___4, 1L);
  if (tmp___5 != 0L) {
    cd_cmd = 5U;
  } else {
    cd_cmd = 1U;
  }
  tmp___6 = skb_transport_header((struct sk_buff  const  *)skb);
  fh = (struct fc_frame_header *)tmp___6;
  if (((int )fh->fh_f_ctl[2] & 8) != 0) {
    cd_cmd = cd_cmd | 16U;
  } else {

  }
  cd_type = 2U;
  cd_tso_len = skb->len - (unsigned int )*hdr_len;
  tmp___7 = skb_end_pointer((struct sk_buff  const  *)skb);
  cd_mss = (u32 )((struct skb_shared_info *)tmp___7)->gso_size;
  cd_type_cmd_tso_mss = (((unsigned long long )cd_type | ((unsigned long long )cd_cmd << 4)) | ((unsigned long long )cd_tso_len << 30)) | ((unsigned long long )cd_mss << 50);
  context_desc = (struct i40e_tx_context_desc *)tx_ring->desc + (unsigned long )tx_ring->next_to_use;
  tx_ring->next_to_use = (u16 )((int )tx_ring->next_to_use + 1);
  if ((int )tx_ring->next_to_use == (int )tx_ring->count) {
    tx_ring->next_to_use = 0U;
  } else {

  }
  context_desc->tunneling_params = 0U;
  context_desc->l2tag2 = (unsigned short )(tx_flags >> 16);
  context_desc->type_cmd_tso_mss = cd_type_cmd_tso_mss;
  return (1);
}
}
static void i40e_fcoe_tx_map(struct i40e_ring *tx_ring , struct sk_buff *skb , struct i40e_tx_buffer *first ,
                             u32 tx_flags , u8 hdr_len , u8 eof ) 
{ 
  u32 td_offset ;
  u32 td_cmd ;
  u32 maclen ;
  int tmp ;
  u32 tmp___0 ;

  {
  td_offset = 0U;
  td_cmd = 0U;
  td_cmd = 4U;
  tmp = skb_network_offset((struct sk_buff  const  *)skb);
  maclen = (u32 )tmp;
  if ((tx_flags & 4U) != 0U) {
    maclen = maclen + 4U;
  } else {

  }
  if ((unsigned int )skb->protocol == 1673U) {
    maclen = maclen - 2U;
    tmp___0 = i40e_fcoe_ctxt_eof((int )eof);
    td_cmd = (tmp___0 | td_cmd) | 128U;
    td_offset = td_offset | 98816U;
    pskb_trim(skb, skb->len - 8U);
  } else {

  }
  td_offset = (maclen >> 1) | td_offset;
  i40e_tx_map(tx_ring, skb, first, tx_flags, (int )hdr_len, td_cmd, td_offset);
  return;
}
}
__inline static int i40e_fcoe_set_skb_header(struct sk_buff *skb ) 
{ 
  __be16 protocol ;
  struct vlan_ethhdr *veth ;
  struct ethhdr *tmp ;

  {
  protocol = skb->protocol;
  skb_reset_mac_header(skb);
  skb->mac_len = 14U;
  if ((unsigned int )protocol == 129U) {
    tmp = eth_hdr((struct sk_buff  const  *)skb);
    veth = (struct vlan_ethhdr *)tmp;
    protocol = veth->h_vlan_encapsulated_proto;
    skb->mac_len = (unsigned int )skb->mac_len + 4U;
  } else {

  }
  if ((unsigned int )protocol != 5257U && (unsigned int )protocol != 1673U) {
    return (-22);
  } else {

  }
  skb_set_network_header(skb, (int const   )skb->mac_len);
  if ((unsigned int )protocol == 5257U) {
    return (0);
  } else {

  }
  skb_set_transport_header(skb, (int const   )((unsigned int )skb->mac_len + 14U));
  return (0);
}
}
static netdev_tx_t i40e_fcoe_xmit_frame(struct sk_buff *skb , struct net_device *netdev ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;
  struct i40e_ring *tx_ring ;
  struct i40e_tx_buffer *first ;
  u32 tx_flags ;
  u8 hdr_len ;
  u8 sof ;
  u8 eof ;
  int fso ;
    klee_make_symbolic(&fso, sizeof(int), "fso");
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;

  {
  tmp = netdev_priv((struct net_device  const  *)skb->dev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  tx_ring = *(vsi->tx_rings + (unsigned long )skb->queue_mapping);
  tx_flags = 0U;
  hdr_len = 0U;
  sof = 0U;
  eof = 0U;
  tmp___0 = i40e_fcoe_set_skb_header(skb);
  if (tmp___0 != 0) {
    goto out_drop;
  } else {

  }
  tmp___1 = i40e_xmit_descriptor_count(skb, tx_ring);
  if (tmp___1 == 0) {
    return (16);
  } else {

  }
  tmp___2 = i40e_tx_prepare_vlan_flags(skb, tx_ring, & tx_flags);
  if (tmp___2 != 0) {
    goto out_drop;
  } else {

  }
  first = tx_ring->__annonCompField121.tx_bi + (unsigned long )tx_ring->next_to_use;
  if ((unsigned int )skb->protocol == 5257U) {
    goto out_send;
  } else {

  }
  tmp___3 = i40e_fcoe_fc_sof(skb, & sof);
  if (tmp___3 != 0) {
    netdev_err((struct net_device  const  *)netdev, "SOF/EOF error:%02x - %02x\n",
               (int )sof, (int )eof);
    goto out_drop;
  } else {
    tmp___4 = i40e_fcoe_fc_eof(skb, & eof);
    if (tmp___4 != 0) {
      netdev_err((struct net_device  const  *)netdev, "SOF/EOF error:%02x - %02x\n",
                 (int )sof, (int )eof);
      goto out_drop;
    } else {

    }
  }
  tx_flags = tx_flags | 64U;
  fso = i40e_fcoe_tso(tx_ring, skb, tx_flags, & hdr_len, (int )sof);
  if (fso < 0) {
    goto out_drop;
  } else
  if (fso != 0) {
    tx_flags = tx_flags | 128U;
  } else {
    i40e_fcoe_handle_ddp(tx_ring, skb, (int )sof);
  }
  out_send: 
  i40e_fcoe_tx_map(tx_ring, skb, first, tx_flags, (int )hdr_len, (int )eof);
  i40e_maybe_stop_tx(tx_ring, 21);
  return (0);
  out_drop: 
  dev_kfree_skb_any(skb);
  return (0);
}
}
static int i40e_fcoe_change_mtu(struct net_device *netdev , int new_mtu ) 
{ 


  {
  netdev_warn((struct net_device  const  *)netdev, "MTU change is not supported on FCoE interfaces\n");
  return (-1);
}
}
static int i40e_fcoe_set_features(struct net_device *netdev , netdev_features_t features ) 
{ 
  struct i40e_netdev_priv *np ;
  void *tmp ;
  struct i40e_vsi *vsi ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  np = (struct i40e_netdev_priv *)tmp;
  vsi = np->vsi;
  if ((features & 256ULL) != 0ULL) {
    i40e_vlan_stripping_enable(vsi);
  } else {
    i40e_vlan_stripping_disable(vsi);
  }
  return (0);
}
}
static struct net_device_ops  const  i40e_fcoe_netdev_ops  = 
     {0, 0, & i40e_open, & i40e_close, & i40e_fcoe_xmit_frame, 0, 0, & i40e_set_rx_mode,
    & i40e_set_mac, & eth_validate_addr, & i40e_ioctl, 0, & i40e_fcoe_change_mtu,
    0, & i40e_tx_timeout, & i40e_get_netdev_stats_struct, 0, & i40e_vlan_rx_add_vid,
    & i40e_vlan_rx_kill_vid, & i40e_netpoll, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    & i40e_setup_tc, & i40e_fcoe_enable, & i40e_fcoe_disable, & i40e_fcoe_ddp_get,
    & i40e_fcoe_ddp_put, & i40e_fcoe_ddp_target, 0, 0, 0, 0, 0, 0, & i40e_fcoe_set_features,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static struct device_type fcoe_netdev_type  =    {"fcoe", 0, 0, 0, 0, 0};
void i40e_fcoe_config_netdev(struct net_device *netdev , struct i40e_vsi *vsi ) 
{ 
  struct i40e_hw *hw ;
  struct i40e_pf *pf ;
  u8 __constr_expr_0[6] ;
  __u8 __constr_expr_1[6] ;
  __u8 __constr_expr_2[6] ;

  {
  hw = & (vsi->back)->hw;
  pf = vsi->back;
  if ((unsigned int )vsi->type != 4U) {
    return;
  } else {

  }
  netdev->features = 896ULL;
  netdev->vlan_features = netdev->features;
  netdev->vlan_features = netdev->vlan_features & 0xfffffffffffffc7fULL;
  netdev->fcoe_ddp_xid = 2047U;
  netdev->features = netdev->features | 2686451712ULL;
  netdev->vlan_features = netdev->vlan_features | 2686451712ULL;
  netdev->hw_features = netdev->hw_features | netdev->features;
  netdev->priv_flags = netdev->priv_flags | 131072U;
  netdev->priv_flags = netdev->priv_flags | 524288U;
  strlcpy((char *)(& netdev->name), "fcoe%d", 15UL);
  netdev->mtu = 2158U;
  netdev->dev.parent = & (pf->pdev)->dev;
  netdev->dev.type = (struct device_type  const  *)(& fcoe_netdev_type);
  netdev->dev_port = 1U;
  i40e_add_filter(vsi, (u8 *)(& hw->mac.san_addr), 0, 0, 0);
  __constr_expr_0[0] = 14U;
  __constr_expr_0[1] = 252U;
  __constr_expr_0[2] = 0U;
  __constr_expr_0[3] = 255U;
  __constr_expr_0[4] = 255U;
  __constr_expr_0[5] = 254U;
  i40e_add_filter(vsi, (u8 *)(& __constr_expr_0), 0, 0, 0);
  __constr_expr_1[0] = 1U;
  __constr_expr_1[1] = 16U;
  __constr_expr_1[2] = 24U;
  __constr_expr_1[3] = 1U;
  __constr_expr_1[4] = 0U;
  __constr_expr_1[5] = 0U;
  i40e_add_filter(vsi, (u8 *)(& __constr_expr_1), 0, 0, 0);
  __constr_expr_2[0] = 1U;
  __constr_expr_2[1] = 16U;
  __constr_expr_2[2] = 24U;
  __constr_expr_2[3] = 1U;
  __constr_expr_2[4] = 0U;
  __constr_expr_2[5] = 1U;
  i40e_add_filter(vsi, (u8 *)(& __constr_expr_2), 0, 0, 0);
  ether_addr_copy(netdev->dev_addr, (u8 const   *)(& hw->mac.san_addr));
  ether_addr_copy((u8 *)(& netdev->perm_addr), (u8 const   *)(& hw->mac.san_addr));
  netdev->netdev_ops = & i40e_fcoe_netdev_ops;
  return;
}
}
void i40e_fcoe_vsi_setup(struct i40e_pf *pf ) 
{ 
  struct i40e_vsi *vsi ;
  u16 seid ;
  int i ;
  long tmp ;
  struct _ddebug descriptor ;
  long tmp___0 ;

  {
  if ((pf->flags & 2048ULL) == 0ULL) {
    return;
  } else {

  }
  tmp = ldv__builtin_expect((unsigned long )*(pf->vsi + (unsigned long )pf->lan_vsi) == (unsigned long )((struct i40e_vsi *)0),
                         0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_fcoe.c"),
                         "i" (1548), "i" (12UL));
    ldv_67998: ;
    goto ldv_67998;
  } else {

  }
  i = 0;
  goto ldv_68000;
  ldv_67999: 
  vsi = *(pf->vsi + (unsigned long )i);
  if ((unsigned long )vsi != (unsigned long )((struct i40e_vsi *)0) && (unsigned int )vsi->type == 4U) {
    dev_warn((struct device  const  *)(& (pf->pdev)->dev), "FCoE VSI already created\n");
    return;
  } else {

  }
  i = i + 1;
  ldv_68000: ;
  if ((int )pf->num_alloc_vsi > i) {
    goto ldv_67999;
  } else {

  }
  seid = (*(pf->vsi + (unsigned long )pf->lan_vsi))->seid;
  vsi = i40e_vsi_setup(pf, 4, (int )seid, 0U);
  if ((unsigned long )vsi != (unsigned long )((struct i40e_vsi *)0)) {
    descriptor.modname = "i40e";
    descriptor.function = "i40e_fcoe_vsi_setup";
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--32_7a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/11344/dscv_tempdir/dscv/ri/32_7a/drivers/net/ethernet/intel/i40e/i40e_fcoe.c";
    descriptor.format = "Successfully created FCoE VSI seid %d id %d uplink_seid %d PF seid %d\n";
    descriptor.lineno = 1564U;
    descriptor.flags = 0U;
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
    if (tmp___0 != 0L) {
      __dynamic_dev_dbg(& descriptor, (struct device  const  *)(& (pf->pdev)->dev),
                        "Successfully created FCoE VSI seid %d id %d uplink_seid %d PF seid %d\n",
                        (int )vsi->seid, (int )vsi->id, (int )vsi->uplink_seid, (int )seid);
    } else {

    }
  } else {
    _dev_info((struct device  const  *)(& (pf->pdev)->dev), "Failed to create FCoE VSI\n");
  }
  return;
}
}
extern int ldv_ndo_init_6(void) ;
int ldv_retval_0  ;
    klee_make_symbolic(&ldv_retval_0, sizeof(int), "ldv_retval_0");
extern int ldv_ndo_uninit_6(void) ;
int ldv_retval_1  ;
    klee_make_symbolic(&ldv_retval_1, sizeof(int), "ldv_retval_1");
void ldv_net_device_ops_6(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(3008UL);
  i40e_fcoe_netdev_ops_group1 = (struct net_device *)tmp;
  return;
}
}
void ldv_main_exported_6(void) 
{ 
  void *ldvarg2 ;
  void *tmp ;
  int ldvarg14 ;
    klee_make_symbolic(&ldvarg14, sizeof(int), "ldvarg14");
  unsigned int ldvarg4 ;
    klee_make_symbolic(&ldvarg4, sizeof(int), "ldvarg4");
  int ldvarg17 ;
    klee_make_symbolic(&ldvarg17, sizeof(int), "ldvarg17");
  u16 ldvarg15 ;
  u16 ldvarg6 ;
  struct sk_buff *ldvarg16 ;
  void *tmp___0 ;
  struct scatterlist *ldvarg5 ;
  void *tmp___1 ;
  struct rtnl_link_stats64 *ldvarg0 ;
  void *tmp___2 ;
  u16 ldvarg9 ;
  u16 ldvarg10 ;
  __be16 ldvarg13 ;
  u8 ldvarg1 ;
  struct scatterlist *ldvarg8 ;
  void *tmp___3 ;
  u16 ldvarg12 ;
  netdev_features_t ldvarg3 ;
  unsigned int ldvarg7 ;
    klee_make_symbolic(&ldvarg7, sizeof(int), "ldvarg7");
  __be16 ldvarg11 ;
  struct ifreq *ldvarg18 ;
  void *tmp___4 ;
  int tmp___5 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg2 = tmp;
  tmp___0 = ldv_init_zalloc(232UL);
  ldvarg16 = (struct sk_buff *)tmp___0;
  tmp___1 = ldv_init_zalloc(40UL);
  ldvarg5 = (struct scatterlist *)tmp___1;
  tmp___2 = ldv_init_zalloc(184UL);
  ldvarg0 = (struct rtnl_link_stats64 *)tmp___2;
  tmp___3 = ldv_init_zalloc(40UL);
  ldvarg8 = (struct scatterlist *)tmp___3;
  tmp___4 = ldv_init_zalloc(40UL);
  ldvarg18 = (struct ifreq *)tmp___4;
  ldv_memset((void *)(& ldvarg14), 0, 4UL);
  ldv_memset((void *)(& ldvarg4), 0, 4UL);
  ldv_memset((void *)(& ldvarg17), 0, 4UL);
  ldv_memset((void *)(& ldvarg15), 0, 2UL);
  ldv_memset((void *)(& ldvarg6), 0, 2UL);
  ldv_memset((void *)(& ldvarg9), 0, 2UL);
  ldv_memset((void *)(& ldvarg10), 0, 2UL);
  ldv_memset((void *)(& ldvarg13), 0, 2UL);
  ldv_memset((void *)(& ldvarg1), 0, 1UL);
  ldv_memset((void *)(& ldvarg12), 0, 2UL);
  ldv_memset((void *)(& ldvarg3), 0, 8UL);
  ldv_memset((void *)(& ldvarg7), 0, 4UL);
  ldv_memset((void *)(& ldvarg11), 0, 2UL);
  tmp___5 = __VERIFIER_nondet_int();
  switch (tmp___5) {
  case 0: ;
  if (ldv_state_variable_6 == 1) {
    i40e_ioctl(i40e_fcoe_netdev_ops_group1, ldvarg18, ldvarg17);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_ioctl(i40e_fcoe_netdev_ops_group1, ldvarg18, ldvarg17);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_ioctl(i40e_fcoe_netdev_ops_group1, ldvarg18, ldvarg17);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 1: ;
  if (ldv_state_variable_6 == 2) {
    ldv_retval_1 = i40e_open(i40e_fcoe_netdev_ops_group1);
    if (ldv_retval_1 == 0) {
      ldv_state_variable_6 = 3;
    } else {

    }
  } else {

  }
  goto ldv_68036;
  case 2: ;
  if (ldv_state_variable_6 == 3) {
    i40e_fcoe_xmit_frame(ldvarg16, i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 3;
  } else {

  }
  goto ldv_68036;
  case 3: ;
  if (ldv_state_variable_6 == 3) {
    i40e_close(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 4: ;
  if (ldv_state_variable_6 == 1) {
    i40e_set_rx_mode(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_set_rx_mode(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_set_rx_mode(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 5: ;
  if (ldv_state_variable_6 == 1) {
    eth_validate_addr(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    eth_validate_addr(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    eth_validate_addr(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 6: ;
  if (ldv_state_variable_6 == 1) {
    i40e_fcoe_ddp_put(i40e_fcoe_netdev_ops_group1, (int )ldvarg15);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_fcoe_ddp_put(i40e_fcoe_netdev_ops_group1, (int )ldvarg15);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_fcoe_ddp_put(i40e_fcoe_netdev_ops_group1, (int )ldvarg15);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 7: ;
  if (ldv_state_variable_6 == 3) {
    i40e_fcoe_change_mtu(i40e_fcoe_netdev_ops_group1, ldvarg14);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_fcoe_change_mtu(i40e_fcoe_netdev_ops_group1, ldvarg14);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 8: ;
  if (ldv_state_variable_6 == 1) {
    i40e_vlan_rx_kill_vid(i40e_fcoe_netdev_ops_group1, (int )ldvarg13, (int )ldvarg12);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_vlan_rx_kill_vid(i40e_fcoe_netdev_ops_group1, (int )ldvarg13, (int )ldvarg12);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_vlan_rx_kill_vid(i40e_fcoe_netdev_ops_group1, (int )ldvarg13, (int )ldvarg12);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 9: ;
  if (ldv_state_variable_6 == 1) {
    i40e_vlan_rx_add_vid(i40e_fcoe_netdev_ops_group1, (int )ldvarg11, (int )ldvarg10);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_vlan_rx_add_vid(i40e_fcoe_netdev_ops_group1, (int )ldvarg11, (int )ldvarg10);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_vlan_rx_add_vid(i40e_fcoe_netdev_ops_group1, (int )ldvarg11, (int )ldvarg10);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 10: ;
  if (ldv_state_variable_6 == 1) {
    i40e_fcoe_ddp_target(i40e_fcoe_netdev_ops_group1, (int )ldvarg9, ldvarg8, ldvarg7);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_fcoe_ddp_target(i40e_fcoe_netdev_ops_group1, (int )ldvarg9, ldvarg8, ldvarg7);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_fcoe_ddp_target(i40e_fcoe_netdev_ops_group1, (int )ldvarg9, ldvarg8, ldvarg7);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 11: ;
  if (ldv_state_variable_6 == 1) {
    i40e_fcoe_enable(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_fcoe_enable(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_fcoe_enable(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 12: ;
  if (ldv_state_variable_6 == 1) {
    i40e_fcoe_ddp_get(i40e_fcoe_netdev_ops_group1, (int )ldvarg6, ldvarg5, ldvarg4);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_fcoe_ddp_get(i40e_fcoe_netdev_ops_group1, (int )ldvarg6, ldvarg5, ldvarg4);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_fcoe_ddp_get(i40e_fcoe_netdev_ops_group1, (int )ldvarg6, ldvarg5, ldvarg4);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 13: ;
  if (ldv_state_variable_6 == 1) {
    i40e_netpoll(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_netpoll(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_netpoll(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 14: ;
  if (ldv_state_variable_6 == 1) {
    i40e_fcoe_set_features(i40e_fcoe_netdev_ops_group1, ldvarg3);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_fcoe_set_features(i40e_fcoe_netdev_ops_group1, ldvarg3);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_fcoe_set_features(i40e_fcoe_netdev_ops_group1, ldvarg3);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 15: ;
  if (ldv_state_variable_6 == 1) {
    i40e_fcoe_disable(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_fcoe_disable(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_fcoe_disable(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 16: ;
  if (ldv_state_variable_6 == 1) {
    i40e_set_mac(i40e_fcoe_netdev_ops_group1, ldvarg2);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_set_mac(i40e_fcoe_netdev_ops_group1, ldvarg2);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_set_mac(i40e_fcoe_netdev_ops_group1, ldvarg2);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 17: ;
  if (ldv_state_variable_6 == 1) {
    i40e_setup_tc(i40e_fcoe_netdev_ops_group1, (int )ldvarg1);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_setup_tc(i40e_fcoe_netdev_ops_group1, (int )ldvarg1);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_setup_tc(i40e_fcoe_netdev_ops_group1, (int )ldvarg1);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 18: ;
  if (ldv_state_variable_6 == 1) {
    i40e_get_netdev_stats_struct(i40e_fcoe_netdev_ops_group1, ldvarg0);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_get_netdev_stats_struct(i40e_fcoe_netdev_ops_group1, ldvarg0);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_get_netdev_stats_struct(i40e_fcoe_netdev_ops_group1, ldvarg0);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 19: ;
  if (ldv_state_variable_6 == 1) {
    i40e_tx_timeout(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 1;
  } else {

  }
  if (ldv_state_variable_6 == 3) {
    i40e_tx_timeout(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 3;
  } else {

  }
  if (ldv_state_variable_6 == 2) {
    i40e_tx_timeout(i40e_fcoe_netdev_ops_group1);
    ldv_state_variable_6 = 2;
  } else {

  }
  goto ldv_68036;
  case 20: ;
  if (ldv_state_variable_6 == 1) {
    ldv_retval_0 = ldv_ndo_init_6();
    if (ldv_retval_0 == 0) {
      ldv_state_variable_6 = 2;
      ref_cnt = ref_cnt + 1;
    } else {

    }
  } else {

  }
  goto ldv_68036;
  case 21: ;
  if (ldv_state_variable_6 == 2) {
    ldv_ndo_uninit_6();
    ldv_state_variable_6 = 1;
    ref_cnt = ref_cnt - 1;
  } else {

  }
  goto ldv_68036;
  default: 
  ldv_stop();
  }
  ldv_68036: ;
  return;
}
}
bool ldv_queue_work_on_489(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_490(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_491(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_4(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_492(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_4(2);
  return;
}
}
bool ldv_queue_delayed_work_on_493(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_4(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void ldv_mutex_lock_494(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_lock(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_495(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_lock(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_496(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
int ldv_mutex_trylock_497(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = mutex_trylock(ldv_func_arg1);
  ldv_func_res = tmp;
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
  return (tmp___0);
  return (ldv_func_res);
}
}
void ldv_mutex_unlock_498(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_unlock_499(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode(ldv_func_arg1);
  mutex_unlock(ldv_func_arg1);
  return;
}
}
void ldv_mutex_lock_500(struct mutex *ldv_func_arg1 ) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode(ldv_func_arg1);
  mutex_lock(ldv_func_arg1);
  return;
}
}
__inline static void ldv_error(void) 
{ 


  {
  ERROR: ;
  {reach_error();}
}
}
__inline static int ldv_undef_int_negative(void) 
{ 
  int ret ;
  int tmp ;

  {
  tmp = ldv_undef_int();
  ret = tmp;
  if (ret >= 0) {
    ldv_stop();
  } else {

  }
  return (ret);
}
}
bool ldv_is_err(void const   *ptr ) 
{ 


  {
  return ((unsigned long )ptr > 2012UL);
}
}
void *ldv_err_ptr(long error ) 
{ 


  {
  return ((void *)(2012L - error));
}
}
long ldv_ptr_err(void const   *ptr ) 
{ 


  {
  return ((long )(2012UL - (unsigned long )ptr));
}
}
bool ldv_is_err_or_null(void const   *ptr ) 
{ 
  bool tmp ;
  int tmp___0 ;

  {
  if ((unsigned long )ptr == (unsigned long )((void const   *)0)) {
    tmp___0 = 1;
  } else {
    tmp = ldv_is_err(ptr);
    if ((int )tmp) {
      tmp___0 = 1;
    } else {
      tmp___0 = 0;
    }
  }
  return ((bool )tmp___0);
}
}
static int ldv_mutex_arq_mutex_of_i40e_adminq_info  =    1;
int ldv_mutex_lock_interruptible_arq_mutex_of_i40e_adminq_info(struct mutex *lock ) 
{ 
  int nondetermined ;
    klee_make_symbolic(&nondetermined, sizeof(int), "nondetermined");

  {
  if (ldv_mutex_arq_mutex_of_i40e_adminq_info != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_arq_mutex_of_i40e_adminq_info = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_arq_mutex_of_i40e_adminq_info(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_arq_mutex_of_i40e_adminq_info != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_arq_mutex_of_i40e_adminq_info = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_arq_mutex_of_i40e_adminq_info(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_arq_mutex_of_i40e_adminq_info != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_arq_mutex_of_i40e_adminq_info = 2;
  return;
}
}
int ldv_mutex_trylock_arq_mutex_of_i40e_adminq_info(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;
    klee_make_symbolic(&is_mutex_held_by_another_thread, sizeof(int), "is_mutex_held_by_another_thread");

  {
  if (ldv_mutex_arq_mutex_of_i40e_adminq_info != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_arq_mutex_of_i40e_adminq_info = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_arq_mutex_of_i40e_adminq_info(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;
    klee_make_symbolic(&atomic_value_after_dec, sizeof(int), "atomic_value_after_dec");

  {
  if (ldv_mutex_arq_mutex_of_i40e_adminq_info != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_arq_mutex_of_i40e_adminq_info = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_arq_mutex_of_i40e_adminq_info(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_arq_mutex_of_i40e_adminq_info == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_arq_mutex_of_i40e_adminq_info(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_arq_mutex_of_i40e_adminq_info != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_arq_mutex_of_i40e_adminq_info = 1;
  return;
}
}
void ldv_usb_lock_device_arq_mutex_of_i40e_adminq_info(void) 
{ 


  {
  ldv_mutex_lock_arq_mutex_of_i40e_adminq_info((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_arq_mutex_of_i40e_adminq_info(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_arq_mutex_of_i40e_adminq_info((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_arq_mutex_of_i40e_adminq_info(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_arq_mutex_of_i40e_adminq_info((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_arq_mutex_of_i40e_adminq_info(void) 
{ 


  {
  ldv_mutex_unlock_arq_mutex_of_i40e_adminq_info((struct mutex *)0);
  return;
}
}
static int ldv_mutex_asq_mutex_of_i40e_adminq_info  =    1;
int ldv_mutex_lock_interruptible_asq_mutex_of_i40e_adminq_info(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_asq_mutex_of_i40e_adminq_info != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_asq_mutex_of_i40e_adminq_info = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_asq_mutex_of_i40e_adminq_info(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_asq_mutex_of_i40e_adminq_info != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_asq_mutex_of_i40e_adminq_info = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_asq_mutex_of_i40e_adminq_info(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_asq_mutex_of_i40e_adminq_info != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_asq_mutex_of_i40e_adminq_info = 2;
  return;
}
}
int ldv_mutex_trylock_asq_mutex_of_i40e_adminq_info(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
  if (ldv_mutex_asq_mutex_of_i40e_adminq_info != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_asq_mutex_of_i40e_adminq_info = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_asq_mutex_of_i40e_adminq_info(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
  if (ldv_mutex_asq_mutex_of_i40e_adminq_info != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_asq_mutex_of_i40e_adminq_info = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_asq_mutex_of_i40e_adminq_info(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_asq_mutex_of_i40e_adminq_info == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_asq_mutex_of_i40e_adminq_info(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_asq_mutex_of_i40e_adminq_info != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_asq_mutex_of_i40e_adminq_info = 1;
  return;
}
}
void ldv_usb_lock_device_asq_mutex_of_i40e_adminq_info(void) 
{ 


  {
  ldv_mutex_lock_asq_mutex_of_i40e_adminq_info((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_asq_mutex_of_i40e_adminq_info(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_asq_mutex_of_i40e_adminq_info((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_asq_mutex_of_i40e_adminq_info(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_asq_mutex_of_i40e_adminq_info((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_asq_mutex_of_i40e_adminq_info(void) 
{ 


  {
  ldv_mutex_unlock_asq_mutex_of_i40e_adminq_info((struct mutex *)0);
  return;
}
}
static int ldv_mutex_i_mutex_of_inode  =    1;
int ldv_mutex_lock_interruptible_i_mutex_of_inode(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_i_mutex_of_inode != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_i_mutex_of_inode = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_i_mutex_of_inode(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_i_mutex_of_inode != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_i_mutex_of_inode = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_i_mutex_of_inode(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_i_mutex_of_inode != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_i_mutex_of_inode = 2;
  return;
}
}
int ldv_mutex_trylock_i_mutex_of_inode(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
  if (ldv_mutex_i_mutex_of_inode != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_i_mutex_of_inode = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_i_mutex_of_inode(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
  if (ldv_mutex_i_mutex_of_inode != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_i_mutex_of_inode = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_i_mutex_of_inode(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_i_mutex_of_inode == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_i_mutex_of_inode(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_i_mutex_of_inode != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_i_mutex_of_inode = 1;
  return;
}
}
void ldv_usb_lock_device_i_mutex_of_inode(void) 
{ 


  {
  ldv_mutex_lock_i_mutex_of_inode((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_i_mutex_of_inode(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_i_mutex_of_inode((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_i_mutex_of_inode(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_i_mutex_of_inode((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_i_mutex_of_inode(void) 
{ 


  {
  ldv_mutex_unlock_i_mutex_of_inode((struct mutex *)0);
  return;
}
}
static int ldv_mutex_lock  =    1;
int ldv_mutex_lock_interruptible_lock(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_lock != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_lock = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_lock(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_lock != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_lock = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_lock(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_lock != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_lock = 2;
  return;
}
}
int ldv_mutex_trylock_lock(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
  if (ldv_mutex_lock != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_lock = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_lock(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
  if (ldv_mutex_lock != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_lock = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_lock(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_lock == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_lock(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_lock != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_lock = 1;
  return;
}
}
void ldv_usb_lock_device_lock(void) 
{ 


  {
  ldv_mutex_lock_lock((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_lock(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_lock((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_lock(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_lock((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_lock(void) 
{ 


  {
  ldv_mutex_unlock_lock((struct mutex *)0);
  return;
}
}
static int ldv_mutex_mutex_of_device  =    1;
int ldv_mutex_lock_interruptible_mutex_of_device(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_mutex_of_device != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_mutex_of_device = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_mutex_of_device(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_mutex_of_device != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_mutex_of_device = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_mutex_of_device(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_mutex_of_device != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_mutex_of_device = 2;
  return;
}
}
int ldv_mutex_trylock_mutex_of_device(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
  if (ldv_mutex_mutex_of_device != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_mutex_of_device = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_mutex_of_device(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
  if (ldv_mutex_mutex_of_device != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_mutex_of_device = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_mutex_of_device(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_mutex_of_device == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_mutex_of_device(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_mutex_of_device != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_mutex_of_device = 1;
  return;
}
}
void ldv_usb_lock_device_mutex_of_device(void) 
{ 


  {
  ldv_mutex_lock_mutex_of_device((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_mutex_of_device(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_mutex_of_device((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_mutex_of_device(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_mutex_of_device((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_mutex_of_device(void) 
{ 


  {
  ldv_mutex_unlock_mutex_of_device((struct mutex *)0);
  return;
}
}
static int ldv_mutex_switch_mutex_of_i40e_pf  =    1;
int ldv_mutex_lock_interruptible_switch_mutex_of_i40e_pf(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_switch_mutex_of_i40e_pf != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_switch_mutex_of_i40e_pf = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
int ldv_mutex_lock_killable_switch_mutex_of_i40e_pf(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_switch_mutex_of_i40e_pf != 1) {
    ldv_error();
  } else {

  }
  nondetermined = ldv_undef_int();
  if (nondetermined != 0) {
    ldv_mutex_switch_mutex_of_i40e_pf = 2;
    return (0);
  } else {
    return (-4);
  }
}
}
void ldv_mutex_lock_switch_mutex_of_i40e_pf(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_switch_mutex_of_i40e_pf != 1) {
    ldv_error();
  } else {

  }
  ldv_mutex_switch_mutex_of_i40e_pf = 2;
  return;
}
}
int ldv_mutex_trylock_switch_mutex_of_i40e_pf(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
  if (ldv_mutex_switch_mutex_of_i40e_pf != 1) {
    ldv_error();
  } else {

  }
  is_mutex_held_by_another_thread = ldv_undef_int();
  if (is_mutex_held_by_another_thread != 0) {
    return (0);
  } else {
    ldv_mutex_switch_mutex_of_i40e_pf = 2;
    return (1);
  }
}
}
int ldv_atomic_dec_and_mutex_lock_switch_mutex_of_i40e_pf(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
  if (ldv_mutex_switch_mutex_of_i40e_pf != 1) {
    ldv_error();
  } else {

  }
  atomic_value_after_dec = ldv_undef_int();
  if (atomic_value_after_dec == 0) {
    ldv_mutex_switch_mutex_of_i40e_pf = 2;
    return (1);
  } else {

  }
  return (0);
}
}
int ldv_mutex_is_locked_switch_mutex_of_i40e_pf(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
  if (ldv_mutex_switch_mutex_of_i40e_pf == 1) {
    nondetermined = ldv_undef_int();
    if (nondetermined != 0) {
      return (0);
    } else {
      return (1);
    }
  } else {
    return (1);
  }
}
}
void ldv_mutex_unlock_switch_mutex_of_i40e_pf(struct mutex *lock ) 
{ 


  {
  if (ldv_mutex_switch_mutex_of_i40e_pf != 2) {
    ldv_error();
  } else {

  }
  ldv_mutex_switch_mutex_of_i40e_pf = 1;
  return;
}
}
void ldv_usb_lock_device_switch_mutex_of_i40e_pf(void) 
{ 


  {
  ldv_mutex_lock_switch_mutex_of_i40e_pf((struct mutex *)0);
  return;
}
}
int ldv_usb_trylock_device_switch_mutex_of_i40e_pf(void) 
{ 
  int tmp ;

  {
  tmp = ldv_mutex_trylock_switch_mutex_of_i40e_pf((struct mutex *)0);
  return (tmp);
}
}
int ldv_usb_lock_device_for_reset_switch_mutex_of_i40e_pf(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp___0 = ldv_undef_int();
  if (tmp___0 != 0) {
    ldv_mutex_lock_switch_mutex_of_i40e_pf((struct mutex *)0);
    return (0);
  } else {
    tmp = ldv_undef_int_negative();
    return (tmp);
  }
}
}
void ldv_usb_unlock_device_switch_mutex_of_i40e_pf(void) 
{ 


  {
  ldv_mutex_unlock_switch_mutex_of_i40e_pf((struct mutex *)0);
  return;
}
}
void ldv_check_final_state(void) 
{ 


  {
  if (ldv_mutex_arq_mutex_of_i40e_adminq_info != 1) {
    ldv_error();
  } else {

  }
  if (ldv_mutex_asq_mutex_of_i40e_adminq_info != 1) {
    ldv_error();
  } else {

  }
  if (ldv_mutex_i_mutex_of_inode != 1) {
    ldv_error();
  } else {

  }
  if (ldv_mutex_lock != 1) {
    ldv_error();
  } else {

  }
  if (ldv_mutex_mutex_of_device != 1) {
    ldv_error();
  } else {

  }
  if (ldv_mutex_switch_mutex_of_i40e_pf != 1) {
    ldv_error();
  } else {

  }
  return;
}
}
#include "model/linux-4.2-rc1.tar.xz-32_7a-drivers--net--ethernet--intel--i40e--i40e.ko-entry_point_true-unreach-call.cil.out.env.c"
#include <klee/klee.h>
#include "model/common.env.c"
