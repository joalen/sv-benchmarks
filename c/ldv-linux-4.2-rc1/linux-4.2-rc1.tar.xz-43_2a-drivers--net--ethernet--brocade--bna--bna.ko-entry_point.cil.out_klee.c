extern void abort(void);
#include <assert.h>
void reach_error() { assert(0); }
/* Generated by CIL v. 1.5.1 */
/* print_CIL_Input is false */

typedef unsigned char __u8;
    klee_make_symbolic(&__u8, sizeof(char), "__u8");
typedef short __s16;
    klee_make_symbolic(&__s16, sizeof(short), "__s16");
typedef unsigned short __u16;
    klee_make_symbolic(&__u16, sizeof(short), "__u16");
typedef int __s32;
    klee_make_symbolic(&__s32, sizeof(int), "__s32");
typedef unsigned int __u32;
    klee_make_symbolic(&__u32, sizeof(int), "__u32");
typedef unsigned long long __u64;
    klee_make_symbolic(&__u64, sizeof(long), "__u64");
typedef signed char s8;
    klee_make_symbolic(&s8, sizeof(char), "s8");
typedef unsigned char u8;
    klee_make_symbolic(&u8, sizeof(char), "u8");
typedef unsigned short u16;
    klee_make_symbolic(&u16, sizeof(short), "u16");
typedef int s32;
    klee_make_symbolic(&s32, sizeof(int), "s32");
typedef unsigned int u32;
    klee_make_symbolic(&u32, sizeof(int), "u32");
typedef long long s64;
    klee_make_symbolic(&s64, sizeof(long), "s64");
typedef unsigned long long u64;
    klee_make_symbolic(&u64, sizeof(long), "u64");
typedef long __kernel_long_t;
    klee_make_symbolic(&__kernel_long_t, sizeof(long), "__kernel_long_t");
typedef unsigned long __kernel_ulong_t;
    klee_make_symbolic(&__kernel_ulong_t, sizeof(long), "__kernel_ulong_t");
typedef int __kernel_pid_t;
    klee_make_symbolic(&__kernel_pid_t, sizeof(int), "__kernel_pid_t");
typedef unsigned int __kernel_uid32_t;
    klee_make_symbolic(&__kernel_uid32_t, sizeof(int), "__kernel_uid32_t");
typedef unsigned int __kernel_gid32_t;
    klee_make_symbolic(&__kernel_gid32_t, sizeof(int), "__kernel_gid32_t");
typedef __kernel_ulong_t __kernel_size_t;
typedef __kernel_long_t __kernel_ssize_t;
typedef long long __kernel_loff_t;
    klee_make_symbolic(&__kernel_loff_t, sizeof(long), "__kernel_loff_t");
typedef __kernel_long_t __kernel_time_t;
typedef __kernel_long_t __kernel_clock_t;
typedef int __kernel_timer_t;
    klee_make_symbolic(&__kernel_timer_t, sizeof(int), "__kernel_timer_t");
typedef int __kernel_clockid_t;
    klee_make_symbolic(&__kernel_clockid_t, sizeof(int), "__kernel_clockid_t");
typedef __u16 __be16;
typedef __u32 __be32;
typedef __u16 __sum16;
typedef __u32 __wsum;
struct kernel_symbol {
   unsigned long value ;
    klee_make_symbolic(&value, sizeof(long), "value");
   char const   *name ;
};
struct module;
typedef __u32 __kernel_dev_t;
typedef __kernel_dev_t dev_t;
typedef unsigned short umode_t;
    klee_make_symbolic(&umode_t, sizeof(short), "umode_t");
typedef __kernel_pid_t pid_t;
typedef __kernel_clockid_t clockid_t;
typedef _Bool bool;
typedef __kernel_uid32_t uid_t;
typedef __kernel_gid32_t gid_t;
typedef __kernel_loff_t loff_t;
typedef __kernel_size_t size_t;
typedef __kernel_ssize_t ssize_t;
typedef __kernel_time_t time_t;
typedef unsigned int uint;
    klee_make_symbolic(&uint, sizeof(int), "uint");
typedef __s32 int32_t;
typedef __u8 uint8_t;
typedef __u32 uint32_t;
typedef __u64 uint64_t;
typedef unsigned long sector_t;
    klee_make_symbolic(&sector_t, sizeof(long), "sector_t");
typedef unsigned long blkcnt_t;
    klee_make_symbolic(&blkcnt_t, sizeof(long), "blkcnt_t");
typedef u64 dma_addr_t;
typedef unsigned int gfp_t;
    klee_make_symbolic(&gfp_t, sizeof(int), "gfp_t");
typedef unsigned int fmode_t;
    klee_make_symbolic(&fmode_t, sizeof(int), "fmode_t");
typedef unsigned int oom_flags_t;
    klee_make_symbolic(&oom_flags_t, sizeof(int), "oom_flags_t");
typedef u64 phys_addr_t;
typedef phys_addr_t resource_size_t;
struct __anonstruct_atomic_t_6 {
   int counter ;
    klee_make_symbolic(&counter, sizeof(int), "counter");
};
typedef struct __anonstruct_atomic_t_6 atomic_t;
struct __anonstruct_atomic64_t_7 {
   long counter ;
};
typedef struct __anonstruct_atomic64_t_7 atomic64_t;
struct list_head {
   struct list_head *next ;
   struct list_head *prev ;
};
struct hlist_node;
struct hlist_head {
   struct hlist_node *first ;
};
struct hlist_node {
   struct hlist_node *next ;
   struct hlist_node **pprev ;
};
struct callback_head {
   struct callback_head *next ;
   void (*func)(struct callback_head * ) ;
};
struct pt_regs {
   unsigned long r15 ;
    klee_make_symbolic(&r15, sizeof(long), "r15");
   unsigned long r14 ;
    klee_make_symbolic(&r14, sizeof(long), "r14");
   unsigned long r13 ;
    klee_make_symbolic(&r13, sizeof(long), "r13");
   unsigned long r12 ;
    klee_make_symbolic(&r12, sizeof(long), "r12");
   unsigned long bp ;
    klee_make_symbolic(&bp, sizeof(long), "bp");
   unsigned long bx ;
    klee_make_symbolic(&bx, sizeof(long), "bx");
   unsigned long r11 ;
    klee_make_symbolic(&r11, sizeof(long), "r11");
   unsigned long r10 ;
    klee_make_symbolic(&r10, sizeof(long), "r10");
   unsigned long r9 ;
    klee_make_symbolic(&r9, sizeof(long), "r9");
   unsigned long r8 ;
    klee_make_symbolic(&r8, sizeof(long), "r8");
   unsigned long ax ;
    klee_make_symbolic(&ax, sizeof(long), "ax");
   unsigned long cx ;
    klee_make_symbolic(&cx, sizeof(long), "cx");
   unsigned long dx ;
    klee_make_symbolic(&dx, sizeof(long), "dx");
   unsigned long si ;
    klee_make_symbolic(&si, sizeof(long), "si");
   unsigned long di ;
    klee_make_symbolic(&di, sizeof(long), "di");
   unsigned long orig_ax ;
    klee_make_symbolic(&orig_ax, sizeof(long), "orig_ax");
   unsigned long ip ;
    klee_make_symbolic(&ip, sizeof(long), "ip");
   unsigned long cs ;
    klee_make_symbolic(&cs, sizeof(long), "cs");
   unsigned long flags ;
    klee_make_symbolic(&flags, sizeof(long), "flags");
   unsigned long sp ;
    klee_make_symbolic(&sp, sizeof(long), "sp");
   unsigned long ss ;
    klee_make_symbolic(&ss, sizeof(long), "ss");
};
struct __anonstruct____missing_field_name_9 {
   unsigned int a ;
    klee_make_symbolic(&a, sizeof(int), "a");
   unsigned int b ;
    klee_make_symbolic(&b, sizeof(int), "b");
};
struct __anonstruct____missing_field_name_10 {
   u16 limit0 ;
   u16 base0 ;
   unsigned char base1 ;
    klee_make_symbolic(&base1, sizeof(char), "base1");
   unsigned char type : 4 ;
   unsigned char s : 1 ;
   unsigned char dpl : 2 ;
   unsigned char p : 1 ;
   unsigned char limit : 4 ;
   unsigned char avl : 1 ;
   unsigned char l : 1 ;
   unsigned char d : 1 ;
   unsigned char g : 1 ;
   unsigned char base2 ;
    klee_make_symbolic(&base2, sizeof(char), "base2");
};
union __anonunion____missing_field_name_8 {
   struct __anonstruct____missing_field_name_9 __annonCompField4 ;
   struct __anonstruct____missing_field_name_10 __annonCompField5 ;
};
struct desc_struct {
   union __anonunion____missing_field_name_8 __annonCompField6 ;
};
typedef unsigned long pteval_t;
    klee_make_symbolic(&pteval_t, sizeof(long), "pteval_t");
typedef unsigned long pgdval_t;
    klee_make_symbolic(&pgdval_t, sizeof(long), "pgdval_t");
typedef unsigned long pgprotval_t;
    klee_make_symbolic(&pgprotval_t, sizeof(long), "pgprotval_t");
struct __anonstruct_pte_t_11 {
   pteval_t pte ;
};
typedef struct __anonstruct_pte_t_11 pte_t;
struct pgprot {
   pgprotval_t pgprot ;
};
typedef struct pgprot pgprot_t;
struct __anonstruct_pgd_t_12 {
   pgdval_t pgd ;
};
typedef struct __anonstruct_pgd_t_12 pgd_t;
struct page;
typedef struct page *pgtable_t;
struct file;
struct seq_file;
struct thread_struct;
struct mm_struct;
struct task_struct;
struct cpumask;
struct qspinlock {
   atomic_t val ;
};
typedef struct qspinlock arch_spinlock_t;
struct qrwlock {
   atomic_t cnts ;
   arch_spinlock_t lock ;
};
typedef struct qrwlock arch_rwlock_t;
typedef void (*ctor_fn_t)(void);
struct device;
struct net_device;
struct file_operations;
struct completion;
struct bug_entry {
   int bug_addr_disp ;
    klee_make_symbolic(&bug_addr_disp, sizeof(int), "bug_addr_disp");
   int file_disp ;
    klee_make_symbolic(&file_disp, sizeof(int), "file_disp");
   unsigned short line ;
    klee_make_symbolic(&line, sizeof(short), "line");
   unsigned short flags ;
};
struct timespec;
struct compat_timespec;
struct __anonstruct_futex_16 {
   u32 *uaddr ;
   u32 val ;
   u32 flags ;
   u32 bitset ;
   u64 time ;
   u32 *uaddr2 ;
};
struct __anonstruct_nanosleep_17 {
   clockid_t clockid ;
   struct timespec *rmtp ;
   struct compat_timespec *compat_rmtp ;
   u64 expires ;
};
struct pollfd;
struct __anonstruct_poll_18 {
   struct pollfd *ufds ;
   int nfds ;
    klee_make_symbolic(&nfds, sizeof(int), "nfds");
   int has_timeout ;
    klee_make_symbolic(&has_timeout, sizeof(int), "has_timeout");
   unsigned long tv_sec ;
    klee_make_symbolic(&tv_sec, sizeof(long), "tv_sec");
   unsigned long tv_nsec ;
    klee_make_symbolic(&tv_nsec, sizeof(long), "tv_nsec");
};
union __anonunion____missing_field_name_15 {
   struct __anonstruct_futex_16 futex ;
   struct __anonstruct_nanosleep_17 nanosleep ;
   struct __anonstruct_poll_18 poll ;
};
struct restart_block {
   long (*fn)(struct restart_block * ) ;
   union __anonunion____missing_field_name_15 __annonCompField7 ;
};
struct kernel_vm86_regs {
   struct pt_regs pt ;
   unsigned short es ;
    klee_make_symbolic(&es, sizeof(short), "es");
   unsigned short __esh ;
    klee_make_symbolic(&__esh, sizeof(short), "__esh");
   unsigned short ds ;
    klee_make_symbolic(&ds, sizeof(short), "ds");
   unsigned short __dsh ;
    klee_make_symbolic(&__dsh, sizeof(short), "__dsh");
   unsigned short fs ;
    klee_make_symbolic(&fs, sizeof(short), "fs");
   unsigned short __fsh ;
    klee_make_symbolic(&__fsh, sizeof(short), "__fsh");
   unsigned short gs ;
    klee_make_symbolic(&gs, sizeof(short), "gs");
   unsigned short __gsh ;
    klee_make_symbolic(&__gsh, sizeof(short), "__gsh");
};
union __anonunion____missing_field_name_19 {
   struct pt_regs *regs ;
   struct kernel_vm86_regs *vm86 ;
};
struct math_emu_info {
   long ___orig_eip ;
    klee_make_symbolic(&___orig_eip, sizeof(long), "___orig_eip");
   union __anonunion____missing_field_name_19 __annonCompField8 ;
};
struct cpumask {
   unsigned long bits[128U] ;
};
typedef struct cpumask cpumask_t;
typedef struct cpumask *cpumask_var_t;
struct fregs_state {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u32 status ;
};
struct __anonstruct____missing_field_name_29 {
   u64 rip ;
   u64 rdp ;
};
struct __anonstruct____missing_field_name_30 {
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
};
union __anonunion____missing_field_name_28 {
   struct __anonstruct____missing_field_name_29 __annonCompField12 ;
   struct __anonstruct____missing_field_name_30 __annonCompField13 ;
};
union __anonunion____missing_field_name_31 {
   u32 padding1[12U] ;
   u32 sw_reserved[12U] ;
};
struct fxregs_state {
   u16 cwd ;
   u16 swd ;
   u16 twd ;
   u16 fop ;
   union __anonunion____missing_field_name_28 __annonCompField14 ;
   u32 mxcsr ;
   u32 mxcsr_mask ;
   u32 st_space[32U] ;
   u32 xmm_space[64U] ;
   u32 padding[12U] ;
   union __anonunion____missing_field_name_31 __annonCompField15 ;
};
struct swregs_state {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u8 ftop ;
   u8 changed ;
   u8 lookahead ;
   u8 no_update ;
   u8 rm ;
   u8 alimit ;
   struct math_emu_info *info ;
   u32 entry_eip ;
};
struct xstate_header {
   u64 xfeatures ;
   u64 xcomp_bv ;
   u64 reserved[6U] ;
};
struct xregs_state {
   struct fxregs_state i387 ;
   struct xstate_header header ;
   u8 __reserved[464U] ;
};
union fpregs_state {
   struct fregs_state fsave ;
   struct fxregs_state fxsave ;
   struct swregs_state soft ;
   struct xregs_state xsave ;
};
struct fpu {
   union fpregs_state state ;
   unsigned int last_cpu ;
    klee_make_symbolic(&last_cpu, sizeof(int), "last_cpu");
   unsigned char fpstate_active ;
    klee_make_symbolic(&fpstate_active, sizeof(char), "fpstate_active");
   unsigned char fpregs_active ;
    klee_make_symbolic(&fpregs_active, sizeof(char), "fpregs_active");
   unsigned char counter ;
};
struct seq_operations;
struct perf_event;
struct thread_struct {
   struct desc_struct tls_array[3U] ;
   unsigned long sp0 ;
    klee_make_symbolic(&sp0, sizeof(long), "sp0");
   unsigned long sp ;
   unsigned short es ;
   unsigned short ds ;
   unsigned short fsindex ;
    klee_make_symbolic(&fsindex, sizeof(short), "fsindex");
   unsigned short gsindex ;
    klee_make_symbolic(&gsindex, sizeof(short), "gsindex");
   unsigned long fs ;
   unsigned long gs ;
   struct fpu fpu ;
   struct perf_event *ptrace_bps[4U] ;
   unsigned long debugreg6 ;
    klee_make_symbolic(&debugreg6, sizeof(long), "debugreg6");
   unsigned long ptrace_dr7 ;
    klee_make_symbolic(&ptrace_dr7, sizeof(long), "ptrace_dr7");
   unsigned long cr2 ;
    klee_make_symbolic(&cr2, sizeof(long), "cr2");
   unsigned long trap_nr ;
    klee_make_symbolic(&trap_nr, sizeof(long), "trap_nr");
   unsigned long error_code ;
    klee_make_symbolic(&error_code, sizeof(long), "error_code");
   unsigned long *io_bitmap_ptr ;
   unsigned long iopl ;
    klee_make_symbolic(&iopl, sizeof(long), "iopl");
   unsigned int io_bitmap_max ;
    klee_make_symbolic(&io_bitmap_max, sizeof(int), "io_bitmap_max");
};
typedef atomic64_t atomic_long_t;
struct lockdep_map;
struct stack_trace {
   unsigned int nr_entries ;
    klee_make_symbolic(&nr_entries, sizeof(int), "nr_entries");
   unsigned int max_entries ;
    klee_make_symbolic(&max_entries, sizeof(int), "max_entries");
   unsigned long *entries ;
   int skip ;
    klee_make_symbolic(&skip, sizeof(int), "skip");
};
struct lockdep_subclass_key {
   char __one_byte ;
    klee_make_symbolic(&__one_byte, sizeof(char), "__one_byte");
};
struct lock_class_key {
   struct lockdep_subclass_key subkeys[8U] ;
};
struct lock_class {
   struct list_head hash_entry ;
   struct list_head lock_entry ;
   struct lockdep_subclass_key *key ;
   unsigned int subclass ;
    klee_make_symbolic(&subclass, sizeof(int), "subclass");
   unsigned int dep_gen_id ;
    klee_make_symbolic(&dep_gen_id, sizeof(int), "dep_gen_id");
   unsigned long usage_mask ;
    klee_make_symbolic(&usage_mask, sizeof(long), "usage_mask");
   struct stack_trace usage_traces[13U] ;
   struct list_head locks_after ;
   struct list_head locks_before ;
   unsigned int version ;
    klee_make_symbolic(&version, sizeof(int), "version");
   unsigned long ops ;
    klee_make_symbolic(&ops, sizeof(long), "ops");
   char const   *name ;
   int name_version ;
    klee_make_symbolic(&name_version, sizeof(int), "name_version");
   unsigned long contention_point[4U] ;
   unsigned long contending_point[4U] ;
};
struct lockdep_map {
   struct lock_class_key *key ;
   struct lock_class *class_cache[2U] ;
   char const   *name ;
   int cpu ;
    klee_make_symbolic(&cpu, sizeof(int), "cpu");
   unsigned long ip ;
};
struct held_lock {
   u64 prev_chain_key ;
   unsigned long acquire_ip ;
    klee_make_symbolic(&acquire_ip, sizeof(long), "acquire_ip");
   struct lockdep_map *instance ;
   struct lockdep_map *nest_lock ;
   u64 waittime_stamp ;
   u64 holdtime_stamp ;
   unsigned short class_idx : 13 ;
   unsigned char irq_context : 2 ;
   unsigned char trylock : 1 ;
   unsigned char read : 2 ;
   unsigned char check : 1 ;
   unsigned char hardirqs_off : 1 ;
   unsigned short references : 12 ;
   unsigned int pin_count ;
    klee_make_symbolic(&pin_count, sizeof(int), "pin_count");
};
struct raw_spinlock {
   arch_spinlock_t raw_lock ;
   unsigned int magic ;
    klee_make_symbolic(&magic, sizeof(int), "magic");
   unsigned int owner_cpu ;
    klee_make_symbolic(&owner_cpu, sizeof(int), "owner_cpu");
   void *owner ;
   struct lockdep_map dep_map ;
};
typedef struct raw_spinlock raw_spinlock_t;
struct __anonstruct____missing_field_name_35 {
   u8 __padding[24U] ;
   struct lockdep_map dep_map ;
};
union __anonunion____missing_field_name_34 {
   struct raw_spinlock rlock ;
   struct __anonstruct____missing_field_name_35 __annonCompField17 ;
};
struct spinlock {
   union __anonunion____missing_field_name_34 __annonCompField18 ;
};
typedef struct spinlock spinlock_t;
struct __anonstruct_rwlock_t_36 {
   arch_rwlock_t raw_lock ;
   unsigned int magic ;
   unsigned int owner_cpu ;
   void *owner ;
   struct lockdep_map dep_map ;
};
typedef struct __anonstruct_rwlock_t_36 rwlock_t;
struct seqcount {
   unsigned int sequence ;
    klee_make_symbolic(&sequence, sizeof(int), "sequence");
   struct lockdep_map dep_map ;
};
typedef struct seqcount seqcount_t;
struct __anonstruct_seqlock_t_45 {
   struct seqcount seqcount ;
   spinlock_t lock ;
};
typedef struct __anonstruct_seqlock_t_45 seqlock_t;
struct timespec {
   __kernel_time_t tv_sec ;
   long tv_nsec ;
};
struct user_namespace;
struct __anonstruct_kuid_t_46 {
   uid_t val ;
};
typedef struct __anonstruct_kuid_t_46 kuid_t;
struct __anonstruct_kgid_t_47 {
   gid_t val ;
};
typedef struct __anonstruct_kgid_t_47 kgid_t;
struct kstat {
   u64 ino ;
   dev_t dev ;
   umode_t mode ;
   unsigned int nlink ;
    klee_make_symbolic(&nlink, sizeof(int), "nlink");
   kuid_t uid ;
   kgid_t gid ;
   dev_t rdev ;
   loff_t size ;
   struct timespec atime ;
   struct timespec mtime ;
   struct timespec ctime ;
   unsigned long blksize ;
    klee_make_symbolic(&blksize, sizeof(long), "blksize");
   unsigned long long blocks ;
    klee_make_symbolic(&blocks, sizeof(long), "blocks");
};
struct vm_area_struct;
struct __wait_queue_head {
   spinlock_t lock ;
   struct list_head task_list ;
};
typedef struct __wait_queue_head wait_queue_head_t;
struct __anonstruct_nodemask_t_48 {
   unsigned long bits[16U] ;
};
typedef struct __anonstruct_nodemask_t_48 nodemask_t;
struct optimistic_spin_queue {
   atomic_t tail ;
};
struct mutex {
   atomic_t count ;
   spinlock_t wait_lock ;
   struct list_head wait_list ;
   struct task_struct *owner ;
   void *magic ;
   struct lockdep_map dep_map ;
};
struct mutex_waiter {
   struct list_head list ;
   struct task_struct *task ;
   void *magic ;
};
struct rw_semaphore;
struct rw_semaphore {
   long count ;
    klee_make_symbolic(&count, sizeof(long), "count");
   struct list_head wait_list ;
   raw_spinlock_t wait_lock ;
   struct optimistic_spin_queue osq ;
   struct task_struct *owner ;
   struct lockdep_map dep_map ;
};
struct completion {
   unsigned int done ;
    klee_make_symbolic(&done, sizeof(int), "done");
   wait_queue_head_t wait ;
};
union ktime {
   s64 tv64 ;
};
typedef union ktime ktime_t;
struct notifier_block;
struct timer_list {
   struct hlist_node entry ;
   unsigned long expires ;
    klee_make_symbolic(&expires, sizeof(long), "expires");
   void (*function)(unsigned long  ) ;
   unsigned long data ;
    klee_make_symbolic(&data, sizeof(long), "data");
   u32 flags ;
   int slack ;
    klee_make_symbolic(&slack, sizeof(int), "slack");
   int start_pid ;
    klee_make_symbolic(&start_pid, sizeof(int), "start_pid");
   void *start_site ;
   char start_comm[16U] ;
   struct lockdep_map lockdep_map ;
};
struct hrtimer;
enum hrtimer_restart;
struct rb_node {
   unsigned long __rb_parent_color ;
    klee_make_symbolic(&__rb_parent_color, sizeof(long), "__rb_parent_color");
   struct rb_node *rb_right ;
   struct rb_node *rb_left ;
};
struct rb_root {
   struct rb_node *rb_node ;
};
struct ctl_table;
struct nsproxy;
struct ctl_table_root;
struct ctl_table_header;
struct ctl_dir;
typedef int proc_handler(struct ctl_table * , int  , void * , size_t * , loff_t * );
struct ctl_table_poll {
   atomic_t event ;
   wait_queue_head_t wait ;
};
struct ctl_table {
   char const   *procname ;
   void *data ;
   int maxlen ;
    klee_make_symbolic(&maxlen, sizeof(int), "maxlen");
   umode_t mode ;
   struct ctl_table *child ;
   proc_handler *proc_handler ;
   struct ctl_table_poll *poll ;
   void *extra1 ;
   void *extra2 ;
};
struct ctl_node {
   struct rb_node node ;
   struct ctl_table_header *header ;
};
struct __anonstruct____missing_field_name_50 {
   struct ctl_table *ctl_table ;
   int used ;
    klee_make_symbolic(&used, sizeof(int), "used");
   int count ;
   int nreg ;
    klee_make_symbolic(&nreg, sizeof(int), "nreg");
};
union __anonunion____missing_field_name_49 {
   struct __anonstruct____missing_field_name_50 __annonCompField19 ;
   struct callback_head rcu ;
};
struct ctl_table_set;
struct ctl_table_header {
   union __anonunion____missing_field_name_49 __annonCompField20 ;
   struct completion *unregistering ;
   struct ctl_table *ctl_table_arg ;
   struct ctl_table_root *root ;
   struct ctl_table_set *set ;
   struct ctl_dir *parent ;
   struct ctl_node *node ;
};
struct ctl_dir {
   struct ctl_table_header header ;
   struct rb_root root ;
};
struct ctl_table_set {
   int (*is_seen)(struct ctl_table_set * ) ;
   struct ctl_dir dir ;
};
struct ctl_table_root {
   struct ctl_table_set default_set ;
   struct ctl_table_set *(*lookup)(struct ctl_table_root * , struct nsproxy * ) ;
   int (*permissions)(struct ctl_table_header * , struct ctl_table * ) ;
};
struct workqueue_struct;
struct work_struct;
struct work_struct {
   atomic_long_t data ;
   struct list_head entry ;
   void (*func)(struct work_struct * ) ;
   struct lockdep_map lockdep_map ;
};
struct delayed_work {
   struct work_struct work ;
   struct timer_list timer ;
   struct workqueue_struct *wq ;
   int cpu ;
};
struct notifier_block {
   int (*notifier_call)(struct notifier_block * , unsigned long  , void * ) ;
   struct notifier_block *next ;
   int priority ;
    klee_make_symbolic(&priority, sizeof(int), "priority");
};
struct resource {
   resource_size_t start ;
   resource_size_t end ;
   char const   *name ;
   unsigned long flags ;
   struct resource *parent ;
   struct resource *sibling ;
   struct resource *child ;
};
struct pci_dev;
struct pm_message {
   int event ;
    klee_make_symbolic(&event, sizeof(int), "event");
};
typedef struct pm_message pm_message_t;
struct dev_pm_ops {
   int (*prepare)(struct device * ) ;
   void (*complete)(struct device * ) ;
   int (*suspend)(struct device * ) ;
   int (*resume)(struct device * ) ;
   int (*freeze)(struct device * ) ;
   int (*thaw)(struct device * ) ;
   int (*poweroff)(struct device * ) ;
   int (*restore)(struct device * ) ;
   int (*suspend_late)(struct device * ) ;
   int (*resume_early)(struct device * ) ;
   int (*freeze_late)(struct device * ) ;
   int (*thaw_early)(struct device * ) ;
   int (*poweroff_late)(struct device * ) ;
   int (*restore_early)(struct device * ) ;
   int (*suspend_noirq)(struct device * ) ;
   int (*resume_noirq)(struct device * ) ;
   int (*freeze_noirq)(struct device * ) ;
   int (*thaw_noirq)(struct device * ) ;
   int (*poweroff_noirq)(struct device * ) ;
   int (*restore_noirq)(struct device * ) ;
   int (*runtime_suspend)(struct device * ) ;
   int (*runtime_resume)(struct device * ) ;
   int (*runtime_idle)(struct device * ) ;
};
enum rpm_status {
    RPM_ACTIVE = 0,
    RPM_RESUMING = 1,
    RPM_SUSPENDED = 2,
    RPM_SUSPENDING = 3
} ;
enum rpm_request {
    RPM_REQ_NONE = 0,
    RPM_REQ_IDLE = 1,
    RPM_REQ_SUSPEND = 2,
    RPM_REQ_AUTOSUSPEND = 3,
    RPM_REQ_RESUME = 4
} ;
struct wakeup_source;
struct wake_irq;
struct pm_subsys_data {
   spinlock_t lock ;
   unsigned int refcount ;
    klee_make_symbolic(&refcount, sizeof(int), "refcount");
   struct list_head clock_list ;
};
struct dev_pm_qos;
struct dev_pm_info {
   pm_message_t power_state ;
   unsigned char can_wakeup : 1 ;
   unsigned char async_suspend : 1 ;
   bool is_prepared ;
   bool is_suspended ;
   bool is_noirq_suspended ;
   bool is_late_suspended ;
   bool ignore_children ;
   bool early_init ;
   bool direct_complete ;
   spinlock_t lock ;
   struct list_head entry ;
   struct completion completion ;
   struct wakeup_source *wakeup ;
   bool wakeup_path ;
   bool syscore ;
   struct timer_list suspend_timer ;
   unsigned long timer_expires ;
    klee_make_symbolic(&timer_expires, sizeof(long), "timer_expires");
   struct work_struct work ;
   wait_queue_head_t wait_queue ;
   struct wake_irq *wakeirq ;
   atomic_t usage_count ;
   atomic_t child_count ;
   unsigned char disable_depth : 3 ;
   unsigned char idle_notification : 1 ;
   unsigned char request_pending : 1 ;
   unsigned char deferred_resume : 1 ;
   unsigned char run_wake : 1 ;
   unsigned char runtime_auto : 1 ;
   unsigned char no_callbacks : 1 ;
   unsigned char irq_safe : 1 ;
   unsigned char use_autosuspend : 1 ;
   unsigned char timer_autosuspends : 1 ;
   unsigned char memalloc_noio : 1 ;
   enum rpm_request request ;
   enum rpm_status runtime_status ;
   int runtime_error ;
    klee_make_symbolic(&runtime_error, sizeof(int), "runtime_error");
   int autosuspend_delay ;
    klee_make_symbolic(&autosuspend_delay, sizeof(int), "autosuspend_delay");
   unsigned long last_busy ;
    klee_make_symbolic(&last_busy, sizeof(long), "last_busy");
   unsigned long active_jiffies ;
    klee_make_symbolic(&active_jiffies, sizeof(long), "active_jiffies");
   unsigned long suspended_jiffies ;
    klee_make_symbolic(&suspended_jiffies, sizeof(long), "suspended_jiffies");
   unsigned long accounting_timestamp ;
    klee_make_symbolic(&accounting_timestamp, sizeof(long), "accounting_timestamp");
   struct pm_subsys_data *subsys_data ;
   void (*set_latency_tolerance)(struct device * , s32  ) ;
   struct dev_pm_qos *qos ;
};
struct dev_pm_domain {
   struct dev_pm_ops ops ;
   void (*detach)(struct device * , bool  ) ;
   int (*activate)(struct device * ) ;
   void (*sync)(struct device * ) ;
   void (*dismiss)(struct device * ) ;
};
struct pci_bus;
struct __anonstruct_mm_context_t_115 {
   void *ldt ;
   int size ;
    klee_make_symbolic(&size, sizeof(int), "size");
   unsigned short ia32_compat ;
    klee_make_symbolic(&ia32_compat, sizeof(short), "ia32_compat");
   struct mutex lock ;
   void *vdso ;
   atomic_t perf_rdpmc_allowed ;
};
typedef struct __anonstruct_mm_context_t_115 mm_context_t;
struct bio_vec;
struct llist_node;
struct llist_node {
   struct llist_node *next ;
};
struct cred;
struct inode;
struct arch_uprobe_task {
   unsigned long saved_scratch_register ;
    klee_make_symbolic(&saved_scratch_register, sizeof(long), "saved_scratch_register");
   unsigned int saved_trap_nr ;
    klee_make_symbolic(&saved_trap_nr, sizeof(int), "saved_trap_nr");
   unsigned int saved_tf ;
    klee_make_symbolic(&saved_tf, sizeof(int), "saved_tf");
};
enum uprobe_task_state {
    UTASK_RUNNING = 0,
    UTASK_SSTEP = 1,
    UTASK_SSTEP_ACK = 2,
    UTASK_SSTEP_TRAPPED = 3
} ;
struct __anonstruct____missing_field_name_148 {
   struct arch_uprobe_task autask ;
   unsigned long vaddr ;
    klee_make_symbolic(&vaddr, sizeof(long), "vaddr");
};
struct __anonstruct____missing_field_name_149 {
   struct callback_head dup_xol_work ;
   unsigned long dup_xol_addr ;
    klee_make_symbolic(&dup_xol_addr, sizeof(long), "dup_xol_addr");
};
union __anonunion____missing_field_name_147 {
   struct __anonstruct____missing_field_name_148 __annonCompField33 ;
   struct __anonstruct____missing_field_name_149 __annonCompField34 ;
};
struct uprobe;
struct return_instance;
struct uprobe_task {
   enum uprobe_task_state state ;
   union __anonunion____missing_field_name_147 __annonCompField35 ;
   struct uprobe *active_uprobe ;
   unsigned long xol_vaddr ;
    klee_make_symbolic(&xol_vaddr, sizeof(long), "xol_vaddr");
   struct return_instance *return_instances ;
   unsigned int depth ;
    klee_make_symbolic(&depth, sizeof(int), "depth");
};
struct xol_area;
struct uprobes_state {
   struct xol_area *xol_area ;
};
struct address_space;
struct mem_cgroup;
typedef void compound_page_dtor(struct page * );
union __anonunion____missing_field_name_150 {
   struct address_space *mapping ;
   void *s_mem ;
};
union __anonunion____missing_field_name_152 {
   unsigned long index ;
    klee_make_symbolic(&index, sizeof(long), "index");
   void *freelist ;
   bool pfmemalloc ;
};
struct __anonstruct____missing_field_name_156 {
   unsigned short inuse ;
    klee_make_symbolic(&inuse, sizeof(short), "inuse");
   unsigned short objects : 15 ;
   unsigned char frozen : 1 ;
};
union __anonunion____missing_field_name_155 {
   atomic_t _mapcount ;
   struct __anonstruct____missing_field_name_156 __annonCompField38 ;
   int units ;
    klee_make_symbolic(&units, sizeof(int), "units");
};
struct __anonstruct____missing_field_name_154 {
   union __anonunion____missing_field_name_155 __annonCompField39 ;
   atomic_t _count ;
};
union __anonunion____missing_field_name_153 {
   unsigned long counters ;
    klee_make_symbolic(&counters, sizeof(long), "counters");
   struct __anonstruct____missing_field_name_154 __annonCompField40 ;
   unsigned int active ;
    klee_make_symbolic(&active, sizeof(int), "active");
};
struct __anonstruct____missing_field_name_151 {
   union __anonunion____missing_field_name_152 __annonCompField37 ;
   union __anonunion____missing_field_name_153 __annonCompField41 ;
};
struct __anonstruct____missing_field_name_158 {
   struct page *next ;
   int pages ;
    klee_make_symbolic(&pages, sizeof(int), "pages");
   int pobjects ;
    klee_make_symbolic(&pobjects, sizeof(int), "pobjects");
};
struct slab;
struct __anonstruct____missing_field_name_159 {
   compound_page_dtor *compound_dtor ;
   unsigned long compound_order ;
    klee_make_symbolic(&compound_order, sizeof(long), "compound_order");
};
union __anonunion____missing_field_name_157 {
   struct list_head lru ;
   struct __anonstruct____missing_field_name_158 __annonCompField43 ;
   struct slab *slab_page ;
   struct callback_head callback_head ;
   struct __anonstruct____missing_field_name_159 __annonCompField44 ;
   pgtable_t pmd_huge_pte ;
};
struct kmem_cache;
union __anonunion____missing_field_name_160 {
   unsigned long private ;
    klee_make_symbolic(&private, sizeof(long), "private");
   spinlock_t *ptl ;
   struct kmem_cache *slab_cache ;
   struct page *first_page ;
};
struct page {
   unsigned long flags ;
   union __anonunion____missing_field_name_150 __annonCompField36 ;
   struct __anonstruct____missing_field_name_151 __annonCompField42 ;
   union __anonunion____missing_field_name_157 __annonCompField45 ;
   union __anonunion____missing_field_name_160 __annonCompField46 ;
   struct mem_cgroup *mem_cgroup ;
};
struct page_frag {
   struct page *page ;
   __u32 offset ;
   __u32 size ;
};
struct __anonstruct_shared_161 {
   struct rb_node rb ;
   unsigned long rb_subtree_last ;
    klee_make_symbolic(&rb_subtree_last, sizeof(long), "rb_subtree_last");
};
struct anon_vma;
struct vm_operations_struct;
struct mempolicy;
struct vm_area_struct {
   unsigned long vm_start ;
    klee_make_symbolic(&vm_start, sizeof(long), "vm_start");
   unsigned long vm_end ;
    klee_make_symbolic(&vm_end, sizeof(long), "vm_end");
   struct vm_area_struct *vm_next ;
   struct vm_area_struct *vm_prev ;
   struct rb_node vm_rb ;
   unsigned long rb_subtree_gap ;
    klee_make_symbolic(&rb_subtree_gap, sizeof(long), "rb_subtree_gap");
   struct mm_struct *vm_mm ;
   pgprot_t vm_page_prot ;
   unsigned long vm_flags ;
    klee_make_symbolic(&vm_flags, sizeof(long), "vm_flags");
   struct __anonstruct_shared_161 shared ;
   struct list_head anon_vma_chain ;
   struct anon_vma *anon_vma ;
   struct vm_operations_struct  const  *vm_ops ;
   unsigned long vm_pgoff ;
    klee_make_symbolic(&vm_pgoff, sizeof(long), "vm_pgoff");
   struct file *vm_file ;
   void *vm_private_data ;
   struct mempolicy *vm_policy ;
};
struct core_thread {
   struct task_struct *task ;
   struct core_thread *next ;
};
struct core_state {
   atomic_t nr_threads ;
   struct core_thread dumper ;
   struct completion startup ;
};
struct task_rss_stat {
   int events ;
    klee_make_symbolic(&events, sizeof(int), "events");
   int count[3U] ;
};
struct mm_rss_stat {
   atomic_long_t count[3U] ;
};
struct kioctx_table;
struct linux_binfmt;
struct mmu_notifier_mm;
struct mm_struct {
   struct vm_area_struct *mmap ;
   struct rb_root mm_rb ;
   u32 vmacache_seqnum ;
   unsigned long (*get_unmapped_area)(struct file * , unsigned long  , unsigned long  ,
                                      unsigned long  , unsigned long  ) ;
   unsigned long mmap_base ;
    klee_make_symbolic(&mmap_base, sizeof(long), "mmap_base");
   unsigned long mmap_legacy_base ;
    klee_make_symbolic(&mmap_legacy_base, sizeof(long), "mmap_legacy_base");
   unsigned long task_size ;
    klee_make_symbolic(&task_size, sizeof(long), "task_size");
   unsigned long highest_vm_end ;
    klee_make_symbolic(&highest_vm_end, sizeof(long), "highest_vm_end");
   pgd_t *pgd ;
   atomic_t mm_users ;
   atomic_t mm_count ;
   atomic_long_t nr_ptes ;
   atomic_long_t nr_pmds ;
   int map_count ;
    klee_make_symbolic(&map_count, sizeof(int), "map_count");
   spinlock_t page_table_lock ;
   struct rw_semaphore mmap_sem ;
   struct list_head mmlist ;
   unsigned long hiwater_rss ;
    klee_make_symbolic(&hiwater_rss, sizeof(long), "hiwater_rss");
   unsigned long hiwater_vm ;
    klee_make_symbolic(&hiwater_vm, sizeof(long), "hiwater_vm");
   unsigned long total_vm ;
    klee_make_symbolic(&total_vm, sizeof(long), "total_vm");
   unsigned long locked_vm ;
    klee_make_symbolic(&locked_vm, sizeof(long), "locked_vm");
   unsigned long pinned_vm ;
    klee_make_symbolic(&pinned_vm, sizeof(long), "pinned_vm");
   unsigned long shared_vm ;
    klee_make_symbolic(&shared_vm, sizeof(long), "shared_vm");
   unsigned long exec_vm ;
    klee_make_symbolic(&exec_vm, sizeof(long), "exec_vm");
   unsigned long stack_vm ;
    klee_make_symbolic(&stack_vm, sizeof(long), "stack_vm");
   unsigned long def_flags ;
    klee_make_symbolic(&def_flags, sizeof(long), "def_flags");
   unsigned long start_code ;
    klee_make_symbolic(&start_code, sizeof(long), "start_code");
   unsigned long end_code ;
    klee_make_symbolic(&end_code, sizeof(long), "end_code");
   unsigned long start_data ;
    klee_make_symbolic(&start_data, sizeof(long), "start_data");
   unsigned long end_data ;
    klee_make_symbolic(&end_data, sizeof(long), "end_data");
   unsigned long start_brk ;
    klee_make_symbolic(&start_brk, sizeof(long), "start_brk");
   unsigned long brk ;
    klee_make_symbolic(&brk, sizeof(long), "brk");
   unsigned long start_stack ;
    klee_make_symbolic(&start_stack, sizeof(long), "start_stack");
   unsigned long arg_start ;
    klee_make_symbolic(&arg_start, sizeof(long), "arg_start");
   unsigned long arg_end ;
    klee_make_symbolic(&arg_end, sizeof(long), "arg_end");
   unsigned long env_start ;
    klee_make_symbolic(&env_start, sizeof(long), "env_start");
   unsigned long env_end ;
    klee_make_symbolic(&env_end, sizeof(long), "env_end");
   unsigned long saved_auxv[46U] ;
   struct mm_rss_stat rss_stat ;
   struct linux_binfmt *binfmt ;
   cpumask_var_t cpu_vm_mask_var ;
   mm_context_t context ;
   unsigned long flags ;
   struct core_state *core_state ;
   spinlock_t ioctx_lock ;
   struct kioctx_table *ioctx_table ;
   struct task_struct *owner ;
   struct file *exe_file ;
   struct mmu_notifier_mm *mmu_notifier_mm ;
   struct cpumask cpumask_allocation ;
   unsigned long numa_next_scan ;
    klee_make_symbolic(&numa_next_scan, sizeof(long), "numa_next_scan");
   unsigned long numa_scan_offset ;
    klee_make_symbolic(&numa_scan_offset, sizeof(long), "numa_scan_offset");
   int numa_scan_seq ;
    klee_make_symbolic(&numa_scan_seq, sizeof(int), "numa_scan_seq");
   bool tlb_flush_pending ;
   struct uprobes_state uprobes_state ;
   void *bd_addr ;
};
typedef __u64 Elf64_Addr;
typedef __u16 Elf64_Half;
typedef __u32 Elf64_Word;
typedef __u64 Elf64_Xword;
struct elf64_sym {
   Elf64_Word st_name ;
   unsigned char st_info ;
    klee_make_symbolic(&st_info, sizeof(char), "st_info");
   unsigned char st_other ;
    klee_make_symbolic(&st_other, sizeof(char), "st_other");
   Elf64_Half st_shndx ;
   Elf64_Addr st_value ;
   Elf64_Xword st_size ;
};
typedef struct elf64_sym Elf64_Sym;
union __anonunion____missing_field_name_166 {
   unsigned long bitmap[4U] ;
   struct callback_head callback_head ;
};
struct idr_layer {
   int prefix ;
    klee_make_symbolic(&prefix, sizeof(int), "prefix");
   int layer ;
    klee_make_symbolic(&layer, sizeof(int), "layer");
   struct idr_layer *ary[256U] ;
   int count ;
   union __anonunion____missing_field_name_166 __annonCompField47 ;
};
struct idr {
   struct idr_layer *hint ;
   struct idr_layer *top ;
   int layers ;
    klee_make_symbolic(&layers, sizeof(int), "layers");
   int cur ;
    klee_make_symbolic(&cur, sizeof(int), "cur");
   spinlock_t lock ;
   int id_free_cnt ;
    klee_make_symbolic(&id_free_cnt, sizeof(int), "id_free_cnt");
   struct idr_layer *id_free ;
};
struct ida_bitmap {
   long nr_busy ;
    klee_make_symbolic(&nr_busy, sizeof(long), "nr_busy");
   unsigned long bitmap[15U] ;
};
struct ida {
   struct idr idr ;
   struct ida_bitmap *free_bitmap ;
};
struct dentry;
struct iattr;
struct super_block;
struct file_system_type;
struct kernfs_open_node;
struct kernfs_iattrs;
struct kernfs_root;
struct kernfs_elem_dir {
   unsigned long subdirs ;
    klee_make_symbolic(&subdirs, sizeof(long), "subdirs");
   struct rb_root children ;
   struct kernfs_root *root ;
};
struct kernfs_node;
struct kernfs_elem_symlink {
   struct kernfs_node *target_kn ;
};
struct kernfs_ops;
struct kernfs_elem_attr {
   struct kernfs_ops  const  *ops ;
   struct kernfs_open_node *open ;
   loff_t size ;
   struct kernfs_node *notify_next ;
};
union __anonunion____missing_field_name_171 {
   struct kernfs_elem_dir dir ;
   struct kernfs_elem_symlink symlink ;
   struct kernfs_elem_attr attr ;
};
struct kernfs_node {
   atomic_t count ;
   atomic_t active ;
   struct lockdep_map dep_map ;
   struct kernfs_node *parent ;
   char const   *name ;
   struct rb_node rb ;
   void const   *ns ;
   unsigned int hash ;
    klee_make_symbolic(&hash, sizeof(int), "hash");
   union __anonunion____missing_field_name_171 __annonCompField48 ;
   void *priv ;
   unsigned short flags ;
   umode_t mode ;
   unsigned int ino ;
    klee_make_symbolic(&ino, sizeof(int), "ino");
   struct kernfs_iattrs *iattr ;
};
struct kernfs_syscall_ops {
   int (*remount_fs)(struct kernfs_root * , int * , char * ) ;
   int (*show_options)(struct seq_file * , struct kernfs_root * ) ;
   int (*mkdir)(struct kernfs_node * , char const   * , umode_t  ) ;
   int (*rmdir)(struct kernfs_node * ) ;
   int (*rename)(struct kernfs_node * , struct kernfs_node * , char const   * ) ;
};
struct kernfs_root {
   struct kernfs_node *kn ;
   unsigned int flags ;
   struct ida ino_ida ;
   struct kernfs_syscall_ops *syscall_ops ;
   struct list_head supers ;
   wait_queue_head_t deactivate_waitq ;
};
struct kernfs_open_file {
   struct kernfs_node *kn ;
   struct file *file ;
   void *priv ;
   struct mutex mutex ;
   int event ;
   struct list_head list ;
   char *prealloc_buf ;
   size_t atomic_write_len ;
   bool mmapped ;
   struct vm_operations_struct  const  *vm_ops ;
};
struct kernfs_ops {
   int (*seq_show)(struct seq_file * , void * ) ;
   void *(*seq_start)(struct seq_file * , loff_t * ) ;
   void *(*seq_next)(struct seq_file * , void * , loff_t * ) ;
   void (*seq_stop)(struct seq_file * , void * ) ;
   ssize_t (*read)(struct kernfs_open_file * , char * , size_t  , loff_t  ) ;
   size_t atomic_write_len ;
   bool prealloc ;
   ssize_t (*write)(struct kernfs_open_file * , char * , size_t  , loff_t  ) ;
   int (*mmap)(struct kernfs_open_file * , struct vm_area_struct * ) ;
   struct lock_class_key lockdep_key ;
};
struct sock;
struct kobject;
enum kobj_ns_type {
    KOBJ_NS_TYPE_NONE = 0,
    KOBJ_NS_TYPE_NET = 1,
    KOBJ_NS_TYPES = 2
} ;
struct kobj_ns_type_operations {
   enum kobj_ns_type type ;
   bool (*current_may_mount)(void) ;
   void *(*grab_current_ns)(void) ;
   void const   *(*netlink_ns)(struct sock * ) ;
   void const   *(*initial_ns)(void) ;
   void (*drop_ns)(void * ) ;
};
struct bin_attribute;
struct attribute {
   char const   *name ;
   umode_t mode ;
   bool ignore_lockdep ;
   struct lock_class_key *key ;
   struct lock_class_key skey ;
};
struct attribute_group {
   char const   *name ;
   umode_t (*is_visible)(struct kobject * , struct attribute * , int  ) ;
   struct attribute **attrs ;
   struct bin_attribute **bin_attrs ;
};
struct bin_attribute {
   struct attribute attr ;
   size_t size ;
   void *private ;
   ssize_t (*read)(struct file * , struct kobject * , struct bin_attribute * , char * ,
                   loff_t  , size_t  ) ;
   ssize_t (*write)(struct file * , struct kobject * , struct bin_attribute * , char * ,
                    loff_t  , size_t  ) ;
   int (*mmap)(struct file * , struct kobject * , struct bin_attribute * , struct vm_area_struct * ) ;
};
struct sysfs_ops {
   ssize_t (*show)(struct kobject * , struct attribute * , char * ) ;
   ssize_t (*store)(struct kobject * , struct attribute * , char const   * , size_t  ) ;
};
struct kref {
   atomic_t refcount ;
};
struct kset;
struct kobj_type;
struct kobject {
   char const   *name ;
   struct list_head entry ;
   struct kobject *parent ;
   struct kset *kset ;
   struct kobj_type *ktype ;
   struct kernfs_node *sd ;
   struct kref kref ;
   struct delayed_work release ;
   unsigned char state_initialized : 1 ;
   unsigned char state_in_sysfs : 1 ;
   unsigned char state_add_uevent_sent : 1 ;
   unsigned char state_remove_uevent_sent : 1 ;
   unsigned char uevent_suppress : 1 ;
};
struct kobj_type {
   void (*release)(struct kobject * ) ;
   struct sysfs_ops  const  *sysfs_ops ;
   struct attribute **default_attrs ;
   struct kobj_ns_type_operations  const  *(*child_ns_type)(struct kobject * ) ;
   void const   *(*namespace)(struct kobject * ) ;
};
struct kobj_uevent_env {
   char *argv[3U] ;
   char *envp[32U] ;
   int envp_idx ;
    klee_make_symbolic(&envp_idx, sizeof(int), "envp_idx");
   char buf[2048U] ;
   int buflen ;
    klee_make_symbolic(&buflen, sizeof(int), "buflen");
};
struct kset_uevent_ops {
   int (* const  filter)(struct kset * , struct kobject * ) ;
   char const   *(* const  name)(struct kset * , struct kobject * ) ;
   int (* const  uevent)(struct kset * , struct kobject * , struct kobj_uevent_env * ) ;
};
struct kset {
   struct list_head list ;
   spinlock_t list_lock ;
   struct kobject kobj ;
   struct kset_uevent_ops  const  *uevent_ops ;
};
struct kernel_param;
struct kernel_param_ops {
   unsigned int flags ;
   int (*set)(char const   * , struct kernel_param  const  * ) ;
   int (*get)(char * , struct kernel_param  const  * ) ;
   void (*free)(void * ) ;
};
struct kparam_string;
struct kparam_array;
union __anonunion____missing_field_name_172 {
   void *arg ;
   struct kparam_string  const  *str ;
   struct kparam_array  const  *arr ;
};
struct kernel_param {
   char const   *name ;
   struct module *mod ;
   struct kernel_param_ops  const  *ops ;
   u16 const   perm ;
   s8 level ;
   u8 flags ;
   union __anonunion____missing_field_name_172 __annonCompField49 ;
};
struct kparam_string {
   unsigned int maxlen ;
   char *string ;
};
struct kparam_array {
   unsigned int max ;
    klee_make_symbolic(&max, sizeof(int), "max");
   unsigned int elemsize ;
    klee_make_symbolic(&elemsize, sizeof(int), "elemsize");
   unsigned int *num ;
   struct kernel_param_ops  const  *ops ;
   void *elem ;
};
struct latch_tree_node {
   struct rb_node node[2U] ;
};
struct mod_arch_specific {

};
struct module_param_attrs;
struct module_kobject {
   struct kobject kobj ;
   struct module *mod ;
   struct kobject *drivers_dir ;
   struct module_param_attrs *mp ;
   struct completion *kobj_completion ;
};
struct module_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct module_attribute * , struct module_kobject * , char * ) ;
   ssize_t (*store)(struct module_attribute * , struct module_kobject * , char const   * ,
                    size_t  ) ;
   void (*setup)(struct module * , char const   * ) ;
   int (*test)(struct module * ) ;
   void (*free)(struct module * ) ;
};
struct exception_table_entry;
enum module_state {
    MODULE_STATE_LIVE = 0,
    MODULE_STATE_COMING = 1,
    MODULE_STATE_GOING = 2,
    MODULE_STATE_UNFORMED = 3
} ;
struct mod_tree_node {
   struct module *mod ;
   struct latch_tree_node node ;
};
struct module_sect_attrs;
struct module_notes_attrs;
struct tracepoint;
struct trace_event_call;
struct trace_enum_map;
struct module {
   enum module_state state ;
   struct list_head list ;
   char name[56U] ;
   struct module_kobject mkobj ;
   struct module_attribute *modinfo_attrs ;
   char const   *version ;
   char const   *srcversion ;
   struct kobject *holders_dir ;
   struct kernel_symbol  const  *syms ;
   unsigned long const   *crcs ;
   unsigned int num_syms ;
    klee_make_symbolic(&num_syms, sizeof(int), "num_syms");
   struct mutex param_lock ;
   struct kernel_param *kp ;
   unsigned int num_kp ;
    klee_make_symbolic(&num_kp, sizeof(int), "num_kp");
   unsigned int num_gpl_syms ;
    klee_make_symbolic(&num_gpl_syms, sizeof(int), "num_gpl_syms");
   struct kernel_symbol  const  *gpl_syms ;
   unsigned long const   *gpl_crcs ;
   struct kernel_symbol  const  *unused_syms ;
   unsigned long const   *unused_crcs ;
   unsigned int num_unused_syms ;
    klee_make_symbolic(&num_unused_syms, sizeof(int), "num_unused_syms");
   unsigned int num_unused_gpl_syms ;
    klee_make_symbolic(&num_unused_gpl_syms, sizeof(int), "num_unused_gpl_syms");
   struct kernel_symbol  const  *unused_gpl_syms ;
   unsigned long const   *unused_gpl_crcs ;
   bool sig_ok ;
   bool async_probe_requested ;
   struct kernel_symbol  const  *gpl_future_syms ;
   unsigned long const   *gpl_future_crcs ;
   unsigned int num_gpl_future_syms ;
    klee_make_symbolic(&num_gpl_future_syms, sizeof(int), "num_gpl_future_syms");
   unsigned int num_exentries ;
    klee_make_symbolic(&num_exentries, sizeof(int), "num_exentries");
   struct exception_table_entry *extable ;
   int (*init)(void) ;
   void *module_init ;
   void *module_core ;
   unsigned int init_size ;
    klee_make_symbolic(&init_size, sizeof(int), "init_size");
   unsigned int core_size ;
    klee_make_symbolic(&core_size, sizeof(int), "core_size");
   unsigned int init_text_size ;
    klee_make_symbolic(&init_text_size, sizeof(int), "init_text_size");
   unsigned int core_text_size ;
    klee_make_symbolic(&core_text_size, sizeof(int), "core_text_size");
   struct mod_tree_node mtn_core ;
   struct mod_tree_node mtn_init ;
   unsigned int init_ro_size ;
    klee_make_symbolic(&init_ro_size, sizeof(int), "init_ro_size");
   unsigned int core_ro_size ;
    klee_make_symbolic(&core_ro_size, sizeof(int), "core_ro_size");
   struct mod_arch_specific arch ;
   unsigned int taints ;
    klee_make_symbolic(&taints, sizeof(int), "taints");
   unsigned int num_bugs ;
    klee_make_symbolic(&num_bugs, sizeof(int), "num_bugs");
   struct list_head bug_list ;
   struct bug_entry *bug_table ;
   Elf64_Sym *symtab ;
   Elf64_Sym *core_symtab ;
   unsigned int num_symtab ;
    klee_make_symbolic(&num_symtab, sizeof(int), "num_symtab");
   unsigned int core_num_syms ;
    klee_make_symbolic(&core_num_syms, sizeof(int), "core_num_syms");
   char *strtab ;
   char *core_strtab ;
   struct module_sect_attrs *sect_attrs ;
   struct module_notes_attrs *notes_attrs ;
   char *args ;
   void *percpu ;
   unsigned int percpu_size ;
    klee_make_symbolic(&percpu_size, sizeof(int), "percpu_size");
   unsigned int num_tracepoints ;
    klee_make_symbolic(&num_tracepoints, sizeof(int), "num_tracepoints");
   struct tracepoint * const  *tracepoints_ptrs ;
   unsigned int num_trace_bprintk_fmt ;
    klee_make_symbolic(&num_trace_bprintk_fmt, sizeof(int), "num_trace_bprintk_fmt");
   char const   **trace_bprintk_fmt_start ;
   struct trace_event_call **trace_events ;
   unsigned int num_trace_events ;
    klee_make_symbolic(&num_trace_events, sizeof(int), "num_trace_events");
   struct trace_enum_map **trace_enums ;
   unsigned int num_trace_enums ;
    klee_make_symbolic(&num_trace_enums, sizeof(int), "num_trace_enums");
   unsigned int num_ftrace_callsites ;
    klee_make_symbolic(&num_ftrace_callsites, sizeof(int), "num_ftrace_callsites");
   unsigned long *ftrace_callsites ;
   bool klp_alive ;
   struct list_head source_list ;
   struct list_head target_list ;
   void (*exit)(void) ;
   atomic_t refcnt ;
   ctor_fn_t (**ctors)(void) ;
   unsigned int num_ctors ;
    klee_make_symbolic(&num_ctors, sizeof(int), "num_ctors");
};
struct kernel_cap_struct {
   __u32 cap[2U] ;
};
typedef struct kernel_cap_struct kernel_cap_t;
struct plist_node {
   int prio ;
    klee_make_symbolic(&prio, sizeof(int), "prio");
   struct list_head prio_list ;
   struct list_head node_list ;
};
typedef unsigned long cputime_t;
    klee_make_symbolic(&cputime_t, sizeof(long), "cputime_t");
struct sem_undo_list;
struct sysv_sem {
   struct sem_undo_list *undo_list ;
};
struct user_struct;
struct sysv_shm {
   struct list_head shm_clist ;
};
struct __anonstruct_sigset_t_180 {
   unsigned long sig[1U] ;
};
typedef struct __anonstruct_sigset_t_180 sigset_t;
struct siginfo;
typedef void __signalfn_t(int  );
typedef __signalfn_t *__sighandler_t;
typedef void __restorefn_t(void);
typedef __restorefn_t *__sigrestore_t;
union sigval {
   int sival_int ;
    klee_make_symbolic(&sival_int, sizeof(int), "sival_int");
   void *sival_ptr ;
};
typedef union sigval sigval_t;
struct __anonstruct__kill_182 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
};
struct __anonstruct__timer_183 {
   __kernel_timer_t _tid ;
   int _overrun ;
    klee_make_symbolic(&_overrun, sizeof(int), "_overrun");
   char _pad[0U] ;
   sigval_t _sigval ;
   int _sys_private ;
    klee_make_symbolic(&_sys_private, sizeof(int), "_sys_private");
};
struct __anonstruct__rt_184 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
   sigval_t _sigval ;
};
struct __anonstruct__sigchld_185 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
   int _status ;
    klee_make_symbolic(&_status, sizeof(int), "_status");
   __kernel_clock_t _utime ;
   __kernel_clock_t _stime ;
};
struct __anonstruct__addr_bnd_187 {
   void *_lower ;
   void *_upper ;
};
struct __anonstruct__sigfault_186 {
   void *_addr ;
   short _addr_lsb ;
    klee_make_symbolic(&_addr_lsb, sizeof(short), "_addr_lsb");
   struct __anonstruct__addr_bnd_187 _addr_bnd ;
};
struct __anonstruct__sigpoll_188 {
   long _band ;
    klee_make_symbolic(&_band, sizeof(long), "_band");
   int _fd ;
    klee_make_symbolic(&_fd, sizeof(int), "_fd");
};
struct __anonstruct__sigsys_189 {
   void *_call_addr ;
   int _syscall ;
    klee_make_symbolic(&_syscall, sizeof(int), "_syscall");
   unsigned int _arch ;
    klee_make_symbolic(&_arch, sizeof(int), "_arch");
};
union __anonunion__sifields_181 {
   int _pad[28U] ;
   struct __anonstruct__kill_182 _kill ;
   struct __anonstruct__timer_183 _timer ;
   struct __anonstruct__rt_184 _rt ;
   struct __anonstruct__sigchld_185 _sigchld ;
   struct __anonstruct__sigfault_186 _sigfault ;
   struct __anonstruct__sigpoll_188 _sigpoll ;
   struct __anonstruct__sigsys_189 _sigsys ;
};
struct siginfo {
   int si_signo ;
    klee_make_symbolic(&si_signo, sizeof(int), "si_signo");
   int si_errno ;
    klee_make_symbolic(&si_errno, sizeof(int), "si_errno");
   int si_code ;
    klee_make_symbolic(&si_code, sizeof(int), "si_code");
   union __anonunion__sifields_181 _sifields ;
};
typedef struct siginfo siginfo_t;
struct sigpending {
   struct list_head list ;
   sigset_t signal ;
};
struct sigaction {
   __sighandler_t sa_handler ;
   unsigned long sa_flags ;
    klee_make_symbolic(&sa_flags, sizeof(long), "sa_flags");
   __sigrestore_t sa_restorer ;
   sigset_t sa_mask ;
};
struct k_sigaction {
   struct sigaction sa ;
};
enum pid_type {
    PIDTYPE_PID = 0,
    PIDTYPE_PGID = 1,
    PIDTYPE_SID = 2,
    PIDTYPE_MAX = 3
} ;
struct pid_namespace;
struct upid {
   int nr ;
    klee_make_symbolic(&nr, sizeof(int), "nr");
   struct pid_namespace *ns ;
   struct hlist_node pid_chain ;
};
struct pid {
   atomic_t count ;
   unsigned int level ;
    klee_make_symbolic(&level, sizeof(int), "level");
   struct hlist_head tasks[3U] ;
   struct callback_head rcu ;
   struct upid numbers[1U] ;
};
struct pid_link {
   struct hlist_node node ;
   struct pid *pid ;
};
struct percpu_counter {
   raw_spinlock_t lock ;
   s64 count ;
   struct list_head list ;
   s32 *counters ;
};
struct seccomp_filter;
struct seccomp {
   int mode ;
    klee_make_symbolic(&mode, sizeof(int), "mode");
   struct seccomp_filter *filter ;
};
struct rt_mutex_waiter;
struct rlimit {
   __kernel_ulong_t rlim_cur ;
   __kernel_ulong_t rlim_max ;
};
struct timerqueue_node {
   struct rb_node node ;
   ktime_t expires ;
};
struct timerqueue_head {
   struct rb_root head ;
   struct timerqueue_node *next ;
};
struct hrtimer_clock_base;
struct hrtimer_cpu_base;
enum hrtimer_restart {
    HRTIMER_NORESTART = 0,
    HRTIMER_RESTART = 1
} ;
struct hrtimer {
   struct timerqueue_node node ;
   ktime_t _softexpires ;
   enum hrtimer_restart (*function)(struct hrtimer * ) ;
   struct hrtimer_clock_base *base ;
   unsigned long state ;
    klee_make_symbolic(&state, sizeof(long), "state");
   int start_pid ;
   void *start_site ;
   char start_comm[16U] ;
};
struct hrtimer_clock_base {
   struct hrtimer_cpu_base *cpu_base ;
   int index ;
   clockid_t clockid ;
   struct timerqueue_head active ;
   ktime_t (*get_time)(void) ;
   ktime_t offset ;
};
struct hrtimer_cpu_base {
   raw_spinlock_t lock ;
   seqcount_t seq ;
   struct hrtimer *running ;
   unsigned int cpu ;
   unsigned int active_bases ;
    klee_make_symbolic(&active_bases, sizeof(int), "active_bases");
   unsigned int clock_was_set_seq ;
    klee_make_symbolic(&clock_was_set_seq, sizeof(int), "clock_was_set_seq");
   bool migration_enabled ;
   bool nohz_active ;
   unsigned char in_hrtirq : 1 ;
   unsigned char hres_active : 1 ;
   unsigned char hang_detected : 1 ;
   ktime_t expires_next ;
   struct hrtimer *next_timer ;
   unsigned int nr_events ;
    klee_make_symbolic(&nr_events, sizeof(int), "nr_events");
   unsigned int nr_retries ;
    klee_make_symbolic(&nr_retries, sizeof(int), "nr_retries");
   unsigned int nr_hangs ;
    klee_make_symbolic(&nr_hangs, sizeof(int), "nr_hangs");
   unsigned int max_hang_time ;
    klee_make_symbolic(&max_hang_time, sizeof(int), "max_hang_time");
   struct hrtimer_clock_base clock_base[4U] ;
};
struct task_io_accounting {
   u64 rchar ;
   u64 wchar ;
   u64 syscr ;
   u64 syscw ;
   u64 read_bytes ;
   u64 write_bytes ;
   u64 cancelled_write_bytes ;
};
struct latency_record {
   unsigned long backtrace[12U] ;
   unsigned int count ;
   unsigned long time ;
    klee_make_symbolic(&time, sizeof(long), "time");
   unsigned long max ;
};
struct assoc_array_ptr;
struct assoc_array {
   struct assoc_array_ptr *root ;
   unsigned long nr_leaves_on_tree ;
    klee_make_symbolic(&nr_leaves_on_tree, sizeof(long), "nr_leaves_on_tree");
};
typedef int32_t key_serial_t;
typedef uint32_t key_perm_t;
struct key;
struct signal_struct;
struct key_type;
struct keyring_index_key {
   struct key_type *type ;
   char const   *description ;
   size_t desc_len ;
};
union __anonunion____missing_field_name_196 {
   struct list_head graveyard_link ;
   struct rb_node serial_node ;
};
struct key_user;
union __anonunion____missing_field_name_197 {
   time_t expiry ;
   time_t revoked_at ;
};
struct __anonstruct____missing_field_name_199 {
   struct key_type *type ;
   char *description ;
};
union __anonunion____missing_field_name_198 {
   struct keyring_index_key index_key ;
   struct __anonstruct____missing_field_name_199 __annonCompField52 ;
};
union __anonunion_type_data_200 {
   struct list_head link ;
   unsigned long x[2U] ;
   void *p[2U] ;
   int reject_error ;
    klee_make_symbolic(&reject_error, sizeof(int), "reject_error");
};
union __anonunion_payload_202 {
   unsigned long value ;
   void *rcudata ;
   void *data ;
   void *data2[2U] ;
};
union __anonunion____missing_field_name_201 {
   union __anonunion_payload_202 payload ;
   struct assoc_array keys ;
};
struct key {
   atomic_t usage ;
   key_serial_t serial ;
   union __anonunion____missing_field_name_196 __annonCompField50 ;
   struct rw_semaphore sem ;
   struct key_user *user ;
   void *security ;
   union __anonunion____missing_field_name_197 __annonCompField51 ;
   time_t last_used_at ;
   kuid_t uid ;
   kgid_t gid ;
   key_perm_t perm ;
   unsigned short quotalen ;
    klee_make_symbolic(&quotalen, sizeof(short), "quotalen");
   unsigned short datalen ;
    klee_make_symbolic(&datalen, sizeof(short), "datalen");
   unsigned long flags ;
   union __anonunion____missing_field_name_198 __annonCompField53 ;
   union __anonunion_type_data_200 type_data ;
   union __anonunion____missing_field_name_201 __annonCompField54 ;
};
struct audit_context;
struct group_info {
   atomic_t usage ;
   int ngroups ;
    klee_make_symbolic(&ngroups, sizeof(int), "ngroups");
   int nblocks ;
    klee_make_symbolic(&nblocks, sizeof(int), "nblocks");
   kgid_t small_block[32U] ;
   kgid_t *blocks[0U] ;
};
struct cred {
   atomic_t usage ;
   atomic_t subscribers ;
   void *put_addr ;
   unsigned int magic ;
   kuid_t uid ;
   kgid_t gid ;
   kuid_t suid ;
   kgid_t sgid ;
   kuid_t euid ;
   kgid_t egid ;
   kuid_t fsuid ;
   kgid_t fsgid ;
   unsigned int securebits ;
    klee_make_symbolic(&securebits, sizeof(int), "securebits");
   kernel_cap_t cap_inheritable ;
   kernel_cap_t cap_permitted ;
   kernel_cap_t cap_effective ;
   kernel_cap_t cap_bset ;
   unsigned char jit_keyring ;
    klee_make_symbolic(&jit_keyring, sizeof(char), "jit_keyring");
   struct key *session_keyring ;
   struct key *process_keyring ;
   struct key *thread_keyring ;
   struct key *request_key_auth ;
   void *security ;
   struct user_struct *user ;
   struct user_namespace *user_ns ;
   struct group_info *group_info ;
   struct callback_head rcu ;
};
struct percpu_ref;
typedef void percpu_ref_func_t(struct percpu_ref * );
struct percpu_ref {
   atomic_long_t count ;
   unsigned long percpu_count_ptr ;
    klee_make_symbolic(&percpu_count_ptr, sizeof(long), "percpu_count_ptr");
   percpu_ref_func_t *release ;
   percpu_ref_func_t *confirm_switch ;
   bool force_atomic ;
   struct callback_head rcu ;
};
struct cgroup;
struct cgroup_root;
struct cgroup_subsys;
struct cgroup_taskset;
struct cgroup_subsys_state {
   struct cgroup *cgroup ;
   struct cgroup_subsys *ss ;
   struct percpu_ref refcnt ;
   struct cgroup_subsys_state *parent ;
   struct list_head sibling ;
   struct list_head children ;
   int id ;
    klee_make_symbolic(&id, sizeof(int), "id");
   unsigned int flags ;
   u64 serial_nr ;
   struct callback_head callback_head ;
   struct work_struct destroy_work ;
};
struct css_set {
   atomic_t refcount ;
   struct hlist_node hlist ;
   struct list_head tasks ;
   struct list_head mg_tasks ;
   struct list_head cgrp_links ;
   struct cgroup *dfl_cgrp ;
   struct cgroup_subsys_state *subsys[12U] ;
   struct list_head mg_preload_node ;
   struct list_head mg_node ;
   struct cgroup *mg_src_cgrp ;
   struct css_set *mg_dst_cset ;
   struct list_head e_cset_node[12U] ;
   struct callback_head callback_head ;
};
struct cgroup {
   struct cgroup_subsys_state self ;
   unsigned long flags ;
   int id ;
   int populated_cnt ;
    klee_make_symbolic(&populated_cnt, sizeof(int), "populated_cnt");
   struct kernfs_node *kn ;
   struct kernfs_node *procs_kn ;
   struct kernfs_node *populated_kn ;
   unsigned int subtree_control ;
    klee_make_symbolic(&subtree_control, sizeof(int), "subtree_control");
   unsigned int child_subsys_mask ;
    klee_make_symbolic(&child_subsys_mask, sizeof(int), "child_subsys_mask");
   struct cgroup_subsys_state *subsys[12U] ;
   struct cgroup_root *root ;
   struct list_head cset_links ;
   struct list_head e_csets[12U] ;
   struct list_head pidlists ;
   struct mutex pidlist_mutex ;
   wait_queue_head_t offline_waitq ;
   struct work_struct release_agent_work ;
};
struct cgroup_root {
   struct kernfs_root *kf_root ;
   unsigned int subsys_mask ;
    klee_make_symbolic(&subsys_mask, sizeof(int), "subsys_mask");
   int hierarchy_id ;
    klee_make_symbolic(&hierarchy_id, sizeof(int), "hierarchy_id");
   struct cgroup cgrp ;
   atomic_t nr_cgrps ;
   struct list_head root_list ;
   unsigned int flags ;
   struct idr cgroup_idr ;
   char release_agent_path[4096U] ;
   char name[64U] ;
};
struct cftype {
   char name[64U] ;
   int private ;
   umode_t mode ;
   size_t max_write_len ;
   unsigned int flags ;
   struct cgroup_subsys *ss ;
   struct list_head node ;
   struct kernfs_ops *kf_ops ;
   u64 (*read_u64)(struct cgroup_subsys_state * , struct cftype * ) ;
   s64 (*read_s64)(struct cgroup_subsys_state * , struct cftype * ) ;
   int (*seq_show)(struct seq_file * , void * ) ;
   void *(*seq_start)(struct seq_file * , loff_t * ) ;
   void *(*seq_next)(struct seq_file * , void * , loff_t * ) ;
   void (*seq_stop)(struct seq_file * , void * ) ;
   int (*write_u64)(struct cgroup_subsys_state * , struct cftype * , u64  ) ;
   int (*write_s64)(struct cgroup_subsys_state * , struct cftype * , s64  ) ;
   ssize_t (*write)(struct kernfs_open_file * , char * , size_t  , loff_t  ) ;
   struct lock_class_key lockdep_key ;
};
struct cgroup_subsys {
   struct cgroup_subsys_state *(*css_alloc)(struct cgroup_subsys_state * ) ;
   int (*css_online)(struct cgroup_subsys_state * ) ;
   void (*css_offline)(struct cgroup_subsys_state * ) ;
   void (*css_released)(struct cgroup_subsys_state * ) ;
   void (*css_free)(struct cgroup_subsys_state * ) ;
   void (*css_reset)(struct cgroup_subsys_state * ) ;
   void (*css_e_css_changed)(struct cgroup_subsys_state * ) ;
   int (*can_attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*cancel_attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*fork)(struct task_struct * ) ;
   void (*exit)(struct cgroup_subsys_state * , struct cgroup_subsys_state * , struct task_struct * ) ;
   void (*bind)(struct cgroup_subsys_state * ) ;
   int disabled ;
    klee_make_symbolic(&disabled, sizeof(int), "disabled");
   int early_init ;
    klee_make_symbolic(&early_init, sizeof(int), "early_init");
   bool broken_hierarchy ;
   bool warned_broken_hierarchy ;
   int id ;
   char const   *name ;
   struct cgroup_root *root ;
   struct idr css_idr ;
   struct list_head cfts ;
   struct cftype *dfl_cftypes ;
   struct cftype *legacy_cftypes ;
   unsigned int depends_on ;
    klee_make_symbolic(&depends_on, sizeof(int), "depends_on");
};
struct futex_pi_state;
struct robust_list_head;
struct bio_list;
struct fs_struct;
struct perf_event_context;
struct blk_plug;
struct nameidata;
struct cfs_rq;
struct task_group;
struct sighand_struct {
   atomic_t count ;
   struct k_sigaction action[64U] ;
   spinlock_t siglock ;
   wait_queue_head_t signalfd_wqh ;
};
struct pacct_struct {
   int ac_flag ;
    klee_make_symbolic(&ac_flag, sizeof(int), "ac_flag");
   long ac_exitcode ;
    klee_make_symbolic(&ac_exitcode, sizeof(long), "ac_exitcode");
   unsigned long ac_mem ;
    klee_make_symbolic(&ac_mem, sizeof(long), "ac_mem");
   cputime_t ac_utime ;
   cputime_t ac_stime ;
   unsigned long ac_minflt ;
    klee_make_symbolic(&ac_minflt, sizeof(long), "ac_minflt");
   unsigned long ac_majflt ;
    klee_make_symbolic(&ac_majflt, sizeof(long), "ac_majflt");
};
struct cpu_itimer {
   cputime_t expires ;
   cputime_t incr ;
   u32 error ;
   u32 incr_error ;
};
struct cputime {
   cputime_t utime ;
   cputime_t stime ;
};
struct task_cputime {
   cputime_t utime ;
   cputime_t stime ;
   unsigned long long sum_exec_runtime ;
    klee_make_symbolic(&sum_exec_runtime, sizeof(long), "sum_exec_runtime");
};
struct task_cputime_atomic {
   atomic64_t utime ;
   atomic64_t stime ;
   atomic64_t sum_exec_runtime ;
};
struct thread_group_cputimer {
   struct task_cputime_atomic cputime_atomic ;
   int running ;
    klee_make_symbolic(&running, sizeof(int), "running");
};
struct autogroup;
struct tty_struct;
struct taskstats;
struct tty_audit_buf;
struct signal_struct {
   atomic_t sigcnt ;
   atomic_t live ;
   int nr_threads ;
    klee_make_symbolic(&nr_threads, sizeof(int), "nr_threads");
   struct list_head thread_head ;
   wait_queue_head_t wait_chldexit ;
   struct task_struct *curr_target ;
   struct sigpending shared_pending ;
   int group_exit_code ;
    klee_make_symbolic(&group_exit_code, sizeof(int), "group_exit_code");
   int notify_count ;
    klee_make_symbolic(&notify_count, sizeof(int), "notify_count");
   struct task_struct *group_exit_task ;
   int group_stop_count ;
    klee_make_symbolic(&group_stop_count, sizeof(int), "group_stop_count");
   unsigned int flags ;
   unsigned char is_child_subreaper : 1 ;
   unsigned char has_child_subreaper : 1 ;
   int posix_timer_id ;
    klee_make_symbolic(&posix_timer_id, sizeof(int), "posix_timer_id");
   struct list_head posix_timers ;
   struct hrtimer real_timer ;
   struct pid *leader_pid ;
   ktime_t it_real_incr ;
   struct cpu_itimer it[2U] ;
   struct thread_group_cputimer cputimer ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   struct pid *tty_old_pgrp ;
   int leader ;
    klee_make_symbolic(&leader, sizeof(int), "leader");
   struct tty_struct *tty ;
   struct autogroup *autogroup ;
   seqlock_t stats_lock ;
   cputime_t utime ;
   cputime_t stime ;
   cputime_t cutime ;
   cputime_t cstime ;
   cputime_t gtime ;
   cputime_t cgtime ;
   struct cputime prev_cputime ;
   unsigned long nvcsw ;
    klee_make_symbolic(&nvcsw, sizeof(long), "nvcsw");
   unsigned long nivcsw ;
    klee_make_symbolic(&nivcsw, sizeof(long), "nivcsw");
   unsigned long cnvcsw ;
    klee_make_symbolic(&cnvcsw, sizeof(long), "cnvcsw");
   unsigned long cnivcsw ;
    klee_make_symbolic(&cnivcsw, sizeof(long), "cnivcsw");
   unsigned long min_flt ;
    klee_make_symbolic(&min_flt, sizeof(long), "min_flt");
   unsigned long maj_flt ;
    klee_make_symbolic(&maj_flt, sizeof(long), "maj_flt");
   unsigned long cmin_flt ;
    klee_make_symbolic(&cmin_flt, sizeof(long), "cmin_flt");
   unsigned long cmaj_flt ;
    klee_make_symbolic(&cmaj_flt, sizeof(long), "cmaj_flt");
   unsigned long inblock ;
    klee_make_symbolic(&inblock, sizeof(long), "inblock");
   unsigned long oublock ;
    klee_make_symbolic(&oublock, sizeof(long), "oublock");
   unsigned long cinblock ;
    klee_make_symbolic(&cinblock, sizeof(long), "cinblock");
   unsigned long coublock ;
    klee_make_symbolic(&coublock, sizeof(long), "coublock");
   unsigned long maxrss ;
    klee_make_symbolic(&maxrss, sizeof(long), "maxrss");
   unsigned long cmaxrss ;
    klee_make_symbolic(&cmaxrss, sizeof(long), "cmaxrss");
   struct task_io_accounting ioac ;
   unsigned long long sum_sched_runtime ;
    klee_make_symbolic(&sum_sched_runtime, sizeof(long), "sum_sched_runtime");
   struct rlimit rlim[16U] ;
   struct pacct_struct pacct ;
   struct taskstats *stats ;
   unsigned int audit_tty ;
    klee_make_symbolic(&audit_tty, sizeof(int), "audit_tty");
   unsigned int audit_tty_log_passwd ;
    klee_make_symbolic(&audit_tty_log_passwd, sizeof(int), "audit_tty_log_passwd");
   struct tty_audit_buf *tty_audit_buf ;
   oom_flags_t oom_flags ;
   short oom_score_adj ;
    klee_make_symbolic(&oom_score_adj, sizeof(short), "oom_score_adj");
   short oom_score_adj_min ;
    klee_make_symbolic(&oom_score_adj_min, sizeof(short), "oom_score_adj_min");
   struct mutex cred_guard_mutex ;
};
struct user_struct {
   atomic_t __count ;
   atomic_t processes ;
   atomic_t sigpending ;
   atomic_t inotify_watches ;
   atomic_t inotify_devs ;
   atomic_t fanotify_listeners ;
   atomic_long_t epoll_watches ;
   unsigned long mq_bytes ;
    klee_make_symbolic(&mq_bytes, sizeof(long), "mq_bytes");
   unsigned long locked_shm ;
    klee_make_symbolic(&locked_shm, sizeof(long), "locked_shm");
   struct key *uid_keyring ;
   struct key *session_keyring ;
   struct hlist_node uidhash_node ;
   kuid_t uid ;
   atomic_long_t locked_vm ;
};
struct backing_dev_info;
struct reclaim_state;
struct sched_info {
   unsigned long pcount ;
    klee_make_symbolic(&pcount, sizeof(long), "pcount");
   unsigned long long run_delay ;
    klee_make_symbolic(&run_delay, sizeof(long), "run_delay");
   unsigned long long last_arrival ;
    klee_make_symbolic(&last_arrival, sizeof(long), "last_arrival");
   unsigned long long last_queued ;
    klee_make_symbolic(&last_queued, sizeof(long), "last_queued");
};
struct task_delay_info {
   spinlock_t lock ;
   unsigned int flags ;
   u64 blkio_start ;
   u64 blkio_delay ;
   u64 swapin_delay ;
   u32 blkio_count ;
   u32 swapin_count ;
   u64 freepages_start ;
   u64 freepages_delay ;
   u32 freepages_count ;
};
struct wake_q_node {
   struct wake_q_node *next ;
};
struct io_context;
struct pipe_inode_info;
struct uts_namespace;
struct load_weight {
   unsigned long weight ;
    klee_make_symbolic(&weight, sizeof(long), "weight");
   u32 inv_weight ;
};
struct sched_avg {
   u64 last_runnable_update ;
   s64 decay_count ;
   unsigned long load_avg_contrib ;
    klee_make_symbolic(&load_avg_contrib, sizeof(long), "load_avg_contrib");
   unsigned long utilization_avg_contrib ;
    klee_make_symbolic(&utilization_avg_contrib, sizeof(long), "utilization_avg_contrib");
   u32 runnable_avg_sum ;
   u32 avg_period ;
   u32 running_avg_sum ;
};
struct sched_statistics {
   u64 wait_start ;
   u64 wait_max ;
   u64 wait_count ;
   u64 wait_sum ;
   u64 iowait_count ;
   u64 iowait_sum ;
   u64 sleep_start ;
   u64 sleep_max ;
   s64 sum_sleep_runtime ;
   u64 block_start ;
   u64 block_max ;
   u64 exec_max ;
   u64 slice_max ;
   u64 nr_migrations_cold ;
   u64 nr_failed_migrations_affine ;
   u64 nr_failed_migrations_running ;
   u64 nr_failed_migrations_hot ;
   u64 nr_forced_migrations ;
   u64 nr_wakeups ;
   u64 nr_wakeups_sync ;
   u64 nr_wakeups_migrate ;
   u64 nr_wakeups_local ;
   u64 nr_wakeups_remote ;
   u64 nr_wakeups_affine ;
   u64 nr_wakeups_affine_attempts ;
   u64 nr_wakeups_passive ;
   u64 nr_wakeups_idle ;
};
struct sched_entity {
   struct load_weight load ;
   struct rb_node run_node ;
   struct list_head group_node ;
   unsigned int on_rq ;
    klee_make_symbolic(&on_rq, sizeof(int), "on_rq");
   u64 exec_start ;
   u64 sum_exec_runtime ;
   u64 vruntime ;
   u64 prev_sum_exec_runtime ;
   u64 nr_migrations ;
   struct sched_statistics statistics ;
   int depth ;
   struct sched_entity *parent ;
   struct cfs_rq *cfs_rq ;
   struct cfs_rq *my_q ;
   struct sched_avg avg ;
};
struct rt_rq;
struct sched_rt_entity {
   struct list_head run_list ;
   unsigned long timeout ;
    klee_make_symbolic(&timeout, sizeof(long), "timeout");
   unsigned long watchdog_stamp ;
    klee_make_symbolic(&watchdog_stamp, sizeof(long), "watchdog_stamp");
   unsigned int time_slice ;
    klee_make_symbolic(&time_slice, sizeof(int), "time_slice");
   struct sched_rt_entity *back ;
   struct sched_rt_entity *parent ;
   struct rt_rq *rt_rq ;
   struct rt_rq *my_q ;
};
struct sched_dl_entity {
   struct rb_node rb_node ;
   u64 dl_runtime ;
   u64 dl_deadline ;
   u64 dl_period ;
   u64 dl_bw ;
   s64 runtime ;
   u64 deadline ;
   unsigned int flags ;
   int dl_throttled ;
    klee_make_symbolic(&dl_throttled, sizeof(int), "dl_throttled");
   int dl_new ;
    klee_make_symbolic(&dl_new, sizeof(int), "dl_new");
   int dl_boosted ;
    klee_make_symbolic(&dl_boosted, sizeof(int), "dl_boosted");
   int dl_yielded ;
    klee_make_symbolic(&dl_yielded, sizeof(int), "dl_yielded");
   struct hrtimer dl_timer ;
};
struct memcg_oom_info {
   struct mem_cgroup *memcg ;
   gfp_t gfp_mask ;
   int order ;
    klee_make_symbolic(&order, sizeof(int), "order");
   unsigned char may_oom : 1 ;
};
struct sched_class;
struct files_struct;
struct compat_robust_list_head;
struct numa_group;
struct ftrace_ret_stack;
struct task_struct {
   long volatile   state ;
   void *stack ;
   atomic_t usage ;
   unsigned int flags ;
   unsigned int ptrace ;
    klee_make_symbolic(&ptrace, sizeof(int), "ptrace");
   struct llist_node wake_entry ;
   int on_cpu ;
    klee_make_symbolic(&on_cpu, sizeof(int), "on_cpu");
   struct task_struct *last_wakee ;
   unsigned long wakee_flips ;
    klee_make_symbolic(&wakee_flips, sizeof(long), "wakee_flips");
   unsigned long wakee_flip_decay_ts ;
    klee_make_symbolic(&wakee_flip_decay_ts, sizeof(long), "wakee_flip_decay_ts");
   int wake_cpu ;
    klee_make_symbolic(&wake_cpu, sizeof(int), "wake_cpu");
   int on_rq ;
   int prio ;
   int static_prio ;
    klee_make_symbolic(&static_prio, sizeof(int), "static_prio");
   int normal_prio ;
    klee_make_symbolic(&normal_prio, sizeof(int), "normal_prio");
   unsigned int rt_priority ;
    klee_make_symbolic(&rt_priority, sizeof(int), "rt_priority");
   struct sched_class  const  *sched_class ;
   struct sched_entity se ;
   struct sched_rt_entity rt ;
   struct task_group *sched_task_group ;
   struct sched_dl_entity dl ;
   struct hlist_head preempt_notifiers ;
   unsigned int btrace_seq ;
    klee_make_symbolic(&btrace_seq, sizeof(int), "btrace_seq");
   unsigned int policy ;
    klee_make_symbolic(&policy, sizeof(int), "policy");
   int nr_cpus_allowed ;
    klee_make_symbolic(&nr_cpus_allowed, sizeof(int), "nr_cpus_allowed");
   cpumask_t cpus_allowed ;
   unsigned long rcu_tasks_nvcsw ;
    klee_make_symbolic(&rcu_tasks_nvcsw, sizeof(long), "rcu_tasks_nvcsw");
   bool rcu_tasks_holdout ;
   struct list_head rcu_tasks_holdout_list ;
   int rcu_tasks_idle_cpu ;
    klee_make_symbolic(&rcu_tasks_idle_cpu, sizeof(int), "rcu_tasks_idle_cpu");
   struct sched_info sched_info ;
   struct list_head tasks ;
   struct plist_node pushable_tasks ;
   struct rb_node pushable_dl_tasks ;
   struct mm_struct *mm ;
   struct mm_struct *active_mm ;
   u32 vmacache_seqnum ;
   struct vm_area_struct *vmacache[4U] ;
   struct task_rss_stat rss_stat ;
   int exit_state ;
    klee_make_symbolic(&exit_state, sizeof(int), "exit_state");
   int exit_code ;
    klee_make_symbolic(&exit_code, sizeof(int), "exit_code");
   int exit_signal ;
    klee_make_symbolic(&exit_signal, sizeof(int), "exit_signal");
   int pdeath_signal ;
    klee_make_symbolic(&pdeath_signal, sizeof(int), "pdeath_signal");
   unsigned long jobctl ;
    klee_make_symbolic(&jobctl, sizeof(long), "jobctl");
   unsigned int personality ;
    klee_make_symbolic(&personality, sizeof(int), "personality");
   unsigned char in_execve : 1 ;
   unsigned char in_iowait : 1 ;
   unsigned char sched_reset_on_fork : 1 ;
   unsigned char sched_contributes_to_load : 1 ;
   unsigned char sched_migrated : 1 ;
   unsigned char memcg_kmem_skip_account : 1 ;
   unsigned char brk_randomized : 1 ;
   unsigned long atomic_flags ;
    klee_make_symbolic(&atomic_flags, sizeof(long), "atomic_flags");
   struct restart_block restart_block ;
   pid_t pid ;
   pid_t tgid ;
   struct task_struct *real_parent ;
   struct task_struct *parent ;
   struct list_head children ;
   struct list_head sibling ;
   struct task_struct *group_leader ;
   struct list_head ptraced ;
   struct list_head ptrace_entry ;
   struct pid_link pids[3U] ;
   struct list_head thread_group ;
   struct list_head thread_node ;
   struct completion *vfork_done ;
   int *set_child_tid ;
   int *clear_child_tid ;
   cputime_t utime ;
   cputime_t stime ;
   cputime_t utimescaled ;
   cputime_t stimescaled ;
   cputime_t gtime ;
   struct cputime prev_cputime ;
   unsigned long nvcsw ;
   unsigned long nivcsw ;
   u64 start_time ;
   u64 real_start_time ;
   unsigned long min_flt ;
   unsigned long maj_flt ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   struct cred  const  *real_cred ;
   struct cred  const  *cred ;
   char comm[16U] ;
   struct nameidata *nameidata ;
   struct sysv_sem sysvsem ;
   struct sysv_shm sysvshm ;
   unsigned long last_switch_count ;
    klee_make_symbolic(&last_switch_count, sizeof(long), "last_switch_count");
   struct thread_struct thread ;
   struct fs_struct *fs ;
   struct files_struct *files ;
   struct nsproxy *nsproxy ;
   struct signal_struct *signal ;
   struct sighand_struct *sighand ;
   sigset_t blocked ;
   sigset_t real_blocked ;
   sigset_t saved_sigmask ;
   struct sigpending pending ;
   unsigned long sas_ss_sp ;
    klee_make_symbolic(&sas_ss_sp, sizeof(long), "sas_ss_sp");
   size_t sas_ss_size ;
   int (*notifier)(void * ) ;
   void *notifier_data ;
   sigset_t *notifier_mask ;
   struct callback_head *task_works ;
   struct audit_context *audit_context ;
   kuid_t loginuid ;
   unsigned int sessionid ;
    klee_make_symbolic(&sessionid, sizeof(int), "sessionid");
   struct seccomp seccomp ;
   u32 parent_exec_id ;
   u32 self_exec_id ;
   spinlock_t alloc_lock ;
   raw_spinlock_t pi_lock ;
   struct wake_q_node wake_q ;
   struct rb_root pi_waiters ;
   struct rb_node *pi_waiters_leftmost ;
   struct rt_mutex_waiter *pi_blocked_on ;
   struct mutex_waiter *blocked_on ;
   unsigned int irq_events ;
    klee_make_symbolic(&irq_events, sizeof(int), "irq_events");
   unsigned long hardirq_enable_ip ;
    klee_make_symbolic(&hardirq_enable_ip, sizeof(long), "hardirq_enable_ip");
   unsigned long hardirq_disable_ip ;
    klee_make_symbolic(&hardirq_disable_ip, sizeof(long), "hardirq_disable_ip");
   unsigned int hardirq_enable_event ;
    klee_make_symbolic(&hardirq_enable_event, sizeof(int), "hardirq_enable_event");
   unsigned int hardirq_disable_event ;
    klee_make_symbolic(&hardirq_disable_event, sizeof(int), "hardirq_disable_event");
   int hardirqs_enabled ;
    klee_make_symbolic(&hardirqs_enabled, sizeof(int), "hardirqs_enabled");
   int hardirq_context ;
    klee_make_symbolic(&hardirq_context, sizeof(int), "hardirq_context");
   unsigned long softirq_disable_ip ;
    klee_make_symbolic(&softirq_disable_ip, sizeof(long), "softirq_disable_ip");
   unsigned long softirq_enable_ip ;
    klee_make_symbolic(&softirq_enable_ip, sizeof(long), "softirq_enable_ip");
   unsigned int softirq_disable_event ;
    klee_make_symbolic(&softirq_disable_event, sizeof(int), "softirq_disable_event");
   unsigned int softirq_enable_event ;
    klee_make_symbolic(&softirq_enable_event, sizeof(int), "softirq_enable_event");
   int softirqs_enabled ;
    klee_make_symbolic(&softirqs_enabled, sizeof(int), "softirqs_enabled");
   int softirq_context ;
    klee_make_symbolic(&softirq_context, sizeof(int), "softirq_context");
   u64 curr_chain_key ;
   int lockdep_depth ;
    klee_make_symbolic(&lockdep_depth, sizeof(int), "lockdep_depth");
   unsigned int lockdep_recursion ;
    klee_make_symbolic(&lockdep_recursion, sizeof(int), "lockdep_recursion");
   struct held_lock held_locks[48U] ;
   gfp_t lockdep_reclaim_gfp ;
   void *journal_info ;
   struct bio_list *bio_list ;
   struct blk_plug *plug ;
   struct reclaim_state *reclaim_state ;
   struct backing_dev_info *backing_dev_info ;
   struct io_context *io_context ;
   unsigned long ptrace_message ;
    klee_make_symbolic(&ptrace_message, sizeof(long), "ptrace_message");
   siginfo_t *last_siginfo ;
   struct task_io_accounting ioac ;
   u64 acct_rss_mem1 ;
   u64 acct_vm_mem1 ;
   cputime_t acct_timexpd ;
   nodemask_t mems_allowed ;
   seqcount_t mems_allowed_seq ;
   int cpuset_mem_spread_rotor ;
    klee_make_symbolic(&cpuset_mem_spread_rotor, sizeof(int), "cpuset_mem_spread_rotor");
   int cpuset_slab_spread_rotor ;
    klee_make_symbolic(&cpuset_slab_spread_rotor, sizeof(int), "cpuset_slab_spread_rotor");
   struct css_set *cgroups ;
   struct list_head cg_list ;
   struct robust_list_head *robust_list ;
   struct compat_robust_list_head *compat_robust_list ;
   struct list_head pi_state_list ;
   struct futex_pi_state *pi_state_cache ;
   struct perf_event_context *perf_event_ctxp[2U] ;
   struct mutex perf_event_mutex ;
   struct list_head perf_event_list ;
   struct mempolicy *mempolicy ;
   short il_next ;
    klee_make_symbolic(&il_next, sizeof(short), "il_next");
   short pref_node_fork ;
    klee_make_symbolic(&pref_node_fork, sizeof(short), "pref_node_fork");
   int numa_scan_seq ;
   unsigned int numa_scan_period ;
    klee_make_symbolic(&numa_scan_period, sizeof(int), "numa_scan_period");
   unsigned int numa_scan_period_max ;
    klee_make_symbolic(&numa_scan_period_max, sizeof(int), "numa_scan_period_max");
   int numa_preferred_nid ;
    klee_make_symbolic(&numa_preferred_nid, sizeof(int), "numa_preferred_nid");
   unsigned long numa_migrate_retry ;
    klee_make_symbolic(&numa_migrate_retry, sizeof(long), "numa_migrate_retry");
   u64 node_stamp ;
   u64 last_task_numa_placement ;
   u64 last_sum_exec_runtime ;
   struct callback_head numa_work ;
   struct list_head numa_entry ;
   struct numa_group *numa_group ;
   unsigned long *numa_faults ;
   unsigned long total_numa_faults ;
    klee_make_symbolic(&total_numa_faults, sizeof(long), "total_numa_faults");
   unsigned long numa_faults_locality[3U] ;
   unsigned long numa_pages_migrated ;
    klee_make_symbolic(&numa_pages_migrated, sizeof(long), "numa_pages_migrated");
   struct callback_head rcu ;
   struct pipe_inode_info *splice_pipe ;
   struct page_frag task_frag ;
   struct task_delay_info *delays ;
   int make_it_fail ;
    klee_make_symbolic(&make_it_fail, sizeof(int), "make_it_fail");
   int nr_dirtied ;
    klee_make_symbolic(&nr_dirtied, sizeof(int), "nr_dirtied");
   int nr_dirtied_pause ;
    klee_make_symbolic(&nr_dirtied_pause, sizeof(int), "nr_dirtied_pause");
   unsigned long dirty_paused_when ;
    klee_make_symbolic(&dirty_paused_when, sizeof(long), "dirty_paused_when");
   int latency_record_count ;
    klee_make_symbolic(&latency_record_count, sizeof(int), "latency_record_count");
   struct latency_record latency_record[32U] ;
   unsigned long timer_slack_ns ;
    klee_make_symbolic(&timer_slack_ns, sizeof(long), "timer_slack_ns");
   unsigned long default_timer_slack_ns ;
    klee_make_symbolic(&default_timer_slack_ns, sizeof(long), "default_timer_slack_ns");
   unsigned int kasan_depth ;
    klee_make_symbolic(&kasan_depth, sizeof(int), "kasan_depth");
   int curr_ret_stack ;
    klee_make_symbolic(&curr_ret_stack, sizeof(int), "curr_ret_stack");
   struct ftrace_ret_stack *ret_stack ;
   unsigned long long ftrace_timestamp ;
    klee_make_symbolic(&ftrace_timestamp, sizeof(long), "ftrace_timestamp");
   atomic_t trace_overrun ;
   atomic_t tracing_graph_pause ;
   unsigned long trace ;
    klee_make_symbolic(&trace, sizeof(long), "trace");
   unsigned long trace_recursion ;
    klee_make_symbolic(&trace_recursion, sizeof(long), "trace_recursion");
   struct memcg_oom_info memcg_oom ;
   struct uprobe_task *utask ;
   unsigned int sequential_io ;
    klee_make_symbolic(&sequential_io, sizeof(int), "sequential_io");
   unsigned int sequential_io_avg ;
    klee_make_symbolic(&sequential_io_avg, sizeof(int), "sequential_io_avg");
   unsigned long task_state_change ;
    klee_make_symbolic(&task_state_change, sizeof(long), "task_state_change");
   int pagefault_disabled ;
    klee_make_symbolic(&pagefault_disabled, sizeof(int), "pagefault_disabled");
};
enum irqreturn {
    IRQ_NONE = 0,
    IRQ_HANDLED = 1,
    IRQ_WAKE_THREAD = 2
} ;
typedef enum irqreturn irqreturn_t;
struct ethtool_cmd;
struct ethtool_pauseparam;
struct ethtool_eeprom;
struct bfa_ioc;
struct ethtool_ringparam;
struct ethtool_coalesce;
struct klist_node;
struct klist_node {
   void *n_klist ;
   struct list_head n_node ;
   struct kref n_ref ;
};
struct path;
struct seq_file {
   char *buf ;
   size_t size ;
   size_t from ;
   size_t count ;
   size_t pad_until ;
   loff_t index ;
   loff_t read_pos ;
   u64 version ;
   struct mutex lock ;
   struct seq_operations  const  *op ;
   int poll_event ;
    klee_make_symbolic(&poll_event, sizeof(int), "poll_event");
   struct user_namespace *user_ns ;
   void *private ;
};
struct seq_operations {
   void *(*start)(struct seq_file * , loff_t * ) ;
   void (*stop)(struct seq_file * , void * ) ;
   void *(*next)(struct seq_file * , void * , loff_t * ) ;
   int (*show)(struct seq_file * , void * ) ;
};
struct pinctrl;
struct pinctrl_state;
struct dev_pin_info {
   struct pinctrl *p ;
   struct pinctrl_state *default_state ;
   struct pinctrl_state *sleep_state ;
   struct pinctrl_state *idle_state ;
};
struct dma_map_ops;
struct dev_archdata {
   struct dma_map_ops *dma_ops ;
   void *iommu ;
};
struct device_private;
struct device_driver;
struct driver_private;
struct class;
struct subsys_private;
struct bus_type;
struct device_node;
struct fwnode_handle;
struct iommu_ops;
struct iommu_group;
struct device_attribute;
struct bus_type {
   char const   *name ;
   char const   *dev_name ;
   struct device *dev_root ;
   struct device_attribute *dev_attrs ;
   struct attribute_group  const  **bus_groups ;
   struct attribute_group  const  **dev_groups ;
   struct attribute_group  const  **drv_groups ;
   int (*match)(struct device * , struct device_driver * ) ;
   int (*uevent)(struct device * , struct kobj_uevent_env * ) ;
   int (*probe)(struct device * ) ;
   int (*remove)(struct device * ) ;
   void (*shutdown)(struct device * ) ;
   int (*online)(struct device * ) ;
   int (*offline)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
   struct iommu_ops  const  *iommu_ops ;
   struct subsys_private *p ;
   struct lock_class_key lock_key ;
};
struct device_type;
enum probe_type {
    PROBE_DEFAULT_STRATEGY = 0,
    PROBE_PREFER_ASYNCHRONOUS = 1,
    PROBE_FORCE_SYNCHRONOUS = 2
} ;
struct of_device_id;
struct acpi_device_id;
struct device_driver {
   char const   *name ;
   struct bus_type *bus ;
   struct module *owner ;
   char const   *mod_name ;
   bool suppress_bind_attrs ;
   enum probe_type probe_type ;
   struct of_device_id  const  *of_match_table ;
   struct acpi_device_id  const  *acpi_match_table ;
   int (*probe)(struct device * ) ;
   int (*remove)(struct device * ) ;
   void (*shutdown)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct attribute_group  const  **groups ;
   struct dev_pm_ops  const  *pm ;
   struct driver_private *p ;
};
struct class_attribute;
struct class {
   char const   *name ;
   struct module *owner ;
   struct class_attribute *class_attrs ;
   struct attribute_group  const  **dev_groups ;
   struct kobject *dev_kobj ;
   int (*dev_uevent)(struct device * , struct kobj_uevent_env * ) ;
   char *(*devnode)(struct device * , umode_t * ) ;
   void (*class_release)(struct class * ) ;
   void (*dev_release)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct kobj_ns_type_operations  const  *ns_type ;
   void const   *(*namespace)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
   struct subsys_private *p ;
};
struct class_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct class * , struct class_attribute * , char * ) ;
   ssize_t (*store)(struct class * , struct class_attribute * , char const   * , size_t  ) ;
};
struct device_type {
   char const   *name ;
   struct attribute_group  const  **groups ;
   int (*uevent)(struct device * , struct kobj_uevent_env * ) ;
   char *(*devnode)(struct device * , umode_t * , kuid_t * , kgid_t * ) ;
   void (*release)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
};
struct device_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct device * , struct device_attribute * , char * ) ;
   ssize_t (*store)(struct device * , struct device_attribute * , char const   * ,
                    size_t  ) ;
};
struct device_dma_parameters {
   unsigned int max_segment_size ;
    klee_make_symbolic(&max_segment_size, sizeof(int), "max_segment_size");
   unsigned long segment_boundary_mask ;
    klee_make_symbolic(&segment_boundary_mask, sizeof(long), "segment_boundary_mask");
};
struct dma_coherent_mem;
struct cma;
struct device {
   struct device *parent ;
   struct device_private *p ;
   struct kobject kobj ;
   char const   *init_name ;
   struct device_type  const  *type ;
   struct mutex mutex ;
   struct bus_type *bus ;
   struct device_driver *driver ;
   void *platform_data ;
   void *driver_data ;
   struct dev_pm_info power ;
   struct dev_pm_domain *pm_domain ;
   struct dev_pin_info *pins ;
   int numa_node ;
    klee_make_symbolic(&numa_node, sizeof(int), "numa_node");
   u64 *dma_mask ;
   u64 coherent_dma_mask ;
   unsigned long dma_pfn_offset ;
    klee_make_symbolic(&dma_pfn_offset, sizeof(long), "dma_pfn_offset");
   struct device_dma_parameters *dma_parms ;
   struct list_head dma_pools ;
   struct dma_coherent_mem *dma_mem ;
   struct cma *cma_area ;
   struct dev_archdata archdata ;
   struct device_node *of_node ;
   struct fwnode_handle *fwnode ;
   dev_t devt ;
   u32 id ;
   spinlock_t devres_lock ;
   struct list_head devres_head ;
   struct klist_node knode_class ;
   struct class *class ;
   struct attribute_group  const  **groups ;
   void (*release)(struct device * ) ;
   struct iommu_group *iommu_group ;
   bool offline_disabled ;
   bool offline ;
};
struct wakeup_source {
   char const   *name ;
   struct list_head entry ;
   spinlock_t lock ;
   struct wake_irq *wakeirq ;
   struct timer_list timer ;
   unsigned long timer_expires ;
   ktime_t total_time ;
   ktime_t max_time ;
   ktime_t last_time ;
   ktime_t start_prevent_time ;
   ktime_t prevent_sleep_time ;
   unsigned long event_count ;
    klee_make_symbolic(&event_count, sizeof(long), "event_count");
   unsigned long active_count ;
    klee_make_symbolic(&active_count, sizeof(long), "active_count");
   unsigned long relax_count ;
    klee_make_symbolic(&relax_count, sizeof(long), "relax_count");
   unsigned long expire_count ;
    klee_make_symbolic(&expire_count, sizeof(long), "expire_count");
   unsigned long wakeup_count ;
    klee_make_symbolic(&wakeup_count, sizeof(long), "wakeup_count");
   bool active ;
   bool autosleep_enabled ;
};
struct iovec {
   void *iov_base ;
   __kernel_size_t iov_len ;
};
struct kvec {
   void *iov_base ;
   size_t iov_len ;
};
union __anonunion____missing_field_name_217 {
   struct iovec  const  *iov ;
   struct kvec  const  *kvec ;
   struct bio_vec  const  *bvec ;
};
struct iov_iter {
   int type ;
    klee_make_symbolic(&type, sizeof(int), "type");
   size_t iov_offset ;
   size_t count ;
   union __anonunion____missing_field_name_217 __annonCompField58 ;
   unsigned long nr_segs ;
    klee_make_symbolic(&nr_segs, sizeof(long), "nr_segs");
};
struct shrink_control {
   gfp_t gfp_mask ;
   unsigned long nr_to_scan ;
    klee_make_symbolic(&nr_to_scan, sizeof(long), "nr_to_scan");
   int nid ;
    klee_make_symbolic(&nid, sizeof(int), "nid");
   struct mem_cgroup *memcg ;
};
struct shrinker {
   unsigned long (*count_objects)(struct shrinker * , struct shrink_control * ) ;
   unsigned long (*scan_objects)(struct shrinker * , struct shrink_control * ) ;
   int seeks ;
    klee_make_symbolic(&seeks, sizeof(int), "seeks");
   long batch ;
    klee_make_symbolic(&batch, sizeof(long), "batch");
   unsigned long flags ;
   struct list_head list ;
   atomic_long_t *nr_deferred ;
};
struct file_ra_state;
struct writeback_control;
struct bdi_writeback;
struct vm_fault {
   unsigned int flags ;
   unsigned long pgoff ;
    klee_make_symbolic(&pgoff, sizeof(long), "pgoff");
   void *virtual_address ;
   struct page *cow_page ;
   struct page *page ;
   unsigned long max_pgoff ;
    klee_make_symbolic(&max_pgoff, sizeof(long), "max_pgoff");
   pte_t *pte ;
};
struct vm_operations_struct {
   void (*open)(struct vm_area_struct * ) ;
   void (*close)(struct vm_area_struct * ) ;
   int (*fault)(struct vm_area_struct * , struct vm_fault * ) ;
   void (*map_pages)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*page_mkwrite)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*pfn_mkwrite)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*access)(struct vm_area_struct * , unsigned long  , void * , int  , int  ) ;
   char const   *(*name)(struct vm_area_struct * ) ;
   int (*set_policy)(struct vm_area_struct * , struct mempolicy * ) ;
   struct mempolicy *(*get_policy)(struct vm_area_struct * , unsigned long  ) ;
   struct page *(*find_special_page)(struct vm_area_struct * , unsigned long  ) ;
};
struct scatterlist {
   unsigned long sg_magic ;
    klee_make_symbolic(&sg_magic, sizeof(long), "sg_magic");
   unsigned long page_link ;
    klee_make_symbolic(&page_link, sizeof(long), "page_link");
   unsigned int offset ;
    klee_make_symbolic(&offset, sizeof(int), "offset");
   unsigned int length ;
    klee_make_symbolic(&length, sizeof(int), "length");
   dma_addr_t dma_address ;
   unsigned int dma_length ;
    klee_make_symbolic(&dma_length, sizeof(int), "dma_length");
};
struct sg_table {
   struct scatterlist *sgl ;
   unsigned int nents ;
    klee_make_symbolic(&nents, sizeof(int), "nents");
   unsigned int orig_nents ;
    klee_make_symbolic(&orig_nents, sizeof(int), "orig_nents");
};
struct dql {
   unsigned int num_queued ;
    klee_make_symbolic(&num_queued, sizeof(int), "num_queued");
   unsigned int adj_limit ;
    klee_make_symbolic(&adj_limit, sizeof(int), "adj_limit");
   unsigned int last_obj_cnt ;
    klee_make_symbolic(&last_obj_cnt, sizeof(int), "last_obj_cnt");
   unsigned int limit ;
    klee_make_symbolic(&limit, sizeof(int), "limit");
   unsigned int num_completed ;
    klee_make_symbolic(&num_completed, sizeof(int), "num_completed");
   unsigned int prev_ovlimit ;
    klee_make_symbolic(&prev_ovlimit, sizeof(int), "prev_ovlimit");
   unsigned int prev_num_queued ;
    klee_make_symbolic(&prev_num_queued, sizeof(int), "prev_num_queued");
   unsigned int prev_last_obj_cnt ;
    klee_make_symbolic(&prev_last_obj_cnt, sizeof(int), "prev_last_obj_cnt");
   unsigned int lowest_slack ;
    klee_make_symbolic(&lowest_slack, sizeof(int), "lowest_slack");
   unsigned long slack_start_time ;
    klee_make_symbolic(&slack_start_time, sizeof(long), "slack_start_time");
   unsigned int max_limit ;
    klee_make_symbolic(&max_limit, sizeof(int), "max_limit");
   unsigned int min_limit ;
    klee_make_symbolic(&min_limit, sizeof(int), "min_limit");
   unsigned int slack_hold_time ;
    klee_make_symbolic(&slack_hold_time, sizeof(int), "slack_hold_time");
};
typedef unsigned short __kernel_sa_family_t;
    klee_make_symbolic(&__kernel_sa_family_t, sizeof(short), "__kernel_sa_family_t");
typedef __kernel_sa_family_t sa_family_t;
struct sockaddr {
   sa_family_t sa_family ;
   char sa_data[14U] ;
};
struct kiocb;
struct msghdr {
   void *msg_name ;
   int msg_namelen ;
    klee_make_symbolic(&msg_namelen, sizeof(int), "msg_namelen");
   struct iov_iter msg_iter ;
   void *msg_control ;
   __kernel_size_t msg_controllen ;
   unsigned int msg_flags ;
    klee_make_symbolic(&msg_flags, sizeof(int), "msg_flags");
   struct kiocb *msg_iocb ;
};
struct __anonstruct_sync_serial_settings_219 {
   unsigned int clock_rate ;
    klee_make_symbolic(&clock_rate, sizeof(int), "clock_rate");
   unsigned int clock_type ;
    klee_make_symbolic(&clock_type, sizeof(int), "clock_type");
   unsigned short loopback ;
    klee_make_symbolic(&loopback, sizeof(short), "loopback");
};
typedef struct __anonstruct_sync_serial_settings_219 sync_serial_settings;
struct __anonstruct_te1_settings_220 {
   unsigned int clock_rate ;
   unsigned int clock_type ;
   unsigned short loopback ;
   unsigned int slot_map ;
    klee_make_symbolic(&slot_map, sizeof(int), "slot_map");
};
typedef struct __anonstruct_te1_settings_220 te1_settings;
struct __anonstruct_raw_hdlc_proto_221 {
   unsigned short encoding ;
    klee_make_symbolic(&encoding, sizeof(short), "encoding");
   unsigned short parity ;
    klee_make_symbolic(&parity, sizeof(short), "parity");
};
typedef struct __anonstruct_raw_hdlc_proto_221 raw_hdlc_proto;
struct __anonstruct_fr_proto_222 {
   unsigned int t391 ;
    klee_make_symbolic(&t391, sizeof(int), "t391");
   unsigned int t392 ;
    klee_make_symbolic(&t392, sizeof(int), "t392");
   unsigned int n391 ;
    klee_make_symbolic(&n391, sizeof(int), "n391");
   unsigned int n392 ;
    klee_make_symbolic(&n392, sizeof(int), "n392");
   unsigned int n393 ;
    klee_make_symbolic(&n393, sizeof(int), "n393");
   unsigned short lmi ;
    klee_make_symbolic(&lmi, sizeof(short), "lmi");
   unsigned short dce ;
    klee_make_symbolic(&dce, sizeof(short), "dce");
};
typedef struct __anonstruct_fr_proto_222 fr_proto;
struct __anonstruct_fr_proto_pvc_223 {
   unsigned int dlci ;
    klee_make_symbolic(&dlci, sizeof(int), "dlci");
};
typedef struct __anonstruct_fr_proto_pvc_223 fr_proto_pvc;
struct __anonstruct_fr_proto_pvc_info_224 {
   unsigned int dlci ;
   char master[16U] ;
};
typedef struct __anonstruct_fr_proto_pvc_info_224 fr_proto_pvc_info;
struct __anonstruct_cisco_proto_225 {
   unsigned int interval ;
    klee_make_symbolic(&interval, sizeof(int), "interval");
   unsigned int timeout ;
};
typedef struct __anonstruct_cisco_proto_225 cisco_proto;
struct ifmap {
   unsigned long mem_start ;
    klee_make_symbolic(&mem_start, sizeof(long), "mem_start");
   unsigned long mem_end ;
    klee_make_symbolic(&mem_end, sizeof(long), "mem_end");
   unsigned short base_addr ;
    klee_make_symbolic(&base_addr, sizeof(short), "base_addr");
   unsigned char irq ;
    klee_make_symbolic(&irq, sizeof(char), "irq");
   unsigned char dma ;
    klee_make_symbolic(&dma, sizeof(char), "dma");
   unsigned char port ;
    klee_make_symbolic(&port, sizeof(char), "port");
};
union __anonunion_ifs_ifsu_226 {
   raw_hdlc_proto *raw_hdlc ;
   cisco_proto *cisco ;
   fr_proto *fr ;
   fr_proto_pvc *fr_pvc ;
   fr_proto_pvc_info *fr_pvc_info ;
   sync_serial_settings *sync ;
   te1_settings *te1 ;
};
struct if_settings {
   unsigned int type ;
   unsigned int size ;
   union __anonunion_ifs_ifsu_226 ifs_ifsu ;
};
union __anonunion_ifr_ifrn_227 {
   char ifrn_name[16U] ;
};
union __anonunion_ifr_ifru_228 {
   struct sockaddr ifru_addr ;
   struct sockaddr ifru_dstaddr ;
   struct sockaddr ifru_broadaddr ;
   struct sockaddr ifru_netmask ;
   struct sockaddr ifru_hwaddr ;
   short ifru_flags ;
    klee_make_symbolic(&ifru_flags, sizeof(short), "ifru_flags");
   int ifru_ivalue ;
    klee_make_symbolic(&ifru_ivalue, sizeof(int), "ifru_ivalue");
   int ifru_mtu ;
    klee_make_symbolic(&ifru_mtu, sizeof(int), "ifru_mtu");
   struct ifmap ifru_map ;
   char ifru_slave[16U] ;
   char ifru_newname[16U] ;
   void *ifru_data ;
   struct if_settings ifru_settings ;
};
struct ifreq {
   union __anonunion_ifr_ifrn_227 ifr_ifrn ;
   union __anonunion_ifr_ifru_228 ifr_ifru ;
};
struct hlist_bl_node;
struct hlist_bl_head {
   struct hlist_bl_node *first ;
};
struct hlist_bl_node {
   struct hlist_bl_node *next ;
   struct hlist_bl_node **pprev ;
};
struct __anonstruct____missing_field_name_233 {
   spinlock_t lock ;
   int count ;
};
union __anonunion____missing_field_name_232 {
   struct __anonstruct____missing_field_name_233 __annonCompField59 ;
};
struct lockref {
   union __anonunion____missing_field_name_232 __annonCompField60 ;
};
struct vfsmount;
struct __anonstruct____missing_field_name_235 {
   u32 hash ;
   u32 len ;
};
union __anonunion____missing_field_name_234 {
   struct __anonstruct____missing_field_name_235 __annonCompField61 ;
   u64 hash_len ;
};
struct qstr {
   union __anonunion____missing_field_name_234 __annonCompField62 ;
   unsigned char const   *name ;
};
struct dentry_operations;
union __anonunion_d_u_236 {
   struct hlist_node d_alias ;
   struct callback_head d_rcu ;
};
struct dentry {
   unsigned int d_flags ;
    klee_make_symbolic(&d_flags, sizeof(int), "d_flags");
   seqcount_t d_seq ;
   struct hlist_bl_node d_hash ;
   struct dentry *d_parent ;
   struct qstr d_name ;
   struct inode *d_inode ;
   unsigned char d_iname[32U] ;
   struct lockref d_lockref ;
   struct dentry_operations  const  *d_op ;
   struct super_block *d_sb ;
   unsigned long d_time ;
    klee_make_symbolic(&d_time, sizeof(long), "d_time");
   void *d_fsdata ;
   struct list_head d_lru ;
   struct list_head d_child ;
   struct list_head d_subdirs ;
   union __anonunion_d_u_236 d_u ;
};
struct dentry_operations {
   int (*d_revalidate)(struct dentry * , unsigned int  ) ;
   int (*d_weak_revalidate)(struct dentry * , unsigned int  ) ;
   int (*d_hash)(struct dentry  const  * , struct qstr * ) ;
   int (*d_compare)(struct dentry  const  * , struct dentry  const  * , unsigned int  ,
                    char const   * , struct qstr  const  * ) ;
   int (*d_delete)(struct dentry  const  * ) ;
   void (*d_release)(struct dentry * ) ;
   void (*d_prune)(struct dentry * ) ;
   void (*d_iput)(struct dentry * , struct inode * ) ;
   char *(*d_dname)(struct dentry * , char * , int  ) ;
   struct vfsmount *(*d_automount)(struct path * ) ;
   int (*d_manage)(struct dentry * , bool  ) ;
   struct inode *(*d_select_inode)(struct dentry * , unsigned int  ) ;
};
struct path {
   struct vfsmount *mnt ;
   struct dentry *dentry ;
};
struct list_lru_one {
   struct list_head list ;
   long nr_items ;
    klee_make_symbolic(&nr_items, sizeof(long), "nr_items");
};
struct list_lru_memcg {
   struct list_lru_one *lru[0U] ;
};
struct list_lru_node {
   spinlock_t lock ;
   struct list_lru_one lru ;
   struct list_lru_memcg *memcg_lrus ;
};
struct list_lru {
   struct list_lru_node *node ;
   struct list_head list ;
};
struct __anonstruct____missing_field_name_240 {
   struct radix_tree_node *parent ;
   void *private_data ;
};
union __anonunion____missing_field_name_239 {
   struct __anonstruct____missing_field_name_240 __annonCompField63 ;
   struct callback_head callback_head ;
};
struct radix_tree_node {
   unsigned int path ;
    klee_make_symbolic(&path, sizeof(int), "path");
   unsigned int count ;
   union __anonunion____missing_field_name_239 __annonCompField64 ;
   struct list_head private_list ;
   void *slots[64U] ;
   unsigned long tags[3U][1U] ;
};
struct radix_tree_root {
   unsigned int height ;
    klee_make_symbolic(&height, sizeof(int), "height");
   gfp_t gfp_mask ;
   struct radix_tree_node *rnode ;
};
struct fiemap_extent {
   __u64 fe_logical ;
   __u64 fe_physical ;
   __u64 fe_length ;
   __u64 fe_reserved64[2U] ;
   __u32 fe_flags ;
   __u32 fe_reserved[3U] ;
};
enum migrate_mode {
    MIGRATE_ASYNC = 0,
    MIGRATE_SYNC_LIGHT = 1,
    MIGRATE_SYNC = 2
} ;
struct block_device;
struct bio_vec {
   struct page *bv_page ;
   unsigned int bv_len ;
    klee_make_symbolic(&bv_len, sizeof(int), "bv_len");
   unsigned int bv_offset ;
    klee_make_symbolic(&bv_offset, sizeof(int), "bv_offset");
};
struct export_operations;
struct poll_table_struct;
struct kstatfs;
struct swap_info_struct;
struct iattr {
   unsigned int ia_valid ;
    klee_make_symbolic(&ia_valid, sizeof(int), "ia_valid");
   umode_t ia_mode ;
   kuid_t ia_uid ;
   kgid_t ia_gid ;
   loff_t ia_size ;
   struct timespec ia_atime ;
   struct timespec ia_mtime ;
   struct timespec ia_ctime ;
   struct file *ia_file ;
};
struct dquot;
typedef __kernel_uid32_t projid_t;
struct __anonstruct_kprojid_t_244 {
   projid_t val ;
};
typedef struct __anonstruct_kprojid_t_244 kprojid_t;
enum quota_type {
    USRQUOTA = 0,
    GRPQUOTA = 1,
    PRJQUOTA = 2
} ;
typedef long long qsize_t;
    klee_make_symbolic(&qsize_t, sizeof(long), "qsize_t");
union __anonunion____missing_field_name_245 {
   kuid_t uid ;
   kgid_t gid ;
   kprojid_t projid ;
};
struct kqid {
   union __anonunion____missing_field_name_245 __annonCompField66 ;
   enum quota_type type ;
};
struct mem_dqblk {
   qsize_t dqb_bhardlimit ;
   qsize_t dqb_bsoftlimit ;
   qsize_t dqb_curspace ;
   qsize_t dqb_rsvspace ;
   qsize_t dqb_ihardlimit ;
   qsize_t dqb_isoftlimit ;
   qsize_t dqb_curinodes ;
   time_t dqb_btime ;
   time_t dqb_itime ;
};
struct quota_format_type;
struct mem_dqinfo {
   struct quota_format_type *dqi_format ;
   int dqi_fmt_id ;
    klee_make_symbolic(&dqi_fmt_id, sizeof(int), "dqi_fmt_id");
   struct list_head dqi_dirty_list ;
   unsigned long dqi_flags ;
    klee_make_symbolic(&dqi_flags, sizeof(long), "dqi_flags");
   unsigned int dqi_bgrace ;
    klee_make_symbolic(&dqi_bgrace, sizeof(int), "dqi_bgrace");
   unsigned int dqi_igrace ;
    klee_make_symbolic(&dqi_igrace, sizeof(int), "dqi_igrace");
   qsize_t dqi_max_spc_limit ;
   qsize_t dqi_max_ino_limit ;
   void *dqi_priv ;
};
struct dquot {
   struct hlist_node dq_hash ;
   struct list_head dq_inuse ;
   struct list_head dq_free ;
   struct list_head dq_dirty ;
   struct mutex dq_lock ;
   atomic_t dq_count ;
   wait_queue_head_t dq_wait_unused ;
   struct super_block *dq_sb ;
   struct kqid dq_id ;
   loff_t dq_off ;
   unsigned long dq_flags ;
    klee_make_symbolic(&dq_flags, sizeof(long), "dq_flags");
   struct mem_dqblk dq_dqb ;
};
struct quota_format_ops {
   int (*check_quota_file)(struct super_block * , int  ) ;
   int (*read_file_info)(struct super_block * , int  ) ;
   int (*write_file_info)(struct super_block * , int  ) ;
   int (*free_file_info)(struct super_block * , int  ) ;
   int (*read_dqblk)(struct dquot * ) ;
   int (*commit_dqblk)(struct dquot * ) ;
   int (*release_dqblk)(struct dquot * ) ;
};
struct dquot_operations {
   int (*write_dquot)(struct dquot * ) ;
   struct dquot *(*alloc_dquot)(struct super_block * , int  ) ;
   void (*destroy_dquot)(struct dquot * ) ;
   int (*acquire_dquot)(struct dquot * ) ;
   int (*release_dquot)(struct dquot * ) ;
   int (*mark_dirty)(struct dquot * ) ;
   int (*write_info)(struct super_block * , int  ) ;
   qsize_t *(*get_reserved_space)(struct inode * ) ;
   int (*get_projid)(struct inode * , kprojid_t * ) ;
};
struct qc_dqblk {
   int d_fieldmask ;
    klee_make_symbolic(&d_fieldmask, sizeof(int), "d_fieldmask");
   u64 d_spc_hardlimit ;
   u64 d_spc_softlimit ;
   u64 d_ino_hardlimit ;
   u64 d_ino_softlimit ;
   u64 d_space ;
   u64 d_ino_count ;
   s64 d_ino_timer ;
   s64 d_spc_timer ;
   int d_ino_warns ;
    klee_make_symbolic(&d_ino_warns, sizeof(int), "d_ino_warns");
   int d_spc_warns ;
    klee_make_symbolic(&d_spc_warns, sizeof(int), "d_spc_warns");
   u64 d_rt_spc_hardlimit ;
   u64 d_rt_spc_softlimit ;
   u64 d_rt_space ;
   s64 d_rt_spc_timer ;
   int d_rt_spc_warns ;
    klee_make_symbolic(&d_rt_spc_warns, sizeof(int), "d_rt_spc_warns");
};
struct qc_type_state {
   unsigned int flags ;
   unsigned int spc_timelimit ;
    klee_make_symbolic(&spc_timelimit, sizeof(int), "spc_timelimit");
   unsigned int ino_timelimit ;
    klee_make_symbolic(&ino_timelimit, sizeof(int), "ino_timelimit");
   unsigned int rt_spc_timelimit ;
    klee_make_symbolic(&rt_spc_timelimit, sizeof(int), "rt_spc_timelimit");
   unsigned int spc_warnlimit ;
    klee_make_symbolic(&spc_warnlimit, sizeof(int), "spc_warnlimit");
   unsigned int ino_warnlimit ;
    klee_make_symbolic(&ino_warnlimit, sizeof(int), "ino_warnlimit");
   unsigned int rt_spc_warnlimit ;
    klee_make_symbolic(&rt_spc_warnlimit, sizeof(int), "rt_spc_warnlimit");
   unsigned long long ino ;
   blkcnt_t blocks ;
   blkcnt_t nextents ;
};
struct qc_state {
   unsigned int s_incoredqs ;
    klee_make_symbolic(&s_incoredqs, sizeof(int), "s_incoredqs");
   struct qc_type_state s_state[3U] ;
};
struct qc_info {
   int i_fieldmask ;
    klee_make_symbolic(&i_fieldmask, sizeof(int), "i_fieldmask");
   unsigned int i_flags ;
    klee_make_symbolic(&i_flags, sizeof(int), "i_flags");
   unsigned int i_spc_timelimit ;
    klee_make_symbolic(&i_spc_timelimit, sizeof(int), "i_spc_timelimit");
   unsigned int i_ino_timelimit ;
    klee_make_symbolic(&i_ino_timelimit, sizeof(int), "i_ino_timelimit");
   unsigned int i_rt_spc_timelimit ;
    klee_make_symbolic(&i_rt_spc_timelimit, sizeof(int), "i_rt_spc_timelimit");
   unsigned int i_spc_warnlimit ;
    klee_make_symbolic(&i_spc_warnlimit, sizeof(int), "i_spc_warnlimit");
   unsigned int i_ino_warnlimit ;
    klee_make_symbolic(&i_ino_warnlimit, sizeof(int), "i_ino_warnlimit");
   unsigned int i_rt_spc_warnlimit ;
    klee_make_symbolic(&i_rt_spc_warnlimit, sizeof(int), "i_rt_spc_warnlimit");
};
struct quotactl_ops {
   int (*quota_on)(struct super_block * , int  , int  , struct path * ) ;
   int (*quota_off)(struct super_block * , int  ) ;
   int (*quota_enable)(struct super_block * , unsigned int  ) ;
   int (*quota_disable)(struct super_block * , unsigned int  ) ;
   int (*quota_sync)(struct super_block * , int  ) ;
   int (*set_info)(struct super_block * , int  , struct qc_info * ) ;
   int (*get_dqblk)(struct super_block * , struct kqid  , struct qc_dqblk * ) ;
   int (*set_dqblk)(struct super_block * , struct kqid  , struct qc_dqblk * ) ;
   int (*get_state)(struct super_block * , struct qc_state * ) ;
   int (*rm_xquota)(struct super_block * , unsigned int  ) ;
};
struct quota_format_type {
   int qf_fmt_id ;
    klee_make_symbolic(&qf_fmt_id, sizeof(int), "qf_fmt_id");
   struct quota_format_ops  const  *qf_ops ;
   struct module *qf_owner ;
   struct quota_format_type *qf_next ;
};
struct quota_info {
   unsigned int flags ;
   struct mutex dqio_mutex ;
   struct mutex dqonoff_mutex ;
   struct inode *files[3U] ;
   struct mem_dqinfo info[3U] ;
   struct quota_format_ops  const  *ops[3U] ;
};
struct kiocb {
   struct file *ki_filp ;
   loff_t ki_pos ;
   void (*ki_complete)(struct kiocb * , long  , long  ) ;
   void *private ;
   int ki_flags ;
    klee_make_symbolic(&ki_flags, sizeof(int), "ki_flags");
};
struct address_space_operations {
   int (*writepage)(struct page * , struct writeback_control * ) ;
   int (*readpage)(struct file * , struct page * ) ;
   int (*writepages)(struct address_space * , struct writeback_control * ) ;
   int (*set_page_dirty)(struct page * ) ;
   int (*readpages)(struct file * , struct address_space * , struct list_head * ,
                    unsigned int  ) ;
   int (*write_begin)(struct file * , struct address_space * , loff_t  , unsigned int  ,
                      unsigned int  , struct page ** , void ** ) ;
   int (*write_end)(struct file * , struct address_space * , loff_t  , unsigned int  ,
                    unsigned int  , struct page * , void * ) ;
   sector_t (*bmap)(struct address_space * , sector_t  ) ;
   void (*invalidatepage)(struct page * , unsigned int  , unsigned int  ) ;
   int (*releasepage)(struct page * , gfp_t  ) ;
   void (*freepage)(struct page * ) ;
   ssize_t (*direct_IO)(struct kiocb * , struct iov_iter * , loff_t  ) ;
   int (*migratepage)(struct address_space * , struct page * , struct page * , enum migrate_mode  ) ;
   int (*launder_page)(struct page * ) ;
   int (*is_partially_uptodate)(struct page * , unsigned long  , unsigned long  ) ;
   void (*is_dirty_writeback)(struct page * , bool * , bool * ) ;
   int (*error_remove_page)(struct address_space * , struct page * ) ;
   int (*swap_activate)(struct swap_info_struct * , struct file * , sector_t * ) ;
   void (*swap_deactivate)(struct file * ) ;
};
struct address_space {
   struct inode *host ;
   struct radix_tree_root page_tree ;
   spinlock_t tree_lock ;
   atomic_t i_mmap_writable ;
   struct rb_root i_mmap ;
   struct rw_semaphore i_mmap_rwsem ;
   unsigned long nrpages ;
    klee_make_symbolic(&nrpages, sizeof(long), "nrpages");
   unsigned long nrshadows ;
    klee_make_symbolic(&nrshadows, sizeof(long), "nrshadows");
   unsigned long writeback_index ;
    klee_make_symbolic(&writeback_index, sizeof(long), "writeback_index");
   struct address_space_operations  const  *a_ops ;
   unsigned long flags ;
   spinlock_t private_lock ;
   struct list_head private_list ;
   void *private_data ;
};
struct request_queue;
struct hd_struct;
struct gendisk;
struct block_device {
   dev_t bd_dev ;
   int bd_openers ;
    klee_make_symbolic(&bd_openers, sizeof(int), "bd_openers");
   struct inode *bd_inode ;
   struct super_block *bd_super ;
   struct mutex bd_mutex ;
   struct list_head bd_inodes ;
   void *bd_claiming ;
   void *bd_holder ;
   int bd_holders ;
    klee_make_symbolic(&bd_holders, sizeof(int), "bd_holders");
   bool bd_write_holder ;
   struct list_head bd_holder_disks ;
   struct block_device *bd_contains ;
   unsigned int bd_block_size ;
    klee_make_symbolic(&bd_block_size, sizeof(int), "bd_block_size");
   struct hd_struct *bd_part ;
   unsigned int bd_part_count ;
    klee_make_symbolic(&bd_part_count, sizeof(int), "bd_part_count");
   int bd_invalidated ;
    klee_make_symbolic(&bd_invalidated, sizeof(int), "bd_invalidated");
   struct gendisk *bd_disk ;
   struct request_queue *bd_queue ;
   struct list_head bd_list ;
   unsigned long bd_private ;
    klee_make_symbolic(&bd_private, sizeof(long), "bd_private");
   int bd_fsfreeze_count ;
    klee_make_symbolic(&bd_fsfreeze_count, sizeof(int), "bd_fsfreeze_count");
   struct mutex bd_fsfreeze_mutex ;
};
struct posix_acl;
struct inode_operations;
union __anonunion____missing_field_name_248 {
   unsigned int const   i_nlink ;
   unsigned int __i_nlink ;
    klee_make_symbolic(&__i_nlink, sizeof(int), "__i_nlink");
};
union __anonunion____missing_field_name_249 {
   struct hlist_head i_dentry ;
   struct callback_head i_rcu ;
};
struct file_lock_context;
struct cdev;
union __anonunion____missing_field_name_250 {
   struct pipe_inode_info *i_pipe ;
   struct block_device *i_bdev ;
   struct cdev *i_cdev ;
   char *i_link ;
};
struct inode {
   umode_t i_mode ;
   unsigned short i_opflags ;
    klee_make_symbolic(&i_opflags, sizeof(short), "i_opflags");
   kuid_t i_uid ;
   kgid_t i_gid ;
   unsigned int i_flags ;
   struct posix_acl *i_acl ;
   struct posix_acl *i_default_acl ;
   struct inode_operations  const  *i_op ;
   struct super_block *i_sb ;
   struct address_space *i_mapping ;
   void *i_security ;
   unsigned long i_ino ;
    klee_make_symbolic(&i_ino, sizeof(long), "i_ino");
   union __anonunion____missing_field_name_248 __annonCompField67 ;
   dev_t i_rdev ;
   loff_t i_size ;
   struct timespec i_atime ;
   struct timespec i_mtime ;
   struct timespec i_ctime ;
   spinlock_t i_lock ;
   unsigned short i_bytes ;
    klee_make_symbolic(&i_bytes, sizeof(short), "i_bytes");
   unsigned int i_blkbits ;
    klee_make_symbolic(&i_blkbits, sizeof(int), "i_blkbits");
   blkcnt_t i_blocks ;
   unsigned long i_state ;
    klee_make_symbolic(&i_state, sizeof(long), "i_state");
   struct mutex i_mutex ;
   unsigned long dirtied_when ;
    klee_make_symbolic(&dirtied_when, sizeof(long), "dirtied_when");
   unsigned long dirtied_time_when ;
    klee_make_symbolic(&dirtied_time_when, sizeof(long), "dirtied_time_when");
   struct hlist_node i_hash ;
   struct list_head i_wb_list ;
   struct bdi_writeback *i_wb ;
   int i_wb_frn_winner ;
    klee_make_symbolic(&i_wb_frn_winner, sizeof(int), "i_wb_frn_winner");
   u16 i_wb_frn_avg_time ;
   u16 i_wb_frn_history ;
   struct list_head i_lru ;
   struct list_head i_sb_list ;
   union __anonunion____missing_field_name_249 __annonCompField68 ;
   u64 i_version ;
   atomic_t i_count ;
   atomic_t i_dio_count ;
   atomic_t i_writecount ;
   atomic_t i_readcount ;
   struct file_operations  const  *i_fop ;
   struct file_lock_context *i_flctx ;
   struct address_space i_data ;
   struct list_head i_devices ;
   union __anonunion____missing_field_name_250 __annonCompField69 ;
   __u32 i_generation ;
   __u32 i_fsnotify_mask ;
   struct hlist_head i_fsnotify_marks ;
   void *i_private ;
};
struct fown_struct {
   rwlock_t lock ;
   struct pid *pid ;
   enum pid_type pid_type ;
   kuid_t uid ;
   kuid_t euid ;
   int signum ;
    klee_make_symbolic(&signum, sizeof(int), "signum");
};
struct file_ra_state {
   unsigned long start ;
    klee_make_symbolic(&start, sizeof(long), "start");
   unsigned int size ;
   unsigned int async_size ;
    klee_make_symbolic(&async_size, sizeof(int), "async_size");
   unsigned int ra_pages ;
    klee_make_symbolic(&ra_pages, sizeof(int), "ra_pages");
   unsigned int mmap_miss ;
    klee_make_symbolic(&mmap_miss, sizeof(int), "mmap_miss");
   loff_t prev_pos ;
};
union __anonunion_f_u_251 {
   struct llist_node fu_llist ;
   struct callback_head fu_rcuhead ;
};
struct file {
   union __anonunion_f_u_251 f_u ;
   struct path f_path ;
   struct inode *f_inode ;
   struct file_operations  const  *f_op ;
   spinlock_t f_lock ;
   atomic_long_t f_count ;
   unsigned int f_flags ;
    klee_make_symbolic(&f_flags, sizeof(int), "f_flags");
   fmode_t f_mode ;
   struct mutex f_pos_lock ;
   loff_t f_pos ;
   struct fown_struct f_owner ;
   struct cred  const  *f_cred ;
   struct file_ra_state f_ra ;
   u64 f_version ;
   void *f_security ;
   void *private_data ;
   struct list_head f_ep_links ;
   struct list_head f_tfile_llink ;
   struct address_space *f_mapping ;
};
typedef void *fl_owner_t;
struct file_lock;
struct file_lock_operations {
   void (*fl_copy_lock)(struct file_lock * , struct file_lock * ) ;
   void (*fl_release_private)(struct file_lock * ) ;
};
struct lock_manager_operations {
   int (*lm_compare_owner)(struct file_lock * , struct file_lock * ) ;
   unsigned long (*lm_owner_key)(struct file_lock * ) ;
   fl_owner_t (*lm_get_owner)(fl_owner_t  ) ;
   void (*lm_put_owner)(fl_owner_t  ) ;
   void (*lm_notify)(struct file_lock * ) ;
   int (*lm_grant)(struct file_lock * , int  ) ;
   bool (*lm_break)(struct file_lock * ) ;
   int (*lm_change)(struct file_lock * , int  , struct list_head * ) ;
   void (*lm_setup)(struct file_lock * , void ** ) ;
};
struct net;
struct nlm_lockowner;
struct nfs_lock_info {
   u32 state ;
   struct nlm_lockowner *owner ;
   struct list_head list ;
};
struct nfs4_lock_state;
struct nfs4_lock_info {
   struct nfs4_lock_state *owner ;
};
struct fasync_struct;
struct __anonstruct_afs_253 {
   struct list_head link ;
   int state ;
};
union __anonunion_fl_u_252 {
   struct nfs_lock_info nfs_fl ;
   struct nfs4_lock_info nfs4_fl ;
   struct __anonstruct_afs_253 afs ;
};
struct file_lock {
   struct file_lock *fl_next ;
   struct list_head fl_list ;
   struct hlist_node fl_link ;
   struct list_head fl_block ;
   fl_owner_t fl_owner ;
   unsigned int fl_flags ;
    klee_make_symbolic(&fl_flags, sizeof(int), "fl_flags");
   unsigned char fl_type ;
    klee_make_symbolic(&fl_type, sizeof(char), "fl_type");
   unsigned int fl_pid ;
    klee_make_symbolic(&fl_pid, sizeof(int), "fl_pid");
   int fl_link_cpu ;
    klee_make_symbolic(&fl_link_cpu, sizeof(int), "fl_link_cpu");
   struct pid *fl_nspid ;
   wait_queue_head_t fl_wait ;
   struct file *fl_file ;
   loff_t fl_start ;
   loff_t fl_end ;
   struct fasync_struct *fl_fasync ;
   unsigned long fl_break_time ;
    klee_make_symbolic(&fl_break_time, sizeof(long), "fl_break_time");
   unsigned long fl_downgrade_time ;
    klee_make_symbolic(&fl_downgrade_time, sizeof(long), "fl_downgrade_time");
   struct file_lock_operations  const  *fl_ops ;
   struct lock_manager_operations  const  *fl_lmops ;
   union __anonunion_fl_u_252 fl_u ;
};
struct file_lock_context {
   spinlock_t flc_lock ;
   struct list_head flc_flock ;
   struct list_head flc_posix ;
   struct list_head flc_lease ;
};
struct fasync_struct {
   spinlock_t fa_lock ;
   int magic ;
   int fa_fd ;
    klee_make_symbolic(&fa_fd, sizeof(int), "fa_fd");
   struct fasync_struct *fa_next ;
   struct file *fa_file ;
   struct callback_head fa_rcu ;
};
struct sb_writers {
   struct percpu_counter counter[3U] ;
   wait_queue_head_t wait ;
   int frozen ;
    klee_make_symbolic(&frozen, sizeof(int), "frozen");
   wait_queue_head_t wait_unfrozen ;
   struct lockdep_map lock_map[3U] ;
};
struct super_operations;
struct xattr_handler;
struct mtd_info;
struct super_block {
   struct list_head s_list ;
   dev_t s_dev ;
   unsigned char s_blocksize_bits ;
    klee_make_symbolic(&s_blocksize_bits, sizeof(char), "s_blocksize_bits");
   unsigned long s_blocksize ;
    klee_make_symbolic(&s_blocksize, sizeof(long), "s_blocksize");
   loff_t s_maxbytes ;
   struct file_system_type *s_type ;
   struct super_operations  const  *s_op ;
   struct dquot_operations  const  *dq_op ;
   struct quotactl_ops  const  *s_qcop ;
   struct export_operations  const  *s_export_op ;
   unsigned long s_flags ;
    klee_make_symbolic(&s_flags, sizeof(long), "s_flags");
   unsigned long s_iflags ;
    klee_make_symbolic(&s_iflags, sizeof(long), "s_iflags");
   unsigned long s_magic ;
    klee_make_symbolic(&s_magic, sizeof(long), "s_magic");
   struct dentry *s_root ;
   struct rw_semaphore s_umount ;
   int s_count ;
    klee_make_symbolic(&s_count, sizeof(int), "s_count");
   atomic_t s_active ;
   void *s_security ;
   struct xattr_handler  const  **s_xattr ;
   struct list_head s_inodes ;
   struct hlist_bl_head s_anon ;
   struct list_head s_mounts ;
   struct block_device *s_bdev ;
   struct backing_dev_info *s_bdi ;
   struct mtd_info *s_mtd ;
   struct hlist_node s_instances ;
   unsigned int s_quota_types ;
    klee_make_symbolic(&s_quota_types, sizeof(int), "s_quota_types");
   struct quota_info s_dquot ;
   struct sb_writers s_writers ;
   char s_id[32U] ;
   u8 s_uuid[16U] ;
   void *s_fs_info ;
   unsigned int s_max_links ;
    klee_make_symbolic(&s_max_links, sizeof(int), "s_max_links");
   fmode_t s_mode ;
   u32 s_time_gran ;
   struct mutex s_vfs_rename_mutex ;
   char *s_subtype ;
   char *s_options ;
   struct dentry_operations  const  *s_d_op ;
   int cleancache_poolid ;
    klee_make_symbolic(&cleancache_poolid, sizeof(int), "cleancache_poolid");
   struct shrinker s_shrink ;
   atomic_long_t s_remove_count ;
   int s_readonly_remount ;
    klee_make_symbolic(&s_readonly_remount, sizeof(int), "s_readonly_remount");
   struct workqueue_struct *s_dio_done_wq ;
   struct hlist_head s_pins ;
   struct list_lru s_dentry_lru ;
   struct list_lru s_inode_lru ;
   struct callback_head rcu ;
   int s_stack_depth ;
    klee_make_symbolic(&s_stack_depth, sizeof(int), "s_stack_depth");
};
struct fiemap_extent_info {
   unsigned int fi_flags ;
    klee_make_symbolic(&fi_flags, sizeof(int), "fi_flags");
   unsigned int fi_extents_mapped ;
    klee_make_symbolic(&fi_extents_mapped, sizeof(int), "fi_extents_mapped");
   unsigned int fi_extents_max ;
    klee_make_symbolic(&fi_extents_max, sizeof(int), "fi_extents_max");
   struct fiemap_extent *fi_extents_start ;
};
struct dir_context;
struct dir_context {
   int (*actor)(struct dir_context * , char const   * , int  , loff_t  , u64  , unsigned int  ) ;
   loff_t pos ;
};
struct file_operations {
   struct module *owner ;
   loff_t (*llseek)(struct file * , loff_t  , int  ) ;
   ssize_t (*read)(struct file * , char * , size_t  , loff_t * ) ;
   ssize_t (*write)(struct file * , char const   * , size_t  , loff_t * ) ;
   ssize_t (*read_iter)(struct kiocb * , struct iov_iter * ) ;
   ssize_t (*write_iter)(struct kiocb * , struct iov_iter * ) ;
   int (*iterate)(struct file * , struct dir_context * ) ;
   unsigned int (*poll)(struct file * , struct poll_table_struct * ) ;
   long (*unlocked_ioctl)(struct file * , unsigned int  , unsigned long  ) ;
   long (*compat_ioctl)(struct file * , unsigned int  , unsigned long  ) ;
   int (*mmap)(struct file * , struct vm_area_struct * ) ;
   int (*mremap)(struct file * , struct vm_area_struct * ) ;
   int (*open)(struct inode * , struct file * ) ;
   int (*flush)(struct file * , fl_owner_t  ) ;
   int (*release)(struct inode * , struct file * ) ;
   int (*fsync)(struct file * , loff_t  , loff_t  , int  ) ;
   int (*aio_fsync)(struct kiocb * , int  ) ;
   int (*fasync)(int  , struct file * , int  ) ;
   int (*lock)(struct file * , int  , struct file_lock * ) ;
   ssize_t (*sendpage)(struct file * , struct page * , int  , size_t  , loff_t * ,
                       int  ) ;
   unsigned long (*get_unmapped_area)(struct file * , unsigned long  , unsigned long  ,
                                      unsigned long  , unsigned long  ) ;
   int (*check_flags)(int  ) ;
   int (*flock)(struct file * , int  , struct file_lock * ) ;
   ssize_t (*splice_write)(struct pipe_inode_info * , struct file * , loff_t * , size_t  ,
                           unsigned int  ) ;
   ssize_t (*splice_read)(struct file * , loff_t * , struct pipe_inode_info * , size_t  ,
                          unsigned int  ) ;
   int (*setlease)(struct file * , long  , struct file_lock ** , void ** ) ;
   long (*fallocate)(struct file * , int  , loff_t  , loff_t  ) ;
   void (*show_fdinfo)(struct seq_file * , struct file * ) ;
};
struct inode_operations {
   struct dentry *(*lookup)(struct inode * , struct dentry * , unsigned int  ) ;
   char const   *(*follow_link)(struct dentry * , void ** ) ;
   int (*permission)(struct inode * , int  ) ;
   struct posix_acl *(*get_acl)(struct inode * , int  ) ;
   int (*readlink)(struct dentry * , char * , int  ) ;
   void (*put_link)(struct inode * , void * ) ;
   int (*create)(struct inode * , struct dentry * , umode_t  , bool  ) ;
   int (*link)(struct dentry * , struct inode * , struct dentry * ) ;
   int (*unlink)(struct inode * , struct dentry * ) ;
   int (*symlink)(struct inode * , struct dentry * , char const   * ) ;
   int (*mkdir)(struct inode * , struct dentry * , umode_t  ) ;
   int (*rmdir)(struct inode * , struct dentry * ) ;
   int (*mknod)(struct inode * , struct dentry * , umode_t  , dev_t  ) ;
   int (*rename)(struct inode * , struct dentry * , struct inode * , struct dentry * ) ;
   int (*rename2)(struct inode * , struct dentry * , struct inode * , struct dentry * ,
                  unsigned int  ) ;
   int (*setattr)(struct dentry * , struct iattr * ) ;
   int (*getattr)(struct vfsmount * , struct dentry * , struct kstat * ) ;
   int (*setxattr)(struct dentry * , char const   * , void const   * , size_t  , int  ) ;
   ssize_t (*getxattr)(struct dentry * , char const   * , void * , size_t  ) ;
   ssize_t (*listxattr)(struct dentry * , char * , size_t  ) ;
   int (*removexattr)(struct dentry * , char const   * ) ;
   int (*fiemap)(struct inode * , struct fiemap_extent_info * , u64  , u64  ) ;
   int (*update_time)(struct inode * , struct timespec * , int  ) ;
   int (*atomic_open)(struct inode * , struct dentry * , struct file * , unsigned int  ,
                      umode_t  , int * ) ;
   int (*tmpfile)(struct inode * , struct dentry * , umode_t  ) ;
   int (*set_acl)(struct inode * , struct posix_acl * , int  ) ;
};
struct super_operations {
   struct inode *(*alloc_inode)(struct super_block * ) ;
   void (*destroy_inode)(struct inode * ) ;
   void (*dirty_inode)(struct inode * , int  ) ;
   int (*write_inode)(struct inode * , struct writeback_control * ) ;
   int (*drop_inode)(struct inode * ) ;
   void (*evict_inode)(struct inode * ) ;
   void (*put_super)(struct super_block * ) ;
   int (*sync_fs)(struct super_block * , int  ) ;
   int (*freeze_super)(struct super_block * ) ;
   int (*freeze_fs)(struct super_block * ) ;
   int (*thaw_super)(struct super_block * ) ;
   int (*unfreeze_fs)(struct super_block * ) ;
   int (*statfs)(struct dentry * , struct kstatfs * ) ;
   int (*remount_fs)(struct super_block * , int * , char * ) ;
   void (*umount_begin)(struct super_block * ) ;
   int (*show_options)(struct seq_file * , struct dentry * ) ;
   int (*show_devname)(struct seq_file * , struct dentry * ) ;
   int (*show_path)(struct seq_file * , struct dentry * ) ;
   int (*show_stats)(struct seq_file * , struct dentry * ) ;
   ssize_t (*quota_read)(struct super_block * , int  , char * , size_t  , loff_t  ) ;
   ssize_t (*quota_write)(struct super_block * , int  , char const   * , size_t  ,
                          loff_t  ) ;
   struct dquot **(*get_dquots)(struct inode * ) ;
   int (*bdev_try_to_free_page)(struct super_block * , struct page * , gfp_t  ) ;
   long (*nr_cached_objects)(struct super_block * , struct shrink_control * ) ;
   long (*free_cached_objects)(struct super_block * , struct shrink_control * ) ;
};
struct file_system_type {
   char const   *name ;
   int fs_flags ;
    klee_make_symbolic(&fs_flags, sizeof(int), "fs_flags");
   struct dentry *(*mount)(struct file_system_type * , int  , char const   * , void * ) ;
   void (*kill_sb)(struct super_block * ) ;
   struct module *owner ;
   struct file_system_type *next ;
   struct hlist_head fs_supers ;
   struct lock_class_key s_lock_key ;
   struct lock_class_key s_umount_key ;
   struct lock_class_key s_vfs_rename_key ;
   struct lock_class_key s_writers_key[3U] ;
   struct lock_class_key i_lock_key ;
   struct lock_class_key i_mutex_key ;
   struct lock_class_key i_mutex_dir_key ;
};
typedef s32 compat_time_t;
typedef s32 compat_long_t;
typedef u32 compat_uptr_t;
struct compat_timespec {
   compat_time_t tv_sec ;
   s32 tv_nsec ;
};
struct compat_robust_list {
   compat_uptr_t next ;
};
struct compat_robust_list_head {
   struct compat_robust_list list ;
   compat_long_t futex_offset ;
   compat_uptr_t list_op_pending ;
};
enum ldv_23684 {
    SS_FREE = 0,
    SS_UNCONNECTED = 1,
    SS_CONNECTING = 2,
    SS_CONNECTED = 3,
    SS_DISCONNECTING = 4
} ;
typedef enum ldv_23684 socket_state;
struct socket_wq {
   wait_queue_head_t wait ;
   struct fasync_struct *fasync_list ;
   struct callback_head rcu ;
};
struct proto_ops;
struct socket {
   socket_state state ;
   short type ;
   unsigned long flags ;
   struct socket_wq *wq ;
   struct file *file ;
   struct sock *sk ;
   struct proto_ops  const  *ops ;
};
struct proto_ops {
   int family ;
    klee_make_symbolic(&family, sizeof(int), "family");
   struct module *owner ;
   int (*release)(struct socket * ) ;
   int (*bind)(struct socket * , struct sockaddr * , int  ) ;
   int (*connect)(struct socket * , struct sockaddr * , int  , int  ) ;
   int (*socketpair)(struct socket * , struct socket * ) ;
   int (*accept)(struct socket * , struct socket * , int  ) ;
   int (*getname)(struct socket * , struct sockaddr * , int * , int  ) ;
   unsigned int (*poll)(struct file * , struct socket * , struct poll_table_struct * ) ;
   int (*ioctl)(struct socket * , unsigned int  , unsigned long  ) ;
   int (*compat_ioctl)(struct socket * , unsigned int  , unsigned long  ) ;
   int (*listen)(struct socket * , int  ) ;
   int (*shutdown)(struct socket * , int  ) ;
   int (*setsockopt)(struct socket * , int  , int  , char * , unsigned int  ) ;
   int (*getsockopt)(struct socket * , int  , int  , char * , int * ) ;
   int (*compat_setsockopt)(struct socket * , int  , int  , char * , unsigned int  ) ;
   int (*compat_getsockopt)(struct socket * , int  , int  , char * , int * ) ;
   int (*sendmsg)(struct socket * , struct msghdr * , size_t  ) ;
   int (*recvmsg)(struct socket * , struct msghdr * , size_t  , int  ) ;
   int (*mmap)(struct file * , struct socket * , struct vm_area_struct * ) ;
   ssize_t (*sendpage)(struct socket * , struct page * , int  , size_t  , int  ) ;
   ssize_t (*splice_read)(struct socket * , loff_t * , struct pipe_inode_info * ,
                          size_t  , unsigned int  ) ;
   int (*set_peek_off)(struct sock * , int  ) ;
};
struct exception_table_entry {
   int insn ;
    klee_make_symbolic(&insn, sizeof(int), "insn");
   int fixup ;
    klee_make_symbolic(&fixup, sizeof(int), "fixup");
};
struct in6_addr;
struct sk_buff;
struct dma_attrs {
   unsigned long flags[1U] ;
};
enum dma_data_direction {
    DMA_BIDIRECTIONAL = 0,
    DMA_TO_DEVICE = 1,
    DMA_FROM_DEVICE = 2,
    DMA_NONE = 3
} ;
struct dma_map_ops {
   void *(*alloc)(struct device * , size_t  , dma_addr_t * , gfp_t  , struct dma_attrs * ) ;
   void (*free)(struct device * , size_t  , void * , dma_addr_t  , struct dma_attrs * ) ;
   int (*mmap)(struct device * , struct vm_area_struct * , void * , dma_addr_t  ,
               size_t  , struct dma_attrs * ) ;
   int (*get_sgtable)(struct device * , struct sg_table * , void * , dma_addr_t  ,
                      size_t  , struct dma_attrs * ) ;
   dma_addr_t (*map_page)(struct device * , struct page * , unsigned long  , size_t  ,
                          enum dma_data_direction  , struct dma_attrs * ) ;
   void (*unmap_page)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ,
                      struct dma_attrs * ) ;
   int (*map_sg)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ,
                 struct dma_attrs * ) ;
   void (*unmap_sg)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ,
                    struct dma_attrs * ) ;
   void (*sync_single_for_cpu)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ) ;
   void (*sync_single_for_device)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ) ;
   void (*sync_sg_for_cpu)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ) ;
   void (*sync_sg_for_device)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ) ;
   int (*mapping_error)(struct device * , dma_addr_t  ) ;
   int (*dma_supported)(struct device * , u64  ) ;
   int (*set_dma_mask)(struct device * , u64  ) ;
   int is_phys ;
    klee_make_symbolic(&is_phys, sizeof(int), "is_phys");
};
typedef u64 netdev_features_t;
union __anonunion_in6_u_268 {
   __u8 u6_addr8[16U] ;
   __be16 u6_addr16[8U] ;
   __be32 u6_addr32[4U] ;
};
struct in6_addr {
   union __anonunion_in6_u_268 in6_u ;
};
struct ethhdr {
   unsigned char h_dest[6U] ;
   unsigned char h_source[6U] ;
   __be16 h_proto ;
};
struct pipe_buf_operations;
struct pipe_buffer {
   struct page *page ;
   unsigned int offset ;
   unsigned int len ;
    klee_make_symbolic(&len, sizeof(int), "len");
   struct pipe_buf_operations  const  *ops ;
   unsigned int flags ;
   unsigned long private ;
};
struct pipe_inode_info {
   struct mutex mutex ;
   wait_queue_head_t wait ;
   unsigned int nrbufs ;
    klee_make_symbolic(&nrbufs, sizeof(int), "nrbufs");
   unsigned int curbuf ;
    klee_make_symbolic(&curbuf, sizeof(int), "curbuf");
   unsigned int buffers ;
    klee_make_symbolic(&buffers, sizeof(int), "buffers");
   unsigned int readers ;
    klee_make_symbolic(&readers, sizeof(int), "readers");
   unsigned int writers ;
    klee_make_symbolic(&writers, sizeof(int), "writers");
   unsigned int files ;
    klee_make_symbolic(&files, sizeof(int), "files");
   unsigned int waiting_writers ;
    klee_make_symbolic(&waiting_writers, sizeof(int), "waiting_writers");
   unsigned int r_counter ;
    klee_make_symbolic(&r_counter, sizeof(int), "r_counter");
   unsigned int w_counter ;
    klee_make_symbolic(&w_counter, sizeof(int), "w_counter");
   struct page *tmp_page ;
   struct fasync_struct *fasync_readers ;
   struct fasync_struct *fasync_writers ;
   struct pipe_buffer *bufs ;
};
struct pipe_buf_operations {
   int can_merge ;
    klee_make_symbolic(&can_merge, sizeof(int), "can_merge");
   int (*confirm)(struct pipe_inode_info * , struct pipe_buffer * ) ;
   void (*release)(struct pipe_inode_info * , struct pipe_buffer * ) ;
   int (*steal)(struct pipe_inode_info * , struct pipe_buffer * ) ;
   void (*get)(struct pipe_inode_info * , struct pipe_buffer * ) ;
};
struct napi_struct;
struct nf_conntrack {
   atomic_t use ;
};
union __anonunion____missing_field_name_273 {
   struct net_device *physoutdev ;
   char neigh_header[8U] ;
};
union __anonunion____missing_field_name_274 {
   __be32 ipv4_daddr ;
   struct in6_addr ipv6_daddr ;
};
struct nf_bridge_info {
   atomic_t use ;
   unsigned char orig_proto ;
    klee_make_symbolic(&orig_proto, sizeof(char), "orig_proto");
   bool pkt_otherhost ;
   __u16 frag_max_size ;
   unsigned int mask ;
    klee_make_symbolic(&mask, sizeof(int), "mask");
   struct net_device *physindev ;
   union __anonunion____missing_field_name_273 __annonCompField73 ;
   union __anonunion____missing_field_name_274 __annonCompField74 ;
};
struct sk_buff_head {
   struct sk_buff *next ;
   struct sk_buff *prev ;
   __u32 qlen ;
   spinlock_t lock ;
};
struct skb_frag_struct;
typedef struct skb_frag_struct skb_frag_t;
struct __anonstruct_page_275 {
   struct page *p ;
};
struct skb_frag_struct {
   struct __anonstruct_page_275 page ;
   __u32 page_offset ;
   __u32 size ;
};
struct skb_shared_hwtstamps {
   ktime_t hwtstamp ;
};
struct skb_shared_info {
   unsigned char nr_frags ;
    klee_make_symbolic(&nr_frags, sizeof(char), "nr_frags");
   __u8 tx_flags ;
   unsigned short gso_size ;
    klee_make_symbolic(&gso_size, sizeof(short), "gso_size");
   unsigned short gso_segs ;
    klee_make_symbolic(&gso_segs, sizeof(short), "gso_segs");
   unsigned short gso_type ;
    klee_make_symbolic(&gso_type, sizeof(short), "gso_type");
   struct sk_buff *frag_list ;
   struct skb_shared_hwtstamps hwtstamps ;
   u32 tskey ;
   __be32 ip6_frag_id ;
   atomic_t dataref ;
   void *destructor_arg ;
   skb_frag_t frags[17U] ;
};
typedef unsigned int sk_buff_data_t;
    klee_make_symbolic(&sk_buff_data_t, sizeof(int), "sk_buff_data_t");
struct __anonstruct____missing_field_name_277 {
   u32 stamp_us ;
   u32 stamp_jiffies ;
};
union __anonunion____missing_field_name_276 {
   u64 v64 ;
   struct __anonstruct____missing_field_name_277 __annonCompField75 ;
};
struct skb_mstamp {
   union __anonunion____missing_field_name_276 __annonCompField76 ;
};
union __anonunion____missing_field_name_280 {
   ktime_t tstamp ;
   struct skb_mstamp skb_mstamp ;
};
struct __anonstruct____missing_field_name_279 {
   struct sk_buff *next ;
   struct sk_buff *prev ;
   union __anonunion____missing_field_name_280 __annonCompField77 ;
};
union __anonunion____missing_field_name_278 {
   struct __anonstruct____missing_field_name_279 __annonCompField78 ;
   struct rb_node rbnode ;
};
struct sec_path;
struct __anonstruct____missing_field_name_282 {
   __u16 csum_start ;
   __u16 csum_offset ;
};
union __anonunion____missing_field_name_281 {
   __wsum csum ;
   struct __anonstruct____missing_field_name_282 __annonCompField80 ;
};
union __anonunion____missing_field_name_283 {
   unsigned int napi_id ;
    klee_make_symbolic(&napi_id, sizeof(int), "napi_id");
   unsigned int sender_cpu ;
    klee_make_symbolic(&sender_cpu, sizeof(int), "sender_cpu");
};
union __anonunion____missing_field_name_284 {
   __u32 mark ;
   __u32 reserved_tailroom ;
};
union __anonunion____missing_field_name_285 {
   __be16 inner_protocol ;
   __u8 inner_ipproto ;
};
struct sk_buff {
   union __anonunion____missing_field_name_278 __annonCompField79 ;
   struct sock *sk ;
   struct net_device *dev ;
   char cb[48U] ;
   unsigned long _skb_refdst ;
    klee_make_symbolic(&_skb_refdst, sizeof(long), "_skb_refdst");
   void (*destructor)(struct sk_buff * ) ;
   struct sec_path *sp ;
   struct nf_conntrack *nfct ;
   struct nf_bridge_info *nf_bridge ;
   unsigned int len ;
   unsigned int data_len ;
    klee_make_symbolic(&data_len, sizeof(int), "data_len");
   __u16 mac_len ;
   __u16 hdr_len ;
   __u16 queue_mapping ;
   unsigned char cloned : 1 ;
   unsigned char nohdr : 1 ;
   unsigned char fclone : 2 ;
   unsigned char peeked : 1 ;
   unsigned char head_frag : 1 ;
   unsigned char xmit_more : 1 ;
   __u32 headers_start[0U] ;
   __u8 __pkt_type_offset[0U] ;
   unsigned char pkt_type : 3 ;
   unsigned char pfmemalloc : 1 ;
   unsigned char ignore_df : 1 ;
   unsigned char nfctinfo : 3 ;
   unsigned char nf_trace : 1 ;
   unsigned char ip_summed : 2 ;
   unsigned char ooo_okay : 1 ;
   unsigned char l4_hash : 1 ;
   unsigned char sw_hash : 1 ;
   unsigned char wifi_acked_valid : 1 ;
   unsigned char wifi_acked : 1 ;
   unsigned char no_fcs : 1 ;
   unsigned char encapsulation : 1 ;
   unsigned char encap_hdr_csum : 1 ;
   unsigned char csum_valid : 1 ;
   unsigned char csum_complete_sw : 1 ;
   unsigned char csum_level : 2 ;
   unsigned char csum_bad : 1 ;
   unsigned char ndisc_nodetype : 2 ;
   unsigned char ipvs_property : 1 ;
   unsigned char inner_protocol_type : 1 ;
   unsigned char remcsum_offload : 1 ;
   __u16 tc_index ;
   __u16 tc_verd ;
   union __anonunion____missing_field_name_281 __annonCompField81 ;
   __u32 priority ;
   int skb_iif ;
    klee_make_symbolic(&skb_iif, sizeof(int), "skb_iif");
   __u32 hash ;
   __be16 vlan_proto ;
   __u16 vlan_tci ;
   union __anonunion____missing_field_name_283 __annonCompField82 ;
   __u32 secmark ;
   union __anonunion____missing_field_name_284 __annonCompField83 ;
   union __anonunion____missing_field_name_285 __annonCompField84 ;
   __u16 inner_transport_header ;
   __u16 inner_network_header ;
   __u16 inner_mac_header ;
   __be16 protocol ;
   __u16 transport_header ;
   __u16 network_header ;
   __u16 mac_header ;
   __u32 headers_end[0U] ;
   sk_buff_data_t tail ;
   sk_buff_data_t end ;
   unsigned char *head ;
   unsigned char *data ;
   unsigned int truesize ;
    klee_make_symbolic(&truesize, sizeof(int), "truesize");
   atomic_t users ;
};
struct dst_entry;
struct rtable;
struct ethtool_cmd {
   __u32 cmd ;
   __u32 supported ;
   __u32 advertising ;
   __u16 speed ;
   __u8 duplex ;
   __u8 port ;
   __u8 phy_address ;
   __u8 transceiver ;
   __u8 autoneg ;
   __u8 mdio_support ;
   __u32 maxtxpkt ;
   __u32 maxrxpkt ;
   __u16 speed_hi ;
   __u8 eth_tp_mdix ;
   __u8 eth_tp_mdix_ctrl ;
   __u32 lp_advertising ;
   __u32 reserved[2U] ;
};
struct ethtool_drvinfo {
   __u32 cmd ;
   char driver[32U] ;
   char version[32U] ;
   char fw_version[32U] ;
   char bus_info[32U] ;
   char erom_version[32U] ;
   char reserved2[12U] ;
   __u32 n_priv_flags ;
   __u32 n_stats ;
   __u32 testinfo_len ;
   __u32 eedump_len ;
   __u32 regdump_len ;
};
struct ethtool_wolinfo {
   __u32 cmd ;
   __u32 supported ;
   __u32 wolopts ;
   __u8 sopass[6U] ;
};
struct ethtool_tunable {
   __u32 cmd ;
   __u32 id ;
   __u32 type_id ;
   __u32 len ;
   void *data[0U] ;
};
struct ethtool_regs {
   __u32 cmd ;
   __u32 version ;
   __u32 len ;
   __u8 data[0U] ;
};
struct ethtool_eeprom {
   __u32 cmd ;
   __u32 magic ;
   __u32 offset ;
   __u32 len ;
   __u8 data[0U] ;
};
struct ethtool_eee {
   __u32 cmd ;
   __u32 supported ;
   __u32 advertised ;
   __u32 lp_advertised ;
   __u32 eee_active ;
   __u32 eee_enabled ;
   __u32 tx_lpi_enabled ;
   __u32 tx_lpi_timer ;
   __u32 reserved[2U] ;
};
struct ethtool_modinfo {
   __u32 cmd ;
   __u32 type ;
   __u32 eeprom_len ;
   __u32 reserved[8U] ;
};
struct ethtool_coalesce {
   __u32 cmd ;
   __u32 rx_coalesce_usecs ;
   __u32 rx_max_coalesced_frames ;
   __u32 rx_coalesce_usecs_irq ;
   __u32 rx_max_coalesced_frames_irq ;
   __u32 tx_coalesce_usecs ;
   __u32 tx_max_coalesced_frames ;
   __u32 tx_coalesce_usecs_irq ;
   __u32 tx_max_coalesced_frames_irq ;
   __u32 stats_block_coalesce_usecs ;
   __u32 use_adaptive_rx_coalesce ;
   __u32 use_adaptive_tx_coalesce ;
   __u32 pkt_rate_low ;
   __u32 rx_coalesce_usecs_low ;
   __u32 rx_max_coalesced_frames_low ;
   __u32 tx_coalesce_usecs_low ;
   __u32 tx_max_coalesced_frames_low ;
   __u32 pkt_rate_high ;
   __u32 rx_coalesce_usecs_high ;
   __u32 rx_max_coalesced_frames_high ;
   __u32 tx_coalesce_usecs_high ;
   __u32 tx_max_coalesced_frames_high ;
   __u32 rate_sample_interval ;
};
struct ethtool_ringparam {
   __u32 cmd ;
   __u32 rx_max_pending ;
   __u32 rx_mini_max_pending ;
   __u32 rx_jumbo_max_pending ;
   __u32 tx_max_pending ;
   __u32 rx_pending ;
   __u32 rx_mini_pending ;
   __u32 rx_jumbo_pending ;
   __u32 tx_pending ;
};
struct ethtool_channels {
   __u32 cmd ;
   __u32 max_rx ;
   __u32 max_tx ;
   __u32 max_other ;
   __u32 max_combined ;
   __u32 rx_count ;
   __u32 tx_count ;
   __u32 other_count ;
   __u32 combined_count ;
};
struct ethtool_pauseparam {
   __u32 cmd ;
   __u32 autoneg ;
   __u32 rx_pause ;
   __u32 tx_pause ;
};
struct ethtool_test {
   __u32 cmd ;
   __u32 flags ;
   __u32 reserved ;
   __u32 len ;
   __u64 data[0U] ;
};
struct ethtool_stats {
   __u32 cmd ;
   __u32 n_stats ;
   __u64 data[0U] ;
};
struct ethtool_tcpip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be16 psrc ;
   __be16 pdst ;
   __u8 tos ;
};
struct ethtool_ah_espip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be32 spi ;
   __u8 tos ;
};
struct ethtool_usrip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be32 l4_4_bytes ;
   __u8 tos ;
   __u8 ip_ver ;
   __u8 proto ;
};
union ethtool_flow_union {
   struct ethtool_tcpip4_spec tcp_ip4_spec ;
   struct ethtool_tcpip4_spec udp_ip4_spec ;
   struct ethtool_tcpip4_spec sctp_ip4_spec ;
   struct ethtool_ah_espip4_spec ah_ip4_spec ;
   struct ethtool_ah_espip4_spec esp_ip4_spec ;
   struct ethtool_usrip4_spec usr_ip4_spec ;
   struct ethhdr ether_spec ;
   __u8 hdata[52U] ;
};
struct ethtool_flow_ext {
   __u8 padding[2U] ;
   unsigned char h_dest[6U] ;
   __be16 vlan_etype ;
   __be16 vlan_tci ;
   __be32 data[2U] ;
};
struct ethtool_rx_flow_spec {
   __u32 flow_type ;
   union ethtool_flow_union h_u ;
   struct ethtool_flow_ext h_ext ;
   union ethtool_flow_union m_u ;
   struct ethtool_flow_ext m_ext ;
   __u64 ring_cookie ;
   __u32 location ;
};
struct ethtool_rxnfc {
   __u32 cmd ;
   __u32 flow_type ;
   __u64 data ;
   struct ethtool_rx_flow_spec fs ;
   __u32 rule_cnt ;
   __u32 rule_locs[0U] ;
};
struct ethtool_flash {
   __u32 cmd ;
   __u32 region ;
   char data[128U] ;
};
struct ethtool_dump {
   __u32 cmd ;
   __u32 version ;
   __u32 flag ;
   __u32 len ;
   __u8 data[0U] ;
};
struct ethtool_ts_info {
   __u32 cmd ;
   __u32 so_timestamping ;
   __s32 phc_index ;
   __u32 tx_types ;
   __u32 tx_reserved[3U] ;
   __u32 rx_filters ;
   __u32 rx_reserved[3U] ;
};
enum ethtool_phys_id_state {
    ETHTOOL_ID_INACTIVE = 0,
    ETHTOOL_ID_ACTIVE = 1,
    ETHTOOL_ID_ON = 2,
    ETHTOOL_ID_OFF = 3
} ;
struct ethtool_ops {
   int (*get_settings)(struct net_device * , struct ethtool_cmd * ) ;
   int (*set_settings)(struct net_device * , struct ethtool_cmd * ) ;
   void (*get_drvinfo)(struct net_device * , struct ethtool_drvinfo * ) ;
   int (*get_regs_len)(struct net_device * ) ;
   void (*get_regs)(struct net_device * , struct ethtool_regs * , void * ) ;
   void (*get_wol)(struct net_device * , struct ethtool_wolinfo * ) ;
   int (*set_wol)(struct net_device * , struct ethtool_wolinfo * ) ;
   u32 (*get_msglevel)(struct net_device * ) ;
   void (*set_msglevel)(struct net_device * , u32  ) ;
   int (*nway_reset)(struct net_device * ) ;
   u32 (*get_link)(struct net_device * ) ;
   int (*get_eeprom_len)(struct net_device * ) ;
   int (*get_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*set_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_coalesce)(struct net_device * , struct ethtool_coalesce * ) ;
   int (*set_coalesce)(struct net_device * , struct ethtool_coalesce * ) ;
   void (*get_ringparam)(struct net_device * , struct ethtool_ringparam * ) ;
   int (*set_ringparam)(struct net_device * , struct ethtool_ringparam * ) ;
   void (*get_pauseparam)(struct net_device * , struct ethtool_pauseparam * ) ;
   int (*set_pauseparam)(struct net_device * , struct ethtool_pauseparam * ) ;
   void (*self_test)(struct net_device * , struct ethtool_test * , u64 * ) ;
   void (*get_strings)(struct net_device * , u32  , u8 * ) ;
   int (*set_phys_id)(struct net_device * , enum ethtool_phys_id_state  ) ;
   void (*get_ethtool_stats)(struct net_device * , struct ethtool_stats * , u64 * ) ;
   int (*begin)(struct net_device * ) ;
   void (*complete)(struct net_device * ) ;
   u32 (*get_priv_flags)(struct net_device * ) ;
   int (*set_priv_flags)(struct net_device * , u32  ) ;
   int (*get_sset_count)(struct net_device * , int  ) ;
   int (*get_rxnfc)(struct net_device * , struct ethtool_rxnfc * , u32 * ) ;
   int (*set_rxnfc)(struct net_device * , struct ethtool_rxnfc * ) ;
   int (*flash_device)(struct net_device * , struct ethtool_flash * ) ;
   int (*reset)(struct net_device * , u32 * ) ;
   u32 (*get_rxfh_key_size)(struct net_device * ) ;
   u32 (*get_rxfh_indir_size)(struct net_device * ) ;
   int (*get_rxfh)(struct net_device * , u32 * , u8 * , u8 * ) ;
   int (*set_rxfh)(struct net_device * , u32 const   * , u8 const   * , u8 const    ) ;
   void (*get_channels)(struct net_device * , struct ethtool_channels * ) ;
   int (*set_channels)(struct net_device * , struct ethtool_channels * ) ;
   int (*get_dump_flag)(struct net_device * , struct ethtool_dump * ) ;
   int (*get_dump_data)(struct net_device * , struct ethtool_dump * , void * ) ;
   int (*set_dump)(struct net_device * , struct ethtool_dump * ) ;
   int (*get_ts_info)(struct net_device * , struct ethtool_ts_info * ) ;
   int (*get_module_info)(struct net_device * , struct ethtool_modinfo * ) ;
   int (*get_module_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_eee)(struct net_device * , struct ethtool_eee * ) ;
   int (*set_eee)(struct net_device * , struct ethtool_eee * ) ;
   int (*get_tunable)(struct net_device * , struct ethtool_tunable  const  * , void * ) ;
   int (*set_tunable)(struct net_device * , struct ethtool_tunable  const  * , void const   * ) ;
};
struct prot_inuse;
struct netns_core {
   struct ctl_table_header *sysctl_hdr ;
   int sysctl_somaxconn ;
    klee_make_symbolic(&sysctl_somaxconn, sizeof(int), "sysctl_somaxconn");
   struct prot_inuse *inuse ;
};
struct u64_stats_sync {

};
struct ipstats_mib {
   u64 mibs[36U] ;
   struct u64_stats_sync syncp ;
};
struct icmp_mib {
   unsigned long mibs[28U] ;
};
struct icmpmsg_mib {
   atomic_long_t mibs[512U] ;
};
struct icmpv6_mib {
   unsigned long mibs[6U] ;
};
struct icmpv6_mib_device {
   atomic_long_t mibs[6U] ;
};
struct icmpv6msg_mib {
   atomic_long_t mibs[512U] ;
};
struct icmpv6msg_mib_device {
   atomic_long_t mibs[512U] ;
};
struct tcp_mib {
   unsigned long mibs[16U] ;
};
struct udp_mib {
   unsigned long mibs[9U] ;
};
struct linux_mib {
   unsigned long mibs[115U] ;
};
struct linux_xfrm_mib {
   unsigned long mibs[29U] ;
};
struct proc_dir_entry;
struct netns_mib {
   struct tcp_mib *tcp_statistics ;
   struct ipstats_mib *ip_statistics ;
   struct linux_mib *net_statistics ;
   struct udp_mib *udp_statistics ;
   struct udp_mib *udplite_statistics ;
   struct icmp_mib *icmp_statistics ;
   struct icmpmsg_mib *icmpmsg_statistics ;
   struct proc_dir_entry *proc_net_devsnmp6 ;
   struct udp_mib *udp_stats_in6 ;
   struct udp_mib *udplite_stats_in6 ;
   struct ipstats_mib *ipv6_statistics ;
   struct icmpv6_mib *icmpv6_statistics ;
   struct icmpv6msg_mib *icmpv6msg_statistics ;
   struct linux_xfrm_mib *xfrm_statistics ;
};
struct netns_unix {
   int sysctl_max_dgram_qlen ;
    klee_make_symbolic(&sysctl_max_dgram_qlen, sizeof(int), "sysctl_max_dgram_qlen");
   struct ctl_table_header *ctl ;
};
struct netns_packet {
   struct mutex sklist_lock ;
   struct hlist_head sklist ;
};
struct netns_frags {
   struct percpu_counter mem ;
   int timeout ;
   int high_thresh ;
    klee_make_symbolic(&high_thresh, sizeof(int), "high_thresh");
   int low_thresh ;
    klee_make_symbolic(&low_thresh, sizeof(int), "low_thresh");
};
struct ipv4_devconf;
struct fib_rules_ops;
struct fib_table;
struct local_ports {
   seqlock_t lock ;
   int range[2U] ;
   bool warned ;
};
struct ping_group_range {
   seqlock_t lock ;
   kgid_t range[2U] ;
};
struct inet_peer_base;
struct xt_table;
struct netns_ipv4 {
   struct ctl_table_header *forw_hdr ;
   struct ctl_table_header *frags_hdr ;
   struct ctl_table_header *ipv4_hdr ;
   struct ctl_table_header *route_hdr ;
   struct ctl_table_header *xfrm4_hdr ;
   struct ipv4_devconf *devconf_all ;
   struct ipv4_devconf *devconf_dflt ;
   struct fib_rules_ops *rules_ops ;
   bool fib_has_custom_rules ;
   struct fib_table *fib_local ;
   struct fib_table *fib_main ;
   struct fib_table *fib_default ;
   int fib_num_tclassid_users ;
    klee_make_symbolic(&fib_num_tclassid_users, sizeof(int), "fib_num_tclassid_users");
   struct hlist_head *fib_table_hash ;
   bool fib_offload_disabled ;
   struct sock *fibnl ;
   struct sock **icmp_sk ;
   struct sock *mc_autojoin_sk ;
   struct inet_peer_base *peers ;
   struct sock **tcp_sk ;
   struct netns_frags frags ;
   struct xt_table *iptable_filter ;
   struct xt_table *iptable_mangle ;
   struct xt_table *iptable_raw ;
   struct xt_table *arptable_filter ;
   struct xt_table *iptable_security ;
   struct xt_table *nat_table ;
   int sysctl_icmp_echo_ignore_all ;
    klee_make_symbolic(&sysctl_icmp_echo_ignore_all, sizeof(int), "sysctl_icmp_echo_ignore_all");
   int sysctl_icmp_echo_ignore_broadcasts ;
    klee_make_symbolic(&sysctl_icmp_echo_ignore_broadcasts, sizeof(int), "sysctl_icmp_echo_ignore_broadcasts");
   int sysctl_icmp_ignore_bogus_error_responses ;
    klee_make_symbolic(&sysctl_icmp_ignore_bogus_error_responses, sizeof(int), "sysctl_icmp_ignore_bogus_error_responses");
   int sysctl_icmp_ratelimit ;
    klee_make_symbolic(&sysctl_icmp_ratelimit, sizeof(int), "sysctl_icmp_ratelimit");
   int sysctl_icmp_ratemask ;
    klee_make_symbolic(&sysctl_icmp_ratemask, sizeof(int), "sysctl_icmp_ratemask");
   int sysctl_icmp_errors_use_inbound_ifaddr ;
    klee_make_symbolic(&sysctl_icmp_errors_use_inbound_ifaddr, sizeof(int), "sysctl_icmp_errors_use_inbound_ifaddr");
   struct local_ports ip_local_ports ;
   int sysctl_tcp_ecn ;
    klee_make_symbolic(&sysctl_tcp_ecn, sizeof(int), "sysctl_tcp_ecn");
   int sysctl_tcp_ecn_fallback ;
    klee_make_symbolic(&sysctl_tcp_ecn_fallback, sizeof(int), "sysctl_tcp_ecn_fallback");
   int sysctl_ip_no_pmtu_disc ;
    klee_make_symbolic(&sysctl_ip_no_pmtu_disc, sizeof(int), "sysctl_ip_no_pmtu_disc");
   int sysctl_ip_fwd_use_pmtu ;
    klee_make_symbolic(&sysctl_ip_fwd_use_pmtu, sizeof(int), "sysctl_ip_fwd_use_pmtu");
   int sysctl_ip_nonlocal_bind ;
    klee_make_symbolic(&sysctl_ip_nonlocal_bind, sizeof(int), "sysctl_ip_nonlocal_bind");
   int sysctl_fwmark_reflect ;
    klee_make_symbolic(&sysctl_fwmark_reflect, sizeof(int), "sysctl_fwmark_reflect");
   int sysctl_tcp_fwmark_accept ;
    klee_make_symbolic(&sysctl_tcp_fwmark_accept, sizeof(int), "sysctl_tcp_fwmark_accept");
   int sysctl_tcp_mtu_probing ;
    klee_make_symbolic(&sysctl_tcp_mtu_probing, sizeof(int), "sysctl_tcp_mtu_probing");
   int sysctl_tcp_base_mss ;
    klee_make_symbolic(&sysctl_tcp_base_mss, sizeof(int), "sysctl_tcp_base_mss");
   int sysctl_tcp_probe_threshold ;
    klee_make_symbolic(&sysctl_tcp_probe_threshold, sizeof(int), "sysctl_tcp_probe_threshold");
   u32 sysctl_tcp_probe_interval ;
   struct ping_group_range ping_group_range ;
   atomic_t dev_addr_genid ;
   unsigned long *sysctl_local_reserved_ports ;
   struct list_head mr_tables ;
   struct fib_rules_ops *mr_rules_ops ;
   atomic_t rt_genid ;
};
struct neighbour;
struct dst_ops {
   unsigned short family ;
   unsigned int gc_thresh ;
    klee_make_symbolic(&gc_thresh, sizeof(int), "gc_thresh");
   int (*gc)(struct dst_ops * ) ;
   struct dst_entry *(*check)(struct dst_entry * , __u32  ) ;
   unsigned int (*default_advmss)(struct dst_entry  const  * ) ;
   unsigned int (*mtu)(struct dst_entry  const  * ) ;
   u32 *(*cow_metrics)(struct dst_entry * , unsigned long  ) ;
   void (*destroy)(struct dst_entry * ) ;
   void (*ifdown)(struct dst_entry * , struct net_device * , int  ) ;
   struct dst_entry *(*negative_advice)(struct dst_entry * ) ;
   void (*link_failure)(struct sk_buff * ) ;
   void (*update_pmtu)(struct dst_entry * , struct sock * , struct sk_buff * , u32  ) ;
   void (*redirect)(struct dst_entry * , struct sock * , struct sk_buff * ) ;
   int (*local_out)(struct sk_buff * ) ;
   struct neighbour *(*neigh_lookup)(struct dst_entry  const  * , struct sk_buff * ,
                                     void const   * ) ;
   struct kmem_cache *kmem_cachep ;
   struct percpu_counter pcpuc_entries ;
};
struct netns_sysctl_ipv6 {
   struct ctl_table_header *hdr ;
   struct ctl_table_header *route_hdr ;
   struct ctl_table_header *icmp_hdr ;
   struct ctl_table_header *frags_hdr ;
   struct ctl_table_header *xfrm6_hdr ;
   int bindv6only ;
    klee_make_symbolic(&bindv6only, sizeof(int), "bindv6only");
   int flush_delay ;
    klee_make_symbolic(&flush_delay, sizeof(int), "flush_delay");
   int ip6_rt_max_size ;
    klee_make_symbolic(&ip6_rt_max_size, sizeof(int), "ip6_rt_max_size");
   int ip6_rt_gc_min_interval ;
    klee_make_symbolic(&ip6_rt_gc_min_interval, sizeof(int), "ip6_rt_gc_min_interval");
   int ip6_rt_gc_timeout ;
    klee_make_symbolic(&ip6_rt_gc_timeout, sizeof(int), "ip6_rt_gc_timeout");
   int ip6_rt_gc_interval ;
    klee_make_symbolic(&ip6_rt_gc_interval, sizeof(int), "ip6_rt_gc_interval");
   int ip6_rt_gc_elasticity ;
    klee_make_symbolic(&ip6_rt_gc_elasticity, sizeof(int), "ip6_rt_gc_elasticity");
   int ip6_rt_mtu_expires ;
    klee_make_symbolic(&ip6_rt_mtu_expires, sizeof(int), "ip6_rt_mtu_expires");
   int ip6_rt_min_advmss ;
    klee_make_symbolic(&ip6_rt_min_advmss, sizeof(int), "ip6_rt_min_advmss");
   int flowlabel_consistency ;
    klee_make_symbolic(&flowlabel_consistency, sizeof(int), "flowlabel_consistency");
   int auto_flowlabels ;
    klee_make_symbolic(&auto_flowlabels, sizeof(int), "auto_flowlabels");
   int icmpv6_time ;
    klee_make_symbolic(&icmpv6_time, sizeof(int), "icmpv6_time");
   int anycast_src_echo_reply ;
    klee_make_symbolic(&anycast_src_echo_reply, sizeof(int), "anycast_src_echo_reply");
   int fwmark_reflect ;
    klee_make_symbolic(&fwmark_reflect, sizeof(int), "fwmark_reflect");
   int idgen_retries ;
    klee_make_symbolic(&idgen_retries, sizeof(int), "idgen_retries");
   int idgen_delay ;
    klee_make_symbolic(&idgen_delay, sizeof(int), "idgen_delay");
   int flowlabel_state_ranges ;
    klee_make_symbolic(&flowlabel_state_ranges, sizeof(int), "flowlabel_state_ranges");
};
struct ipv6_devconf;
struct rt6_info;
struct rt6_statistics;
struct fib6_table;
struct netns_ipv6 {
   struct netns_sysctl_ipv6 sysctl ;
   struct ipv6_devconf *devconf_all ;
   struct ipv6_devconf *devconf_dflt ;
   struct inet_peer_base *peers ;
   struct netns_frags frags ;
   struct xt_table *ip6table_filter ;
   struct xt_table *ip6table_mangle ;
   struct xt_table *ip6table_raw ;
   struct xt_table *ip6table_security ;
   struct xt_table *ip6table_nat ;
   struct rt6_info *ip6_null_entry ;
   struct rt6_statistics *rt6_stats ;
   struct timer_list ip6_fib_timer ;
   struct hlist_head *fib_table_hash ;
   struct fib6_table *fib6_main_tbl ;
   struct dst_ops ip6_dst_ops ;
   unsigned int ip6_rt_gc_expire ;
    klee_make_symbolic(&ip6_rt_gc_expire, sizeof(int), "ip6_rt_gc_expire");
   unsigned long ip6_rt_last_gc ;
    klee_make_symbolic(&ip6_rt_last_gc, sizeof(long), "ip6_rt_last_gc");
   struct rt6_info *ip6_prohibit_entry ;
   struct rt6_info *ip6_blk_hole_entry ;
   struct fib6_table *fib6_local_tbl ;
   struct fib_rules_ops *fib6_rules_ops ;
   struct sock **icmp_sk ;
   struct sock *ndisc_sk ;
   struct sock *tcp_sk ;
   struct sock *igmp_sk ;
   struct sock *mc_autojoin_sk ;
   struct list_head mr6_tables ;
   struct fib_rules_ops *mr6_rules_ops ;
   atomic_t dev_addr_genid ;
   atomic_t fib6_sernum ;
};
struct netns_nf_frag {
   struct netns_sysctl_ipv6 sysctl ;
   struct netns_frags frags ;
};
struct netns_sysctl_lowpan {
   struct ctl_table_header *frags_hdr ;
};
struct netns_ieee802154_lowpan {
   struct netns_sysctl_lowpan sysctl ;
   struct netns_frags frags ;
};
struct sctp_mib;
struct netns_sctp {
   struct sctp_mib *sctp_statistics ;
   struct proc_dir_entry *proc_net_sctp ;
   struct ctl_table_header *sysctl_header ;
   struct sock *ctl_sock ;
   struct list_head local_addr_list ;
   struct list_head addr_waitq ;
   struct timer_list addr_wq_timer ;
   struct list_head auto_asconf_splist ;
   spinlock_t addr_wq_lock ;
   spinlock_t local_addr_lock ;
   unsigned int rto_initial ;
    klee_make_symbolic(&rto_initial, sizeof(int), "rto_initial");
   unsigned int rto_min ;
    klee_make_symbolic(&rto_min, sizeof(int), "rto_min");
   unsigned int rto_max ;
    klee_make_symbolic(&rto_max, sizeof(int), "rto_max");
   int rto_alpha ;
    klee_make_symbolic(&rto_alpha, sizeof(int), "rto_alpha");
   int rto_beta ;
    klee_make_symbolic(&rto_beta, sizeof(int), "rto_beta");
   int max_burst ;
    klee_make_symbolic(&max_burst, sizeof(int), "max_burst");
   int cookie_preserve_enable ;
    klee_make_symbolic(&cookie_preserve_enable, sizeof(int), "cookie_preserve_enable");
   char *sctp_hmac_alg ;
   unsigned int valid_cookie_life ;
    klee_make_symbolic(&valid_cookie_life, sizeof(int), "valid_cookie_life");
   unsigned int sack_timeout ;
    klee_make_symbolic(&sack_timeout, sizeof(int), "sack_timeout");
   unsigned int hb_interval ;
    klee_make_symbolic(&hb_interval, sizeof(int), "hb_interval");
   int max_retrans_association ;
    klee_make_symbolic(&max_retrans_association, sizeof(int), "max_retrans_association");
   int max_retrans_path ;
    klee_make_symbolic(&max_retrans_path, sizeof(int), "max_retrans_path");
   int max_retrans_init ;
    klee_make_symbolic(&max_retrans_init, sizeof(int), "max_retrans_init");
   int pf_retrans ;
    klee_make_symbolic(&pf_retrans, sizeof(int), "pf_retrans");
   int sndbuf_policy ;
    klee_make_symbolic(&sndbuf_policy, sizeof(int), "sndbuf_policy");
   int rcvbuf_policy ;
    klee_make_symbolic(&rcvbuf_policy, sizeof(int), "rcvbuf_policy");
   int default_auto_asconf ;
    klee_make_symbolic(&default_auto_asconf, sizeof(int), "default_auto_asconf");
   int addip_enable ;
    klee_make_symbolic(&addip_enable, sizeof(int), "addip_enable");
   int addip_noauth ;
    klee_make_symbolic(&addip_noauth, sizeof(int), "addip_noauth");
   int prsctp_enable ;
    klee_make_symbolic(&prsctp_enable, sizeof(int), "prsctp_enable");
   int auth_enable ;
    klee_make_symbolic(&auth_enable, sizeof(int), "auth_enable");
   int scope_policy ;
    klee_make_symbolic(&scope_policy, sizeof(int), "scope_policy");
   int rwnd_upd_shift ;
    klee_make_symbolic(&rwnd_upd_shift, sizeof(int), "rwnd_upd_shift");
   unsigned long max_autoclose ;
    klee_make_symbolic(&max_autoclose, sizeof(long), "max_autoclose");
};
struct netns_dccp {
   struct sock *v4_ctl_sk ;
   struct sock *v6_ctl_sk ;
};
struct nf_logger;
struct netns_nf {
   struct proc_dir_entry *proc_netfilter ;
   struct nf_logger  const  *nf_loggers[13U] ;
   struct ctl_table_header *nf_log_dir_header ;
};
struct ebt_table;
struct netns_xt {
   struct list_head tables[13U] ;
   bool notrack_deprecated_warning ;
   bool clusterip_deprecated_warning ;
   struct ebt_table *broute_table ;
   struct ebt_table *frame_filter ;
   struct ebt_table *frame_nat ;
};
struct hlist_nulls_node;
struct hlist_nulls_head {
   struct hlist_nulls_node *first ;
};
struct hlist_nulls_node {
   struct hlist_nulls_node *next ;
   struct hlist_nulls_node **pprev ;
};
struct nf_proto_net {
   struct ctl_table_header *ctl_table_header ;
   struct ctl_table *ctl_table ;
   struct ctl_table_header *ctl_compat_header ;
   struct ctl_table *ctl_compat_table ;
   unsigned int users ;
    klee_make_symbolic(&users, sizeof(int), "users");
};
struct nf_generic_net {
   struct nf_proto_net pn ;
   unsigned int timeout ;
};
struct nf_tcp_net {
   struct nf_proto_net pn ;
   unsigned int timeouts[14U] ;
   unsigned int tcp_loose ;
    klee_make_symbolic(&tcp_loose, sizeof(int), "tcp_loose");
   unsigned int tcp_be_liberal ;
    klee_make_symbolic(&tcp_be_liberal, sizeof(int), "tcp_be_liberal");
   unsigned int tcp_max_retrans ;
    klee_make_symbolic(&tcp_max_retrans, sizeof(int), "tcp_max_retrans");
};
struct nf_udp_net {
   struct nf_proto_net pn ;
   unsigned int timeouts[2U] ;
};
struct nf_icmp_net {
   struct nf_proto_net pn ;
   unsigned int timeout ;
};
struct nf_ip_net {
   struct nf_generic_net generic ;
   struct nf_tcp_net tcp ;
   struct nf_udp_net udp ;
   struct nf_icmp_net icmp ;
   struct nf_icmp_net icmpv6 ;
   struct ctl_table_header *ctl_table_header ;
   struct ctl_table *ctl_table ;
};
struct ct_pcpu {
   spinlock_t lock ;
   struct hlist_nulls_head unconfirmed ;
   struct hlist_nulls_head dying ;
   struct hlist_nulls_head tmpl ;
};
struct ip_conntrack_stat;
struct nf_ct_event_notifier;
struct nf_exp_event_notifier;
struct netns_ct {
   atomic_t count ;
   unsigned int expect_count ;
    klee_make_symbolic(&expect_count, sizeof(int), "expect_count");
   struct delayed_work ecache_dwork ;
   bool ecache_dwork_pending ;
   struct ctl_table_header *sysctl_header ;
   struct ctl_table_header *acct_sysctl_header ;
   struct ctl_table_header *tstamp_sysctl_header ;
   struct ctl_table_header *event_sysctl_header ;
   struct ctl_table_header *helper_sysctl_header ;
   char *slabname ;
   unsigned int sysctl_log_invalid ;
    klee_make_symbolic(&sysctl_log_invalid, sizeof(int), "sysctl_log_invalid");
   int sysctl_events ;
    klee_make_symbolic(&sysctl_events, sizeof(int), "sysctl_events");
   int sysctl_acct ;
    klee_make_symbolic(&sysctl_acct, sizeof(int), "sysctl_acct");
   int sysctl_auto_assign_helper ;
    klee_make_symbolic(&sysctl_auto_assign_helper, sizeof(int), "sysctl_auto_assign_helper");
   bool auto_assign_helper_warned ;
   int sysctl_tstamp ;
    klee_make_symbolic(&sysctl_tstamp, sizeof(int), "sysctl_tstamp");
   int sysctl_checksum ;
    klee_make_symbolic(&sysctl_checksum, sizeof(int), "sysctl_checksum");
   unsigned int htable_size ;
    klee_make_symbolic(&htable_size, sizeof(int), "htable_size");
   seqcount_t generation ;
   struct kmem_cache *nf_conntrack_cachep ;
   struct hlist_nulls_head *hash ;
   struct hlist_head *expect_hash ;
   struct ct_pcpu *pcpu_lists ;
   struct ip_conntrack_stat *stat ;
   struct nf_ct_event_notifier *nf_conntrack_event_cb ;
   struct nf_exp_event_notifier *nf_expect_event_cb ;
   struct nf_ip_net nf_ct_proto ;
   unsigned int labels_used ;
    klee_make_symbolic(&labels_used, sizeof(int), "labels_used");
   u8 label_words ;
   struct hlist_head *nat_bysource ;
   unsigned int nat_htable_size ;
    klee_make_symbolic(&nat_htable_size, sizeof(int), "nat_htable_size");
};
struct nft_af_info;
struct netns_nftables {
   struct list_head af_info ;
   struct list_head commit_list ;
   struct nft_af_info *ipv4 ;
   struct nft_af_info *ipv6 ;
   struct nft_af_info *inet ;
   struct nft_af_info *arp ;
   struct nft_af_info *bridge ;
   struct nft_af_info *netdev ;
   unsigned int base_seq ;
    klee_make_symbolic(&base_seq, sizeof(int), "base_seq");
   u8 gencursor ;
};
struct tasklet_struct {
   struct tasklet_struct *next ;
   unsigned long state ;
   atomic_t count ;
   void (*func)(unsigned long  ) ;
   unsigned long data ;
};
struct flow_cache_percpu {
   struct hlist_head *hash_table ;
   int hash_count ;
    klee_make_symbolic(&hash_count, sizeof(int), "hash_count");
   u32 hash_rnd ;
   int hash_rnd_recalc ;
    klee_make_symbolic(&hash_rnd_recalc, sizeof(int), "hash_rnd_recalc");
   struct tasklet_struct flush_tasklet ;
};
struct flow_cache {
   u32 hash_shift ;
   struct flow_cache_percpu *percpu ;
   struct notifier_block hotcpu_notifier ;
   int low_watermark ;
    klee_make_symbolic(&low_watermark, sizeof(int), "low_watermark");
   int high_watermark ;
    klee_make_symbolic(&high_watermark, sizeof(int), "high_watermark");
   struct timer_list rnd_timer ;
};
struct xfrm_policy_hash {
   struct hlist_head *table ;
   unsigned int hmask ;
    klee_make_symbolic(&hmask, sizeof(int), "hmask");
   u8 dbits4 ;
   u8 sbits4 ;
   u8 dbits6 ;
   u8 sbits6 ;
};
struct xfrm_policy_hthresh {
   struct work_struct work ;
   seqlock_t lock ;
   u8 lbits4 ;
   u8 rbits4 ;
   u8 lbits6 ;
   u8 rbits6 ;
};
struct netns_xfrm {
   struct list_head state_all ;
   struct hlist_head *state_bydst ;
   struct hlist_head *state_bysrc ;
   struct hlist_head *state_byspi ;
   unsigned int state_hmask ;
    klee_make_symbolic(&state_hmask, sizeof(int), "state_hmask");
   unsigned int state_num ;
    klee_make_symbolic(&state_num, sizeof(int), "state_num");
   struct work_struct state_hash_work ;
   struct hlist_head state_gc_list ;
   struct work_struct state_gc_work ;
   struct list_head policy_all ;
   struct hlist_head *policy_byidx ;
   unsigned int policy_idx_hmask ;
    klee_make_symbolic(&policy_idx_hmask, sizeof(int), "policy_idx_hmask");
   struct hlist_head policy_inexact[3U] ;
   struct xfrm_policy_hash policy_bydst[3U] ;
   unsigned int policy_count[6U] ;
   struct work_struct policy_hash_work ;
   struct xfrm_policy_hthresh policy_hthresh ;
   struct sock *nlsk ;
   struct sock *nlsk_stash ;
   u32 sysctl_aevent_etime ;
   u32 sysctl_aevent_rseqth ;
   int sysctl_larval_drop ;
    klee_make_symbolic(&sysctl_larval_drop, sizeof(int), "sysctl_larval_drop");
   u32 sysctl_acq_expires ;
   struct ctl_table_header *sysctl_hdr ;
   struct dst_ops xfrm4_dst_ops ;
   struct dst_ops xfrm6_dst_ops ;
   spinlock_t xfrm_state_lock ;
   rwlock_t xfrm_policy_lock ;
   struct mutex xfrm_cfg_mutex ;
   struct flow_cache flow_cache_global ;
   atomic_t flow_cache_genid ;
   struct list_head flow_cache_gc_list ;
   spinlock_t flow_cache_gc_lock ;
   struct work_struct flow_cache_gc_work ;
   struct work_struct flow_cache_flush_work ;
   struct mutex flow_flush_sem ;
};
struct mpls_route;
struct netns_mpls {
   size_t platform_labels ;
   struct mpls_route **platform_label ;
   struct ctl_table_header *ctl ;
};
struct proc_ns_operations;
struct ns_common {
   atomic_long_t stashed ;
   struct proc_ns_operations  const  *ops ;
   unsigned int inum ;
    klee_make_symbolic(&inum, sizeof(int), "inum");
};
struct net_generic;
struct netns_ipvs;
struct net {
   atomic_t passive ;
   atomic_t count ;
   spinlock_t rules_mod_lock ;
   atomic64_t cookie_gen ;
   struct list_head list ;
   struct list_head cleanup_list ;
   struct list_head exit_list ;
   struct user_namespace *user_ns ;
   spinlock_t nsid_lock ;
   struct idr netns_ids ;
   struct ns_common ns ;
   struct proc_dir_entry *proc_net ;
   struct proc_dir_entry *proc_net_stat ;
   struct ctl_table_set sysctls ;
   struct sock *rtnl ;
   struct sock *genl_sock ;
   struct list_head dev_base_head ;
   struct hlist_head *dev_name_head ;
   struct hlist_head *dev_index_head ;
   unsigned int dev_base_seq ;
    klee_make_symbolic(&dev_base_seq, sizeof(int), "dev_base_seq");
   int ifindex ;
    klee_make_symbolic(&ifindex, sizeof(int), "ifindex");
   unsigned int dev_unreg_count ;
    klee_make_symbolic(&dev_unreg_count, sizeof(int), "dev_unreg_count");
   struct list_head rules_ops ;
   struct net_device *loopback_dev ;
   struct netns_core core ;
   struct netns_mib mib ;
   struct netns_packet packet ;
   struct netns_unix unx ;
   struct netns_ipv4 ipv4 ;
   struct netns_ipv6 ipv6 ;
   struct netns_ieee802154_lowpan ieee802154_lowpan ;
   struct netns_sctp sctp ;
   struct netns_dccp dccp ;
   struct netns_nf nf ;
   struct netns_xt xt ;
   struct netns_ct ct ;
   struct netns_nftables nft ;
   struct netns_nf_frag nf_frag ;
   struct sock *nfnl ;
   struct sock *nfnl_stash ;
   struct sk_buff_head wext_nlevents ;
   struct net_generic *gen ;
   struct netns_xfrm xfrm ;
   struct netns_ipvs *ipvs ;
   struct netns_mpls mpls ;
   struct sock *diag_nlsk ;
   atomic_t fnhe_genid ;
};
struct __anonstruct_possible_net_t_302 {
   struct net *net ;
};
typedef struct __anonstruct_possible_net_t_302 possible_net_t;
typedef unsigned long kernel_ulong_t;
    klee_make_symbolic(&kernel_ulong_t, sizeof(long), "kernel_ulong_t");
struct pci_device_id {
   __u32 vendor ;
   __u32 device ;
   __u32 subvendor ;
   __u32 subdevice ;
   __u32 class ;
   __u32 class_mask ;
   kernel_ulong_t driver_data ;
};
struct acpi_device_id {
   __u8 id[9U] ;
   kernel_ulong_t driver_data ;
};
struct of_device_id {
   char name[32U] ;
   char type[32U] ;
   char compatible[128U] ;
   void const   *data ;
};
enum fwnode_type {
    FWNODE_INVALID = 0,
    FWNODE_OF = 1,
    FWNODE_ACPI = 2,
    FWNODE_PDATA = 3
} ;
struct fwnode_handle {
   enum fwnode_type type ;
   struct fwnode_handle *secondary ;
};
typedef u32 phandle;
struct property {
   char *name ;
   int length ;
   void *value ;
   struct property *next ;
   unsigned long _flags ;
    klee_make_symbolic(&_flags, sizeof(long), "_flags");
   unsigned int unique_id ;
    klee_make_symbolic(&unique_id, sizeof(int), "unique_id");
   struct bin_attribute attr ;
};
struct device_node {
   char const   *name ;
   char const   *type ;
   phandle phandle ;
   char const   *full_name ;
   struct fwnode_handle fwnode ;
   struct property *properties ;
   struct property *deadprops ;
   struct device_node *parent ;
   struct device_node *child ;
   struct device_node *sibling ;
   struct kobject kobj ;
   unsigned long _flags ;
   void *data ;
};
enum ldv_27995 {
    PHY_INTERFACE_MODE_NA = 0,
    PHY_INTERFACE_MODE_MII = 1,
    PHY_INTERFACE_MODE_GMII = 2,
    PHY_INTERFACE_MODE_SGMII = 3,
    PHY_INTERFACE_MODE_TBI = 4,
    PHY_INTERFACE_MODE_REVMII = 5,
    PHY_INTERFACE_MODE_RMII = 6,
    PHY_INTERFACE_MODE_RGMII = 7,
    PHY_INTERFACE_MODE_RGMII_ID = 8,
    PHY_INTERFACE_MODE_RGMII_RXID = 9,
    PHY_INTERFACE_MODE_RGMII_TXID = 10,
    PHY_INTERFACE_MODE_RTBI = 11,
    PHY_INTERFACE_MODE_SMII = 12,
    PHY_INTERFACE_MODE_XGMII = 13,
    PHY_INTERFACE_MODE_MOCA = 14,
    PHY_INTERFACE_MODE_QSGMII = 15,
    PHY_INTERFACE_MODE_MAX = 16
} ;
typedef enum ldv_27995 phy_interface_t;
enum ldv_28049 {
    MDIOBUS_ALLOCATED = 1,
    MDIOBUS_REGISTERED = 2,
    MDIOBUS_UNREGISTERED = 3,
    MDIOBUS_RELEASED = 4
} ;
struct phy_device;
struct mii_bus {
   char const   *name ;
   char id[17U] ;
   void *priv ;
   int (*read)(struct mii_bus * , int  , int  ) ;
   int (*write)(struct mii_bus * , int  , int  , u16  ) ;
   int (*reset)(struct mii_bus * ) ;
   struct mutex mdio_lock ;
   struct device *parent ;
   enum ldv_28049 state ;
   struct device dev ;
   struct phy_device *phy_map[32U] ;
   u32 phy_mask ;
   u32 phy_ignore_ta_mask ;
   int *irq ;
};
enum phy_state {
    PHY_DOWN = 0,
    PHY_STARTING = 1,
    PHY_READY = 2,
    PHY_PENDING = 3,
    PHY_UP = 4,
    PHY_AN = 5,
    PHY_RUNNING = 6,
    PHY_NOLINK = 7,
    PHY_FORCING = 8,
    PHY_CHANGELINK = 9,
    PHY_HALTED = 10,
    PHY_RESUMING = 11
} ;
struct phy_c45_device_ids {
   u32 devices_in_package ;
   u32 device_ids[8U] ;
};
struct phy_driver;
struct phy_device {
   struct phy_driver *drv ;
   struct mii_bus *bus ;
   struct device dev ;
   u32 phy_id ;
   struct phy_c45_device_ids c45_ids ;
   bool is_c45 ;
   bool is_internal ;
   bool has_fixups ;
   bool suspended ;
   enum phy_state state ;
   u32 dev_flags ;
   phy_interface_t interface ;
   int addr ;
    klee_make_symbolic(&addr, sizeof(int), "addr");
   int speed ;
    klee_make_symbolic(&speed, sizeof(int), "speed");
   int duplex ;
    klee_make_symbolic(&duplex, sizeof(int), "duplex");
   int pause ;
    klee_make_symbolic(&pause, sizeof(int), "pause");
   int asym_pause ;
    klee_make_symbolic(&asym_pause, sizeof(int), "asym_pause");
   int link ;
    klee_make_symbolic(&link, sizeof(int), "link");
   u32 interrupts ;
   u32 supported ;
   u32 advertising ;
   u32 lp_advertising ;
   int autoneg ;
    klee_make_symbolic(&autoneg, sizeof(int), "autoneg");
   int link_timeout ;
    klee_make_symbolic(&link_timeout, sizeof(int), "link_timeout");
   int irq ;
   void *priv ;
   struct work_struct phy_queue ;
   struct delayed_work state_queue ;
   atomic_t irq_disable ;
   struct mutex lock ;
   struct net_device *attached_dev ;
   void (*adjust_link)(struct net_device * ) ;
};
struct phy_driver {
   u32 phy_id ;
   char *name ;
   unsigned int phy_id_mask ;
    klee_make_symbolic(&phy_id_mask, sizeof(int), "phy_id_mask");
   u32 features ;
   u32 flags ;
   void const   *driver_data ;
   int (*soft_reset)(struct phy_device * ) ;
   int (*config_init)(struct phy_device * ) ;
   int (*probe)(struct phy_device * ) ;
   int (*suspend)(struct phy_device * ) ;
   int (*resume)(struct phy_device * ) ;
   int (*config_aneg)(struct phy_device * ) ;
   int (*aneg_done)(struct phy_device * ) ;
   int (*read_status)(struct phy_device * ) ;
   int (*ack_interrupt)(struct phy_device * ) ;
   int (*config_intr)(struct phy_device * ) ;
   int (*did_interrupt)(struct phy_device * ) ;
   void (*remove)(struct phy_device * ) ;
   int (*match_phy_device)(struct phy_device * ) ;
   int (*ts_info)(struct phy_device * , struct ethtool_ts_info * ) ;
   int (*hwtstamp)(struct phy_device * , struct ifreq * ) ;
   bool (*rxtstamp)(struct phy_device * , struct sk_buff * , int  ) ;
   void (*txtstamp)(struct phy_device * , struct sk_buff * , int  ) ;
   int (*set_wol)(struct phy_device * , struct ethtool_wolinfo * ) ;
   void (*get_wol)(struct phy_device * , struct ethtool_wolinfo * ) ;
   void (*link_change_notify)(struct phy_device * ) ;
   int (*read_mmd_indirect)(struct phy_device * , int  , int  , int  ) ;
   void (*write_mmd_indirect)(struct phy_device * , int  , int  , int  , u32  ) ;
   int (*module_info)(struct phy_device * , struct ethtool_modinfo * ) ;
   int (*module_eeprom)(struct phy_device * , struct ethtool_eeprom * , u8 * ) ;
   struct device_driver driver ;
};
struct fixed_phy_status {
   int link ;
   int speed ;
   int duplex ;
   int pause ;
   int asym_pause ;
};
enum dsa_tag_protocol {
    DSA_TAG_PROTO_NONE = 0,
    DSA_TAG_PROTO_DSA = 1,
    DSA_TAG_PROTO_TRAILER = 2,
    DSA_TAG_PROTO_EDSA = 3,
    DSA_TAG_PROTO_BRCM = 4
} ;
struct dsa_chip_data {
   struct device *host_dev ;
   int sw_addr ;
    klee_make_symbolic(&sw_addr, sizeof(int), "sw_addr");
   int eeprom_len ;
    klee_make_symbolic(&eeprom_len, sizeof(int), "eeprom_len");
   struct device_node *of_node ;
   char *port_names[12U] ;
   struct device_node *port_dn[12U] ;
   s8 *rtable ;
};
struct dsa_platform_data {
   struct device *netdev ;
   struct net_device *of_netdev ;
   int nr_chips ;
    klee_make_symbolic(&nr_chips, sizeof(int), "nr_chips");
   struct dsa_chip_data *chip ;
};
struct packet_type;
struct dsa_switch;
struct dsa_switch_tree {
   struct dsa_platform_data *pd ;
   struct net_device *master_netdev ;
   int (*rcv)(struct sk_buff * , struct net_device * , struct packet_type * , struct net_device * ) ;
   enum dsa_tag_protocol tag_protocol ;
   s8 cpu_switch ;
   s8 cpu_port ;
   int link_poll_needed ;
    klee_make_symbolic(&link_poll_needed, sizeof(int), "link_poll_needed");
   struct work_struct link_poll_work ;
   struct timer_list link_poll_timer ;
   struct dsa_switch *ds[4U] ;
};
struct dsa_switch_driver;
struct dsa_switch {
   struct dsa_switch_tree *dst ;
   int index ;
   enum dsa_tag_protocol tag_protocol ;
   struct dsa_chip_data *pd ;
   struct dsa_switch_driver *drv ;
   struct device *master_dev ;
   char hwmon_name[24U] ;
   struct device *hwmon_dev ;
   u32 dsa_port_mask ;
   u32 phys_port_mask ;
   u32 phys_mii_mask ;
   struct mii_bus *slave_mii_bus ;
   struct net_device *ports[12U] ;
};
struct dsa_switch_driver {
   struct list_head list ;
   enum dsa_tag_protocol tag_protocol ;
   int priv_size ;
    klee_make_symbolic(&priv_size, sizeof(int), "priv_size");
   char *(*probe)(struct device * , int  ) ;
   int (*setup)(struct dsa_switch * ) ;
   int (*set_addr)(struct dsa_switch * , u8 * ) ;
   u32 (*get_phy_flags)(struct dsa_switch * , int  ) ;
   int (*phy_read)(struct dsa_switch * , int  , int  ) ;
   int (*phy_write)(struct dsa_switch * , int  , int  , u16  ) ;
   void (*poll_link)(struct dsa_switch * ) ;
   void (*adjust_link)(struct dsa_switch * , int  , struct phy_device * ) ;
   void (*fixed_link_update)(struct dsa_switch * , int  , struct fixed_phy_status * ) ;
   void (*get_strings)(struct dsa_switch * , int  , uint8_t * ) ;
   void (*get_ethtool_stats)(struct dsa_switch * , int  , uint64_t * ) ;
   int (*get_sset_count)(struct dsa_switch * ) ;
   void (*get_wol)(struct dsa_switch * , int  , struct ethtool_wolinfo * ) ;
   int (*set_wol)(struct dsa_switch * , int  , struct ethtool_wolinfo * ) ;
   int (*suspend)(struct dsa_switch * ) ;
   int (*resume)(struct dsa_switch * ) ;
   int (*port_enable)(struct dsa_switch * , int  , struct phy_device * ) ;
   void (*port_disable)(struct dsa_switch * , int  , struct phy_device * ) ;
   int (*set_eee)(struct dsa_switch * , int  , struct phy_device * , struct ethtool_eee * ) ;
   int (*get_eee)(struct dsa_switch * , int  , struct ethtool_eee * ) ;
   int (*get_temp)(struct dsa_switch * , int * ) ;
   int (*get_temp_limit)(struct dsa_switch * , int * ) ;
   int (*set_temp_limit)(struct dsa_switch * , int  ) ;
   int (*get_temp_alarm)(struct dsa_switch * , bool * ) ;
   int (*get_eeprom_len)(struct dsa_switch * ) ;
   int (*get_eeprom)(struct dsa_switch * , struct ethtool_eeprom * , u8 * ) ;
   int (*set_eeprom)(struct dsa_switch * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_regs_len)(struct dsa_switch * , int  ) ;
   void (*get_regs)(struct dsa_switch * , int  , struct ethtool_regs * , void * ) ;
   int (*port_join_bridge)(struct dsa_switch * , int  , u32  ) ;
   int (*port_leave_bridge)(struct dsa_switch * , int  , u32  ) ;
   int (*port_stp_update)(struct dsa_switch * , int  , u8  ) ;
   int (*fdb_add)(struct dsa_switch * , int  , unsigned char const   * , u16  ) ;
   int (*fdb_del)(struct dsa_switch * , int  , unsigned char const   * , u16  ) ;
   int (*fdb_getnext)(struct dsa_switch * , int  , unsigned char * , bool * ) ;
};
struct ieee_ets {
   __u8 willing ;
   __u8 ets_cap ;
   __u8 cbs ;
   __u8 tc_tx_bw[8U] ;
   __u8 tc_rx_bw[8U] ;
   __u8 tc_tsa[8U] ;
   __u8 prio_tc[8U] ;
   __u8 tc_reco_bw[8U] ;
   __u8 tc_reco_tsa[8U] ;
   __u8 reco_prio_tc[8U] ;
};
struct ieee_maxrate {
   __u64 tc_maxrate[8U] ;
};
struct ieee_qcn {
   __u8 rpg_enable[8U] ;
   __u32 rppp_max_rps[8U] ;
   __u32 rpg_time_reset[8U] ;
   __u32 rpg_byte_reset[8U] ;
   __u32 rpg_threshold[8U] ;
   __u32 rpg_max_rate[8U] ;
   __u32 rpg_ai_rate[8U] ;
   __u32 rpg_hai_rate[8U] ;
   __u32 rpg_gd[8U] ;
   __u32 rpg_min_dec_fac[8U] ;
   __u32 rpg_min_rate[8U] ;
   __u32 cndd_state_machine[8U] ;
};
struct ieee_qcn_stats {
   __u64 rppp_rp_centiseconds[8U] ;
   __u32 rppp_created_rps[8U] ;
};
struct ieee_pfc {
   __u8 pfc_cap ;
   __u8 pfc_en ;
   __u8 mbc ;
   __u16 delay ;
   __u64 requests[8U] ;
   __u64 indications[8U] ;
};
struct cee_pg {
   __u8 willing ;
   __u8 error ;
   __u8 pg_en ;
   __u8 tcs_supported ;
   __u8 pg_bw[8U] ;
   __u8 prio_pg[8U] ;
};
struct cee_pfc {
   __u8 willing ;
   __u8 error ;
   __u8 pfc_en ;
   __u8 tcs_supported ;
};
struct dcb_app {
   __u8 selector ;
   __u8 priority ;
   __u16 protocol ;
};
struct dcb_peer_app_info {
   __u8 willing ;
   __u8 error ;
};
struct dcbnl_rtnl_ops {
   int (*ieee_getets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_setets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_getmaxrate)(struct net_device * , struct ieee_maxrate * ) ;
   int (*ieee_setmaxrate)(struct net_device * , struct ieee_maxrate * ) ;
   int (*ieee_getqcn)(struct net_device * , struct ieee_qcn * ) ;
   int (*ieee_setqcn)(struct net_device * , struct ieee_qcn * ) ;
   int (*ieee_getqcnstats)(struct net_device * , struct ieee_qcn_stats * ) ;
   int (*ieee_getpfc)(struct net_device * , struct ieee_pfc * ) ;
   int (*ieee_setpfc)(struct net_device * , struct ieee_pfc * ) ;
   int (*ieee_getapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_setapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_delapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_peer_getets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_peer_getpfc)(struct net_device * , struct ieee_pfc * ) ;
   u8 (*getstate)(struct net_device * ) ;
   u8 (*setstate)(struct net_device * , u8  ) ;
   void (*getpermhwaddr)(struct net_device * , u8 * ) ;
   void (*setpgtccfgtx)(struct net_device * , int  , u8  , u8  , u8  , u8  ) ;
   void (*setpgbwgcfgtx)(struct net_device * , int  , u8  ) ;
   void (*setpgtccfgrx)(struct net_device * , int  , u8  , u8  , u8  , u8  ) ;
   void (*setpgbwgcfgrx)(struct net_device * , int  , u8  ) ;
   void (*getpgtccfgtx)(struct net_device * , int  , u8 * , u8 * , u8 * , u8 * ) ;
   void (*getpgbwgcfgtx)(struct net_device * , int  , u8 * ) ;
   void (*getpgtccfgrx)(struct net_device * , int  , u8 * , u8 * , u8 * , u8 * ) ;
   void (*getpgbwgcfgrx)(struct net_device * , int  , u8 * ) ;
   void (*setpfccfg)(struct net_device * , int  , u8  ) ;
   void (*getpfccfg)(struct net_device * , int  , u8 * ) ;
   u8 (*setall)(struct net_device * ) ;
   u8 (*getcap)(struct net_device * , int  , u8 * ) ;
   int (*getnumtcs)(struct net_device * , int  , u8 * ) ;
   int (*setnumtcs)(struct net_device * , int  , u8  ) ;
   u8 (*getpfcstate)(struct net_device * ) ;
   void (*setpfcstate)(struct net_device * , u8  ) ;
   void (*getbcncfg)(struct net_device * , int  , u32 * ) ;
   void (*setbcncfg)(struct net_device * , int  , u32  ) ;
   void (*getbcnrp)(struct net_device * , int  , u8 * ) ;
   void (*setbcnrp)(struct net_device * , int  , u8  ) ;
   int (*setapp)(struct net_device * , u8  , u16  , u8  ) ;
   int (*getapp)(struct net_device * , u8  , u16  ) ;
   u8 (*getfeatcfg)(struct net_device * , int  , u8 * ) ;
   u8 (*setfeatcfg)(struct net_device * , int  , u8  ) ;
   u8 (*getdcbx)(struct net_device * ) ;
   u8 (*setdcbx)(struct net_device * , u8  ) ;
   int (*peer_getappinfo)(struct net_device * , struct dcb_peer_app_info * , u16 * ) ;
   int (*peer_getapptable)(struct net_device * , struct dcb_app * ) ;
   int (*cee_peer_getpg)(struct net_device * , struct cee_pg * ) ;
   int (*cee_peer_getpfc)(struct net_device * , struct cee_pfc * ) ;
};
struct taskstats {
   __u16 version ;
   __u32 ac_exitcode ;
   __u8 ac_flag ;
   __u8 ac_nice ;
   __u64 cpu_count ;
   __u64 cpu_delay_total ;
   __u64 blkio_count ;
   __u64 blkio_delay_total ;
   __u64 swapin_count ;
   __u64 swapin_delay_total ;
   __u64 cpu_run_real_total ;
   __u64 cpu_run_virtual_total ;
   char ac_comm[32U] ;
   __u8 ac_sched ;
   __u8 ac_pad[3U] ;
   __u32 ac_uid ;
   __u32 ac_gid ;
   __u32 ac_pid ;
   __u32 ac_ppid ;
   __u32 ac_btime ;
   __u64 ac_etime ;
   __u64 ac_utime ;
   __u64 ac_stime ;
   __u64 ac_minflt ;
   __u64 ac_majflt ;
   __u64 coremem ;
   __u64 virtmem ;
   __u64 hiwater_rss ;
   __u64 hiwater_vm ;
   __u64 read_char ;
   __u64 write_char ;
   __u64 read_syscalls ;
   __u64 write_syscalls ;
   __u64 read_bytes ;
   __u64 write_bytes ;
   __u64 cancelled_write_bytes ;
   __u64 nvcsw ;
   __u64 nivcsw ;
   __u64 ac_utimescaled ;
   __u64 ac_stimescaled ;
   __u64 cpu_scaled_run_real_total ;
   __u64 freepages_count ;
   __u64 freepages_delay_total ;
};
struct netprio_map {
   struct callback_head rcu ;
   u32 priomap_len ;
   u32 priomap[] ;
};
struct xfrm_policy;
struct xfrm_state;
struct request_sock;
struct mnt_namespace;
struct ipc_namespace;
struct nsproxy {
   atomic_t count ;
   struct uts_namespace *uts_ns ;
   struct ipc_namespace *ipc_ns ;
   struct mnt_namespace *mnt_ns ;
   struct pid_namespace *pid_ns_for_children ;
   struct net *net_ns ;
};
struct nlmsghdr {
   __u32 nlmsg_len ;
   __u16 nlmsg_type ;
   __u16 nlmsg_flags ;
   __u32 nlmsg_seq ;
   __u32 nlmsg_pid ;
};
struct nlattr {
   __u16 nla_len ;
   __u16 nla_type ;
};
struct netlink_callback {
   struct sk_buff *skb ;
   struct nlmsghdr  const  *nlh ;
   int (*dump)(struct sk_buff * , struct netlink_callback * ) ;
   int (*done)(struct netlink_callback * ) ;
   void *data ;
   struct module *module ;
   u16 family ;
   u16 min_dump_alloc ;
   unsigned int prev_seq ;
    klee_make_symbolic(&prev_seq, sizeof(int), "prev_seq");
   unsigned int seq ;
    klee_make_symbolic(&seq, sizeof(int), "seq");
   long args[6U] ;
};
struct ndmsg {
   __u8 ndm_family ;
   __u8 ndm_pad1 ;
   __u16 ndm_pad2 ;
   __s32 ndm_ifindex ;
   __u16 ndm_state ;
   __u8 ndm_flags ;
   __u8 ndm_type ;
};
struct rtnl_link_stats64 {
   __u64 rx_packets ;
   __u64 tx_packets ;
   __u64 rx_bytes ;
   __u64 tx_bytes ;
   __u64 rx_errors ;
   __u64 tx_errors ;
   __u64 rx_dropped ;
   __u64 tx_dropped ;
   __u64 multicast ;
   __u64 collisions ;
   __u64 rx_length_errors ;
   __u64 rx_over_errors ;
   __u64 rx_crc_errors ;
   __u64 rx_frame_errors ;
   __u64 rx_fifo_errors ;
   __u64 rx_missed_errors ;
   __u64 tx_aborted_errors ;
   __u64 tx_carrier_errors ;
   __u64 tx_fifo_errors ;
   __u64 tx_heartbeat_errors ;
   __u64 tx_window_errors ;
   __u64 rx_compressed ;
   __u64 tx_compressed ;
};
struct ifla_vf_stats {
   __u64 rx_packets ;
   __u64 tx_packets ;
   __u64 rx_bytes ;
   __u64 tx_bytes ;
   __u64 broadcast ;
   __u64 multicast ;
};
struct ifla_vf_info {
   __u32 vf ;
   __u8 mac[32U] ;
   __u32 vlan ;
   __u32 qos ;
   __u32 spoofchk ;
   __u32 linkstate ;
   __u32 min_tx_rate ;
   __u32 max_tx_rate ;
   __u32 rss_query_en ;
};
struct netpoll_info;
struct wireless_dev;
struct wpan_dev;
struct mpls_dev;
enum netdev_tx {
    __NETDEV_TX_MIN = (-0x7FFFFFFF-1),
    NETDEV_TX_OK = 0,
    NETDEV_TX_BUSY = 16,
    NETDEV_TX_LOCKED = 32
} ;
typedef enum netdev_tx netdev_tx_t;
struct net_device_stats {
   unsigned long rx_packets ;
    klee_make_symbolic(&rx_packets, sizeof(long), "rx_packets");
   unsigned long tx_packets ;
    klee_make_symbolic(&tx_packets, sizeof(long), "tx_packets");
   unsigned long rx_bytes ;
    klee_make_symbolic(&rx_bytes, sizeof(long), "rx_bytes");
   unsigned long tx_bytes ;
    klee_make_symbolic(&tx_bytes, sizeof(long), "tx_bytes");
   unsigned long rx_errors ;
    klee_make_symbolic(&rx_errors, sizeof(long), "rx_errors");
   unsigned long tx_errors ;
    klee_make_symbolic(&tx_errors, sizeof(long), "tx_errors");
   unsigned long rx_dropped ;
    klee_make_symbolic(&rx_dropped, sizeof(long), "rx_dropped");
   unsigned long tx_dropped ;
    klee_make_symbolic(&tx_dropped, sizeof(long), "tx_dropped");
   unsigned long multicast ;
    klee_make_symbolic(&multicast, sizeof(long), "multicast");
   unsigned long collisions ;
    klee_make_symbolic(&collisions, sizeof(long), "collisions");
   unsigned long rx_length_errors ;
    klee_make_symbolic(&rx_length_errors, sizeof(long), "rx_length_errors");
   unsigned long rx_over_errors ;
    klee_make_symbolic(&rx_over_errors, sizeof(long), "rx_over_errors");
   unsigned long rx_crc_errors ;
    klee_make_symbolic(&rx_crc_errors, sizeof(long), "rx_crc_errors");
   unsigned long rx_frame_errors ;
    klee_make_symbolic(&rx_frame_errors, sizeof(long), "rx_frame_errors");
   unsigned long rx_fifo_errors ;
    klee_make_symbolic(&rx_fifo_errors, sizeof(long), "rx_fifo_errors");
   unsigned long rx_missed_errors ;
    klee_make_symbolic(&rx_missed_errors, sizeof(long), "rx_missed_errors");
   unsigned long tx_aborted_errors ;
    klee_make_symbolic(&tx_aborted_errors, sizeof(long), "tx_aborted_errors");
   unsigned long tx_carrier_errors ;
    klee_make_symbolic(&tx_carrier_errors, sizeof(long), "tx_carrier_errors");
   unsigned long tx_fifo_errors ;
    klee_make_symbolic(&tx_fifo_errors, sizeof(long), "tx_fifo_errors");
   unsigned long tx_heartbeat_errors ;
    klee_make_symbolic(&tx_heartbeat_errors, sizeof(long), "tx_heartbeat_errors");
   unsigned long tx_window_errors ;
    klee_make_symbolic(&tx_window_errors, sizeof(long), "tx_window_errors");
   unsigned long rx_compressed ;
    klee_make_symbolic(&rx_compressed, sizeof(long), "rx_compressed");
   unsigned long tx_compressed ;
    klee_make_symbolic(&tx_compressed, sizeof(long), "tx_compressed");
};
struct neigh_parms;
struct netdev_hw_addr {
   struct list_head list ;
   unsigned char addr[32U] ;
   unsigned char type ;
   bool global_use ;
   int sync_cnt ;
    klee_make_symbolic(&sync_cnt, sizeof(int), "sync_cnt");
   int refcount ;
   int synced ;
    klee_make_symbolic(&synced, sizeof(int), "synced");
   struct callback_head callback_head ;
};
struct netdev_hw_addr_list {
   struct list_head list ;
   int count ;
};
struct hh_cache {
   u16 hh_len ;
   u16 __pad ;
   seqlock_t hh_lock ;
   unsigned long hh_data[16U] ;
};
struct header_ops {
   int (*create)(struct sk_buff * , struct net_device * , unsigned short  , void const   * ,
                 void const   * , unsigned int  ) ;
   int (*parse)(struct sk_buff  const  * , unsigned char * ) ;
   int (*cache)(struct neighbour  const  * , struct hh_cache * , __be16  ) ;
   void (*cache_update)(struct hh_cache * , struct net_device  const  * , unsigned char const   * ) ;
};
struct napi_struct {
   struct list_head poll_list ;
   unsigned long state ;
   int weight ;
   unsigned int gro_count ;
    klee_make_symbolic(&gro_count, sizeof(int), "gro_count");
   int (*poll)(struct napi_struct * , int  ) ;
   spinlock_t poll_lock ;
   int poll_owner ;
    klee_make_symbolic(&poll_owner, sizeof(int), "poll_owner");
   struct net_device *dev ;
   struct sk_buff *gro_list ;
   struct sk_buff *skb ;
   struct hrtimer timer ;
   struct list_head dev_list ;
   struct hlist_node napi_hash_node ;
   unsigned int napi_id ;
};
enum gro_result {
    GRO_MERGED = 0,
    GRO_MERGED_FREE = 1,
    GRO_HELD = 2,
    GRO_NORMAL = 3,
    GRO_DROP = 4
} ;
typedef enum gro_result gro_result_t;
enum rx_handler_result {
    RX_HANDLER_CONSUMED = 0,
    RX_HANDLER_ANOTHER = 1,
    RX_HANDLER_EXACT = 2,
    RX_HANDLER_PASS = 3
} ;
typedef enum rx_handler_result rx_handler_result_t;
typedef rx_handler_result_t rx_handler_func_t(struct sk_buff ** );
struct Qdisc;
struct netdev_queue {
   struct net_device *dev ;
   struct Qdisc *qdisc ;
   struct Qdisc *qdisc_sleeping ;
   struct kobject kobj ;
   int numa_node ;
   spinlock_t _xmit_lock ;
   int xmit_lock_owner ;
    klee_make_symbolic(&xmit_lock_owner, sizeof(int), "xmit_lock_owner");
   unsigned long trans_start ;
    klee_make_symbolic(&trans_start, sizeof(long), "trans_start");
   unsigned long trans_timeout ;
    klee_make_symbolic(&trans_timeout, sizeof(long), "trans_timeout");
   unsigned long state ;
   struct dql dql ;
   unsigned long tx_maxrate ;
    klee_make_symbolic(&tx_maxrate, sizeof(long), "tx_maxrate");
};
struct rps_map {
   unsigned int len ;
   struct callback_head rcu ;
   u16 cpus[0U] ;
};
struct rps_dev_flow {
   u16 cpu ;
   u16 filter ;
   unsigned int last_qtail ;
    klee_make_symbolic(&last_qtail, sizeof(int), "last_qtail");
};
struct rps_dev_flow_table {
   unsigned int mask ;
   struct callback_head rcu ;
   struct rps_dev_flow flows[0U] ;
};
struct netdev_rx_queue {
   struct rps_map *rps_map ;
   struct rps_dev_flow_table *rps_flow_table ;
   struct kobject kobj ;
   struct net_device *dev ;
};
struct xps_map {
   unsigned int len ;
   unsigned int alloc_len ;
    klee_make_symbolic(&alloc_len, sizeof(int), "alloc_len");
   struct callback_head rcu ;
   u16 queues[0U] ;
};
struct xps_dev_maps {
   struct callback_head rcu ;
   struct xps_map *cpu_map[0U] ;
};
struct netdev_tc_txq {
   u16 count ;
   u16 offset ;
};
struct netdev_fcoe_hbainfo {
   char manufacturer[64U] ;
   char serial_number[64U] ;
   char hardware_version[64U] ;
   char driver_version[64U] ;
   char optionrom_version[64U] ;
   char firmware_version[64U] ;
   char model[256U] ;
   char model_description[256U] ;
};
struct netdev_phys_item_id {
   unsigned char id[32U] ;
   unsigned char id_len ;
    klee_make_symbolic(&id_len, sizeof(char), "id_len");
};
struct net_device_ops {
   int (*ndo_init)(struct net_device * ) ;
   void (*ndo_uninit)(struct net_device * ) ;
   int (*ndo_open)(struct net_device * ) ;
   int (*ndo_stop)(struct net_device * ) ;
   netdev_tx_t (*ndo_start_xmit)(struct sk_buff * , struct net_device * ) ;
   u16 (*ndo_select_queue)(struct net_device * , struct sk_buff * , void * , u16 (*)(struct net_device * ,
                                                                                     struct sk_buff * ) ) ;
   void (*ndo_change_rx_flags)(struct net_device * , int  ) ;
   void (*ndo_set_rx_mode)(struct net_device * ) ;
   int (*ndo_set_mac_address)(struct net_device * , void * ) ;
   int (*ndo_validate_addr)(struct net_device * ) ;
   int (*ndo_do_ioctl)(struct net_device * , struct ifreq * , int  ) ;
   int (*ndo_set_config)(struct net_device * , struct ifmap * ) ;
   int (*ndo_change_mtu)(struct net_device * , int  ) ;
   int (*ndo_neigh_setup)(struct net_device * , struct neigh_parms * ) ;
   void (*ndo_tx_timeout)(struct net_device * ) ;
   struct rtnl_link_stats64 *(*ndo_get_stats64)(struct net_device * , struct rtnl_link_stats64 * ) ;
   struct net_device_stats *(*ndo_get_stats)(struct net_device * ) ;
   int (*ndo_vlan_rx_add_vid)(struct net_device * , __be16  , u16  ) ;
   int (*ndo_vlan_rx_kill_vid)(struct net_device * , __be16  , u16  ) ;
   void (*ndo_poll_controller)(struct net_device * ) ;
   int (*ndo_netpoll_setup)(struct net_device * , struct netpoll_info * ) ;
   void (*ndo_netpoll_cleanup)(struct net_device * ) ;
   int (*ndo_busy_poll)(struct napi_struct * ) ;
   int (*ndo_set_vf_mac)(struct net_device * , int  , u8 * ) ;
   int (*ndo_set_vf_vlan)(struct net_device * , int  , u16  , u8  ) ;
   int (*ndo_set_vf_rate)(struct net_device * , int  , int  , int  ) ;
   int (*ndo_set_vf_spoofchk)(struct net_device * , int  , bool  ) ;
   int (*ndo_get_vf_config)(struct net_device * , int  , struct ifla_vf_info * ) ;
   int (*ndo_set_vf_link_state)(struct net_device * , int  , int  ) ;
   int (*ndo_get_vf_stats)(struct net_device * , int  , struct ifla_vf_stats * ) ;
   int (*ndo_set_vf_port)(struct net_device * , int  , struct nlattr ** ) ;
   int (*ndo_get_vf_port)(struct net_device * , int  , struct sk_buff * ) ;
   int (*ndo_set_vf_rss_query_en)(struct net_device * , int  , bool  ) ;
   int (*ndo_setup_tc)(struct net_device * , u8  ) ;
   int (*ndo_fcoe_enable)(struct net_device * ) ;
   int (*ndo_fcoe_disable)(struct net_device * ) ;
   int (*ndo_fcoe_ddp_setup)(struct net_device * , u16  , struct scatterlist * , unsigned int  ) ;
   int (*ndo_fcoe_ddp_done)(struct net_device * , u16  ) ;
   int (*ndo_fcoe_ddp_target)(struct net_device * , u16  , struct scatterlist * ,
                              unsigned int  ) ;
   int (*ndo_fcoe_get_hbainfo)(struct net_device * , struct netdev_fcoe_hbainfo * ) ;
   int (*ndo_fcoe_get_wwn)(struct net_device * , u64 * , int  ) ;
   int (*ndo_rx_flow_steer)(struct net_device * , struct sk_buff  const  * , u16  ,
                            u32  ) ;
   int (*ndo_add_slave)(struct net_device * , struct net_device * ) ;
   int (*ndo_del_slave)(struct net_device * , struct net_device * ) ;
   netdev_features_t (*ndo_fix_features)(struct net_device * , netdev_features_t  ) ;
   int (*ndo_set_features)(struct net_device * , netdev_features_t  ) ;
   int (*ndo_neigh_construct)(struct neighbour * ) ;
   void (*ndo_neigh_destroy)(struct neighbour * ) ;
   int (*ndo_fdb_add)(struct ndmsg * , struct nlattr ** , struct net_device * , unsigned char const   * ,
                      u16  , u16  ) ;
   int (*ndo_fdb_del)(struct ndmsg * , struct nlattr ** , struct net_device * , unsigned char const   * ,
                      u16  ) ;
   int (*ndo_fdb_dump)(struct sk_buff * , struct netlink_callback * , struct net_device * ,
                       struct net_device * , int  ) ;
   int (*ndo_bridge_setlink)(struct net_device * , struct nlmsghdr * , u16  ) ;
   int (*ndo_bridge_getlink)(struct sk_buff * , u32  , u32  , struct net_device * ,
                             u32  , int  ) ;
   int (*ndo_bridge_dellink)(struct net_device * , struct nlmsghdr * , u16  ) ;
   int (*ndo_change_carrier)(struct net_device * , bool  ) ;
   int (*ndo_get_phys_port_id)(struct net_device * , struct netdev_phys_item_id * ) ;
   int (*ndo_get_phys_port_name)(struct net_device * , char * , size_t  ) ;
   void (*ndo_add_vxlan_port)(struct net_device * , sa_family_t  , __be16  ) ;
   void (*ndo_del_vxlan_port)(struct net_device * , sa_family_t  , __be16  ) ;
   void *(*ndo_dfwd_add_station)(struct net_device * , struct net_device * ) ;
   void (*ndo_dfwd_del_station)(struct net_device * , void * ) ;
   netdev_tx_t (*ndo_dfwd_start_xmit)(struct sk_buff * , struct net_device * , void * ) ;
   int (*ndo_get_lock_subclass)(struct net_device * ) ;
   netdev_features_t (*ndo_features_check)(struct sk_buff * , struct net_device * ,
                                           netdev_features_t  ) ;
   int (*ndo_set_tx_maxrate)(struct net_device * , int  , u32  ) ;
   int (*ndo_get_iflink)(struct net_device  const  * ) ;
};
struct __anonstruct_adj_list_315 {
   struct list_head upper ;
   struct list_head lower ;
};
struct __anonstruct_all_adj_list_316 {
   struct list_head upper ;
   struct list_head lower ;
};
struct iw_handler_def;
struct iw_public_data;
struct switchdev_ops;
struct vlan_info;
struct tipc_bearer;
struct in_device;
struct dn_dev;
struct inet6_dev;
struct tcf_proto;
struct cpu_rmap;
struct pcpu_lstats;
struct pcpu_sw_netstats;
struct pcpu_dstats;
struct pcpu_vstats;
union __anonunion____missing_field_name_317 {
   void *ml_priv ;
   struct pcpu_lstats *lstats ;
   struct pcpu_sw_netstats *tstats ;
   struct pcpu_dstats *dstats ;
   struct pcpu_vstats *vstats ;
};
struct garp_port;
struct mrp_port;
struct rtnl_link_ops;
struct net_device {
   char name[16U] ;
   struct hlist_node name_hlist ;
   char *ifalias ;
   unsigned long mem_end ;
   unsigned long mem_start ;
   unsigned long base_addr ;
   int irq ;
   atomic_t carrier_changes ;
   unsigned long state ;
   struct list_head dev_list ;
   struct list_head napi_list ;
   struct list_head unreg_list ;
   struct list_head close_list ;
   struct list_head ptype_all ;
   struct list_head ptype_specific ;
   struct __anonstruct_adj_list_315 adj_list ;
   struct __anonstruct_all_adj_list_316 all_adj_list ;
   netdev_features_t features ;
   netdev_features_t hw_features ;
   netdev_features_t wanted_features ;
   netdev_features_t vlan_features ;
   netdev_features_t hw_enc_features ;
   netdev_features_t mpls_features ;
   int ifindex ;
   int group ;
    klee_make_symbolic(&group, sizeof(int), "group");
   struct net_device_stats stats ;
   atomic_long_t rx_dropped ;
   atomic_long_t tx_dropped ;
   struct iw_handler_def  const  *wireless_handlers ;
   struct iw_public_data *wireless_data ;
   struct net_device_ops  const  *netdev_ops ;
   struct ethtool_ops  const  *ethtool_ops ;
   struct switchdev_ops  const  *switchdev_ops ;
   struct header_ops  const  *header_ops ;
   unsigned int flags ;
   unsigned int priv_flags ;
    klee_make_symbolic(&priv_flags, sizeof(int), "priv_flags");
   unsigned short gflags ;
    klee_make_symbolic(&gflags, sizeof(short), "gflags");
   unsigned short padded ;
    klee_make_symbolic(&padded, sizeof(short), "padded");
   unsigned char operstate ;
    klee_make_symbolic(&operstate, sizeof(char), "operstate");
   unsigned char link_mode ;
    klee_make_symbolic(&link_mode, sizeof(char), "link_mode");
   unsigned char if_port ;
    klee_make_symbolic(&if_port, sizeof(char), "if_port");
   unsigned char dma ;
   unsigned int mtu ;
    klee_make_symbolic(&mtu, sizeof(int), "mtu");
   unsigned short type ;
   unsigned short hard_header_len ;
    klee_make_symbolic(&hard_header_len, sizeof(short), "hard_header_len");
   unsigned short needed_headroom ;
    klee_make_symbolic(&needed_headroom, sizeof(short), "needed_headroom");
   unsigned short needed_tailroom ;
    klee_make_symbolic(&needed_tailroom, sizeof(short), "needed_tailroom");
   unsigned char perm_addr[32U] ;
   unsigned char addr_assign_type ;
    klee_make_symbolic(&addr_assign_type, sizeof(char), "addr_assign_type");
   unsigned char addr_len ;
    klee_make_symbolic(&addr_len, sizeof(char), "addr_len");
   unsigned short neigh_priv_len ;
    klee_make_symbolic(&neigh_priv_len, sizeof(short), "neigh_priv_len");
   unsigned short dev_id ;
    klee_make_symbolic(&dev_id, sizeof(short), "dev_id");
   unsigned short dev_port ;
    klee_make_symbolic(&dev_port, sizeof(short), "dev_port");
   spinlock_t addr_list_lock ;
   unsigned char name_assign_type ;
    klee_make_symbolic(&name_assign_type, sizeof(char), "name_assign_type");
   bool uc_promisc ;
   struct netdev_hw_addr_list uc ;
   struct netdev_hw_addr_list mc ;
   struct netdev_hw_addr_list dev_addrs ;
   struct kset *queues_kset ;
   unsigned int promiscuity ;
    klee_make_symbolic(&promiscuity, sizeof(int), "promiscuity");
   unsigned int allmulti ;
    klee_make_symbolic(&allmulti, sizeof(int), "allmulti");
   struct vlan_info *vlan_info ;
   struct dsa_switch_tree *dsa_ptr ;
   struct tipc_bearer *tipc_ptr ;
   void *atalk_ptr ;
   struct in_device *ip_ptr ;
   struct dn_dev *dn_ptr ;
   struct inet6_dev *ip6_ptr ;
   void *ax25_ptr ;
   struct wireless_dev *ieee80211_ptr ;
   struct wpan_dev *ieee802154_ptr ;
   struct mpls_dev *mpls_ptr ;
   unsigned long last_rx ;
    klee_make_symbolic(&last_rx, sizeof(long), "last_rx");
   unsigned char *dev_addr ;
   struct netdev_rx_queue *_rx ;
   unsigned int num_rx_queues ;
    klee_make_symbolic(&num_rx_queues, sizeof(int), "num_rx_queues");
   unsigned int real_num_rx_queues ;
    klee_make_symbolic(&real_num_rx_queues, sizeof(int), "real_num_rx_queues");
   unsigned long gro_flush_timeout ;
    klee_make_symbolic(&gro_flush_timeout, sizeof(long), "gro_flush_timeout");
   rx_handler_func_t *rx_handler ;
   void *rx_handler_data ;
   struct tcf_proto *ingress_cl_list ;
   struct netdev_queue *ingress_queue ;
   struct list_head nf_hooks_ingress ;
   unsigned char broadcast[32U] ;
   struct cpu_rmap *rx_cpu_rmap ;
   struct hlist_node index_hlist ;
   struct netdev_queue *_tx ;
   unsigned int num_tx_queues ;
    klee_make_symbolic(&num_tx_queues, sizeof(int), "num_tx_queues");
   unsigned int real_num_tx_queues ;
    klee_make_symbolic(&real_num_tx_queues, sizeof(int), "real_num_tx_queues");
   struct Qdisc *qdisc ;
   unsigned long tx_queue_len ;
    klee_make_symbolic(&tx_queue_len, sizeof(long), "tx_queue_len");
   spinlock_t tx_global_lock ;
   int watchdog_timeo ;
    klee_make_symbolic(&watchdog_timeo, sizeof(int), "watchdog_timeo");
   struct xps_dev_maps *xps_maps ;
   unsigned long trans_start ;
   struct timer_list watchdog_timer ;
   int *pcpu_refcnt ;
   struct list_head todo_list ;
   struct list_head link_watch_list ;
   unsigned char reg_state ;
    klee_make_symbolic(&reg_state, sizeof(char), "reg_state");
   bool dismantle ;
   unsigned short rtnl_link_state ;
    klee_make_symbolic(&rtnl_link_state, sizeof(short), "rtnl_link_state");
   void (*destructor)(struct net_device * ) ;
   struct netpoll_info *npinfo ;
   possible_net_t nd_net ;
   union __anonunion____missing_field_name_317 __annonCompField94 ;
   struct garp_port *garp_port ;
   struct mrp_port *mrp_port ;
   struct device dev ;
   struct attribute_group  const  *sysfs_groups[4U] ;
   struct attribute_group  const  *sysfs_rx_queue_group ;
   struct rtnl_link_ops  const  *rtnl_link_ops ;
   unsigned int gso_max_size ;
    klee_make_symbolic(&gso_max_size, sizeof(int), "gso_max_size");
   u16 gso_max_segs ;
   u16 gso_min_segs ;
   struct dcbnl_rtnl_ops  const  *dcbnl_ops ;
   u8 num_tc ;
   struct netdev_tc_txq tc_to_txq[16U] ;
   u8 prio_tc_map[16U] ;
   unsigned int fcoe_ddp_xid ;
    klee_make_symbolic(&fcoe_ddp_xid, sizeof(int), "fcoe_ddp_xid");
   struct netprio_map *priomap ;
   struct phy_device *phydev ;
   struct lock_class_key *qdisc_tx_busylock ;
};
struct packet_type {
   __be16 type ;
   struct net_device *dev ;
   int (*func)(struct sk_buff * , struct net_device * , struct packet_type * , struct net_device * ) ;
   bool (*id_match)(struct packet_type * , struct sock * ) ;
   void *af_packet_priv ;
   struct list_head list ;
};
struct pcpu_sw_netstats {
   u64 rx_packets ;
   u64 rx_bytes ;
   u64 tx_packets ;
   u64 tx_bytes ;
   struct u64_stats_sync syncp ;
};
enum skb_free_reason {
    SKB_REASON_CONSUMED = 0,
    SKB_REASON_DROPPED = 1
} ;
struct vlan_hdr {
   __be16 h_vlan_TCI ;
   __be16 h_vlan_encapsulated_proto ;
};
struct iphdr {
   unsigned char ihl : 4 ;
   unsigned char version : 4 ;
   __u8 tos ;
   __be16 tot_len ;
   __be16 id ;
   __be16 frag_off ;
   __u8 ttl ;
   __u8 protocol ;
   __sum16 check ;
   __be32 saddr ;
   __be32 daddr ;
};
struct ipv6hdr {
   unsigned char priority : 4 ;
   unsigned char version : 4 ;
   __u8 flow_lbl[3U] ;
   __be16 payload_len ;
   __u8 nexthdr ;
   __u8 hop_limit ;
   struct in6_addr saddr ;
   struct in6_addr daddr ;
};
struct ipv6_stable_secret {
   bool initialized ;
   struct in6_addr secret ;
};
struct ipv6_devconf {
   __s32 forwarding ;
   __s32 hop_limit ;
   __s32 mtu6 ;
   __s32 accept_ra ;
   __s32 accept_redirects ;
   __s32 autoconf ;
   __s32 dad_transmits ;
   __s32 rtr_solicits ;
   __s32 rtr_solicit_interval ;
   __s32 rtr_solicit_delay ;
   __s32 force_mld_version ;
   __s32 mldv1_unsolicited_report_interval ;
   __s32 mldv2_unsolicited_report_interval ;
   __s32 use_tempaddr ;
   __s32 temp_valid_lft ;
   __s32 temp_prefered_lft ;
   __s32 regen_max_retry ;
   __s32 max_desync_factor ;
   __s32 max_addresses ;
   __s32 accept_ra_defrtr ;
   __s32 accept_ra_pinfo ;
   __s32 accept_ra_rtr_pref ;
   __s32 rtr_probe_interval ;
   __s32 accept_ra_rt_info_max_plen ;
   __s32 proxy_ndp ;
   __s32 accept_source_route ;
   __s32 accept_ra_from_local ;
   __s32 optimistic_dad ;
   __s32 use_optimistic ;
   __s32 mc_forwarding ;
   __s32 disable_ipv6 ;
   __s32 accept_dad ;
   __s32 force_tllao ;
   __s32 ndisc_notify ;
   __s32 suppress_frag_ndisc ;
   __s32 accept_ra_mtu ;
   struct ipv6_stable_secret stable_secret ;
   void *sysctl ;
};
struct page_counter {
   atomic_long_t count ;
   unsigned long limit ;
   struct page_counter *parent ;
   unsigned long watermark ;
    klee_make_symbolic(&watermark, sizeof(long), "watermark");
   unsigned long failcnt ;
    klee_make_symbolic(&failcnt, sizeof(long), "failcnt");
};
struct sock_filter {
   __u16 code ;
   __u8 jt ;
   __u8 jf ;
   __u32 k ;
};
struct bpf_insn {
   __u8 code ;
   unsigned char dst_reg : 4 ;
   unsigned char src_reg : 4 ;
   __s16 off ;
   __s32 imm ;
};
enum bpf_prog_type {
    BPF_PROG_TYPE_UNSPEC = 0,
    BPF_PROG_TYPE_SOCKET_FILTER = 1,
    BPF_PROG_TYPE_KPROBE = 2,
    BPF_PROG_TYPE_SCHED_CLS = 3,
    BPF_PROG_TYPE_SCHED_ACT = 4
} ;
struct bpf_prog_aux;
struct sock_fprog_kern {
   u16 len ;
   struct sock_filter *filter ;
};
union __anonunion____missing_field_name_337 {
   struct sock_filter insns[0U] ;
   struct bpf_insn insnsi[0U] ;
};
struct bpf_prog {
   u16 pages ;
   bool jited ;
   bool gpl_compatible ;
   u32 len ;
   enum bpf_prog_type type ;
   struct bpf_prog_aux *aux ;
   struct sock_fprog_kern *orig_prog ;
   unsigned int (*bpf_func)(struct sk_buff  const  * , struct bpf_insn  const  * ) ;
   union __anonunion____missing_field_name_337 __annonCompField99 ;
};
struct sk_filter {
   atomic_t refcnt ;
   struct callback_head rcu ;
   struct bpf_prog *prog ;
};
struct pollfd {
   int fd ;
    klee_make_symbolic(&fd, sizeof(int), "fd");
   short events ;
   short revents ;
    klee_make_symbolic(&revents, sizeof(short), "revents");
};
struct poll_table_struct {
   void (*_qproc)(struct file * , wait_queue_head_t * , struct poll_table_struct * ) ;
   unsigned long _key ;
    klee_make_symbolic(&_key, sizeof(long), "_key");
};
struct nla_policy {
   u16 type ;
   u16 len ;
};
struct rtnl_link_ops {
   struct list_head list ;
   char const   *kind ;
   size_t priv_size ;
   void (*setup)(struct net_device * ) ;
   int maxtype ;
    klee_make_symbolic(&maxtype, sizeof(int), "maxtype");
   struct nla_policy  const  *policy ;
   int (*validate)(struct nlattr ** , struct nlattr ** ) ;
   int (*newlink)(struct net * , struct net_device * , struct nlattr ** , struct nlattr ** ) ;
   int (*changelink)(struct net_device * , struct nlattr ** , struct nlattr ** ) ;
   void (*dellink)(struct net_device * , struct list_head * ) ;
   size_t (*get_size)(struct net_device  const  * ) ;
   int (*fill_info)(struct sk_buff * , struct net_device  const  * ) ;
   size_t (*get_xstats_size)(struct net_device  const  * ) ;
   int (*fill_xstats)(struct sk_buff * , struct net_device  const  * ) ;
   unsigned int (*get_num_tx_queues)(void) ;
   unsigned int (*get_num_rx_queues)(void) ;
   int slave_maxtype ;
    klee_make_symbolic(&slave_maxtype, sizeof(int), "slave_maxtype");
   struct nla_policy  const  *slave_policy ;
   int (*slave_validate)(struct nlattr ** , struct nlattr ** ) ;
   int (*slave_changelink)(struct net_device * , struct net_device * , struct nlattr ** ,
                           struct nlattr ** ) ;
   size_t (*get_slave_size)(struct net_device  const  * , struct net_device  const  * ) ;
   int (*fill_slave_info)(struct sk_buff * , struct net_device  const  * , struct net_device  const  * ) ;
   struct net *(*get_link_net)(struct net_device  const  * ) ;
};
struct neigh_table;
struct neigh_parms {
   possible_net_t net ;
   struct net_device *dev ;
   struct list_head list ;
   int (*neigh_setup)(struct neighbour * ) ;
   void (*neigh_cleanup)(struct neighbour * ) ;
   struct neigh_table *tbl ;
   void *sysctl_table ;
   int dead ;
    klee_make_symbolic(&dead, sizeof(int), "dead");
   atomic_t refcnt ;
   struct callback_head callback_head ;
   int reachable_time ;
    klee_make_symbolic(&reachable_time, sizeof(int), "reachable_time");
   int data[13U] ;
   unsigned long data_state[1U] ;
};
struct neigh_statistics {
   unsigned long allocs ;
    klee_make_symbolic(&allocs, sizeof(long), "allocs");
   unsigned long destroys ;
    klee_make_symbolic(&destroys, sizeof(long), "destroys");
   unsigned long hash_grows ;
    klee_make_symbolic(&hash_grows, sizeof(long), "hash_grows");
   unsigned long res_failed ;
    klee_make_symbolic(&res_failed, sizeof(long), "res_failed");
   unsigned long lookups ;
    klee_make_symbolic(&lookups, sizeof(long), "lookups");
   unsigned long hits ;
    klee_make_symbolic(&hits, sizeof(long), "hits");
   unsigned long rcv_probes_mcast ;
    klee_make_symbolic(&rcv_probes_mcast, sizeof(long), "rcv_probes_mcast");
   unsigned long rcv_probes_ucast ;
    klee_make_symbolic(&rcv_probes_ucast, sizeof(long), "rcv_probes_ucast");
   unsigned long periodic_gc_runs ;
    klee_make_symbolic(&periodic_gc_runs, sizeof(long), "periodic_gc_runs");
   unsigned long forced_gc_runs ;
    klee_make_symbolic(&forced_gc_runs, sizeof(long), "forced_gc_runs");
   unsigned long unres_discards ;
    klee_make_symbolic(&unres_discards, sizeof(long), "unres_discards");
};
struct neigh_ops;
struct neighbour {
   struct neighbour *next ;
   struct neigh_table *tbl ;
   struct neigh_parms *parms ;
   unsigned long confirmed ;
    klee_make_symbolic(&confirmed, sizeof(long), "confirmed");
   unsigned long updated ;
    klee_make_symbolic(&updated, sizeof(long), "updated");
   rwlock_t lock ;
   atomic_t refcnt ;
   struct sk_buff_head arp_queue ;
   unsigned int arp_queue_len_bytes ;
    klee_make_symbolic(&arp_queue_len_bytes, sizeof(int), "arp_queue_len_bytes");
   struct timer_list timer ;
   unsigned long used ;
   atomic_t probes ;
   __u8 flags ;
   __u8 nud_state ;
   __u8 type ;
   __u8 dead ;
   seqlock_t ha_lock ;
   unsigned char ha[32U] ;
   struct hh_cache hh ;
   int (*output)(struct neighbour * , struct sk_buff * ) ;
   struct neigh_ops  const  *ops ;
   struct callback_head rcu ;
   struct net_device *dev ;
   u8 primary_key[0U] ;
};
struct neigh_ops {
   int family ;
   void (*solicit)(struct neighbour * , struct sk_buff * ) ;
   void (*error_report)(struct neighbour * , struct sk_buff * ) ;
   int (*output)(struct neighbour * , struct sk_buff * ) ;
   int (*connected_output)(struct neighbour * , struct sk_buff * ) ;
};
struct pneigh_entry {
   struct pneigh_entry *next ;
   possible_net_t net ;
   struct net_device *dev ;
   u8 flags ;
   u8 key[0U] ;
};
struct neigh_hash_table {
   struct neighbour **hash_buckets ;
   unsigned int hash_shift ;
    klee_make_symbolic(&hash_shift, sizeof(int), "hash_shift");
   __u32 hash_rnd[4U] ;
   struct callback_head rcu ;
};
struct neigh_table {
   int family ;
   int entry_size ;
    klee_make_symbolic(&entry_size, sizeof(int), "entry_size");
   int key_len ;
    klee_make_symbolic(&key_len, sizeof(int), "key_len");
   __be16 protocol ;
   __u32 (*hash)(void const   * , struct net_device  const  * , __u32 * ) ;
   bool (*key_eq)(struct neighbour  const  * , void const   * ) ;
   int (*constructor)(struct neighbour * ) ;
   int (*pconstructor)(struct pneigh_entry * ) ;
   void (*pdestructor)(struct pneigh_entry * ) ;
   void (*proxy_redo)(struct sk_buff * ) ;
   char *id ;
   struct neigh_parms parms ;
   struct list_head parms_list ;
   int gc_interval ;
    klee_make_symbolic(&gc_interval, sizeof(int), "gc_interval");
   int gc_thresh1 ;
    klee_make_symbolic(&gc_thresh1, sizeof(int), "gc_thresh1");
   int gc_thresh2 ;
    klee_make_symbolic(&gc_thresh2, sizeof(int), "gc_thresh2");
   int gc_thresh3 ;
    klee_make_symbolic(&gc_thresh3, sizeof(int), "gc_thresh3");
   unsigned long last_flush ;
    klee_make_symbolic(&last_flush, sizeof(long), "last_flush");
   struct delayed_work gc_work ;
   struct timer_list proxy_timer ;
   struct sk_buff_head proxy_queue ;
   atomic_t entries ;
   rwlock_t lock ;
   unsigned long last_rand ;
    klee_make_symbolic(&last_rand, sizeof(long), "last_rand");
   struct neigh_statistics *stats ;
   struct neigh_hash_table *nht ;
   struct pneigh_entry **phash_buckets ;
};
struct dn_route;
union __anonunion____missing_field_name_345 {
   struct dst_entry *next ;
   struct rtable *rt_next ;
   struct rt6_info *rt6_next ;
   struct dn_route *dn_next ;
};
struct dst_entry {
   struct callback_head callback_head ;
   struct dst_entry *child ;
   struct net_device *dev ;
   struct dst_ops *ops ;
   unsigned long _metrics ;
    klee_make_symbolic(&_metrics, sizeof(long), "_metrics");
   unsigned long expires ;
   struct dst_entry *path ;
   struct dst_entry *from ;
   struct xfrm_state *xfrm ;
   int (*input)(struct sk_buff * ) ;
   int (*output)(struct sock * , struct sk_buff * ) ;
   unsigned short flags ;
   unsigned short pending_confirm ;
    klee_make_symbolic(&pending_confirm, sizeof(short), "pending_confirm");
   short error ;
    klee_make_symbolic(&error, sizeof(short), "error");
   short obsolete ;
    klee_make_symbolic(&obsolete, sizeof(short), "obsolete");
   unsigned short header_len ;
    klee_make_symbolic(&header_len, sizeof(short), "header_len");
   unsigned short trailer_len ;
    klee_make_symbolic(&trailer_len, sizeof(short), "trailer_len");
   __u32 tclassid ;
   long __pad_to_align_refcnt[2U] ;
   atomic_t __refcnt ;
   int __use ;
    klee_make_symbolic(&__use, sizeof(int), "__use");
   unsigned long lastuse ;
    klee_make_symbolic(&lastuse, sizeof(long), "lastuse");
   union __anonunion____missing_field_name_345 __annonCompField100 ;
};
struct __anonstruct_socket_lock_t_346 {
   spinlock_t slock ;
   int owned ;
    klee_make_symbolic(&owned, sizeof(int), "owned");
   wait_queue_head_t wq ;
   struct lockdep_map dep_map ;
};
typedef struct __anonstruct_socket_lock_t_346 socket_lock_t;
struct proto;
typedef __u32 __portpair;
typedef __u64 __addrpair;
struct __anonstruct____missing_field_name_348 {
   __be32 skc_daddr ;
   __be32 skc_rcv_saddr ;
};
union __anonunion____missing_field_name_347 {
   __addrpair skc_addrpair ;
   struct __anonstruct____missing_field_name_348 __annonCompField101 ;
};
union __anonunion____missing_field_name_349 {
   unsigned int skc_hash ;
    klee_make_symbolic(&skc_hash, sizeof(int), "skc_hash");
   __u16 skc_u16hashes[2U] ;
};
struct __anonstruct____missing_field_name_351 {
   __be16 skc_dport ;
   __u16 skc_num ;
};
union __anonunion____missing_field_name_350 {
   __portpair skc_portpair ;
   struct __anonstruct____missing_field_name_351 __annonCompField104 ;
};
union __anonunion____missing_field_name_352 {
   struct hlist_node skc_bind_node ;
   struct hlist_nulls_node skc_portaddr_node ;
};
union __anonunion____missing_field_name_353 {
   struct hlist_node skc_node ;
   struct hlist_nulls_node skc_nulls_node ;
};
struct sock_common {
   union __anonunion____missing_field_name_347 __annonCompField102 ;
   union __anonunion____missing_field_name_349 __annonCompField103 ;
   union __anonunion____missing_field_name_350 __annonCompField105 ;
   unsigned short skc_family ;
    klee_make_symbolic(&skc_family, sizeof(short), "skc_family");
   unsigned char volatile   skc_state ;
   unsigned char skc_reuse : 4 ;
   unsigned char skc_reuseport : 1 ;
   unsigned char skc_ipv6only : 1 ;
   unsigned char skc_net_refcnt : 1 ;
   int skc_bound_dev_if ;
    klee_make_symbolic(&skc_bound_dev_if, sizeof(int), "skc_bound_dev_if");
   union __anonunion____missing_field_name_352 __annonCompField106 ;
   struct proto *skc_prot ;
   possible_net_t skc_net ;
   struct in6_addr skc_v6_daddr ;
   struct in6_addr skc_v6_rcv_saddr ;
   atomic64_t skc_cookie ;
   int skc_dontcopy_begin[0U] ;
   union __anonunion____missing_field_name_353 __annonCompField107 ;
   int skc_tx_queue_mapping ;
    klee_make_symbolic(&skc_tx_queue_mapping, sizeof(int), "skc_tx_queue_mapping");
   atomic_t skc_refcnt ;
   int skc_dontcopy_end[0U] ;
};
struct cg_proto;
struct __anonstruct_sk_backlog_354 {
   atomic_t rmem_alloc ;
   int len ;
   struct sk_buff *head ;
   struct sk_buff *tail ;
};
struct sock {
   struct sock_common __sk_common ;
   socket_lock_t sk_lock ;
   struct sk_buff_head sk_receive_queue ;
   struct __anonstruct_sk_backlog_354 sk_backlog ;
   int sk_forward_alloc ;
    klee_make_symbolic(&sk_forward_alloc, sizeof(int), "sk_forward_alloc");
   __u32 sk_rxhash ;
   u16 sk_incoming_cpu ;
   __u32 sk_txhash ;
   unsigned int sk_napi_id ;
    klee_make_symbolic(&sk_napi_id, sizeof(int), "sk_napi_id");
   unsigned int sk_ll_usec ;
    klee_make_symbolic(&sk_ll_usec, sizeof(int), "sk_ll_usec");
   atomic_t sk_drops ;
   int sk_rcvbuf ;
    klee_make_symbolic(&sk_rcvbuf, sizeof(int), "sk_rcvbuf");
   struct sk_filter *sk_filter ;
   struct socket_wq *sk_wq ;
   struct xfrm_policy *sk_policy[2U] ;
   unsigned long sk_flags ;
    klee_make_symbolic(&sk_flags, sizeof(long), "sk_flags");
   struct dst_entry *sk_rx_dst ;
   struct dst_entry *sk_dst_cache ;
   spinlock_t sk_dst_lock ;
   atomic_t sk_wmem_alloc ;
   atomic_t sk_omem_alloc ;
   int sk_sndbuf ;
    klee_make_symbolic(&sk_sndbuf, sizeof(int), "sk_sndbuf");
   struct sk_buff_head sk_write_queue ;
   unsigned char sk_shutdown : 2 ;
   unsigned char sk_no_check_tx : 1 ;
   unsigned char sk_no_check_rx : 1 ;
   unsigned char sk_userlocks : 4 ;
   unsigned char sk_protocol ;
    klee_make_symbolic(&sk_protocol, sizeof(char), "sk_protocol");
   unsigned short sk_type ;
    klee_make_symbolic(&sk_type, sizeof(short), "sk_type");
   int sk_wmem_queued ;
    klee_make_symbolic(&sk_wmem_queued, sizeof(int), "sk_wmem_queued");
   gfp_t sk_allocation ;
   u32 sk_pacing_rate ;
   u32 sk_max_pacing_rate ;
   netdev_features_t sk_route_caps ;
   netdev_features_t sk_route_nocaps ;
   int sk_gso_type ;
    klee_make_symbolic(&sk_gso_type, sizeof(int), "sk_gso_type");
   unsigned int sk_gso_max_size ;
    klee_make_symbolic(&sk_gso_max_size, sizeof(int), "sk_gso_max_size");
   u16 sk_gso_max_segs ;
   int sk_rcvlowat ;
    klee_make_symbolic(&sk_rcvlowat, sizeof(int), "sk_rcvlowat");
   unsigned long sk_lingertime ;
    klee_make_symbolic(&sk_lingertime, sizeof(long), "sk_lingertime");
   struct sk_buff_head sk_error_queue ;
   struct proto *sk_prot_creator ;
   rwlock_t sk_callback_lock ;
   int sk_err ;
    klee_make_symbolic(&sk_err, sizeof(int), "sk_err");
   int sk_err_soft ;
    klee_make_symbolic(&sk_err_soft, sizeof(int), "sk_err_soft");
   u32 sk_ack_backlog ;
   u32 sk_max_ack_backlog ;
   __u32 sk_priority ;
   __u32 sk_cgrp_prioidx ;
   struct pid *sk_peer_pid ;
   struct cred  const  *sk_peer_cred ;
   long sk_rcvtimeo ;
    klee_make_symbolic(&sk_rcvtimeo, sizeof(long), "sk_rcvtimeo");
   long sk_sndtimeo ;
    klee_make_symbolic(&sk_sndtimeo, sizeof(long), "sk_sndtimeo");
   struct timer_list sk_timer ;
   ktime_t sk_stamp ;
   u16 sk_tsflags ;
   u32 sk_tskey ;
   struct socket *sk_socket ;
   void *sk_user_data ;
   struct page_frag sk_frag ;
   struct sk_buff *sk_send_head ;
   __s32 sk_peek_off ;
   int sk_write_pending ;
    klee_make_symbolic(&sk_write_pending, sizeof(int), "sk_write_pending");
   void *sk_security ;
   __u32 sk_mark ;
   u32 sk_classid ;
   struct cg_proto *sk_cgrp ;
   void (*sk_state_change)(struct sock * ) ;
   void (*sk_data_ready)(struct sock * ) ;
   void (*sk_write_space)(struct sock * ) ;
   void (*sk_error_report)(struct sock * ) ;
   int (*sk_backlog_rcv)(struct sock * , struct sk_buff * ) ;
   void (*sk_destruct)(struct sock * ) ;
};
struct request_sock_ops;
struct timewait_sock_ops;
struct inet_hashinfo;
struct raw_hashinfo;
struct udp_table;
union __anonunion_h_357 {
   struct inet_hashinfo *hashinfo ;
   struct udp_table *udp_table ;
   struct raw_hashinfo *raw_hash ;
};
struct proto {
   void (*close)(struct sock * , long  ) ;
   int (*connect)(struct sock * , struct sockaddr * , int  ) ;
   int (*disconnect)(struct sock * , int  ) ;
   struct sock *(*accept)(struct sock * , int  , int * ) ;
   int (*ioctl)(struct sock * , int  , unsigned long  ) ;
   int (*init)(struct sock * ) ;
   void (*destroy)(struct sock * ) ;
   void (*shutdown)(struct sock * , int  ) ;
   int (*setsockopt)(struct sock * , int  , int  , char * , unsigned int  ) ;
   int (*getsockopt)(struct sock * , int  , int  , char * , int * ) ;
   int (*compat_setsockopt)(struct sock * , int  , int  , char * , unsigned int  ) ;
   int (*compat_getsockopt)(struct sock * , int  , int  , char * , int * ) ;
   int (*compat_ioctl)(struct sock * , unsigned int  , unsigned long  ) ;
   int (*sendmsg)(struct sock * , struct msghdr * , size_t  ) ;
   int (*recvmsg)(struct sock * , struct msghdr * , size_t  , int  , int  , int * ) ;
   int (*sendpage)(struct sock * , struct page * , int  , size_t  , int  ) ;
   int (*bind)(struct sock * , struct sockaddr * , int  ) ;
   int (*backlog_rcv)(struct sock * , struct sk_buff * ) ;
   void (*release_cb)(struct sock * ) ;
   void (*hash)(struct sock * ) ;
   void (*unhash)(struct sock * ) ;
   void (*rehash)(struct sock * ) ;
   int (*get_port)(struct sock * , unsigned short  ) ;
   void (*clear_sk)(struct sock * , int  ) ;
   unsigned int inuse_idx ;
    klee_make_symbolic(&inuse_idx, sizeof(int), "inuse_idx");
   bool (*stream_memory_free)(struct sock  const  * ) ;
   void (*enter_memory_pressure)(struct sock * ) ;
   atomic_long_t *memory_allocated ;
   struct percpu_counter *sockets_allocated ;
   int *memory_pressure ;
   long *sysctl_mem ;
   int *sysctl_wmem ;
   int *sysctl_rmem ;
   int max_header ;
    klee_make_symbolic(&max_header, sizeof(int), "max_header");
   bool no_autobind ;
   struct kmem_cache *slab ;
   unsigned int obj_size ;
    klee_make_symbolic(&obj_size, sizeof(int), "obj_size");
   int slab_flags ;
    klee_make_symbolic(&slab_flags, sizeof(int), "slab_flags");
   struct percpu_counter *orphan_count ;
   struct request_sock_ops *rsk_prot ;
   struct timewait_sock_ops *twsk_prot ;
   union __anonunion_h_357 h ;
   struct module *owner ;
   char name[32U] ;
   struct list_head node ;
   int (*init_cgroup)(struct mem_cgroup * , struct cgroup_subsys * ) ;
   void (*destroy_cgroup)(struct mem_cgroup * ) ;
   struct cg_proto *(*proto_cgroup)(struct mem_cgroup * ) ;
};
struct cg_proto {
   struct page_counter memory_allocated ;
   struct percpu_counter sockets_allocated ;
   int memory_pressure ;
    klee_make_symbolic(&memory_pressure, sizeof(int), "memory_pressure");
   long sysctl_mem[3U] ;
   unsigned long flags ;
   struct mem_cgroup *memcg ;
};
struct request_sock_ops {
   int family ;
   int obj_size ;
   struct kmem_cache *slab ;
   char *slab_name ;
   int (*rtx_syn_ack)(struct sock * , struct request_sock * ) ;
   void (*send_ack)(struct sock * , struct sk_buff * , struct request_sock * ) ;
   void (*send_reset)(struct sock * , struct sk_buff * ) ;
   void (*destructor)(struct request_sock * ) ;
   void (*syn_ack_timeout)(struct request_sock  const  * ) ;
};
struct request_sock {
   struct sock_common __req_common ;
   struct request_sock *dl_next ;
   struct sock *rsk_listener ;
   u16 mss ;
   u8 num_retrans ;
   unsigned char cookie_ts : 1 ;
   unsigned char num_timeout : 7 ;
   u32 window_clamp ;
   u32 rcv_wnd ;
   u32 ts_recent ;
   struct timer_list rsk_timer ;
   struct request_sock_ops  const  *rsk_ops ;
   struct sock *sk ;
   u32 *saved_syn ;
   u32 secid ;
   u32 peer_secid ;
};
struct timewait_sock_ops {
   struct kmem_cache *twsk_slab ;
   char *twsk_slab_name ;
   unsigned int twsk_obj_size ;
    klee_make_symbolic(&twsk_obj_size, sizeof(int), "twsk_obj_size");
   int (*twsk_unique)(struct sock * , struct sock * , void * ) ;
   void (*twsk_destructor)(struct sock * ) ;
};
struct tcphdr {
   __be16 source ;
   __be16 dest ;
   __be32 seq ;
   __be32 ack_seq ;
   unsigned char res1 : 4 ;
   unsigned char doff : 4 ;
   unsigned char fin : 1 ;
   unsigned char syn : 1 ;
   unsigned char rst : 1 ;
   unsigned char psh : 1 ;
   unsigned char ack : 1 ;
   unsigned char urg : 1 ;
   unsigned char ece : 1 ;
   unsigned char cwr : 1 ;
   __be16 window ;
   __sum16 check ;
   __be16 urg_ptr ;
};
struct firmware {
   size_t size ;
   u8 const   *data ;
   struct page **pages ;
   void *priv ;
};
struct ip6_sf_list {
   struct ip6_sf_list *sf_next ;
   struct in6_addr sf_addr ;
   unsigned long sf_count[2U] ;
   unsigned char sf_gsresp ;
    klee_make_symbolic(&sf_gsresp, sizeof(char), "sf_gsresp");
   unsigned char sf_oldin ;
    klee_make_symbolic(&sf_oldin, sizeof(char), "sf_oldin");
   unsigned char sf_crcount ;
    klee_make_symbolic(&sf_crcount, sizeof(char), "sf_crcount");
};
struct ifmcaddr6 {
   struct in6_addr mca_addr ;
   struct inet6_dev *idev ;
   struct ifmcaddr6 *next ;
   struct ip6_sf_list *mca_sources ;
   struct ip6_sf_list *mca_tomb ;
   unsigned int mca_sfmode ;
    klee_make_symbolic(&mca_sfmode, sizeof(int), "mca_sfmode");
   unsigned char mca_crcount ;
    klee_make_symbolic(&mca_crcount, sizeof(char), "mca_crcount");
   unsigned long mca_sfcount[2U] ;
   struct timer_list mca_timer ;
   unsigned int mca_flags ;
    klee_make_symbolic(&mca_flags, sizeof(int), "mca_flags");
   int mca_users ;
    klee_make_symbolic(&mca_users, sizeof(int), "mca_users");
   atomic_t mca_refcnt ;
   spinlock_t mca_lock ;
   unsigned long mca_cstamp ;
    klee_make_symbolic(&mca_cstamp, sizeof(long), "mca_cstamp");
   unsigned long mca_tstamp ;
    klee_make_symbolic(&mca_tstamp, sizeof(long), "mca_tstamp");
};
struct ifacaddr6 {
   struct in6_addr aca_addr ;
   struct inet6_dev *aca_idev ;
   struct rt6_info *aca_rt ;
   struct ifacaddr6 *aca_next ;
   int aca_users ;
    klee_make_symbolic(&aca_users, sizeof(int), "aca_users");
   atomic_t aca_refcnt ;
   unsigned long aca_cstamp ;
    klee_make_symbolic(&aca_cstamp, sizeof(long), "aca_cstamp");
   unsigned long aca_tstamp ;
    klee_make_symbolic(&aca_tstamp, sizeof(long), "aca_tstamp");
};
struct ipv6_devstat {
   struct proc_dir_entry *proc_dir_entry ;
   struct ipstats_mib *ipv6 ;
   struct icmpv6_mib_device *icmpv6dev ;
   struct icmpv6msg_mib_device *icmpv6msgdev ;
};
struct inet6_dev {
   struct net_device *dev ;
   struct list_head addr_list ;
   struct ifmcaddr6 *mc_list ;
   struct ifmcaddr6 *mc_tomb ;
   spinlock_t mc_lock ;
   unsigned char mc_qrv ;
    klee_make_symbolic(&mc_qrv, sizeof(char), "mc_qrv");
   unsigned char mc_gq_running ;
    klee_make_symbolic(&mc_gq_running, sizeof(char), "mc_gq_running");
   unsigned char mc_ifc_count ;
    klee_make_symbolic(&mc_ifc_count, sizeof(char), "mc_ifc_count");
   unsigned char mc_dad_count ;
    klee_make_symbolic(&mc_dad_count, sizeof(char), "mc_dad_count");
   unsigned long mc_v1_seen ;
    klee_make_symbolic(&mc_v1_seen, sizeof(long), "mc_v1_seen");
   unsigned long mc_qi ;
    klee_make_symbolic(&mc_qi, sizeof(long), "mc_qi");
   unsigned long mc_qri ;
    klee_make_symbolic(&mc_qri, sizeof(long), "mc_qri");
   unsigned long mc_maxdelay ;
    klee_make_symbolic(&mc_maxdelay, sizeof(long), "mc_maxdelay");
   struct timer_list mc_gq_timer ;
   struct timer_list mc_ifc_timer ;
   struct timer_list mc_dad_timer ;
   struct ifacaddr6 *ac_list ;
   rwlock_t lock ;
   atomic_t refcnt ;
   __u32 if_flags ;
   int dead ;
   u8 rndid[8U] ;
   struct timer_list regen_timer ;
   struct list_head tempaddr_list ;
   struct in6_addr token ;
   struct neigh_parms *nd_parms ;
   struct ipv6_devconf cnf ;
   struct ipv6_devstat stats ;
   struct timer_list rs_timer ;
   __u8 rs_probes ;
   __u8 addr_gen_mode ;
   unsigned long tstamp ;
    klee_make_symbolic(&tstamp, sizeof(long), "tstamp");
   struct callback_head rcu ;
};
union __anonunion____missing_field_name_376 {
   __be32 a4 ;
   __be32 a6[4U] ;
   struct in6_addr in6 ;
};
struct inetpeer_addr_base {
   union __anonunion____missing_field_name_376 __annonCompField109 ;
};
struct inetpeer_addr {
   struct inetpeer_addr_base addr ;
   __u16 family ;
};
union __anonunion____missing_field_name_377 {
   struct list_head gc_list ;
   struct callback_head gc_rcu ;
};
struct __anonstruct____missing_field_name_379 {
   atomic_t rid ;
};
union __anonunion____missing_field_name_378 {
   struct __anonstruct____missing_field_name_379 __annonCompField111 ;
   struct callback_head rcu ;
   struct inet_peer *gc_next ;
};
struct inet_peer {
   struct inet_peer *avl_left ;
   struct inet_peer *avl_right ;
   struct inetpeer_addr daddr ;
   __u32 avl_height ;
   u32 metrics[16U] ;
   u32 rate_tokens ;
   unsigned long rate_last ;
    klee_make_symbolic(&rate_last, sizeof(long), "rate_last");
   union __anonunion____missing_field_name_377 __annonCompField110 ;
   union __anonunion____missing_field_name_378 __annonCompField112 ;
   __u32 dtime ;
   atomic_t refcnt ;
};
struct inet_peer_base {
   struct inet_peer *root ;
   seqlock_t lock ;
   int total ;
    klee_make_symbolic(&total, sizeof(int), "total");
};
struct uncached_list;
struct rtable {
   struct dst_entry dst ;
   int rt_genid ;
    klee_make_symbolic(&rt_genid, sizeof(int), "rt_genid");
   unsigned int rt_flags ;
    klee_make_symbolic(&rt_flags, sizeof(int), "rt_flags");
   __u16 rt_type ;
   __u8 rt_is_input ;
   __u8 rt_uses_gateway ;
   int rt_iif ;
    klee_make_symbolic(&rt_iif, sizeof(int), "rt_iif");
   __be32 rt_gateway ;
   u32 rt_pmtu ;
   struct list_head rt_uncached ;
   struct uncached_list *rt_uncached_list ;
};
struct inet_ehash_bucket {
   struct hlist_nulls_head chain ;
};
struct inet_bind_hashbucket {
   spinlock_t lock ;
   struct hlist_head chain ;
};
struct inet_listen_hashbucket {
   spinlock_t lock ;
   struct hlist_nulls_head head ;
};
struct inet_hashinfo {
   struct inet_ehash_bucket *ehash ;
   spinlock_t *ehash_locks ;
   unsigned int ehash_mask ;
    klee_make_symbolic(&ehash_mask, sizeof(int), "ehash_mask");
   unsigned int ehash_locks_mask ;
    klee_make_symbolic(&ehash_locks_mask, sizeof(int), "ehash_locks_mask");
   struct inet_bind_hashbucket *bhash ;
   unsigned int bhash_size ;
    klee_make_symbolic(&bhash_size, sizeof(int), "bhash_size");
   struct kmem_cache *bind_bucket_cachep ;
   struct inet_listen_hashbucket listening_hash[32U] ;
};
struct hotplug_slot;
struct pci_slot {
   struct pci_bus *bus ;
   struct list_head list ;
   struct hotplug_slot *hotplug ;
   unsigned char number ;
    klee_make_symbolic(&number, sizeof(char), "number");
   struct kobject kobj ;
};
typedef int pci_power_t;
    klee_make_symbolic(&pci_power_t, sizeof(int), "pci_power_t");
typedef unsigned int pci_channel_state_t;
    klee_make_symbolic(&pci_channel_state_t, sizeof(int), "pci_channel_state_t");
enum pci_channel_state {
    pci_channel_io_normal = 1,
    pci_channel_io_frozen = 2,
    pci_channel_io_perm_failure = 3
} ;
typedef unsigned short pci_dev_flags_t;
    klee_make_symbolic(&pci_dev_flags_t, sizeof(short), "pci_dev_flags_t");
typedef unsigned short pci_bus_flags_t;
    klee_make_symbolic(&pci_bus_flags_t, sizeof(short), "pci_bus_flags_t");
struct pcie_link_state;
struct pci_vpd;
struct pci_sriov;
struct pci_ats;
struct pci_driver;
union __anonunion____missing_field_name_386 {
   struct pci_sriov *sriov ;
   struct pci_dev *physfn ;
};
struct pci_dev {
   struct list_head bus_list ;
   struct pci_bus *bus ;
   struct pci_bus *subordinate ;
   void *sysdata ;
   struct proc_dir_entry *procent ;
   struct pci_slot *slot ;
   unsigned int devfn ;
    klee_make_symbolic(&devfn, sizeof(int), "devfn");
   unsigned short vendor ;
    klee_make_symbolic(&vendor, sizeof(short), "vendor");
   unsigned short device ;
    klee_make_symbolic(&device, sizeof(short), "device");
   unsigned short subsystem_vendor ;
    klee_make_symbolic(&subsystem_vendor, sizeof(short), "subsystem_vendor");
   unsigned short subsystem_device ;
    klee_make_symbolic(&subsystem_device, sizeof(short), "subsystem_device");
   unsigned int class ;
    klee_make_symbolic(&class, sizeof(int), "class");
   u8 revision ;
   u8 hdr_type ;
   u8 pcie_cap ;
   u8 msi_cap ;
   u8 msix_cap ;
   unsigned char pcie_mpss : 3 ;
   u8 rom_base_reg ;
   u8 pin ;
   u16 pcie_flags_reg ;
   u8 dma_alias_devfn ;
   struct pci_driver *driver ;
   u64 dma_mask ;
   struct device_dma_parameters dma_parms ;
   pci_power_t current_state ;
   u8 pm_cap ;
   unsigned char pme_support : 5 ;
   unsigned char pme_interrupt : 1 ;
   unsigned char pme_poll : 1 ;
   unsigned char d1_support : 1 ;
   unsigned char d2_support : 1 ;
   unsigned char no_d1d2 : 1 ;
   unsigned char no_d3cold : 1 ;
   unsigned char d3cold_allowed : 1 ;
   unsigned char mmio_always_on : 1 ;
   unsigned char wakeup_prepared : 1 ;
   unsigned char runtime_d3cold : 1 ;
   unsigned char ignore_hotplug : 1 ;
   unsigned int d3_delay ;
    klee_make_symbolic(&d3_delay, sizeof(int), "d3_delay");
   unsigned int d3cold_delay ;
    klee_make_symbolic(&d3cold_delay, sizeof(int), "d3cold_delay");
   struct pcie_link_state *link_state ;
   pci_channel_state_t error_state ;
   struct device dev ;
   int cfg_size ;
    klee_make_symbolic(&cfg_size, sizeof(int), "cfg_size");
   unsigned int irq ;
   struct resource resource[17U] ;
   bool match_driver ;
   unsigned char transparent : 1 ;
   unsigned char multifunction : 1 ;
   unsigned char is_added : 1 ;
   unsigned char is_busmaster : 1 ;
   unsigned char no_msi : 1 ;
   unsigned char no_64bit_msi : 1 ;
   unsigned char block_cfg_access : 1 ;
   unsigned char broken_parity_status : 1 ;
   unsigned char irq_reroute_variant : 2 ;
   unsigned char msi_enabled : 1 ;
   unsigned char msix_enabled : 1 ;
   unsigned char ari_enabled : 1 ;
   unsigned char is_managed : 1 ;
   unsigned char needs_freset : 1 ;
   unsigned char state_saved : 1 ;
   unsigned char is_physfn : 1 ;
   unsigned char is_virtfn : 1 ;
   unsigned char reset_fn : 1 ;
   unsigned char is_hotplug_bridge : 1 ;
   unsigned char __aer_firmware_first_valid : 1 ;
   unsigned char __aer_firmware_first : 1 ;
   unsigned char broken_intx_masking : 1 ;
   unsigned char io_window_1k : 1 ;
   unsigned char irq_managed : 1 ;
   unsigned char has_secondary_link : 1 ;
   pci_dev_flags_t dev_flags ;
   atomic_t enable_cnt ;
   u32 saved_config_space[16U] ;
   struct hlist_head saved_cap_space ;
   struct bin_attribute *rom_attr ;
   int rom_attr_enabled ;
    klee_make_symbolic(&rom_attr_enabled, sizeof(int), "rom_attr_enabled");
   struct bin_attribute *res_attr[17U] ;
   struct bin_attribute *res_attr_wc[17U] ;
   struct list_head msi_list ;
   struct attribute_group  const  **msi_irq_groups ;
   struct pci_vpd *vpd ;
   union __anonunion____missing_field_name_386 __annonCompField116 ;
   struct pci_ats *ats ;
   phys_addr_t rom ;
   size_t romlen ;
   char *driver_override ;
};
struct pci_ops;
struct msi_controller;
struct pci_bus {
   struct list_head node ;
   struct pci_bus *parent ;
   struct list_head children ;
   struct list_head devices ;
   struct pci_dev *self ;
   struct list_head slots ;
   struct resource *resource[4U] ;
   struct list_head resources ;
   struct resource busn_res ;
   struct pci_ops *ops ;
   struct msi_controller *msi ;
   void *sysdata ;
   struct proc_dir_entry *procdir ;
   unsigned char number ;
   unsigned char primary ;
    klee_make_symbolic(&primary, sizeof(char), "primary");
   unsigned char max_bus_speed ;
    klee_make_symbolic(&max_bus_speed, sizeof(char), "max_bus_speed");
   unsigned char cur_bus_speed ;
    klee_make_symbolic(&cur_bus_speed, sizeof(char), "cur_bus_speed");
   char name[48U] ;
   unsigned short bridge_ctl ;
    klee_make_symbolic(&bridge_ctl, sizeof(short), "bridge_ctl");
   pci_bus_flags_t bus_flags ;
   struct device *bridge ;
   struct device dev ;
   struct bin_attribute *legacy_io ;
   struct bin_attribute *legacy_mem ;
   unsigned char is_added : 1 ;
};
struct pci_ops {
   void *(*map_bus)(struct pci_bus * , unsigned int  , int  ) ;
   int (*read)(struct pci_bus * , unsigned int  , int  , int  , u32 * ) ;
   int (*write)(struct pci_bus * , unsigned int  , int  , int  , u32  ) ;
};
struct pci_dynids {
   spinlock_t lock ;
   struct list_head list ;
};
typedef unsigned int pci_ers_result_t;
    klee_make_symbolic(&pci_ers_result_t, sizeof(int), "pci_ers_result_t");
struct pci_error_handlers {
   pci_ers_result_t (*error_detected)(struct pci_dev * , enum pci_channel_state  ) ;
   pci_ers_result_t (*mmio_enabled)(struct pci_dev * ) ;
   pci_ers_result_t (*link_reset)(struct pci_dev * ) ;
   pci_ers_result_t (*slot_reset)(struct pci_dev * ) ;
   void (*reset_notify)(struct pci_dev * , bool  ) ;
   void (*resume)(struct pci_dev * ) ;
};
struct pci_driver {
   struct list_head node ;
   char const   *name ;
   struct pci_device_id  const  *id_table ;
   int (*probe)(struct pci_dev * , struct pci_device_id  const  * ) ;
   void (*remove)(struct pci_dev * ) ;
   int (*suspend)(struct pci_dev * , pm_message_t  ) ;
   int (*suspend_late)(struct pci_dev * , pm_message_t  ) ;
   int (*resume_early)(struct pci_dev * ) ;
   int (*resume)(struct pci_dev * ) ;
   void (*shutdown)(struct pci_dev * ) ;
   int (*sriov_configure)(struct pci_dev * , int  ) ;
   struct pci_error_handlers  const  *err_handler ;
   struct device_driver driver ;
   struct pci_dynids dynids ;
};
struct msix_entry {
   u32 vector ;
   u16 entry ;
};
enum bfa_status {
    BFA_STATUS_OK = 0,
    BFA_STATUS_FAILED = 1,
    BFA_STATUS_EINVAL = 2,
    BFA_STATUS_ENOMEM = 3,
    BFA_STATUS_ENOSYS = 4,
    BFA_STATUS_ETIMER = 5,
    BFA_STATUS_EPROTOCOL = 6,
    BFA_STATUS_ENOFCPORTS = 7,
    BFA_STATUS_NOFLASH = 8,
    BFA_STATUS_BADFLASH = 9,
    BFA_STATUS_SFP_UNSUPP = 10,
    BFA_STATUS_UNKNOWN_VFID = 11,
    BFA_STATUS_DATACORRUPTED = 12,
    BFA_STATUS_DEVBUSY = 13,
    BFA_STATUS_ABORTED = 14,
    BFA_STATUS_NODEV = 15,
    BFA_STATUS_HDMA_FAILED = 16,
    BFA_STATUS_FLASH_BAD_LEN = 17,
    BFA_STATUS_UNKNOWN_LWWN = 18,
    BFA_STATUS_UNKNOWN_RWWN = 19,
    BFA_STATUS_FCPT_LS_RJT = 20,
    BFA_STATUS_VPORT_EXISTS = 21,
    BFA_STATUS_VPORT_MAX = 22,
    BFA_STATUS_UNSUPP_SPEED = 23,
    BFA_STATUS_INVLD_DFSZ = 24,
    BFA_STATUS_CNFG_FAILED = 25,
    BFA_STATUS_CMD_NOTSUPP = 26,
    BFA_STATUS_NO_ADAPTER = 27,
    BFA_STATUS_LINKDOWN = 28,
    BFA_STATUS_FABRIC_RJT = 29,
    BFA_STATUS_UNKNOWN_VWWN = 30,
    BFA_STATUS_NSLOGIN_FAILED = 31,
    BFA_STATUS_NO_RPORTS = 32,
    BFA_STATUS_NSQUERY_FAILED = 33,
    BFA_STATUS_PORT_OFFLINE = 34,
    BFA_STATUS_RPORT_OFFLINE = 35,
    BFA_STATUS_TGTOPEN_FAILED = 36,
    BFA_STATUS_BAD_LUNS = 37,
    BFA_STATUS_IO_FAILURE = 38,
    BFA_STATUS_NO_FABRIC = 39,
    BFA_STATUS_EBADF = 40,
    BFA_STATUS_EINTR = 41,
    BFA_STATUS_EIO = 42,
    BFA_STATUS_ENOTTY = 43,
    BFA_STATUS_ENXIO = 44,
    BFA_STATUS_EFOPEN = 45,
    BFA_STATUS_VPORT_WWN_BP = 46,
    BFA_STATUS_PORT_NOT_DISABLED = 47,
    BFA_STATUS_BADFRMHDR = 48,
    BFA_STATUS_BADFRMSZ = 49,
    BFA_STATUS_MISSINGFRM = 50,
    BFA_STATUS_LINKTIMEOUT = 51,
    BFA_STATUS_NO_FCPIM_NEXUS = 52,
    BFA_STATUS_CHECKSUM_FAIL = 53,
    BFA_STATUS_GZME_FAILED = 54,
    BFA_STATUS_SCSISTART_REQD = 55,
    BFA_STATUS_IOC_FAILURE = 56,
    BFA_STATUS_INVALID_WWN = 57,
    BFA_STATUS_MISMATCH = 58,
    BFA_STATUS_IOC_ENABLED = 59,
    BFA_STATUS_ADAPTER_ENABLED = 60,
    BFA_STATUS_IOC_NON_OP = 61,
    BFA_STATUS_ADDR_MAP_FAILURE = 62,
    BFA_STATUS_SAME_NAME = 63,
    BFA_STATUS_PENDING = 64,
    BFA_STATUS_8G_SPD = 65,
    BFA_STATUS_4G_SPD = 66,
    BFA_STATUS_AD_IS_ENABLE = 67,
    BFA_STATUS_EINVAL_TOV = 68,
    BFA_STATUS_EINVAL_QDEPTH = 69,
    BFA_STATUS_VERSION_FAIL = 70,
    BFA_STATUS_DIAG_BUSY = 71,
    BFA_STATUS_BEACON_ON = 72,
    BFA_STATUS_BEACON_OFF = 73,
    BFA_STATUS_LBEACON_ON = 74,
    BFA_STATUS_LBEACON_OFF = 75,
    BFA_STATUS_PORT_NOT_INITED = 76,
    BFA_STATUS_RPSC_ENABLED = 77,
    BFA_STATUS_ENOFSAVE = 78,
    BFA_STATUS_BAD_FILE = 79,
    BFA_STATUS_RLIM_EN = 80,
    BFA_STATUS_RLIM_DIS = 81,
    BFA_STATUS_IOC_DISABLED = 82,
    BFA_STATUS_ADAPTER_DISABLED = 83,
    BFA_STATUS_BIOS_DISABLED = 84,
    BFA_STATUS_AUTH_ENABLED = 85,
    BFA_STATUS_AUTH_DISABLED = 86,
    BFA_STATUS_ERROR_TRL_ENABLED = 87,
    BFA_STATUS_ERROR_QOS_ENABLED = 88,
    BFA_STATUS_NO_SFP_DEV = 89,
    BFA_STATUS_MEMTEST_FAILED = 90,
    BFA_STATUS_INVALID_DEVID = 91,
    BFA_STATUS_QOS_ENABLED = 92,
    BFA_STATUS_QOS_DISABLED = 93,
    BFA_STATUS_INCORRECT_DRV_CONFIG = 94,
    BFA_STATUS_REG_FAIL = 95,
    BFA_STATUS_IM_INV_CODE = 96,
    BFA_STATUS_IM_INV_VLAN = 97,
    BFA_STATUS_IM_INV_ADAPT_NAME = 98,
    BFA_STATUS_IM_LOW_RESOURCES = 99,
    BFA_STATUS_IM_VLANID_IS_PVID = 100,
    BFA_STATUS_IM_VLANID_EXISTS = 101,
    BFA_STATUS_IM_FW_UPDATE_FAIL = 102,
    BFA_STATUS_PORTLOG_ENABLED = 103,
    BFA_STATUS_PORTLOG_DISABLED = 104,
    BFA_STATUS_FILE_NOT_FOUND = 105,
    BFA_STATUS_QOS_FC_ONLY = 106,
    BFA_STATUS_RLIM_FC_ONLY = 107,
    BFA_STATUS_CT_SPD = 108,
    BFA_STATUS_LEDTEST_OP = 109,
    BFA_STATUS_CEE_NOT_DN = 110,
    BFA_STATUS_10G_SPD = 111,
    BFA_STATUS_IM_INV_TEAM_NAME = 112,
    BFA_STATUS_IM_DUP_TEAM_NAME = 113,
    BFA_STATUS_IM_ADAPT_ALREADY_IN_TEAM = 114,
    BFA_STATUS_IM_ADAPT_HAS_VLANS = 115,
    BFA_STATUS_IM_PVID_MISMATCH = 116,
    BFA_STATUS_IM_LINK_SPEED_MISMATCH = 117,
    BFA_STATUS_IM_MTU_MISMATCH = 118,
    BFA_STATUS_IM_RSS_MISMATCH = 119,
    BFA_STATUS_IM_HDS_MISMATCH = 120,
    BFA_STATUS_IM_OFFLOAD_MISMATCH = 121,
    BFA_STATUS_IM_PORT_PARAMS = 122,
    BFA_STATUS_IM_PORT_NOT_IN_TEAM = 123,
    BFA_STATUS_IM_CANNOT_REM_PRI = 124,
    BFA_STATUS_IM_MAX_PORTS_REACHED = 125,
    BFA_STATUS_IM_LAST_PORT_DELETE = 126,
    BFA_STATUS_IM_NO_DRIVER = 127,
    BFA_STATUS_IM_MAX_VLANS_REACHED = 128,
    BFA_STATUS_TOMCAT_SPD_NOT_ALLOWED = 129,
    BFA_STATUS_NO_MINPORT_DRIVER = 130,
    BFA_STATUS_CARD_TYPE_MISMATCH = 131,
    BFA_STATUS_BAD_ASICBLK = 132,
    BFA_STATUS_NO_DRIVER = 133,
    BFA_STATUS_INVALID_MAC = 134,
    BFA_STATUS_IM_NO_VLAN = 135,
    BFA_STATUS_IM_ETH_LB_FAILED = 136,
    BFA_STATUS_IM_PVID_REMOVE = 137,
    BFA_STATUS_IM_PVID_EDIT = 138,
    BFA_STATUS_CNA_NO_BOOT = 139,
    BFA_STATUS_IM_PVID_NON_ZERO = 140,
    BFA_STATUS_IM_INETCFG_LOCK_FAILED = 141,
    BFA_STATUS_IM_GET_INETCFG_FAILED = 142,
    BFA_STATUS_IM_NOT_BOUND = 143,
    BFA_STATUS_INSUFFICIENT_PERMS = 144,
    BFA_STATUS_IM_INV_VLAN_NAME = 145,
    BFA_STATUS_CMD_NOTSUPP_CNA = 146,
    BFA_STATUS_IM_PASSTHRU_EDIT = 147,
    BFA_STATUS_IM_BIND_FAILED = 148,
    BFA_STATUS_IM_UNBIND_FAILED = 149,
    BFA_STATUS_IM_PORT_IN_TEAM = 150,
    BFA_STATUS_IM_VLAN_NOT_FOUND = 151,
    BFA_STATUS_IM_TEAM_NOT_FOUND = 152,
    BFA_STATUS_IM_TEAM_CFG_NOT_ALLOWED = 153,
    BFA_STATUS_PBC = 154,
    BFA_STATUS_DEVID_MISSING = 155,
    BFA_STATUS_BAD_FWCFG = 156,
    BFA_STATUS_CREATE_FILE = 157,
    BFA_STATUS_INVALID_VENDOR = 158,
    BFA_STATUS_SFP_NOT_READY = 159,
    BFA_STATUS_FLASH_UNINIT = 160,
    BFA_STATUS_FLASH_EMPTY = 161,
    BFA_STATUS_FLASH_CKFAIL = 162,
    BFA_STATUS_TRUNK_UNSUPP = 163,
    BFA_STATUS_TRUNK_ENABLED = 164,
    BFA_STATUS_TRUNK_DISABLED = 165,
    BFA_STATUS_TRUNK_ERROR_TRL_ENABLED = 166,
    BFA_STATUS_BOOT_CODE_UPDATED = 167,
    BFA_STATUS_BOOT_VERSION = 168,
    BFA_STATUS_CARDTYPE_MISSING = 169,
    BFA_STATUS_INVALID_CARDTYPE = 170,
    BFA_STATUS_NO_TOPOLOGY_FOR_CNA = 171,
    BFA_STATUS_IM_VLAN_OVER_TEAM_DELETE_FAILED = 172,
    BFA_STATUS_ETHBOOT_ENABLED = 173,
    BFA_STATUS_ETHBOOT_DISABLED = 174,
    BFA_STATUS_IOPROFILE_OFF = 175,
    BFA_STATUS_NO_PORT_INSTANCE = 176,
    BFA_STATUS_BOOT_CODE_TIMEDOUT = 177,
    BFA_STATUS_NO_VPORT_LOCK = 178,
    BFA_STATUS_VPORT_NO_CNFG = 179,
    BFA_STATUS_MAX_VAL = 180
} ;
struct bfa_mfg_vpd {
   u8 version ;
   u8 vpd_sig[3U] ;
   u8 chksum ;
   u8 vendor ;
   u8 len ;
   u8 rsv ;
   u8 data[512U] ;
};
struct bfa_ioc_drv_stats {
   u32 ioc_isrs ;
   u32 ioc_enables ;
   u32 ioc_disables ;
   u32 ioc_hbfails ;
   u32 ioc_boots ;
   u32 stats_tmos ;
   u32 hb_count ;
   u32 disable_reqs ;
   u32 enable_reqs ;
   u32 disable_replies ;
   u32 enable_replies ;
   u32 rsvd ;
};
enum bfa_mode {
    BFA_MODE_HBA = 1,
    BFA_MODE_CNA = 2,
    BFA_MODE_NIC = 3
} ;
struct bfa_wc {
   void (*wc_resume)(void * ) ;
   void *wc_cbarg ;
   int wc_count ;
    klee_make_symbolic(&wc_count, sizeof(int), "wc_count");
};
struct __anonstruct_h2i_388 {
   u8 qid ;
   u8 fn_lpu ;
};
union __anonunion_mtag_387 {
   struct __anonstruct_h2i_388 h2i ;
   u16 i2htok ;
};
struct bfi_mhdr {
   u8 msg_class ;
   u8 msg_id ;
   union __anonunion_mtag_387 mtag ;
};
struct __anonstruct_a32_389 {
   u32 addr_lo ;
   u32 addr_hi ;
};
union bfi_addr_u {
   struct __anonstruct_a32_389 a32 ;
};
struct bfi_mbmsg {
   struct bfi_mhdr mh ;
   u32 pl[7U] ;
};
enum bfi_pcifn_class {
    BFI_PCIFN_CLASS_FC = 3076,
    BFI_PCIFN_CLASS_ETH = 512
} ;
enum bfi_asic_gen {
    BFI_ASIC_GEN_CB = 1,
    BFI_ASIC_GEN_CT = 2,
    BFI_ASIC_GEN_CT2 = 3
} ;
enum bfi_asic_mode {
    BFI_ASIC_MODE_FC = 1,
    BFI_ASIC_MODE_FC16 = 2,
    BFI_ASIC_MODE_ETH = 3,
    BFI_ASIC_MODE_COMBO = 4
} ;
struct bfi_ioc_attr {
   u64 mfg_pwwn ;
   u64 mfg_nwwn ;
   u8 mfg_mac[6U] ;
   u8 port_mode ;
   u8 rsvd_a ;
   u64 pwwn ;
   u64 nwwn ;
   u8 mac[6U] ;
   u16 rsvd_b ;
   u8 fcoe_mac[6U] ;
   u16 rsvd_c ;
   char brcd_serialnum[12U] ;
   u8 pcie_gen ;
   u8 pcie_lanes_orig ;
   u8 pcie_lanes ;
   u8 rx_bbcredit ;
   u32 adapter_prop ;
   u16 maxfrsize ;
   char asic_rev ;
    klee_make_symbolic(&asic_rev, sizeof(char), "asic_rev");
   u8 rsvd_d ;
   char fw_version[64U] ;
   char optrom_version[64U] ;
   struct bfa_mfg_vpd vpd ;
   u32 card_type ;
};
enum bfi_port_mode {
    BFI_PORT_MODE_FC = 1,
    BFI_PORT_MODE_ETH = 2
} ;
enum bfi_ioc_state {
    BFI_IOC_UNINIT = 0,
    BFI_IOC_INITING = 1,
    BFI_IOC_HWINIT = 2,
    BFI_IOC_CFG = 3,
    BFI_IOC_OP = 4,
    BFI_IOC_DISABLING = 5,
    BFI_IOC_DISABLED = 6,
    BFI_IOC_CFG_DISABLED = 7,
    BFI_IOC_FAIL = 8,
    BFI_IOC_MEMTEST = 9
} ;
struct bfi_msgq_mhdr {
   u8 msg_class ;
   u8 msg_id ;
   u16 msg_token ;
   u16 num_entries ;
   u8 enet_id ;
   u8 rsvd[1U] ;
};
struct bfa_pcidev {
   int pci_slot ;
    klee_make_symbolic(&pci_slot, sizeof(int), "pci_slot");
   u8 pci_func ;
   u16 device_id ;
   u16 ssid ;
   void *pci_bar_kva ;
};
struct bfa_dma {
   void *kva ;
   u64 pa ;
};
struct bfa_ioc_regs {
   void *hfn_mbox_cmd ;
   void *hfn_mbox ;
   void *lpu_mbox_cmd ;
   void *lpu_mbox ;
   void *lpu_read_stat ;
   void *pss_ctl_reg ;
   void *pss_err_status_reg ;
   void *app_pll_fast_ctl_reg ;
   void *app_pll_slow_ctl_reg ;
   void *ioc_sem_reg ;
   void *ioc_usage_sem_reg ;
   void *ioc_init_sem_reg ;
   void *ioc_usage_reg ;
   void *host_page_num_fn ;
   void *heartbeat ;
   void *ioc_fwstate ;
   void *alt_ioc_fwstate ;
   void *ll_halt ;
   void *alt_ll_halt ;
   void *err_set ;
   void *ioc_fail_sync ;
   void *shirq_isr_next ;
   void *shirq_msk_next ;
   void *smem_page_start ;
   u32 smem_pg0 ;
};
struct bfa_mbox_cmd {
   struct list_head qe ;
   void (*cbfn)(void * ) ;
   void *cbarg ;
   u32 msg[8U] ;
};
struct __anonstruct_mbhdlr_392 {
   void (*cbfn)(void * , struct bfi_mbmsg * ) ;
   void *cbarg ;
};
struct bfa_ioc_mbox_mod {
   struct list_head cmd_q ;
   int nmclass ;
    klee_make_symbolic(&nmclass, sizeof(int), "nmclass");
   struct __anonstruct_mbhdlr_392 mbhdlr[34U] ;
};
struct bfa_ioc_cbfn {
   void (*enable_cbfn)(void * , enum bfa_status  ) ;
   void (*disable_cbfn)(void * ) ;
   void (*hbfail_cbfn)(void * ) ;
   void (*reset_cbfn)(void * ) ;
};
enum bfa_ioc_event {
    BFA_IOC_E_ENABLED = 1,
    BFA_IOC_E_DISABLED = 2,
    BFA_IOC_E_FAILED = 3
} ;
struct bfa_ioc_notify {
   struct list_head qe ;
   void (*cbfn)(void * , enum bfa_ioc_event  ) ;
   void *cbarg ;
};
struct bfa_iocpf {
   void (*fsm)(void * , int  ) ;
   struct bfa_ioc *ioc ;
   bool fw_mismatch_notified ;
   bool auto_recover ;
   u32 poll_time ;
};
struct bfa;
struct bfa_ioc_hwif;
struct bfa_ioc {
   void (*fsm)(void * , int  ) ;
   struct bfa *bfa ;
   struct bfa_pcidev pcidev ;
   struct timer_list ioc_timer ;
   struct timer_list iocpf_timer ;
   struct timer_list sem_timer ;
   struct timer_list hb_timer ;
   u32 hb_count ;
   struct list_head notify_q ;
   void *dbg_fwsave ;
   int dbg_fwsave_len ;
    klee_make_symbolic(&dbg_fwsave_len, sizeof(int), "dbg_fwsave_len");
   bool dbg_fwsave_once ;
   enum bfi_pcifn_class clscode ;
   struct bfa_ioc_regs ioc_regs ;
   struct bfa_ioc_drv_stats stats ;
   bool fcmode ;
   bool pllinit ;
   bool stats_busy ;
   u8 port_id ;
   struct bfa_dma attr_dma ;
   struct bfi_ioc_attr *attr ;
   struct bfa_ioc_cbfn *cbfn ;
   struct bfa_ioc_mbox_mod mbox_mod ;
   struct bfa_ioc_hwif  const  *ioc_hwif ;
   struct bfa_iocpf iocpf ;
   enum bfi_asic_gen asic_gen ;
   enum bfi_asic_mode asic_mode ;
   enum bfi_port_mode port0_mode ;
   enum bfi_port_mode port1_mode ;
   enum bfa_mode port_mode ;
   u8 ad_cap_bm ;
   u8 port_mode_cfg ;
};
struct bfa_ioc_hwif {
   enum bfa_status (*ioc_pll_init)(void * , enum bfi_asic_mode  ) ;
   bool (*ioc_firmware_lock)(struct bfa_ioc * ) ;
   void (*ioc_firmware_unlock)(struct bfa_ioc * ) ;
   void (*ioc_reg_init)(struct bfa_ioc * ) ;
   void (*ioc_map_port)(struct bfa_ioc * ) ;
   void (*ioc_isr_mode_set)(struct bfa_ioc * , bool  ) ;
   void (*ioc_notify_fail)(struct bfa_ioc * ) ;
   void (*ioc_ownership_reset)(struct bfa_ioc * ) ;
   bool (*ioc_sync_start)(struct bfa_ioc * ) ;
   void (*ioc_sync_join)(struct bfa_ioc * ) ;
   void (*ioc_sync_leave)(struct bfa_ioc * ) ;
   void (*ioc_sync_ack)(struct bfa_ioc * ) ;
   bool (*ioc_sync_complete)(struct bfa_ioc * ) ;
   bool (*ioc_lpu_read_stat)(struct bfa_ioc * ) ;
   void (*ioc_set_fwstate)(struct bfa_ioc * , enum bfi_ioc_state  ) ;
   enum bfi_ioc_state (*ioc_get_fwstate)(struct bfa_ioc * ) ;
   void (*ioc_set_alt_fwstate)(struct bfa_ioc * , enum bfi_ioc_state  ) ;
   enum bfi_ioc_state (*ioc_get_alt_fwstate)(struct bfa_ioc * ) ;
};
struct bfa_flash {
   struct bfa_ioc *ioc ;
   u32 type ;
   u8 instance ;
   u8 rsv[3U] ;
   u32 op_busy ;
   u32 residue ;
   u32 offset ;
   enum bfa_status status ;
   u8 *dbuf_kva ;
   u64 dbuf_pa ;
   void (*cbfn)(void * , enum bfa_status  ) ;
   void *cbarg ;
   u8 *ubuf ;
   u32 addr_off ;
   struct bfa_mbox_cmd mb ;
   struct bfa_ioc_notify ioc_notify ;
};
struct bfi_enet_q {
   union bfi_addr_u pg_tbl ;
   union bfi_addr_u first_entry ;
   u16 pages ;
   u16 page_sz ;
};
struct bfi_enet_txq {
   struct bfi_enet_q q ;
   u8 priority ;
   u8 rsvd[3U] ;
};
struct bfi_enet_rxq {
   struct bfi_enet_q q ;
   u16 rx_buffer_size ;
   u16 rsvd ;
};
struct bfi_enet_cq {
   struct bfi_enet_q q ;
};
struct bfi_enet_ib_cfg {
   u8 int_pkt_dma ;
   u8 int_enabled ;
   u8 int_pkt_enabled ;
   u8 continuous_coalescing ;
   u8 msix ;
   u8 rsvd[3U] ;
   u32 coalescing_timeout ;
   u32 inter_pkt_timeout ;
   u8 inter_pkt_count ;
   u8 rsvd1[3U] ;
};
union __anonunion_intr_395 {
   u16 msix_index ;
   u16 intx_bitmask ;
};
struct bfi_enet_ib {
   union bfi_addr_u index_addr ;
   union __anonunion_intr_395 intr ;
   u16 rsvd ;
};
struct bfi_enet_req {
   struct bfi_msgq_mhdr mh ;
};
struct bfi_enet_enable_req {
   struct bfi_msgq_mhdr mh ;
   u8 enable ;
   u8 rsvd[3U] ;
};
struct bfi_enet_attr_req {
   struct bfi_msgq_mhdr mh ;
};
struct bfi_enet_tx_cfg {
   u8 vlan_mode ;
   u8 rsvd ;
   u16 vlan_id ;
   u8 admit_tagged_frame ;
   u8 apply_vlan_filter ;
   u8 add_to_vswitch ;
   u8 rsvd1[1U] ;
};
struct __anonstruct_q_cfg_396 {
   struct bfi_enet_txq q ;
   struct bfi_enet_ib ib ;
};
struct bfi_enet_tx_cfg_req {
   struct bfi_msgq_mhdr mh ;
   u8 num_queues ;
   u8 rsvd[3U] ;
   struct __anonstruct_q_cfg_396 q_cfg[8U] ;
   struct bfi_enet_ib_cfg ib_cfg ;
   struct bfi_enet_tx_cfg tx_cfg ;
};
struct __anonstruct_q_handles_397 {
   u32 q_dbell ;
   u32 i_dbell ;
   u8 hw_qid ;
   u8 rsvd[3U] ;
};
struct bfi_enet_tx_cfg_rsp {
   struct bfi_msgq_mhdr mh ;
   u8 error ;
   u8 hw_id ;
   u8 rsvd[2U] ;
   struct __anonstruct_q_handles_397 q_handles[8U] ;
};
enum bfi_enet_hds_type {
    BFI_ENET_HDS_FORCED = 1,
    BFI_ENET_HDS_IPV6_UDP = 2,
    BFI_ENET_HDS_IPV6_TCP = 4,
    BFI_ENET_HDS_IPV4_TCP = 8,
    BFI_ENET_HDS_IPV4_UDP = 16
} ;
struct __anonstruct_hds_398 {
   u8 max_header_size ;
   u8 force_offset ;
   u8 type ;
   u8 rsvd1 ;
};
struct bfi_enet_rx_cfg {
   u8 rxq_type ;
   u8 rsvd[1U] ;
   u16 frame_size ;
   struct __anonstruct_hds_398 hds ;
   u8 multi_buffer ;
   u8 strip_vlan ;
   u8 drop_untagged ;
   u8 rsvd2 ;
};
struct __anonstruct_q_cfg_399 {
   struct bfi_enet_rxq ql ;
   struct bfi_enet_rxq qs ;
   struct bfi_enet_cq cq ;
   struct bfi_enet_ib ib ;
};
struct bfi_enet_rx_cfg_req {
   struct bfi_msgq_mhdr mh ;
   u8 num_queue_sets ;
   u8 rsvd[3U] ;
   struct __anonstruct_q_cfg_399 q_cfg[16U] ;
   struct bfi_enet_ib_cfg ib_cfg ;
   struct bfi_enet_rx_cfg rx_cfg ;
};
struct __anonstruct_q_handles_400 {
   u32 ql_dbell ;
   u32 qs_dbell ;
   u32 i_dbell ;
   u8 hw_lqid ;
   u8 hw_sqid ;
   u8 hw_cqid ;
   u8 rsvd ;
};
struct bfi_enet_rx_cfg_rsp {
   struct bfi_msgq_mhdr mh ;
   u8 error ;
   u8 hw_id ;
   u8 rsvd[2U] ;
   struct __anonstruct_q_handles_400 q_handles[16U] ;
};
struct bfi_enet_rit_req {
   struct bfi_msgq_mhdr mh ;
   u16 size ;
   u8 rsvd[2U] ;
   u8 table[64U] ;
};
enum bfi_enet_rss_type {
    BFI_ENET_RSS_IPV6 = 1,
    BFI_ENET_RSS_IPV6_TCP = 2,
    BFI_ENET_RSS_IPV4 = 4,
    BFI_ENET_RSS_IPV4_TCP = 8
} ;
struct bfi_enet_rss_cfg {
   u8 type ;
   u8 mask ;
   u8 rsvd[2U] ;
   u32 key[10U] ;
};
struct bfi_enet_rss_cfg_req {
   struct bfi_msgq_mhdr mh ;
   struct bfi_enet_rss_cfg cfg ;
};
struct bfi_enet_ucast_req {
   struct bfi_msgq_mhdr mh ;
   u8 mac_addr[6U] ;
   u8 rsvd[2U] ;
};
struct bfi_enet_mcast_add_req {
   struct bfi_msgq_mhdr mh ;
   u8 mac_addr[6U] ;
   u8 rsvd[2U] ;
};
struct bfi_enet_mcast_del_req {
   struct bfi_msgq_mhdr mh ;
   u16 handle ;
   u8 rsvd[2U] ;
};
struct bfi_enet_rx_vlan_req {
   struct bfi_msgq_mhdr mh ;
   u8 block_idx ;
   u8 rsvd[3U] ;
   u32 bit_mask[16U] ;
};
struct bfi_enet_set_pause_req {
   struct bfi_msgq_mhdr mh ;
   u8 rsvd[2U] ;
   u8 tx_pause ;
   u8 rx_pause ;
};
struct bfi_enet_diag_lb_req {
   struct bfi_msgq_mhdr mh ;
   u8 rsvd[2U] ;
   u8 mode ;
   u8 enable ;
};
struct bfi_enet_stats_req {
   struct bfi_msgq_mhdr mh ;
   u16 stats_mask ;
   u8 rsvd[2U] ;
   u32 rx_enet_mask ;
   u32 tx_enet_mask ;
   union bfi_addr_u host_buffer ;
};
struct bfi_enet_stats_txf {
   u64 ucast_octets ;
   u64 ucast ;
   u64 ucast_vlan ;
   u64 mcast_octets ;
   u64 mcast ;
   u64 mcast_vlan ;
   u64 bcast_octets ;
   u64 bcast ;
   u64 bcast_vlan ;
   u64 errors ;
   u64 filter_vlan ;
   u64 filter_mac_sa ;
};
struct bfi_enet_stats_rxf {
   u64 ucast_octets ;
   u64 ucast ;
   u64 ucast_vlan ;
   u64 mcast_octets ;
   u64 mcast ;
   u64 mcast_vlan ;
   u64 bcast_octets ;
   u64 bcast ;
   u64 bcast_vlan ;
   u64 frame_drops ;
};
struct bfi_enet_stats_fc_tx {
   u64 txf_ucast_octets ;
   u64 txf_ucast ;
   u64 txf_ucast_vlan ;
   u64 txf_mcast_octets ;
   u64 txf_mcast ;
   u64 txf_mcast_vlan ;
   u64 txf_bcast_octets ;
   u64 txf_bcast ;
   u64 txf_bcast_vlan ;
   u64 txf_parity_errors ;
   u64 txf_timeout ;
   u64 txf_fid_parity_errors ;
};
struct bfi_enet_stats_fc_rx {
   u64 rxf_ucast_octets ;
   u64 rxf_ucast ;
   u64 rxf_ucast_vlan ;
   u64 rxf_mcast_octets ;
   u64 rxf_mcast ;
   u64 rxf_mcast_vlan ;
   u64 rxf_bcast_octets ;
   u64 rxf_bcast ;
   u64 rxf_bcast_vlan ;
};
struct bfi_enet_stats_rad {
   u64 rx_frames ;
   u64 rx_octets ;
   u64 rx_vlan_frames ;
   u64 rx_ucast ;
   u64 rx_ucast_octets ;
   u64 rx_ucast_vlan ;
   u64 rx_mcast ;
   u64 rx_mcast_octets ;
   u64 rx_mcast_vlan ;
   u64 rx_bcast ;
   u64 rx_bcast_octets ;
   u64 rx_bcast_vlan ;
   u64 rx_drops ;
};
struct bfi_enet_stats_bpc {
   u64 tx_pause[8U] ;
   u64 tx_zero_pause[8U] ;
   u64 tx_first_pause[8U] ;
   u64 rx_pause[8U] ;
   u64 rx_zero_pause[8U] ;
   u64 rx_first_pause[8U] ;
};
struct bfi_enet_stats_mac {
   u64 stats_clr_cnt ;
   u64 frame_64 ;
   u64 frame_65_127 ;
   u64 frame_128_255 ;
   u64 frame_256_511 ;
   u64 frame_512_1023 ;
   u64 frame_1024_1518 ;
   u64 frame_1519_1522 ;
   u64 rx_bytes ;
   u64 rx_packets ;
   u64 rx_fcs_error ;
   u64 rx_multicast ;
   u64 rx_broadcast ;
   u64 rx_control_frames ;
   u64 rx_pause ;
   u64 rx_unknown_opcode ;
   u64 rx_alignment_error ;
   u64 rx_frame_length_error ;
   u64 rx_code_error ;
   u64 rx_carrier_sense_error ;
   u64 rx_undersize ;
   u64 rx_oversize ;
   u64 rx_fragments ;
   u64 rx_jabber ;
   u64 rx_drop ;
   u64 tx_bytes ;
   u64 tx_packets ;
   u64 tx_multicast ;
   u64 tx_broadcast ;
   u64 tx_pause ;
   u64 tx_deferral ;
   u64 tx_excessive_deferral ;
   u64 tx_single_collision ;
   u64 tx_muliple_collision ;
   u64 tx_late_collision ;
   u64 tx_excessive_collision ;
   u64 tx_total_collision ;
   u64 tx_pause_honored ;
   u64 tx_drop ;
   u64 tx_jabber ;
   u64 tx_fcs_error ;
   u64 tx_control_frame ;
   u64 tx_oversize ;
   u64 tx_undersize ;
   u64 tx_fragments ;
};
struct bfi_enet_stats {
   struct bfi_enet_stats_mac mac_stats ;
   struct bfi_enet_stats_bpc bpc_stats ;
   struct bfi_enet_stats_rad rad_stats ;
   struct bfi_enet_stats_rad rlb_stats ;
   struct bfi_enet_stats_fc_rx fc_rx_stats ;
   struct bfi_enet_stats_fc_tx fc_tx_stats ;
   struct bfi_enet_stats_rxf rxf_stats[32U] ;
   struct bfi_enet_stats_txf txf_stats[32U] ;
};
struct bna_bit_defn {
   u32 mbox_status_bits ;
   u32 mbox_mask_bits ;
   u32 error_status_bits ;
   u32 error_mask_bits ;
   u32 halt_status_bits ;
   u32 halt_mask_bits ;
};
struct bna_reg {
   void *fn_int_status ;
   void *fn_int_mask ;
};
struct bna_dma_addr {
   u32 msb ;
   u32 lsb ;
};
struct bna_txq_wi_vector {
   u16 reserved ;
   u16 length ;
   struct bna_dma_addr host_addr ;
};
struct __anonstruct_wi_402 {
   u8 reserved ;
   u8 num_vectors ;
   u16 opcode ;
   u16 flags ;
   u16 l4_hdr_size_n_offset ;
   u16 vlan_tag ;
   u16 lso_mss ;
   u32 frame_length ;
};
struct __anonstruct_wi_ext_403 {
   u16 reserved ;
   u16 opcode ;
   u32 reserved2[3U] ;
};
union __anonunion_hdr_401 {
   struct __anonstruct_wi_402 wi ;
   struct __anonstruct_wi_ext_403 wi_ext ;
};
struct bna_txq_entry {
   union __anonunion_hdr_401 hdr ;
   struct bna_txq_wi_vector vector[4U] ;
};
struct bna_rxq_entry {
   struct bna_dma_addr host_addr ;
};
struct bna_cq_entry {
   u32 flags ;
   u16 vlan_tag ;
   u16 length ;
   u32 rss_hash ;
   u8 valid ;
   u8 reserved1 ;
   u8 reserved2 ;
   u8 rxq_id ;
};
struct bfa_cee_lldp_str {
   u8 sub_type ;
   u8 len ;
   u8 rsvd[2U] ;
   u8 value[128U] ;
};
struct bfa_cee_lldp_cfg {
   struct bfa_cee_lldp_str chassis_id ;
   struct bfa_cee_lldp_str port_id ;
   struct bfa_cee_lldp_str port_desc ;
   struct bfa_cee_lldp_str sys_name ;
   struct bfa_cee_lldp_str sys_desc ;
   struct bfa_cee_lldp_str mgmt_addr ;
   u16 time_to_live ;
   u16 enabled_system_cap ;
};
struct bfa_cee_dcbx_cfg {
   u8 pgid[8U] ;
   u8 pg_percentage[8U] ;
   u8 pfc_primap ;
   u8 fcoe_primap ;
   u8 iscsi_primap ;
   u8 dcbx_version ;
   u8 lls_fcoe ;
   u8 lls_lan ;
   u8 rsvd[2U] ;
};
struct bfa_cee_attr {
   u8 cee_status ;
   u8 error_reason ;
   struct bfa_cee_lldp_cfg lldp_remote ;
   struct bfa_cee_dcbx_cfg dcbx_remote ;
   u8 src_mac[6U] ;
   u8 link_speed ;
   u8 nw_priority ;
   u8 filler[2U] ;
};
struct bfa_cee_stats {
   u32 lldp_tx_frames ;
   u32 lldp_rx_frames ;
   u32 lldp_rx_frames_invalid ;
   u32 lldp_rx_frames_new ;
   u32 lldp_tlvs_unrecognized ;
   u32 lldp_rx_shutdown_tlvs ;
   u32 lldp_info_aged_out ;
   u32 dcbx_phylink_ups ;
   u32 dcbx_phylink_downs ;
   u32 dcbx_rx_tlvs ;
   u32 dcbx_rx_tlvs_invalid ;
   u32 dcbx_control_tlv_error ;
   u32 dcbx_feature_tlv_error ;
   u32 dcbx_cee_cfg_new ;
   u32 cee_status_down ;
   u32 cee_status_up ;
   u32 cee_hw_cfg_changed ;
   u32 cee_rx_invalid_cfg ;
};
struct bfa_cee_cbfn {
   void (*get_attr_cbfn)(void * , enum bfa_status  ) ;
   void *get_attr_cbarg ;
   void (*get_stats_cbfn)(void * , enum bfa_status  ) ;
   void *get_stats_cbarg ;
   void (*reset_stats_cbfn)(void * , enum bfa_status  ) ;
   void *reset_stats_cbarg ;
};
struct bfa_cee {
   void *dev ;
   bool get_attr_pending ;
   bool get_stats_pending ;
   bool reset_stats_pending ;
   enum bfa_status get_attr_status ;
   enum bfa_status get_stats_status ;
   enum bfa_status reset_stats_status ;
   struct bfa_cee_cbfn cbfn ;
   struct bfa_ioc_notify ioc_notify ;
   struct bfa_cee_attr *attr ;
   struct bfa_cee_stats *stats ;
   struct bfa_dma attr_dma ;
   struct bfa_dma stats_dma ;
   struct bfa_ioc *ioc ;
   struct bfa_mbox_cmd get_cfg_mb ;
   struct bfa_mbox_cmd get_stats_mb ;
   struct bfa_mbox_cmd reset_stats_mb ;
};
struct bfa_msgq;
struct bfa_msgq_cmd_entry {
   struct list_head qe ;
   void (*cbfn)(void * , enum bfa_status  ) ;
   void *cbarg ;
   size_t msg_size ;
   struct bfi_msgq_mhdr *msg_hdr ;
};
enum bfa_msgq_cmdq_flags {
    BFA_MSGQ_CMDQ_F_DB_UPDATE = 1
} ;
struct bfa_msgq_cmdq {
   void (*fsm)(void * , int  ) ;
   enum bfa_msgq_cmdq_flags flags ;
   u16 producer_index ;
   u16 consumer_index ;
   u16 depth ;
   struct bfa_dma addr ;
   struct bfa_mbox_cmd dbell_mb ;
   u16 token ;
   int offset ;
   int bytes_to_copy ;
    klee_make_symbolic(&bytes_to_copy, sizeof(int), "bytes_to_copy");
   struct bfa_mbox_cmd copy_mb ;
   struct list_head pending_q ;
   struct bfa_msgq *msgq ;
};
enum bfa_msgq_rspq_flags {
    BFA_MSGQ_RSPQ_F_DB_UPDATE = 1
} ;
struct __anonstruct_rsphdlr_404 {
   void (*cbfn)(void * , struct bfi_msgq_mhdr * ) ;
   void *cbarg ;
};
struct bfa_msgq_rspq {
   void (*fsm)(void * , int  ) ;
   enum bfa_msgq_rspq_flags flags ;
   u16 producer_index ;
   u16 consumer_index ;
   u16 depth ;
   struct bfa_dma addr ;
   struct bfa_mbox_cmd dbell_mb ;
   int nmclass ;
   struct __anonstruct_rsphdlr_404 rsphdlr[34U] ;
   struct bfa_msgq *msgq ;
};
struct bfa_msgq {
   struct bfa_msgq_cmdq cmdq ;
   struct bfa_msgq_rspq rspq ;
   struct bfa_wc init_wc ;
   struct bfa_mbox_cmd init_mb ;
   struct bfa_ioc_notify ioc_notify ;
   struct bfa_ioc *ioc ;
};
struct bna_mcam_handle;
struct bna_txq;
struct bna_tx;
struct bna_rxq;
struct bna_cq;
struct bna_rx;
struct bna_rxf;
struct bna_enet;
struct bna;
struct bnad;
enum bna_status {
    BNA_STATUS_T_DISABLED = 0,
    BNA_STATUS_T_ENABLED = 1
} ;
enum bna_cleanup_type {
    BNA_HARD_CLEANUP = 0,
    BNA_SOFT_CLEANUP = 1
} ;
enum bna_cb_status {
    BNA_CB_SUCCESS = 0,
    BNA_CB_FAIL = 1,
    BNA_CB_INTERRUPT = 2,
    BNA_CB_BUSY = 3,
    BNA_CB_INVALID_MAC = 4,
    BNA_CB_MCAST_LIST_FULL = 5,
    BNA_CB_UCAST_CAM_FULL = 6,
    BNA_CB_WAITING = 7,
    BNA_CB_NOT_EXEC = 8
} ;
enum bna_res_type {
    BNA_RES_T_MEM = 1,
    BNA_RES_T_INTR = 2
} ;
enum bna_mem_type {
    BNA_MEM_T_KVA = 1,
    BNA_MEM_T_DMA = 2
} ;
enum bna_intr_type {
    BNA_INTR_T_INTX = 1,
    BNA_INTR_T_MSIX = 2
} ;
enum bna_tx_type {
    BNA_TX_T_REGULAR = 0,
    BNA_TX_T_LOOPBACK = 1
} ;
enum bna_tx_flags {
    BNA_TX_F_ENET_STARTED = 1,
    BNA_TX_F_ENABLED = 2,
    BNA_TX_F_BW_UPDATED = 8
} ;
enum bna_tx_mod_flags {
    BNA_TX_MOD_F_ENET_STARTED = 1,
    BNA_TX_MOD_F_ENET_LOOPBACK = 2
} ;
enum bna_rx_type {
    BNA_RX_T_REGULAR = 0,
    BNA_RX_T_LOOPBACK = 1
} ;
enum bna_rxp_type {
    BNA_RXP_SINGLE = 1,
    BNA_RXP_SLR = 2,
    BNA_RXP_HDS = 3
} ;
enum bna_rxmode {
    BNA_RXMODE_PROMISC = 1,
    BNA_RXMODE_DEFAULT = 2,
    BNA_RXMODE_ALLMULTI = 4
} ;
enum bna_rx_flags {
    BNA_RX_F_ENET_STARTED = 1,
    BNA_RX_F_ENABLED = 2
} ;
enum bna_rx_mod_flags {
    BNA_RX_MOD_F_ENET_STARTED = 1,
    BNA_RX_MOD_F_ENET_LOOPBACK = 2
} ;
enum bna_enet_type {
    BNA_ENET_T_REGULAR = 0,
    BNA_ENET_T_LOOPBACK_INTERNAL = 1,
    BNA_ENET_T_LOOPBACK_EXTERNAL = 2
} ;
enum bna_link_status {
    BNA_LINK_DOWN = 0,
    BNA_LINK_UP = 1,
    BNA_CEE_UP = 2
} ;
enum bna_ethport_flags {
    BNA_ETHPORT_F_ADMIN_UP = 1,
    BNA_ETHPORT_F_PORT_ENABLED = 2,
    BNA_ETHPORT_F_RX_STARTED = 4
} ;
enum bna_enet_flags {
    BNA_ENET_F_IOCETH_READY = 1,
    BNA_ENET_F_ENABLED = 2,
    BNA_ENET_F_PAUSE_CHANGED = 4,
    BNA_ENET_F_MTU_CHANGED = 8
} ;
enum bna_rss_flags {
    BNA_RSS_F_RIT_PENDING = 1,
    BNA_RSS_F_CFG_PENDING = 2,
    BNA_RSS_F_STATUS_PENDING = 4
} ;
enum bna_mod_flags {
    BNA_MOD_F_INIT_DONE = 1
} ;
struct bna_ident {
   int id ;
   char name[64U] ;
};
struct bna_mac {
   struct list_head qe ;
   u8 addr[6U] ;
   struct bna_mcam_handle *handle ;
};
struct bna_mem_descr {
   u32 len ;
   void *kva ;
   struct bna_dma_addr dma ;
};
struct bna_mem_info {
   enum bna_mem_type mem_type ;
   u32 len ;
   u32 num ;
   u32 align_sz ;
   struct bna_mem_descr *mdl ;
   void *cookie ;
};
struct bna_intr_descr {
   int vector ;
    klee_make_symbolic(&vector, sizeof(int), "vector");
};
struct bna_intr_info {
   enum bna_intr_type intr_type ;
   int num ;
    klee_make_symbolic(&num, sizeof(int), "num");
   struct bna_intr_descr *idl ;
};
union bna_res_u {
   struct bna_mem_info mem_info ;
   struct bna_intr_info intr_info ;
};
struct bna_res_info {
   enum bna_res_type res_type ;
   union bna_res_u res_u ;
};
struct bna_qpt {
   struct bna_dma_addr hw_qpt_ptr ;
   void *kv_qpt_ptr ;
   u32 page_count ;
   u32 page_size ;
};
struct bna_attr {
   bool fw_query_complete ;
   int num_txq ;
    klee_make_symbolic(&num_txq, sizeof(int), "num_txq");
   int num_rxp ;
    klee_make_symbolic(&num_rxp, sizeof(int), "num_rxp");
   int num_ucmac ;
    klee_make_symbolic(&num_ucmac, sizeof(int), "num_ucmac");
   int num_mcmac ;
    klee_make_symbolic(&num_mcmac, sizeof(int), "num_mcmac");
   int max_rit_size ;
    klee_make_symbolic(&max_rit_size, sizeof(int), "max_rit_size");
};
struct bna_ioceth {
   void (*fsm)(void * , int  ) ;
   struct bfa_ioc ioc ;
   struct bna_attr attr ;
   struct bfa_msgq_cmd_entry msgq_cmd ;
   struct bfi_enet_attr_req attr_req ;
   void (*stop_cbfn)(struct bnad * ) ;
   struct bnad *stop_cbarg ;
   struct bna *bna ;
};
struct bna_pause_config {
   enum bna_status tx_pause ;
   enum bna_status rx_pause ;
};
struct bna_enet {
   void (*fsm)(void * , int  ) ;
   enum bna_enet_flags flags ;
   enum bna_enet_type type ;
   struct bna_pause_config pause_config ;
   int mtu ;
   void (*stop_cbfn)(void * ) ;
   void *stop_cbarg ;
   void (*mtu_cbfn)(struct bnad * ) ;
   struct bfa_wc chld_stop_wc ;
   struct bfa_msgq_cmd_entry msgq_cmd ;
   struct bfi_enet_set_pause_req pause_req ;
   struct bna *bna ;
};
union __anonunion_bfi_enet_cmd_405 {
   struct bfi_enet_enable_req admin_req ;
   struct bfi_enet_diag_lb_req lpbk_req ;
};
struct bna_ethport {
   void (*fsm)(void * , int  ) ;
   enum bna_ethport_flags flags ;
   enum bna_link_status link_status ;
   int rx_started_count ;
    klee_make_symbolic(&rx_started_count, sizeof(int), "rx_started_count");
   void (*stop_cbfn)(struct bna_enet * ) ;
   void (*adminup_cbfn)(struct bnad * , enum bna_cb_status  ) ;
   void (*link_cbfn)(struct bnad * , enum bna_link_status  ) ;
   struct bfa_msgq_cmd_entry msgq_cmd ;
   union __anonunion_bfi_enet_cmd_405 bfi_enet_cmd ;
   struct bna *bna ;
};
struct bna_ib_dbell {
   void *doorbell_addr ;
   u32 doorbell_ack ;
};
struct bna_ib {
   struct bna_dma_addr ib_seg_host_addr ;
   void *ib_seg_host_addr_kva ;
   struct bna_ib_dbell door_bell ;
   enum bna_intr_type intr_type ;
   int intr_vector ;
    klee_make_symbolic(&intr_vector, sizeof(int), "intr_vector");
   u8 coalescing_timeo ;
   int interpkt_count ;
    klee_make_symbolic(&interpkt_count, sizeof(int), "interpkt_count");
   int interpkt_timeo ;
    klee_make_symbolic(&interpkt_timeo, sizeof(int), "interpkt_timeo");
};
struct bna_tcb {
   void **sw_qpt ;
   void *sw_q ;
   void *unmap_q ;
   u32 producer_index ;
   u32 consumer_index ;
   u32 volatile   *hw_consumer_index ;
   u32 q_depth ;
   void *q_dbell ;
   struct bna_ib_dbell *i_dbell ;
   struct bna_txq *txq ;
   struct bnad *bnad ;
   void *priv ;
   enum bna_intr_type intr_type ;
   int intr_vector ;
   u8 priority ;
   unsigned long flags ;
   int id ;
   char name[16U] ;
};
struct bna_txq {
   struct list_head qe ;
   u8 priority ;
   struct bna_qpt qpt ;
   struct bna_tcb *tcb ;
   struct bna_ib ib ;
   struct bna_tx *tx ;
   int hw_id ;
    klee_make_symbolic(&hw_id, sizeof(int), "hw_id");
   u64 tx_packets ;
   u64 tx_bytes ;
};
union __anonunion_bfi_enet_cmd_406 {
   struct bfi_enet_tx_cfg_req cfg_req ;
   struct bfi_enet_req req ;
   struct bfi_enet_tx_cfg_rsp cfg_rsp ;
};
struct bna_tx {
   struct list_head qe ;
   int rid ;
    klee_make_symbolic(&rid, sizeof(int), "rid");
   int hw_id ;
   void (*fsm)(void * , int  ) ;
   enum bna_tx_flags flags ;
   enum bna_tx_type type ;
   int num_txq ;
   struct list_head txq_q ;
   u16 txf_vlan_id ;
   void (*tcb_setup_cbfn)(struct bnad * , struct bna_tcb * ) ;
   void (*tcb_destroy_cbfn)(struct bnad * , struct bna_tcb * ) ;
   void (*tx_stall_cbfn)(struct bnad * , struct bna_tx * ) ;
   void (*tx_resume_cbfn)(struct bnad * , struct bna_tx * ) ;
   void (*tx_cleanup_cbfn)(struct bnad * , struct bna_tx * ) ;
   void (*stop_cbfn)(void * , struct bna_tx * ) ;
   void *stop_cbarg ;
   struct bfa_msgq_cmd_entry msgq_cmd ;
   union __anonunion_bfi_enet_cmd_406 bfi_enet_cmd ;
   struct bna *bna ;
   void *priv ;
};
struct bna_tx_config {
   int num_txq ;
   int txq_depth ;
    klee_make_symbolic(&txq_depth, sizeof(int), "txq_depth");
   int coalescing_timeo ;
    klee_make_symbolic(&coalescing_timeo, sizeof(int), "coalescing_timeo");
   enum bna_tx_type tx_type ;
};
struct bna_tx_event_cbfn {
   void (*tcb_setup_cbfn)(struct bnad * , struct bna_tcb * ) ;
   void (*tcb_destroy_cbfn)(struct bnad * , struct bna_tcb * ) ;
   void (*tx_stall_cbfn)(struct bnad * , struct bna_tx * ) ;
   void (*tx_resume_cbfn)(struct bnad * , struct bna_tx * ) ;
   void (*tx_cleanup_cbfn)(struct bnad * , struct bna_tx * ) ;
};
struct bna_tx_mod {
   struct bna_tx *tx ;
   struct bna_txq *txq ;
   struct list_head tx_free_q ;
   struct list_head tx_active_q ;
   struct list_head txq_free_q ;
   void (*stop_cbfn)(struct bna_enet * ) ;
   struct bfa_wc tx_stop_wc ;
   enum bna_tx_mod_flags flags ;
   u8 prio_map ;
   int default_prio ;
    klee_make_symbolic(&default_prio, sizeof(int), "default_prio");
   int iscsi_over_cee ;
    klee_make_symbolic(&iscsi_over_cee, sizeof(int), "iscsi_over_cee");
   int iscsi_prio ;
    klee_make_symbolic(&iscsi_prio, sizeof(int), "iscsi_prio");
   int prio_reconfigured ;
    klee_make_symbolic(&prio_reconfigured, sizeof(int), "prio_reconfigured");
   u32 rid_mask ;
   struct bna *bna ;
};
struct bna_ccb;
struct bna_rcb {
   void **sw_qpt ;
   void *sw_q ;
   void *unmap_q ;
   u32 producer_index ;
   u32 consumer_index ;
   u32 q_depth ;
   void *q_dbell ;
   struct bna_rxq *rxq ;
   struct bna_ccb *ccb ;
   struct bnad *bnad ;
   void *priv ;
   unsigned long flags ;
   int id ;
};
struct bna_rxp;
struct bna_rxq {
   struct list_head qe ;
   int buffer_size ;
    klee_make_symbolic(&buffer_size, sizeof(int), "buffer_size");
   int q_depth ;
    klee_make_symbolic(&q_depth, sizeof(int), "q_depth");
   u32 num_vecs ;
   enum bna_status multi_buffer ;
   struct bna_qpt qpt ;
   struct bna_rcb *rcb ;
   struct bna_rxp *rxp ;
   struct bna_rx *rx ;
   int hw_id ;
   u64 rx_packets ;
   u64 rx_bytes ;
   u64 rx_packets_with_error ;
   u64 rxbuf_alloc_failed ;
};
struct __anonstruct_hds_407 {
   struct bna_rxq *hdr ;
   struct bna_rxq *data ;
};
struct __anonstruct_slr_408 {
   struct bna_rxq *small ;
   struct bna_rxq *large ;
};
struct __anonstruct_single_409 {
   struct bna_rxq *only ;
   struct bna_rxq *reserved ;
};
union bna_rxq_u {
   struct __anonstruct_hds_407 hds ;
   struct __anonstruct_slr_408 slr ;
   struct __anonstruct_single_409 single ;
};
struct bna_pkt_rate {
   u32 small_pkt_cnt ;
   u32 large_pkt_cnt ;
};
struct bna_ccb {
   void **sw_qpt ;
   void *sw_q ;
   u32 producer_index ;
   u32 volatile   *hw_producer_index ;
   u32 q_depth ;
   struct bna_ib_dbell *i_dbell ;
   struct bna_rcb *rcb[2U] ;
   void *ctrl ;
   struct bna_pkt_rate pkt_rate ;
   u32 pkts_una ;
   u32 bytes_per_intr ;
   struct bna_cq *cq ;
   struct bnad *bnad ;
   void *priv ;
   enum bna_intr_type intr_type ;
   int intr_vector ;
   u8 rx_coalescing_timeo ;
   int id ;
   char name[16U] ;
};
struct bna_cq {
   struct bna_qpt qpt ;
   struct bna_ccb *ccb ;
   struct bna_ib ib ;
   struct bna_rx *rx ;
};
struct bna_rss_config {
   enum bfi_enet_rss_type hash_type ;
   u8 hash_mask ;
   u32 toeplitz_hash_key[10U] ;
};
struct bna_hds_config {
   enum bfi_enet_hds_type hdr_type ;
   int forced_offset ;
    klee_make_symbolic(&forced_offset, sizeof(int), "forced_offset");
};
struct bna_rx_config {
   enum bna_rx_type rx_type ;
   int num_paths ;
    klee_make_symbolic(&num_paths, sizeof(int), "num_paths");
   enum bna_rxp_type rxp_type ;
   int coalescing_timeo ;
   u32 frame_size ;
   u32 q1_depth ;
   u32 q1_buf_size ;
   u32 q0_depth ;
   u32 q0_buf_size ;
   u32 q0_num_vecs ;
   enum bna_status q0_multi_buf ;
   enum bna_status rss_status ;
   struct bna_rss_config rss_config ;
   struct bna_hds_config hds_config ;
   enum bna_status vlan_strip_status ;
};
struct bna_rxp {
   struct list_head qe ;
   enum bna_rxp_type type ;
   union bna_rxq_u rxq ;
   struct bna_cq cq ;
   struct bna_rx *rx ;
   int vector ;
   int hw_id ;
};
union __anonunion_bfi_enet_cmd_410 {
   struct bfi_enet_enable_req req ;
   struct bfi_enet_rss_cfg_req rss_req ;
   struct bfi_enet_rit_req rit_req ;
   struct bfi_enet_rx_vlan_req vlan_req ;
   struct bfi_enet_mcast_add_req mcast_add_req ;
   struct bfi_enet_mcast_del_req mcast_del_req ;
   struct bfi_enet_ucast_req ucast_req ;
};
struct bna_rxf {
   void (*fsm)(void * , int  ) ;
   struct bfa_msgq_cmd_entry msgq_cmd ;
   union __anonunion_bfi_enet_cmd_410 bfi_enet_cmd ;
   void (*start_cbfn)(struct bna_rx * ) ;
   struct bna_rx *start_cbarg ;
   void (*stop_cbfn)(struct bna_rx * ) ;
   struct bna_rx *stop_cbarg ;
   void (*cam_fltr_cbfn)(struct bnad * , struct bna_rx * ) ;
   struct bnad *cam_fltr_cbarg ;
   struct list_head ucast_pending_add_q ;
   struct list_head ucast_pending_del_q ;
   struct bna_mac *ucast_pending_mac ;
   int ucast_pending_set ;
    klee_make_symbolic(&ucast_pending_set, sizeof(int), "ucast_pending_set");
   struct list_head ucast_active_q ;
   struct bna_mac ucast_active_mac ;
   int ucast_active_set ;
    klee_make_symbolic(&ucast_active_set, sizeof(int), "ucast_active_set");
   struct list_head mcast_pending_add_q ;
   struct list_head mcast_pending_del_q ;
   struct list_head mcast_active_q ;
   struct list_head mcast_handle_q ;
   enum bna_rxmode rxmode_pending ;
   enum bna_rxmode rxmode_pending_bitmask ;
   enum bna_rxmode rxmode_active ;
   u8 vlan_pending_bitmask ;
   enum bna_status vlan_filter_status ;
   u32 vlan_filter_table[128U] ;
   bool vlan_strip_pending ;
   enum bna_status vlan_strip_status ;
   enum bna_rss_flags rss_pending ;
   enum bna_status rss_status ;
   struct bna_rss_config rss_cfg ;
   u8 *rit ;
   int rit_size ;
    klee_make_symbolic(&rit_size, sizeof(int), "rit_size");
   struct bna_rx *rx ;
};
union __anonunion_bfi_enet_cmd_411 {
   struct bfi_enet_rx_cfg_req cfg_req ;
   struct bfi_enet_req req ;
   struct bfi_enet_rx_cfg_rsp cfg_rsp ;
};
struct bna_rx {
   struct list_head qe ;
   int rid ;
   int hw_id ;
   void (*fsm)(void * , int  ) ;
   enum bna_rx_type type ;
   int num_paths ;
   struct list_head rxp_q ;
   struct bna_hds_config hds_cfg ;
   struct bna_rxf rxf ;
   enum bna_rx_flags rx_flags ;
   struct bfa_msgq_cmd_entry msgq_cmd ;
   union __anonunion_bfi_enet_cmd_411 bfi_enet_cmd ;
   void (*rcb_setup_cbfn)(struct bnad * , struct bna_rcb * ) ;
   void (*rcb_destroy_cbfn)(struct bnad * , struct bna_rcb * ) ;
   void (*ccb_setup_cbfn)(struct bnad * , struct bna_ccb * ) ;
   void (*ccb_destroy_cbfn)(struct bnad * , struct bna_ccb * ) ;
   void (*rx_stall_cbfn)(struct bnad * , struct bna_rx * ) ;
   void (*rx_cleanup_cbfn)(struct bnad * , struct bna_rx * ) ;
   void (*rx_post_cbfn)(struct bnad * , struct bna_rx * ) ;
   void (*stop_cbfn)(void * , struct bna_rx * ) ;
   void *stop_cbarg ;
   struct bna *bna ;
   void *priv ;
};
struct bna_rx_event_cbfn {
   void (*rcb_setup_cbfn)(struct bnad * , struct bna_rcb * ) ;
   void (*rcb_destroy_cbfn)(struct bnad * , struct bna_rcb * ) ;
   void (*ccb_setup_cbfn)(struct bnad * , struct bna_ccb * ) ;
   void (*ccb_destroy_cbfn)(struct bnad * , struct bna_ccb * ) ;
   void (*rx_stall_cbfn)(struct bnad * , struct bna_rx * ) ;
   void (*rx_cleanup_cbfn)(struct bnad * , struct bna_rx * ) ;
   void (*rx_post_cbfn)(struct bnad * , struct bna_rx * ) ;
};
struct bna_rx_mod {
   struct bna *bna ;
   struct bna_rx *rx ;
   struct bna_rxp *rxp ;
   struct bna_rxq *rxq ;
   struct list_head rx_free_q ;
   struct list_head rx_active_q ;
   int rx_free_count ;
    klee_make_symbolic(&rx_free_count, sizeof(int), "rx_free_count");
   struct list_head rxp_free_q ;
   int rxp_free_count ;
    klee_make_symbolic(&rxp_free_count, sizeof(int), "rxp_free_count");
   struct list_head rxq_free_q ;
   int rxq_free_count ;
    klee_make_symbolic(&rxq_free_count, sizeof(int), "rxq_free_count");
   enum bna_rx_mod_flags flags ;
   void (*stop_cbfn)(struct bna_enet * ) ;
   struct bfa_wc rx_stop_wc ;
   u32 dim_vector[8U][2U] ;
   u32 rid_mask ;
};
struct bna_ucam_mod {
   struct bna_mac *ucmac ;
   struct list_head free_q ;
   struct list_head del_q ;
   struct bna *bna ;
};
struct bna_mcam_handle {
   struct list_head qe ;
   int handle ;
    klee_make_symbolic(&handle, sizeof(int), "handle");
   int refcnt ;
    klee_make_symbolic(&refcnt, sizeof(int), "refcnt");
};
struct bna_mcam_mod {
   struct bna_mac *mcmac ;
   struct bna_mcam_handle *mchandle ;
   struct list_head free_q ;
   struct list_head del_q ;
   struct list_head free_handle_q ;
   struct bna *bna ;
};
struct bna_stats {
   struct bna_dma_addr hw_stats_dma ;
   struct bfi_enet_stats *hw_stats_kva ;
   struct bfi_enet_stats hw_stats ;
};
struct bna_stats_mod {
   bool ioc_ready ;
   bool stats_get_busy ;
   bool stats_clr_busy ;
   struct bfa_msgq_cmd_entry stats_get_cmd ;
   struct bfa_msgq_cmd_entry stats_clr_cmd ;
   struct bfi_enet_stats_req stats_get ;
   struct bfi_enet_stats_req stats_clr ;
};
struct bna {
   struct bna_ident ident ;
   struct bfa_pcidev pcidev ;
   struct bna_reg regs ;
   struct bna_bit_defn bits ;
   struct bna_stats stats ;
   struct bna_ioceth ioceth ;
   struct bfa_cee cee ;
   struct bfa_flash flash ;
   struct bfa_msgq msgq ;
   struct bna_ethport ethport ;
   struct bna_enet enet ;
   struct bna_stats_mod stats_mod ;
   struct bna_tx_mod tx_mod ;
   struct bna_rx_mod rx_mod ;
   struct bna_ucam_mod ucam_mod ;
   struct bna_mcam_mod mcam_mod ;
   enum bna_mod_flags mod_flags ;
   int default_mode_rid ;
    klee_make_symbolic(&default_mode_rid, sizeof(int), "default_mode_rid");
   int promisc_rid ;
    klee_make_symbolic(&promisc_rid, sizeof(int), "promisc_rid");
   struct bnad *bnad ;
};
struct bnad_rx_ctrl {
   struct bna_ccb *ccb ;
   struct bnad *bnad ;
   unsigned long flags ;
   struct napi_struct napi ;
   u64 rx_intr_ctr ;
   u64 rx_poll_ctr ;
   u64 rx_schedule ;
   u64 rx_keep_poll ;
   u64 rx_complete ;
};
enum bnad_intr_source {
    BNAD_INTR_TX = 1,
    BNAD_INTR_RX = 2
} ;
struct bnad_iocmd_comp {
   struct bnad *bnad ;
   struct completion comp ;
   int comp_status ;
    klee_make_symbolic(&comp_status, sizeof(int), "comp_status");
};
struct bnad_completion {
   struct completion ioc_comp ;
   struct completion ucast_comp ;
   struct completion mcast_comp ;
   struct completion tx_comp ;
   struct completion rx_comp ;
   struct completion stats_comp ;
   struct completion enet_comp ;
   struct completion mtu_comp ;
   u8 ioc_comp_status ;
   u8 ucast_comp_status ;
   u8 mcast_comp_status ;
   u8 tx_comp_status ;
   u8 rx_comp_status ;
   u8 stats_comp_status ;
   u8 port_comp_status ;
   u8 mtu_comp_status ;
};
struct bnad_drv_stats {
   u64 netif_queue_stop ;
   u64 netif_queue_wakeup ;
   u64 netif_queue_stopped ;
   u64 tso4 ;
   u64 tso6 ;
   u64 tso_err ;
   u64 tcpcsum_offload ;
   u64 udpcsum_offload ;
   u64 csum_help ;
   u64 tx_skb_too_short ;
   u64 tx_skb_stopping ;
   u64 tx_skb_max_vectors ;
   u64 tx_skb_mss_too_long ;
   u64 tx_skb_tso_too_short ;
   u64 tx_skb_tso_prepare ;
   u64 tx_skb_non_tso_too_long ;
   u64 tx_skb_tcp_hdr ;
   u64 tx_skb_udp_hdr ;
   u64 tx_skb_csum_err ;
   u64 tx_skb_headlen_too_long ;
   u64 tx_skb_headlen_zero ;
   u64 tx_skb_frag_zero ;
   u64 tx_skb_len_mismatch ;
   u64 hw_stats_updates ;
   u64 netif_rx_dropped ;
   u64 link_toggle ;
   u64 cee_toggle ;
   u64 rxp_info_alloc_failed ;
   u64 mbox_intr_disabled ;
   u64 mbox_intr_enabled ;
   u64 tx_unmap_q_alloc_failed ;
   u64 rx_unmap_q_alloc_failed ;
   u64 rxbuf_alloc_failed ;
};
struct bnad_stats {
   struct bnad_drv_stats drv_stats ;
   struct bna_stats *bna_stats ;
};
struct bnad_tx_res_info {
   struct bna_res_info res_info[7U] ;
};
struct bnad_rx_res_info {
   struct bna_res_info res_info[16U] ;
};
struct bnad_tx_info {
   struct bna_tx *tx ;
   struct bna_tcb *tcb[8U] ;
   u32 tx_id ;
   struct delayed_work tx_cleanup_work ;
};
struct bnad_rx_info {
   struct bna_rx *rx ;
   struct bnad_rx_ctrl rx_ctrl[16U] ;
   u32 rx_id ;
   struct work_struct rx_cleanup_work ;
};
struct bnad_tx_vector {
   dma_addr_t dma_addr ;
   __u32 dma_len ;
};
struct bnad_tx_unmap {
   struct sk_buff *skb ;
   u32 nvecs ;
   struct bnad_tx_vector vectors[4U] ;
};
struct bnad_rx_vector {
   dma_addr_t dma_addr ;
   u32 len ;
};
struct bnad_rx_unmap {
   struct page *page ;
   struct sk_buff *skb ;
   struct bnad_rx_vector vector ;
   u32 page_offset ;
};
enum bnad_rxbuf_type {
    BNAD_RXBUF_NONE = 0,
    BNAD_RXBUF_SK_BUFF = 1,
    BNAD_RXBUF_PAGE = 2,
    BNAD_RXBUF_MULTI_BUFF = 3
} ;
struct bnad_rx_unmap_q {
   int reuse_pi ;
    klee_make_symbolic(&reuse_pi, sizeof(int), "reuse_pi");
   int alloc_order ;
    klee_make_symbolic(&alloc_order, sizeof(int), "alloc_order");
   u32 map_size ;
   enum bnad_rxbuf_type type ;
   struct bnad_rx_unmap unmap[0U] ;
};
struct bnad_diag;
struct bnad {
   struct net_device *netdev ;
   u32 id ;
   struct list_head list_entry ;
   struct bnad_tx_info tx_info[1U] ;
   struct bnad_rx_info rx_info[1U] ;
   unsigned long active_vlans[64U] ;
   u32 num_tx ;
   u32 num_rx ;
   u32 num_txq_per_tx ;
   u32 num_rxp_per_rx ;
   u32 txq_depth ;
   u32 rxq_depth ;
   u8 tx_coalescing_timeo ;
   u8 rx_coalescing_timeo ;
   struct bna_rx_config rx_config[1U] ;
   struct bna_tx_config tx_config[1U] ;
   void *bar0 ;
   struct bna bna ;
   u32 cfg_flags ;
   unsigned long run_flags ;
    klee_make_symbolic(&run_flags, sizeof(long), "run_flags");
   struct pci_dev *pcidev ;
   u64 mmio_start ;
   u64 mmio_len ;
   u32 msix_num ;
   struct msix_entry *msix_table ;
   struct mutex conf_mutex ;
   spinlock_t bna_lock ;
   struct timer_list ioc_timer ;
   struct timer_list dim_timer ;
   struct timer_list stats_timer ;
   struct bna_res_info res_info[4U] ;
   struct bna_res_info mod_res_info[8U] ;
   struct bnad_tx_res_info tx_res_info[1U] ;
   struct bnad_rx_res_info rx_res_info[1U] ;
   struct bnad_completion bnad_completions ;
   u8 perm_addr[6U] ;
   struct workqueue_struct *work_q ;
   struct bnad_stats stats ;
   struct bnad_diag *diag ;
   char adapter_name[64U] ;
   char port_name[64U] ;
   char mbox_irq_name[64U] ;
   char wq_name[64U] ;
   char *regdata ;
   u32 reglen ;
   struct dentry *bnad_dentry_files[5U] ;
   struct dentry *port_debugfs_root ;
};
typedef bool ldv_func_ret_type___2;
typedef bool ldv_func_ret_type___3;
typedef bool ldv_func_ret_type___4;
typedef bool ldv_func_ret_type___5;
typedef int ldv_func_ret_type___6;
    klee_make_symbolic(&ldv_func_ret_type___6, sizeof(int), "ldv_func_ret_type___6");
typedef int ldv_func_ret_type___7;
    klee_make_symbolic(&ldv_func_ret_type___7, sizeof(int), "ldv_func_ret_type___7");
typedef int ldv_func_ret_type___8;
    klee_make_symbolic(&ldv_func_ret_type___8, sizeof(int), "ldv_func_ret_type___8");
typedef int ldv_func_ret_type___9;
    klee_make_symbolic(&ldv_func_ret_type___9, sizeof(int), "ldv_func_ret_type___9");
typedef int ldv_func_ret_type___10;
    klee_make_symbolic(&ldv_func_ret_type___10, sizeof(int), "ldv_func_ret_type___10");
typedef int ldv_func_ret_type___11;
    klee_make_symbolic(&ldv_func_ret_type___11, sizeof(int), "ldv_func_ret_type___11");
typedef int ldv_func_ret_type___12;
    klee_make_symbolic(&ldv_func_ret_type___12, sizeof(int), "ldv_func_ret_type___12");
typedef int ldv_func_ret_type___13;
    klee_make_symbolic(&ldv_func_ret_type___13, sizeof(int), "ldv_func_ret_type___13");
typedef int ldv_func_ret_type___14;
    klee_make_symbolic(&ldv_func_ret_type___14, sizeof(int), "ldv_func_ret_type___14");
typedef int ldv_func_ret_type___15;
    klee_make_symbolic(&ldv_func_ret_type___15, sizeof(int), "ldv_func_ret_type___15");
typedef int ldv_func_ret_type___16;
    klee_make_symbolic(&ldv_func_ret_type___16, sizeof(int), "ldv_func_ret_type___16");
typedef int ldv_func_ret_type___17;
    klee_make_symbolic(&ldv_func_ret_type___17, sizeof(int), "ldv_func_ret_type___17");
typedef int ldv_func_ret_type___18;
    klee_make_symbolic(&ldv_func_ret_type___18, sizeof(int), "ldv_func_ret_type___18");
typedef int ldv_func_ret_type___19;
    klee_make_symbolic(&ldv_func_ret_type___19, sizeof(int), "ldv_func_ret_type___19");
typedef int ldv_func_ret_type___20;
    klee_make_symbolic(&ldv_func_ret_type___20, sizeof(int), "ldv_func_ret_type___20");
typedef int ldv_func_ret_type___21;
    klee_make_symbolic(&ldv_func_ret_type___21, sizeof(int), "ldv_func_ret_type___21");
typedef int ldv_func_ret_type___22;
    klee_make_symbolic(&ldv_func_ret_type___22, sizeof(int), "ldv_func_ret_type___22");
enum hrtimer_restart;
struct bfa_adapter_attr {
   char manufacturer[8U] ;
   char serial_num[12U] ;
   u32 card_type ;
   char model[16U] ;
   char model_descr[128U] ;
   u64 pwwn ;
   char node_symname[256U] ;
   char hw_ver[64U] ;
   char fw_ver[64U] ;
   char optrom_ver[64U] ;
   char os_type[64U] ;
   struct bfa_mfg_vpd vpd ;
   u8 mac[6U] ;
   u8 nports ;
   u8 max_speed ;
   u8 prototype ;
   char asic_rev ;
   u8 pcie_gen ;
   u8 pcie_lanes_orig ;
   u8 pcie_lanes ;
   u8 cna_capable ;
   u8 is_mezz ;
   u8 trunk_capable ;
};
struct bfa_ioc_driver_attr {
   char driver[16U] ;
   char driver_ver[64U] ;
   char fw_ver[64U] ;
   char bios_ver[64U] ;
   char efi_ver[64U] ;
   char ob_ver[64U] ;
};
struct bfa_ioc_pci_attr {
   u16 vendor_id ;
   u16 device_id ;
   u16 ssid ;
   u16 ssvid ;
   u32 pcifn ;
   u32 rsvd ;
   char chip_rev[8U] ;
};
enum bfa_ioc_state {
    BFA_IOC_UNINIT = 1,
    BFA_IOC_RESET = 2,
    BFA_IOC_SEMWAIT = 3,
    BFA_IOC_HWINIT = 4,
    BFA_IOC_GETATTR = 5,
    BFA_IOC_OPERATIONAL = 6,
    BFA_IOC_INITFAIL = 7,
    BFA_IOC_FAIL = 8,
    BFA_IOC_DISABLING = 9,
    BFA_IOC_DISABLED = 10,
    BFA_IOC_FWMISMATCH = 11,
    BFA_IOC_ENABLING = 12,
    BFA_IOC_HWFAIL = 13
} ;
enum bfa_ioc_type {
    BFA_IOC_TYPE_FC = 1,
    BFA_IOC_TYPE_FCoE = 2,
    BFA_IOC_TYPE_LL = 3
} ;
struct bfa_ioc_attr {
   enum bfa_ioc_type ioc_type ;
   enum bfa_ioc_state state ;
   struct bfa_adapter_attr adapter_attr ;
   struct bfa_ioc_driver_attr driver_attr ;
   struct bfa_ioc_pci_attr pci_attr ;
   u8 port_id ;
   u8 port_mode ;
   u8 cap_bm ;
   u8 port_mode_cfg ;
   u8 def_fn ;
   u8 rsvd[3U] ;
};
struct bfa_flash_part_attr {
   u32 part_type ;
   u32 part_instance ;
   u32 part_off ;
   u32 part_size ;
   u32 part_len ;
   u32 part_status ;
   char rsv[8U] ;
};
struct bfa_flash_attr {
   u32 status ;
   u32 npart ;
   struct bfa_flash_part_attr part[32U] ;
};
enum hrtimer_restart;
struct bnad_drvinfo {
   struct bfa_ioc_attr ioc_attr ;
   struct bfa_cee_attr cee_attr ;
   struct bfa_flash_attr flash_attr ;
   u32 cee_status ;
   u32 flash_status ;
};
struct bnad_debug_info {
   char *debug_buffer ;
   void *i_private ;
   int buffer_len ;
    klee_make_symbolic(&buffer_len, sizeof(int), "buffer_len");
};
struct bnad_debugfs_entry {
   char const   *name ;
   umode_t mode ;
   struct file_operations  const  *fops ;
};
enum hrtimer_restart;
enum bfi_mclass {
    BFI_MC_IOC = 1,
    BFI_MC_DIAG = 2,
    BFI_MC_FLASH = 3,
    BFI_MC_CEE = 4,
    BFI_MC_FCPORT = 5,
    BFI_MC_IOCFC = 6,
    BFI_MC_LL = 7,
    BFI_MC_UF = 8,
    BFI_MC_FCXP = 9,
    BFI_MC_LPS = 10,
    BFI_MC_RPORT = 11,
    BFI_MC_ITNIM = 12,
    BFI_MC_IOIM_READ = 13,
    BFI_MC_IOIM_WRITE = 14,
    BFI_MC_IOIM_IO = 15,
    BFI_MC_IOIM = 16,
    BFI_MC_IOIM_IOCOM = 17,
    BFI_MC_TSKIM = 18,
    BFI_MC_SBOOT = 19,
    BFI_MC_IPFC = 20,
    BFI_MC_PORT = 21,
    BFI_MC_SFP = 22,
    BFI_MC_MSGQ = 23,
    BFI_MC_ENET = 24,
    BFI_MC_PHY = 25,
    BFI_MC_NBOOT = 26,
    BFI_MC_TIO_READ = 27,
    BFI_MC_TIO_WRITE = 28,
    BFI_MC_TIO_DATA_XFERED = 29,
    BFI_MC_TIO_IO = 30,
    BFI_MC_TIO = 31,
    BFI_MC_MFG = 32,
    BFI_MC_EDMA = 33,
    BFI_MC_MAX = 34
} ;
struct bfi_enet_rsp {
   struct bfi_msgq_mhdr mh ;
   u8 error ;
   u8 rsvd ;
   u16 cmd_offset ;
};
struct bfi_enet_attr_rsp {
   struct bfi_msgq_mhdr mh ;
   u8 error ;
   u8 rsvd ;
   u16 cmd_offset ;
   u32 max_cfg ;
   u32 max_ucmac ;
   u32 rit_size ;
};
struct bna_reg_offset {
   u32 fn_int_status ;
   u32 fn_int_mask ;
};
enum bna_ethport_event {
    ETHPORT_E_START = 1,
    ETHPORT_E_STOP = 2,
    ETHPORT_E_FAIL = 3,
    ETHPORT_E_UP = 4,
    ETHPORT_E_DOWN = 5,
    ETHPORT_E_FWRESP_UP_OK = 6,
    ETHPORT_E_FWRESP_DOWN = 7,
    ETHPORT_E_FWRESP_UP_FAIL = 8
} ;
enum bna_enet_event {
    ENET_E_START = 1,
    ENET_E_STOP = 2,
    ENET_E_FAIL = 3,
    ENET_E_PAUSE_CFG = 4,
    ENET_E_MTU_CFG = 5,
    ENET_E_FWRESP_PAUSE = 6,
    ENET_E_CHLD_STOPPED = 7
} ;
enum bna_ioceth_event {
    IOCETH_E_ENABLE = 1,
    IOCETH_E_DISABLE = 2,
    IOCETH_E_IOC_RESET = 3,
    IOCETH_E_IOC_FAILED = 4,
    IOCETH_E_IOC_READY = 5,
    IOCETH_E_ENET_ATTR_RESP = 6,
    IOCETH_E_ENET_STOPPED = 7,
    IOCETH_E_IOC_DISABLED = 8
} ;
enum hrtimer_restart;
enum bfi_enet_h2i_msgs {
    BFI_ENET_H2I_RX_CFG_SET_REQ = 1,
    BFI_ENET_H2I_RX_CFG_CLR_REQ = 2,
    BFI_ENET_H2I_RIT_CFG_REQ = 3,
    BFI_ENET_H2I_RSS_CFG_REQ = 4,
    BFI_ENET_H2I_RSS_ENABLE_REQ = 5,
    BFI_ENET_H2I_RX_PROMISCUOUS_REQ = 6,
    BFI_ENET_H2I_RX_DEFAULT_REQ = 7,
    BFI_ENET_H2I_MAC_UCAST_SET_REQ = 8,
    BFI_ENET_H2I_MAC_UCAST_CLR_REQ = 9,
    BFI_ENET_H2I_MAC_UCAST_ADD_REQ = 10,
    BFI_ENET_H2I_MAC_UCAST_DEL_REQ = 11,
    BFI_ENET_H2I_MAC_MCAST_ADD_REQ = 12,
    BFI_ENET_H2I_MAC_MCAST_DEL_REQ = 13,
    BFI_ENET_H2I_MAC_MCAST_FILTER_REQ = 14,
    BFI_ENET_H2I_RX_VLAN_SET_REQ = 15,
    BFI_ENET_H2I_RX_VLAN_STRIP_ENABLE_REQ = 16,
    BFI_ENET_H2I_TX_CFG_SET_REQ = 17,
    BFI_ENET_H2I_TX_CFG_CLR_REQ = 18,
    BFI_ENET_H2I_PORT_ADMIN_UP_REQ = 19,
    BFI_ENET_H2I_SET_PAUSE_REQ = 20,
    BFI_ENET_H2I_DIAG_LOOPBACK_REQ = 21,
    BFI_ENET_H2I_GET_ATTR_REQ = 22,
    BFI_ENET_H2I_STATS_GET_REQ = 23,
    BFI_ENET_H2I_STATS_CLR_REQ = 24,
    BFI_ENET_H2I_WOL_MAGIC_REQ = 25,
    BFI_ENET_H2I_WOL_FRAME_REQ = 26,
    BFI_ENET_H2I_MAX = 27
} ;
struct bfi_enet_mcast_add_rsp {
   struct bfi_msgq_mhdr mh ;
   u8 error ;
   u8 rsvd ;
   u16 cmd_offset ;
   u16 handle ;
   u8 rsvd1[2U] ;
};
enum bna_rx_event {
    RX_E_START = 1,
    RX_E_STOP = 2,
    RX_E_FAIL = 3,
    RX_E_STARTED = 4,
    RX_E_STOPPED = 5,
    RX_E_RXF_STARTED = 6,
    RX_E_RXF_STOPPED = 7,
    RX_E_CLEANUP_DONE = 8
} ;
enum bna_rxf_event {
    RXF_E_START = 1,
    RXF_E_STOP = 2,
    RXF_E_FAIL = 3,
    RXF_E_CONFIG = 4,
    RXF_E_FW_RESP = 7
} ;
enum bna_tx_event {
    TX_E_START = 1,
    TX_E_STOP = 2,
    TX_E_FAIL = 3,
    TX_E_STARTED = 4,
    TX_E_STOPPED = 5,
    TX_E_CLEANUP_DONE = 7,
    TX_E_BW_UPDATE = 8
} ;
enum hrtimer_restart;
struct bfi_msgq {
   union bfi_addr_u addr ;
   u16 q_depth ;
   u8 rsvd[2U] ;
};
struct bfi_msgq_cfg_req {
   struct bfi_mhdr mh ;
   struct bfi_msgq cmdq ;
   struct bfi_msgq rspq ;
};
union __anonunion_idx_334 {
   u16 cmdq_pi ;
   u16 rspq_ci ;
};
struct bfi_msgq_h2i_db {
   struct bfi_mhdr mh ;
   union __anonunion_idx_334 idx ;
};
union __anonunion_idx_335 {
   u16 rspq_pi ;
   u16 cmdq_ci ;
};
struct bfi_msgq_i2h_db {
   struct bfi_mhdr mh ;
   union __anonunion_idx_335 idx ;
};
struct bfi_msgq_h2i_cmdq_copy_rsp {
   struct bfi_mhdr mh ;
   u8 data[28U] ;
};
struct bfi_msgq_i2h_cmdq_copy_req {
   struct bfi_mhdr mh ;
   u16 offset ;
   u16 len ;
};
enum cmdq_event {
    CMDQ_E_START = 1,
    CMDQ_E_STOP = 2,
    CMDQ_E_FAIL = 3,
    CMDQ_E_POST = 4,
    CMDQ_E_INIT_RESP = 5,
    CMDQ_E_DB_READY = 6
} ;
enum rspq_event {
    RSPQ_E_START = 1,
    RSPQ_E_STOP = 2,
    RSPQ_E_FAIL = 3,
    RSPQ_E_RESP = 4,
    RSPQ_E_INIT_RESP = 5,
    RSPQ_E_DB_READY = 6
} ;
typedef __kernel_long_t __kernel_suseconds_t;
struct timeval {
   __kernel_time_t tv_sec ;
   __kernel_suseconds_t tv_usec ;
};
enum hrtimer_restart;
struct bfa_sm_table {
   void (*sm)(void * , int  ) ;
   int state ;
   char *name ;
};
struct bfi_alen {
   union bfi_addr_u al_addr ;
   u32 al_len ;
};
struct bfi_ioc_getattr_req {
   struct bfi_mhdr mh ;
   union bfi_addr_u attr_addr ;
};
struct bfi_ioc_fwver {
   u8 major ;
   u8 minor ;
   u8 maint ;
   u8 patch ;
   u8 phase ;
   u8 build ;
   u8 rsvd[2U] ;
};
struct bfi_ioc_image_hdr {
   u32 signature ;
   u8 asic_gen ;
   u8 asic_mode ;
   u8 port0_mode ;
   u8 port1_mode ;
   u32 exec ;
   u32 bootenv ;
   u32 rsvd_b[2U] ;
   struct bfi_ioc_fwver fwver ;
   u32 md5sum[4U] ;
};
enum bfi_ioc_img_ver_cmp {
    BFI_IOC_IMG_VER_INCOMP = 0,
    BFI_IOC_IMG_VER_OLD = 1,
    BFI_IOC_IMG_VER_SAME = 2,
    BFI_IOC_IMG_VER_BETTER = 3
} ;
enum bfi_fwboot_type {
    BFI_FWBOOT_TYPE_NORMAL = 0,
    BFI_FWBOOT_TYPE_FLASH = 1,
    BFI_FWBOOT_TYPE_MEMTEST = 2
} ;
struct bfi_ioc_ctrl_req {
   struct bfi_mhdr mh ;
   u16 clscode ;
   u16 rsvd ;
   u32 tv_sec ;
};
struct bfi_ioc_ctrl_reply {
   struct bfi_mhdr mh ;
   u8 status ;
   u8 port_mode ;
   u8 cap_bm ;
   u8 rsvd ;
};
union bfi_ioc_i2h_msg_u {
   struct bfi_mhdr mh ;
   struct bfi_ioc_ctrl_reply fw_event ;
   u32 mboxmsg[8U] ;
};
struct bfi_flash_query_req {
   struct bfi_mhdr mh ;
   struct bfi_alen alen ;
};
struct bfi_flash_write_req {
   struct bfi_mhdr mh ;
   struct bfi_alen alen ;
   u32 type ;
   u8 instance ;
   u8 last ;
   u8 rsv[2U] ;
   u32 offset ;
   u32 length ;
};
struct bfi_flash_read_req {
   struct bfi_mhdr mh ;
   u32 type ;
   u8 instance ;
   u8 rsv[3U] ;
   u32 offset ;
   u32 length ;
   struct bfi_alen alen ;
};
struct bfi_flash_query_rsp {
   struct bfi_mhdr mh ;
   u32 status ;
};
struct bfi_flash_read_rsp {
   struct bfi_mhdr mh ;
   u32 type ;
   u8 instance ;
   u8 rsv[3U] ;
   u32 status ;
   u32 length ;
};
struct bfi_flash_write_rsp {
   struct bfi_mhdr mh ;
   u32 type ;
   u8 instance ;
   u8 rsv[3U] ;
   u32 status ;
   u32 length ;
};
enum ioc_event {
    IOC_E_RESET = 1,
    IOC_E_ENABLE = 2,
    IOC_E_DISABLE = 3,
    IOC_E_DETACH = 4,
    IOC_E_ENABLED = 5,
    IOC_E_FWRSP_GETATTR = 6,
    IOC_E_DISABLED = 7,
    IOC_E_PFFAILED = 8,
    IOC_E_HBFAIL = 9,
    IOC_E_HWERROR = 10,
    IOC_E_TIMEOUT = 11,
    IOC_E_HWFAILED = 12
} ;
enum iocpf_event {
    IOCPF_E_ENABLE = 1,
    IOCPF_E_DISABLE = 2,
    IOCPF_E_STOP = 3,
    IOCPF_E_FWREADY = 4,
    IOCPF_E_FWRSP_ENABLE = 5,
    IOCPF_E_FWRSP_DISABLE = 6,
    IOCPF_E_FAIL = 7,
    IOCPF_E_INITFAIL = 8,
    IOCPF_E_GETATTRFAIL = 9,
    IOCPF_E_SEMLOCKED = 10,
    IOCPF_E_TIMEOUT = 11,
    IOCPF_E_SEM_ERROR = 12
} ;
enum bfa_iocpf_state {
    BFA_IOCPF_RESET = 1,
    BFA_IOCPF_SEMWAIT = 2,
    BFA_IOCPF_HWINIT = 3,
    BFA_IOCPF_READY = 4,
    BFA_IOCPF_INITFAIL = 5,
    BFA_IOCPF_FAIL = 6,
    BFA_IOCPF_DISABLING = 7,
    BFA_IOCPF_DISABLED = 8,
    BFA_IOCPF_FWMISMATCH = 9
} ;
struct __anonstruct_r_337 {
   unsigned char cmd ;
    klee_make_symbolic(&cmd, sizeof(char), "cmd");
   unsigned char addr_cnt : 4 ;
   unsigned short read_cnt : 9 ;
   unsigned short write_cnt : 9 ;
   unsigned char rsv : 1 ;
   unsigned char act : 1 ;
};
union bfa_flash_cmd_reg {
   struct __anonstruct_r_337 r ;
   u32 i ;
};
struct __anonstruct_r_338 {
   unsigned char good : 1 ;
   unsigned char bad : 1 ;
   unsigned char present : 1 ;
   unsigned char init_status : 1 ;
   unsigned char busy : 1 ;
   unsigned char fifo_cnt : 6 ;
   unsigned int rsv : 21 ;
};
union bfa_flash_dev_status_reg {
   struct __anonstruct_r_338 r ;
   u32 i ;
};
struct __anonstruct_r_339 {
   unsigned char dummy ;
    klee_make_symbolic(&dummy, sizeof(char), "dummy");
   unsigned int addr : 24 ;
};
union bfa_flash_addr_reg {
   struct __anonstruct_r_339 r ;
   u32 i ;
};
union __anonunion_m_341 {
   struct bfi_flash_query_rsp *query ;
   struct bfi_flash_write_rsp *write ;
   struct bfi_flash_read_rsp *read ;
   struct bfi_mbmsg *msg ;
};
typedef int ldv_func_ret_type___23;
    klee_make_symbolic(&ldv_func_ret_type___23, sizeof(int), "ldv_func_ret_type___23");
typedef int ldv_func_ret_type___24;
    klee_make_symbolic(&ldv_func_ret_type___24, sizeof(int), "ldv_func_ret_type___24");
typedef int ldv_func_ret_type___25;
    klee_make_symbolic(&ldv_func_ret_type___25, sizeof(int), "ldv_func_ret_type___25");
typedef int ldv_func_ret_type___26;
    klee_make_symbolic(&ldv_func_ret_type___26, sizeof(int), "ldv_func_ret_type___26");
typedef int ldv_func_ret_type___27;
    klee_make_symbolic(&ldv_func_ret_type___27, sizeof(int), "ldv_func_ret_type___27");
typedef int ldv_func_ret_type___28;
    klee_make_symbolic(&ldv_func_ret_type___28, sizeof(int), "ldv_func_ret_type___28");
enum hrtimer_restart;
struct __anonstruct_ct_fnreg_337 {
   u32 hfn_mbox ;
   u32 lpu_mbox ;
   u32 hfn_pgn ;
};
struct __anonstruct_ct_p0reg_338 {
   u32 hfn ;
   u32 lpu ;
};
struct __anonstruct_ct_p1reg_339 {
   u32 hfn ;
   u32 lpu ;
};
struct __anonstruct_ct2_reg_340 {
   u32 hfn_mbox ;
   u32 lpu_mbox ;
   u32 hfn_pgn ;
   u32 hfn ;
   u32 lpu ;
   u32 lpu_read ;
};
enum hrtimer_restart;
struct bfi_cee_get_req {
   struct bfi_mhdr mh ;
   union bfi_addr_u dma_addr ;
};
struct bfi_cee_get_rsp {
   struct bfi_mhdr mh ;
   u8 cmd_status ;
   u8 rsvd[3U] ;
};
struct bfi_cee_stats_rsp {
   struct bfi_mhdr mh ;
   u8 cmd_status ;
   u8 rsvd[3U] ;
};
union bfi_cee_i2h_msg_u {
   struct bfi_mhdr mh ;
   struct bfi_cee_get_rsp get_rsp ;
   struct bfi_cee_stats_rsp stats_rsp ;
};
enum hrtimer_restart;
void __builtin_prefetch(void const   *  , ...) ;
__inline static long ldv__builtin_expect(long exp , long c ) ;
extern struct module __this_module ;
__inline static void set_bit(long nr , unsigned long volatile   *addr ) 
{ 


  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; bts %1,%0": "+m" (*((long volatile   *)addr)): "Ir" (nr): "memory");
  return;
}
}
__inline static void clear_bit(long nr , unsigned long volatile   *addr ) 
{ 


  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; btr %1,%0": "+m" (*((long volatile   *)addr)): "Ir" (nr));
  return;
}
}
__inline static int test_and_set_bit(long nr , unsigned long volatile   *addr ) 
{ 
  char c ;
    klee_make_symbolic(&c, sizeof(char), "c");

  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; bts %2, %0; setc %1": "+m" (*addr),
                       "=qm" (c): "Ir" (nr): "memory");
  return ((int )((signed char )c) != 0);
}
}
__inline static int test_and_clear_bit(long nr , unsigned long volatile   *addr ) 
{ 
  char c ;

  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; btr %2, %0; setc %1": "+m" (*addr),
                       "=qm" (c): "Ir" (nr): "memory");
  return ((int )((signed char )c) != 0);
}
}
__inline static int constant_test_bit(long nr , unsigned long const volatile   *addr ) 
{ 


  {
  return ((int )((unsigned long )*(addr + (unsigned long )(nr >> 6)) >> ((int )nr & 63)) & 1);
}
}
__inline static int fls64(__u64 x ) 
{ 
  int bitpos ;
    klee_make_symbolic(&bitpos, sizeof(int), "bitpos");

  {
  bitpos = -1;
  __asm__  ("bsrq %1,%q0": "+r" (bitpos): "rm" (x));
  return (bitpos + 1);
}
}
extern unsigned long find_next_bit(unsigned long const   * , unsigned long  , unsigned long  ) ;
extern unsigned long find_first_bit(unsigned long const   * , unsigned long  ) ;
__inline static __u32 __arch_swab32(__u32 val ) 
{ 


  {
  __asm__  ("bswapl %0": "=r" (val): "0" (val));
  return (val);
}
}
__inline static __u64 __arch_swab64(__u64 val ) 
{ 


  {
  __asm__  ("bswapq %0": "=r" (val): "0" (val));
  return (val);
}
}
__inline static __u16 __fswab16(__u16 val ) 
{ 


  {
  return ((__u16 )((int )((short )((int )val << 8)) | (int )((short )((int )val >> 8))));
}
}
__inline static __u32 __fswab32(__u32 val ) 
{ 
  __u32 tmp ;

  {
  tmp = __arch_swab32(val);
  return (tmp);
}
}
__inline static __u64 __fswab64(__u64 val ) 
{ 
  __u64 tmp ;

  {
  tmp = __arch_swab64(val);
  return (tmp);
}
}
extern int printk(char const   *  , ...) ;
extern int sprintf(char * , char const   *  , ...) ;
void ldv_spin_lock(void) ;
void ldv_spin_unlock(void) ;
extern void *malloc(size_t  ) ;
extern void *calloc(size_t  , size_t  ) ;
extern void *memset(void * , int  , size_t  ) ;
extern void *memmove(void * , void const   * , size_t  ) ;
extern int __VERIFIER_nondet_int(void) ;
extern unsigned long __VERIFIER_nondet_ulong(void) ;
extern void abort(void);
void assume_abort_if_not(int cond) {
  if(!cond) {abort();}
}
__inline static bool IS_ERR(void const *ptr ) ;

void *ldv_malloc(size_t size ) 
{ 
  void *p ;
  void *tmp ;
  int tmp___0 ;
    klee_make_symbolic(&tmp___0, sizeof(int), "tmp___0");

  {
  tmp___0 = __VERIFIER_nondet_int();
  if (tmp___0 != 0) {
    return ((void *)0);
  } else {
    tmp = malloc(size);
    p = tmp;
    assume_abort_if_not((unsigned long )p != (unsigned long )((void *)0));
    assume_abort_if_not(IS_ERR(p) == 0);
    return (p);
  }
}
}
void *ldv_zalloc(size_t size ) 
{ 
  void *p ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp___0 = __VERIFIER_nondet_int();
  if (tmp___0 != 0) {
    return ((void *)0);
  } else {
    tmp = calloc(1UL, size);
    p = tmp;
    assume_abort_if_not((unsigned long )p != (unsigned long )((void *)0));
    assume_abort_if_not(IS_ERR(p) == 0);
    return (p);
  }
}
}
void *ldv_init_zalloc(size_t size ) 
{ 
  void *p ;
  void *tmp ;

  {
  tmp = calloc(1UL, size);
  p = tmp;
  assume_abort_if_not((unsigned long )p != (unsigned long )((void *)0));
  return (p);
}
}
void *ldv_memset(void *s , int c , size_t n ) 
{ 
  void *tmp ;

  {
  tmp = memset(s, c, n);
  return (tmp);
}
}
int ldv_undef_int(void) 
{ 
  int tmp ;
    klee_make_symbolic(&tmp, sizeof(int), "tmp");

  {
  tmp = __VERIFIER_nondet_int();
  return (tmp);
}
}
unsigned long ldv_undef_ulong(void) 
{ 
  unsigned long tmp ;

  {
  tmp = __VERIFIER_nondet_ulong();
  return (tmp);
}
}
__inline static void ldv_error(void) 
{ 


  {
  ERROR: ;
  {reach_error();}
}
}
__inline static void ldv_stop(void) 
{ 


  {
  LDV_STOP: ;
  goto LDV_STOP;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) 
{ 


  {
  return (exp);
}
}
__inline static void ldv__builtin_trap(void) 
{ 


  {
  ldv_error();
  return;
}
}
__inline static void INIT_LIST_HEAD(struct list_head *list ) 
{ 


  {
  list->next = list;
  list->prev = list;
  return;
}
}
extern void __list_add(struct list_head * , struct list_head * , struct list_head * ) ;
__inline static void list_add_tail(struct list_head *new , struct list_head *head ) 
{ 


  {
  __list_add(new, head->prev, head);
  return;
}
}
extern void list_del(struct list_head * ) ;
extern void warn_slowpath_null(char const   * , int const    ) ;
extern unsigned long __phys_addr(unsigned long  ) ;
__inline static int __get_order(unsigned long size ) 
{ 
  int order ;

  {
  size = size - 1UL;
  size = size >> 12;
  order = fls64((__u64 )size);
  return (order);
}
}
extern void *memset(void * , int  , size_t  ) ;
extern int __bitmap_weight(unsigned long const   * , unsigned int  ) ;
__inline static int bitmap_weight(unsigned long const   *src , unsigned int nbits ) 
{ 
  int tmp___0 ;

  {
  tmp___0 = __bitmap_weight(src, nbits);
  return (tmp___0);
}
}
extern int nr_cpu_ids ;
    klee_make_symbolic(&nr_cpu_ids, sizeof(int), "nr_cpu_ids");
extern struct cpumask  const  * const  cpu_online_mask ;
__inline static unsigned int cpumask_weight(struct cpumask  const  *srcp ) 
{ 
  int tmp ;

  {
  tmp = bitmap_weight((unsigned long const   *)(& srcp->bits), (unsigned int )nr_cpu_ids);
  return ((unsigned int )tmp);
}
}
__inline static int atomic_read(atomic_t const   *v ) 
{ 
  int __var ;
    klee_make_symbolic(&__var, sizeof(int), "__var");

  {
  __var = 0;
  return ((int )*((int const volatile   *)(& v->counter)));
}
}
__inline static void atomic_inc(atomic_t *v ) 
{ 


  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; incl %0": "+m" (v->counter));
  return;
}
}
extern void lockdep_init_map(struct lockdep_map * , char const   * , struct lock_class_key * ,
                             int  ) ;
extern void __raw_spin_lock_init(raw_spinlock_t * , char const   * , struct lock_class_key * ) ;
extern void _raw_spin_unlock_irqrestore(raw_spinlock_t * , unsigned long  ) ;
__inline static raw_spinlock_t *spinlock_check(spinlock_t *lock ) 
{ 


  {
  return (& lock->__annonCompField18.rlock);
}
}
__inline static void ldv_spin_unlock_irqrestore_12(spinlock_t *lock , unsigned long flags ) 
{ 


  {
  _raw_spin_unlock_irqrestore(& lock->__annonCompField18.rlock, flags);
  return;
}
}
__inline static void spin_unlock_irqrestore(spinlock_t *lock , unsigned long flags ) ;
extern void dump_page(struct page * , char const   * ) ;
extern void __init_waitqueue_head(wait_queue_head_t * , char const   * , struct lock_class_key * ) ;
extern void mutex_destroy(struct mutex * ) ;
extern void __mutex_init(struct mutex * , char const   * , struct lock_class_key * ) ;
extern void mutex_lock_nested(struct mutex * , unsigned int  ) ;
extern void mutex_unlock(struct mutex * ) ;
__inline static void init_completion(struct completion *x ) 
{ 
  struct lock_class_key __key ;

  {
  x->done = 0U;
  __init_waitqueue_head(& x->wait, "&x->wait", & __key);
  return;
}
}
extern void wait_for_completion(struct completion * ) ;
extern unsigned long wait_for_completion_timeout(struct completion * , unsigned long  ) ;
extern void complete(struct completion * ) ;
extern unsigned long volatile   jiffies ;
extern unsigned long __msecs_to_jiffies(unsigned int const    ) ;
__inline static unsigned long msecs_to_jiffies(unsigned int const   m ) 
{ 
  unsigned long tmp___0 ;

  {
  tmp___0 = __msecs_to_jiffies(m);
  return (tmp___0);
}
}
extern void init_timer_key(struct timer_list * , unsigned int  , char const   * ,
                           struct lock_class_key * ) ;
extern int mod_timer(struct timer_list * , unsigned long  ) ;
int ldv_mod_timer_43(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_50(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_51(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_52(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
extern int del_timer_sync(struct timer_list * ) ;
int ldv_del_timer_sync_53(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_54(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_58(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_59(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_60(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_63(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_64(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_65(struct timer_list *ldv_func_arg1 ) ;
extern void delayed_work_timer_fn(unsigned long  ) ;
extern void __init_work(struct work_struct * , int  ) ;
extern struct workqueue_struct *__alloc_workqueue_key(char const   * , unsigned int  ,
                                                      int  , struct lock_class_key * ,
                                                      char const   *  , ...) ;
extern void destroy_workqueue(struct workqueue_struct * ) ;
void ldv_destroy_workqueue_56(struct workqueue_struct *ldv_func_arg1 ) ;
extern bool queue_work_on(int  , struct workqueue_struct * , struct work_struct * ) ;
bool ldv_queue_work_on_15(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_17(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
extern bool queue_delayed_work_on(int  , struct workqueue_struct * , struct delayed_work * ,
                                  unsigned long  ) ;
bool ldv_queue_delayed_work_on_16(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_19(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
extern void flush_workqueue(struct workqueue_struct * ) ;
void ldv_flush_workqueue_18(struct workqueue_struct *ldv_func_arg1 ) ;
void ldv_flush_workqueue_55(struct workqueue_struct *ldv_func_arg1 ) ;
__inline static bool queue_work(struct workqueue_struct *wq , struct work_struct *work ) 
{ 
  bool tmp ;

  {
  tmp = ldv_queue_work_on_15(8192, wq, work);
  return (tmp);
}
}
__inline static bool queue_delayed_work(struct workqueue_struct *wq , struct delayed_work *dwork ,
                                        unsigned long delay ) 
{ 
  bool tmp ;

  {
  tmp = ldv_queue_delayed_work_on_16(8192, wq, dwork, delay);
  return (tmp);
}
}
__inline static unsigned int readl(void const volatile   *addr ) 
{ 
  unsigned int ret ;
    klee_make_symbolic(&ret, sizeof(int), "ret");

  {
  __asm__  volatile   ("movl %1,%0": "=r" (ret): "m" (*((unsigned int volatile   *)addr)): "memory");
  return (ret);
}
}
__inline static void writel(unsigned int val , void volatile   *addr ) 
{ 


  {
  __asm__  volatile   ("movl %0,%1": : "r" (val), "m" (*((unsigned int volatile   *)addr)): "memory");
  return;
}
}
extern void *ioremap_nocache(resource_size_t  , unsigned long  ) ;
extern void iounmap(void volatile   * ) ;
__inline static struct page *alloc_pages(gfp_t flags , unsigned int order ) ;
extern void kfree(void const   * ) ;
__inline static void *kcalloc(size_t n , size_t size , gfp_t flags ) ;
__inline static void *kzalloc(size_t size , gfp_t flags ) ;
void ldv_check_alloc_flags(gfp_t flags ) ;
struct timer_list *ldv_timer_list_7_1  ;
int ldv_state_variable_20  ;
    klee_make_symbolic(&ldv_state_variable_20, sizeof(int), "ldv_state_variable_20");
int pci_counter  ;
    klee_make_symbolic(&pci_counter, sizeof(int), "pci_counter");
struct work_struct *ldv_work_struct_3_1  ;
int ldv_state_variable_0  ;
    klee_make_symbolic(&ldv_state_variable_0, sizeof(int), "ldv_state_variable_0");
struct timer_list *ldv_timer_list_9_3  ;
struct timer_list *ldv_timer_list_10_2  ;
struct timer_list *ldv_timer_list_8_1  ;
int ldv_timer_5_2  ;
    klee_make_symbolic(&ldv_timer_5_2, sizeof(int), "ldv_timer_5_2");
int ldv_irq_2_0  =    0;
int ldv_state_variable_12  ;
    klee_make_symbolic(&ldv_state_variable_12, sizeof(int), "ldv_state_variable_12");
struct pci_dev *bnad_pci_driver_group1  ;
struct timer_list *ldv_timer_list_5_0  ;
int ldv_state_variable_14  ;
    klee_make_symbolic(&ldv_state_variable_14, sizeof(int), "ldv_state_variable_14");
int ldv_timer_9_1  ;
    klee_make_symbolic(&ldv_timer_9_1, sizeof(int), "ldv_timer_9_1");
int ldv_timer_6_2  ;
    klee_make_symbolic(&ldv_timer_6_2, sizeof(int), "ldv_timer_6_2");
int ldv_timer_9_0  ;
    klee_make_symbolic(&ldv_timer_9_0, sizeof(int), "ldv_timer_9_0");
struct timer_list *ldv_timer_list_5_3  ;
int ldv_state_variable_17  ;
    klee_make_symbolic(&ldv_state_variable_17, sizeof(int), "ldv_state_variable_17");
int ldv_timer_9_3  ;
    klee_make_symbolic(&ldv_timer_9_3, sizeof(int), "ldv_timer_9_3");
struct inode *bnad_debugfs_op_fwtrc_group1  ;
void *ldv_irq_data_2_3  ;
int ldv_state_variable_19  ;
    klee_make_symbolic(&ldv_state_variable_19, sizeof(int), "ldv_state_variable_19");
struct work_struct *ldv_work_struct_4_3  ;
int ldv_state_variable_9  ;
    klee_make_symbolic(&ldv_state_variable_9, sizeof(int), "ldv_state_variable_9");
struct file *bnad_debugfs_op_regwr_group2  ;
int ldv_timer_6_0  ;
    klee_make_symbolic(&ldv_timer_6_0, sizeof(int), "ldv_timer_6_0");
struct timer_list *ldv_timer_list_5_1  ;
struct file *bnad_debugfs_op_regrd_group2  ;
int ref_cnt  ;
    klee_make_symbolic(&ref_cnt, sizeof(int), "ref_cnt");
int ldv_irq_line_1_1  ;
    klee_make_symbolic(&ldv_irq_line_1_1, sizeof(int), "ldv_irq_line_1_1");
void *ldv_irq_data_2_2  ;
int ldv_work_3_3  ;
    klee_make_symbolic(&ldv_work_3_3, sizeof(int), "ldv_work_3_3");
struct work_struct *ldv_work_struct_4_0  ;
int ldv_state_variable_7  ;
    klee_make_symbolic(&ldv_state_variable_7, sizeof(int), "ldv_state_variable_7");
struct work_struct *ldv_work_struct_3_3  ;
struct timer_list *ldv_timer_list_10_0  ;
struct timer_list *ldv_timer_list_6_3  ;
int ldv_irq_2_1  =    0;
int ldv_timer_8_2  ;
    klee_make_symbolic(&ldv_timer_8_2, sizeof(int), "ldv_timer_8_2");
void *ldv_irq_data_2_1  ;
struct timer_list *ldv_timer_list_6_2  ;
int ldv_irq_1_3  =    0;
struct timer_list *ldv_timer_list_9_2  ;
int ldv_irq_line_2_2  ;
    klee_make_symbolic(&ldv_irq_line_2_2, sizeof(int), "ldv_irq_line_2_2");
int ldv_timer_9_2  ;
    klee_make_symbolic(&ldv_timer_9_2, sizeof(int), "ldv_timer_9_2");
struct timer_list *ldv_timer_list_7_3  ;
int ldv_work_4_0  ;
    klee_make_symbolic(&ldv_work_4_0, sizeof(int), "ldv_work_4_0");
struct work_struct *ldv_work_struct_3_2  ;
int ldv_state_variable_6  ;
    klee_make_symbolic(&ldv_state_variable_6, sizeof(int), "ldv_state_variable_6");
void *ldv_irq_data_1_0  ;
void *ldv_irq_data_1_3  ;
struct work_struct *ldv_work_struct_4_2  ;
struct timer_list *ldv_timer_list_6_0  ;
struct net_device *bnad_ethtool_ops_group5  ;
struct timer_list *ldv_timer_list_8_3  ;
int ldv_timer_7_1  ;
    klee_make_symbolic(&ldv_timer_7_1, sizeof(int), "ldv_timer_7_1");
int ldv_timer_10_2  ;
    klee_make_symbolic(&ldv_timer_10_2, sizeof(int), "ldv_timer_10_2");
int LDV_IN_INTERRUPT  =    1;
int ldv_irq_1_1  =    0;
struct inode *bnad_debugfs_op_drvinfo_group1  ;
int ldv_timer_5_3  ;
    klee_make_symbolic(&ldv_timer_5_3, sizeof(int), "ldv_timer_5_3");
struct timer_list *ldv_timer_list_7_0  ;
struct ethtool_cmd *bnad_ethtool_ops_group1  ;
struct timer_list *ldv_timer_list_10_1  ;
struct ethtool_pauseparam *bnad_ethtool_ops_group3  ;
int ldv_state_variable_3  ;
    klee_make_symbolic(&ldv_state_variable_3, sizeof(int), "ldv_state_variable_3");
int ldv_irq_line_1_0  ;
    klee_make_symbolic(&ldv_irq_line_1_0, sizeof(int), "ldv_irq_line_1_0");
struct timer_list *ldv_timer_list_9_0  ;
int ldv_timer_8_3  ;
    klee_make_symbolic(&ldv_timer_8_3, sizeof(int), "ldv_timer_8_3");
int ldv_state_variable_4  ;
    klee_make_symbolic(&ldv_state_variable_4, sizeof(int), "ldv_state_variable_4");
int ldv_timer_7_3  ;
    klee_make_symbolic(&ldv_timer_7_3, sizeof(int), "ldv_timer_7_3");
int ldv_state_variable_8  ;
    klee_make_symbolic(&ldv_state_variable_8, sizeof(int), "ldv_state_variable_8");
struct inode *bnad_debugfs_op_regwr_group1  ;
int ldv_state_variable_15  ;
    klee_make_symbolic(&ldv_state_variable_15, sizeof(int), "ldv_state_variable_15");
struct ethtool_eeprom *bnad_ethtool_ops_group2  ;
struct timer_list *ldv_timer_list_5_2  ;
int ldv_state_variable_21  ;
    klee_make_symbolic(&ldv_state_variable_21, sizeof(int), "ldv_state_variable_21");
int ldv_state_variable_5  ;
    klee_make_symbolic(&ldv_state_variable_5, sizeof(int), "ldv_state_variable_5");
struct net_device *bnad_netdev_ops_group1  ;
int ldv_state_variable_13  ;
    klee_make_symbolic(&ldv_state_variable_13, sizeof(int), "ldv_state_variable_13");
int ldv_work_3_2  ;
    klee_make_symbolic(&ldv_work_3_2, sizeof(int), "ldv_work_3_2");
int ldv_timer_5_1  ;
    klee_make_symbolic(&ldv_timer_5_1, sizeof(int), "ldv_timer_5_1");
struct timer_list *ldv_timer_list_7_2  ;
struct file *bnad_debugfs_op_fwtrc_group2  ;
int ldv_work_3_0  ;
    klee_make_symbolic(&ldv_work_3_0, sizeof(int), "ldv_work_3_0");
struct file *bnad_debugfs_op_fwsave_group2  ;
struct timer_list *ldv_timer_list_6_1  ;
struct inode *bnad_debugfs_op_regrd_group1  ;
int ldv_irq_2_2  =    0;
int ldv_timer_7_0  ;
    klee_make_symbolic(&ldv_timer_7_0, sizeof(int), "ldv_timer_7_0");
struct bfa_ioc *nw_hwif_ct2_group0  ;
int ldv_irq_line_2_0  ;
    klee_make_symbolic(&ldv_irq_line_2_0, sizeof(int), "ldv_irq_line_2_0");
struct ethtool_ringparam *bnad_ethtool_ops_group0  ;
int ldv_state_variable_1  ;
    klee_make_symbolic(&ldv_state_variable_1, sizeof(int), "ldv_state_variable_1");
int ldv_irq_line_1_2  ;
    klee_make_symbolic(&ldv_irq_line_1_2, sizeof(int), "ldv_irq_line_1_2");
int ldv_timer_6_3  ;
    klee_make_symbolic(&ldv_timer_6_3, sizeof(int), "ldv_timer_6_3");
int ldv_timer_8_0  ;
    klee_make_symbolic(&ldv_timer_8_0, sizeof(int), "ldv_timer_8_0");
int ldv_irq_line_2_3  ;
    klee_make_symbolic(&ldv_irq_line_2_3, sizeof(int), "ldv_irq_line_2_3");
int ldv_timer_10_0  ;
    klee_make_symbolic(&ldv_timer_10_0, sizeof(int), "ldv_timer_10_0");
struct ethtool_coalesce *bnad_ethtool_ops_group4  ;
void *ldv_irq_data_1_1  ;
struct bfa_ioc *nw_hwif_ct_group0  ;
int ldv_state_variable_10  ;
    klee_make_symbolic(&ldv_state_variable_10, sizeof(int), "ldv_state_variable_10");
int ldv_irq_1_0  =    0;
int ldv_work_4_1  ;
    klee_make_symbolic(&ldv_work_4_1, sizeof(int), "ldv_work_4_1");
int ldv_work_4_3  ;
    klee_make_symbolic(&ldv_work_4_3, sizeof(int), "ldv_work_4_3");
int ldv_timer_8_1  ;
    klee_make_symbolic(&ldv_timer_8_1, sizeof(int), "ldv_timer_8_1");
int ldv_state_variable_16  ;
    klee_make_symbolic(&ldv_state_variable_16, sizeof(int), "ldv_state_variable_16");
int ldv_work_3_1  ;
    klee_make_symbolic(&ldv_work_3_1, sizeof(int), "ldv_work_3_1");
int ldv_irq_line_2_1  ;
    klee_make_symbolic(&ldv_irq_line_2_1, sizeof(int), "ldv_irq_line_2_1");
int ldv_state_variable_2  ;
    klee_make_symbolic(&ldv_state_variable_2, sizeof(int), "ldv_state_variable_2");
int ldv_timer_10_1  ;
    klee_make_symbolic(&ldv_timer_10_1, sizeof(int), "ldv_timer_10_1");
int ldv_timer_5_0  ;
    klee_make_symbolic(&ldv_timer_5_0, sizeof(int), "ldv_timer_5_0");
void *ldv_irq_data_1_2  ;
void *ldv_irq_data_2_0  ;
struct work_struct *ldv_work_struct_3_0  ;
int ldv_work_4_2  ;
    klee_make_symbolic(&ldv_work_4_2, sizeof(int), "ldv_work_4_2");
int ldv_state_variable_11  ;
    klee_make_symbolic(&ldv_state_variable_11, sizeof(int), "ldv_state_variable_11");
int ldv_timer_7_2  ;
    klee_make_symbolic(&ldv_timer_7_2, sizeof(int), "ldv_timer_7_2");
int ldv_irq_1_2  =    0;
int ldv_state_variable_18  ;
    klee_make_symbolic(&ldv_state_variable_18, sizeof(int), "ldv_state_variable_18");
int ldv_irq_2_3  =    0;
struct timer_list *ldv_timer_list_8_0  ;
struct timer_list *ldv_timer_list_10_3  ;
int ldv_irq_line_1_3  ;
    klee_make_symbolic(&ldv_irq_line_1_3, sizeof(int), "ldv_irq_line_1_3");
int ldv_timer_6_1  ;
    klee_make_symbolic(&ldv_timer_6_1, sizeof(int), "ldv_timer_6_1");
struct work_struct *ldv_work_struct_4_1  ;
struct inode *bnad_debugfs_op_fwsave_group1  ;
int ldv_timer_10_3  ;
    klee_make_symbolic(&ldv_timer_10_3, sizeof(int), "ldv_timer_10_3");
struct timer_list *ldv_timer_list_8_2  ;
struct timer_list *ldv_timer_list_9_1  ;
struct file *bnad_debugfs_op_drvinfo_group2  ;
void work_init_3(void) ;
void activate_suitable_timer_6(struct timer_list *timer , unsigned long data ) ;
void disable_suitable_irq_2(int line , void *data ) ;
int reg_timer_7(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) ;
void ldv_timer_5(int state , struct timer_list *timer ) ;
void choose_timer_5(void) ;
void activate_pending_timer_9(struct timer_list *timer , unsigned long data , int pending_flag ) ;
int reg_check_1(irqreturn_t (*handler)(int  , void * ) ) ;
void ldv_file_operations_15(void) ;
void disable_suitable_timer_8(struct timer_list *timer ) ;
void activate_work_3(struct work_struct *work , int state ) ;
void activate_pending_timer_10(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void ldv_file_operations_14(void) ;
void call_and_disable_all_4(int state ) ;
void ldv_initialize_bfa_ioc_hwif_11(void) ;
int reg_timer_10(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) ;
void call_and_disable_work_3(struct work_struct *work ) ;
void ldv_file_operations_16(void) ;
void timer_init_6(void) ;
void ldv_initialize_ethtool_ops_19(void) ;
void disable_work_3(struct work_struct *work ) ;
void ldv_timer_9(int state , struct timer_list *timer ) ;
void activate_pending_timer_8(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void ldv_timer_7(int state , struct timer_list *timer ) ;
void timer_init_5(void) ;
void disable_suitable_irq_1(int line , void *data ) ;
void activate_suitable_irq_1(int line , void *data ) ;
void invoke_work_4(void) ;
void timer_init_9(void) ;
void ldv_pci_driver_20(void) ;
void disable_suitable_timer_6(struct timer_list *timer ) ;
void ldv_file_operations_17(void) ;
void disable_suitable_timer_5(struct timer_list *timer ) ;
void ldv_timer_10(int state , struct timer_list *timer ) ;
int ldv_irq_2(int state , int line , void *data ) ;
void ldv_net_device_ops_21(void) ;
void activate_pending_timer_6(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void activate_suitable_timer_9(struct timer_list *timer , unsigned long data ) ;
void choose_interrupt_2(void) ;
void disable_suitable_timer_10(struct timer_list *timer ) ;
void activate_work_4(struct work_struct *work , int state ) ;
void choose_timer_8(void) ;
void disable_suitable_timer_7(struct timer_list *timer ) ;
int reg_timer_9(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) ;
void ldv_initialize_bfa_ioc_hwif_12(void) ;
void activate_suitable_irq_2(int line , void *data ) ;
int reg_timer_8(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) ;
void disable_suitable_timer_9(struct timer_list *timer ) ;
void choose_timer_6(void) ;
int reg_timer_6(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) ;
void activate_suitable_timer_10(struct timer_list *timer , unsigned long data ) ;
void ldv_timer_6(int state , struct timer_list *timer ) ;
void timer_init_7(void) ;
void choose_interrupt_1(void) ;
int reg_check_2(irqreturn_t (*handler)(int  , void * ) ) ;
void ldv_file_operations_18(void) ;
void choose_timer_9(void) ;
void timer_init_10(void) ;
void disable_work_4(struct work_struct *work ) ;
void work_init_4(void) ;
void invoke_work_3(void) ;
int ldv_irq_1(int state , int line , void *data ) ;
void ldv_timer_8(int state , struct timer_list *timer ) ;
void activate_pending_timer_5(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void choose_timer_7(void) ;
void timer_init_8(void) ;
void call_and_disable_all_3(int state ) ;
void activate_suitable_timer_8(struct timer_list *timer , unsigned long data ) ;
void choose_timer_10(void) ;
int reg_timer_5(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) ;
void call_and_disable_work_4(struct work_struct *work ) ;
void activate_suitable_timer_5(struct timer_list *timer , unsigned long data ) ;
void activate_pending_timer_7(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void activate_suitable_timer_7(struct timer_list *timer , unsigned long data ) ;
__inline static void *dev_get_drvdata(struct device  const  *dev ) 
{ 


  {
  return ((void *)dev->driver_data);
}
}
__inline static void dev_set_drvdata(struct device *dev , void *data ) 
{ 


  {
  dev->driver_data = data;
  return;
}
}
extern void dev_err(struct device  const  * , char const   *  , ...) ;
extern void dev_warn(struct device  const  * , char const   *  , ...) ;
extern void _dev_info(struct device  const  * , char const   *  , ...) ;
__inline static int PageTail(struct page  const  *page ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(15L, (unsigned long const volatile   *)(& page->flags));
  return (tmp);
}
}
__inline static struct page *compound_head_by_tail(struct page *tail ) 
{ 
  struct page *head ;
  int tmp ;
  long tmp___0 ;

  {
  head = tail->__annonCompField46.first_page;
  __asm__  volatile   ("": : : "memory");
  tmp = PageTail((struct page  const  *)tail);
  tmp___0 = ldv__builtin_expect(tmp != 0, 1L);
  if (tmp___0 != 0L) {
    return (head);
  } else {

  }
  return (tail);
}
}
__inline static struct page *compound_head(struct page *page ) 
{ 
  struct page *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp___0 = PageTail((struct page  const  *)page);
  tmp___1 = ldv__builtin_expect(tmp___0 != 0, 0L);
  if (tmp___1 != 0L) {
    tmp = compound_head_by_tail(page);
    return (tmp);
  } else {

  }
  return (page);
}
}
extern bool __get_page_tail(struct page * ) ;
__inline static void get_page(struct page *page ) 
{ 
  bool tmp ;
  long tmp___0 ;
  int tmp___1 ;
    klee_make_symbolic(&tmp___1, sizeof(int), "tmp___1");
  long tmp___2 ;
    klee_make_symbolic(&tmp___2, sizeof(long), "tmp___2");
  int tmp___3 ;
    klee_make_symbolic(&tmp___3, sizeof(int), "tmp___3");
  long tmp___4 ;

  {
  tmp___1 = PageTail((struct page  const  *)page);
  tmp___2 = ldv__builtin_expect(tmp___1 != 0, 0L);
  if (tmp___2 != 0L) {
    tmp = __get_page_tail(page);
    tmp___0 = ldv__builtin_expect((long )tmp, 1L);
    if (tmp___0 != 0L) {
      return;
    } else {

    }
  } else {

  }
  tmp___3 = atomic_read((atomic_t const   *)(& page->__annonCompField42.__annonCompField41.__annonCompField40._count));
  tmp___4 = ldv__builtin_expect(tmp___3 <= 0, 0L);
  if (tmp___4 != 0L) {
    dump_page(page, "VM_BUG_ON_PAGE(atomic_read(&page->_count) <= 0)");
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/mm.h"),
                         "i" (543), "i" (12UL));
    ldv_23242: ;
    goto ldv_23242;
  } else {

  }
  atomic_inc(& page->__annonCompField42.__annonCompField41.__annonCompField40._count);
  return;
}
}
extern void put_page(struct page * ) ;
__inline static void *lowmem_page_address(struct page  const  *page ) 
{ 


  {
  return ((void *)((unsigned long )((unsigned long long )(((long )page + 24189255811072L) / 64L) << 12) + 0xffff880000000000UL));
}
}
__inline static void kmemcheck_mark_initialized(void *address , unsigned int n ) 
{ 


  {
  return;
}
}
__inline static __sum16 csum_fold(__wsum sum ) 
{ 


  {
  __asm__  ("  addl %1,%0\n  adcl $0xffff,%0": "=r" (sum): "r" (sum << 16), "0" (sum & 4294901760U));
  return ((__sum16 )(~ sum >> 16));
}
}
__inline static __wsum csum_tcpudp_nofold(__be32 saddr , __be32 daddr , unsigned short len ,
                                          unsigned short proto , __wsum sum ) 
{ 


  {
  __asm__  ("  addl %1, %0\n  adcl %2, %0\n  adcl %3, %0\n  adcl $0, %0\n": "=r" (sum): "g" (daddr),
            "g" (saddr), "g" (((int )len + (int )proto) << 8), "0" (sum));
  return (sum);
}
}
__inline static __sum16 csum_tcpudp_magic(__be32 saddr , __be32 daddr , unsigned short len ,
                                          unsigned short proto , __wsum sum ) 
{ 
  __wsum tmp ;
  __sum16 tmp___0 ;

  {
  tmp = csum_tcpudp_nofold(saddr, daddr, (int )len, (int )proto, sum);
  tmp___0 = csum_fold(tmp);
  return (tmp___0);
}
}
extern __sum16 csum_ipv6_magic(struct in6_addr  const  * , struct in6_addr  const  * ,
                               __u32  , unsigned short  , __wsum  ) ;
__inline static int valid_dma_direction(int dma_direction ) 
{ 


  {
  return ((dma_direction == 0 || dma_direction == 1) || dma_direction == 2);
}
}
extern void debug_dma_map_page(struct device * , struct page * , size_t  , size_t  ,
                               int  , dma_addr_t  , bool  ) ;
extern void debug_dma_unmap_page(struct device * , dma_addr_t  , size_t  , int  ,
                                 bool  ) ;
extern struct dma_map_ops *dma_ops ;
__inline static struct dma_map_ops *get_dma_ops(struct device *dev ) 
{ 
  long tmp ;

  {
  tmp = ldv__builtin_expect((unsigned long )dev == (unsigned long )((struct device *)0),
                         0L);
  if (tmp != 0L || (unsigned long )dev->archdata.dma_ops == (unsigned long )((struct dma_map_ops *)0)) {
    return (dma_ops);
  } else {
    return (dev->archdata.dma_ops);
  }
}
}
__inline static dma_addr_t dma_map_single_attrs(struct device *dev , void *ptr , size_t size ,
                                                enum dma_data_direction dir , struct dma_attrs *attrs ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  dma_addr_t addr ;
  int tmp___0 ;
  long tmp___1 ;
  unsigned long tmp___2 ;
  unsigned long tmp___3 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  kmemcheck_mark_initialized(ptr, (unsigned int )size);
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (19), "i" (12UL));
    ldv_31784: ;
    goto ldv_31784;
  } else {

  }
  tmp___2 = __phys_addr((unsigned long )ptr);
  addr = (*(ops->map_page))(dev, (struct page *)-24189255811072L + (tmp___2 >> 12),
                            (unsigned long )ptr & 4095UL, size, dir, attrs);
  tmp___3 = __phys_addr((unsigned long )ptr);
  debug_dma_map_page(dev, (struct page *)-24189255811072L + (tmp___3 >> 12), (unsigned long )ptr & 4095UL,
                     size, (int )dir, addr, 1);
  return (addr);
}
}
__inline static void dma_unmap_single_attrs(struct device *dev , dma_addr_t addr ,
                                            size_t size , enum dma_data_direction dir ,
                                            struct dma_attrs *attrs ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (36), "i" (12UL));
    ldv_31793: ;
    goto ldv_31793;
  } else {

  }
  if ((unsigned long )ops->unmap_page != (unsigned long )((void (*)(struct device * ,
                                                                    dma_addr_t  ,
                                                                    size_t  , enum dma_data_direction  ,
                                                                    struct dma_attrs * ))0)) {
    (*(ops->unmap_page))(dev, addr, size, dir, attrs);
  } else {

  }
  debug_dma_unmap_page(dev, addr, size, (int )dir, 1);
  return;
}
}
__inline static dma_addr_t dma_map_page(struct device *dev , struct page *page , size_t offset ,
                                        size_t size , enum dma_data_direction dir ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  dma_addr_t addr ;
  void *tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = lowmem_page_address((struct page  const  *)page);
  kmemcheck_mark_initialized(tmp___0 + offset, (unsigned int )size);
  tmp___1 = valid_dma_direction((int )dir);
  tmp___2 = ldv__builtin_expect(tmp___1 == 0, 0L);
  if (tmp___2 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (84), "i" (12UL));
    ldv_31828: ;
    goto ldv_31828;
  } else {

  }
  addr = (*(ops->map_page))(dev, page, offset, size, dir, (struct dma_attrs *)0);
  debug_dma_map_page(dev, page, offset, size, (int )dir, addr, 0);
  return (addr);
}
}
__inline static void dma_unmap_page(struct device *dev , dma_addr_t addr , size_t size ,
                                    enum dma_data_direction dir ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (96), "i" (12UL));
    ldv_31836: ;
    goto ldv_31836;
  } else {

  }
  if ((unsigned long )ops->unmap_page != (unsigned long )((void (*)(struct device * ,
                                                                    dma_addr_t  ,
                                                                    size_t  , enum dma_data_direction  ,
                                                                    struct dma_attrs * ))0)) {
    (*(ops->unmap_page))(dev, addr, size, dir, (struct dma_attrs *)0);
  } else {

  }
  debug_dma_unmap_page(dev, addr, size, (int )dir, 0);
  return;
}
}
extern int dma_supported(struct device * , u64  ) ;
extern int dma_set_mask(struct device * , u64  ) ;
extern void *dma_alloc_attrs(struct device * , size_t  , dma_addr_t * , gfp_t  , struct dma_attrs * ) ;
extern void dma_free_attrs(struct device * , size_t  , void * , dma_addr_t  , struct dma_attrs * ) ;
__inline static int dma_set_coherent_mask(struct device *dev , u64 mask ) 
{ 
  int tmp ;

  {
  tmp = dma_supported(dev, mask);
  if (tmp == 0) {
    return (-5);
  } else {

  }
  dev->coherent_dma_mask = mask;
  return (0);
}
}
__inline static int dma_set_mask_and_coherent(struct device *dev , u64 mask ) 
{ 
  int rc ;
    klee_make_symbolic(&rc, sizeof(int), "rc");
  int tmp ;

  {
  tmp = dma_set_mask(dev, mask);
  rc = tmp;
  if (rc == 0) {
    dma_set_coherent_mask(dev, mask);
  } else {

  }
  return (rc);
}
}
__inline static unsigned int skb_frag_size(skb_frag_t const   *frag ) 
{ 


  {
  return ((unsigned int )frag->size);
}
}
__inline static void skb_frag_size_set(skb_frag_t *frag , unsigned int size ) 
{ 


  {
  frag->size = size;
  return;
}
}
struct sk_buff *ldv_skb_clone_33(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_41(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_35(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_31(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                            gfp_t flags ) ;
int ldv_pskb_expand_head_39(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                            gfp_t flags ) ;
int ldv_pskb_expand_head_40(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                            gfp_t flags ) ;
__inline static unsigned char *skb_end_pointer(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->end);
}
}
__inline static int skb_header_cloned(struct sk_buff  const  *skb ) 
{ 
  int dataref ;
    klee_make_symbolic(&dataref, sizeof(int), "dataref");
  unsigned char *tmp ;

  {
  if ((unsigned int )*((unsigned char *)skb + 142UL) == 0U) {
    return (0);
  } else {

  }
  tmp = skb_end_pointer(skb);
  dataref = atomic_read((atomic_t const   *)(& ((struct skb_shared_info *)tmp)->dataref));
  dataref = (dataref & 65535) - (dataref >> 16);
  return (dataref != 1);
}
}
__inline static unsigned int skb_headlen(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned int )skb->len - (unsigned int )skb->data_len);
}
}
__inline static void __skb_fill_page_desc(struct sk_buff *skb , int i , struct page *page ,
                                          int off , int size ) 
{ 
  skb_frag_t *frag ;
  unsigned char *tmp ;

  {
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  frag = (skb_frag_t *)(& ((struct skb_shared_info *)tmp)->frags) + (unsigned long )i;
  frag->page.p = page;
  frag->page_offset = (__u32 )off;
  skb_frag_size_set(frag, (unsigned int )size);
  page = compound_head(page);
  if ((int )page->__annonCompField42.__annonCompField37.pfmemalloc && (unsigned long )page->__annonCompField36.mapping == (unsigned long )((struct address_space *)0)) {
    skb->pfmemalloc = 1U;
  } else {

  }
  return;
}
}
__inline static void skb_fill_page_desc(struct sk_buff *skb , int i , struct page *page ,
                                        int off , int size ) 
{ 
  unsigned char *tmp ;

  {
  __skb_fill_page_desc(skb, i, page, off, size);
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  ((struct skb_shared_info *)tmp)->nr_frags = (unsigned int )((unsigned char )i) + 1U;
  return;
}
}
extern unsigned char *skb_put(struct sk_buff * , unsigned int  ) ;
extern unsigned char *__pskb_pull_tail(struct sk_buff * , int  ) ;
__inline static int pskb_may_pull(struct sk_buff *skb , unsigned int len ) 
{ 
  unsigned int tmp ;
  long tmp___0 ;
  long tmp___1 ;
  unsigned int tmp___2 ;
  unsigned char *tmp___3 ;

  {
  tmp = skb_headlen((struct sk_buff  const  *)skb);
  tmp___0 = ldv__builtin_expect(tmp >= len, 1L);
  if (tmp___0 != 0L) {
    return (1);
  } else {

  }
  tmp___1 = ldv__builtin_expect(skb->len < len, 0L);
  if (tmp___1 != 0L) {
    return (0);
  } else {

  }
  tmp___2 = skb_headlen((struct sk_buff  const  *)skb);
  tmp___3 = __pskb_pull_tail(skb, (int )(len - tmp___2));
  return ((unsigned long )tmp___3 != (unsigned long )((unsigned char *)0U));
}
}
__inline static unsigned int skb_headroom(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned int )((long )skb->data) - (unsigned int )((long )skb->head));
}
}
__inline static unsigned char *skb_transport_header(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->transport_header);
}
}
__inline static unsigned char *skb_network_header(struct sk_buff  const  *skb ) 
{ 


  {
  return ((unsigned char *)skb->head + (unsigned long )skb->network_header);
}
}
__inline static int skb_transport_offset(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_transport_header(skb);
  return ((int )((unsigned int )((long )tmp) - (unsigned int )((long )skb->data)));
}
}
void *ldv_malloc(size_t size ) ;
struct sk_buff *ldv___netdev_alloc_skb_36(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                          gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_37(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                          gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_38(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                          gfp_t flags ) ;
__inline static struct sk_buff *__netdev_alloc_skb_ip_align(struct net_device *dev ,
                                                            unsigned int length ,
                                                            gfp_t gfp ) 
{ 
  struct sk_buff *skb ;
  struct sk_buff *tmp ;

  {
  tmp = ldv___netdev_alloc_skb_38(dev, length, gfp);
  skb = tmp;
  return (skb);
}
}
__inline static struct sk_buff *netdev_alloc_skb_ip_align(struct net_device *dev ,
                                                          unsigned int length ) 
{ 
  struct sk_buff *tmp ;

  {
  tmp = __netdev_alloc_skb_ip_align(dev, length, 32U);
  return (tmp);
}
}
__inline static struct page *skb_frag_page(skb_frag_t const   *frag ) 
{ 


  {
  return ((struct page *)frag->page.p);
}
}
__inline static dma_addr_t skb_frag_dma_map(struct device *dev , skb_frag_t const   *frag ,
                                            size_t offset , size_t size , enum dma_data_direction dir ) 
{ 
  struct page *tmp ;
  dma_addr_t tmp___0 ;

  {
  tmp = skb_frag_page(frag);
  tmp___0 = dma_map_page(dev, tmp, (size_t )frag->page_offset + offset, size, dir);
  return (tmp___0);
}
}
__inline static int __skb_cow(struct sk_buff *skb , unsigned int headroom , int cloned ) 
{ 
  int delta ;
    klee_make_symbolic(&delta, sizeof(int), "delta");
  unsigned int tmp ;
  unsigned int tmp___0 ;
  int _max1 ;
    klee_make_symbolic(&_max1, sizeof(int), "_max1");
  int _max2 ;
    klee_make_symbolic(&_max2, sizeof(int), "_max2");
  int _max1___0 ;
    klee_make_symbolic(&_max1___0, sizeof(int), "_max1___0");
  int _max2___0 ;
    klee_make_symbolic(&_max2___0, sizeof(int), "_max2___0");
  int tmp___1 ;

  {
  delta = 0;
  tmp___0 = skb_headroom((struct sk_buff  const  *)skb);
  if (tmp___0 < headroom) {
    tmp = skb_headroom((struct sk_buff  const  *)skb);
    delta = (int )(headroom - tmp);
  } else {

  }
  if (delta != 0 || cloned != 0) {
    _max1 = 32;
    _max2 = 64;
    _max1___0 = 32;
    _max2___0 = 64;
    tmp___1 = ldv_pskb_expand_head_39(skb, (((_max1 > _max2 ? _max1 : _max2) + -1) + delta) & - (_max1___0 > _max2___0 ? _max1___0 : _max2___0),
                                      0, 32U);
    return (tmp___1);
  } else {

  }
  return (0);
}
}
__inline static int skb_cow_head(struct sk_buff *skb , unsigned int headroom ) 
{ 
  int tmp ;
  int tmp___0 ;

  {
  tmp = skb_header_cloned((struct sk_buff  const  *)skb);
  tmp___0 = __skb_cow(skb, headroom, tmp);
  return (tmp___0);
}
}
extern void skb_clone_tx_timestamp(struct sk_buff * ) ;
extern void skb_tstamp_tx(struct sk_buff * , struct skb_shared_hwtstamps * ) ;
__inline static void sw_tx_timestamp(struct sk_buff *skb ) 
{ 
  unsigned char *tmp ;
  unsigned char *tmp___0 ;

  {
  tmp = skb_end_pointer((struct sk_buff  const  *)skb);
  if (((int )((struct skb_shared_info *)tmp)->tx_flags & 2) != 0) {
    tmp___0 = skb_end_pointer((struct sk_buff  const  *)skb);
    if (((int )((struct skb_shared_info *)tmp___0)->tx_flags & 4) == 0) {
      skb_tstamp_tx(skb, (struct skb_shared_hwtstamps *)0);
    } else {

    }
  } else {

  }
  return;
}
}
__inline static void skb_tx_timestamp(struct sk_buff *skb ) 
{ 


  {
  skb_clone_tx_timestamp(skb);
  sw_tx_timestamp(skb);
  return;
}
}
__inline static bool skb_is_gso(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_end_pointer(skb);
  return ((unsigned int )((struct skb_shared_info *)tmp)->gso_size != 0U);
}
}
__inline static void skb_checksum_none_assert(struct sk_buff  const  *skb ) 
{ 


  {
  return;
}
}
extern void synchronize_irq(unsigned int  ) ;
extern int request_threaded_irq(unsigned int  , irqreturn_t (*)(int  , void * ) ,
                                irqreturn_t (*)(int  , void * ) , unsigned long  ,
                                char const   * , void * ) ;
__inline static int request_irq(unsigned int irq , irqreturn_t (*handler)(int  , void * ) ,
                                unsigned long flags , char const   *name , void *dev ) 
{ 
  int tmp ;

  {
  tmp = request_threaded_irq(irq, handler, (irqreturn_t (*)(int  , void * ))0, flags,
                             name, dev);
  return (tmp);
}
}
__inline static int ldv_request_irq_45(unsigned int irq , irqreturn_t (*handler)(int  ,
                                                                                 void * ) ,
                                       unsigned long flags , char const   *name ,
                                       void *dev ) ;
__inline static int ldv_request_irq_47(unsigned int irq , irqreturn_t (*handler)(int  ,
                                                                                 void * ) ,
                                       unsigned long flags , char const   *name ,
                                       void *dev ) ;
__inline static int ldv_request_irq_49(unsigned int irq , irqreturn_t (*handler)(int  ,
                                                                                 void * ) ,
                                       unsigned long flags , char const   *name ,
                                       void *dev ) ;
extern void free_irq(unsigned int  , void * ) ;
void ldv_free_irq_44(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) ;
void ldv_free_irq_46(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) ;
void ldv_free_irq_48(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) ;
extern void __napi_schedule(struct napi_struct * ) ;
__inline static bool napi_disable_pending(struct napi_struct *n ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& n->state));
  return (tmp != 0);
}
}
__inline static bool napi_schedule_prep(struct napi_struct *n ) 
{ 
  bool tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
  tmp = napi_disable_pending(n);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    tmp___1 = test_and_set_bit(0L, (unsigned long volatile   *)(& n->state));
    if (tmp___1 == 0) {
      tmp___2 = 1;
    } else {
      tmp___2 = 0;
    }
  } else {
    tmp___2 = 0;
  }
  return ((bool )tmp___2);
}
}
__inline static void napi_complete(struct napi_struct *n ) 
{ 


  {
  return;
}
}
extern void napi_disable(struct napi_struct * ) ;
__inline static void napi_enable(struct napi_struct *n ) 
{ 
  int tmp ;
  long tmp___0 ;

  {
  tmp = constant_test_bit(0L, (unsigned long const volatile   *)(& n->state));
  tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/netdevice.h"),
                         "i" (507), "i" (12UL));
    ldv_42066: ;
    goto ldv_42066;
  } else {

  }
  __asm__  volatile   ("": : : "memory");
  clear_bit(0L, (unsigned long volatile   *)(& n->state));
  return;
}
}
__inline static struct netdev_queue *netdev_get_tx_queue(struct net_device  const  *dev ,
                                                         unsigned int index ) 
{ 


  {
  return ((struct netdev_queue *)dev->_tx + (unsigned long )index);
}
}
__inline static void *netdev_priv(struct net_device  const  *dev ) 
{ 


  {
  return ((void *)dev + 3008U);
}
}
extern void netif_napi_add(struct net_device * , struct napi_struct * , int (*)(struct napi_struct * ,
                                                                                int  ) ,
                           int  ) ;
extern void netif_napi_del(struct napi_struct * ) ;
extern void free_netdev(struct net_device * ) ;
void ldv_free_netdev_61(struct net_device *dev ) ;
void ldv_free_netdev_66(struct net_device *dev ) ;
extern void netif_tx_wake_queue(struct netdev_queue * ) ;
__inline static void netif_wake_queue(struct net_device *dev ) 
{ 
  struct netdev_queue *tmp ;

  {
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, 0U);
  netif_tx_wake_queue(tmp);
  return;
}
}
__inline static void netif_tx_stop_queue(struct netdev_queue *dev_queue ) 
{ 


  {
  set_bit(0L, (unsigned long volatile   *)(& dev_queue->state));
  return;
}
}
__inline static void netif_stop_queue(struct net_device *dev ) 
{ 
  struct netdev_queue *tmp ;

  {
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, 0U);
  netif_tx_stop_queue(tmp);
  return;
}
}
__inline static bool netif_tx_queue_stopped(struct netdev_queue  const  *dev_queue ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(0L, (unsigned long const volatile   *)(& dev_queue->state));
  return (tmp != 0);
}
}
__inline static bool netif_queue_stopped(struct net_device  const  *dev ) 
{ 
  struct netdev_queue *tmp ;
  bool tmp___0 ;

  {
  tmp = netdev_get_tx_queue(dev, 0U);
  tmp___0 = netif_tx_queue_stopped((struct netdev_queue  const  *)tmp);
  return (tmp___0);
}
}
__inline static bool netif_running(struct net_device  const  *dev ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(0L, (unsigned long const volatile   *)(& dev->state));
  return (tmp != 0);
}
}
__inline static void netif_stop_subqueue(struct net_device *dev , u16 queue_index ) 
{ 
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;

  {
  tmp = netdev_get_tx_queue((struct net_device  const  *)dev, (unsigned int )queue_index);
  txq = tmp;
  netif_tx_stop_queue(txq);
  return;
}
}
extern void netif_wake_subqueue(struct net_device * , u16  ) ;
extern void __dev_kfree_skb_any(struct sk_buff * , enum skb_free_reason  ) ;
__inline static void dev_kfree_skb_any(struct sk_buff *skb ) 
{ 


  {
  __dev_kfree_skb_any(skb, 1);
  return;
}
}
extern int netif_receive_skb_sk(struct sock * , struct sk_buff * ) ;
__inline static int netif_receive_skb(struct sk_buff *skb ) 
{ 
  int tmp ;

  {
  tmp = netif_receive_skb_sk(skb->sk, skb);
  return (tmp);
}
}
extern void napi_gro_flush(struct napi_struct * , bool  ) ;
extern struct sk_buff *napi_get_frags(struct napi_struct * ) ;
extern gro_result_t napi_gro_frags(struct napi_struct * ) ;
__inline static bool netif_carrier_ok(struct net_device  const  *dev ) 
{ 
  int tmp ;

  {
  tmp = constant_test_bit(2L, (unsigned long const volatile   *)(& dev->state));
  return (tmp == 0);
}
}
extern void netif_carrier_on(struct net_device * ) ;
extern void netif_carrier_off(struct net_device * ) ;
extern int register_netdev(struct net_device * ) ;
int ldv_register_netdev_57(struct net_device *dev ) ;
extern void unregister_netdev(struct net_device * ) ;
void ldv_unregister_netdev_62(struct net_device *dev ) ;
extern void netdev_rss_key_fill(void * , size_t  ) ;
extern void netdev_err(struct net_device  const  * , char const   *  , ...) ;
extern void netdev_info(struct net_device  const  * , char const   *  , ...) ;
extern __be16 eth_type_trans(struct sk_buff * , struct net_device * ) ;
extern int eth_validate_addr(struct net_device * ) ;
extern struct net_device *alloc_etherdev_mqs(int  , unsigned int  , unsigned int  ) ;
__inline static bool is_zero_ether_addr(u8 const   *addr ) 
{ 


  {
  return (((unsigned int )*((u32 const   *)addr) | (unsigned int )*((u16 const   *)addr + 4U)) == 0U);
}
}
__inline static bool is_multicast_ether_addr(u8 const   *addr ) 
{ 
  u32 a ;

  {
  a = *((u32 const   *)addr);
  return ((a & 1U) != 0U);
}
}
__inline static bool is_valid_ether_addr(u8 const   *addr ) 
{ 
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
  tmp = is_multicast_ether_addr(addr);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    tmp___1 = is_zero_ether_addr(addr);
    if (tmp___1) {
      tmp___2 = 0;
    } else {
      tmp___2 = 1;
    }
    if (tmp___2) {
      tmp___3 = 1;
    } else {
      tmp___3 = 0;
    }
  } else {
    tmp___3 = 0;
  }
  return ((bool )tmp___3);
}
}
__inline static void ether_addr_copy(u8 *dst , u8 const   *src ) 
{ 


  {
  *((u32 *)dst) = *((u32 const   *)src);
  *((u16 *)dst + 4U) = *((u16 const   *)src + 4U);
  return;
}
}
__inline static void __vlan_hwaccel_put_tag(struct sk_buff *skb , __be16 vlan_proto ,
                                            u16 vlan_tci ) 
{ 


  {
  skb->vlan_proto = vlan_proto;
  skb->vlan_tci = (__u16 )((unsigned int )vlan_tci | 4096U);
  return;
}
}
__inline static __be16 __vlan_get_protocol(struct sk_buff *skb , __be16 type , int *depth ) 
{ 
  unsigned int vlan_depth ;
    klee_make_symbolic(&vlan_depth, sizeof(int), "vlan_depth");
  int __ret_warn_on ;
    klee_make_symbolic(&__ret_warn_on, sizeof(int), "__ret_warn_on");
  long tmp ;
  long tmp___0 ;
  struct vlan_hdr *vh ;
  int tmp___1 ;
  long tmp___2 ;

  {
  vlan_depth = (unsigned int )skb->mac_len;
  if ((unsigned int )type == 129U || (unsigned int )type == 43144U) {
    if (vlan_depth != 0U) {
      __ret_warn_on = vlan_depth <= 3U;
      tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
      if (tmp != 0L) {
        warn_slowpath_null("include/linux/if_vlan.h", 492);
      } else {

      }
      tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
      if (tmp___0 != 0L) {
        return (0U);
      } else {

      }
      vlan_depth = vlan_depth - 4U;
    } else {
      vlan_depth = 14U;
    }
    ldv_44952: 
    tmp___1 = pskb_may_pull(skb, vlan_depth + 4U);
    tmp___2 = ldv__builtin_expect(tmp___1 == 0, 0L);
    if (tmp___2 != 0L) {
      return (0U);
    } else {

    }
    vh = (struct vlan_hdr *)skb->data + (unsigned long )vlan_depth;
    type = vh->h_vlan_encapsulated_proto;
    vlan_depth = vlan_depth + 4U;
    if ((unsigned int )type == 129U || (unsigned int )type == 43144U) {
      goto ldv_44952;
    } else {

    }

  } else {

  }
  if ((unsigned long )depth != (unsigned long )((int *)0)) {
    *depth = (int )vlan_depth;
  } else {

  }
  return (type);
}
}
__inline static __be16 vlan_get_protocol(struct sk_buff *skb ) 
{ 
  __be16 tmp ;

  {
  tmp = __vlan_get_protocol(skb, (int )skb->protocol, (int *)0);
  return (tmp);
}
}
__inline static struct iphdr *ip_hdr(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_network_header(skb);
  return ((struct iphdr *)tmp);
}
}
__inline static struct tcphdr *tcp_hdr(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_transport_header(skb);
  return ((struct tcphdr *)tmp);
}
}
__inline static unsigned int tcp_hdrlen(struct sk_buff  const  *skb ) 
{ 
  struct tcphdr *tmp ;

  {
  tmp = tcp_hdr(skb);
  return ((unsigned int )((int )tmp->doff * 4));
}
}
__inline static struct ipv6hdr *ipv6_hdr(struct sk_buff  const  *skb ) 
{ 
  unsigned char *tmp ;

  {
  tmp = skb_network_header(skb);
  return ((struct ipv6hdr *)tmp);
}
}
extern void release_firmware(struct firmware  const  * ) ;
extern int pci_enable_device(struct pci_dev * ) ;
extern void pci_disable_device(struct pci_dev * ) ;
extern void pci_set_master(struct pci_dev * ) ;
extern void pci_intx(struct pci_dev * , int  ) ;
extern int pci_request_regions(struct pci_dev * , char const   * ) ;
extern void pci_release_regions(struct pci_dev * ) ;
extern int __pci_register_driver(struct pci_driver * , struct module * , char const   * ) ;
int ldv___pci_register_driver_67(struct pci_driver *ldv_func_arg1 , struct module *ldv_func_arg2 ,
                                 char const   *ldv_func_arg3 ) ;
extern void pci_unregister_driver(struct pci_driver * ) ;
void ldv_pci_unregister_driver_68(struct pci_driver *ldv_func_arg1 ) ;
extern void pci_disable_msix(struct pci_dev * ) ;
extern int pci_enable_msix_range(struct pci_dev * , struct msix_entry * , int  , int  ) ;
__inline static void *pci_get_drvdata(struct pci_dev *pdev ) 
{ 
  void *tmp ;

  {
  tmp = dev_get_drvdata((struct device  const  *)(& pdev->dev));
  return (tmp);
}
}
__inline static void pci_set_drvdata(struct pci_dev *pdev , void *data ) 
{ 


  {
  dev_set_drvdata(& pdev->dev, data);
  return;
}
}
void bfa_nw_ioc_auto_recover(bool auto_recover ) ;
void bfa_nw_ioc_timeout(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_hb_check(struct bfa_ioc *ioc ) ;
void bfa_nw_iocpf_timeout(struct bfa_ioc *ioc ) ;
void bfa_nw_iocpf_sem_timeout(struct bfa_ioc *ioc ) ;
u32 const   bna_napi_dim_vector[8U][2U] ;
void bna_res_req(struct bna_res_info *res_info ) ;
void bna_mod_res_req(struct bna *bna , struct bna_res_info *res_info ) ;
void bna_init(struct bna *bna , struct bnad *bnad , struct bfa_pcidev *pcidev , struct bna_res_info *res_info ) ;
void bna_mod_init(struct bna *bna , struct bna_res_info *res_info ) ;
void bna_uninit(struct bna *bna ) ;
int bna_num_txq_set(struct bna *bna , int num_txq ) ;
int bna_num_rxp_set(struct bna *bna , int num_rxp ) ;
void bna_hw_stats_get(struct bna *bna ) ;
void bna_mbox_handler(struct bna *bna , u32 intr_status ) ;
void bna_tx_res_req(int num_txq , int txq_depth , struct bna_res_info *res_info ) ;
struct bna_tx *bna_tx_create(struct bna *bna , struct bnad *bnad , struct bna_tx_config *tx_cfg ,
                             struct bna_tx_event_cbfn  const  *tx_cbfn , struct bna_res_info *res_info ,
                             void *priv ) ;
void bna_tx_destroy(struct bna_tx *tx ) ;
void bna_tx_enable(struct bna_tx *tx ) ;
void bna_tx_disable(struct bna_tx *tx , enum bna_cleanup_type type , void (*cbfn)(void * ,
                                                                                  struct bna_tx * ) ) ;
void bna_tx_cleanup_complete(struct bna_tx *tx ) ;
void bna_tx_coalescing_timeo_set(struct bna_tx *tx , int coalescing_timeo ) ;
void bna_rx_res_req(struct bna_rx_config *q_cfg , struct bna_res_info *res_info ) ;
struct bna_rx *bna_rx_create(struct bna *bna , struct bnad *bnad , struct bna_rx_config *rx_cfg ,
                             struct bna_rx_event_cbfn  const  *rx_cbfn , struct bna_res_info *res_info ,
                             void *priv ) ;
void bna_rx_destroy(struct bna_rx *rx ) ;
void bna_rx_enable(struct bna_rx *rx ) ;
void bna_rx_disable(struct bna_rx *rx , enum bna_cleanup_type type , void (*cbfn)(void * ,
                                                                                  struct bna_rx * ) ) ;
void bna_rx_cleanup_complete(struct bna_rx *rx ) ;
void bna_rx_coalescing_timeo_set(struct bna_rx *rx , int coalescing_timeo ) ;
void bna_rx_dim_reconfig(struct bna *bna , u32 const   (*vector)[2] ) ;
void bna_rx_dim_update(struct bna_ccb *ccb ) ;
enum bna_cb_status bna_rx_ucast_set(struct bna_rx *rx , u8 const   *ucmac ) ;
enum bna_cb_status bna_rx_ucast_listset(struct bna_rx *rx , int count , u8 const   *uclist ) ;
enum bna_cb_status bna_rx_mcast_add(struct bna_rx *rx , u8 const   *addr , void (*cbfn)(struct bnad * ,
                                                                                        struct bna_rx * ) ) ;
enum bna_cb_status bna_rx_mcast_listset(struct bna_rx *rx , int count , u8 const   *mclist ) ;
void bna_rx_mcast_delall(struct bna_rx *rx ) ;
enum bna_cb_status bna_rx_mode_set(struct bna_rx *rx , enum bna_rxmode new_mode ,
                                   enum bna_rxmode bitmask ) ;
void bna_rx_vlan_add(struct bna_rx *rx , int vlan_id ) ;
void bna_rx_vlan_del(struct bna_rx *rx , int vlan_id ) ;
void bna_rx_vlanfilter_enable(struct bna_rx *rx ) ;
void bna_rx_vlan_strip_enable(struct bna_rx *rx ) ;
void bna_rx_vlan_strip_disable(struct bna_rx *rx ) ;
void bna_enet_enable(struct bna_enet *enet ) ;
void bna_enet_disable(struct bna_enet *enet , enum bna_cleanup_type type , void (*cbfn)(void * ) ) ;
void bna_enet_pause_config(struct bna_enet *enet , struct bna_pause_config *pause_config ) ;
void bna_enet_mtu_set(struct bna_enet *enet , int mtu , void (*cbfn)(struct bnad * ) ) ;
void bna_enet_perm_mac_get(struct bna_enet *enet , u8 *mac ) ;
void bna_ioceth_enable(struct bna_ioceth *ioceth ) ;
void bna_ioceth_disable(struct bna_ioceth *ioceth , enum bna_cleanup_type type ) ;
void bnad_cb_ethport_link_status(struct bnad *bnad , enum bna_link_status link_status ) ;
void bnad_cb_ioceth_ready(struct bnad *bnad ) ;
void bnad_cb_ioceth_failed(struct bnad *bnad ) ;
void bnad_cb_ioceth_disabled(struct bnad *bnad ) ;
void bnad_cb_mbox_intr_enable(struct bnad *bnad ) ;
void bnad_cb_mbox_intr_disable(struct bnad *bnad ) ;
void bnad_cb_stats_get(struct bnad *bnad , enum bna_cb_status status , struct bna_stats *stats ) ;
struct firmware  const  *bfi_fw ;
u32 *cna_get_firmware_buf(struct pci_dev *pdev ) ;
void bnad_set_rx_mode(struct net_device *netdev ) ;
int bnad_mac_addr_set_locked(struct bnad *bnad , u8 const   *mac_addr ) ;
int bnad_enable_default_bcast(struct bnad *bnad ) ;
void bnad_restore_vlans(struct bnad *bnad , u32 rx_id ) ;
void bnad_set_ethtool_ops(struct net_device *netdev ) ;
void bnad_cb_completion(void *arg , enum bfa_status status ) ;
void bnad_tx_coalescing_timeo_set(struct bnad *bnad ) ;
void bnad_rx_coalescing_timeo_set(struct bnad *bnad ) ;
int bnad_setup_rx(struct bnad *bnad , u32 rx_id ) ;
int bnad_setup_tx(struct bnad *bnad , u32 tx_id ) ;
void bnad_destroy_tx(struct bnad *bnad , u32 tx_id ) ;
void bnad_destroy_rx(struct bnad *bnad , u32 rx_id ) ;
void bnad_dim_timer_start(struct bnad *bnad ) ;
void bnad_netdev_qstats_fill(struct bnad *bnad , struct rtnl_link_stats64 *stats ) ;
void bnad_netdev_hwstats_fill(struct bnad *bnad , struct rtnl_link_stats64 *stats ) ;
void bnad_debugfs_init(struct bnad *bnad ) ;
void bnad_debugfs_uninit(struct bnad *bnad ) ;
static struct mutex bnad_fwimg_mutex  =    {{1}, {{{{{0}}, 3735899821U, 4294967295U, (void *)-1, {0, {0, 0}, "bnad_fwimg_mutex.wait_lock",
                                                          0, 0UL}}}}, {& bnad_fwimg_mutex.wait_list,
                                                                       & bnad_fwimg_mutex.wait_list},
    0, (void *)(& bnad_fwimg_mutex), {0, {0, 0}, "bnad_fwimg_mutex", 0, 0UL}};
static uint bnad_msix_disable  ;
    klee_make_symbolic(&bnad_msix_disable, sizeof(int), "bnad_msix_disable");
static uint bnad_ioc_auto_recover  =    1U;
static uint bna_debugfs_enable  =    1U;
static u32 bnad_rxqs_per_cq  =    2U;
static u32 bna_id  ;
static struct mutex bnad_list_mutex  ;
static struct list_head bnad_list  =    {& bnad_list, & bnad_list};
static u8 const   bnad_bcast_addr[6U]  = {      255U,      255U,      255U,      255U, 
        255U,      255U};
static void bnad_add_to_list(struct bnad *bnad ) 
{ 
  u32 tmp ;

  {
  mutex_lock_nested(& bnad_list_mutex, 0U);
  list_add_tail(& bnad->list_entry, & bnad_list);
  tmp = bna_id;
  bna_id = bna_id + 1U;
  bnad->id = tmp;
  mutex_unlock(& bnad_list_mutex);
  return;
}
}
static void bnad_remove_from_list(struct bnad *bnad ) 
{ 


  {
  mutex_lock_nested(& bnad_list_mutex, 0U);
  list_del(& bnad->list_entry);
  mutex_unlock(& bnad_list_mutex);
  return;
}
}
static void bnad_cq_cleanup(struct bnad *bnad , struct bna_ccb *ccb ) 
{ 
  struct bna_cq_entry *cmpl ;
  int i ;
    klee_make_symbolic(&i, sizeof(int), "i");

  {
  i = 0;
  goto ldv_58411;
  ldv_58410: 
  cmpl = (struct bna_cq_entry *)ccb->sw_q + (unsigned long )i;
  cmpl->valid = 0U;
  i = i + 1;
  ldv_58411: ;
  if ((u32 )i < ccb->q_depth) {
    goto ldv_58410;
  } else {

  }

  return;
}
}
static u32 bnad_tx_buff_unmap(struct bnad *bnad , struct bnad_tx_unmap *unmap_q ,
                              u32 q_depth , u32 index ) 
{ 
  struct bnad_tx_unmap *unmap ;
  struct sk_buff *skb ;
  int vector ;
  int nvecs ;
    klee_make_symbolic(&nvecs, sizeof(int), "nvecs");
  unsigned int tmp ;

  {
  unmap = unmap_q + (unsigned long )index;
  nvecs = (int )unmap->nvecs;
  skb = unmap->skb;
  unmap->skb = (struct sk_buff *)0;
  unmap->nvecs = 0U;
  tmp = skb_headlen((struct sk_buff  const  *)skb);
  dma_unmap_single_attrs(& (bnad->pcidev)->dev, ((struct bnad_tx_vector *)(& unmap->vectors))->dma_addr,
                         (size_t )tmp, 1, (struct dma_attrs *)0);
  ((struct bnad_tx_vector *)(& unmap->vectors))->dma_addr = 0ULL;
  nvecs = nvecs - 1;
  vector = 0;
  goto ldv_58424;
  ldv_58423: 
  vector = vector + 1;
  if (vector == 4) {
    vector = 0;
    index = (index + 1U) & (q_depth - 1U);
    unmap = unmap_q + (unsigned long )index;
  } else {

  }
  dma_unmap_page(& (bnad->pcidev)->dev, ((struct bnad_tx_vector *)(& unmap->vectors) + (unsigned long )vector)->dma_addr,
                 (size_t )((struct bnad_tx_vector *)(& unmap->vectors) + (unsigned long )vector)->dma_len,
                 1);
  ((struct bnad_tx_vector *)(& unmap->vectors) + (unsigned long )vector)->dma_addr = 0ULL;
  nvecs = nvecs - 1;
  ldv_58424: ;
  if (nvecs != 0) {
    goto ldv_58423;
  } else {

  }
  index = (index + 1U) & (q_depth - 1U);
  return (index);
}
}
static void bnad_txq_cleanup(struct bnad *bnad , struct bna_tcb *tcb ) 
{ 
  struct bnad_tx_unmap *unmap_q ;
  struct sk_buff *skb ;
  int i ;

  {
  unmap_q = (struct bnad_tx_unmap *)tcb->unmap_q;
  i = 0;
  goto ldv_58435;
  ldv_58434: 
  skb = (unmap_q + (unsigned long )i)->skb;
  if ((unsigned long )skb == (unsigned long )((struct sk_buff *)0)) {
    goto ldv_58433;
  } else {

  }
  bnad_tx_buff_unmap(bnad, unmap_q, tcb->q_depth, (u32 )i);
  dev_kfree_skb_any(skb);
  ldv_58433: 
  i = i + 1;
  ldv_58435: ;
  if ((u32 )i < tcb->q_depth) {
    goto ldv_58434;
  } else {

  }

  return;
}
}
static u32 bnad_txcmpl_process(struct bnad *bnad , struct bna_tcb *tcb ) 
{ 
  u32 sent_packets ;
  u32 sent_bytes ;
  u32 wis ;
  u32 unmap_wis ;
  u32 hw_cons ;
  u32 cons ;
  u32 q_depth ;
  struct bnad_tx_unmap *unmap_q ;
  struct bnad_tx_unmap *unmap ;
  struct sk_buff *skb ;
  int tmp ;
  long tmp___0 ;

  {
  sent_packets = 0U;
  sent_bytes = 0U;
  unmap_q = (struct bnad_tx_unmap *)tcb->unmap_q;
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& tcb->flags));
  if (tmp == 0) {
    return (0U);
  } else {

  }
  hw_cons = *(tcb->hw_consumer_index);
  cons = tcb->consumer_index;
  q_depth = tcb->q_depth;
  wis = (hw_cons - cons) & (q_depth - 1U);
  tmp___0 = ldv__builtin_expect(((tcb->producer_index - tcb->consumer_index) & (tcb->q_depth - 1U)) < wis,
                             0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bnad.c"),
                         "i" (203), "i" (12UL));
    ldv_58451: ;
    goto ldv_58451;
  } else {

  }
  goto ldv_58453;
  ldv_58452: 
  unmap = unmap_q + (unsigned long )cons;
  skb = unmap->skb;
  sent_packets = sent_packets + 1U;
  sent_bytes = skb->len + sent_bytes;
  unmap_wis = (unmap->nvecs + 3U) >> 2;
  wis = wis - unmap_wis;
  cons = bnad_tx_buff_unmap(bnad, unmap_q, q_depth, cons);
  dev_kfree_skb_any(skb);
  ldv_58453: ;
  if (wis != 0U) {
    goto ldv_58452;
  } else {

  }
  tcb->consumer_index = hw_cons;
  (tcb->txq)->tx_packets = (tcb->txq)->tx_packets + (u64 )sent_packets;
  (tcb->txq)->tx_bytes = (tcb->txq)->tx_bytes + (u64 )sent_bytes;
  return (sent_packets);
}
}
static u32 bnad_tx_complete(struct bnad *bnad , struct bna_tcb *tcb ) 
{ 
  struct net_device *netdev ;
  u32 sent ;
  int tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  long tmp___4 ;

  {
  netdev = bnad->netdev;
  sent = 0U;
  tmp = test_and_set_bit(0L, (unsigned long volatile   *)(& tcb->flags));
  if (tmp != 0) {
    return (0U);
  } else {

  }
  sent = bnad_txcmpl_process(bnad, tcb);
  if (sent != 0U) {
    tmp___1 = netif_queue_stopped((struct net_device  const  *)netdev);
    if ((int )tmp___1) {
      tmp___2 = netif_carrier_ok((struct net_device  const  *)netdev);
      if ((int )tmp___2) {
        if ((((tcb->consumer_index - tcb->producer_index) - 1U) & (tcb->q_depth - 1U)) > 7U) {
          tmp___0 = constant_test_bit(1L, (unsigned long const volatile   *)(& tcb->flags));
          if (tmp___0 != 0) {
            netif_wake_queue(netdev);
            bnad->stats.drv_stats.netif_queue_wakeup = bnad->stats.drv_stats.netif_queue_wakeup + 1ULL;
          } else {

          }
        } else {

        }
      } else {

      }
    } else {

    }
  } else {

  }
  tmp___3 = constant_test_bit(1L, (unsigned long const volatile   *)(& tcb->flags));
  tmp___4 = ldv__builtin_expect(tmp___3 != 0, 1L);
  if (tmp___4 != 0L) {
    writel((tcb->i_dbell)->doorbell_ack | sent, (void volatile   *)(tcb->i_dbell)->doorbell_addr);
  } else {

  }
  __asm__  volatile   ("": : : "memory");
  clear_bit(0L, (unsigned long volatile   *)(& tcb->flags));
  return (sent);
}
}
static irqreturn_t bnad_msix_tx(int irq , void *data ) 
{ 
  struct bna_tcb *tcb ;
  struct bnad *bnad ;

  {
  tcb = (struct bna_tcb *)data;
  bnad = tcb->bnad;
  bnad_tx_complete(bnad, tcb);
  return (1);
}
}
__inline static void bnad_rxq_alloc_uninit(struct bnad *bnad , struct bna_rcb *rcb ) 
{ 
  struct bnad_rx_unmap_q *unmap_q ;

  {
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  unmap_q->reuse_pi = -1;
  unmap_q->alloc_order = -1;
  unmap_q->map_size = 0U;
  unmap_q->type = 0;
  return;
}
}
static int bnad_rxq_alloc_init(struct bnad *bnad , struct bna_rcb *rcb ) 
{ 
  struct bnad_rx_unmap_q *unmap_q ;
  int order ;
  long tmp ;

  {
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  bnad_rxq_alloc_uninit(bnad, rcb);
  order = __get_order((unsigned long )(rcb->rxq)->buffer_size);
  unmap_q->type = 2;
  if (rcb->id & 1) {
    unmap_q->alloc_order = 0;
    unmap_q->map_size = (u32 )(rcb->rxq)->buffer_size;
  } else
  if ((unsigned int )(rcb->rxq)->multi_buffer != 0U) {
    unmap_q->alloc_order = 0;
    unmap_q->map_size = (u32 )(rcb->rxq)->buffer_size;
    unmap_q->type = 3;
  } else {
    unmap_q->alloc_order = order;
    unmap_q->map_size = (rcb->rxq)->buffer_size > 2048 ? (u32 )(4096UL << order) : 2048U;
  }
  tmp = ldv__builtin_expect((4096UL << order) % (unsigned long )unmap_q->map_size != 0UL,
                         0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bnad.c"),
                         "i" (312), "i" (12UL));
    ldv_58478: ;
    goto ldv_58478;
  } else {

  }
  return (0);
}
}
__inline static void bnad_rxq_cleanup_page(struct bnad *bnad , struct bnad_rx_unmap *unmap ) 
{ 


  {
  if ((unsigned long )unmap->page == (unsigned long )((struct page *)0)) {
    return;
  } else {

  }
  dma_unmap_page(& (bnad->pcidev)->dev, unmap->vector.dma_addr, (size_t )unmap->vector.len,
                 2);
  put_page(unmap->page);
  unmap->page = (struct page *)0;
  unmap->vector.dma_addr = 0ULL;
  unmap->vector.len = 0U;
  return;
}
}
__inline static void bnad_rxq_cleanup_skb(struct bnad *bnad , struct bnad_rx_unmap *unmap ) 
{ 


  {
  if ((unsigned long )unmap->skb == (unsigned long )((struct sk_buff *)0)) {
    return;
  } else {

  }
  dma_unmap_single_attrs(& (bnad->pcidev)->dev, unmap->vector.dma_addr, (size_t )unmap->vector.len,
                         2, (struct dma_attrs *)0);
  dev_kfree_skb_any(unmap->skb);
  unmap->skb = (struct sk_buff *)0;
  unmap->vector.dma_addr = 0ULL;
  unmap->vector.len = 0U;
  return;
}
}
static void bnad_rxq_cleanup(struct bnad *bnad , struct bna_rcb *rcb ) 
{ 
  struct bnad_rx_unmap_q *unmap_q ;
  int i ;
  struct bnad_rx_unmap *unmap ;

  {
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  i = 0;
  goto ldv_58495;
  ldv_58494: 
  unmap = (struct bnad_rx_unmap *)(& unmap_q->unmap) + (unsigned long )i;
  if ((unsigned int )unmap_q->type == 1U) {
    bnad_rxq_cleanup_skb(bnad, unmap);
  } else {
    bnad_rxq_cleanup_page(bnad, unmap);
  }
  i = i + 1;
  ldv_58495: ;
  if ((u32 )i < rcb->q_depth) {
    goto ldv_58494;
  } else {

  }
  bnad_rxq_alloc_uninit(bnad, rcb);
  return;
}
}
static u32 bnad_rxq_refill_page(struct bnad *bnad , struct bna_rcb *rcb , u32 nalloc ) 
{ 
  u32 alloced ;
  u32 prod ;
  u32 q_depth ;
  struct bnad_rx_unmap_q *unmap_q ;
  struct bnad_rx_unmap *unmap ;
  struct bnad_rx_unmap *prev ;
  struct bna_rxq_entry *rxent ;
  struct page *page ;
  u32 page_offset ;
  u32 alloc_size ;
  dma_addr_t dma_addr ;
  long tmp ;
  u64 tmp_addr ;
  __u64 tmp___0 ;
  u32 tmp___1 ;
  int tmp___2 ;
  long tmp___3 ;
  long tmp___4 ;

  {
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  prod = rcb->producer_index;
  q_depth = rcb->q_depth;
  alloc_size = (u32 )(4096UL << unmap_q->alloc_order);
  alloced = 0U;
  goto ldv_58516;
  ldv_58515: 
  unmap = (struct bnad_rx_unmap *)(& unmap_q->unmap) + (unsigned long )prod;
  if (unmap_q->reuse_pi < 0) {
    page = alloc_pages(16416U, (unsigned int )unmap_q->alloc_order);
    page_offset = 0U;
  } else {
    prev = (struct bnad_rx_unmap *)(& unmap_q->unmap) + (unsigned long )unmap_q->reuse_pi;
    page = prev->page;
    page_offset = prev->page_offset + unmap_q->map_size;
    get_page(page);
  }
  tmp = ldv__builtin_expect((unsigned long )page == (unsigned long )((struct page *)0),
                         0L);
  if (tmp != 0L) {
    bnad->stats.drv_stats.rxbuf_alloc_failed = bnad->stats.drv_stats.rxbuf_alloc_failed + 1ULL;
    (rcb->rxq)->rxbuf_alloc_failed = (rcb->rxq)->rxbuf_alloc_failed + 1ULL;
    goto finishing;
  } else {

  }
  dma_addr = dma_map_page(& (bnad->pcidev)->dev, page, (size_t )page_offset, (size_t )unmap_q->map_size,
                          2);
  unmap->page = page;
  unmap->page_offset = page_offset;
  unmap->vector.dma_addr = dma_addr;
  unmap->vector.len = unmap_q->map_size;
  page_offset = unmap_q->map_size + page_offset;
  if (page_offset < alloc_size) {
    unmap_q->reuse_pi = (int )prod;
  } else {
    unmap_q->reuse_pi = -1;
  }
  rxent = (struct bna_rxq_entry *)rcb->sw_q + (unsigned long )prod;
  tmp___0 = __fswab64(dma_addr);
  tmp_addr = tmp___0;
  rxent->host_addr.msb = ((struct bna_dma_addr *)(& tmp_addr))->msb;
  rxent->host_addr.lsb = ((struct bna_dma_addr *)(& tmp_addr))->lsb;
  prod = (prod + 1U) & (q_depth - 1U);
  alloced = alloced + 1U;
  ldv_58516: 
  tmp___1 = nalloc;
  nalloc = nalloc - 1U;
  if (tmp___1 != 0U) {
    goto ldv_58515;
  } else {

  }

  finishing: 
  tmp___4 = ldv__builtin_expect(alloced != 0U, 1L);
  if (tmp___4 != 0L) {
    rcb->producer_index = prod;
    __asm__  volatile   ("mfence": : : "memory");
    tmp___2 = constant_test_bit(1L, (unsigned long const volatile   *)(& rcb->flags));
    tmp___3 = ldv__builtin_expect(tmp___2 != 0, 1L);
    if (tmp___3 != 0L) {
      writel(rcb->producer_index | 2147483648U, (void volatile   *)rcb->q_dbell);
    } else {

    }
  } else {

  }
  return (alloced);
}
}
static u32 bnad_rxq_refill_skb(struct bnad *bnad , struct bna_rcb *rcb , u32 nalloc ) 
{ 
  u32 alloced ;
  u32 prod ;
  u32 q_depth ;
  u32 buff_sz ;
  struct bnad_rx_unmap_q *unmap_q ;
  struct bnad_rx_unmap *unmap ;
  struct bna_rxq_entry *rxent ;
  struct sk_buff *skb ;
  dma_addr_t dma_addr ;
  long tmp ;
  u64 tmp_addr ;
  __u64 tmp___0 ;
  u32 tmp___1 ;
  int tmp___2 ;
  long tmp___3 ;
  long tmp___4 ;

  {
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  buff_sz = (u32 )(rcb->rxq)->buffer_size;
  prod = rcb->producer_index;
  q_depth = rcb->q_depth;
  alloced = 0U;
  goto ldv_58535;
  ldv_58534: 
  unmap = (struct bnad_rx_unmap *)(& unmap_q->unmap) + (unsigned long )prod;
  skb = netdev_alloc_skb_ip_align(bnad->netdev, buff_sz);
  tmp = ldv__builtin_expect((unsigned long )skb == (unsigned long )((struct sk_buff *)0),
                         0L);
  if (tmp != 0L) {
    bnad->stats.drv_stats.rxbuf_alloc_failed = bnad->stats.drv_stats.rxbuf_alloc_failed + 1ULL;
    (rcb->rxq)->rxbuf_alloc_failed = (rcb->rxq)->rxbuf_alloc_failed + 1ULL;
    goto finishing;
  } else {

  }
  dma_addr = dma_map_single_attrs(& (bnad->pcidev)->dev, (void *)skb->data, (size_t )buff_sz,
                                  2, (struct dma_attrs *)0);
  unmap->skb = skb;
  unmap->vector.dma_addr = dma_addr;
  unmap->vector.len = buff_sz;
  rxent = (struct bna_rxq_entry *)rcb->sw_q + (unsigned long )prod;
  tmp___0 = __fswab64(dma_addr);
  tmp_addr = tmp___0;
  rxent->host_addr.msb = ((struct bna_dma_addr *)(& tmp_addr))->msb;
  rxent->host_addr.lsb = ((struct bna_dma_addr *)(& tmp_addr))->lsb;
  prod = (prod + 1U) & (q_depth - 1U);
  alloced = alloced + 1U;
  ldv_58535: 
  tmp___1 = nalloc;
  nalloc = nalloc - 1U;
  if (tmp___1 != 0U) {
    goto ldv_58534;
  } else {

  }

  finishing: 
  tmp___4 = ldv__builtin_expect(alloced != 0U, 1L);
  if (tmp___4 != 0L) {
    rcb->producer_index = prod;
    __asm__  volatile   ("mfence": : : "memory");
    tmp___2 = constant_test_bit(1L, (unsigned long const volatile   *)(& rcb->flags));
    tmp___3 = ldv__builtin_expect(tmp___2 != 0, 1L);
    if (tmp___3 != 0L) {
      writel(rcb->producer_index | 2147483648U, (void volatile   *)rcb->q_dbell);
    } else {

    }
  } else {

  }
  return (alloced);
}
}
__inline static void bnad_rxq_post(struct bnad *bnad , struct bna_rcb *rcb ) 
{ 
  struct bnad_rx_unmap_q *unmap_q ;
  u32 to_alloc ;

  {
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  to_alloc = ((rcb->consumer_index - rcb->producer_index) - 1U) & (rcb->q_depth - 1U);
  if (to_alloc >> 3 == 0U) {
    return;
  } else {

  }
  if ((unsigned int )unmap_q->type == 1U) {
    bnad_rxq_refill_skb(bnad, rcb, to_alloc);
  } else {
    bnad_rxq_refill_page(bnad, rcb, to_alloc);
  }
  return;
}
}
static void bnad_cq_drop_packet(struct bnad *bnad , struct bna_rcb *rcb , u32 sop_ci ,
                                u32 nvecs ) 
{ 
  struct bnad_rx_unmap_q *unmap_q ;
  struct bnad_rx_unmap *unmap ;
  u32 ci ;
  u32 vec ;

  {
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  vec = 0U;
  ci = sop_ci;
  goto ldv_58554;
  ldv_58553: 
  unmap = (struct bnad_rx_unmap *)(& unmap_q->unmap) + (unsigned long )ci;
  ci = (ci + 1U) & (rcb->q_depth - 1U);
  if ((unsigned int )unmap_q->type == 1U) {
    bnad_rxq_cleanup_skb(bnad, unmap);
  } else {
    bnad_rxq_cleanup_page(bnad, unmap);
  }
  vec = vec + 1U;
  ldv_58554: ;
  if (vec < nvecs) {
    goto ldv_58553;
  } else {

  }

  return;
}
}
static void bnad_cq_setup_skb_frags(struct bna_rcb *rcb , struct sk_buff *skb , u32 sop_ci ,
                                    u32 nvecs , u32 last_fraglen ) 
{ 
  struct bnad *bnad ;
  u32 ci ;
  u32 vec ;
  u32 len ;
  u32 totlen ;
  struct bnad_rx_unmap_q *unmap_q ;
  struct bnad_rx_unmap *unmap ;
  void *tmp ;
  unsigned char *tmp___0 ;

  {
  totlen = 0U;
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  bnad = rcb->bnad;
  tmp = lowmem_page_address((struct page  const  *)unmap_q->unmap[sop_ci].page);
  __builtin_prefetch((void const   *)tmp + (unsigned long )unmap_q->unmap[sop_ci].page_offset);
  vec = 1U;
  ci = sop_ci;
  goto ldv_58571;
  ldv_58570: 
  unmap = (struct bnad_rx_unmap *)(& unmap_q->unmap) + (unsigned long )ci;
  ci = (ci + 1U) & (rcb->q_depth - 1U);
  dma_unmap_page(& (bnad->pcidev)->dev, unmap->vector.dma_addr, (size_t )unmap->vector.len,
                 2);
  len = vec != nvecs ? unmap->vector.len : last_fraglen;
  skb->truesize = skb->truesize + unmap->vector.len;
  totlen = totlen + len;
  tmp___0 = skb_end_pointer((struct sk_buff  const  *)skb);
  skb_fill_page_desc(skb, (int )((struct skb_shared_info *)tmp___0)->nr_frags, unmap->page,
                     (int )unmap->page_offset, (int )len);
  unmap->page = (struct page *)0;
  unmap->vector.len = 0U;
  vec = vec + 1U;
  ldv_58571: ;
  if (vec <= nvecs) {
    goto ldv_58570;
  } else {

  }
  skb->len = skb->len + totlen;
  skb->data_len = skb->data_len + totlen;
  return;
}
}
__inline static void bnad_cq_setup_skb(struct bnad *bnad , struct sk_buff *skb , struct bnad_rx_unmap *unmap ,
                                       u32 len ) 
{ 


  {
  __builtin_prefetch((void const   *)skb->data);
  dma_unmap_single_attrs(& (bnad->pcidev)->dev, unmap->vector.dma_addr, (size_t )unmap->vector.len,
                         2, (struct dma_attrs *)0);
  skb_put(skb, len);
  skb->protocol = eth_type_trans(skb, bnad->netdev);
  unmap->skb = (struct sk_buff *)0;
  unmap->vector.len = 0U;
  return;
}
}
static u32 bnad_cq_process(struct bnad *bnad , struct bna_ccb *ccb , int budget ) 
{ 
  struct bna_cq_entry *cq ;
  struct bna_cq_entry *cmpl ;
  struct bna_cq_entry *next_cmpl ;
  struct bna_rcb *rcb ;
  struct bnad_rx_unmap_q *unmap_q ;
  struct bnad_rx_unmap *unmap ;
  struct sk_buff *skb ;
  struct bna_pkt_rate *pkt_rt ;
  struct bnad_rx_ctrl *rx_ctrl ;
  u32 packets ;
  u32 len ;
  u32 totlen ;
  u32 pi ;
  u32 vec ;
  u32 sop_ci ;
  u32 nvecs ;
  u32 flags ;
  u32 masked_flags ;
  __u16 tmp ;
  long tmp___0 ;
  __u32 tmp___1 ;
  __u16 tmp___2 ;
  __u16 tmp___3 ;
  __u32 tmp___4 ;
  long tmp___5 ;
  long tmp___6 ;
  __u16 tmp___7 ;
  int tmp___8 ;
  long tmp___9 ;
    klee_make_symbolic(&tmp___9, sizeof(long), "tmp___9");

  {
  rcb = (struct bna_rcb *)0;
  unmap = (struct bnad_rx_unmap *)0;
  skb = (struct sk_buff *)0;
  pkt_rt = & ccb->pkt_rate;
  rx_ctrl = (struct bnad_rx_ctrl *)ccb->ctrl;
  packets = 0U;
  len = 0U;
  totlen = 0U;
  sop_ci = 0U;
  nvecs = 0U;
  __builtin_prefetch((void const   *)bnad->netdev);
  cq = (struct bna_cq_entry *)ccb->sw_q;
  goto ldv_58610;
  ldv_58609: 
  cmpl = cq + (unsigned long )ccb->producer_index;
  if ((unsigned int )cmpl->valid == 0U) {
    goto ldv_58602;
  } else {

  }
  __asm__  volatile   ("lfence": : : "memory");
  tmp = __fswab16((int )cmpl->length);
  if ((unsigned int )tmp > 1000U) {
    pkt_rt->large_pkt_cnt = pkt_rt->large_pkt_cnt + 1U;
  } else {
    pkt_rt->small_pkt_cnt = pkt_rt->small_pkt_cnt + 1U;
  }
  if ((int )cmpl->rxq_id & 1) {
    rcb = ccb->rcb[1];
  } else {
    rcb = ccb->rcb[0];
  }
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  sop_ci = rcb->consumer_index;
  if ((unsigned int )unmap_q->type == 1U) {
    unmap = (struct bnad_rx_unmap *)(& unmap_q->unmap) + (unsigned long )sop_ci;
    skb = unmap->skb;
  } else {
    skb = napi_get_frags(& rx_ctrl->napi);
    tmp___0 = ldv__builtin_expect((unsigned long )skb == (unsigned long )((struct sk_buff *)0),
                               0L);
    if (tmp___0 != 0L) {
      goto ldv_58602;
    } else {

    }
  }
  __builtin_prefetch((void const   *)skb);
  tmp___1 = __fswab32(cmpl->flags);
  flags = tmp___1;
  tmp___2 = __fswab16((int )cmpl->length);
  len = (u32 )tmp___2;
  totlen = len;
  nvecs = 1U;
  if ((unsigned int )unmap_q->type == 3U && (int )flags >= 0) {
    pi = ccb->producer_index;
    ldv_58604: 
    pi = (pi + 1U) & (ccb->q_depth - 1U);
    next_cmpl = cq + (unsigned long )pi;
    if ((unsigned int )next_cmpl->valid == 0U) {
      goto ldv_58603;
    } else {

    }
    __asm__  volatile   ("lfence": : : "memory");
    tmp___3 = __fswab16((int )next_cmpl->length);
    len = (u32 )tmp___3;
    tmp___4 = __fswab32(next_cmpl->flags);
    flags = tmp___4;
    nvecs = nvecs + 1U;
    totlen = totlen + len;
    if ((int )flags >= 0) {
      goto ldv_58604;
    } else {

    }
    ldv_58603: ;
    if ((unsigned int )next_cmpl->valid == 0U) {
      goto ldv_58602;
    } else {

    }
  } else {

  }
  tmp___5 = ldv__builtin_expect(((unsigned long )flags & 7UL) != 0UL, 0L);
  if (tmp___5 != 0L) {
    bnad_cq_drop_packet(bnad, rcb, sop_ci, nvecs);
    (rcb->rxq)->rx_packets_with_error = (rcb->rxq)->rx_packets_with_error + 1ULL;
    goto next;
  } else {

  }
  if ((unsigned int )unmap_q->type == 1U) {
    bnad_cq_setup_skb(bnad, skb, unmap, len);
  } else {
    bnad_cq_setup_skb_frags(rcb, skb, sop_ci, nvecs, len);
  }
  packets = packets + 1U;
  (rcb->rxq)->rx_packets = (rcb->rxq)->rx_packets + 1ULL;
  (rcb->rxq)->rx_bytes = (rcb->rxq)->rx_bytes + (u64 )totlen;
  ccb->bytes_per_intr = ccb->bytes_per_intr + totlen;
  masked_flags = flags & 7008U;
  tmp___6 = ldv__builtin_expect((long )(((bnad->netdev)->features & 17179869184ULL) != 0ULL && (((masked_flags == 4704U || masked_flags == 4448U) || masked_flags == 2592U) || masked_flags == 2336U)),
                             1L);
  if (tmp___6 != 0L) {
    skb->ip_summed = 1U;
  } else {
    skb_checksum_none_assert((struct sk_buff  const  *)skb);
  }
  if (((unsigned long )flags & 8192UL) != 0UL && ((bnad->netdev)->features & 256ULL) != 0ULL) {
    tmp___7 = __fswab16((int )cmpl->vlan_tag);
    __vlan_hwaccel_put_tag(skb, 129, (int )tmp___7);
  } else {

  }
  if ((unsigned int )unmap_q->type == 1U) {
    netif_receive_skb(skb);
  } else {
    napi_gro_frags(& rx_ctrl->napi);
  }
  next: 
  rcb->consumer_index = (rcb->consumer_index + nvecs) & (rcb->q_depth - 1U);
  vec = 0U;
  goto ldv_58607;
  ldv_58606: 
  cmpl = cq + (unsigned long )ccb->producer_index;
  cmpl->valid = 0U;
  ccb->producer_index = (ccb->producer_index + 1U) & (ccb->q_depth - 1U);
  vec = vec + 1U;
  ldv_58607: ;
  if (vec < nvecs) {
    goto ldv_58606;
  } else {

  }

  ldv_58610: ;
  if ((u32 )budget > packets) {
    goto ldv_58609;
  } else {

  }
  ldv_58602: 
  napi_gro_flush(& rx_ctrl->napi, 0);
  tmp___8 = constant_test_bit(0L, (unsigned long const volatile   *)(& (ccb->rcb[0])->flags));
  tmp___9 = ldv__builtin_expect(tmp___8 != 0, 1L);
  if (tmp___9 != 0L) {
    writel(packets | 2147483648U, (void volatile   *)(ccb->i_dbell)->doorbell_addr);
  } else {

  }
  bnad_rxq_post(bnad, ccb->rcb[0]);
  if ((unsigned long )ccb->rcb[1] != (unsigned long )((struct bna_rcb *)0)) {
    bnad_rxq_post(bnad, ccb->rcb[1]);
  } else {

  }
  return (packets);
}
}
static void bnad_netif_rx_schedule_poll(struct bnad *bnad , struct bna_ccb *ccb ) 
{ 
  struct bnad_rx_ctrl *rx_ctrl ;
  struct napi_struct *napi ;
  bool tmp ;
  long tmp___0 ;

  {
  rx_ctrl = (struct bnad_rx_ctrl *)ccb->ctrl;
  napi = & rx_ctrl->napi;
  tmp = napi_schedule_prep(napi);
  tmp___0 = ldv__builtin_expect((long )tmp, 1L);
  if (tmp___0 != 0L) {
    __napi_schedule(napi);
    rx_ctrl->rx_schedule = rx_ctrl->rx_schedule + 1ULL;
  } else {

  }
  return;
}
}
static irqreturn_t bnad_msix_rx(int irq , void *data ) 
{ 
  struct bna_ccb *ccb ;

  {
  ccb = (struct bna_ccb *)data;
  if ((unsigned long )ccb != (unsigned long )((struct bna_ccb *)0)) {
    ((struct bnad_rx_ctrl *)ccb->ctrl)->rx_intr_ctr = ((struct bnad_rx_ctrl *)ccb->ctrl)->rx_intr_ctr + 1ULL;
    bnad_netif_rx_schedule_poll(ccb->bnad, ccb);
  } else {

  }
  return (1);
}
}
static irqreturn_t bnad_msix_mbox_handler(int irq , void *data ) 
{ 
  u32 intr_status ;
  unsigned long flags ;
  struct bnad *bnad ;
  int tmp ;
  long tmp___0 ;

  {
  bnad = (struct bnad *)data;
  ldv_spin_lock();
  tmp = constant_test_bit(2L, (unsigned long const volatile   *)(& bnad->run_flags));
  tmp___0 = ldv__builtin_expect(tmp != 0, 0L);
  if (tmp___0 != 0L) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    return (1);
  } else {

  }
  intr_status = readl((void const volatile   *)bnad->bna.regs.fn_int_status);
  if (intr_status != 0U) {
    writel(~ bnad->bna.bits.mbox_status_bits & intr_status, (void volatile   *)bnad->bna.regs.fn_int_status);
  } else {

  }
  if (((bnad->bna.bits.mbox_status_bits | bnad->bna.bits.error_status_bits) & intr_status) != 0U) {
    bna_mbox_handler(& bnad->bna, intr_status);
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return (1);
}
}
static irqreturn_t bnad_isr(int irq , void *data ) 
{ 
  int i ;
  int j ;
    klee_make_symbolic(&j, sizeof(int), "j");
  u32 intr_status ;
  unsigned long flags ;
  struct bnad *bnad ;
  struct bnad_rx_info *rx_info ;
  struct bnad_rx_ctrl *rx_ctrl ;
  struct bna_tcb *tcb ;
  int tmp ;
  long tmp___0 ;
  long tmp___1 ;
  int tmp___2 ;

  {
  bnad = (struct bnad *)data;
  tcb = (struct bna_tcb *)0;
  ldv_spin_lock();
  tmp = constant_test_bit(2L, (unsigned long const volatile   *)(& bnad->run_flags));
  tmp___0 = ldv__builtin_expect(tmp != 0, 0L);
  if (tmp___0 != 0L) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    return (0);
  } else {

  }
  intr_status = readl((void const volatile   *)bnad->bna.regs.fn_int_status);
  if (intr_status != 0U) {
    writel(~ bnad->bna.bits.mbox_status_bits & intr_status, (void volatile   *)bnad->bna.regs.fn_int_status);
  } else {

  }
  tmp___1 = ldv__builtin_expect(intr_status == 0U, 0L);
  if (tmp___1 != 0L) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    return (0);
  } else {

  }
  if (((bnad->bna.bits.mbox_status_bits | bnad->bna.bits.error_status_bits) & intr_status) != 0U) {
    bna_mbox_handler(& bnad->bna, intr_status);
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if ((intr_status & 65535U) == 0U) {
    return (1);
  } else {

  }
  i = 0;
  goto ldv_58645;
  ldv_58644: 
  j = 0;
  goto ldv_58642;
  ldv_58641: 
  tcb = bnad->tx_info[i].tcb[j];
  if ((unsigned long )tcb != (unsigned long )((struct bna_tcb *)0)) {
    tmp___2 = constant_test_bit(1L, (unsigned long const volatile   *)(& tcb->flags));
    if (tmp___2 != 0) {
      bnad_tx_complete(bnad, bnad->tx_info[i].tcb[j]);
    } else {

    }
  } else {

  }
  j = j + 1;
  ldv_58642: ;
  if ((u32 )j < bnad->num_txq_per_tx) {
    goto ldv_58641;
  } else {

  }
  i = i + 1;
  ldv_58645: ;
  if ((u32 )i < bnad->num_tx) {
    goto ldv_58644;
  } else {

  }
  i = 0;
  goto ldv_58652;
  ldv_58651: 
  rx_info = (struct bnad_rx_info *)(& bnad->rx_info) + (unsigned long )i;
  if ((unsigned long )rx_info->rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_58647;
  } else {

  }
  j = 0;
  goto ldv_58649;
  ldv_58648: 
  rx_ctrl = (struct bnad_rx_ctrl *)(& rx_info->rx_ctrl) + (unsigned long )j;
  if ((unsigned long )rx_ctrl->ccb != (unsigned long )((struct bna_ccb *)0)) {
    bnad_netif_rx_schedule_poll(bnad, rx_ctrl->ccb);
  } else {

  }
  j = j + 1;
  ldv_58649: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_58648;
  } else {

  }

  ldv_58647: 
  i = i + 1;
  ldv_58652: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_58651;
  } else {

  }

  return (1);
}
}
static void bnad_enable_mbox_irq(struct bnad *bnad ) 
{ 


  {
  clear_bit(2L, (unsigned long volatile   *)(& bnad->run_flags));
  bnad->stats.drv_stats.mbox_intr_enabled = bnad->stats.drv_stats.mbox_intr_enabled + 1ULL;
  return;
}
}
static void bnad_disable_mbox_irq(struct bnad *bnad ) 
{ 


  {
  set_bit(2L, (unsigned long volatile   *)(& bnad->run_flags));
  bnad->stats.drv_stats.mbox_intr_disabled = bnad->stats.drv_stats.mbox_intr_disabled + 1ULL;
  return;
}
}
static void bnad_set_netdev_perm_addr(struct bnad *bnad ) 
{ 
  struct net_device *netdev ;
  bool tmp ;

  {
  netdev = bnad->netdev;
  ether_addr_copy((u8 *)(& netdev->perm_addr), (u8 const   *)(& bnad->perm_addr));
  tmp = is_zero_ether_addr((u8 const   *)netdev->dev_addr);
  if ((int )tmp) {
    ether_addr_copy(netdev->dev_addr, (u8 const   *)(& bnad->perm_addr));
  } else {

  }
  return;
}
}
void bnad_cb_mbox_intr_enable(struct bnad *bnad ) 
{ 


  {
  bnad_enable_mbox_irq(bnad);
  return;
}
}
void bnad_cb_mbox_intr_disable(struct bnad *bnad ) 
{ 


  {
  bnad_disable_mbox_irq(bnad);
  return;
}
}
void bnad_cb_ioceth_ready(struct bnad *bnad ) 
{ 


  {
  bnad->bnad_completions.ioc_comp_status = 0U;
  complete(& bnad->bnad_completions.ioc_comp);
  return;
}
}
void bnad_cb_ioceth_failed(struct bnad *bnad ) 
{ 


  {
  bnad->bnad_completions.ioc_comp_status = 1U;
  complete(& bnad->bnad_completions.ioc_comp);
  return;
}
}
void bnad_cb_ioceth_disabled(struct bnad *bnad ) 
{ 


  {
  bnad->bnad_completions.ioc_comp_status = 0U;
  complete(& bnad->bnad_completions.ioc_comp);
  return;
}
}
static void bnad_cb_enet_disabled(void *arg ) 
{ 
  struct bnad *bnad ;

  {
  bnad = (struct bnad *)arg;
  netif_carrier_off(bnad->netdev);
  complete(& bnad->bnad_completions.enet_comp);
  return;
}
}
void bnad_cb_ethport_link_status(struct bnad *bnad , enum bna_link_status link_status ) 
{ 
  bool link_up ;
  int tmp ;
  int tmp___0 ;
  uint tx_id ;
    klee_make_symbolic(&tx_id, sizeof(int), "tx_id");
  uint tcb_id ;
    klee_make_symbolic(&tcb_id, sizeof(int), "tcb_id");
  struct bna_tcb *tcb ;
  u32 txq_id ;
  int tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  bool tmp___4 ;

  {
  link_up = 0;
  link_up = (bool )((unsigned int )link_status == 1U || (unsigned int )link_status == 2U);
  if ((unsigned int )link_status == 2U) {
    tmp = constant_test_bit(0L, (unsigned long const volatile   *)(& bnad->run_flags));
    if (tmp == 0) {
      bnad->stats.drv_stats.cee_toggle = bnad->stats.drv_stats.cee_toggle + 1ULL;
    } else {

    }
    set_bit(0L, (unsigned long volatile   *)(& bnad->run_flags));
  } else {
    tmp___0 = constant_test_bit(0L, (unsigned long const volatile   *)(& bnad->run_flags));
    if (tmp___0 != 0) {
      bnad->stats.drv_stats.cee_toggle = bnad->stats.drv_stats.cee_toggle + 1ULL;
    } else {

    }
    clear_bit(0L, (unsigned long volatile   *)(& bnad->run_flags));
  }
  if ((int )link_up) {
    tmp___2 = netif_carrier_ok((struct net_device  const  *)bnad->netdev);
    if (tmp___2) {
      tmp___3 = 0;
    } else {
      tmp___3 = 1;
    }
    if (tmp___3) {
      netdev_info((struct net_device  const  *)bnad->netdev, "link up\n");
      netif_carrier_on(bnad->netdev);
      bnad->stats.drv_stats.link_toggle = bnad->stats.drv_stats.link_toggle + 1ULL;
      tx_id = 0U;
      goto ldv_58697;
      ldv_58696: 
      tcb_id = 0U;
      goto ldv_58694;
      ldv_58693: 
      tcb = bnad->tx_info[tx_id].tcb[tcb_id];
      if ((unsigned long )tcb == (unsigned long )((struct bna_tcb *)0)) {
        goto ldv_58692;
      } else {

      }
      txq_id = (u32 )tcb->id;
      tmp___1 = constant_test_bit(1L, (unsigned long const volatile   *)(& tcb->flags));
      if (tmp___1 != 0) {
        netif_wake_subqueue(bnad->netdev, (int )((u16 )txq_id));
        bnad->stats.drv_stats.netif_queue_wakeup = bnad->stats.drv_stats.netif_queue_wakeup + 1ULL;
      } else {
        netif_stop_subqueue(bnad->netdev, (int )((u16 )txq_id));
        bnad->stats.drv_stats.netif_queue_stop = bnad->stats.drv_stats.netif_queue_stop + 1ULL;
      }
      ldv_58692: 
      tcb_id = tcb_id + 1U;
      ldv_58694: ;
      if (bnad->num_txq_per_tx > tcb_id) {
        goto ldv_58693;
      } else {

      }
      tx_id = tx_id + 1U;
      ldv_58697: ;
      if (bnad->num_tx > tx_id) {
        goto ldv_58696;
      } else {

      }

    } else {

    }
  } else {
    tmp___4 = netif_carrier_ok((struct net_device  const  *)bnad->netdev);
    if ((int )tmp___4) {
      netdev_info((struct net_device  const  *)bnad->netdev, "link down\n");
      netif_carrier_off(bnad->netdev);
      bnad->stats.drv_stats.link_toggle = bnad->stats.drv_stats.link_toggle + 1ULL;
    } else {

    }
  }
  return;
}
}
static void bnad_cb_tx_disabled(void *arg , struct bna_tx *tx ) 
{ 
  struct bnad *bnad ;

  {
  bnad = (struct bnad *)arg;
  complete(& bnad->bnad_completions.tx_comp);
  return;
}
}
static void bnad_cb_tcb_setup(struct bnad *bnad , struct bna_tcb *tcb ) 
{ 
  struct bnad_tx_info *tx_info ;

  {
  tx_info = (struct bnad_tx_info *)((tcb->txq)->tx)->priv;
  tcb->priv = (void *)tcb;
  tx_info->tcb[tcb->id] = tcb;
  return;
}
}
static void bnad_cb_tcb_destroy(struct bnad *bnad , struct bna_tcb *tcb ) 
{ 
  struct bnad_tx_info *tx_info ;

  {
  tx_info = (struct bnad_tx_info *)((tcb->txq)->tx)->priv;
  tx_info->tcb[tcb->id] = (struct bna_tcb *)0;
  tcb->priv = (void *)0;
  return;
}
}
static void bnad_cb_ccb_setup(struct bnad *bnad , struct bna_ccb *ccb ) 
{ 
  struct bnad_rx_info *rx_info ;

  {
  rx_info = (struct bnad_rx_info *)((ccb->cq)->rx)->priv;
  rx_info->rx_ctrl[ccb->id].ccb = ccb;
  ccb->ctrl = (void *)(& rx_info->rx_ctrl) + (unsigned long )ccb->id;
  return;
}
}
static void bnad_cb_ccb_destroy(struct bnad *bnad , struct bna_ccb *ccb ) 
{ 
  struct bnad_rx_info *rx_info ;

  {
  rx_info = (struct bnad_rx_info *)((ccb->cq)->rx)->priv;
  rx_info->rx_ctrl[ccb->id].ccb = (struct bna_ccb *)0;
  return;
}
}
static void bnad_cb_tx_stall(struct bnad *bnad , struct bna_tx *tx ) 
{ 
  struct bnad_tx_info *tx_info ;
  struct bna_tcb *tcb ;
  u32 txq_id ;
  int i ;

  {
  tx_info = (struct bnad_tx_info *)tx->priv;
  i = 0;
  goto ldv_58734;
  ldv_58733: 
  tcb = tx_info->tcb[i];
  if ((unsigned long )tcb == (unsigned long )((struct bna_tcb *)0)) {
    goto ldv_58732;
  } else {

  }
  txq_id = (u32 )tcb->id;
  clear_bit(1L, (unsigned long volatile   *)(& tcb->flags));
  netif_stop_subqueue(bnad->netdev, (int )((u16 )txq_id));
  ldv_58732: 
  i = i + 1;
  ldv_58734: ;
  if (i <= 7) {
    goto ldv_58733;
  } else {

  }

  return;
}
}
static void bnad_cb_tx_resume(struct bnad *bnad , struct bna_tx *tx ) 
{ 
  struct bnad_tx_info *tx_info ;
  struct bna_tcb *tcb ;
  u32 txq_id ;
  int i ;
  int tmp ;
  long tmp___0 ;
  long tmp___1 ;
  bool tmp___2 ;
  bool tmp___3 ;

  {
  tx_info = (struct bnad_tx_info *)tx->priv;
  i = 0;
  goto ldv_58748;
  ldv_58747: 
  tcb = tx_info->tcb[i];
  if ((unsigned long )tcb == (unsigned long )((struct bna_tcb *)0)) {
    goto ldv_58744;
  } else {

  }
  txq_id = (u32 )tcb->id;
  tmp = constant_test_bit(1L, (unsigned long const volatile   *)(& tcb->flags));
  tmp___0 = ldv__builtin_expect(tmp != 0, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bnad.c"),
                         "i" (1072), "i" (12UL));
    ldv_58745: ;
    goto ldv_58745;
  } else {

  }
  set_bit(1L, (unsigned long volatile   *)(& tcb->flags));
  tmp___1 = ldv__builtin_expect((unsigned int )*(tcb->hw_consumer_index) != 0U, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bnad.c"),
                         "i" (1074), "i" (12UL));
    ldv_58746: ;
    goto ldv_58746;
  } else {

  }
  tmp___2 = netif_carrier_ok((struct net_device  const  *)bnad->netdev);
  if ((int )tmp___2) {
    netif_wake_subqueue(bnad->netdev, (int )((u16 )txq_id));
    bnad->stats.drv_stats.netif_queue_wakeup = bnad->stats.drv_stats.netif_queue_wakeup + 1ULL;
  } else {

  }
  ldv_58744: 
  i = i + 1;
  ldv_58748: ;
  if (i <= 7) {
    goto ldv_58747;
  } else {

  }
  tmp___3 = is_zero_ether_addr((u8 const   *)(& bnad->perm_addr));
  if ((int )tmp___3) {
    bna_enet_perm_mac_get(& bnad->bna.enet, (u8 *)(& bnad->perm_addr));
    bnad_set_netdev_perm_addr(bnad);
  } else {

  }
  return;
}
}
static void bnad_tx_cleanup(struct delayed_work *work ) 
{ 
  struct bnad_tx_info *tx_info ;
  struct delayed_work  const  *__mptr ;
  struct bnad *bnad ;
  struct bna_tcb *tcb ;
  unsigned long flags ;
  u32 i ;
  u32 pending ;
  int tmp ;
  unsigned long tmp___0 ;

  {
  __mptr = (struct delayed_work  const  *)work;
  tx_info = (struct bnad_tx_info *)__mptr + 0xffffffffffffffb0UL;
  bnad = (struct bnad *)0;
  pending = 0U;
  i = 0U;
  goto ldv_58763;
  ldv_58762: 
  tcb = tx_info->tcb[i];
  if ((unsigned long )tcb == (unsigned long )((struct bna_tcb *)0)) {
    goto ldv_58761;
  } else {

  }
  bnad = tcb->bnad;
  tmp = test_and_set_bit(0L, (unsigned long volatile   *)(& tcb->flags));
  if (tmp != 0) {
    pending = pending + 1U;
    goto ldv_58761;
  } else {

  }
  bnad_txq_cleanup(bnad, tcb);
  __asm__  volatile   ("": : : "memory");
  clear_bit(0L, (unsigned long volatile   *)(& tcb->flags));
  ldv_58761: 
  i = i + 1U;
  ldv_58763: ;
  if (i <= 7U) {
    goto ldv_58762;
  } else {

  }

  if (pending != 0U) {
    tmp___0 = msecs_to_jiffies(1U);
    queue_delayed_work(bnad->work_q, & tx_info->tx_cleanup_work, tmp___0);
    return;
  } else {

  }
  ldv_spin_lock();
  bna_tx_cleanup_complete(tx_info->tx);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_cb_tx_cleanup(struct bnad *bnad , struct bna_tx *tx ) 
{ 
  struct bnad_tx_info *tx_info ;
  struct bna_tcb *tcb ;
  int i ;

  {
  tx_info = (struct bnad_tx_info *)tx->priv;
  i = 0;
  goto ldv_58774;
  ldv_58773: 
  tcb = tx_info->tcb[i];
  if ((unsigned long )tcb == (unsigned long )((struct bna_tcb *)0)) {

  } else {

  }
  i = i + 1;
  ldv_58774: ;
  if (i <= 7) {
    goto ldv_58773;
  } else {

  }
  queue_delayed_work(bnad->work_q, & tx_info->tx_cleanup_work, 0UL);
  return;
}
}
static void bnad_cb_rx_stall(struct bnad *bnad , struct bna_rx *rx ) 
{ 
  struct bnad_rx_info *rx_info ;
  struct bna_ccb *ccb ;
  struct bnad_rx_ctrl *rx_ctrl ;
  int i ;

  {
  rx_info = (struct bnad_rx_info *)rx->priv;
  i = 0;
  goto ldv_58786;
  ldv_58785: 
  rx_ctrl = (struct bnad_rx_ctrl *)(& rx_info->rx_ctrl) + (unsigned long )i;
  ccb = rx_ctrl->ccb;
  if ((unsigned long )ccb == (unsigned long )((struct bna_ccb *)0)) {
    goto ldv_58784;
  } else {

  }
  clear_bit(1L, (unsigned long volatile   *)(& (ccb->rcb[0])->flags));
  if ((unsigned long )ccb->rcb[1] != (unsigned long )((struct bna_rcb *)0)) {
    clear_bit(1L, (unsigned long volatile   *)(& (ccb->rcb[1])->flags));
  } else {

  }
  ldv_58784: 
  i = i + 1;
  ldv_58786: ;
  if (i <= 15) {
    goto ldv_58785;
  } else {

  }

  return;
}
}
static void bnad_rx_cleanup(void *work ) 
{ 
  struct bnad_rx_info *rx_info ;
  struct work_struct  const  *__mptr ;
  struct bnad_rx_ctrl *rx_ctrl ;
  struct bnad *bnad ;
  unsigned long flags ;
  u32 i ;

  {
  __mptr = (struct work_struct  const  *)work;
  rx_info = (struct bnad_rx_info *)__mptr + 0xffffffffffffea70UL;
  bnad = (struct bnad *)0;
  i = 0U;
  goto ldv_58800;
  ldv_58799: 
  rx_ctrl = (struct bnad_rx_ctrl *)(& rx_info->rx_ctrl) + (unsigned long )i;
  if ((unsigned long )rx_ctrl->ccb == (unsigned long )((struct bna_ccb *)0)) {
    goto ldv_58798;
  } else {

  }
  bnad = (rx_ctrl->ccb)->bnad;
  napi_disable(& rx_ctrl->napi);
  bnad_cq_cleanup(bnad, rx_ctrl->ccb);
  bnad_rxq_cleanup(bnad, (rx_ctrl->ccb)->rcb[0]);
  if ((unsigned long )(rx_ctrl->ccb)->rcb[1] != (unsigned long )((struct bna_rcb *)0)) {
    bnad_rxq_cleanup(bnad, (rx_ctrl->ccb)->rcb[1]);
  } else {

  }
  ldv_58798: 
  i = i + 1U;
  ldv_58800: ;
  if (i <= 15U) {
    goto ldv_58799;
  } else {

  }
  ldv_spin_lock();
  bna_rx_cleanup_complete(rx_info->rx);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_cb_rx_cleanup(struct bnad *bnad , struct bna_rx *rx ) 
{ 
  struct bnad_rx_info *rx_info ;
  struct bna_ccb *ccb ;
  struct bnad_rx_ctrl *rx_ctrl ;
  int i ;

  {
  rx_info = (struct bnad_rx_info *)rx->priv;
  i = 0;
  goto ldv_58812;
  ldv_58811: 
  rx_ctrl = (struct bnad_rx_ctrl *)(& rx_info->rx_ctrl) + (unsigned long )i;
  ccb = rx_ctrl->ccb;
  if ((unsigned long )ccb == (unsigned long )((struct bna_ccb *)0)) {
    goto ldv_58810;
  } else {

  }
  clear_bit(0L, (unsigned long volatile   *)(& (ccb->rcb[0])->flags));
  if ((unsigned long )ccb->rcb[1] != (unsigned long )((struct bna_rcb *)0)) {
    clear_bit(0L, (unsigned long volatile   *)(& (ccb->rcb[1])->flags));
  } else {

  }
  ldv_58810: 
  i = i + 1;
  ldv_58812: ;
  if (i <= 15) {
    goto ldv_58811;
  } else {

  }
  queue_work(bnad->work_q, & rx_info->rx_cleanup_work);
  return;
}
}
static void bnad_cb_rx_post(struct bnad *bnad , struct bna_rx *rx ) 
{ 
  struct bnad_rx_info *rx_info ;
  struct bna_ccb *ccb ;
  struct bna_rcb *rcb ;
  struct bnad_rx_ctrl *rx_ctrl ;
  int i ;
  int j ;

  {
  rx_info = (struct bnad_rx_info *)rx->priv;
  i = 0;
  goto ldv_58830;
  ldv_58829: 
  rx_ctrl = (struct bnad_rx_ctrl *)(& rx_info->rx_ctrl) + (unsigned long )i;
  ccb = rx_ctrl->ccb;
  if ((unsigned long )ccb == (unsigned long )((struct bna_ccb *)0)) {
    goto ldv_58824;
  } else {

  }
  napi_enable(& rx_ctrl->napi);
  j = 0;
  goto ldv_58827;
  ldv_58826: 
  rcb = ccb->rcb[j];
  if ((unsigned long )rcb == (unsigned long )((struct bna_rcb *)0)) {
    goto ldv_58825;
  } else {

  }
  bnad_rxq_alloc_init(bnad, rcb);
  set_bit(0L, (unsigned long volatile   *)(& rcb->flags));
  set_bit(1L, (unsigned long volatile   *)(& rcb->flags));
  bnad_rxq_post(bnad, rcb);
  ldv_58825: 
  j = j + 1;
  ldv_58827: ;
  if (j <= 1) {
    goto ldv_58826;
  } else {

  }

  ldv_58824: 
  i = i + 1;
  ldv_58830: ;
  if (i <= 15) {
    goto ldv_58829;
  } else {

  }

  return;
}
}
static void bnad_cb_rx_disabled(void *arg , struct bna_rx *rx ) 
{ 
  struct bnad *bnad ;

  {
  bnad = (struct bnad *)arg;
  complete(& bnad->bnad_completions.rx_comp);
  return;
}
}
static void bnad_cb_rx_mcast_add(struct bnad *bnad , struct bna_rx *rx ) 
{ 


  {
  bnad->bnad_completions.mcast_comp_status = 0U;
  complete(& bnad->bnad_completions.mcast_comp);
  return;
}
}
void bnad_cb_stats_get(struct bnad *bnad , enum bna_cb_status status , struct bna_stats *stats ) 
{ 
  bool tmp ;
  int tmp___0 ;
  int tmp___1 ;
  unsigned long tmp___2 ;

  {
  if ((unsigned int )status == 0U) {
    bnad->stats.drv_stats.hw_stats_updates = bnad->stats.drv_stats.hw_stats_updates + 1ULL;
  } else {

  }
  tmp = netif_running((struct net_device  const  *)bnad->netdev);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return;
  } else {
    tmp___1 = constant_test_bit(5L, (unsigned long const volatile   *)(& bnad->run_flags));
    if (tmp___1 == 0) {
      return;
    } else {

    }
  }
  tmp___2 = msecs_to_jiffies(1000U);
  ldv_mod_timer_43(& bnad->stats_timer, tmp___2 + (unsigned long )jiffies);
  return;
}
}
static void bnad_cb_enet_mtu_set(struct bnad *bnad ) 
{ 


  {
  bnad->bnad_completions.mtu_comp_status = 0U;
  complete(& bnad->bnad_completions.mtu_comp);
  return;
}
}
void bnad_cb_completion(void *arg , enum bfa_status status ) 
{ 
  struct bnad_iocmd_comp *iocmd_comp ;

  {
  iocmd_comp = (struct bnad_iocmd_comp *)arg;
  iocmd_comp->comp_status = (int )status;
  complete(& iocmd_comp->comp);
  return;
}
}
static void bnad_mem_free(struct bnad *bnad , struct bna_mem_info *mem_info ) 
{ 
  int i ;
  dma_addr_t dma_pa ;
  __u32 tmp ;
  __u32 tmp___0 ;

  {
  if ((unsigned long )mem_info->mdl == (unsigned long )((struct bna_mem_descr *)0)) {
    return;
  } else {

  }
  i = 0;
  goto ldv_58861;
  ldv_58860: ;
  if ((unsigned long )(mem_info->mdl + (unsigned long )i)->kva != (unsigned long )((void *)0)) {
    if ((unsigned int )mem_info->mem_type == 2U) {
      tmp = __fswab32((mem_info->mdl + (unsigned long )i)->dma.msb);
      tmp___0 = __fswab32((mem_info->mdl + (unsigned long )i)->dma.lsb);
      dma_pa = ((unsigned long long )tmp << 32) | (unsigned long long )tmp___0;
      dma_free_attrs(& (bnad->pcidev)->dev, (size_t )(mem_info->mdl + (unsigned long )i)->len,
                     (mem_info->mdl + (unsigned long )i)->kva, dma_pa, (struct dma_attrs *)0);
    } else {
      kfree((void const   *)(mem_info->mdl + (unsigned long )i)->kva);
    }
  } else {

  }
  i = i + 1;
  ldv_58861: ;
  if ((u32 )i < mem_info->num) {
    goto ldv_58860;
  } else {

  }
  kfree((void const   *)mem_info->mdl);
  mem_info->mdl = (struct bna_mem_descr *)0;
  return;
}
}
static int bnad_mem_alloc(struct bnad *bnad , struct bna_mem_info *mem_info ) 
{ 
  int i ;
  dma_addr_t dma_pa ;
  void *tmp ;
  u64 tmp_addr ;
  __u64 tmp___0 ;

  {
  if (mem_info->num == 0U || mem_info->len == 0U) {
    mem_info->mdl = (struct bna_mem_descr *)0;
    return (0);
  } else {

  }
  tmp = kcalloc((size_t )mem_info->num, 24UL, 208U);
  mem_info->mdl = (struct bna_mem_descr *)tmp;
  if ((unsigned long )mem_info->mdl == (unsigned long )((struct bna_mem_descr *)0)) {
    return (-12);
  } else {

  }
  if ((unsigned int )mem_info->mem_type == 2U) {
    i = 0;
    goto ldv_58872;
    ldv_58871: 
    (mem_info->mdl + (unsigned long )i)->len = mem_info->len;
    (mem_info->mdl + (unsigned long )i)->kva = dma_alloc_attrs(& (bnad->pcidev)->dev,
                                                               (size_t )mem_info->len,
                                                               & dma_pa, 208U, (struct dma_attrs *)0);
    if ((unsigned long )(mem_info->mdl + (unsigned long )i)->kva == (unsigned long )((void *)0)) {
      goto err_return;
    } else {

    }
    tmp___0 = __fswab64(dma_pa);
    tmp_addr = tmp___0;
    (mem_info->mdl + (unsigned long )i)->dma.msb = ((struct bna_dma_addr *)(& tmp_addr))->msb;
    (mem_info->mdl + (unsigned long )i)->dma.lsb = ((struct bna_dma_addr *)(& tmp_addr))->lsb;
    i = i + 1;
    ldv_58872: ;
    if ((u32 )i < mem_info->num) {
      goto ldv_58871;
    } else {

    }

  } else {
    i = 0;
    goto ldv_58875;
    ldv_58874: 
    (mem_info->mdl + (unsigned long )i)->len = mem_info->len;
    (mem_info->mdl + (unsigned long )i)->kva = kzalloc((size_t )mem_info->len, 208U);
    if ((unsigned long )(mem_info->mdl + (unsigned long )i)->kva == (unsigned long )((void *)0)) {
      goto err_return;
    } else {

    }
    i = i + 1;
    ldv_58875: ;
    if ((u32 )i < mem_info->num) {
      goto ldv_58874;
    } else {

    }

  }
  return (0);
  err_return: 
  bnad_mem_free(bnad, mem_info);
  return (-12);
}
}
static void bnad_mbox_irq_free(struct bnad *bnad ) 
{ 
  int irq ;
  unsigned long flags ;

  {
  ldv_spin_lock();
  bnad_disable_mbox_irq(bnad);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  irq = (bnad->cfg_flags & 16U) != 0U ? (int )(bnad->msix_table)->vector : (int )(bnad->pcidev)->irq;
  ldv_free_irq_44((unsigned int )irq, (void *)bnad);
  return;
}
}
static int bnad_mbox_irq_alloc(struct bnad *bnad ) 
{ 
  int err ;
    klee_make_symbolic(&err, sizeof(int), "err");
  unsigned long irq_flags ;
    klee_make_symbolic(&irq_flags, sizeof(long), "irq_flags");
  unsigned long flags ;
  u32 irq ;
  irqreturn_t (*irq_handler)(int  , void * ) ;

  {
  err = 0;
  ldv_spin_lock();
  if ((bnad->cfg_flags & 16U) != 0U) {
    irq_handler = & bnad_msix_mbox_handler;
    irq = (bnad->msix_table)->vector;
    irq_flags = 0UL;
  } else {
    irq_handler = & bnad_isr;
    irq = (bnad->pcidev)->irq;
    irq_flags = 128UL;
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  sprintf((char *)(& bnad->mbox_irq_name), "%s", (char *)"bna");
  set_bit(2L, (unsigned long volatile   *)(& bnad->run_flags));
  bnad->stats.drv_stats.mbox_intr_disabled = bnad->stats.drv_stats.mbox_intr_disabled + 1ULL;
  err = ldv_request_irq_45(irq, irq_handler, irq_flags, (char const   *)(& bnad->mbox_irq_name),
                           (void *)bnad);
  return (err);
}
}
static void bnad_txrx_irq_free(struct bnad *bnad , struct bna_intr_info *intr_info ) 
{ 


  {
  kfree((void const   *)intr_info->idl);
  intr_info->idl = (struct bna_intr_descr *)0;
  return;
}
}
static int bnad_txrx_irq_alloc(struct bnad *bnad , enum bnad_intr_source src , u32 txrx_id ,
                               struct bna_intr_info *intr_info ) 
{ 
  int i ;
  int vector_start ;
    klee_make_symbolic(&vector_start, sizeof(int), "vector_start");
  u32 cfg_flags ;
  unsigned long flags ;
  void *tmp ;
  void *tmp___0 ;

  {
  vector_start = 0;
  ldv_spin_lock();
  cfg_flags = bnad->cfg_flags;
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if ((cfg_flags & 16U) != 0U) {
    intr_info->intr_type = 2;
    tmp = kcalloc((size_t )intr_info->num, 4UL, 208U);
    intr_info->idl = (struct bna_intr_descr *)tmp;
    if ((unsigned long )intr_info->idl == (unsigned long )((struct bna_intr_descr *)0)) {
      return (-12);
    } else {

    }
    switch ((unsigned int )src) {
    case 1U: 
    vector_start = (int )(txrx_id + 1U);
    goto ldv_58905;
    case 2U: 
    vector_start = (int )((bnad->num_tx * bnad->num_txq_per_tx + txrx_id) + 1U);
    goto ldv_58905;
    default: 
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bnad.c"),
                         "i" (1481), "i" (12UL));
    ldv_58908: ;
    goto ldv_58908;
    }
    ldv_58905: 
    i = 0;
    goto ldv_58910;
    ldv_58909: 
    (intr_info->idl + (unsigned long )i)->vector = vector_start + i;
    i = i + 1;
    ldv_58910: ;
    if (intr_info->num > i) {
      goto ldv_58909;
    } else {

    }

  } else {
    intr_info->intr_type = 1;
    intr_info->num = 1;
    tmp___0 = kcalloc((size_t )intr_info->num, 4UL, 208U);
    intr_info->idl = (struct bna_intr_descr *)tmp___0;
    if ((unsigned long )intr_info->idl == (unsigned long )((struct bna_intr_descr *)0)) {
      return (-12);
    } else {

    }
    switch ((unsigned int )src) {
    case 1U: 
    (intr_info->idl)->vector = 1;
    goto ldv_58913;
    case 2U: 
    (intr_info->idl)->vector = 2;
    goto ldv_58913;
    }
    ldv_58913: ;
  }
  return (0);
}
}
static void bnad_tx_msix_unregister(struct bnad *bnad , struct bnad_tx_info *tx_info ,
                                    int num_txqs ) 
{ 
  int i ;
  int vector_num ;
    klee_make_symbolic(&vector_num, sizeof(int), "vector_num");

  {
  i = 0;
  goto ldv_58924;
  ldv_58923: ;
  if ((unsigned long )tx_info->tcb[i] == (unsigned long )((struct bna_tcb *)0)) {
    goto ldv_58922;
  } else {

  }
  vector_num = (tx_info->tcb[i])->intr_vector;
  ldv_free_irq_46((bnad->msix_table + (unsigned long )vector_num)->vector, (void *)tx_info->tcb[i]);
  ldv_58922: 
  i = i + 1;
  ldv_58924: ;
  if (i < num_txqs) {
    goto ldv_58923;
  } else {

  }

  return;
}
}
static int bnad_tx_msix_register(struct bnad *bnad , struct bnad_tx_info *tx_info ,
                                 u32 tx_id , int num_txqs ) 
{ 
  int i ;
  int err ;
  int vector_num ;

  {
  i = 0;
  goto ldv_58937;
  ldv_58936: 
  vector_num = (tx_info->tcb[i])->intr_vector;
  sprintf((char *)(& (tx_info->tcb[i])->name), "%s TXQ %d", (char *)(& (bnad->netdev)->name),
          (u32 )(tx_info->tcb[i])->id + tx_id);
  err = ldv_request_irq_47((bnad->msix_table + (unsigned long )vector_num)->vector,
                           & bnad_msix_tx, 0UL, (char const   *)(& (tx_info->tcb[i])->name),
                           (void *)tx_info->tcb[i]);
  if (err != 0) {
    goto err_return;
  } else {

  }
  i = i + 1;
  ldv_58937: ;
  if (i < num_txqs) {
    goto ldv_58936;
  } else {

  }

  return (0);
  err_return: ;
  if (i > 0) {
    bnad_tx_msix_unregister(bnad, tx_info, i + -1);
  } else {

  }
  return (-1);
}
}
static void bnad_rx_msix_unregister(struct bnad *bnad , struct bnad_rx_info *rx_info ,
                                    int num_rxps ) 
{ 
  int i ;
  int vector_num ;

  {
  i = 0;
  goto ldv_58948;
  ldv_58947: ;
  if ((unsigned long )rx_info->rx_ctrl[i].ccb == (unsigned long )((struct bna_ccb *)0)) {
    goto ldv_58946;
  } else {

  }
  vector_num = (rx_info->rx_ctrl[i].ccb)->intr_vector;
  ldv_free_irq_48((bnad->msix_table + (unsigned long )vector_num)->vector, (void *)rx_info->rx_ctrl[i].ccb);
  ldv_58946: 
  i = i + 1;
  ldv_58948: ;
  if (i < num_rxps) {
    goto ldv_58947;
  } else {

  }

  return;
}
}
static int bnad_rx_msix_register(struct bnad *bnad , struct bnad_rx_info *rx_info ,
                                 u32 rx_id , int num_rxps ) 
{ 
  int i ;
  int err ;
  int vector_num ;

  {
  i = 0;
  goto ldv_58961;
  ldv_58960: 
  vector_num = (rx_info->rx_ctrl[i].ccb)->intr_vector;
  sprintf((char *)(& (rx_info->rx_ctrl[i].ccb)->name), "%s CQ %d", (char *)(& (bnad->netdev)->name),
          (u32 )(rx_info->rx_ctrl[i].ccb)->id + rx_id);
  err = ldv_request_irq_49((bnad->msix_table + (unsigned long )vector_num)->vector,
                           & bnad_msix_rx, 0UL, (char const   *)(& (rx_info->rx_ctrl[i].ccb)->name),
                           (void *)rx_info->rx_ctrl[i].ccb);
  if (err != 0) {
    goto err_return;
  } else {

  }
  i = i + 1;
  ldv_58961: ;
  if (i < num_rxps) {
    goto ldv_58960;
  } else {

  }

  return (0);
  err_return: ;
  if (i > 0) {
    bnad_rx_msix_unregister(bnad, rx_info, i + -1);
  } else {

  }
  return (-1);
}
}
static void bnad_tx_res_free(struct bnad *bnad , struct bna_res_info *res_info ) 
{ 
  int i ;

  {
  i = 0;
  goto ldv_58969;
  ldv_58968: ;
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 1U) {
    bnad_mem_free(bnad, & (res_info + (unsigned long )i)->res_u.mem_info);
  } else
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 2U) {
    bnad_txrx_irq_free(bnad, & (res_info + (unsigned long )i)->res_u.intr_info);
  } else {

  }
  i = i + 1;
  ldv_58969: ;
  if (i <= 6) {
    goto ldv_58968;
  } else {

  }

  return;
}
}
static int bnad_tx_res_alloc(struct bnad *bnad , struct bna_res_info *res_info , u32 tx_id ) 
{ 
  int i ;
  int err ;

  {
  err = 0;
  i = 0;
  goto ldv_58980;
  ldv_58979: ;
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 1U) {
    err = bnad_mem_alloc(bnad, & (res_info + (unsigned long )i)->res_u.mem_info);
  } else
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 2U) {
    err = bnad_txrx_irq_alloc(bnad, 1, tx_id, & (res_info + (unsigned long )i)->res_u.intr_info);
  } else {

  }
  if (err != 0) {
    goto err_return;
  } else {

  }
  i = i + 1;
  ldv_58980: ;
  if (i <= 6) {
    goto ldv_58979;
  } else {

  }

  return (0);
  err_return: 
  bnad_tx_res_free(bnad, res_info);
  return (err);
}
}
static void bnad_rx_res_free(struct bnad *bnad , struct bna_res_info *res_info ) 
{ 
  int i ;

  {
  i = 0;
  goto ldv_58988;
  ldv_58987: ;
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 1U) {
    bnad_mem_free(bnad, & (res_info + (unsigned long )i)->res_u.mem_info);
  } else
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 2U) {
    bnad_txrx_irq_free(bnad, & (res_info + (unsigned long )i)->res_u.intr_info);
  } else {

  }
  i = i + 1;
  ldv_58988: ;
  if (i <= 15) {
    goto ldv_58987;
  } else {

  }

  return;
}
}
static int bnad_rx_res_alloc(struct bnad *bnad , struct bna_res_info *res_info , uint rx_id ) 
{ 
  int i ;
  int err ;

  {
  err = 0;
  i = 0;
  goto ldv_58999;
  ldv_58998: ;
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 1U) {
    err = bnad_mem_alloc(bnad, & (res_info + (unsigned long )i)->res_u.mem_info);
  } else
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 2U) {
    err = bnad_txrx_irq_alloc(bnad, 2, rx_id, & (res_info + (unsigned long )i)->res_u.intr_info);
  } else {

  }
  if (err != 0) {
    goto err_return;
  } else {

  }
  i = i + 1;
  ldv_58999: ;
  if (i <= 15) {
    goto ldv_58998;
  } else {

  }

  return (0);
  err_return: 
  bnad_rx_res_free(bnad, res_info);
  return (err);
}
}
static void bnad_ioc_timeout(unsigned long data ) 
{ 
  struct bnad *bnad ;
  unsigned long flags ;

  {
  bnad = (struct bnad *)data;
  ldv_spin_lock();
  bfa_nw_ioc_timeout(& bnad->bna.ioceth.ioc);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_ioc_hb_check(unsigned long data ) 
{ 
  struct bnad *bnad ;
  unsigned long flags ;

  {
  bnad = (struct bnad *)data;
  ldv_spin_lock();
  bfa_nw_ioc_hb_check(& bnad->bna.ioceth.ioc);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_iocpf_timeout(unsigned long data ) 
{ 
  struct bnad *bnad ;
  unsigned long flags ;

  {
  bnad = (struct bnad *)data;
  ldv_spin_lock();
  bfa_nw_iocpf_timeout(& bnad->bna.ioceth.ioc);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_iocpf_sem_timeout(unsigned long data ) 
{ 
  struct bnad *bnad ;
  unsigned long flags ;

  {
  bnad = (struct bnad *)data;
  ldv_spin_lock();
  bfa_nw_iocpf_sem_timeout(& bnad->bna.ioceth.ioc);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_dim_timeout(unsigned long data ) 
{ 
  struct bnad *bnad ;
  struct bnad_rx_info *rx_info ;
  struct bnad_rx_ctrl *rx_ctrl ;
  int i ;
  int j ;
  unsigned long flags ;
  bool tmp ;
  int tmp___0 ;
  unsigned long tmp___1 ;
  int tmp___2 ;

  {
  bnad = (struct bnad *)data;
  tmp = netif_carrier_ok((struct net_device  const  *)bnad->netdev);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return;
  } else {

  }
  ldv_spin_lock();
  i = 0;
  goto ldv_59036;
  ldv_59035: 
  rx_info = (struct bnad_rx_info *)(& bnad->rx_info) + (unsigned long )i;
  if ((unsigned long )rx_info->rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_59030;
  } else {

  }
  j = 0;
  goto ldv_59033;
  ldv_59032: 
  rx_ctrl = (struct bnad_rx_ctrl *)(& rx_info->rx_ctrl) + (unsigned long )j;
  if ((unsigned long )rx_ctrl->ccb == (unsigned long )((struct bna_ccb *)0)) {
    goto ldv_59031;
  } else {

  }
  bna_rx_dim_update(rx_ctrl->ccb);
  ldv_59031: 
  j = j + 1;
  ldv_59033: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_59032;
  } else {

  }

  ldv_59030: 
  i = i + 1;
  ldv_59036: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_59035;
  } else {

  }
  tmp___2 = constant_test_bit(4L, (unsigned long const volatile   *)(& bnad->run_flags));
  if (tmp___2 != 0) {
    tmp___1 = msecs_to_jiffies(1000U);
    ldv_mod_timer_50(& bnad->dim_timer, tmp___1 + (unsigned long )jiffies);
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_stats_timeout(unsigned long data ) 
{ 
  struct bnad *bnad ;
  unsigned long flags ;
  bool tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
  bnad = (struct bnad *)data;
  tmp = netif_running((struct net_device  const  *)bnad->netdev);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return;
  } else {
    tmp___1 = constant_test_bit(5L, (unsigned long const volatile   *)(& bnad->run_flags));
    if (tmp___1 == 0) {
      return;
    } else {

    }
  }
  ldv_spin_lock();
  bna_hw_stats_get(& bnad->bna);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
void bnad_dim_timer_start(struct bnad *bnad ) 
{ 
  unsigned long tmp ;
  int tmp___0 ;

  {
  if ((int )bnad->cfg_flags & 1) {
    tmp___0 = constant_test_bit(4L, (unsigned long const volatile   *)(& bnad->run_flags));
    if (tmp___0 == 0) {
      reg_timer_7(& bnad->dim_timer, & bnad_dim_timeout, (unsigned long )bnad);
      set_bit(4L, (unsigned long volatile   *)(& bnad->run_flags));
      tmp = msecs_to_jiffies(1000U);
      ldv_mod_timer_51(& bnad->dim_timer, tmp + (unsigned long )jiffies);
    } else {

    }
  } else {

  }
  return;
}
}
static void bnad_stats_timer_start(struct bnad *bnad ) 
{ 
  unsigned long flags ;
  unsigned long tmp ;
  int tmp___0 ;

  {
  ldv_spin_lock();
  tmp___0 = test_and_set_bit(5L, (unsigned long volatile   *)(& bnad->run_flags));
  if (tmp___0 == 0) {
    reg_timer_7(& bnad->stats_timer, & bnad_stats_timeout, (unsigned long )bnad);
    tmp = msecs_to_jiffies(1000U);
    ldv_mod_timer_52(& bnad->stats_timer, tmp + (unsigned long )jiffies);
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_stats_timer_stop(struct bnad *bnad ) 
{ 
  int to_del ;
    klee_make_symbolic(&to_del, sizeof(int), "to_del");
  unsigned long flags ;
  int tmp ;

  {
  to_del = 0;
  ldv_spin_lock();
  tmp = test_and_clear_bit(5L, (unsigned long volatile   *)(& bnad->run_flags));
  if (tmp != 0) {
    to_del = 1;
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if (to_del != 0) {
    ldv_del_timer_sync_53(& bnad->stats_timer);
  } else {

  }
  return;
}
}
static void bnad_netdev_mc_list_get(struct net_device *netdev , u8 *mc_list ) 
{ 
  int i ;
  struct netdev_hw_addr *mc_addr ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  i = 1;
  __mptr = (struct list_head  const  *)netdev->mc.list.next;
  mc_addr = (struct netdev_hw_addr *)__mptr;
  goto ldv_59066;
  ldv_59065: 
  ether_addr_copy(mc_list + (unsigned long )(i * 6), (u8 const   *)(& mc_addr->addr));
  i = i + 1;
  __mptr___0 = (struct list_head  const  *)mc_addr->list.next;
  mc_addr = (struct netdev_hw_addr *)__mptr___0;
  ldv_59066: ;
  if ((unsigned long )(& mc_addr->list) != (unsigned long )(& netdev->mc.list)) {
    goto ldv_59065;
  } else {

  }

  return;
}
}
static int bnad_napi_poll_rx(struct napi_struct *napi , int budget ) 
{ 
  struct bnad_rx_ctrl *rx_ctrl ;
  struct napi_struct  const  *__mptr ;
  struct bnad *bnad ;
  int rcvd ;
    klee_make_symbolic(&rcvd, sizeof(int), "rcvd");
  bool tmp ;
  int tmp___0 ;
  u32 tmp___1 ;
  int tmp___2 ;
  long tmp___3 ;

  {
  __mptr = (struct napi_struct  const  *)napi;
  rx_ctrl = (struct bnad_rx_ctrl *)__mptr + 0xffffffffffffffe8UL;
  bnad = rx_ctrl->bnad;
  rcvd = 0;
  rx_ctrl->rx_poll_ctr = rx_ctrl->rx_poll_ctr + 1ULL;
  tmp = netif_carrier_ok((struct net_device  const  *)bnad->netdev);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    goto poll_exit;
  } else {

  }
  tmp___1 = bnad_cq_process(bnad, rx_ctrl->ccb, budget);
  rcvd = (int )tmp___1;
  if (rcvd >= budget) {
    return (rcvd);
  } else {

  }
  poll_exit: 
  napi_complete(napi);
  rx_ctrl->rx_complete = rx_ctrl->rx_complete + 1ULL;
  if ((unsigned long )rx_ctrl->ccb != (unsigned long )((struct bna_ccb *)0)) {
    tmp___2 = constant_test_bit(0L, (unsigned long const volatile   *)(& ((rx_ctrl->ccb)->rcb[0])->flags));
    tmp___3 = ldv__builtin_expect(tmp___2 != 0, 1L);
    if (tmp___3 != 0L) {
      ((rx_ctrl->ccb)->i_dbell)->doorbell_ack = (unsigned int )((int )(rx_ctrl->ccb)->rx_coalescing_timeo << 16) | 2147483648U;
      writel(((rx_ctrl->ccb)->i_dbell)->doorbell_ack, (void volatile   *)((rx_ctrl->ccb)->i_dbell)->doorbell_addr);
    } else {

    }
  } else {

  }
  return (rcvd);
}
}
static void bnad_napi_add(struct bnad *bnad , u32 rx_id ) 
{ 
  struct bnad_rx_ctrl *rx_ctrl ;
  int i ;

  {
  i = 0;
  goto ldv_59085;
  ldv_59084: 
  rx_ctrl = (struct bnad_rx_ctrl *)(& bnad->rx_info[rx_id].rx_ctrl) + (unsigned long )i;
  netif_napi_add(bnad->netdev, & rx_ctrl->napi, & bnad_napi_poll_rx, 64);
  i = i + 1;
  ldv_59085: ;
  if ((u32 )i < bnad->num_rxp_per_rx) {
    goto ldv_59084;
  } else {

  }

  return;
}
}
static void bnad_napi_delete(struct bnad *bnad , u32 rx_id ) 
{ 
  int i ;

  {
  i = 0;
  goto ldv_59093;
  ldv_59092: 
  netif_napi_del(& bnad->rx_info[rx_id].rx_ctrl[i].napi);
  i = i + 1;
  ldv_59093: ;
  if ((u32 )i < bnad->num_rxp_per_rx) {
    goto ldv_59092;
  } else {

  }

  return;
}
}
void bnad_destroy_tx(struct bnad *bnad , u32 tx_id ) 
{ 
  struct bnad_tx_info *tx_info ;
  struct bna_res_info *res_info ;
  unsigned long flags ;

  {
  tx_info = (struct bnad_tx_info *)(& bnad->tx_info) + (unsigned long )tx_id;
  res_info = (struct bna_res_info *)(& bnad->tx_res_info[tx_id].res_info);
  if ((unsigned long )tx_info->tx == (unsigned long )((struct bna_tx *)0)) {
    return;
  } else {

  }
  init_completion(& bnad->bnad_completions.tx_comp);
  ldv_spin_lock();
  bna_tx_disable(tx_info->tx, 0, & bnad_cb_tx_disabled);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& bnad->bnad_completions.tx_comp);
  if ((unsigned int )(tx_info->tcb[0])->intr_type == 2U) {
    bnad_tx_msix_unregister(bnad, tx_info, (int )bnad->num_txq_per_tx);
  } else {

  }
  ldv_spin_lock();
  bna_tx_destroy(tx_info->tx);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  tx_info->tx = (struct bna_tx *)0;
  tx_info->tx_id = 0U;
  bnad_tx_res_free(bnad, res_info);
  return;
}
}
int bnad_setup_tx(struct bnad *bnad , u32 tx_id ) 
{ 
  int err ;
  struct bnad_tx_info *tx_info ;
  struct bna_res_info *res_info ;
  struct bna_intr_info *intr_info ;
  struct bna_tx_config *tx_config ;
  struct bna_tx_event_cbfn tx_cbfn ;
  struct bna_tx *tx ;
  unsigned long flags ;
  struct lock_class_key __key ;
  atomic_long_t __constr_expr_0 ;
  struct lock_class_key __key___0 ;

  {
  tx_info = (struct bnad_tx_info *)(& bnad->tx_info) + (unsigned long )tx_id;
  res_info = (struct bna_res_info *)(& bnad->tx_res_info[tx_id].res_info);
  intr_info = & (res_info + 6UL)->res_u.intr_info;
  tx_config = (struct bna_tx_config *)(& bnad->tx_config) + (unsigned long )tx_id;
  tx_cbfn.tcb_setup_cbfn = & bnad_cb_tcb_setup;
  tx_cbfn.tcb_destroy_cbfn = & bnad_cb_tcb_destroy;
  tx_cbfn.tx_stall_cbfn = & bnad_cb_tx_stall;
  tx_cbfn.tx_resume_cbfn = & bnad_cb_tx_resume;
  tx_cbfn.tx_cleanup_cbfn = & bnad_cb_tx_cleanup;
  tx_info->tx_id = tx_id;
  tx_config->num_txq = (int )bnad->num_txq_per_tx;
  tx_config->txq_depth = (int )bnad->txq_depth;
  tx_config->tx_type = 0;
  tx_config->coalescing_timeo = (int )bnad->tx_coalescing_timeo;
  ldv_spin_lock();
  bna_tx_res_req((int )bnad->num_txq_per_tx, (int )bnad->txq_depth, res_info);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  (res_info + 1UL)->res_type = 1;
  (res_info + 1UL)->res_u.mem_info.mem_type = 1;
  (res_info + 1UL)->res_u.mem_info.num = bnad->num_txq_per_tx;
  (res_info + 1UL)->res_u.mem_info.len = bnad->txq_depth * 80U;
  err = bnad_tx_res_alloc(bnad, res_info, tx_id);
  if (err != 0) {
    return (err);
  } else {

  }
  ldv_spin_lock();
  tx = bna_tx_create(& bnad->bna, bnad, tx_config, & tx_cbfn, res_info, (void *)tx_info);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if ((unsigned long )tx == (unsigned long )((struct bna_tx *)0)) {
    err = -12;
    goto err_return;
  } else {

  }
  tx_info->tx = tx;
  __init_work(& tx_info->tx_cleanup_work.work, 0);
  __constr_expr_0.counter = 137438953408L;
  tx_info->tx_cleanup_work.work.data = __constr_expr_0;
  lockdep_init_map(& tx_info->tx_cleanup_work.work.lockdep_map, "(&(&tx_info->tx_cleanup_work)->work)",
                   & __key, 0);
  INIT_LIST_HEAD(& tx_info->tx_cleanup_work.work.entry);
  tx_info->tx_cleanup_work.work.func = (void (*)(struct work_struct * ))(& bnad_tx_cleanup);
  init_timer_key(& tx_info->tx_cleanup_work.timer, 2097152U, "(&(&tx_info->tx_cleanup_work)->timer)",
                 & __key___0);
  tx_info->tx_cleanup_work.timer.function = & delayed_work_timer_fn;
  tx_info->tx_cleanup_work.timer.data = (unsigned long )(& tx_info->tx_cleanup_work);
  if ((unsigned int )intr_info->intr_type == 2U) {
    err = bnad_tx_msix_register(bnad, tx_info, tx_id, (int )bnad->num_txq_per_tx);
    if (err != 0) {
      goto cleanup_tx;
    } else {

    }
  } else {

  }
  ldv_spin_lock();
  bna_tx_enable(tx);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return (0);
  cleanup_tx: 
  ldv_spin_lock();
  bna_tx_destroy(tx_info->tx);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  tx_info->tx = (struct bna_tx *)0;
  tx_info->tx_id = 0U;
  err_return: 
  bnad_tx_res_free(bnad, res_info);
  return (err);
}
}
static void bnad_init_rx_config(struct bnad *bnad , struct bna_rx_config *rx_config ) 
{ 


  {
  memset((void *)rx_config, 0, 108UL);
  rx_config->rx_type = 0;
  rx_config->num_paths = (int )bnad->num_rxp_per_rx;
  rx_config->coalescing_timeo = (int )bnad->rx_coalescing_timeo;
  if (bnad->num_rxp_per_rx > 1U) {
    rx_config->rss_status = 1;
    rx_config->rss_config.hash_type = 15;
    rx_config->rss_config.hash_mask = (unsigned int )((u8 )bnad->num_rxp_per_rx) - 1U;
    netdev_rss_key_fill((void *)(& rx_config->rss_config.toeplitz_hash_key), 40UL);
  } else {
    rx_config->rss_status = 0;
    memset((void *)(& rx_config->rss_config), 0, 48UL);
  }
  rx_config->frame_size = (bnad->netdev)->mtu + 22U;
  rx_config->q0_multi_buf = 0;
  rx_config->rxp_type = 2;
  if ((unsigned int )(bnad->pcidev)->device == 34U && rx_config->frame_size > 4096U) {
    rx_config->q0_buf_size = 2048U;
    rx_config->q0_num_vecs = 4U;
    rx_config->q0_depth = bnad->rxq_depth * rx_config->q0_num_vecs;
    rx_config->q0_multi_buf = 1;
  } else {
    rx_config->q0_buf_size = rx_config->frame_size;
    rx_config->q0_num_vecs = 1U;
    rx_config->q0_depth = bnad->rxq_depth;
  }
  if ((unsigned int )rx_config->rxp_type == 2U) {
    rx_config->q1_depth = bnad->rxq_depth;
    rx_config->q1_buf_size = 128U;
  } else {

  }
  rx_config->vlan_strip_status = ((bnad->netdev)->features & 256ULL) != 0ULL;
  return;
}
}
static void bnad_rx_ctrl_init(struct bnad *bnad , u32 rx_id ) 
{ 
  struct bnad_rx_info *rx_info ;
  int i ;

  {
  rx_info = (struct bnad_rx_info *)(& bnad->rx_info) + (unsigned long )rx_id;
  i = 0;
  goto ldv_59130;
  ldv_59129: 
  rx_info->rx_ctrl[i].bnad = bnad;
  i = i + 1;
  ldv_59130: ;
  if ((u32 )i < bnad->num_rxp_per_rx) {
    goto ldv_59129;
  } else {

  }

  return;
}
}
static u32 bnad_reinit_rx(struct bnad *bnad ) 
{ 
  struct net_device *netdev ;
  u32 err ;
  u32 current_err ;
  u32 rx_id ;
  u32 count ;
  unsigned long flags ;
  int tmp ;

  {
  netdev = bnad->netdev;
  err = 0U;
  current_err = 0U;
  rx_id = 0U;
  count = 0U;
  rx_id = 0U;
  goto ldv_59143;
  ldv_59142: ;
  if ((unsigned long )bnad->rx_info[rx_id].rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_59141;
  } else {

  }
  bnad_destroy_rx(bnad, rx_id);
  ldv_59141: 
  rx_id = rx_id + 1U;
  ldv_59143: ;
  if (bnad->num_rx > rx_id) {
    goto ldv_59142;
  } else {

  }
  ldv_spin_lock();
  bna_enet_mtu_set(& bnad->bna.enet, (int )((bnad->netdev)->mtu + 22U), (void (*)(struct bnad * ))0);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  rx_id = 0U;
  goto ldv_59146;
  ldv_59145: 
  count = count + 1U;
  tmp = bnad_setup_rx(bnad, rx_id);
  current_err = (u32 )tmp;
  if (current_err != 0U && err == 0U) {
    err = current_err;
    netdev_err((struct net_device  const  *)netdev, "RXQ:%u setup failed\n", rx_id);
  } else {

  }
  rx_id = rx_id + 1U;
  ldv_59146: ;
  if (bnad->num_rx > rx_id) {
    goto ldv_59145;
  } else {

  }

  if ((unsigned long )bnad->rx_info[0].rx != (unsigned long )((struct bna_rx *)0) && err == 0U) {
    bnad_restore_vlans(bnad, 0U);
    bnad_enable_default_bcast(bnad);
    ldv_spin_lock();
    bnad_mac_addr_set_locked(bnad, (u8 const   *)netdev->dev_addr);
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    bnad_set_rx_mode(netdev);
  } else {

  }
  return (count);
}
}
void bnad_destroy_rx(struct bnad *bnad , u32 rx_id ) 
{ 
  struct bnad_rx_info *rx_info ;
  struct bna_rx_config *rx_config ;
  struct bna_res_info *res_info ;
  unsigned long flags ;
  int to_del ;
  int tmp ;

  {
  rx_info = (struct bnad_rx_info *)(& bnad->rx_info) + (unsigned long )rx_id;
  rx_config = (struct bna_rx_config *)(& bnad->rx_config) + (unsigned long )rx_id;
  res_info = (struct bna_res_info *)(& bnad->rx_res_info[rx_id].res_info);
  to_del = 0;
  if ((unsigned long )rx_info->rx == (unsigned long )((struct bna_rx *)0)) {
    return;
  } else {

  }
  if (rx_id == 0U) {
    ldv_spin_lock();
    if ((int )bnad->cfg_flags & 1) {
      tmp = constant_test_bit(4L, (unsigned long const volatile   *)(& bnad->run_flags));
      if (tmp != 0) {
        clear_bit(4L, (unsigned long volatile   *)(& bnad->run_flags));
        to_del = 1;
      } else {

      }
    } else {

    }
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    if (to_del != 0) {
      ldv_del_timer_sync_54(& bnad->dim_timer);
    } else {

    }
  } else {

  }
  init_completion(& bnad->bnad_completions.rx_comp);
  ldv_spin_lock();
  bna_rx_disable(rx_info->rx, 0, & bnad_cb_rx_disabled);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& bnad->bnad_completions.rx_comp);
  if ((unsigned int )(rx_info->rx_ctrl[0].ccb)->intr_type == 2U) {
    bnad_rx_msix_unregister(bnad, rx_info, rx_config->num_paths);
  } else {

  }
  bnad_napi_delete(bnad, rx_id);
  ldv_spin_lock();
  bna_rx_destroy(rx_info->rx);
  rx_info->rx = (struct bna_rx *)0;
  rx_info->rx_id = 0U;
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  bnad_rx_res_free(bnad, res_info);
  return;
}
}
int bnad_setup_rx(struct bnad *bnad , u32 rx_id ) 
{ 
  int err ;
  struct bnad_rx_info *rx_info ;
  struct bna_res_info *res_info ;
  struct bna_intr_info *intr_info ;
  struct bna_rx_config *rx_config ;
  struct bna_rx_event_cbfn rx_cbfn ;
  struct bna_rx *rx ;
  unsigned long flags ;
  struct lock_class_key __key ;
  atomic_long_t __constr_expr_0 ;

  {
  rx_info = (struct bnad_rx_info *)(& bnad->rx_info) + (unsigned long )rx_id;
  res_info = (struct bna_res_info *)(& bnad->rx_res_info[rx_id].res_info);
  intr_info = & (res_info + 15UL)->res_u.intr_info;
  rx_config = (struct bna_rx_config *)(& bnad->rx_config) + (unsigned long )rx_id;
  rx_cbfn.rcb_setup_cbfn = (void (*)(struct bnad * , struct bna_rcb * ))0;
  rx_cbfn.rcb_destroy_cbfn = (void (*)(struct bnad * , struct bna_rcb * ))0;
  rx_cbfn.ccb_setup_cbfn = & bnad_cb_ccb_setup;
  rx_cbfn.ccb_destroy_cbfn = & bnad_cb_ccb_destroy;
  rx_cbfn.rx_stall_cbfn = & bnad_cb_rx_stall;
  rx_cbfn.rx_cleanup_cbfn = & bnad_cb_rx_cleanup;
  rx_cbfn.rx_post_cbfn = & bnad_cb_rx_post;
  rx_info->rx_id = rx_id;
  bnad_init_rx_config(bnad, rx_config);
  ldv_spin_lock();
  bna_rx_res_req(rx_config, res_info);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  (res_info + 3UL)->res_type = 1;
  (res_info + 3UL)->res_u.mem_info.mem_type = 1;
  (res_info + 3UL)->res_u.mem_info.num = (u32 )rx_config->num_paths;
  (res_info + 3UL)->res_u.mem_info.len = rx_config->q0_depth * 40U + 64U;
  if ((unsigned int )rx_config->rxp_type != 1U) {
    (res_info + 2UL)->res_type = 1;
    (res_info + 2UL)->res_u.mem_info.mem_type = 1;
    (res_info + 2UL)->res_u.mem_info.num = (u32 )rx_config->num_paths;
    (res_info + 2UL)->res_u.mem_info.len = rx_config->q1_depth * 40U + 64U;
  } else {

  }
  err = bnad_rx_res_alloc(bnad, res_info, rx_id);
  if (err != 0) {
    return (err);
  } else {

  }
  bnad_rx_ctrl_init(bnad, rx_id);
  ldv_spin_lock();
  rx = bna_rx_create(& bnad->bna, bnad, rx_config, & rx_cbfn, res_info, (void *)rx_info);
  if ((unsigned long )rx == (unsigned long )((struct bna_rx *)0)) {
    err = -12;
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    goto err_return;
  } else {

  }
  rx_info->rx = rx;
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  __init_work(& rx_info->rx_cleanup_work, 0);
  __constr_expr_0.counter = 137438953408L;
  rx_info->rx_cleanup_work.data = __constr_expr_0;
  lockdep_init_map(& rx_info->rx_cleanup_work.lockdep_map, "(&rx_info->rx_cleanup_work)",
                   & __key, 0);
  INIT_LIST_HEAD(& rx_info->rx_cleanup_work.entry);
  rx_info->rx_cleanup_work.func = (void (*)(struct work_struct * ))(& bnad_rx_cleanup);
  bnad_napi_add(bnad, rx_id);
  if ((unsigned int )intr_info->intr_type == 2U) {
    err = bnad_rx_msix_register(bnad, rx_info, rx_id, rx_config->num_paths);
    if (err != 0) {
      goto err_return;
    } else {

    }
  } else {

  }
  ldv_spin_lock();
  if (rx_id == 0U) {
    if ((int )bnad->cfg_flags & 1) {
      bna_rx_dim_reconfig(& bnad->bna, (u32 const   (*)[2])(& bna_napi_dim_vector));
    } else {

    }
    bna_rx_vlanfilter_enable(rx);
    bnad_dim_timer_start(bnad);
  } else {

  }
  bna_rx_enable(rx);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return (0);
  err_return: 
  bnad_destroy_rx(bnad, rx_id);
  return (err);
}
}
void bnad_tx_coalescing_timeo_set(struct bnad *bnad ) 
{ 
  struct bnad_tx_info *tx_info ;

  {
  tx_info = (struct bnad_tx_info *)(& bnad->tx_info);
  if ((unsigned long )tx_info->tx == (unsigned long )((struct bna_tx *)0)) {
    return;
  } else {

  }
  bna_tx_coalescing_timeo_set(tx_info->tx, (int )bnad->tx_coalescing_timeo);
  return;
}
}
void bnad_rx_coalescing_timeo_set(struct bnad *bnad ) 
{ 
  struct bnad_rx_info *rx_info ;
  int i ;

  {
  i = 0;
  goto ldv_59183;
  ldv_59182: 
  rx_info = (struct bnad_rx_info *)(& bnad->rx_info) + (unsigned long )i;
  if ((unsigned long )rx_info->rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_59181;
  } else {

  }
  bna_rx_coalescing_timeo_set(rx_info->rx, (int )bnad->rx_coalescing_timeo);
  ldv_59181: 
  i = i + 1;
  ldv_59183: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_59182;
  } else {

  }

  return;
}
}
int bnad_mac_addr_set_locked(struct bnad *bnad , u8 const   *mac_addr ) 
{ 
  int ret ;
  bool tmp ;
  int tmp___0 ;
  enum bna_cb_status tmp___1 ;

  {
  tmp = is_valid_ether_addr(mac_addr);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (-99);
  } else {

  }
  if ((unsigned long )bnad->rx_info[0].rx == (unsigned long )((struct bna_rx *)0)) {
    return (0);
  } else {

  }
  tmp___1 = bna_rx_ucast_set(bnad->rx_info[0].rx, mac_addr);
  ret = (int )tmp___1;
  if (ret != 0) {
    return (-99);
  } else {

  }
  return (0);
}
}
int bnad_enable_default_bcast(struct bnad *bnad ) 
{ 
  struct bnad_rx_info *rx_info ;
  int ret ;
  unsigned long flags ;
  enum bna_cb_status tmp ;

  {
  rx_info = (struct bnad_rx_info *)(& bnad->rx_info);
  init_completion(& bnad->bnad_completions.mcast_comp);
  ldv_spin_lock();
  tmp = bna_rx_mcast_add(rx_info->rx, (u8 const   *)(& bnad_bcast_addr), & bnad_cb_rx_mcast_add);
  ret = (int )tmp;
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if (ret == 0) {
    wait_for_completion(& bnad->bnad_completions.mcast_comp);
  } else {
    return (-19);
  }
  if ((unsigned int )bnad->bnad_completions.mcast_comp_status != 0U) {
    return (-19);
  } else {

  }
  return (0);
}
}
void bnad_restore_vlans(struct bnad *bnad , u32 rx_id ) 
{ 
  u16 vid ;
  unsigned long flags ;
  unsigned long tmp ;
  unsigned long tmp___0 ;

  {
  tmp = find_first_bit((unsigned long const   *)(& bnad->active_vlans), 4096UL);
  vid = (u16 )tmp;
  goto ldv_59203;
  ldv_59202: 
  ldv_spin_lock();
  bna_rx_vlan_add(bnad->rx_info[rx_id].rx, (int )vid);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  tmp___0 = find_next_bit((unsigned long const   *)(& bnad->active_vlans), 4096UL,
                          (unsigned long )((int )vid + 1));
  vid = (u16 )tmp___0;
  ldv_59203: ;
  if ((unsigned int )vid <= 4095U) {
    goto ldv_59202;
  } else {

  }

  return;
}
}
void bnad_netdev_qstats_fill(struct bnad *bnad , struct rtnl_link_stats64 *stats ) 
{ 
  int i ;
  int j ;

  {
  i = 0;
  goto ldv_59215;
  ldv_59214: 
  j = 0;
  goto ldv_59212;
  ldv_59211: ;
  if ((unsigned long )bnad->rx_info[i].rx_ctrl[j].ccb != (unsigned long )((struct bna_ccb *)0)) {
    stats->rx_packets = stats->rx_packets + (((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[0])->rxq)->rx_packets;
    stats->rx_bytes = stats->rx_bytes + (((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[0])->rxq)->rx_bytes;
    if ((unsigned long )(bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1] != (unsigned long )((struct bna_rcb *)0) && (unsigned long )((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1])->rxq != (unsigned long )((struct bna_rxq *)0)) {
      stats->rx_packets = stats->rx_packets + (((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1])->rxq)->rx_packets;
      stats->rx_bytes = stats->rx_bytes + (((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1])->rxq)->rx_bytes;
    } else {

    }
  } else {

  }
  j = j + 1;
  ldv_59212: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_59211;
  } else {

  }
  i = i + 1;
  ldv_59215: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_59214;
  } else {

  }
  i = 0;
  goto ldv_59221;
  ldv_59220: 
  j = 0;
  goto ldv_59218;
  ldv_59217: ;
  if ((unsigned long )bnad->tx_info[i].tcb[j] != (unsigned long )((struct bna_tcb *)0)) {
    stats->tx_packets = stats->tx_packets + ((bnad->tx_info[i].tcb[j])->txq)->tx_packets;
    stats->tx_bytes = stats->tx_bytes + ((bnad->tx_info[i].tcb[j])->txq)->tx_bytes;
  } else {

  }
  j = j + 1;
  ldv_59218: ;
  if ((u32 )j < bnad->num_txq_per_tx) {
    goto ldv_59217;
  } else {

  }
  i = i + 1;
  ldv_59221: ;
  if ((u32 )i < bnad->num_tx) {
    goto ldv_59220;
  } else {

  }

  return;
}
}
void bnad_netdev_hwstats_fill(struct bnad *bnad , struct rtnl_link_stats64 *stats ) 
{ 
  struct bfi_enet_stats_mac *mac_stats ;
  u32 bmap___0 ;
  int i ;

  {
  mac_stats = & (bnad->stats.bna_stats)->hw_stats.mac_stats;
  stats->rx_errors = (((mac_stats->rx_fcs_error + mac_stats->rx_alignment_error) + mac_stats->rx_frame_length_error) + mac_stats->rx_code_error) + mac_stats->rx_undersize;
  stats->tx_errors = mac_stats->tx_fcs_error + mac_stats->tx_undersize;
  stats->rx_dropped = mac_stats->rx_drop;
  stats->tx_dropped = mac_stats->tx_drop;
  stats->multicast = mac_stats->rx_multicast;
  stats->collisions = mac_stats->tx_total_collision;
  stats->rx_length_errors = mac_stats->rx_frame_length_error;
  stats->rx_crc_errors = mac_stats->rx_fcs_error;
  stats->rx_frame_errors = mac_stats->rx_alignment_error;
  bmap___0 = bnad->bna.rx_mod.rid_mask;
  i = 0;
  goto ldv_59232;
  ldv_59231: ;
  if ((int )bmap___0 & 1) {
    stats->rx_fifo_errors = stats->rx_fifo_errors + (bnad->stats.bna_stats)->hw_stats.rxf_stats[i].frame_drops;
    goto ldv_59230;
  } else {

  }
  bmap___0 = bmap___0 >> 1;
  i = i + 1;
  ldv_59232: ;
  if (bmap___0 != 0U) {
    goto ldv_59231;
  } else {

  }
  ldv_59230: ;
  return;
}
}
static void bnad_mbox_irq_sync(struct bnad *bnad ) 
{ 
  u32 irq ;
  unsigned long flags ;

  {
  ldv_spin_lock();
  if ((bnad->cfg_flags & 16U) != 0U) {
    irq = (bnad->msix_table)->vector;
  } else {
    irq = (bnad->pcidev)->irq;
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  synchronize_irq(irq);
  return;
}
}
static int bnad_tso_prepare(struct bnad *bnad , struct sk_buff *skb ) 
{ 
  int err ;
  struct iphdr *iph ;
  struct iphdr *tmp ;
  struct tcphdr *tmp___0 ;
  __sum16 tmp___1 ;
  struct ipv6hdr *ipv6h ;
  struct ipv6hdr *tmp___2 ;
  struct tcphdr *tmp___3 ;
  __sum16 tmp___4 ;
  __be16 tmp___5 ;

  {
  err = skb_cow_head(skb, 0U);
  if (err < 0) {
    bnad->stats.drv_stats.tso_err = bnad->stats.drv_stats.tso_err + 1ULL;
    return (err);
  } else {

  }
  tmp___5 = vlan_get_protocol(skb);
  if ((unsigned int )tmp___5 == 8U) {
    tmp = ip_hdr((struct sk_buff  const  *)skb);
    iph = tmp;
    iph->tot_len = 0U;
    iph->check = 0U;
    tmp___0 = tcp_hdr((struct sk_buff  const  *)skb);
    tmp___1 = csum_tcpudp_magic(iph->saddr, iph->daddr, 0, 6, 0U);
    tmp___0->check = ~ ((int )tmp___1);
    bnad->stats.drv_stats.tso4 = bnad->stats.drv_stats.tso4 + 1ULL;
  } else {
    tmp___2 = ipv6_hdr((struct sk_buff  const  *)skb);
    ipv6h = tmp___2;
    ipv6h->payload_len = 0U;
    tmp___3 = tcp_hdr((struct sk_buff  const  *)skb);
    tmp___4 = csum_ipv6_magic((struct in6_addr  const  *)(& ipv6h->saddr), (struct in6_addr  const  *)(& ipv6h->daddr),
                              0U, 6, 0U);
    tmp___3->check = ~ ((int )tmp___4);
    bnad->stats.drv_stats.tso6 = bnad->stats.drv_stats.tso6 + 1ULL;
  }
  return (0);
}
}
static void bnad_q_num_init(struct bnad *bnad ) 
{ 
  int rxps ;
    klee_make_symbolic(&rxps, sizeof(int), "rxps");
  unsigned int _min1 ;
    klee_make_symbolic(&_min1, sizeof(int), "_min1");
  unsigned int tmp ;
  unsigned int _min2 ;
    klee_make_symbolic(&_min2, sizeof(int), "_min2");

  {
  tmp = cpumask_weight(cpu_online_mask);
  _min1 = tmp;
  _min2 = 16U;
  rxps = (int )(_min1 < _min2 ? _min1 : _min2);
  if ((bnad->cfg_flags & 16U) == 0U) {
    rxps = 1;
  } else {

  }
  bnad->num_rx = 1U;
  bnad->num_tx = 1U;
  bnad->num_rxp_per_rx = (u32 )rxps;
  bnad->num_txq_per_tx = 1U;
  return;
}
}
static void bnad_q_num_adjust(struct bnad *bnad , int msix_vectors , int temp ) 
{ 


  {
  bnad->num_txq_per_tx = 1U;
  if ((u32 )msix_vectors >= (bnad->num_tx * bnad->num_txq_per_tx + bnad_rxqs_per_cq) + 1U && (bnad->cfg_flags & 16U) != 0U) {
    bnad->num_rxp_per_rx = ((u32 )msix_vectors - bnad->num_tx * bnad->num_txq_per_tx) - 1U;
  } else {
    bnad->num_rxp_per_rx = 1U;
  }
  return;
}
}
static int bnad_ioceth_disable(struct bnad *bnad ) 
{ 
  unsigned long flags ;
  int err ;
  unsigned long tmp ;

  {
  err = 0;
  ldv_spin_lock();
  init_completion(& bnad->bnad_completions.ioc_comp);
  bna_ioceth_disable(& bnad->bna.ioceth, 0);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  tmp = msecs_to_jiffies(10000U);
  wait_for_completion_timeout(& bnad->bnad_completions.ioc_comp, tmp);
  err = (int )bnad->bnad_completions.ioc_comp_status;
  return (err);
}
}
static int bnad_ioceth_enable(struct bnad *bnad ) 
{ 
  int err ;
  unsigned long flags ;
  unsigned long tmp ;

  {
  err = 0;
  ldv_spin_lock();
  init_completion(& bnad->bnad_completions.ioc_comp);
  bnad->bnad_completions.ioc_comp_status = 7U;
  bna_ioceth_enable(& bnad->bna.ioceth);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  tmp = msecs_to_jiffies(10000U);
  wait_for_completion_timeout(& bnad->bnad_completions.ioc_comp, tmp);
  err = (int )bnad->bnad_completions.ioc_comp_status;
  return (err);
}
}
static void bnad_res_free(struct bnad *bnad , struct bna_res_info *res_info , u32 res_val_max ) 
{ 
  int i ;

  {
  i = 0;
  goto ldv_59274;
  ldv_59273: 
  bnad_mem_free(bnad, & (res_info + (unsigned long )i)->res_u.mem_info);
  i = i + 1;
  ldv_59274: ;
  if ((u32 )i < res_val_max) {
    goto ldv_59273;
  } else {

  }

  return;
}
}
static int bnad_res_alloc(struct bnad *bnad , struct bna_res_info *res_info , u32 res_val_max ) 
{ 
  int i ;
  int err ;

  {
  i = 0;
  goto ldv_59285;
  ldv_59284: 
  err = bnad_mem_alloc(bnad, & (res_info + (unsigned long )i)->res_u.mem_info);
  if (err != 0) {
    goto err_return;
  } else {

  }
  i = i + 1;
  ldv_59285: ;
  if ((u32 )i < res_val_max) {
    goto ldv_59284;
  } else {

  }

  return (0);
  err_return: 
  bnad_res_free(bnad, res_info, res_val_max);
  return (err);
}
}
static void bnad_enable_msix(struct bnad *bnad ) 
{ 
  int i ;
  int ret ;
  unsigned long flags ;
  void *tmp ;

  {
  ldv_spin_lock();
  if ((bnad->cfg_flags & 16U) == 0U) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    return;
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if ((unsigned long )bnad->msix_table != (unsigned long )((struct msix_entry *)0)) {
    return;
  } else {

  }
  tmp = kcalloc((size_t )bnad->msix_num, 8UL, 208U);
  bnad->msix_table = (struct msix_entry *)tmp;
  if ((unsigned long )bnad->msix_table == (unsigned long )((struct msix_entry *)0)) {
    goto intx_mode;
  } else {

  }
  i = 0;
  goto ldv_59295;
  ldv_59294: 
  (bnad->msix_table + (unsigned long )i)->entry = (u16 )i;
  i = i + 1;
  ldv_59295: ;
  if ((u32 )i < bnad->msix_num) {
    goto ldv_59294;
  } else {

  }
  ret = pci_enable_msix_range(bnad->pcidev, bnad->msix_table, 1, (int )bnad->msix_num);
  if (ret < 0) {
    goto intx_mode;
  } else
  if ((u32 )ret < bnad->msix_num) {
    dev_warn((struct device  const  *)(& (bnad->pcidev)->dev), "%d MSI-X vectors allocated < %d requested\n",
             ret, bnad->msix_num);
    ldv_spin_lock();
    bnad_q_num_adjust(bnad, (ret + -1) / 2, (ret + -1) / 2);
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    bnad->msix_num = (bnad->num_tx * bnad->num_txq_per_tx + bnad->num_rx * bnad->num_rxp_per_rx) + 1U;
    if (bnad->msix_num > (u32 )ret) {
      pci_disable_msix(bnad->pcidev);
      goto intx_mode;
    } else {

    }
  } else {

  }
  pci_intx(bnad->pcidev, 0);
  return;
  intx_mode: 
  dev_warn((struct device  const  *)(& (bnad->pcidev)->dev), "MSI-X enable failed - operating in INTx mode\n");
  kfree((void const   *)bnad->msix_table);
  bnad->msix_table = (struct msix_entry *)0;
  bnad->msix_num = 0U;
  ldv_spin_lock();
  bnad->cfg_flags = bnad->cfg_flags & 4294967279U;
  bnad_q_num_init(bnad);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_disable_msix(struct bnad *bnad ) 
{ 
  u32 cfg_flags ;
  unsigned long flags ;

  {
  ldv_spin_lock();
  cfg_flags = bnad->cfg_flags;
  if ((bnad->cfg_flags & 16U) != 0U) {
    bnad->cfg_flags = bnad->cfg_flags & 4294967279U;
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if ((cfg_flags & 16U) != 0U) {
    pci_disable_msix(bnad->pcidev);
    kfree((void const   *)bnad->msix_table);
    bnad->msix_table = (struct msix_entry *)0;
  } else {

  }
  return;
}
}
static int bnad_open(struct net_device *netdev ) 
{ 
  int err ;
  struct bnad *bnad ;
  void *tmp ;
  struct bna_pause_config pause_config ;
  unsigned long flags ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  err = bnad_setup_tx(bnad, 0U);
  if (err != 0) {
    goto err_return;
  } else {

  }
  err = bnad_setup_rx(bnad, 0U);
  if (err != 0) {
    goto cleanup_tx;
  } else {

  }
  pause_config.tx_pause = 0;
  pause_config.rx_pause = 0;
  ldv_spin_lock();
  bna_enet_mtu_set(& bnad->bna.enet, (int )((bnad->netdev)->mtu + 22U), (void (*)(struct bnad * ))0);
  bna_enet_pause_config(& bnad->bna.enet, & pause_config);
  bna_enet_enable(& bnad->bna.enet);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  bnad_enable_default_bcast(bnad);
  bnad_restore_vlans(bnad, 0U);
  ldv_spin_lock();
  bnad_mac_addr_set_locked(bnad, (u8 const   *)netdev->dev_addr);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  bnad_stats_timer_start(bnad);
  mutex_unlock(& bnad->conf_mutex);
  return (0);
  cleanup_tx: 
  bnad_destroy_tx(bnad, 0U);
  err_return: 
  mutex_unlock(& bnad->conf_mutex);
  return (err);
}
}
static int bnad_stop(struct net_device *netdev ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  unsigned long flags ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  bnad_stats_timer_stop(bnad);
  init_completion(& bnad->bnad_completions.enet_comp);
  ldv_spin_lock();
  bna_enet_disable(& bnad->bna.enet, 0, & bnad_cb_enet_disabled);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& bnad->bnad_completions.enet_comp);
  bnad_destroy_tx(bnad, 0U);
  bnad_destroy_rx(bnad, 0U);
  bnad_mbox_irq_sync(bnad);
  mutex_unlock(& bnad->conf_mutex);
  return (0);
}
}
static int bnad_txq_wi_prepare(struct bnad *bnad , struct bna_tcb *tcb , struct sk_buff *skb ,
                               struct bna_txq_entry *txqent ) 
{ 
  u16 flags ;
  u32 gso_size ;
  u16 vlan_tag ;
  int tmp ;
  __u16 tmp___0 ;
  unsigned char *tmp___1 ;
  long tmp___2 ;
  __u16 tmp___3 ;
  int tmp___4 ;
    klee_make_symbolic(&tmp___4, sizeof(int), "tmp___4");
  unsigned int tmp___5 ;
  long tmp___6 ;
  int tmp___7 ;
    klee_make_symbolic(&tmp___7, sizeof(int), "tmp___7");
  unsigned int tmp___8 ;
    klee_make_symbolic(&tmp___8, sizeof(int), "tmp___8");
  int tmp___9 ;
  __u16 tmp___10 ;
  long tmp___11 ;
    klee_make_symbolic(&tmp___11, sizeof(long), "tmp___11");
  __be16 net_proto ;
  __be16 tmp___12 ;
  u8 proto ;
  struct iphdr *tmp___13 ;
  struct ipv6hdr *tmp___14 ;
  int tmp___15 ;
    klee_make_symbolic(&tmp___15, sizeof(int), "tmp___15");
  __u16 tmp___16 ;
  unsigned int tmp___17 ;
    klee_make_symbolic(&tmp___17, sizeof(int), "tmp___17");
  int tmp___18 ;
    klee_make_symbolic(&tmp___18, sizeof(int), "tmp___18");
  unsigned int tmp___19 ;
    klee_make_symbolic(&tmp___19, sizeof(int), "tmp___19");
  long tmp___20 ;
    klee_make_symbolic(&tmp___20, sizeof(long), "tmp___20");
  int tmp___21 ;
    klee_make_symbolic(&tmp___21, sizeof(int), "tmp___21");
  __u16 tmp___22 ;
  unsigned int tmp___23 ;
    klee_make_symbolic(&tmp___23, sizeof(int), "tmp___23");
  int tmp___24 ;
    klee_make_symbolic(&tmp___24, sizeof(int), "tmp___24");
  long tmp___25 ;
    klee_make_symbolic(&tmp___25, sizeof(long), "tmp___25");
  bool tmp___26 ;
  __u16 tmp___27 ;
  __u32 tmp___28 ;

  {
  flags = 0U;
  vlan_tag = 0U;
  if (((int )skb->vlan_tci & 4096) != 0) {
    vlan_tag = (unsigned int )skb->vlan_tci & 61439U;
    flags = (u16 )((unsigned int )flags | 24U);
  } else {

  }
  tmp = constant_test_bit(0L, (unsigned long const volatile   *)(& bnad->run_flags));
  if (tmp != 0) {
    vlan_tag = (u16 )((int )((short )((int )tcb->priority << 13)) | ((int )((short )vlan_tag) & 8191));
    flags = (u16 )((unsigned int )flags | 24U);
  } else {

  }
  tmp___0 = __fswab16((int )vlan_tag);
  txqent->hdr.wi.vlan_tag = tmp___0;
  tmp___26 = skb_is_gso((struct sk_buff  const  *)skb);
  if ((int )tmp___26) {
    tmp___1 = skb_end_pointer((struct sk_buff  const  *)skb);
    gso_size = (u32 )((struct skb_shared_info *)tmp___1)->gso_size;
    tmp___2 = ldv__builtin_expect((bnad->netdev)->mtu < gso_size, 0L);
    if (tmp___2 != 0L) {
      bnad->stats.drv_stats.tx_skb_mss_too_long = bnad->stats.drv_stats.tx_skb_mss_too_long + 1ULL;
      return (-22);
    } else {

    }
    tmp___4 = skb_transport_offset((struct sk_buff  const  *)skb);
    tmp___5 = tcp_hdrlen((struct sk_buff  const  *)skb);
    tmp___6 = ldv__builtin_expect(((u32 )tmp___4 + gso_size) + tmp___5 >= skb->len, 0L);
    if (tmp___6 != 0L) {
      txqent->hdr.wi.opcode = 516U;
      txqent->hdr.wi.lso_mss = 0U;
      bnad->stats.drv_stats.tx_skb_tso_too_short = bnad->stats.drv_stats.tx_skb_tso_too_short + 1ULL;
    } else {
      txqent->hdr.wi.opcode = 772U;
      tmp___3 = __fswab16((int )((__u16 )gso_size));
      txqent->hdr.wi.lso_mss = tmp___3;
    }
    tmp___7 = bnad_tso_prepare(bnad, skb);
    if (tmp___7 != 0) {
      bnad->stats.drv_stats.tx_skb_tso_prepare = bnad->stats.drv_stats.tx_skb_tso_prepare + 1ULL;
      return (-22);
    } else {

    }
    flags = (u16 )((unsigned int )flags | 3U);
    tmp___8 = tcp_hdrlen((struct sk_buff  const  *)skb);
    tmp___9 = skb_transport_offset((struct sk_buff  const  *)skb);
    tmp___10 = __fswab16((int )((unsigned int )((int )((__u16 )(tmp___8 >> 2)) << 10U) | ((unsigned int )((__u16 )tmp___9) & 1023U)));
    txqent->hdr.wi.l4_hdr_size_n_offset = tmp___10;
  } else {
    txqent->hdr.wi.opcode = 516U;
    txqent->hdr.wi.lso_mss = 0U;
    tmp___11 = ldv__builtin_expect(skb->len > (bnad->netdev)->mtu + 18U, 0L);
    if (tmp___11 != 0L) {
      bnad->stats.drv_stats.tx_skb_non_tso_too_long = bnad->stats.drv_stats.tx_skb_non_tso_too_long + 1ULL;
      return (-22);
    } else {

    }
    if ((unsigned int )*((unsigned char *)skb + 145UL) == 6U) {
      tmp___12 = vlan_get_protocol(skb);
      net_proto = tmp___12;
      proto = 0U;
      if ((unsigned int )net_proto == 8U) {
        tmp___13 = ip_hdr((struct sk_buff  const  *)skb);
        proto = tmp___13->protocol;
      } else
      if ((unsigned int )net_proto == 56710U) {
        tmp___14 = ipv6_hdr((struct sk_buff  const  *)skb);
        proto = tmp___14->nexthdr;
      } else {

      }
      if ((unsigned int )proto == 6U) {
        flags = (u16 )((unsigned int )flags | 2U);
        tmp___15 = skb_transport_offset((struct sk_buff  const  *)skb);
        tmp___16 = __fswab16((int )((__u16 )tmp___15) & 1023);
        txqent->hdr.wi.l4_hdr_size_n_offset = tmp___16;
        bnad->stats.drv_stats.tcpcsum_offload = bnad->stats.drv_stats.tcpcsum_offload + 1ULL;
        tmp___17 = skb_headlen((struct sk_buff  const  *)skb);
        tmp___18 = skb_transport_offset((struct sk_buff  const  *)skb);
        tmp___19 = tcp_hdrlen((struct sk_buff  const  *)skb);
        tmp___20 = ldv__builtin_expect(tmp___17 < (unsigned int )tmp___18 + tmp___19,
                                    0L);
        if (tmp___20 != 0L) {
          bnad->stats.drv_stats.tx_skb_tcp_hdr = bnad->stats.drv_stats.tx_skb_tcp_hdr + 1ULL;
          return (-22);
        } else {

        }
      } else
      if ((unsigned int )proto == 17U) {
        flags = (u16 )((unsigned int )flags | 4U);
        tmp___21 = skb_transport_offset((struct sk_buff  const  *)skb);
        tmp___22 = __fswab16((int )((__u16 )tmp___21) & 1023);
        txqent->hdr.wi.l4_hdr_size_n_offset = tmp___22;
        bnad->stats.drv_stats.udpcsum_offload = bnad->stats.drv_stats.udpcsum_offload + 1ULL;
        tmp___23 = skb_headlen((struct sk_buff  const  *)skb);
        tmp___24 = skb_transport_offset((struct sk_buff  const  *)skb);
        tmp___25 = ldv__builtin_expect((unsigned long )tmp___23 < (unsigned long )tmp___24 + 8UL,
                                    0L);
        if (tmp___25 != 0L) {
          bnad->stats.drv_stats.tx_skb_udp_hdr = bnad->stats.drv_stats.tx_skb_udp_hdr + 1ULL;
          return (-22);
        } else {

        }
      } else {
        bnad->stats.drv_stats.tx_skb_csum_err = bnad->stats.drv_stats.tx_skb_csum_err + 1ULL;
        return (-22);
      }
    } else {
      txqent->hdr.wi.l4_hdr_size_n_offset = 0U;
    }
  }
  tmp___27 = __fswab16((int )flags);
  txqent->hdr.wi.flags = tmp___27;
  tmp___28 = __fswab32(skb->len);
  txqent->hdr.wi.frame_length = tmp___28;
  return (0);
}
}
static netdev_tx_t bnad_start_xmit(struct sk_buff *skb , struct net_device *netdev ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  u32 txq_id ;
  struct bna_tcb *tcb ;
  struct bnad_tx_unmap *unmap_q ;
  struct bnad_tx_unmap *unmap ;
  struct bnad_tx_unmap *head_unmap ;
  u32 prod ;
  u32 q_depth ;
  u32 vect_id ;
  u32 wis ;
  u32 vectors ;
  u32 len ;
  int i ;
  dma_addr_t dma_addr ;
  struct bna_txq_entry *txqent ;
  long tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  long tmp___5 ;
  unsigned char *tmp___6 ;
  long tmp___7 ;
  u32 sent ;
  int tmp___8 ;
  long tmp___9 ;
  int tmp___10 ;
    klee_make_symbolic(&tmp___10, sizeof(int), "tmp___10");
  long tmp___11 ;
  long tmp___12 ;
    klee_make_symbolic(&tmp___12, sizeof(long), "tmp___12");
  int tmp___13 ;
    klee_make_symbolic(&tmp___13, sizeof(int), "tmp___13");
  u64 tmp_addr ;
  __u64 tmp___14 ;
  __u16 tmp___15 ;
  struct skb_frag_struct  const  *frag ;
  unsigned char *tmp___16 ;
  u32 size ;
  unsigned int tmp___17 ;
  long tmp___18 ;
  u64 tmp_addr___0 ;
  __u64 tmp___19 ;
  __u16 tmp___20 ;
  long tmp___21 ;
  int tmp___22 ;
    klee_make_symbolic(&tmp___22, sizeof(int), "tmp___22");
  long tmp___23 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  txq_id = 0U;
  tcb = (struct bna_tcb *)0;
  len = skb_headlen((struct sk_buff  const  *)skb);
  tmp___0 = ldv__builtin_expect(skb->len <= 14U, 0L);
  if (tmp___0 != 0L) {
    dev_kfree_skb_any(skb);
    bnad->stats.drv_stats.tx_skb_too_short = bnad->stats.drv_stats.tx_skb_too_short + 1ULL;
    return (0);
  } else {

  }
  tmp___1 = ldv__builtin_expect(len > 65535U, 0L);
  if (tmp___1 != 0L) {
    dev_kfree_skb_any(skb);
    bnad->stats.drv_stats.tx_skb_headlen_zero = bnad->stats.drv_stats.tx_skb_headlen_zero + 1ULL;
    return (0);
  } else {

  }
  tmp___2 = ldv__builtin_expect(len == 0U, 0L);
  if (tmp___2 != 0L) {
    dev_kfree_skb_any(skb);
    bnad->stats.drv_stats.tx_skb_headlen_zero = bnad->stats.drv_stats.tx_skb_headlen_zero + 1ULL;
    return (0);
  } else {

  }
  tcb = bnad->tx_info[0].tcb[txq_id];
  if ((unsigned long )tcb == (unsigned long )((struct bna_tcb *)0)) {
    tmp___4 = 1;
  } else {
    tmp___3 = constant_test_bit(1L, (unsigned long const volatile   *)(& tcb->flags));
    if (tmp___3 == 0) {
      tmp___4 = 1;
    } else {
      tmp___4 = 0;
    }
  }
  tmp___5 = ldv__builtin_expect((long )tmp___4, 0L);
  if (tmp___5 != 0L) {
    dev_kfree_skb_any(skb);
    bnad->stats.drv_stats.tx_skb_stopping = bnad->stats.drv_stats.tx_skb_stopping + 1ULL;
    return (0);
  } else {

  }
  q_depth = tcb->q_depth;
  prod = tcb->producer_index;
  unmap_q = (struct bnad_tx_unmap *)tcb->unmap_q;
  tmp___6 = skb_end_pointer((struct sk_buff  const  *)skb);
  vectors = (u32 )((int )((struct skb_shared_info *)tmp___6)->nr_frags + 1);
  wis = (vectors + 3U) >> 2;
  tmp___7 = ldv__builtin_expect(vectors > 255U, 0L);
  if (tmp___7 != 0L) {
    dev_kfree_skb_any(skb);
    bnad->stats.drv_stats.tx_skb_max_vectors = bnad->stats.drv_stats.tx_skb_max_vectors + 1ULL;
    return (0);
  } else {

  }
  tmp___12 = ldv__builtin_expect((((tcb->consumer_index - tcb->producer_index) - 1U) & (q_depth - 1U)) < wis,
                              0L);
  if (tmp___12 != 0L) {
    if ((unsigned int )*(tcb->hw_consumer_index) != tcb->consumer_index) {
      tmp___10 = test_and_set_bit(0L, (unsigned long volatile   *)(& tcb->flags));
      if (tmp___10 == 0) {
        sent = bnad_txcmpl_process(bnad, tcb);
        tmp___8 = constant_test_bit(1L, (unsigned long const volatile   *)(& tcb->flags));
        tmp___9 = ldv__builtin_expect(tmp___8 != 0, 1L);
        if (tmp___9 != 0L) {
          writel((tcb->i_dbell)->doorbell_ack | sent, (void volatile   *)(tcb->i_dbell)->doorbell_addr);
        } else {

        }
        __asm__  volatile   ("": : : "memory");
        clear_bit(0L, (unsigned long volatile   *)(& tcb->flags));
      } else {
        netif_stop_queue(netdev);
        bnad->stats.drv_stats.netif_queue_stop = bnad->stats.drv_stats.netif_queue_stop + 1ULL;
      }
    } else {
      netif_stop_queue(netdev);
      bnad->stats.drv_stats.netif_queue_stop = bnad->stats.drv_stats.netif_queue_stop + 1ULL;
    }
    __asm__  volatile   ("mfence": : : "memory");
    tmp___11 = ldv__builtin_expect((((tcb->consumer_index - tcb->producer_index) - 1U) & (q_depth - 1U)) < wis,
                                1L);
    if (tmp___11 != 0L) {
      bnad->stats.drv_stats.netif_queue_stop = bnad->stats.drv_stats.netif_queue_stop + 1ULL;
      return (16);
    } else {
      netif_wake_queue(netdev);
      bnad->stats.drv_stats.netif_queue_wakeup = bnad->stats.drv_stats.netif_queue_wakeup + 1ULL;
    }
  } else {

  }
  txqent = (struct bna_txq_entry *)tcb->sw_q + (unsigned long )prod;
  head_unmap = unmap_q + (unsigned long )prod;
  tmp___13 = bnad_txq_wi_prepare(bnad, tcb, skb, txqent);
  if (tmp___13 != 0) {
    dev_kfree_skb_any(skb);
    return (0);
  } else {

  }
  txqent->hdr.wi.reserved = 0U;
  txqent->hdr.wi.num_vectors = (u8 )vectors;
  head_unmap->skb = skb;
  head_unmap->nvecs = 0U;
  unmap = head_unmap;
  dma_addr = dma_map_single_attrs(& (bnad->pcidev)->dev, (void *)skb->data, (size_t )len,
                                  1, (struct dma_attrs *)0);
  tmp___14 = __fswab64(dma_addr);
  tmp_addr = tmp___14;
  txqent->vector[0].host_addr.msb = ((struct bna_dma_addr *)(& tmp_addr))->msb;
  txqent->vector[0].host_addr.lsb = ((struct bna_dma_addr *)(& tmp_addr))->lsb;
  tmp___15 = __fswab16((int )((__u16 )len));
  txqent->vector[0].length = tmp___15;
  ((struct bnad_tx_vector *)(& unmap->vectors))->dma_addr = dma_addr;
  head_unmap->nvecs = head_unmap->nvecs + 1U;
  i = 0;
  vect_id = 0U;
  goto ldv_59352;
  ldv_59351: 
  tmp___16 = skb_end_pointer((struct sk_buff  const  *)skb);
  frag = (struct skb_frag_struct  const  *)(& ((struct skb_shared_info *)tmp___16)->frags) + (unsigned long )i;
  tmp___17 = skb_frag_size(frag);
  size = tmp___17;
  tmp___18 = ldv__builtin_expect(size == 0U, 0L);
  if (tmp___18 != 0L) {
    bnad_tx_buff_unmap(bnad, unmap_q, q_depth, tcb->producer_index);
    dev_kfree_skb_any(skb);
    bnad->stats.drv_stats.tx_skb_frag_zero = bnad->stats.drv_stats.tx_skb_frag_zero + 1ULL;
    return (0);
  } else {

  }
  len = len + size;
  vect_id = vect_id + 1U;
  if (vect_id == 4U) {
    vect_id = 0U;
    prod = (prod + 1U) & (q_depth - 1U);
    txqent = (struct bna_txq_entry *)tcb->sw_q + (unsigned long )prod;
    txqent->hdr.wi_ext.opcode = 1025U;
    unmap = unmap_q + (unsigned long )prod;
  } else {

  }
  dma_addr = skb_frag_dma_map(& (bnad->pcidev)->dev, frag, 0UL, (size_t )size, 1);
  ((struct bnad_tx_vector *)(& unmap->vectors) + (unsigned long )vect_id)->dma_len = size;
  tmp___19 = __fswab64(dma_addr);
  tmp_addr___0 = tmp___19;
  txqent->vector[vect_id].host_addr.msb = ((struct bna_dma_addr *)(& tmp_addr___0))->msb;
  txqent->vector[vect_id].host_addr.lsb = ((struct bna_dma_addr *)(& tmp_addr___0))->lsb;
  tmp___20 = __fswab16((int )((__u16 )size));
  txqent->vector[vect_id].length = tmp___20;
  ((struct bnad_tx_vector *)(& unmap->vectors) + (unsigned long )vect_id)->dma_addr = dma_addr;
  head_unmap->nvecs = head_unmap->nvecs + 1U;
  i = i + 1;
  ldv_59352: ;
  if ((u32 )i < vectors - 1U) {
    goto ldv_59351;
  } else {

  }
  tmp___21 = ldv__builtin_expect(skb->len != len, 0L);
  if (tmp___21 != 0L) {
    bnad_tx_buff_unmap(bnad, unmap_q, q_depth, tcb->producer_index);
    dev_kfree_skb_any(skb);
    bnad->stats.drv_stats.tx_skb_len_mismatch = bnad->stats.drv_stats.tx_skb_len_mismatch + 1ULL;
    return (0);
  } else {

  }
  prod = (prod + 1U) & (q_depth - 1U);
  tcb->producer_index = prod;
  __asm__  volatile   ("mfence": : : "memory");
  tmp___22 = constant_test_bit(1L, (unsigned long const volatile   *)(& tcb->flags));
  tmp___23 = ldv__builtin_expect(tmp___22 == 0, 0L);
  if (tmp___23 != 0L) {
    return (0);
  } else {

  }
  skb_tx_timestamp(skb);
  writel(tcb->producer_index | 2147483648U, (void volatile   *)tcb->q_dbell);
  __asm__  volatile   ("mfence": : : "memory");
  return (0);
}
}
static struct rtnl_link_stats64 *bnad_get_stats64(struct net_device *netdev , struct rtnl_link_stats64 *stats ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  unsigned long flags ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  ldv_spin_lock();
  bnad_netdev_qstats_fill(bnad, stats);
  bnad_netdev_hwstats_fill(bnad, stats);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return (stats);
}
}
static void bnad_set_rx_ucast_fltr(struct bnad *bnad ) 
{ 
  struct net_device *netdev ;
  int uc_count ;
    klee_make_symbolic(&uc_count, sizeof(int), "uc_count");
  enum bna_cb_status ret ;
  u8 *mac_list ;
  struct netdev_hw_addr *ha ;
  int entry ;
    klee_make_symbolic(&entry, sizeof(int), "entry");
  void *tmp ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  netdev = bnad->netdev;
  uc_count = netdev->uc.count;
  if ((bnad->netdev)->uc.count == 0) {
    bna_rx_ucast_listset(bnad->rx_info[0].rx, 0, (u8 const   *)0U);
    return;
  } else {

  }
  if (bnad->bna.ioceth.attr.num_ucmac < uc_count) {
    goto mode_default;
  } else {

  }
  tmp = kzalloc((size_t )(uc_count * 6), 32U);
  mac_list = (u8 *)tmp;
  if ((unsigned long )mac_list == (unsigned long )((u8 *)0U)) {
    goto mode_default;
  } else {

  }
  entry = 0;
  __mptr = (struct list_head  const  *)netdev->uc.list.next;
  ha = (struct netdev_hw_addr *)__mptr;
  goto ldv_59375;
  ldv_59374: 
  ether_addr_copy(mac_list + (unsigned long )(entry * 6), (u8 const   *)(& ha->addr));
  entry = entry + 1;
  __mptr___0 = (struct list_head  const  *)ha->list.next;
  ha = (struct netdev_hw_addr *)__mptr___0;
  ldv_59375: ;
  if ((unsigned long )(& ha->list) != (unsigned long )(& netdev->uc.list)) {
    goto ldv_59374;
  } else {

  }
  ret = bna_rx_ucast_listset(bnad->rx_info[0].rx, entry, (u8 const   *)mac_list);
  kfree((void const   *)mac_list);
  if ((unsigned int )ret != 0U) {
    goto mode_default;
  } else {

  }
  return;
  mode_default: 
  bnad->cfg_flags = bnad->cfg_flags | 8U;
  bna_rx_ucast_listset(bnad->rx_info[0].rx, 0, (u8 const   *)0U);
  return;
}
}
static void bnad_set_rx_mcast_fltr(struct bnad *bnad ) 
{ 
  struct net_device *netdev ;
  int mc_count ;
    klee_make_symbolic(&mc_count, sizeof(int), "mc_count");
  enum bna_cb_status ret ;
  u8 *mac_list ;
  void *tmp ;

  {
  netdev = bnad->netdev;
  mc_count = netdev->mc.count;
  if ((netdev->flags & 512U) != 0U) {
    goto mode_allmulti;
  } else {

  }
  if (netdev->mc.count == 0) {
    return;
  } else {

  }
  if (bnad->bna.ioceth.attr.num_mcmac < mc_count) {
    goto mode_allmulti;
  } else {

  }
  tmp = kzalloc((size_t )((mc_count + 1) * 6), 32U);
  mac_list = (u8 *)tmp;
  if ((unsigned long )mac_list == (unsigned long )((u8 *)0U)) {
    goto mode_allmulti;
  } else {

  }
  ether_addr_copy(mac_list, (u8 const   *)(& bnad_bcast_addr));
  bnad_netdev_mc_list_get(netdev, mac_list);
  ret = bna_rx_mcast_listset(bnad->rx_info[0].rx, mc_count + 1, (u8 const   *)mac_list);
  kfree((void const   *)mac_list);
  if ((unsigned int )ret != 0U) {
    goto mode_allmulti;
  } else {

  }
  return;
  mode_allmulti: 
  bnad->cfg_flags = bnad->cfg_flags | 4U;
  bna_rx_mcast_delall(bnad->rx_info[0].rx);
  return;
}
}
void bnad_set_rx_mode(struct net_device *netdev ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  enum bna_rxmode new_mode ;
  enum bna_rxmode mode_mask ;
  unsigned long flags ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  ldv_spin_lock();
  if ((unsigned long )bnad->rx_info[0].rx == (unsigned long )((struct bna_rx *)0)) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    return;
  } else {

  }
  bnad->cfg_flags = bnad->cfg_flags & 4294967281U;
  new_mode = 0;
  if ((netdev->flags & 256U) != 0U) {
    new_mode = (enum bna_rxmode )((unsigned int )new_mode | 1U);
    bnad->cfg_flags = bnad->cfg_flags | 2U;
  } else {
    bnad_set_rx_mcast_fltr(bnad);
    if ((bnad->cfg_flags & 4U) != 0U) {
      new_mode = (enum bna_rxmode )((unsigned int )new_mode | 4U);
    } else {

    }
    bnad_set_rx_ucast_fltr(bnad);
    if ((bnad->cfg_flags & 8U) != 0U) {
      new_mode = (enum bna_rxmode )((unsigned int )new_mode | 2U);
    } else {

    }
  }
  mode_mask = 7;
  bna_rx_mode_set(bnad->rx_info[0].rx, new_mode, mode_mask);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static int bnad_set_mac_address(struct net_device *netdev , void *addr ) 
{ 
  int err ;
  struct bnad *bnad ;
  void *tmp ;
  struct sockaddr *sa ;
  unsigned long flags ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  sa = (struct sockaddr *)addr;
  ldv_spin_lock();
  err = bnad_mac_addr_set_locked(bnad, (u8 const   *)(& sa->sa_data));
  if (err == 0) {
    ether_addr_copy(netdev->dev_addr, (u8 const   *)(& sa->sa_data));
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return (err);
}
}
static int bnad_mtu_set(struct bnad *bnad , int frame_size ) 
{ 
  unsigned long flags ;

  {
  init_completion(& bnad->bnad_completions.mtu_comp);
  ldv_spin_lock();
  bna_enet_mtu_set(& bnad->bna.enet, frame_size, & bnad_cb_enet_mtu_set);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& bnad->bnad_completions.mtu_comp);
  return ((int )bnad->bnad_completions.mtu_comp_status);
}
}
static int bnad_change_mtu(struct net_device *netdev , int new_mtu ) 
{ 
  int err ;
  int mtu ;
  struct bnad *bnad ;
  void *tmp ;
  u32 rx_count ;
  u32 frame ;
  u32 new_frame ;
  bool tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  rx_count = 0U;
  if (new_mtu + 14 <= 59 || new_mtu > 9000) {
    return (-22);
  } else {

  }
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  mtu = (int )netdev->mtu;
  netdev->mtu = (unsigned int )new_mtu;
  frame = (u32 )(mtu + 22);
  new_frame = (u32 )(new_mtu + 22);
  if ((unsigned int )(bnad->pcidev)->device == 34U) {
    tmp___0 = netif_running((struct net_device  const  *)bnad->netdev);
    if ((int )tmp___0) {
      if ((frame <= 4096U && new_frame > 4096U) || (frame > 4096U && new_frame <= 4096U)) {
        rx_count = bnad_reinit_rx(bnad);
      } else {

      }
    } else {

    }
  } else {

  }
  err = bnad_mtu_set(bnad, (int )new_frame);
  if (err != 0) {
    err = -16;
  } else {

  }
  mutex_unlock(& bnad->conf_mutex);
  return (err);
}
}
static int bnad_vlan_rx_add_vid(struct net_device *netdev , __be16 proto , u16 vid ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  unsigned long flags ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  if ((unsigned long )bnad->rx_info[0].rx == (unsigned long )((struct bna_rx *)0)) {
    return (0);
  } else {

  }
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  ldv_spin_lock();
  bna_rx_vlan_add(bnad->rx_info[0].rx, (int )vid);
  set_bit((long )vid, (unsigned long volatile   *)(& bnad->active_vlans));
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  mutex_unlock(& bnad->conf_mutex);
  return (0);
}
}
static int bnad_vlan_rx_kill_vid(struct net_device *netdev , __be16 proto , u16 vid ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  unsigned long flags ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  if ((unsigned long )bnad->rx_info[0].rx == (unsigned long )((struct bna_rx *)0)) {
    return (0);
  } else {

  }
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  ldv_spin_lock();
  clear_bit((long )vid, (unsigned long volatile   *)(& bnad->active_vlans));
  bna_rx_vlan_del(bnad->rx_info[0].rx, (int )vid);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  mutex_unlock(& bnad->conf_mutex);
  return (0);
}
}
static int bnad_set_features(struct net_device *dev , netdev_features_t features ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  netdev_features_t changed ;
  unsigned long flags ;
  bool tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)dev);
  bnad = (struct bnad *)tmp;
  changed = dev->features ^ features;
  if ((changed & 256ULL) != 0ULL) {
    tmp___0 = netif_running((struct net_device  const  *)dev);
    if ((int )tmp___0) {
      ldv_spin_lock();
      if ((features & 256ULL) != 0ULL) {
        bna_rx_vlan_strip_enable(bnad->rx_info[0].rx);
      } else {
        bna_rx_vlan_strip_disable(bnad->rx_info[0].rx);
      }
      spin_unlock_irqrestore(& bnad->bna_lock, flags);
    } else {

    }
  } else {

  }
  return (0);
}
}
static void bnad_netpoll(struct net_device *netdev ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  struct bnad_rx_info *rx_info ;
  struct bnad_rx_ctrl *rx_ctrl ;
  u32 curr_mask ;
  int i ;
  int j ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  if ((bnad->cfg_flags & 16U) == 0U) {
    curr_mask = readl((void const volatile   *)bnad->bna.regs.fn_int_mask);
    writel(4294967295U, (void volatile   *)bnad->bna.regs.fn_int_mask);
    bnad_isr((int )(bnad->pcidev)->irq, (void *)netdev);
    writel(curr_mask, (void volatile   *)bnad->bna.regs.fn_int_mask);
  } else {
    i = 0;
    goto ldv_59450;
    ldv_59449: 
    rx_info = (struct bnad_rx_info *)(& bnad->rx_info) + (unsigned long )i;
    if ((unsigned long )rx_info->rx == (unsigned long )((struct bna_rx *)0)) {
      goto ldv_59445;
    } else {

    }
    j = 0;
    goto ldv_59447;
    ldv_59446: 
    rx_ctrl = (struct bnad_rx_ctrl *)(& rx_info->rx_ctrl) + (unsigned long )j;
    if ((unsigned long )rx_ctrl->ccb != (unsigned long )((struct bna_ccb *)0)) {
      bnad_netif_rx_schedule_poll(bnad, rx_ctrl->ccb);
    } else {

    }
    j = j + 1;
    ldv_59447: ;
    if ((u32 )j < bnad->num_rxp_per_rx) {
      goto ldv_59446;
    } else {

    }

    ldv_59445: 
    i = i + 1;
    ldv_59450: ;
    if ((u32 )i < bnad->num_rx) {
      goto ldv_59449;
    } else {

    }

  }
  return;
}
}
static struct net_device_ops  const  bnad_netdev_ops  = 
     {0, 0, & bnad_open, & bnad_stop, & bnad_start_xmit, 0, 0, & bnad_set_rx_mode, & bnad_set_mac_address,
    & eth_validate_addr, 0, 0, & bnad_change_mtu, 0, 0, & bnad_get_stats64, 0, & bnad_vlan_rx_add_vid,
    & bnad_vlan_rx_kill_vid, & bnad_netpoll, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, & bnad_set_features, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static void bnad_netdev_init(struct bnad *bnad , bool using_dac ) 
{ 
  struct net_device *netdev ;

  {
  netdev = bnad->netdev;
  netdev->hw_features = 17180983699ULL;
  netdev->vlan_features = 1114163ULL;
  netdev->features = (netdev->features | netdev->hw_features) | 512ULL;
  if ((int )using_dac) {
    netdev->features = netdev->features | 32ULL;
  } else {

  }
  netdev->mem_start = (unsigned long )bnad->mmio_start;
  netdev->mem_end = (unsigned long )((bnad->mmio_start + bnad->mmio_len) - 1ULL);
  netdev->netdev_ops = & bnad_netdev_ops;
  bnad_set_ethtool_ops(netdev);
  return;
}
}
static int bnad_init(struct bnad *bnad , struct pci_dev *pdev , struct net_device *netdev ) 
{ 
  unsigned long flags ;
  struct lock_class_key __key ;
  char const   *__lock_name ;
  struct workqueue_struct *tmp ;

  {
  netdev->dev.parent = & pdev->dev;
  pci_set_drvdata(pdev, (void *)netdev);
  bnad->netdev = netdev;
  bnad->pcidev = pdev;
  bnad->mmio_start = pdev->resource[0].start;
  bnad->mmio_len = pdev->resource[0].start != 0ULL || pdev->resource[0].end != pdev->resource[0].start ? (pdev->resource[0].end - pdev->resource[0].start) + 1ULL : 0ULL;
  bnad->bar0 = ioremap_nocache(bnad->mmio_start, (unsigned long )bnad->mmio_len);
  if ((unsigned long )bnad->bar0 == (unsigned long )((void *)0)) {
    dev_err((struct device  const  *)(& pdev->dev), "ioremap for bar0 failed\n");
    return (-12);
  } else {

  }
  _dev_info((struct device  const  *)(& pdev->dev), "bar0 mapped to %p, len %llu\n",
            bnad->bar0, bnad->mmio_len);
  ldv_spin_lock();
  if (bnad_msix_disable == 0U) {
    bnad->cfg_flags = 16U;
  } else {

  }
  bnad->cfg_flags = bnad->cfg_flags | 1U;
  bnad_q_num_init(bnad);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  bnad->msix_num = (bnad->num_tx * bnad->num_txq_per_tx + bnad->num_rx * bnad->num_rxp_per_rx) + 1U;
  bnad->txq_depth = 2048U;
  bnad->rxq_depth = 2048U;
  bnad->tx_coalescing_timeo = 20U;
  bnad->rx_coalescing_timeo = 12U;
  sprintf((char *)(& bnad->wq_name), "%s_wq_%d", (char *)"bna", bnad->id);
  __lock_name = "\"%s\"bnad->wq_name";
  tmp = __alloc_workqueue_key("%s", 131082U, 1, & __key, __lock_name, (char *)(& bnad->wq_name));
  bnad->work_q = tmp;
  if ((unsigned long )bnad->work_q == (unsigned long )((struct workqueue_struct *)0)) {
    iounmap((void volatile   *)bnad->bar0);
    return (-12);
  } else {

  }
  return (0);
}
}
static void bnad_uninit(struct bnad *bnad ) 
{ 


  {
  if ((unsigned long )bnad->work_q != (unsigned long )((struct workqueue_struct *)0)) {
    ldv_flush_workqueue_55(bnad->work_q);
    ldv_destroy_workqueue_56(bnad->work_q);
    bnad->work_q = (struct workqueue_struct *)0;
  } else {

  }
  if ((unsigned long )bnad->bar0 != (unsigned long )((void *)0)) {
    iounmap((void volatile   *)bnad->bar0);
  } else {

  }
  return;
}
}
static void bnad_lock_init(struct bnad *bnad ) 
{ 
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  struct lock_class_key __key___1 ;

  {
  spinlock_check(& bnad->bna_lock);
  __raw_spin_lock_init(& bnad->bna_lock.__annonCompField18.rlock, "&(&bnad->bna_lock)->rlock",
                       & __key);
  __mutex_init(& bnad->conf_mutex, "&bnad->conf_mutex", & __key___0);
  __mutex_init(& bnad_list_mutex, "&bnad_list_mutex", & __key___1);
  return;
}
}
static void bnad_lock_uninit(struct bnad *bnad ) 
{ 


  {
  mutex_destroy(& bnad->conf_mutex);
  mutex_destroy(& bnad_list_mutex);
  return;
}
}
static int bnad_pci_init(struct bnad *bnad , struct pci_dev *pdev , bool *using_dac ) 
{ 
  int err ;
  int tmp ;

  {
  err = pci_enable_device(pdev);
  if (err != 0) {
    return (err);
  } else {

  }
  err = pci_request_regions(pdev, "bna");
  if (err != 0) {
    goto disable_device;
  } else {

  }
  tmp = dma_set_mask_and_coherent(& pdev->dev, 0xffffffffffffffffULL);
  if (tmp == 0) {
    *using_dac = 1;
  } else {
    err = dma_set_mask_and_coherent(& pdev->dev, 4294967295ULL);
    if (err != 0) {
      goto release_regions;
    } else {

    }
    *using_dac = 0;
  }
  pci_set_master(pdev);
  return (0);
  release_regions: 
  pci_release_regions(pdev);
  disable_device: 
  pci_disable_device(pdev);
  return (err);
}
}
static void bnad_pci_uninit(struct pci_dev *pdev ) 
{ 


  {
  pci_release_regions(pdev);
  pci_disable_device(pdev);
  return;
}
}
static int bnad_pci_probe(struct pci_dev *pdev , struct pci_device_id  const  *pcidev_id ) 
{ 
  bool using_dac ;
  int err ;
  struct bnad *bnad ;
  struct bna *bna ;
  struct net_device *netdev ;
  struct bfa_pcidev pcidev_info ;
  unsigned long flags ;
  u32 *tmp ;
  void *tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;

  {
  mutex_lock_nested(& bnad_fwimg_mutex, 0U);
  tmp = cna_get_firmware_buf(pdev);
  if ((unsigned long )tmp == (unsigned long )((u32 *)0U)) {
    mutex_unlock(& bnad_fwimg_mutex);
    dev_err((struct device  const  *)(& pdev->dev), "failed to load firmware image!\n");
    return (-19);
  } else {

  }
  mutex_unlock(& bnad_fwimg_mutex);
  netdev = alloc_etherdev_mqs(21248, 1U, 1U);
  if ((unsigned long )netdev == (unsigned long )((struct net_device *)0)) {
    err = -12;
    return (err);
  } else {

  }
  tmp___0 = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp___0;
  bnad_lock_init(bnad);
  bnad_add_to_list(bnad);
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  using_dac = 0;
  err = bnad_pci_init(bnad, pdev, & using_dac);
  if (err != 0) {
    goto unlock_mutex;
  } else {

  }
  err = bnad_init(bnad, pdev, netdev);
  if (err != 0) {
    goto pci_uninit;
  } else {

  }
  bnad_netdev_init(bnad, (int )using_dac);
  netif_carrier_off(netdev);
  if (bna_debugfs_enable != 0U) {
    bnad_debugfs_init(bnad);
  } else {

  }
  ldv_spin_lock();
  bna_res_req((struct bna_res_info *)(& bnad->res_info));
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  err = bnad_res_alloc(bnad, (struct bna_res_info *)(& bnad->res_info), 4U);
  if (err != 0) {
    goto drv_uninit;
  } else {

  }
  bna = & bnad->bna;
  pcidev_info.pci_slot = (int )((bnad->pcidev)->devfn >> 3) & 31;
  pcidev_info.pci_func = (unsigned int )((u8 )(bnad->pcidev)->devfn) & 7U;
  pcidev_info.device_id = (bnad->pcidev)->device;
  pcidev_info.pci_bar_kva = bnad->bar0;
  ldv_spin_lock();
  bna_init(bna, bnad, & pcidev_info, (struct bna_res_info *)(& bnad->res_info));
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  bnad->stats.bna_stats = & bna->stats;
  bnad_enable_msix(bnad);
  err = bnad_mbox_irq_alloc(bnad);
  if (err != 0) {
    goto res_free;
  } else {

  }
  reg_timer_7(& bnad->bna.ioceth.ioc.ioc_timer, & bnad_ioc_timeout, (unsigned long )bnad);
  reg_timer_7(& bnad->bna.ioceth.ioc.hb_timer, & bnad_ioc_hb_check, (unsigned long )bnad);
  reg_timer_7(& bnad->bna.ioceth.ioc.iocpf_timer, & bnad_iocpf_timeout, (unsigned long )bnad);
  reg_timer_7(& bnad->bna.ioceth.ioc.sem_timer, & bnad_iocpf_sem_timeout, (unsigned long )bnad);
  err = bnad_ioceth_enable(bnad);
  if (err != 0) {
    dev_err((struct device  const  *)(& pdev->dev), "initialization failed err=%d\n",
            err);
    goto probe_success;
  } else {

  }
  ldv_spin_lock();
  tmp___3 = bna_num_txq_set(bna, (int )(bnad->num_tx * bnad->num_txq_per_tx + 1U));
  if (tmp___3 != 0) {
    goto _L;
  } else {
    tmp___4 = bna_num_rxp_set(bna, (int )(bnad->num_rx * bnad->num_rxp_per_rx + 1U));
    if (tmp___4 != 0) {
      _L: /* CIL Label */ 
      bnad_q_num_adjust(bnad, bna->ioceth.attr.num_txq + -1, bna->ioceth.attr.num_rxp + -1);
      tmp___1 = bna_num_txq_set(bna, (int )(bnad->num_tx * bnad->num_txq_per_tx + 1U));
      if (tmp___1 != 0) {
        err = -5;
      } else {
        tmp___2 = bna_num_rxp_set(bna, (int )(bnad->num_rx * bnad->num_rxp_per_rx + 1U));
        if (tmp___2 != 0) {
          err = -5;
        } else {

        }
      }
    } else {

    }
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if (err != 0) {
    goto disable_ioceth;
  } else {

  }
  ldv_spin_lock();
  bna_mod_res_req(& bnad->bna, (struct bna_res_info *)(& bnad->mod_res_info));
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  err = bnad_res_alloc(bnad, (struct bna_res_info *)(& bnad->mod_res_info), 8U);
  if (err != 0) {
    err = -5;
    goto disable_ioceth;
  } else {

  }
  ldv_spin_lock();
  bna_mod_init(& bnad->bna, (struct bna_res_info *)(& bnad->mod_res_info));
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  ldv_spin_lock();
  bna_enet_perm_mac_get(& bna->enet, (u8 *)(& bnad->perm_addr));
  bnad_set_netdev_perm_addr(bnad);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  mutex_unlock(& bnad->conf_mutex);
  err = ldv_register_netdev_57(netdev);
  if (err != 0) {
    dev_err((struct device  const  *)(& pdev->dev), "registering net device failed\n");
    goto probe_uninit;
  } else {

  }
  set_bit(3L, (unsigned long volatile   *)(& bnad->run_flags));
  return (0);
  probe_success: 
  mutex_unlock(& bnad->conf_mutex);
  return (0);
  probe_uninit: 
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  bnad_res_free(bnad, (struct bna_res_info *)(& bnad->mod_res_info), 8U);
  disable_ioceth: 
  bnad_ioceth_disable(bnad);
  ldv_del_timer_sync_58(& bnad->bna.ioceth.ioc.ioc_timer);
  ldv_del_timer_sync_59(& bnad->bna.ioceth.ioc.sem_timer);
  ldv_del_timer_sync_60(& bnad->bna.ioceth.ioc.hb_timer);
  ldv_spin_lock();
  bna_uninit(bna);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  bnad_mbox_irq_free(bnad);
  bnad_disable_msix(bnad);
  res_free: 
  bnad_res_free(bnad, (struct bna_res_info *)(& bnad->res_info), 4U);
  drv_uninit: 
  kfree((void const   *)bnad->regdata);
  bnad_debugfs_uninit(bnad);
  bnad_uninit(bnad);
  pci_uninit: 
  bnad_pci_uninit(pdev);
  unlock_mutex: 
  mutex_unlock(& bnad->conf_mutex);
  bnad_remove_from_list(bnad);
  bnad_lock_uninit(bnad);
  ldv_free_netdev_61(netdev);
  return (err);
}
}
static void bnad_pci_remove(struct pci_dev *pdev ) 
{ 
  struct net_device *netdev ;
  void *tmp ;
  struct bnad *bnad ;
  struct bna *bna ;
  unsigned long flags ;
  void *tmp___0 ;
  int tmp___1 ;

  {
  tmp = pci_get_drvdata(pdev);
  netdev = (struct net_device *)tmp;
  if ((unsigned long )netdev == (unsigned long )((struct net_device *)0)) {
    return;
  } else {

  }
  tmp___0 = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp___0;
  bna = & bnad->bna;
  tmp___1 = test_and_clear_bit(3L, (unsigned long volatile   *)(& bnad->run_flags));
  if (tmp___1 != 0) {
    ldv_unregister_netdev_62(netdev);
  } else {

  }
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  bnad_ioceth_disable(bnad);
  ldv_del_timer_sync_63(& bnad->bna.ioceth.ioc.ioc_timer);
  ldv_del_timer_sync_64(& bnad->bna.ioceth.ioc.sem_timer);
  ldv_del_timer_sync_65(& bnad->bna.ioceth.ioc.hb_timer);
  ldv_spin_lock();
  bna_uninit(bna);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  bnad_res_free(bnad, (struct bna_res_info *)(& bnad->mod_res_info), 8U);
  bnad_res_free(bnad, (struct bna_res_info *)(& bnad->res_info), 4U);
  bnad_mbox_irq_free(bnad);
  bnad_disable_msix(bnad);
  bnad_pci_uninit(pdev);
  mutex_unlock(& bnad->conf_mutex);
  bnad_remove_from_list(bnad);
  bnad_lock_uninit(bnad);
  kfree((void const   *)bnad->regdata);
  bnad_debugfs_uninit(bnad);
  bnad_uninit(bnad);
  ldv_free_netdev_66(netdev);
  return;
}
}
static struct pci_device_id  const  bnad_pci_id_table[3U]  = {      {5719U, 20U, 4294967295U, 4294967295U, 131072U, 16776960U, 0UL}, 
        {5719U, 34U, 4294967295U, 4294967295U, 131072U, 16776960U, 0UL}, 
        {0U, 0U, 0U, 0U, 0U, 0U, 0UL}};
struct pci_device_id  const  __mod_pci__bnad_pci_id_table_device_table[3U]  ;
static struct pci_driver bnad_pci_driver  = 
     {{0, 0}, "bna", (struct pci_device_id  const  *)(& bnad_pci_id_table), & bnad_pci_probe,
    & bnad_pci_remove, 0, 0, 0, 0, 0, 0, 0, {0, 0, 0, 0, (_Bool)0, 0, 0, 0, 0, 0,
                                             0, 0, 0, 0, 0, 0}, {{{{{{0}}, 0U, 0U,
                                                                    0, {0, {0, 0},
                                                                        0, 0, 0UL}}}},
                                                                 {0, 0}}};
static int bnad_module_init(void) 
{ 
  int err ;

  {
  printk("\016bna: QLogic BR-series 10G Ethernet driver - version: %s\n", (char *)"3.2.25.1");
  bfa_nw_ioc_auto_recover(bnad_ioc_auto_recover != 0U);
  err = ldv___pci_register_driver_67(& bnad_pci_driver, & __this_module, "bna");
  if (err < 0) {
    printk("\vbna: PCI driver registration failed err=%d\n", err);
    return (err);
  } else {

  }
  return (0);
}
}
static void bnad_module_exit(void) 
{ 


  {
  ldv_pci_unregister_driver_68(& bnad_pci_driver);
  release_firmware(bfi_fw);
  return;
}
}
extern int ldv_shutdown_20(void) ;
int ldv_retval_0  ;
    klee_make_symbolic(&ldv_retval_0, sizeof(int), "ldv_retval_0");
int ldv_retval_4  ;
    klee_make_symbolic(&ldv_retval_4, sizeof(int), "ldv_retval_4");
int ldv_retval_6  ;
    klee_make_symbolic(&ldv_retval_6, sizeof(int), "ldv_retval_6");
extern int ldv_ndo_init_21(void) ;
extern void ldv_initialize(void) ;
int ldv_retval_1  ;
    klee_make_symbolic(&ldv_retval_1, sizeof(int), "ldv_retval_1");
extern void ldv_check_final_state(void) ;
extern int ldv_ndo_uninit_21(void) ;
void work_init_3(void) 
{ 


  {
  ldv_work_3_0 = 0;
  ldv_work_3_1 = 0;
  ldv_work_3_2 = 0;
  ldv_work_3_3 = 0;
  return;
}
}
void activate_suitable_timer_6(struct timer_list *timer , unsigned long data ) 
{ 


  {
  if (ldv_timer_6_0 == 0 || ldv_timer_6_0 == 2) {
    ldv_timer_list_6_0 = timer;
    ldv_timer_list_6_0->data = data;
    ldv_timer_6_0 = 1;
    return;
  } else {

  }
  if (ldv_timer_6_1 == 0 || ldv_timer_6_1 == 2) {
    ldv_timer_list_6_1 = timer;
    ldv_timer_list_6_1->data = data;
    ldv_timer_6_1 = 1;
    return;
  } else {

  }
  if (ldv_timer_6_2 == 0 || ldv_timer_6_2 == 2) {
    ldv_timer_list_6_2 = timer;
    ldv_timer_list_6_2->data = data;
    ldv_timer_6_2 = 1;
    return;
  } else {

  }
  if (ldv_timer_6_3 == 0 || ldv_timer_6_3 == 2) {
    ldv_timer_list_6_3 = timer;
    ldv_timer_list_6_3->data = data;
    ldv_timer_6_3 = 1;
    return;
  } else {

  }
  return;
}
}
void disable_suitable_irq_2(int line , void *data ) 
{ 


  {
  if (ldv_irq_2_0 != 0 && line == ldv_irq_line_2_0) {
    ldv_irq_2_0 = 0;
    return;
  } else {

  }
  if (ldv_irq_2_1 != 0 && line == ldv_irq_line_2_1) {
    ldv_irq_2_1 = 0;
    return;
  } else {

  }
  if (ldv_irq_2_2 != 0 && line == ldv_irq_line_2_2) {
    ldv_irq_2_2 = 0;
    return;
  } else {

  }
  if (ldv_irq_2_3 != 0 && line == ldv_irq_line_2_3) {
    ldv_irq_2_3 = 0;
    return;
  } else {

  }
  return;
}
}
int reg_timer_7(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) 
{ 


  {
  if ((unsigned long )function == (unsigned long )(& bnad_ioc_timeout)) {
    activate_suitable_timer_7(timer, data);
  } else {

  }
  return (0);
}
}
void ldv_timer_5(int state , struct timer_list *timer ) 
{ 


  {
  LDV_IN_INTERRUPT = 2;
  bnad_dim_timeout(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void choose_timer_5(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_5_0 == 1) {
    ldv_timer_5_0 = 2;
    ldv_timer_5(ldv_timer_5_0, ldv_timer_list_5_0);
  } else {

  }
  goto ldv_59580;
  case 1: ;
  if (ldv_timer_5_1 == 1) {
    ldv_timer_5_1 = 2;
    ldv_timer_5(ldv_timer_5_1, ldv_timer_list_5_1);
  } else {

  }
  goto ldv_59580;
  case 2: ;
  if (ldv_timer_5_2 == 1) {
    ldv_timer_5_2 = 2;
    ldv_timer_5(ldv_timer_5_2, ldv_timer_list_5_2);
  } else {

  }
  goto ldv_59580;
  case 3: ;
  if (ldv_timer_5_3 == 1) {
    ldv_timer_5_3 = 2;
    ldv_timer_5(ldv_timer_5_3, ldv_timer_list_5_3);
  } else {

  }
  goto ldv_59580;
  default: 
  ldv_stop();
  }
  ldv_59580: ;
  return;
}
}
void activate_pending_timer_9(struct timer_list *timer , unsigned long data , int pending_flag ) 
{ 


  {
  if ((unsigned long )ldv_timer_list_9_0 == (unsigned long )timer) {
    if (ldv_timer_9_0 == 2 || pending_flag != 0) {
      ldv_timer_list_9_0 = timer;
      ldv_timer_list_9_0->data = data;
      ldv_timer_9_0 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_9_1 == (unsigned long )timer) {
    if (ldv_timer_9_1 == 2 || pending_flag != 0) {
      ldv_timer_list_9_1 = timer;
      ldv_timer_list_9_1->data = data;
      ldv_timer_9_1 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_9_2 == (unsigned long )timer) {
    if (ldv_timer_9_2 == 2 || pending_flag != 0) {
      ldv_timer_list_9_2 = timer;
      ldv_timer_list_9_2->data = data;
      ldv_timer_9_2 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_9_3 == (unsigned long )timer) {
    if (ldv_timer_9_3 == 2 || pending_flag != 0) {
      ldv_timer_list_9_3 = timer;
      ldv_timer_list_9_3->data = data;
      ldv_timer_9_3 = 1;
    } else {

    }
    return;
  } else {

  }
  activate_suitable_timer_9(timer, data);
  return;
}
}
int reg_check_1(irqreturn_t (*handler)(int  , void * ) ) 
{ 


  {
  if ((unsigned long )handler == (unsigned long )(& bnad_msix_tx)) {
    return (1);
  } else {

  }
  return (0);
}
}
void disable_suitable_timer_8(struct timer_list *timer ) 
{ 


  {
  if (ldv_timer_8_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_8_0) {
    ldv_timer_8_0 = 0;
    return;
  } else {

  }
  if (ldv_timer_8_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_8_1) {
    ldv_timer_8_1 = 0;
    return;
  } else {

  }
  if (ldv_timer_8_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_8_2) {
    ldv_timer_8_2 = 0;
    return;
  } else {

  }
  if (ldv_timer_8_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_8_3) {
    ldv_timer_8_3 = 0;
    return;
  } else {

  }
  return;
}
}
void activate_work_3(struct work_struct *work , int state ) 
{ 


  {
  if (ldv_work_3_0 == 0) {
    ldv_work_struct_3_0 = work;
    ldv_work_3_0 = state;
    return;
  } else {

  }
  if (ldv_work_3_1 == 0) {
    ldv_work_struct_3_1 = work;
    ldv_work_3_1 = state;
    return;
  } else {

  }
  if (ldv_work_3_2 == 0) {
    ldv_work_struct_3_2 = work;
    ldv_work_3_2 = state;
    return;
  } else {

  }
  if (ldv_work_3_3 == 0) {
    ldv_work_struct_3_3 = work;
    ldv_work_3_3 = state;
    return;
  } else {

  }
  return;
}
}
void activate_pending_timer_10(struct timer_list *timer , unsigned long data , int pending_flag ) 
{ 


  {
  if ((unsigned long )ldv_timer_list_10_0 == (unsigned long )timer) {
    if (ldv_timer_10_0 == 2 || pending_flag != 0) {
      ldv_timer_list_10_0 = timer;
      ldv_timer_list_10_0->data = data;
      ldv_timer_10_0 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_10_1 == (unsigned long )timer) {
    if (ldv_timer_10_1 == 2 || pending_flag != 0) {
      ldv_timer_list_10_1 = timer;
      ldv_timer_list_10_1->data = data;
      ldv_timer_10_1 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_10_2 == (unsigned long )timer) {
    if (ldv_timer_10_2 == 2 || pending_flag != 0) {
      ldv_timer_list_10_2 = timer;
      ldv_timer_list_10_2->data = data;
      ldv_timer_10_2 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_10_3 == (unsigned long )timer) {
    if (ldv_timer_10_3 == 2 || pending_flag != 0) {
      ldv_timer_list_10_3 = timer;
      ldv_timer_list_10_3->data = data;
      ldv_timer_10_3 = 1;
    } else {

    }
    return;
  } else {

  }
  activate_suitable_timer_10(timer, data);
  return;
}
}
void call_and_disable_all_4(int state ) 
{ 


  {
  if (ldv_work_4_0 == state) {
    call_and_disable_work_4(ldv_work_struct_4_0);
  } else {

  }
  if (ldv_work_4_1 == state) {
    call_and_disable_work_4(ldv_work_struct_4_1);
  } else {

  }
  if (ldv_work_4_2 == state) {
    call_and_disable_work_4(ldv_work_struct_4_2);
  } else {

  }
  if (ldv_work_4_3 == state) {
    call_and_disable_work_4(ldv_work_struct_4_3);
  } else {

  }
  return;
}
}
int reg_timer_10(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) 
{ 


  {
  if ((unsigned long )function == (unsigned long )(& bnad_iocpf_sem_timeout)) {
    activate_suitable_timer_10(timer, data);
  } else {

  }
  return (0);
}
}
void call_and_disable_work_3(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_3_0 == 2 || ldv_work_3_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_0) {
    ldv__builtin_trap();
    ldv_work_3_0 = 1;
    return;
  } else {

  }
  if ((ldv_work_3_1 == 2 || ldv_work_3_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_1) {
    ldv__builtin_trap();
    ldv_work_3_1 = 1;
    return;
  } else {

  }
  if ((ldv_work_3_2 == 2 || ldv_work_3_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_2) {
    ldv__builtin_trap();
    ldv_work_3_2 = 1;
    return;
  } else {

  }
  if ((ldv_work_3_3 == 2 || ldv_work_3_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_3) {
    ldv__builtin_trap();
    ldv_work_3_3 = 1;
    return;
  } else {

  }
  return;
}
}
void timer_init_6(void) 
{ 


  {
  ldv_timer_6_0 = 0;
  ldv_timer_6_1 = 0;
  ldv_timer_6_2 = 0;
  ldv_timer_6_3 = 0;
  return;
}
}
void disable_work_3(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_3_0 == 3 || ldv_work_3_0 == 2) && (unsigned long )ldv_work_struct_3_0 == (unsigned long )work) {
    ldv_work_3_0 = 1;
  } else {

  }
  if ((ldv_work_3_1 == 3 || ldv_work_3_1 == 2) && (unsigned long )ldv_work_struct_3_1 == (unsigned long )work) {
    ldv_work_3_1 = 1;
  } else {

  }
  if ((ldv_work_3_2 == 3 || ldv_work_3_2 == 2) && (unsigned long )ldv_work_struct_3_2 == (unsigned long )work) {
    ldv_work_3_2 = 1;
  } else {

  }
  if ((ldv_work_3_3 == 3 || ldv_work_3_3 == 2) && (unsigned long )ldv_work_struct_3_3 == (unsigned long )work) {
    ldv_work_3_3 = 1;
  } else {

  }
  return;
}
}
void ldv_timer_9(int state , struct timer_list *timer ) 
{ 


  {
  LDV_IN_INTERRUPT = 2;
  bnad_iocpf_timeout(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void activate_pending_timer_8(struct timer_list *timer , unsigned long data , int pending_flag ) 
{ 


  {
  if ((unsigned long )ldv_timer_list_8_0 == (unsigned long )timer) {
    if (ldv_timer_8_0 == 2 || pending_flag != 0) {
      ldv_timer_list_8_0 = timer;
      ldv_timer_list_8_0->data = data;
      ldv_timer_8_0 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_8_1 == (unsigned long )timer) {
    if (ldv_timer_8_1 == 2 || pending_flag != 0) {
      ldv_timer_list_8_1 = timer;
      ldv_timer_list_8_1->data = data;
      ldv_timer_8_1 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_8_2 == (unsigned long )timer) {
    if (ldv_timer_8_2 == 2 || pending_flag != 0) {
      ldv_timer_list_8_2 = timer;
      ldv_timer_list_8_2->data = data;
      ldv_timer_8_2 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_8_3 == (unsigned long )timer) {
    if (ldv_timer_8_3 == 2 || pending_flag != 0) {
      ldv_timer_list_8_3 = timer;
      ldv_timer_list_8_3->data = data;
      ldv_timer_8_3 = 1;
    } else {

    }
    return;
  } else {

  }
  activate_suitable_timer_8(timer, data);
  return;
}
}
void ldv_timer_7(int state , struct timer_list *timer ) 
{ 


  {
  LDV_IN_INTERRUPT = 2;
  bnad_ioc_timeout(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void timer_init_5(void) 
{ 


  {
  ldv_timer_5_0 = 0;
  ldv_timer_5_1 = 0;
  ldv_timer_5_2 = 0;
  ldv_timer_5_3 = 0;
  return;
}
}
void disable_suitable_irq_1(int line , void *data ) 
{ 


  {
  if (ldv_irq_1_0 != 0 && line == ldv_irq_line_1_0) {
    ldv_irq_1_0 = 0;
    return;
  } else {

  }
  if (ldv_irq_1_1 != 0 && line == ldv_irq_line_1_1) {
    ldv_irq_1_1 = 0;
    return;
  } else {

  }
  if (ldv_irq_1_2 != 0 && line == ldv_irq_line_1_2) {
    ldv_irq_1_2 = 0;
    return;
  } else {

  }
  if (ldv_irq_1_3 != 0 && line == ldv_irq_line_1_3) {
    ldv_irq_1_3 = 0;
    return;
  } else {

  }
  return;
}
}
void activate_suitable_irq_1(int line , void *data ) 
{ 


  {
  if (ldv_irq_1_0 == 0) {
    ldv_irq_line_1_0 = line;
    ldv_irq_data_1_0 = data;
    ldv_irq_1_0 = 1;
    return;
  } else {

  }
  if (ldv_irq_1_1 == 0) {
    ldv_irq_line_1_1 = line;
    ldv_irq_data_1_1 = data;
    ldv_irq_1_1 = 1;
    return;
  } else {

  }
  if (ldv_irq_1_2 == 0) {
    ldv_irq_line_1_2 = line;
    ldv_irq_data_1_2 = data;
    ldv_irq_1_2 = 1;
    return;
  } else {

  }
  if (ldv_irq_1_3 == 0) {
    ldv_irq_line_1_3 = line;
    ldv_irq_data_1_3 = data;
    ldv_irq_1_3 = 1;
    return;
  } else {

  }
  return;
}
}
void invoke_work_4(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_work_4_0 == 2 || ldv_work_4_0 == 3) {
    ldv_work_4_0 = 4;
    ldv__builtin_trap();
    ldv_work_4_0 = 1;
  } else {

  }
  goto ldv_59657;
  case 1: ;
  if (ldv_work_4_1 == 2 || ldv_work_4_1 == 3) {
    ldv_work_4_1 = 4;
    ldv__builtin_trap();
    ldv_work_4_1 = 1;
  } else {

  }
  goto ldv_59657;
  case 2: ;
  if (ldv_work_4_2 == 2 || ldv_work_4_2 == 3) {
    ldv_work_4_2 = 4;
    ldv__builtin_trap();
    ldv_work_4_2 = 1;
  } else {

  }
  goto ldv_59657;
  case 3: ;
  if (ldv_work_4_3 == 2 || ldv_work_4_3 == 3) {
    ldv_work_4_3 = 4;
    ldv__builtin_trap();
    ldv_work_4_3 = 1;
  } else {

  }
  goto ldv_59657;
  default: 
  ldv_stop();
  }
  ldv_59657: ;
  return;
}
}
void timer_init_9(void) 
{ 


  {
  ldv_timer_9_0 = 0;
  ldv_timer_9_1 = 0;
  ldv_timer_9_2 = 0;
  ldv_timer_9_3 = 0;
  return;
}
}
void ldv_pci_driver_20(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(2976UL);
  bnad_pci_driver_group1 = (struct pci_dev *)tmp;
  return;
}
}
void disable_suitable_timer_6(struct timer_list *timer ) 
{ 


  {
  if (ldv_timer_6_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_6_0) {
    ldv_timer_6_0 = 0;
    return;
  } else {

  }
  if (ldv_timer_6_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_6_1) {
    ldv_timer_6_1 = 0;
    return;
  } else {

  }
  if (ldv_timer_6_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_6_2) {
    ldv_timer_6_2 = 0;
    return;
  } else {

  }
  if (ldv_timer_6_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_6_3) {
    ldv_timer_6_3 = 0;
    return;
  } else {

  }
  return;
}
}
void disable_suitable_timer_5(struct timer_list *timer ) 
{ 


  {
  if (ldv_timer_5_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_5_0) {
    ldv_timer_5_0 = 0;
    return;
  } else {

  }
  if (ldv_timer_5_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_5_1) {
    ldv_timer_5_1 = 0;
    return;
  } else {

  }
  if (ldv_timer_5_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_5_2) {
    ldv_timer_5_2 = 0;
    return;
  } else {

  }
  if (ldv_timer_5_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_5_3) {
    ldv_timer_5_3 = 0;
    return;
  } else {

  }
  return;
}
}
void ldv_timer_10(int state , struct timer_list *timer ) 
{ 


  {
  LDV_IN_INTERRUPT = 2;
  bnad_iocpf_sem_timeout(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
int ldv_irq_2(int state , int line , void *data ) 
{ 
  irqreturn_t irq_retval ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = __VERIFIER_nondet_int();
  irq_retval = (irqreturn_t )tmp;
  if (state != 0) {
    tmp___0 = __VERIFIER_nondet_int();
    switch (tmp___0) {
    case 0: ;
    if (state == 1) {
      LDV_IN_INTERRUPT = 2;
      irq_retval = bnad_msix_rx(line, data);
      LDV_IN_INTERRUPT = 1;
      return (state);
    } else {

    }
    goto ldv_59685;
    default: 
    ldv_stop();
    }
    ldv_59685: ;
  } else {

  }
  return (state);
}
}
void ldv_net_device_ops_21(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(3008UL);
  bnad_netdev_ops_group1 = (struct net_device *)tmp;
  return;
}
}
void activate_pending_timer_6(struct timer_list *timer , unsigned long data , int pending_flag ) 
{ 


  {
  if ((unsigned long )ldv_timer_list_6_0 == (unsigned long )timer) {
    if (ldv_timer_6_0 == 2 || pending_flag != 0) {
      ldv_timer_list_6_0 = timer;
      ldv_timer_list_6_0->data = data;
      ldv_timer_6_0 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_6_1 == (unsigned long )timer) {
    if (ldv_timer_6_1 == 2 || pending_flag != 0) {
      ldv_timer_list_6_1 = timer;
      ldv_timer_list_6_1->data = data;
      ldv_timer_6_1 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_6_2 == (unsigned long )timer) {
    if (ldv_timer_6_2 == 2 || pending_flag != 0) {
      ldv_timer_list_6_2 = timer;
      ldv_timer_list_6_2->data = data;
      ldv_timer_6_2 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_6_3 == (unsigned long )timer) {
    if (ldv_timer_6_3 == 2 || pending_flag != 0) {
      ldv_timer_list_6_3 = timer;
      ldv_timer_list_6_3->data = data;
      ldv_timer_6_3 = 1;
    } else {

    }
    return;
  } else {

  }
  activate_suitable_timer_6(timer, data);
  return;
}
}
void activate_suitable_timer_9(struct timer_list *timer , unsigned long data ) 
{ 


  {
  if (ldv_timer_9_0 == 0 || ldv_timer_9_0 == 2) {
    ldv_timer_list_9_0 = timer;
    ldv_timer_list_9_0->data = data;
    ldv_timer_9_0 = 1;
    return;
  } else {

  }
  if (ldv_timer_9_1 == 0 || ldv_timer_9_1 == 2) {
    ldv_timer_list_9_1 = timer;
    ldv_timer_list_9_1->data = data;
    ldv_timer_9_1 = 1;
    return;
  } else {

  }
  if (ldv_timer_9_2 == 0 || ldv_timer_9_2 == 2) {
    ldv_timer_list_9_2 = timer;
    ldv_timer_list_9_2->data = data;
    ldv_timer_9_2 = 1;
    return;
  } else {

  }
  if (ldv_timer_9_3 == 0 || ldv_timer_9_3 == 2) {
    ldv_timer_list_9_3 = timer;
    ldv_timer_list_9_3->data = data;
    ldv_timer_9_3 = 1;
    return;
  } else {

  }
  return;
}
}
void choose_interrupt_2(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: 
  ldv_irq_2_0 = ldv_irq_2(ldv_irq_2_0, ldv_irq_line_2_0, ldv_irq_data_2_0);
  goto ldv_59703;
  case 1: 
  ldv_irq_2_0 = ldv_irq_2(ldv_irq_2_1, ldv_irq_line_2_1, ldv_irq_data_2_1);
  goto ldv_59703;
  case 2: 
  ldv_irq_2_0 = ldv_irq_2(ldv_irq_2_2, ldv_irq_line_2_2, ldv_irq_data_2_2);
  goto ldv_59703;
  case 3: 
  ldv_irq_2_0 = ldv_irq_2(ldv_irq_2_3, ldv_irq_line_2_3, ldv_irq_data_2_3);
  goto ldv_59703;
  default: 
  ldv_stop();
  }
  ldv_59703: ;
  return;
}
}
void disable_suitable_timer_10(struct timer_list *timer ) 
{ 


  {
  if (ldv_timer_10_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_10_0) {
    ldv_timer_10_0 = 0;
    return;
  } else {

  }
  if (ldv_timer_10_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_10_1) {
    ldv_timer_10_1 = 0;
    return;
  } else {

  }
  if (ldv_timer_10_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_10_2) {
    ldv_timer_10_2 = 0;
    return;
  } else {

  }
  if (ldv_timer_10_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_10_3) {
    ldv_timer_10_3 = 0;
    return;
  } else {

  }
  return;
}
}
void activate_work_4(struct work_struct *work , int state ) 
{ 


  {
  if (ldv_work_4_0 == 0) {
    ldv_work_struct_4_0 = work;
    ldv_work_4_0 = state;
    return;
  } else {

  }
  if (ldv_work_4_1 == 0) {
    ldv_work_struct_4_1 = work;
    ldv_work_4_1 = state;
    return;
  } else {

  }
  if (ldv_work_4_2 == 0) {
    ldv_work_struct_4_2 = work;
    ldv_work_4_2 = state;
    return;
  } else {

  }
  if (ldv_work_4_3 == 0) {
    ldv_work_struct_4_3 = work;
    ldv_work_4_3 = state;
    return;
  } else {

  }
  return;
}
}
void choose_timer_8(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_8_0 == 1) {
    ldv_timer_8_0 = 2;
    ldv_timer_8(ldv_timer_8_0, ldv_timer_list_8_0);
  } else {

  }
  goto ldv_59719;
  case 1: ;
  if (ldv_timer_8_1 == 1) {
    ldv_timer_8_1 = 2;
    ldv_timer_8(ldv_timer_8_1, ldv_timer_list_8_1);
  } else {

  }
  goto ldv_59719;
  case 2: ;
  if (ldv_timer_8_2 == 1) {
    ldv_timer_8_2 = 2;
    ldv_timer_8(ldv_timer_8_2, ldv_timer_list_8_2);
  } else {

  }
  goto ldv_59719;
  case 3: ;
  if (ldv_timer_8_3 == 1) {
    ldv_timer_8_3 = 2;
    ldv_timer_8(ldv_timer_8_3, ldv_timer_list_8_3);
  } else {

  }
  goto ldv_59719;
  default: 
  ldv_stop();
  }
  ldv_59719: ;
  return;
}
}
void disable_suitable_timer_7(struct timer_list *timer ) 
{ 


  {
  if (ldv_timer_7_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_7_0) {
    ldv_timer_7_0 = 0;
    return;
  } else {

  }
  if (ldv_timer_7_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_7_1) {
    ldv_timer_7_1 = 0;
    return;
  } else {

  }
  if (ldv_timer_7_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_7_2) {
    ldv_timer_7_2 = 0;
    return;
  } else {

  }
  if (ldv_timer_7_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_7_3) {
    ldv_timer_7_3 = 0;
    return;
  } else {

  }
  return;
}
}
int reg_timer_9(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) 
{ 


  {
  if ((unsigned long )function == (unsigned long )(& bnad_iocpf_timeout)) {
    activate_suitable_timer_9(timer, data);
  } else {

  }
  return (0);
}
}
void activate_suitable_irq_2(int line , void *data ) 
{ 


  {
  if (ldv_irq_2_0 == 0) {
    ldv_irq_line_2_0 = line;
    ldv_irq_data_2_0 = data;
    ldv_irq_2_0 = 1;
    return;
  } else {

  }
  if (ldv_irq_2_1 == 0) {
    ldv_irq_line_2_1 = line;
    ldv_irq_data_2_1 = data;
    ldv_irq_2_1 = 1;
    return;
  } else {

  }
  if (ldv_irq_2_2 == 0) {
    ldv_irq_line_2_2 = line;
    ldv_irq_data_2_2 = data;
    ldv_irq_2_2 = 1;
    return;
  } else {

  }
  if (ldv_irq_2_3 == 0) {
    ldv_irq_line_2_3 = line;
    ldv_irq_data_2_3 = data;
    ldv_irq_2_3 = 1;
    return;
  } else {

  }
  return;
}
}
int reg_timer_8(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) 
{ 


  {
  if ((unsigned long )function == (unsigned long )(& bnad_ioc_hb_check)) {
    activate_suitable_timer_8(timer, data);
  } else {

  }
  return (0);
}
}
void disable_suitable_timer_9(struct timer_list *timer ) 
{ 


  {
  if (ldv_timer_9_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_9_0) {
    ldv_timer_9_0 = 0;
    return;
  } else {

  }
  if (ldv_timer_9_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_9_1) {
    ldv_timer_9_1 = 0;
    return;
  } else {

  }
  if (ldv_timer_9_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_9_2) {
    ldv_timer_9_2 = 0;
    return;
  } else {

  }
  if (ldv_timer_9_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_9_3) {
    ldv_timer_9_3 = 0;
    return;
  } else {

  }
  return;
}
}
void choose_timer_6(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_6_0 == 1) {
    ldv_timer_6_0 = 2;
    ldv_timer_6(ldv_timer_6_0, ldv_timer_list_6_0);
  } else {

  }
  goto ldv_59750;
  case 1: ;
  if (ldv_timer_6_1 == 1) {
    ldv_timer_6_1 = 2;
    ldv_timer_6(ldv_timer_6_1, ldv_timer_list_6_1);
  } else {

  }
  goto ldv_59750;
  case 2: ;
  if (ldv_timer_6_2 == 1) {
    ldv_timer_6_2 = 2;
    ldv_timer_6(ldv_timer_6_2, ldv_timer_list_6_2);
  } else {

  }
  goto ldv_59750;
  case 3: ;
  if (ldv_timer_6_3 == 1) {
    ldv_timer_6_3 = 2;
    ldv_timer_6(ldv_timer_6_3, ldv_timer_list_6_3);
  } else {

  }
  goto ldv_59750;
  default: 
  ldv_stop();
  }
  ldv_59750: ;
  return;
}
}
int reg_timer_6(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) 
{ 


  {
  if ((unsigned long )function == (unsigned long )(& bnad_stats_timeout)) {
    activate_suitable_timer_6(timer, data);
  } else {

  }
  return (0);
}
}
void activate_suitable_timer_10(struct timer_list *timer , unsigned long data ) 
{ 


  {
  if (ldv_timer_10_0 == 0 || ldv_timer_10_0 == 2) {
    ldv_timer_list_10_0 = timer;
    ldv_timer_list_10_0->data = data;
    ldv_timer_10_0 = 1;
    return;
  } else {

  }
  if (ldv_timer_10_1 == 0 || ldv_timer_10_1 == 2) {
    ldv_timer_list_10_1 = timer;
    ldv_timer_list_10_1->data = data;
    ldv_timer_10_1 = 1;
    return;
  } else {

  }
  if (ldv_timer_10_2 == 0 || ldv_timer_10_2 == 2) {
    ldv_timer_list_10_2 = timer;
    ldv_timer_list_10_2->data = data;
    ldv_timer_10_2 = 1;
    return;
  } else {

  }
  if (ldv_timer_10_3 == 0 || ldv_timer_10_3 == 2) {
    ldv_timer_list_10_3 = timer;
    ldv_timer_list_10_3->data = data;
    ldv_timer_10_3 = 1;
    return;
  } else {

  }
  return;
}
}
void ldv_timer_6(int state , struct timer_list *timer ) 
{ 


  {
  LDV_IN_INTERRUPT = 2;
  bnad_stats_timeout(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void timer_init_7(void) 
{ 


  {
  ldv_timer_7_0 = 0;
  ldv_timer_7_1 = 0;
  ldv_timer_7_2 = 0;
  ldv_timer_7_3 = 0;
  return;
}
}
void choose_interrupt_1(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: 
  ldv_irq_1_0 = ldv_irq_1(ldv_irq_1_0, ldv_irq_line_1_0, ldv_irq_data_1_0);
  goto ldv_59776;
  case 1: 
  ldv_irq_1_0 = ldv_irq_1(ldv_irq_1_1, ldv_irq_line_1_1, ldv_irq_data_1_1);
  goto ldv_59776;
  case 2: 
  ldv_irq_1_0 = ldv_irq_1(ldv_irq_1_2, ldv_irq_line_1_2, ldv_irq_data_1_2);
  goto ldv_59776;
  case 3: 
  ldv_irq_1_0 = ldv_irq_1(ldv_irq_1_3, ldv_irq_line_1_3, ldv_irq_data_1_3);
  goto ldv_59776;
  default: 
  ldv_stop();
  }
  ldv_59776: ;
  return;
}
}
int reg_check_2(irqreturn_t (*handler)(int  , void * ) ) 
{ 


  {
  if ((unsigned long )handler == (unsigned long )(& bnad_msix_rx)) {
    return (1);
  } else {

  }
  return (0);
}
}
void choose_timer_9(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_9_0 == 1) {
    ldv_timer_9_0 = 2;
    ldv_timer_9(ldv_timer_9_0, ldv_timer_list_9_0);
  } else {

  }
  goto ldv_59790;
  case 1: ;
  if (ldv_timer_9_1 == 1) {
    ldv_timer_9_1 = 2;
    ldv_timer_9(ldv_timer_9_1, ldv_timer_list_9_1);
  } else {

  }
  goto ldv_59790;
  case 2: ;
  if (ldv_timer_9_2 == 1) {
    ldv_timer_9_2 = 2;
    ldv_timer_9(ldv_timer_9_2, ldv_timer_list_9_2);
  } else {

  }
  goto ldv_59790;
  case 3: ;
  if (ldv_timer_9_3 == 1) {
    ldv_timer_9_3 = 2;
    ldv_timer_9(ldv_timer_9_3, ldv_timer_list_9_3);
  } else {

  }
  goto ldv_59790;
  default: 
  ldv_stop();
  }
  ldv_59790: ;
  return;
}
}
void timer_init_10(void) 
{ 


  {
  ldv_timer_10_0 = 0;
  ldv_timer_10_1 = 0;
  ldv_timer_10_2 = 0;
  ldv_timer_10_3 = 0;
  return;
}
}
void disable_work_4(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_4_0 == 3 || ldv_work_4_0 == 2) && (unsigned long )ldv_work_struct_4_0 == (unsigned long )work) {
    ldv_work_4_0 = 1;
  } else {

  }
  if ((ldv_work_4_1 == 3 || ldv_work_4_1 == 2) && (unsigned long )ldv_work_struct_4_1 == (unsigned long )work) {
    ldv_work_4_1 = 1;
  } else {

  }
  if ((ldv_work_4_2 == 3 || ldv_work_4_2 == 2) && (unsigned long )ldv_work_struct_4_2 == (unsigned long )work) {
    ldv_work_4_2 = 1;
  } else {

  }
  if ((ldv_work_4_3 == 3 || ldv_work_4_3 == 2) && (unsigned long )ldv_work_struct_4_3 == (unsigned long )work) {
    ldv_work_4_3 = 1;
  } else {

  }
  return;
}
}
void work_init_4(void) 
{ 


  {
  ldv_work_4_0 = 0;
  ldv_work_4_1 = 0;
  ldv_work_4_2 = 0;
  ldv_work_4_3 = 0;
  return;
}
}
void invoke_work_3(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_work_3_0 == 2 || ldv_work_3_0 == 3) {
    ldv_work_3_0 = 4;
    ldv__builtin_trap();
    ldv_work_3_0 = 1;
  } else {

  }
  goto ldv_59810;
  case 1: ;
  if (ldv_work_3_1 == 2 || ldv_work_3_1 == 3) {
    ldv_work_3_1 = 4;
    ldv__builtin_trap();
    ldv_work_3_1 = 1;
  } else {

  }
  goto ldv_59810;
  case 2: ;
  if (ldv_work_3_2 == 2 || ldv_work_3_2 == 3) {
    ldv_work_3_2 = 4;
    ldv__builtin_trap();
    ldv_work_3_2 = 1;
  } else {

  }
  goto ldv_59810;
  case 3: ;
  if (ldv_work_3_3 == 2 || ldv_work_3_3 == 3) {
    ldv_work_3_3 = 4;
    ldv__builtin_trap();
    ldv_work_3_3 = 1;
  } else {

  }
  goto ldv_59810;
  default: 
  ldv_stop();
  }
  ldv_59810: ;
  return;
}
}
int ldv_irq_1(int state , int line , void *data ) 
{ 
  irqreturn_t irq_retval ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = __VERIFIER_nondet_int();
  irq_retval = (irqreturn_t )tmp;
  if (state != 0) {
    tmp___0 = __VERIFIER_nondet_int();
    switch (tmp___0) {
    case 0: ;
    if (state == 1) {
      LDV_IN_INTERRUPT = 2;
      irq_retval = bnad_msix_tx(line, data);
      LDV_IN_INTERRUPT = 1;
      return (state);
    } else {

    }
    goto ldv_59822;
    default: 
    ldv_stop();
    }
    ldv_59822: ;
  } else {

  }
  return (state);
}
}
void ldv_timer_8(int state , struct timer_list *timer ) 
{ 


  {
  LDV_IN_INTERRUPT = 2;
  bnad_ioc_hb_check(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void activate_pending_timer_5(struct timer_list *timer , unsigned long data , int pending_flag ) 
{ 


  {
  if ((unsigned long )ldv_timer_list_5_0 == (unsigned long )timer) {
    if (ldv_timer_5_0 == 2 || pending_flag != 0) {
      ldv_timer_list_5_0 = timer;
      ldv_timer_list_5_0->data = data;
      ldv_timer_5_0 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_5_1 == (unsigned long )timer) {
    if (ldv_timer_5_1 == 2 || pending_flag != 0) {
      ldv_timer_list_5_1 = timer;
      ldv_timer_list_5_1->data = data;
      ldv_timer_5_1 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_5_2 == (unsigned long )timer) {
    if (ldv_timer_5_2 == 2 || pending_flag != 0) {
      ldv_timer_list_5_2 = timer;
      ldv_timer_list_5_2->data = data;
      ldv_timer_5_2 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_5_3 == (unsigned long )timer) {
    if (ldv_timer_5_3 == 2 || pending_flag != 0) {
      ldv_timer_list_5_3 = timer;
      ldv_timer_list_5_3->data = data;
      ldv_timer_5_3 = 1;
    } else {

    }
    return;
  } else {

  }
  activate_suitable_timer_5(timer, data);
  return;
}
}
void choose_timer_7(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_7_0 == 1) {
    ldv_timer_7_0 = 2;
    ldv_timer_7(ldv_timer_7_0, ldv_timer_list_7_0);
  } else {

  }
  goto ldv_59839;
  case 1: ;
  if (ldv_timer_7_1 == 1) {
    ldv_timer_7_1 = 2;
    ldv_timer_7(ldv_timer_7_1, ldv_timer_list_7_1);
  } else {

  }
  goto ldv_59839;
  case 2: ;
  if (ldv_timer_7_2 == 1) {
    ldv_timer_7_2 = 2;
    ldv_timer_7(ldv_timer_7_2, ldv_timer_list_7_2);
  } else {

  }
  goto ldv_59839;
  case 3: ;
  if (ldv_timer_7_3 == 1) {
    ldv_timer_7_3 = 2;
    ldv_timer_7(ldv_timer_7_3, ldv_timer_list_7_3);
  } else {

  }
  goto ldv_59839;
  default: 
  ldv_stop();
  }
  ldv_59839: ;
  return;
}
}
void timer_init_8(void) 
{ 


  {
  ldv_timer_8_0 = 0;
  ldv_timer_8_1 = 0;
  ldv_timer_8_2 = 0;
  ldv_timer_8_3 = 0;
  return;
}
}
void call_and_disable_all_3(int state ) 
{ 


  {
  if (ldv_work_3_0 == state) {
    call_and_disable_work_3(ldv_work_struct_3_0);
  } else {

  }
  if (ldv_work_3_1 == state) {
    call_and_disable_work_3(ldv_work_struct_3_1);
  } else {

  }
  if (ldv_work_3_2 == state) {
    call_and_disable_work_3(ldv_work_struct_3_2);
  } else {

  }
  if (ldv_work_3_3 == state) {
    call_and_disable_work_3(ldv_work_struct_3_3);
  } else {

  }
  return;
}
}
void activate_suitable_timer_8(struct timer_list *timer , unsigned long data ) 
{ 


  {
  if (ldv_timer_8_0 == 0 || ldv_timer_8_0 == 2) {
    ldv_timer_list_8_0 = timer;
    ldv_timer_list_8_0->data = data;
    ldv_timer_8_0 = 1;
    return;
  } else {

  }
  if (ldv_timer_8_1 == 0 || ldv_timer_8_1 == 2) {
    ldv_timer_list_8_1 = timer;
    ldv_timer_list_8_1->data = data;
    ldv_timer_8_1 = 1;
    return;
  } else {

  }
  if (ldv_timer_8_2 == 0 || ldv_timer_8_2 == 2) {
    ldv_timer_list_8_2 = timer;
    ldv_timer_list_8_2->data = data;
    ldv_timer_8_2 = 1;
    return;
  } else {

  }
  if (ldv_timer_8_3 == 0 || ldv_timer_8_3 == 2) {
    ldv_timer_list_8_3 = timer;
    ldv_timer_list_8_3->data = data;
    ldv_timer_8_3 = 1;
    return;
  } else {

  }
  return;
}
}
void choose_timer_10(void) 
{ 
  int tmp ;

  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_10_0 == 1) {
    ldv_timer_10_0 = 2;
    ldv_timer_10(ldv_timer_10_0, ldv_timer_list_10_0);
  } else {

  }
  goto ldv_59858;
  case 1: ;
  if (ldv_timer_10_1 == 1) {
    ldv_timer_10_1 = 2;
    ldv_timer_10(ldv_timer_10_1, ldv_timer_list_10_1);
  } else {

  }
  goto ldv_59858;
  case 2: ;
  if (ldv_timer_10_2 == 1) {
    ldv_timer_10_2 = 2;
    ldv_timer_10(ldv_timer_10_2, ldv_timer_list_10_2);
  } else {

  }
  goto ldv_59858;
  case 3: ;
  if (ldv_timer_10_3 == 1) {
    ldv_timer_10_3 = 2;
    ldv_timer_10(ldv_timer_10_3, ldv_timer_list_10_3);
  } else {

  }
  goto ldv_59858;
  default: 
  ldv_stop();
  }
  ldv_59858: ;
  return;
}
}
int reg_timer_5(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) 
{ 


  {
  if ((unsigned long )function == (unsigned long )(& bnad_dim_timeout)) {
    activate_suitable_timer_5(timer, data);
  } else {

  }
  return (0);
}
}
void call_and_disable_work_4(struct work_struct *work ) 
{ 


  {
  if ((ldv_work_4_0 == 2 || ldv_work_4_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_0) {
    ldv__builtin_trap();
    ldv_work_4_0 = 1;
    return;
  } else {

  }
  if ((ldv_work_4_1 == 2 || ldv_work_4_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_1) {
    ldv__builtin_trap();
    ldv_work_4_1 = 1;
    return;
  } else {

  }
  if ((ldv_work_4_2 == 2 || ldv_work_4_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_2) {
    ldv__builtin_trap();
    ldv_work_4_2 = 1;
    return;
  } else {

  }
  if ((ldv_work_4_3 == 2 || ldv_work_4_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_3) {
    ldv__builtin_trap();
    ldv_work_4_3 = 1;
    return;
  } else {

  }
  return;
}
}
void activate_suitable_timer_5(struct timer_list *timer , unsigned long data ) 
{ 


  {
  if (ldv_timer_5_0 == 0 || ldv_timer_5_0 == 2) {
    ldv_timer_list_5_0 = timer;
    ldv_timer_list_5_0->data = data;
    ldv_timer_5_0 = 1;
    return;
  } else {

  }
  if (ldv_timer_5_1 == 0 || ldv_timer_5_1 == 2) {
    ldv_timer_list_5_1 = timer;
    ldv_timer_list_5_1->data = data;
    ldv_timer_5_1 = 1;
    return;
  } else {

  }
  if (ldv_timer_5_2 == 0 || ldv_timer_5_2 == 2) {
    ldv_timer_list_5_2 = timer;
    ldv_timer_list_5_2->data = data;
    ldv_timer_5_2 = 1;
    return;
  } else {

  }
  if (ldv_timer_5_3 == 0 || ldv_timer_5_3 == 2) {
    ldv_timer_list_5_3 = timer;
    ldv_timer_list_5_3->data = data;
    ldv_timer_5_3 = 1;
    return;
  } else {

  }
  return;
}
}
void activate_pending_timer_7(struct timer_list *timer , unsigned long data , int pending_flag ) 
{ 


  {
  if ((unsigned long )ldv_timer_list_7_0 == (unsigned long )timer) {
    if (ldv_timer_7_0 == 2 || pending_flag != 0) {
      ldv_timer_list_7_0 = timer;
      ldv_timer_list_7_0->data = data;
      ldv_timer_7_0 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_7_1 == (unsigned long )timer) {
    if (ldv_timer_7_1 == 2 || pending_flag != 0) {
      ldv_timer_list_7_1 = timer;
      ldv_timer_list_7_1->data = data;
      ldv_timer_7_1 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_7_2 == (unsigned long )timer) {
    if (ldv_timer_7_2 == 2 || pending_flag != 0) {
      ldv_timer_list_7_2 = timer;
      ldv_timer_list_7_2->data = data;
      ldv_timer_7_2 = 1;
    } else {

    }
    return;
  } else {

  }
  if ((unsigned long )ldv_timer_list_7_3 == (unsigned long )timer) {
    if (ldv_timer_7_3 == 2 || pending_flag != 0) {
      ldv_timer_list_7_3 = timer;
      ldv_timer_list_7_3->data = data;
      ldv_timer_7_3 = 1;
    } else {

    }
    return;
  } else {

  }
  activate_suitable_timer_7(timer, data);
  return;
}
}
void activate_suitable_timer_7(struct timer_list *timer , unsigned long data ) 
{ 


  {
  if (ldv_timer_7_0 == 0 || ldv_timer_7_0 == 2) {
    ldv_timer_list_7_0 = timer;
    ldv_timer_list_7_0->data = data;
    ldv_timer_7_0 = 1;
    return;
  } else {

  }
  if (ldv_timer_7_1 == 0 || ldv_timer_7_1 == 2) {
    ldv_timer_list_7_1 = timer;
    ldv_timer_list_7_1->data = data;
    ldv_timer_7_1 = 1;
    return;
  } else {

  }
  if (ldv_timer_7_2 == 0 || ldv_timer_7_2 == 2) {
    ldv_timer_list_7_2 = timer;
    ldv_timer_list_7_2->data = data;
    ldv_timer_7_2 = 1;
    return;
  } else {

  }
  if (ldv_timer_7_3 == 0 || ldv_timer_7_3 == 2) {
    ldv_timer_list_7_3 = timer;
    ldv_timer_list_7_3->data = data;
    ldv_timer_7_3 = 1;
    return;
  } else {

  }
  return;
}
}
void ldv_main_exported_13(void) ;
void ldv_main_exported_19(void) ;
void ldv_main_exported_18(void) ;
void ldv_main_exported_16(void) ;
void ldv_main_exported_17(void) ;
void ldv_main_exported_15(void) ;
void ldv_main_exported_14(void) ;
void ldv_main_exported_11(void) ;
void ldv_main_exported_12(void) ;
int main(void) 
{ 
  u16 ldvarg11 ;
  int ldvarg7 ;
    klee_make_symbolic(&ldvarg7, sizeof(int), "ldvarg7");
  __be16 ldvarg12 ;
  void *ldvarg5 ;
  void *tmp ;
  struct sk_buff *ldvarg6 ;
  void *tmp___0 ;
  netdev_features_t ldvarg8 ;
  struct rtnl_link_stats64 *ldvarg4 ;
  void *tmp___1 ;
  __be16 ldvarg10 ;
  u16 ldvarg9 ;
  struct pci_device_id *ldvarg41 ;
  void *tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
    klee_make_symbolic(&tmp___5, sizeof(int), "tmp___5");
  int tmp___6 ;
    klee_make_symbolic(&tmp___6, sizeof(int), "tmp___6");

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg5 = tmp;
  tmp___0 = ldv_init_zalloc(232UL);
  ldvarg6 = (struct sk_buff *)tmp___0;
  tmp___1 = ldv_init_zalloc(184UL);
  ldvarg4 = (struct rtnl_link_stats64 *)tmp___1;
  tmp___2 = ldv_init_zalloc(32UL);
  ldvarg41 = (struct pci_device_id *)tmp___2;
  ldv_initialize();
  ldv_memset((void *)(& ldvarg11), 0, 2UL);
  ldv_memset((void *)(& ldvarg7), 0, 4UL);
  ldv_memset((void *)(& ldvarg12), 0, 2UL);
  ldv_memset((void *)(& ldvarg8), 0, 8UL);
  ldv_memset((void *)(& ldvarg10), 0, 2UL);
  ldv_memset((void *)(& ldvarg9), 0, 2UL);
  ldv_state_variable_11 = 0;
  ldv_state_variable_21 = 0;
  timer_init_7();
  ldv_state_variable_7 = 1;
  ldv_state_variable_17 = 0;
  ldv_state_variable_2 = 1;
  ldv_state_variable_1 = 1;
  ldv_state_variable_18 = 0;
  ref_cnt = 0;
  ldv_state_variable_0 = 1;
  ldv_state_variable_16 = 0;
  ldv_state_variable_13 = 0;
  timer_init_6();
  ldv_state_variable_6 = 1;
  work_init_3();
  ldv_state_variable_3 = 1;
  timer_init_9();
  ldv_state_variable_9 = 1;
  ldv_state_variable_12 = 0;
  ldv_state_variable_20 = 0;
  ldv_state_variable_14 = 0;
  ldv_state_variable_15 = 0;
  timer_init_8();
  ldv_state_variable_8 = 1;
  work_init_4();
  ldv_state_variable_4 = 1;
  ldv_state_variable_19 = 0;
  timer_init_10();
  ldv_state_variable_10 = 1;
  timer_init_5();
  ldv_state_variable_5 = 1;
  ldv_59974: 
  tmp___3 = __VERIFIER_nondet_int();
  switch (tmp___3) {
  case 0: ;
  if (ldv_state_variable_11 != 0) {
    ldv_main_exported_11();
  } else {

  }
  goto ldv_59925;
  case 1: ;
  if (ldv_state_variable_21 != 0) {
    tmp___4 = __VERIFIER_nondet_int();
    switch (tmp___4) {
    case 0: ;
    if (ldv_state_variable_21 == 3) {
      bnad_stop(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 2;
    } else {

    }
    goto ldv_59928;
    case 1: ;
    if (ldv_state_variable_21 == 1) {
      bnad_set_rx_mode(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 1;
    } else {

    }
    if (ldv_state_variable_21 == 3) {
      bnad_set_rx_mode(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 3;
    } else {

    }
    if (ldv_state_variable_21 == 2) {
      bnad_set_rx_mode(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 2;
    } else {

    }
    goto ldv_59928;
    case 2: ;
    if (ldv_state_variable_21 == 1) {
      eth_validate_addr(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 1;
    } else {

    }
    if (ldv_state_variable_21 == 3) {
      eth_validate_addr(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 3;
    } else {

    }
    if (ldv_state_variable_21 == 2) {
      eth_validate_addr(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 2;
    } else {

    }
    goto ldv_59928;
    case 3: ;
    if (ldv_state_variable_21 == 1) {
      bnad_vlan_rx_kill_vid(bnad_netdev_ops_group1, (int )ldvarg12, (int )ldvarg11);
      ldv_state_variable_21 = 1;
    } else {

    }
    if (ldv_state_variable_21 == 3) {
      bnad_vlan_rx_kill_vid(bnad_netdev_ops_group1, (int )ldvarg12, (int )ldvarg11);
      ldv_state_variable_21 = 3;
    } else {

    }
    if (ldv_state_variable_21 == 2) {
      bnad_vlan_rx_kill_vid(bnad_netdev_ops_group1, (int )ldvarg12, (int )ldvarg11);
      ldv_state_variable_21 = 2;
    } else {

    }
    goto ldv_59928;
    case 4: ;
    if (ldv_state_variable_21 == 1) {
      bnad_vlan_rx_add_vid(bnad_netdev_ops_group1, (int )ldvarg10, (int )ldvarg9);
      ldv_state_variable_21 = 1;
    } else {

    }
    if (ldv_state_variable_21 == 3) {
      bnad_vlan_rx_add_vid(bnad_netdev_ops_group1, (int )ldvarg10, (int )ldvarg9);
      ldv_state_variable_21 = 3;
    } else {

    }
    if (ldv_state_variable_21 == 2) {
      bnad_vlan_rx_add_vid(bnad_netdev_ops_group1, (int )ldvarg10, (int )ldvarg9);
      ldv_state_variable_21 = 2;
    } else {

    }
    goto ldv_59928;
    case 5: ;
    if (ldv_state_variable_21 == 1) {
      bnad_netpoll(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 1;
    } else {

    }
    if (ldv_state_variable_21 == 3) {
      bnad_netpoll(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 3;
    } else {

    }
    if (ldv_state_variable_21 == 2) {
      bnad_netpoll(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 2;
    } else {

    }
    goto ldv_59928;
    case 6: ;
    if (ldv_state_variable_21 == 1) {
      bnad_set_features(bnad_netdev_ops_group1, ldvarg8);
      ldv_state_variable_21 = 1;
    } else {

    }
    if (ldv_state_variable_21 == 3) {
      bnad_set_features(bnad_netdev_ops_group1, ldvarg8);
      ldv_state_variable_21 = 3;
    } else {

    }
    if (ldv_state_variable_21 == 2) {
      bnad_set_features(bnad_netdev_ops_group1, ldvarg8);
      ldv_state_variable_21 = 2;
    } else {

    }
    goto ldv_59928;
    case 7: ;
    if (ldv_state_variable_21 == 3) {
      bnad_change_mtu(bnad_netdev_ops_group1, ldvarg7);
      ldv_state_variable_21 = 3;
    } else {

    }
    if (ldv_state_variable_21 == 2) {
      bnad_change_mtu(bnad_netdev_ops_group1, ldvarg7);
      ldv_state_variable_21 = 2;
    } else {

    }
    goto ldv_59928;
    case 8: ;
    if (ldv_state_variable_21 == 2) {
      ldv_retval_1 = bnad_open(bnad_netdev_ops_group1);
      if (ldv_retval_1 == 0) {
        ldv_state_variable_21 = 3;
      } else {

      }
    } else {

    }
    goto ldv_59928;
    case 9: ;
    if (ldv_state_variable_21 == 3) {
      bnad_start_xmit(ldvarg6, bnad_netdev_ops_group1);
      ldv_state_variable_21 = 3;
    } else {

    }
    goto ldv_59928;
    case 10: ;
    if (ldv_state_variable_21 == 1) {
      bnad_set_mac_address(bnad_netdev_ops_group1, ldvarg5);
      ldv_state_variable_21 = 1;
    } else {

    }
    if (ldv_state_variable_21 == 3) {
      bnad_set_mac_address(bnad_netdev_ops_group1, ldvarg5);
      ldv_state_variable_21 = 3;
    } else {

    }
    if (ldv_state_variable_21 == 2) {
      bnad_set_mac_address(bnad_netdev_ops_group1, ldvarg5);
      ldv_state_variable_21 = 2;
    } else {

    }
    goto ldv_59928;
    case 11: ;
    if (ldv_state_variable_21 == 1) {
      bnad_get_stats64(bnad_netdev_ops_group1, ldvarg4);
      ldv_state_variable_21 = 1;
    } else {

    }
    if (ldv_state_variable_21 == 3) {
      bnad_get_stats64(bnad_netdev_ops_group1, ldvarg4);
      ldv_state_variable_21 = 3;
    } else {

    }
    if (ldv_state_variable_21 == 2) {
      bnad_get_stats64(bnad_netdev_ops_group1, ldvarg4);
      ldv_state_variable_21 = 2;
    } else {

    }
    goto ldv_59928;
    case 12: ;
    if (ldv_state_variable_21 == 1) {
      ldv_retval_0 = ldv_ndo_init_21();
      if (ldv_retval_0 == 0) {
        ldv_state_variable_21 = 2;
        ref_cnt = ref_cnt + 1;
      } else {

      }
    } else {

    }
    goto ldv_59928;
    case 13: ;
    if (ldv_state_variable_21 == 2) {
      ldv_ndo_uninit_21();
      ldv_state_variable_21 = 1;
      ref_cnt = ref_cnt - 1;
    } else {

    }
    goto ldv_59928;
    default: 
    ldv_stop();
    }
    ldv_59928: ;
  } else {

  }
  goto ldv_59925;
  case 2: ;
  if (ldv_state_variable_7 != 0) {
    choose_timer_7();
  } else {

  }
  goto ldv_59925;
  case 3: ;
  if (ldv_state_variable_17 != 0) {
    ldv_main_exported_17();
  } else {

  }
  goto ldv_59925;
  case 4: ;
  if (ldv_state_variable_2 != 0) {
    choose_interrupt_2();
  } else {

  }
  goto ldv_59925;
  case 5: ;
  if (ldv_state_variable_1 != 0) {
    choose_interrupt_1();
  } else {

  }
  goto ldv_59925;
  case 6: ;
  if (ldv_state_variable_18 != 0) {
    ldv_main_exported_18();
  } else {

  }
  goto ldv_59925;
  case 7: ;
  if (ldv_state_variable_0 != 0) {
    tmp___5 = __VERIFIER_nondet_int();
    switch (tmp___5) {
    case 0: ;
    if (ldv_state_variable_0 == 3 && ref_cnt == 0) {
      bnad_module_exit();
      ldv_state_variable_0 = 2;
      goto ldv_final;
    } else {

    }
    goto ldv_59951;
    case 1: ;
    if (ldv_state_variable_0 == 1) {
      ldv_retval_4 = bnad_module_init();
      if (ldv_retval_4 == 0) {
        ldv_state_variable_0 = 3;
        ldv_state_variable_16 = 1;
        ldv_file_operations_16();
        ldv_state_variable_13 = 1;
        ldv_state_variable_19 = 1;
        ldv_initialize_ethtool_ops_19();
        ldv_state_variable_18 = 1;
        ldv_file_operations_18();
        ldv_state_variable_14 = 1;
        ldv_file_operations_14();
        ldv_state_variable_15 = 1;
        ldv_file_operations_15();
        ldv_state_variable_12 = 1;
        ldv_initialize_bfa_ioc_hwif_12();
        ldv_state_variable_17 = 1;
        ldv_file_operations_17();
        ldv_state_variable_11 = 1;
        ldv_initialize_bfa_ioc_hwif_11();
      } else {

      }
      if (ldv_retval_4 != 0) {
        ldv_state_variable_0 = 2;
        goto ldv_final;
      } else {

      }
    } else {

    }
    goto ldv_59951;
    default: 
    ldv_stop();
    }
    ldv_59951: ;
  } else {

  }
  goto ldv_59925;
  case 8: ;
  if (ldv_state_variable_16 != 0) {
    ldv_main_exported_16();
  } else {

  }
  goto ldv_59925;
  case 9: ;
  if (ldv_state_variable_13 != 0) {
    ldv_main_exported_13();
  } else {

  }
  goto ldv_59925;
  case 10: ;
  if (ldv_state_variable_6 != 0) {
    choose_timer_6();
  } else {

  }
  goto ldv_59925;
  case 11: ;
  if (ldv_state_variable_3 != 0) {
    invoke_work_3();
  } else {

  }
  goto ldv_59925;
  case 12: ;
  if (ldv_state_variable_9 != 0) {
    choose_timer_9();
  } else {

  }
  goto ldv_59925;
  case 13: ;
  if (ldv_state_variable_12 != 0) {
    ldv_main_exported_12();
  } else {

  }
  goto ldv_59925;
  case 14: ;
  if (ldv_state_variable_20 != 0) {
    tmp___6 = __VERIFIER_nondet_int();
    switch (tmp___6) {
    case 0: ;
    if (ldv_state_variable_20 == 1) {
      ldv_retval_6 = bnad_pci_probe(bnad_pci_driver_group1, (struct pci_device_id  const  *)ldvarg41);
      if (ldv_retval_6 == 0) {
        ldv_state_variable_20 = 2;
        ref_cnt = ref_cnt + 1;
      } else {

      }
    } else {

    }
    goto ldv_59962;
    case 1: ;
    if (ldv_state_variable_20 == 2) {
      bnad_pci_remove(bnad_pci_driver_group1);
      ldv_state_variable_20 = 1;
    } else {

    }
    goto ldv_59962;
    case 2: ;
    if (ldv_state_variable_20 == 2) {
      ldv_shutdown_20();
      ldv_state_variable_20 = 2;
    } else {

    }
    goto ldv_59962;
    default: 
    ldv_stop();
    }
    ldv_59962: ;
  } else {

  }
  goto ldv_59925;
  case 15: ;
  if (ldv_state_variable_14 != 0) {
    ldv_main_exported_14();
  } else {

  }
  goto ldv_59925;
  case 16: ;
  if (ldv_state_variable_15 != 0) {
    ldv_main_exported_15();
  } else {

  }
  goto ldv_59925;
  case 17: ;
  if (ldv_state_variable_8 != 0) {
    choose_timer_8();
  } else {

  }
  goto ldv_59925;
  case 18: ;
  if (ldv_state_variable_4 != 0) {
    invoke_work_4();
  } else {

  }
  goto ldv_59925;
  case 19: ;
  if (ldv_state_variable_19 != 0) {
    ldv_main_exported_19();
  } else {

  }
  goto ldv_59925;
  case 20: ;
  if (ldv_state_variable_10 != 0) {
    choose_timer_10();
  } else {

  }
  goto ldv_59925;
  case 21: ;
  if (ldv_state_variable_5 != 0) {
    choose_timer_5();
  } else {

  }
  goto ldv_59925;
  default: 
  ldv_stop();
  }
  ldv_59925: ;
  goto ldv_59974;
  ldv_final: 
  ldv_check_final_state();
  return 0;
}
}
__inline static void spin_unlock_irqrestore(spinlock_t *lock , unsigned long flags ) 
{ 


  {
  ldv_spin_unlock();
  ldv_spin_unlock_irqrestore_12(lock, flags);
  return;
}
}
bool ldv_queue_work_on_15(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_16(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_17(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_18(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_19(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
__inline static struct page *alloc_pages(gfp_t flags , unsigned int order ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct page));
  return ((struct page *)tmp);
}
}
void *ldv_calloc(size_t nmemb , size_t size ) ;
__inline static void *kcalloc(size_t n , size_t size , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_calloc(n, size);
  return (tmp);
}
}
void *ldv_zalloc(size_t size ) ;
__inline static void *kzalloc(size_t size , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_zalloc(size);
  return (tmp);
}
}
int ldv_pskb_expand_head_31(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                            gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_33(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_35(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_36(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                          gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_37(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                          gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_38(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                          gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_39(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                            gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
int ldv_pskb_expand_head_40(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                            gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_41(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
int ldv_mod_timer_43(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___6 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
void ldv_free_irq_44(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) 
{ 


  {
  free_irq(ldv_func_arg1, ldv_func_arg2);
  disable_suitable_irq_2((int )ldv_func_arg1, ldv_func_arg2);
  return;
}
}
__inline static int ldv_request_irq_45(unsigned int irq , irqreturn_t (*handler)(int  ,
                                                                                 void * ) ,
                                       unsigned long flags , char const   *name ,
                                       void *dev ) 
{ 
  ldv_func_ret_type___7 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = request_irq(irq, handler, flags, name, dev);
  ldv_func_res = tmp;
  tmp___0 = reg_check_2(handler);
  if (tmp___0 != 0 && ldv_func_res == 0) {
    activate_suitable_irq_2((int )irq, dev);
  } else {

  }
  return (ldv_func_res);
}
}
void ldv_free_irq_46(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) 
{ 


  {
  free_irq(ldv_func_arg1, ldv_func_arg2);
  disable_suitable_irq_2((int )ldv_func_arg1, ldv_func_arg2);
  return;
}
}
__inline static int ldv_request_irq_47(unsigned int irq , irqreturn_t (*handler)(int  ,
                                                                                 void * ) ,
                                       unsigned long flags , char const   *name ,
                                       void *dev ) 
{ 
  ldv_func_ret_type___8 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = request_irq(irq, handler, flags, name, dev);
  ldv_func_res = tmp;
  tmp___0 = reg_check_2(handler);
  if (tmp___0 != 0 && ldv_func_res == 0) {
    activate_suitable_irq_2((int )irq, dev);
  } else {

  }
  return (ldv_func_res);
}
}
void ldv_free_irq_48(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) 
{ 


  {
  free_irq(ldv_func_arg1, ldv_func_arg2);
  disable_suitable_irq_2((int )ldv_func_arg1, ldv_func_arg2);
  return;
}
}
__inline static int ldv_request_irq_49(unsigned int irq , irqreturn_t (*handler)(int  ,
                                                                                 void * ) ,
                                       unsigned long flags , char const   *name ,
                                       void *dev ) 
{ 
  ldv_func_ret_type___9 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = request_irq(irq, handler, flags, name, dev);
  ldv_func_res = tmp;
  tmp___0 = reg_check_2(handler);
  if (tmp___0 != 0 && ldv_func_res == 0) {
    activate_suitable_irq_2((int )irq, dev);
  } else {

  }
  return (ldv_func_res);
}
}
int ldv_mod_timer_50(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___10 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_51(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___11 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_52(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___12 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_53(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___13 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_54(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___14 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_55(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
void ldv_destroy_workqueue_56(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  destroy_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
int ldv_register_netdev_57(struct net_device *dev ) 
{ 
  ldv_func_ret_type___15 ldv_func_res ;
  int tmp ;

  {
  tmp = register_netdev(dev);
  ldv_func_res = tmp;
  ldv_state_variable_21 = 1;
  ldv_net_device_ops_21();
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_58(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___16 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_59(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___17 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_60(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___18 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
void ldv_free_netdev_61(struct net_device *dev ) 
{ 


  {
  free_netdev(dev);
  ldv_state_variable_21 = 0;
  return;
}
}
void ldv_unregister_netdev_62(struct net_device *dev ) 
{ 


  {
  unregister_netdev(dev);
  ldv_state_variable_21 = 0;
  return;
}
}
int ldv_del_timer_sync_63(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___19 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_64(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___20 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_65(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___21 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
void ldv_free_netdev_66(struct net_device *dev ) 
{ 


  {
  free_netdev(dev);
  ldv_state_variable_21 = 0;
  return;
}
}
int ldv___pci_register_driver_67(struct pci_driver *ldv_func_arg1 , struct module *ldv_func_arg2 ,
                                 char const   *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___22 ldv_func_res ;
  int tmp ;

  {
  tmp = __pci_register_driver(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  ldv_state_variable_20 = 1;
  ldv_pci_driver_20();
  return (ldv_func_res);
}
}
void ldv_pci_unregister_driver_68(struct pci_driver *ldv_func_arg1 ) 
{ 


  {
  pci_unregister_driver(ldv_func_arg1);
  ldv_state_variable_20 = 0;
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
__inline static bool is_power_of_2(unsigned long n ) 
{ 


  {
  return ((bool )(n != 0UL && ((n - 1UL) & n) == 0UL));
}
}
extern void *memcpy(void * , void const   * , size_t  ) ;
extern size_t strlen(char const   * ) ;
extern size_t strlcpy(char * , char const   * , size_t  ) ;
extern void _raw_spin_lock_irq(raw_spinlock_t * ) ;
extern void _raw_spin_unlock_irq(raw_spinlock_t * ) ;
__inline static void ldv_spin_lock_irq_107(spinlock_t *lock ) 
{ 


  {
  _raw_spin_lock_irq(& lock->__annonCompField18.rlock);
  return;
}
}
__inline static void spin_lock_irq(spinlock_t *lock ) ;
__inline static void ldv_spin_unlock_irq_110(spinlock_t *lock ) 
{ 


  {
  _raw_spin_unlock_irq(& lock->__annonCompField18.rlock);
  return;
}
}
__inline static void spin_unlock_irq(spinlock_t *lock ) ;
__inline static void spin_unlock_irqrestore(spinlock_t *lock , unsigned long flags ) ;
int ldv_del_timer_sync_142(struct timer_list *ldv_func_arg1 ) ;
bool ldv_queue_work_on_114(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_116(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_115(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_118(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_117(struct workqueue_struct *ldv_func_arg1 ) ;
__inline static char const   *kobject_name(struct kobject  const  *kobj ) 
{ 


  {
  return ((char const   *)kobj->name);
}
}
__inline static void *kzalloc(size_t size , gfp_t flags ) ;
__inline static char const   *dev_name(struct device  const  *dev ) 
{ 
  char const   *tmp ;

  {
  if ((unsigned long )dev->init_name != (unsigned long )((char const   */* const  */)0)) {
    return ((char const   *)dev->init_name);
  } else {

  }
  tmp = kobject_name(& dev->kobj);
  return (tmp);
}
}
__inline static char const   *pci_name(struct pci_dev  const  *pdev ) 
{ 
  char const   *tmp ;

  {
  tmp = dev_name(& pdev->dev);
  return (tmp);
}
}
struct sk_buff *ldv_skb_clone_132(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_140(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_134(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_130(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_138(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_139(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_135(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_136(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_137(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
__inline static void ethtool_cmd_speed_set(struct ethtool_cmd *ep , __u32 speed ) 
{ 


  {
  ep->speed = (unsigned short )speed;
  ep->speed_hi = (unsigned short )(speed >> 16);
  return;
}
}
__inline static __u32 ethtool_cmd_speed(struct ethtool_cmd  const  *ep ) 
{ 


  {
  return ((__u32 )(((int )ep->speed_hi << 16) | (int )ep->speed));
}
}
extern u32 ethtool_op_get_link(struct net_device * ) ;
extern int ethtool_op_get_ts_info(struct net_device * , struct ethtool_ts_info * ) ;
extern void netdev_warn(struct net_device  const  * , char const   *  , ...) ;
void bfa_nw_ioc_get_attr(struct bfa_ioc *ioc , struct bfa_ioc_attr *ioc_attr ) ;
enum bfa_status bfa_nw_flash_get_attr(struct bfa_flash *flash , struct bfa_flash_attr *attr ,
                                      void (*cbfn)(void * , enum bfa_status  ) , void *cbarg ) ;
enum bfa_status bfa_nw_flash_update_part(struct bfa_flash *flash , u32 type , u8 instance ,
                                         void *buf , u32 len , u32 offset , void (*cbfn)(void * ,
                                                                                         enum bfa_status  ) ,
                                         void *cbarg ) ;
enum bfa_status bfa_nw_flash_read_part(struct bfa_flash *flash , u32 type , u8 instance ,
                                       void *buf , u32 len , u32 offset , void (*cbfn)(void * ,
                                                                                       enum bfa_status  ) ,
                                       void *cbarg ) ;
extern int request_firmware(struct firmware  const  ** , char const   * , struct device * ) ;
static char const   *bnad_net_stats_strings[196U]  = 
  {      "rx_packets",      "tx_packets",      "rx_bytes",      "tx_bytes", 
        "rx_errors",      "tx_errors",      "rx_dropped",      "tx_dropped", 
        "multicast",      "collisions",      "rx_length_errors",      "rx_over_errors", 
        "rx_crc_errors",      "rx_frame_errors",      "rx_fifo_errors",      "rx_missed_errors", 
        "tx_aborted_errors",      "tx_carrier_errors",      "tx_fifo_errors",      "tx_heartbeat_errors", 
        "tx_window_errors",      "rx_compressed",      "tx_compressed",      "netif_queue_stop", 
        "netif_queue_wakeup",      "netif_queue_stopped",      "tso4",      "tso6", 
        "tso_err",      "tcpcsum_offload",      "udpcsum_offload",      "csum_help", 
        "tx_skb_too_short",      "tx_skb_stopping",      "tx_skb_max_vectors",      "tx_skb_mss_too_long", 
        "tx_skb_tso_too_short",      "tx_skb_tso_prepare",      "tx_skb_non_tso_too_long",      "tx_skb_tcp_hdr", 
        "tx_skb_udp_hdr",      "tx_skb_csum_err",      "tx_skb_headlen_too_long",      "tx_skb_headlen_zero", 
        "tx_skb_frag_zero",      "tx_skb_len_mismatch",      "hw_stats_updates",      "netif_rx_dropped", 
        "link_toggle",      "cee_toggle",      "rxp_info_alloc_failed",      "mbox_intr_disabled", 
        "mbox_intr_enabled",      "tx_unmap_q_alloc_failed",      "rx_unmap_q_alloc_failed",      "rxbuf_alloc_failed", 
        "mac_stats_clr_cnt",      "mac_frame_64",      "mac_frame_65_127",      "mac_frame_128_255", 
        "mac_frame_256_511",      "mac_frame_512_1023",      "mac_frame_1024_1518",      "mac_frame_1518_1522", 
        "mac_rx_bytes",      "mac_rx_packets",      "mac_rx_fcs_error",      "mac_rx_multicast", 
        "mac_rx_broadcast",      "mac_rx_control_frames",      "mac_rx_pause",      "mac_rx_unknown_opcode", 
        "mac_rx_alignment_error",      "mac_rx_frame_length_error",      "mac_rx_code_error",      "mac_rx_carrier_sense_error", 
        "mac_rx_undersize",      "mac_rx_oversize",      "mac_rx_fragments",      "mac_rx_jabber", 
        "mac_rx_drop",      "mac_tx_bytes",      "mac_tx_packets",      "mac_tx_multicast", 
        "mac_tx_broadcast",      "mac_tx_pause",      "mac_tx_deferral",      "mac_tx_excessive_deferral", 
        "mac_tx_single_collision",      "mac_tx_muliple_collision",      "mac_tx_late_collision",      "mac_tx_excessive_collision", 
        "mac_tx_total_collision",      "mac_tx_pause_honored",      "mac_tx_drop",      "mac_tx_jabber", 
        "mac_tx_fcs_error",      "mac_tx_control_frame",      "mac_tx_oversize",      "mac_tx_undersize", 
        "mac_tx_fragments",      "bpc_tx_pause_0",      "bpc_tx_pause_1",      "bpc_tx_pause_2", 
        "bpc_tx_pause_3",      "bpc_tx_pause_4",      "bpc_tx_pause_5",      "bpc_tx_pause_6", 
        "bpc_tx_pause_7",      "bpc_tx_zero_pause_0",      "bpc_tx_zero_pause_1",      "bpc_tx_zero_pause_2", 
        "bpc_tx_zero_pause_3",      "bpc_tx_zero_pause_4",      "bpc_tx_zero_pause_5",      "bpc_tx_zero_pause_6", 
        "bpc_tx_zero_pause_7",      "bpc_tx_first_pause_0",      "bpc_tx_first_pause_1",      "bpc_tx_first_pause_2", 
        "bpc_tx_first_pause_3",      "bpc_tx_first_pause_4",      "bpc_tx_first_pause_5",      "bpc_tx_first_pause_6", 
        "bpc_tx_first_pause_7",      "bpc_rx_pause_0",      "bpc_rx_pause_1",      "bpc_rx_pause_2", 
        "bpc_rx_pause_3",      "bpc_rx_pause_4",      "bpc_rx_pause_5",      "bpc_rx_pause_6", 
        "bpc_rx_pause_7",      "bpc_rx_zero_pause_0",      "bpc_rx_zero_pause_1",      "bpc_rx_zero_pause_2", 
        "bpc_rx_zero_pause_3",      "bpc_rx_zero_pause_4",      "bpc_rx_zero_pause_5",      "bpc_rx_zero_pause_6", 
        "bpc_rx_zero_pause_7",      "bpc_rx_first_pause_0",      "bpc_rx_first_pause_1",      "bpc_rx_first_pause_2", 
        "bpc_rx_first_pause_3",      "bpc_rx_first_pause_4",      "bpc_rx_first_pause_5",      "bpc_rx_first_pause_6", 
        "bpc_rx_first_pause_7",      "rad_rx_frames",      "rad_rx_octets",      "rad_rx_vlan_frames", 
        "rad_rx_ucast",      "rad_rx_ucast_octets",      "rad_rx_ucast_vlan",      "rad_rx_mcast", 
        "rad_rx_mcast_octets",      "rad_rx_mcast_vlan",      "rad_rx_bcast",      "rad_rx_bcast_octets", 
        "rad_rx_bcast_vlan",      "rad_rx_drops",      "rlb_rad_rx_frames",      "rlb_rad_rx_octets", 
        "rlb_rad_rx_vlan_frames",      "rlb_rad_rx_ucast",      "rlb_rad_rx_ucast_octets",      "rlb_rad_rx_ucast_vlan", 
        "rlb_rad_rx_mcast",      "rlb_rad_rx_mcast_octets",      "rlb_rad_rx_mcast_vlan",      "rlb_rad_rx_bcast", 
        "rlb_rad_rx_bcast_octets",      "rlb_rad_rx_bcast_vlan",      "rlb_rad_rx_drops",      "fc_rx_ucast_octets", 
        "fc_rx_ucast",      "fc_rx_ucast_vlan",      "fc_rx_mcast_octets",      "fc_rx_mcast", 
        "fc_rx_mcast_vlan",      "fc_rx_bcast_octets",      "fc_rx_bcast",      "fc_rx_bcast_vlan", 
        "fc_tx_ucast_octets",      "fc_tx_ucast",      "fc_tx_ucast_vlan",      "fc_tx_mcast_octets", 
        "fc_tx_mcast",      "fc_tx_mcast_vlan",      "fc_tx_bcast_octets",      "fc_tx_bcast", 
        "fc_tx_bcast_vlan",      "fc_tx_parity_errors",      "fc_tx_timeout",      "fc_tx_fid_parity_errors"};
static int bnad_get_settings(struct net_device *netdev , struct ethtool_cmd *cmd ) 
{ 
  bool tmp ;

  {
  cmd->supported = 4096U;
  cmd->advertising = 4096U;
  cmd->autoneg = 0U;
  cmd->supported = cmd->supported | 1024U;
  cmd->advertising = cmd->advertising | 1024U;
  cmd->port = 3U;
  cmd->phy_address = 0U;
  tmp = netif_carrier_ok((struct net_device  const  *)netdev);
  if ((int )tmp) {
    ethtool_cmd_speed_set(cmd, 10000U);
    cmd->duplex = 1U;
  } else {
    ethtool_cmd_speed_set(cmd, 4294967295U);
    cmd->duplex = 255U;
  }
  cmd->transceiver = 1U;
  cmd->maxtxpkt = 0U;
  cmd->maxrxpkt = 0U;
  return (0);
}
}
static int bnad_set_settings(struct net_device *netdev , struct ethtool_cmd *cmd ) 
{ 
  __u32 tmp ;

  {
  if ((unsigned int )cmd->autoneg == 1U) {
    return (-95);
  } else {
    tmp = ethtool_cmd_speed((struct ethtool_cmd  const  *)cmd);
    if (tmp == 10000U && (unsigned int )cmd->duplex == 1U) {
      return (0);
    } else {

    }
  }
  return (-95);
}
}
static void bnad_get_drvinfo(struct net_device *netdev , struct ethtool_drvinfo *drvinfo ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  struct bfa_ioc_attr *ioc_attr ;
  unsigned long flags ;
  void *tmp___0 ;
  char const   *tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  strlcpy((char *)(& drvinfo->driver), "bna", 32UL);
  strlcpy((char *)(& drvinfo->version), "3.2.25.1", 32UL);
  tmp___0 = kzalloc(1600UL, 208U);
  ioc_attr = (struct bfa_ioc_attr *)tmp___0;
  if ((unsigned long )ioc_attr != (unsigned long )((struct bfa_ioc_attr *)0)) {
    ldv_spin_lock();
    bfa_nw_ioc_get_attr(& bnad->bna.ioceth.ioc, ioc_attr);
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    strlcpy((char *)(& drvinfo->fw_version), (char const   *)(& ioc_attr->adapter_attr.fw_ver),
            32UL);
    kfree((void const   *)ioc_attr);
  } else {

  }
  tmp___1 = pci_name((struct pci_dev  const  *)bnad->pcidev);
  strlcpy((char *)(& drvinfo->bus_info), tmp___1, 32UL);
  return;
}
}
static void bnad_get_wol(struct net_device *netdev , struct ethtool_wolinfo *wolinfo ) 
{ 


  {
  wolinfo->supported = 0U;
  wolinfo->wolopts = 0U;
  return;
}
}
static int bnad_get_coalesce(struct net_device *netdev , struct ethtool_coalesce *coalesce ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  unsigned long flags ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  ldv_spin_lock();
  coalesce->use_adaptive_rx_coalesce = bnad->cfg_flags & 1U;
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  coalesce->rx_coalesce_usecs = (__u32 )((int )bnad->rx_coalescing_timeo * 5);
  coalesce->tx_coalesce_usecs = (__u32 )((int )bnad->tx_coalescing_timeo * 5);
  coalesce->tx_max_coalesced_frames = 12U;
  return (0);
}
}
static int bnad_set_coalesce(struct net_device *netdev , struct ethtool_coalesce *coalesce ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  unsigned long flags ;
  int to_del ;
  int tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  to_del = 0;
  if (coalesce->rx_coalesce_usecs == 0U || coalesce->rx_coalesce_usecs > 1275U) {
    return (-22);
  } else {

  }
  if (coalesce->tx_coalesce_usecs == 0U || coalesce->tx_coalesce_usecs > 1275U) {
    return (-22);
  } else {

  }
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  ldv_spin_lock();
  if (coalesce->use_adaptive_rx_coalesce != 0U) {
    if ((bnad->cfg_flags & 1U) == 0U) {
      bnad->cfg_flags = bnad->cfg_flags | 1U;
      bnad_dim_timer_start(bnad);
    } else {

    }
  } else
  if ((int )bnad->cfg_flags & 1) {
    bnad->cfg_flags = bnad->cfg_flags & 4294967294U;
    if ((int )bnad->cfg_flags & 1) {
      tmp___0 = constant_test_bit(4L, (unsigned long const volatile   *)(& bnad->run_flags));
      if (tmp___0 != 0) {
        clear_bit(4L, (unsigned long volatile   *)(& bnad->run_flags));
        to_del = 1;
      } else {

      }
    } else {

    }
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    if (to_del != 0) {
      ldv_del_timer_sync_142(& bnad->dim_timer);
    } else {

    }
    ldv_spin_lock();
    bnad_rx_coalescing_timeo_set(bnad);
  } else {

  }
  if ((__u32 )bnad->tx_coalescing_timeo != coalesce->tx_coalesce_usecs / 5U) {
    bnad->tx_coalescing_timeo = (u8 )(coalesce->tx_coalesce_usecs / 5U);
    bnad_tx_coalescing_timeo_set(bnad);
  } else {

  }
  if ((__u32 )bnad->rx_coalescing_timeo != coalesce->rx_coalesce_usecs / 5U) {
    bnad->rx_coalescing_timeo = (u8 )(coalesce->rx_coalesce_usecs / 5U);
    if ((bnad->cfg_flags & 1U) == 0U) {
      bnad_rx_coalescing_timeo_set(bnad);
    } else {

    }
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  mutex_unlock(& bnad->conf_mutex);
  return (0);
}
}
static void bnad_get_ringparam(struct net_device *netdev , struct ethtool_ringparam *ringparam ) 
{ 
  struct bnad *bnad ;
  void *tmp ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  ringparam->rx_max_pending = 16384U;
  ringparam->tx_max_pending = 2048U;
  ringparam->rx_pending = bnad->rxq_depth;
  ringparam->tx_pending = bnad->txq_depth;
  return;
}
}
static int bnad_set_ringparam(struct net_device *netdev , struct ethtool_ringparam *ringparam ) 
{ 
  int i ;
  int current_err ;
    klee_make_symbolic(&current_err, sizeof(int), "current_err");
  int err ;
  struct bnad *bnad ;
  void *tmp ;
  unsigned long flags ;
  bool tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  bool tmp___4 ;
  int tmp___5 ;
  bool tmp___6 ;
  int tmp___7 ;

  {
  err = 0;
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  if (ringparam->rx_pending == bnad->rxq_depth && ringparam->tx_pending == bnad->txq_depth) {
    mutex_unlock(& bnad->conf_mutex);
    return (0);
  } else {

  }
  if (ringparam->rx_pending <= 511U || ringparam->rx_pending > 16384U) {
    mutex_unlock(& bnad->conf_mutex);
    return (-22);
  } else {
    tmp___0 = is_power_of_2((unsigned long )ringparam->rx_pending);
    if (tmp___0) {
      tmp___1 = 0;
    } else {
      tmp___1 = 1;
    }
    if (tmp___1) {
      mutex_unlock(& bnad->conf_mutex);
      return (-22);
    } else {

    }
  }
  if (ringparam->tx_pending <= 511U || ringparam->tx_pending > 2048U) {
    mutex_unlock(& bnad->conf_mutex);
    return (-22);
  } else {
    tmp___2 = is_power_of_2((unsigned long )ringparam->tx_pending);
    if (tmp___2) {
      tmp___3 = 0;
    } else {
      tmp___3 = 1;
    }
    if (tmp___3) {
      mutex_unlock(& bnad->conf_mutex);
      return (-22);
    } else {

    }
  }
  if (ringparam->rx_pending != bnad->rxq_depth) {
    bnad->rxq_depth = ringparam->rx_pending;
    tmp___4 = netif_running((struct net_device  const  *)netdev);
    if (tmp___4) {
      tmp___5 = 0;
    } else {
      tmp___5 = 1;
    }
    if (tmp___5) {
      mutex_unlock(& bnad->conf_mutex);
      return (0);
    } else {

    }
    i = 0;
    goto ldv_58209;
    ldv_58208: ;
    if ((unsigned long )bnad->rx_info[i].rx == (unsigned long )((struct bna_rx *)0)) {
      goto ldv_58207;
    } else {

    }
    bnad_destroy_rx(bnad, (u32 )i);
    current_err = bnad_setup_rx(bnad, (u32 )i);
    if (current_err != 0 && err == 0) {
      err = current_err;
    } else {

    }
    ldv_58207: 
    i = i + 1;
    ldv_58209: ;
    if ((u32 )i < bnad->num_rx) {
      goto ldv_58208;
    } else {

    }

    if (err == 0 && (unsigned long )bnad->rx_info[0].rx != (unsigned long )((struct bna_rx *)0)) {
      bnad_restore_vlans(bnad, 0U);
      bnad_enable_default_bcast(bnad);
      ldv_spin_lock();
      bnad_mac_addr_set_locked(bnad, (u8 const   *)netdev->dev_addr);
      spin_unlock_irqrestore(& bnad->bna_lock, flags);
      bnad->cfg_flags = bnad->cfg_flags & 4294967289U;
      bnad_set_rx_mode(netdev);
    } else {

    }
  } else {

  }
  if (ringparam->tx_pending != bnad->txq_depth) {
    bnad->txq_depth = ringparam->tx_pending;
    tmp___6 = netif_running((struct net_device  const  *)netdev);
    if (tmp___6) {
      tmp___7 = 0;
    } else {
      tmp___7 = 1;
    }
    if (tmp___7) {
      mutex_unlock(& bnad->conf_mutex);
      return (0);
    } else {

    }
    i = 0;
    goto ldv_58213;
    ldv_58212: ;
    if ((unsigned long )bnad->tx_info[i].tx == (unsigned long )((struct bna_tx *)0)) {
      goto ldv_58211;
    } else {

    }
    bnad_destroy_tx(bnad, (u32 )i);
    current_err = bnad_setup_tx(bnad, (u32 )i);
    if (current_err != 0 && err == 0) {
      err = current_err;
    } else {

    }
    ldv_58211: 
    i = i + 1;
    ldv_58213: ;
    if ((u32 )i < bnad->num_tx) {
      goto ldv_58212;
    } else {

    }

  } else {

  }
  mutex_unlock(& bnad->conf_mutex);
  return (err);
}
}
static void bnad_get_pauseparam(struct net_device *netdev , struct ethtool_pauseparam *pauseparam ) 
{ 
  struct bnad *bnad ;
  void *tmp ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  pauseparam->autoneg = 0U;
  pauseparam->rx_pause = (__u32 )bnad->bna.enet.pause_config.rx_pause;
  pauseparam->tx_pause = (__u32 )bnad->bna.enet.pause_config.tx_pause;
  return;
}
}
static int bnad_set_pauseparam(struct net_device *netdev , struct ethtool_pauseparam *pauseparam ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  struct bna_pause_config pause_config ;
  unsigned long flags ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  if (pauseparam->autoneg == 1U) {
    return (-22);
  } else {

  }
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  if (pauseparam->rx_pause != (__u32 )bnad->bna.enet.pause_config.rx_pause || pauseparam->tx_pause != (__u32 )bnad->bna.enet.pause_config.tx_pause) {
    pause_config.rx_pause = (enum bna_status )pauseparam->rx_pause;
    pause_config.tx_pause = (enum bna_status )pauseparam->tx_pause;
    ldv_spin_lock();
    bna_enet_pause_config(& bnad->bna.enet, & pause_config);
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
  } else {

  }
  mutex_unlock(& bnad->conf_mutex);
  return (0);
}
}
static void bnad_get_strings(struct net_device *netdev , u32 stringset , u8 *string ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  int i ;
  int j ;
  int q_num ;
    klee_make_symbolic(&q_num, sizeof(int), "q_num");
  u32 bmap___0 ;
  size_t tmp___0 ;
  long tmp___1 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  switch (stringset) {
  case 1U: 
  i = 0;
  goto ldv_58240;
  ldv_58239: 
  tmp___0 = strlen(bnad_net_stats_strings[i]);
  tmp___1 = ldv__builtin_expect(tmp___0 > 31UL, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bnad_ethtool.c"),
                         "i" (556), "i" (12UL));
    ldv_58238: ;
    goto ldv_58238;
  } else {

  }
  memcpy((void *)string, (void const   *)bnad_net_stats_strings[i], 32UL);
  string = string + 32UL;
  i = i + 1;
  ldv_58240: ;
  if ((unsigned int )i <= 195U) {
    goto ldv_58239;
  } else {

  }
  bmap___0 = bnad->bna.tx_mod.rid_mask;
  i = 0;
  goto ldv_58243;
  ldv_58242: ;
  if ((int )bmap___0 & 1) {
    sprintf((char *)string, "txf%d_ucast_octets", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_ucast", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_ucast_vlan", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_mcast_octets", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_mcast", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_mcast_vlan", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_bcast_octets", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_bcast", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_bcast_vlan", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_errors", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_filter_vlan", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_filter_mac_sa", i);
    string = string + 32UL;
  } else {

  }
  bmap___0 = bmap___0 >> 1;
  i = i + 1;
  ldv_58243: ;
  if (bmap___0 != 0U) {
    goto ldv_58242;
  } else {

  }
  bmap___0 = bnad->bna.rx_mod.rid_mask;
  i = 0;
  goto ldv_58246;
  ldv_58245: ;
  if ((int )bmap___0 & 1) {
    sprintf((char *)string, "rxf%d_ucast_octets", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_ucast", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_ucast_vlan", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_mcast_octets", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_mcast", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_mcast_vlan", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_bcast_octets", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_bcast", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_bcast_vlan", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_frame_drops", i);
    string = string + 32UL;
  } else {

  }
  bmap___0 = bmap___0 >> 1;
  i = i + 1;
  ldv_58246: ;
  if (bmap___0 != 0U) {
    goto ldv_58245;
  } else {

  }
  q_num = 0;
  i = 0;
  goto ldv_58253;
  ldv_58252: ;
  if ((unsigned long )bnad->rx_info[i].rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_58248;
  } else {

  }
  j = 0;
  goto ldv_58250;
  ldv_58249: 
  sprintf((char *)string, "cq%d_producer_index", q_num);
  string = string + 32UL;
  sprintf((char *)string, "cq%d_consumer_index", q_num);
  string = string + 32UL;
  sprintf((char *)string, "cq%d_hw_producer_index", q_num);
  string = string + 32UL;
  sprintf((char *)string, "cq%d_intr", q_num);
  string = string + 32UL;
  sprintf((char *)string, "cq%d_poll", q_num);
  string = string + 32UL;
  sprintf((char *)string, "cq%d_schedule", q_num);
  string = string + 32UL;
  sprintf((char *)string, "cq%d_keep_poll", q_num);
  string = string + 32UL;
  sprintf((char *)string, "cq%d_complete", q_num);
  string = string + 32UL;
  q_num = q_num + 1;
  j = j + 1;
  ldv_58250: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_58249;
  } else {

  }

  ldv_58248: 
  i = i + 1;
  ldv_58253: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_58252;
  } else {

  }
  q_num = 0;
  i = 0;
  goto ldv_58260;
  ldv_58259: ;
  if ((unsigned long )bnad->rx_info[i].rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_58255;
  } else {

  }
  j = 0;
  goto ldv_58257;
  ldv_58256: 
  sprintf((char *)string, "rxq%d_packets", q_num);
  string = string + 32UL;
  sprintf((char *)string, "rxq%d_bytes", q_num);
  string = string + 32UL;
  sprintf((char *)string, "rxq%d_packets_with_error", q_num);
  string = string + 32UL;
  sprintf((char *)string, "rxq%d_allocbuf_failed", q_num);
  string = string + 32UL;
  sprintf((char *)string, "rxq%d_producer_index", q_num);
  string = string + 32UL;
  sprintf((char *)string, "rxq%d_consumer_index", q_num);
  string = string + 32UL;
  q_num = q_num + 1;
  if (((unsigned long )bnad->rx_info[i].rx_ctrl[j].ccb != (unsigned long )((struct bna_ccb *)0) && (unsigned long )(bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1] != (unsigned long )((struct bna_rcb *)0)) && (unsigned long )((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1])->rxq != (unsigned long )((struct bna_rxq *)0)) {
    sprintf((char *)string, "rxq%d_packets", q_num);
    string = string + 32UL;
    sprintf((char *)string, "rxq%d_bytes", q_num);
    string = string + 32UL;
    sprintf((char *)string, "rxq%d_packets_with_error", q_num);
    string = string + 32UL;
    sprintf((char *)string, "rxq%d_allocbuf_failed", q_num);
    string = string + 32UL;
    sprintf((char *)string, "rxq%d_producer_index", q_num);
    string = string + 32UL;
    sprintf((char *)string, "rxq%d_consumer_index", q_num);
    string = string + 32UL;
    q_num = q_num + 1;
  } else {

  }
  j = j + 1;
  ldv_58257: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_58256;
  } else {

  }

  ldv_58255: 
  i = i + 1;
  ldv_58260: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_58259;
  } else {

  }
  q_num = 0;
  i = 0;
  goto ldv_58267;
  ldv_58266: ;
  if ((unsigned long )bnad->tx_info[i].tx == (unsigned long )((struct bna_tx *)0)) {
    goto ldv_58262;
  } else {

  }
  j = 0;
  goto ldv_58264;
  ldv_58263: 
  sprintf((char *)string, "txq%d_packets", q_num);
  string = string + 32UL;
  sprintf((char *)string, "txq%d_bytes", q_num);
  string = string + 32UL;
  sprintf((char *)string, "txq%d_producer_index", q_num);
  string = string + 32UL;
  sprintf((char *)string, "txq%d_consumer_index", q_num);
  string = string + 32UL;
  sprintf((char *)string, "txq%d_hw_consumer_index", q_num);
  string = string + 32UL;
  q_num = q_num + 1;
  j = j + 1;
  ldv_58264: ;
  if ((u32 )j < bnad->num_txq_per_tx) {
    goto ldv_58263;
  } else {

  }

  ldv_58262: 
  i = i + 1;
  ldv_58267: ;
  if ((u32 )i < bnad->num_tx) {
    goto ldv_58266;
  } else {

  }

  goto ldv_58269;
  default: ;
  goto ldv_58269;
  }
  ldv_58269: 
  mutex_unlock(& bnad->conf_mutex);
  return;
}
}
static int bnad_get_stats_count_locked(struct net_device *netdev ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  int i ;
  int j ;
  int count ;
  int rxf_active_num ;
    klee_make_symbolic(&rxf_active_num, sizeof(int), "rxf_active_num");
  int txf_active_num ;
    klee_make_symbolic(&txf_active_num, sizeof(int), "txf_active_num");
  u32 bmap___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  count = 0;
  rxf_active_num = 0;
  txf_active_num = 0;
  bmap___0 = bnad->bna.tx_mod.rid_mask;
  i = 0;
  goto ldv_58282;
  ldv_58281: ;
  if ((int )bmap___0 & 1) {
    txf_active_num = txf_active_num + 1;
  } else {

  }
  bmap___0 = bmap___0 >> 1;
  i = i + 1;
  ldv_58282: ;
  if (bmap___0 != 0U) {
    goto ldv_58281;
  } else {

  }
  bmap___0 = bnad->bna.rx_mod.rid_mask;
  i = 0;
  goto ldv_58285;
  ldv_58284: ;
  if ((int )bmap___0 & 1) {
    rxf_active_num = rxf_active_num + 1;
  } else {

  }
  bmap___0 = bmap___0 >> 1;
  i = i + 1;
  ldv_58285: ;
  if (bmap___0 != 0U) {
    goto ldv_58284;
  } else {

  }
  count = (int )(((unsigned int )(txf_active_num * 12) + (unsigned int )(rxf_active_num * 10)) + 196U);
  i = 0;
  goto ldv_58292;
  ldv_58291: ;
  if ((unsigned long )bnad->rx_info[i].rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_58287;
  } else {

  }
  count = (int )(bnad->num_rxp_per_rx * 8U + (u32 )count);
  count = (int )(bnad->num_rxp_per_rx * 6U + (u32 )count);
  j = 0;
  goto ldv_58289;
  ldv_58288: ;
  if (((unsigned long )bnad->rx_info[i].rx_ctrl[j].ccb != (unsigned long )((struct bna_ccb *)0) && (unsigned long )(bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1] != (unsigned long )((struct bna_rcb *)0)) && (unsigned long )((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1])->rxq != (unsigned long )((struct bna_rxq *)0)) {
    count = count + 6;
  } else {

  }
  j = j + 1;
  ldv_58289: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_58288;
  } else {

  }

  ldv_58287: 
  i = i + 1;
  ldv_58292: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_58291;
  } else {

  }
  i = 0;
  goto ldv_58296;
  ldv_58295: ;
  if ((unsigned long )bnad->tx_info[i].tx == (unsigned long )((struct bna_tx *)0)) {
    goto ldv_58294;
  } else {

  }
  count = (int )(bnad->num_txq_per_tx * 5U + (u32 )count);
  ldv_58294: 
  i = i + 1;
  ldv_58296: ;
  if ((u32 )i < bnad->num_tx) {
    goto ldv_58295;
  } else {

  }

  return (count);
}
}
static int bnad_per_q_stats_fill(struct bnad *bnad , u64 *buf , int bi ) 
{ 
  int i ;
  int j ;
  struct bna_rcb *rcb ;
  struct bna_tcb *tcb ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;
  int tmp___10 ;
  int tmp___11 ;
  int tmp___12 ;
  int tmp___13 ;
  int tmp___14 ;
    klee_make_symbolic(&tmp___14, sizeof(int), "tmp___14");
  int tmp___15 ;
  int tmp___16 ;
    klee_make_symbolic(&tmp___16, sizeof(int), "tmp___16");
  int tmp___17 ;
  int tmp___18 ;
  int tmp___19 ;
  int tmp___20 ;
  int tmp___21 ;
  int tmp___22 ;
  int tmp___23 ;

  {
  rcb = (struct bna_rcb *)0;
  tcb = (struct bna_tcb *)0;
  i = 0;
  goto ldv_58312;
  ldv_58311: ;
  if ((unsigned long )bnad->rx_info[i].rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_58307;
  } else {

  }
  j = 0;
  goto ldv_58309;
  ldv_58308: ;
  if (((unsigned long )bnad->rx_info[i].rx_ctrl[j].ccb != (unsigned long )((struct bna_ccb *)0) && (unsigned long )(bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[0] != (unsigned long )((struct bna_rcb *)0)) && (unsigned long )((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[0])->rxq != (unsigned long )((struct bna_rxq *)0)) {
    tmp = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp) = (u64 )(bnad->rx_info[i].rx_ctrl[j].ccb)->producer_index;
    tmp___0 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___0) = 0ULL;
    tmp___1 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___1) = (u64 )*((bnad->rx_info[i].rx_ctrl[j].ccb)->hw_producer_index);
    tmp___2 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___2) = bnad->rx_info[i].rx_ctrl[j].rx_intr_ctr;
    tmp___3 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___3) = bnad->rx_info[i].rx_ctrl[j].rx_poll_ctr;
    tmp___4 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___4) = bnad->rx_info[i].rx_ctrl[j].rx_schedule;
    tmp___5 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___5) = bnad->rx_info[i].rx_ctrl[j].rx_keep_poll;
    tmp___6 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___6) = bnad->rx_info[i].rx_ctrl[j].rx_complete;
  } else {

  }
  j = j + 1;
  ldv_58309: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_58308;
  } else {

  }

  ldv_58307: 
  i = i + 1;
  ldv_58312: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_58311;
  } else {

  }
  i = 0;
  goto ldv_58319;
  ldv_58318: ;
  if ((unsigned long )bnad->rx_info[i].rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_58314;
  } else {

  }
  j = 0;
  goto ldv_58316;
  ldv_58315: ;
  if ((unsigned long )bnad->rx_info[i].rx_ctrl[j].ccb != (unsigned long )((struct bna_ccb *)0)) {
    if ((unsigned long )(bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[0] != (unsigned long )((struct bna_rcb *)0) && (unsigned long )((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[0])->rxq != (unsigned long )((struct bna_rxq *)0)) {
      rcb = (bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[0];
      tmp___7 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___7) = (rcb->rxq)->rx_packets;
      tmp___8 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___8) = (rcb->rxq)->rx_bytes;
      tmp___9 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___9) = (rcb->rxq)->rx_packets_with_error;
      tmp___10 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___10) = (rcb->rxq)->rxbuf_alloc_failed;
      tmp___11 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___11) = (u64 )rcb->producer_index;
      tmp___12 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___12) = (u64 )rcb->consumer_index;
    } else {

    }
    if ((unsigned long )(bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1] != (unsigned long )((struct bna_rcb *)0) && (unsigned long )((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1])->rxq != (unsigned long )((struct bna_rxq *)0)) {
      rcb = (bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1];
      tmp___13 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___13) = (rcb->rxq)->rx_packets;
      tmp___14 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___14) = (rcb->rxq)->rx_bytes;
      tmp___15 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___15) = (rcb->rxq)->rx_packets_with_error;
      tmp___16 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___16) = (rcb->rxq)->rxbuf_alloc_failed;
      tmp___17 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___17) = (u64 )rcb->producer_index;
      tmp___18 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___18) = (u64 )rcb->consumer_index;
    } else {

    }
  } else {

  }
  j = j + 1;
  ldv_58316: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_58315;
  } else {

  }

  ldv_58314: 
  i = i + 1;
  ldv_58319: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_58318;
  } else {

  }
  i = 0;
  goto ldv_58326;
  ldv_58325: ;
  if ((unsigned long )bnad->tx_info[i].tx == (unsigned long )((struct bna_tx *)0)) {
    goto ldv_58321;
  } else {

  }
  j = 0;
  goto ldv_58323;
  ldv_58322: ;
  if ((unsigned long )bnad->tx_info[i].tcb[j] != (unsigned long )((struct bna_tcb *)0) && (unsigned long )(bnad->tx_info[i].tcb[j])->txq != (unsigned long )((struct bna_txq *)0)) {
    tcb = bnad->tx_info[i].tcb[j];
    tmp___19 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___19) = (tcb->txq)->tx_packets;
    tmp___20 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___20) = (tcb->txq)->tx_bytes;
    tmp___21 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___21) = (u64 )tcb->producer_index;
    tmp___22 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___22) = (u64 )tcb->consumer_index;
    tmp___23 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___23) = (u64 )*(tcb->hw_consumer_index);
  } else {

  }
  j = j + 1;
  ldv_58323: ;
  if ((u32 )j < bnad->num_txq_per_tx) {
    goto ldv_58322;
  } else {

  }

  ldv_58321: 
  i = i + 1;
  ldv_58326: ;
  if ((u32 )i < bnad->num_tx) {
    goto ldv_58325;
  } else {

  }

  return (bi);
}
}
static void bnad_get_ethtool_stats(struct net_device *netdev , struct ethtool_stats *stats ,
                                   u64 *buf ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  int i ;
  int j ;
  int bi ;
    klee_make_symbolic(&bi, sizeof(int), "bi");
  unsigned long flags ;
  struct rtnl_link_stats64 *net_stats64 ;
  u64 *stats64 ;
  u32 bmap___0 ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  tmp___0 = bnad_get_stats_count_locked(netdev);
  if ((__u32 )tmp___0 != stats->n_stats) {
    mutex_unlock(& bnad->conf_mutex);
    return;
  } else {

  }
  ldv_spin_lock();
  bi = 0;
  memset((void *)buf, 0, (unsigned long )stats->n_stats * 8UL);
  net_stats64 = (struct rtnl_link_stats64 *)buf;
  bnad_netdev_qstats_fill(bnad, net_stats64);
  bnad_netdev_hwstats_fill(bnad, net_stats64);
  bi = 23;
  tmp___1 = netif_queue_stopped((struct net_device  const  *)netdev);
  bnad->stats.drv_stats.netif_queue_stopped = (u64 )tmp___1;
  stats64 = (u64 *)(& bnad->stats.drv_stats);
  i = 0;
  goto ldv_58342;
  ldv_58341: 
  tmp___2 = bi;
  bi = bi + 1;
  *(buf + (unsigned long )tmp___2) = *(stats64 + (unsigned long )i);
  i = i + 1;
  ldv_58342: ;
  if ((unsigned int )i <= 32U) {
    goto ldv_58341;
  } else {

  }
  stats64 = (u64 *)(& (bnad->stats.bna_stats)->hw_stats);
  i = 0;
  goto ldv_58345;
  ldv_58344: 
  tmp___3 = bi;
  bi = bi + 1;
  *(buf + (unsigned long )tmp___3) = *(stats64 + (unsigned long )i);
  i = i + 1;
  ldv_58345: ;
  if ((unsigned int )i <= 139U) {
    goto ldv_58344;
  } else {

  }
  bmap___0 = bnad->bna.tx_mod.rid_mask;
  i = 0;
  goto ldv_58351;
  ldv_58350: ;
  if ((int )bmap___0 & 1) {
    stats64 = (u64 *)(& (bnad->stats.bna_stats)->hw_stats.txf_stats) + (unsigned long )i;
    j = 0;
    goto ldv_58348;
    ldv_58347: 
    tmp___4 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___4) = *(stats64 + (unsigned long )j);
    j = j + 1;
    ldv_58348: ;
    if ((unsigned int )j <= 11U) {
      goto ldv_58347;
    } else {

    }

  } else {

  }
  bmap___0 = bmap___0 >> 1;
  i = i + 1;
  ldv_58351: ;
  if (bmap___0 != 0U) {
    goto ldv_58350;
  } else {

  }
  bmap___0 = bnad->bna.rx_mod.rid_mask;
  i = 0;
  goto ldv_58357;
  ldv_58356: ;
  if ((int )bmap___0 & 1) {
    stats64 = (u64 *)(& (bnad->stats.bna_stats)->hw_stats.rxf_stats) + (unsigned long )i;
    j = 0;
    goto ldv_58354;
    ldv_58353: 
    tmp___5 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___5) = *(stats64 + (unsigned long )j);
    j = j + 1;
    ldv_58354: ;
    if ((unsigned int )j <= 9U) {
      goto ldv_58353;
    } else {

    }

  } else {

  }
  bmap___0 = bmap___0 >> 1;
  i = i + 1;
  ldv_58357: ;
  if (bmap___0 != 0U) {
    goto ldv_58356;
  } else {

  }
  bi = bnad_per_q_stats_fill(bnad, buf, bi);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  mutex_unlock(& bnad->conf_mutex);
  return;
}
}
static int bnad_get_sset_count(struct net_device *netdev , int sset ) 
{ 
  int tmp ;

  {
  switch (sset) {
  case 1: 
  tmp = bnad_get_stats_count_locked(netdev);
  return (tmp);
  default: ;
  return (-95);
  }
}
}
static u32 bnad_get_flash_partition_by_offset(struct bnad *bnad , u32 offset , u32 *base_offset ) 
{ 
  struct bfa_flash_attr *flash_attr ;
  struct bnad_iocmd_comp fcomp ;
  u32 i ;
  u32 flash_part ;
  u32 ret ;
  unsigned long flags ;
  void *tmp ;
  enum bfa_status tmp___0 ;

  {
  flash_part = 0U;
  flags = 0UL;
  tmp = kzalloc(1032UL, 208U);
  flash_attr = (struct bfa_flash_attr *)tmp;
  if ((unsigned long )flash_attr == (unsigned long )((struct bfa_flash_attr *)0)) {
    return (0U);
  } else {

  }
  fcomp.bnad = bnad;
  fcomp.comp_status = 0;
  init_completion(& fcomp.comp);
  ldv_spin_lock();
  tmp___0 = bfa_nw_flash_get_attr(& bnad->bna.flash, flash_attr, & bnad_cb_completion,
                                  (void *)(& fcomp));
  ret = (u32 )tmp___0;
  if (ret != 0U) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    kfree((void const   *)flash_attr);
    return (0U);
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& fcomp.comp);
  ret = (u32 )fcomp.comp_status;
  if (ret == 0U) {
    i = 0U;
    goto ldv_58378;
    ldv_58377: ;
    if (flash_attr->part[i].part_off <= offset && flash_attr->part[i].part_off + flash_attr->part[i].part_size > offset) {
      flash_part = flash_attr->part[i].part_type;
      *base_offset = flash_attr->part[i].part_off;
      goto ldv_58376;
    } else {

    }
    i = i + 1U;
    ldv_58378: ;
    if (flash_attr->npart > i) {
      goto ldv_58377;
    } else {

    }
    ldv_58376: ;
  } else {

  }
  kfree((void const   *)flash_attr);
  return (flash_part);
}
}
static int bnad_get_eeprom_len(struct net_device *netdev ) 
{ 


  {
  return (4194304);
}
}
static int bnad_get_eeprom(struct net_device *netdev , struct ethtool_eeprom *eeprom ,
                           u8 *bytes ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  struct bnad_iocmd_comp fcomp ;
  u32 flash_part ;
  u32 base_offset ;
  unsigned long flags ;
  int ret ;
  enum bfa_status tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  flash_part = 0U;
  base_offset = 0U;
  flags = 0UL;
  ret = 0;
  eeprom->magic = (__u32 )((int )(bnad->pcidev)->vendor | ((int )(bnad->pcidev)->device << 16));
  flash_part = bnad_get_flash_partition_by_offset(bnad, eeprom->offset, & base_offset);
  if (flash_part == 0U) {
    return (-14);
  } else {

  }
  fcomp.bnad = bnad;
  fcomp.comp_status = 0;
  init_completion(& fcomp.comp);
  ldv_spin_lock();
  tmp___0 = bfa_nw_flash_read_part(& bnad->bna.flash, flash_part, (int )((u8 )bnad->id),
                                   (void *)bytes, eeprom->len, eeprom->offset - base_offset,
                                   & bnad_cb_completion, (void *)(& fcomp));
  ret = (int )tmp___0;
  if (ret != 0) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    goto done;
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& fcomp.comp);
  ret = fcomp.comp_status;
  done: ;
  return (ret);
}
}
static int bnad_set_eeprom(struct net_device *netdev , struct ethtool_eeprom *eeprom ,
                           u8 *bytes ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  struct bnad_iocmd_comp fcomp ;
  u32 flash_part ;
  u32 base_offset ;
  unsigned long flags ;
  int ret ;
  enum bfa_status tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  flash_part = 0U;
  base_offset = 0U;
  flags = 0UL;
  ret = 0;
  if (eeprom->magic != (__u32 )((int )(bnad->pcidev)->vendor | ((int )(bnad->pcidev)->device << 16))) {
    return (-22);
  } else {

  }
  flash_part = bnad_get_flash_partition_by_offset(bnad, eeprom->offset, & base_offset);
  if (flash_part == 0U) {
    return (-14);
  } else {

  }
  fcomp.bnad = bnad;
  fcomp.comp_status = 0;
  init_completion(& fcomp.comp);
  ldv_spin_lock();
  tmp___0 = bfa_nw_flash_update_part(& bnad->bna.flash, flash_part, (int )((u8 )bnad->id),
                                     (void *)bytes, eeprom->len, eeprom->offset - base_offset,
                                     & bnad_cb_completion, (void *)(& fcomp));
  ret = (int )tmp___0;
  if (ret != 0) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    goto done;
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& fcomp.comp);
  ret = fcomp.comp_status;
  done: ;
  return (ret);
}
}
static int bnad_flash_device(struct net_device *netdev , struct ethtool_flash *eflash ) 
{ 
  struct bnad *bnad ;
  void *tmp ;
  struct bnad_iocmd_comp fcomp ;
  struct firmware  const  *fw ;
  int ret ;
  enum bfa_status tmp___0 ;

  {
  tmp = netdev_priv((struct net_device  const  *)netdev);
  bnad = (struct bnad *)tmp;
  ret = 0;
  ret = request_firmware(& fw, (char const   *)(& eflash->data), & (bnad->pcidev)->dev);
  if (ret != 0) {
    netdev_err((struct net_device  const  *)netdev, "can\'t load firmware %s\n", (char *)(& eflash->data));
    goto out;
  } else {

  }
  fcomp.bnad = bnad;
  fcomp.comp_status = 0;
  init_completion(& fcomp.comp);
  spin_lock_irq(& bnad->bna_lock);
  tmp___0 = bfa_nw_flash_update_part(& bnad->bna.flash, 2U, (int )((u8 )bnad->id),
                                     (void *)fw->data, (u32 )fw->size, 0U, & bnad_cb_completion,
                                     (void *)(& fcomp));
  ret = (int )tmp___0;
  if (ret != 0) {
    netdev_warn((struct net_device  const  *)netdev, "flash update failed with err=%d\n",
                ret);
    ret = -5;
    spin_unlock_irq(& bnad->bna_lock);
    goto out;
  } else {

  }
  spin_unlock_irq(& bnad->bna_lock);
  wait_for_completion(& fcomp.comp);
  if (fcomp.comp_status != 0) {
    ret = -5;
    netdev_warn((struct net_device  const  *)netdev, "firmware image update failed with err=%d\n",
                fcomp.comp_status);
  } else {

  }
  out: 
  release_firmware(fw);
  return (ret);
}
}
static struct ethtool_ops  const  bnad_ethtool_ops  = 
     {& bnad_get_settings, & bnad_set_settings, & bnad_get_drvinfo, 0, 0, & bnad_get_wol,
    0, 0, 0, 0, & ethtool_op_get_link, & bnad_get_eeprom_len, & bnad_get_eeprom, & bnad_set_eeprom,
    & bnad_get_coalesce, & bnad_set_coalesce, & bnad_get_ringparam, & bnad_set_ringparam,
    & bnad_get_pauseparam, & bnad_set_pauseparam, 0, & bnad_get_strings, 0, & bnad_get_ethtool_stats,
    0, 0, 0, 0, & bnad_get_sset_count, 0, 0, & bnad_flash_device, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, & ethtool_op_get_ts_info, 0, 0, 0, 0, 0, 0};
void bnad_set_ethtool_ops(struct net_device *netdev ) 
{ 


  {
  netdev->ethtool_ops = & bnad_ethtool_ops;
  return;
}
}
void ldv_initialize_ethtool_ops_19(void) 
{ 
  void *tmp ;
  void *tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  void *tmp___4 ;

  {
  tmp = ldv_init_zalloc(92UL);
  bnad_ethtool_ops_group4 = (struct ethtool_coalesce *)tmp;
  tmp___0 = ldv_init_zalloc(36UL);
  bnad_ethtool_ops_group0 = (struct ethtool_ringparam *)tmp___0;
  tmp___1 = ldv_init_zalloc(3008UL);
  bnad_ethtool_ops_group5 = (struct net_device *)tmp___1;
  tmp___2 = ldv_init_zalloc(16UL);
  bnad_ethtool_ops_group2 = (struct ethtool_eeprom *)tmp___2;
  tmp___3 = ldv_init_zalloc(44UL);
  bnad_ethtool_ops_group1 = (struct ethtool_cmd *)tmp___3;
  tmp___4 = ldv_init_zalloc(16UL);
  bnad_ethtool_ops_group3 = (struct ethtool_pauseparam *)tmp___4;
  return;
}
}
void ldv_main_exported_19(void) 
{ 
  u8 *ldvarg52 ;
  void *tmp ;
  u32 ldvarg55 ;
  struct ethtool_wolinfo *ldvarg53 ;
  void *tmp___0 ;
  struct ethtool_stats *ldvarg61 ;
  void *tmp___1 ;
  struct ethtool_ts_info *ldvarg58 ;
  void *tmp___2 ;
  u8 *ldvarg54 ;
  void *tmp___3 ;
  struct ethtool_flash *ldvarg57 ;
  void *tmp___4 ;
  struct ethtool_drvinfo *ldvarg62 ;
  void *tmp___5 ;
  u8 *ldvarg56 ;
  void *tmp___6 ;
  int ldvarg59 ;
    klee_make_symbolic(&ldvarg59, sizeof(int), "ldvarg59");
  u64 *ldvarg60 ;
  void *tmp___7 ;
  int tmp___8 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg52 = (u8 *)tmp;
  tmp___0 = ldv_init_zalloc(20UL);
  ldvarg53 = (struct ethtool_wolinfo *)tmp___0;
  tmp___1 = ldv_init_zalloc(8UL);
  ldvarg61 = (struct ethtool_stats *)tmp___1;
  tmp___2 = ldv_init_zalloc(44UL);
  ldvarg58 = (struct ethtool_ts_info *)tmp___2;
  tmp___3 = ldv_init_zalloc(1UL);
  ldvarg54 = (u8 *)tmp___3;
  tmp___4 = ldv_init_zalloc(136UL);
  ldvarg57 = (struct ethtool_flash *)tmp___4;
  tmp___5 = ldv_init_zalloc(196UL);
  ldvarg62 = (struct ethtool_drvinfo *)tmp___5;
  tmp___6 = ldv_init_zalloc(1UL);
  ldvarg56 = (u8 *)tmp___6;
  tmp___7 = ldv_init_zalloc(8UL);
  ldvarg60 = (u64 *)tmp___7;
  ldv_memset((void *)(& ldvarg55), 0, 4UL);
  ldv_memset((void *)(& ldvarg59), 0, 4UL);
  tmp___8 = __VERIFIER_nondet_int();
  switch (tmp___8) {
  case 0: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_drvinfo(bnad_ethtool_ops_group5, ldvarg62);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 1: ;
  if (ldv_state_variable_19 == 1) {
    bnad_set_pauseparam(bnad_ethtool_ops_group5, bnad_ethtool_ops_group3);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 2: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_coalesce(bnad_ethtool_ops_group5, bnad_ethtool_ops_group4);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 3: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_ethtool_stats(bnad_ethtool_ops_group5, ldvarg61, ldvarg60);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 4: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_ringparam(bnad_ethtool_ops_group5, bnad_ethtool_ops_group0);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 5: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_pauseparam(bnad_ethtool_ops_group5, bnad_ethtool_ops_group3);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 6: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_sset_count(bnad_ethtool_ops_group5, ldvarg59);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 7: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_settings(bnad_ethtool_ops_group5, bnad_ethtool_ops_group1);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 8: ;
  if (ldv_state_variable_19 == 1) {
    bnad_set_coalesce(bnad_ethtool_ops_group5, bnad_ethtool_ops_group4);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 9: ;
  if (ldv_state_variable_19 == 1) {
    ethtool_op_get_ts_info(bnad_ethtool_ops_group5, ldvarg58);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 10: ;
  if (ldv_state_variable_19 == 1) {
    bnad_flash_device(bnad_ethtool_ops_group5, ldvarg57);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 11: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_eeprom_len(bnad_ethtool_ops_group5);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 12: ;
  if (ldv_state_variable_19 == 1) {
    bnad_set_settings(bnad_ethtool_ops_group5, bnad_ethtool_ops_group1);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 13: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_eeprom(bnad_ethtool_ops_group5, bnad_ethtool_ops_group2, ldvarg56);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 14: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_strings(bnad_ethtool_ops_group5, ldvarg55, ldvarg54);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 15: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_wol(bnad_ethtool_ops_group5, ldvarg53);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 16: ;
  if (ldv_state_variable_19 == 1) {
    bnad_set_eeprom(bnad_ethtool_ops_group5, bnad_ethtool_ops_group2, ldvarg52);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 17: ;
  if (ldv_state_variable_19 == 1) {
    bnad_set_ringparam(bnad_ethtool_ops_group5, bnad_ethtool_ops_group0);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  case 18: ;
  if (ldv_state_variable_19 == 1) {
    ethtool_op_get_link(bnad_ethtool_ops_group5);
    ldv_state_variable_19 = 1;
  } else {

  }
  goto ldv_58437;
  default: 
  ldv_stop();
  }
  ldv_58437: ;
  return;
}
}
__inline static void spin_lock_irq(spinlock_t *lock ) 
{ 


  {
  ldv_spin_lock();
  ldv_spin_lock_irq_107(lock);
  return;
}
}
__inline static void spin_unlock_irq(spinlock_t *lock ) 
{ 


  {
  ldv_spin_unlock();
  ldv_spin_unlock_irq_110(lock);
  return;
}
}
bool ldv_queue_work_on_114(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_115(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_116(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_117(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_118(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
int ldv_pskb_expand_head_130(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_132(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_134(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_135(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_136(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_137(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_138(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
int ldv_pskb_expand_head_139(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_140(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
int ldv_del_timer_sync_142(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___6 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
extern int snprintf(char * , size_t  , char const   *  , ...) ;
extern int sscanf(char const   * , char const   *  , ...) ;
bool ldv_is_err(void const   *ptr ) ;
long ldv_ptr_err(void const   *ptr ) ;
extern void *memdup_user(void const   * , size_t  ) ;
__inline static long PTR_ERR(void const   *ptr ) ;
__inline static bool IS_ERR(void const   *ptr ) ;
__inline static void atomic_set(atomic_t *v , int i ) 
{ 


  {
  v->counter = i;
  return;
}
}
__inline static void atomic_dec(atomic_t *v ) 
{ 


  {
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; decl %0": "+m" (v->counter));
  return;
}
}
__inline static void spin_unlock_irqrestore(spinlock_t *lock , unsigned long flags ) ;
__inline static void reinit_completion(struct completion *x ) 
{ 


  {
  x->done = 0U;
  return;
}
}
bool ldv_queue_work_on_163(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_165(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_164(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_167(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_166(struct workqueue_struct *ldv_func_arg1 ) ;
__inline static void *kzalloc(size_t size , gfp_t flags ) ;
extern loff_t fixed_size_llseek(struct file * , loff_t  , int  , loff_t  ) ;
extern ssize_t simple_read_from_buffer(void * , size_t  , loff_t * , void const   * ,
                                       size_t  ) ;
extern struct dentry *debugfs_create_file(char const   * , umode_t  , struct dentry * ,
                                          void * , struct file_operations  const  * ) ;
extern struct dentry *debugfs_create_dir(char const   * , struct dentry * ) ;
extern void debugfs_remove(struct dentry * ) ;
struct sk_buff *ldv_skb_clone_181(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_189(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_183(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_179(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_187(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_188(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_184(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_185(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_186(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
int bfa_nw_ioc_debug_fwtrc(struct bfa_ioc *ioc , void *trcdata , int *trclen ) ;
int bfa_nw_ioc_debug_fwsave(struct bfa_ioc *ioc , void *trcdata , int *trclen ) ;
enum bfa_status bfa_nw_cee_get_attr(struct bfa_cee *cee , struct bfa_cee_attr *attr ,
                                    void (*cbfn)(void * , enum bfa_status  ) , void *cbarg ) ;
static int bnad_debugfs_open_fwtrc(struct inode *inode , struct file *file ) 
{ 
  struct bnad *bnad ;
  struct bnad_debug_info *fw_debug ;
  unsigned long flags ;
  int rc ;
  void *tmp ;
  void *tmp___0 ;

  {
  bnad = (struct bnad *)inode->i_private;
  tmp = kzalloc(24UL, 208U);
  fw_debug = (struct bnad_debug_info *)tmp;
  if ((unsigned long )fw_debug == (unsigned long )((struct bnad_debug_info *)0)) {
    return (-12);
  } else {

  }
  fw_debug->buffer_len = 4128;
  tmp___0 = kzalloc((size_t )fw_debug->buffer_len, 208U);
  fw_debug->debug_buffer = (char *)tmp___0;
  if ((unsigned long )fw_debug->debug_buffer == (unsigned long )((char *)0)) {
    kfree((void const   *)fw_debug);
    fw_debug = (struct bnad_debug_info *)0;
    return (-12);
  } else {

  }
  ldv_spin_lock();
  rc = bfa_nw_ioc_debug_fwtrc(& bnad->bna.ioceth.ioc, (void *)fw_debug->debug_buffer,
                              & fw_debug->buffer_len);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if (rc != 0) {
    kfree((void const   *)fw_debug->debug_buffer);
    fw_debug->debug_buffer = (char *)0;
    kfree((void const   *)fw_debug);
    fw_debug = (struct bnad_debug_info *)0;
    netdev_warn((struct net_device  const  *)bnad->netdev, "failed to collect fwtrc\n");
    return (-12);
  } else {

  }
  file->private_data = (void *)fw_debug;
  return (0);
}
}
static int bnad_debugfs_open_fwsave(struct inode *inode , struct file *file ) 
{ 
  struct bnad *bnad ;
  struct bnad_debug_info *fw_debug ;
  unsigned long flags ;
  int rc ;
  void *tmp ;
  void *tmp___0 ;

  {
  bnad = (struct bnad *)inode->i_private;
  tmp = kzalloc(24UL, 208U);
  fw_debug = (struct bnad_debug_info *)tmp;
  if ((unsigned long )fw_debug == (unsigned long )((struct bnad_debug_info *)0)) {
    return (-12);
  } else {

  }
  fw_debug->buffer_len = 4128;
  tmp___0 = kzalloc((size_t )fw_debug->buffer_len, 208U);
  fw_debug->debug_buffer = (char *)tmp___0;
  if ((unsigned long )fw_debug->debug_buffer == (unsigned long )((char *)0)) {
    kfree((void const   *)fw_debug);
    fw_debug = (struct bnad_debug_info *)0;
    return (-12);
  } else {

  }
  ldv_spin_lock();
  rc = bfa_nw_ioc_debug_fwsave(& bnad->bna.ioceth.ioc, (void *)fw_debug->debug_buffer,
                               & fw_debug->buffer_len);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if (rc != 0 && rc != 78) {
    kfree((void const   *)fw_debug->debug_buffer);
    fw_debug->debug_buffer = (char *)0;
    kfree((void const   *)fw_debug);
    fw_debug = (struct bnad_debug_info *)0;
    netdev_warn((struct net_device  const  *)bnad->netdev, "failed to collect fwsave\n");
    return (-12);
  } else {

  }
  file->private_data = (void *)fw_debug;
  return (0);
}
}
static int bnad_debugfs_open_reg(struct inode *inode , struct file *file ) 
{ 
  struct bnad_debug_info *reg_debug ;
  void *tmp ;

  {
  tmp = kzalloc(24UL, 208U);
  reg_debug = (struct bnad_debug_info *)tmp;
  if ((unsigned long )reg_debug == (unsigned long )((struct bnad_debug_info *)0)) {
    return (-12);
  } else {

  }
  reg_debug->i_private = inode->i_private;
  file->private_data = (void *)reg_debug;
  return (0);
}
}
static int bnad_get_debug_drvinfo(struct bnad *bnad , void *buffer , u32 len ) 
{ 
  struct bnad_drvinfo *drvinfo ;
  struct bnad_iocmd_comp fcomp ;
  unsigned long flags ;
  int ret ;
  enum bfa_status tmp ;
  enum bfa_status tmp___0 ;

  {
  drvinfo = (struct bnad_drvinfo *)buffer;
  flags = 0UL;
  ret = 1;
  ldv_spin_lock();
  bfa_nw_ioc_get_attr(& bnad->bna.ioceth.ioc, & drvinfo->ioc_attr);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  fcomp.bnad = bnad;
  fcomp.comp_status = 0;
  init_completion(& fcomp.comp);
  ldv_spin_lock();
  tmp = bfa_nw_cee_get_attr(& bnad->bna.cee, & drvinfo->cee_attr, & bnad_cb_completion,
                            (void *)(& fcomp));
  ret = (int )tmp;
  if (ret != 0) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    goto out;
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& fcomp.comp);
  drvinfo->cee_status = (u32 )fcomp.comp_status;
  fcomp.comp_status = 0;
  reinit_completion(& fcomp.comp);
  ldv_spin_lock();
  tmp___0 = bfa_nw_flash_get_attr(& bnad->bna.flash, & drvinfo->flash_attr, & bnad_cb_completion,
                                  (void *)(& fcomp));
  ret = (int )tmp___0;
  if (ret != 0) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    goto out;
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& fcomp.comp);
  drvinfo->flash_status = (u32 )fcomp.comp_status;
  out: ;
  return (ret);
}
}
static int bnad_debugfs_open_drvinfo(struct inode *inode , struct file *file ) 
{ 
  struct bnad *bnad ;
  struct bnad_debug_info *drv_info ;
  int rc ;
  void *tmp ;
  void *tmp___0 ;

  {
  bnad = (struct bnad *)inode->i_private;
  tmp = kzalloc(24UL, 208U);
  drv_info = (struct bnad_debug_info *)tmp;
  if ((unsigned long )drv_info == (unsigned long )((struct bnad_debug_info *)0)) {
    return (-12);
  } else {

  }
  drv_info->buffer_len = 3472;
  tmp___0 = kzalloc((size_t )drv_info->buffer_len, 208U);
  drv_info->debug_buffer = (char *)tmp___0;
  if ((unsigned long )drv_info->debug_buffer == (unsigned long )((char *)0)) {
    kfree((void const   *)drv_info);
    drv_info = (struct bnad_debug_info *)0;
    return (-12);
  } else {

  }
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  rc = bnad_get_debug_drvinfo(bnad, (void *)drv_info->debug_buffer, (u32 )drv_info->buffer_len);
  mutex_unlock(& bnad->conf_mutex);
  if (rc != 0) {
    kfree((void const   *)drv_info->debug_buffer);
    drv_info->debug_buffer = (char *)0;
    kfree((void const   *)drv_info);
    drv_info = (struct bnad_debug_info *)0;
    netdev_warn((struct net_device  const  *)bnad->netdev, "failed to collect drvinfo\n");
    return (-12);
  } else {

  }
  file->private_data = (void *)drv_info;
  return (0);
}
}
static loff_t bnad_debugfs_lseek(struct file *file , loff_t offset , int orig ) 
{ 
  struct bnad_debug_info *debug ;
  loff_t tmp ;

  {
  debug = (struct bnad_debug_info *)file->private_data;
  if ((unsigned long )debug == (unsigned long )((struct bnad_debug_info *)0)) {
    return (-22LL);
  } else {

  }
  tmp = fixed_size_llseek(file, offset, orig, (loff_t )debug->buffer_len);
  return (tmp);
}
}
static ssize_t bnad_debugfs_read(struct file *file , char *buf , size_t nbytes , loff_t *pos ) 
{ 
  struct bnad_debug_info *debug ;
  ssize_t tmp ;

  {
  debug = (struct bnad_debug_info *)file->private_data;
  if ((unsigned long )debug == (unsigned long )((struct bnad_debug_info *)0) || (unsigned long )debug->debug_buffer == (unsigned long )((char *)0)) {
    return (0L);
  } else {

  }
  tmp = simple_read_from_buffer((void *)buf, nbytes, pos, (void const   *)debug->debug_buffer,
                                (size_t )debug->buffer_len);
  return (tmp);
}
}
static int bna_reg_offset_check(struct bfa_ioc *ioc , u32 offset , u32 len ) 
{ 
  u8 area ;

  {
  area = (unsigned int )((u8 )(offset >> 15)) & 7U;
  if ((unsigned int )area == 0U) {
    if ((len << 2) + offset > 32768U) {
      return (2);
    } else {

    }
  } else
  if ((unsigned int )area == 1U) {
    if ((len << 2) + offset > 65536U) {
      return (2);
    } else {

    }
  } else
  if ((len << 2) + offset > (((unsigned int )ioc->pcidev.device_id == 20U || (unsigned int )ioc->pcidev.device_id == 33U) || (unsigned int )ioc->pcidev.device_id == 34U ? 262143U : 131071U)) {
    return (2);
  } else {

  }
  return (0);
}
}
static ssize_t bnad_debugfs_read_regrd(struct file *file , char *buf , size_t nbytes ,
                                       loff_t *pos ) 
{ 
  struct bnad_debug_info *regrd_debug ;
  struct bnad *bnad ;
  ssize_t rc ;

  {
  regrd_debug = (struct bnad_debug_info *)file->private_data;
  bnad = (struct bnad *)regrd_debug->i_private;
  if ((unsigned long )bnad->regdata == (unsigned long )((char *)0)) {
    return (0L);
  } else {

  }
  rc = simple_read_from_buffer((void *)buf, nbytes, pos, (void const   *)bnad->regdata,
                               (size_t )bnad->reglen);
  if ((unsigned long long )*pos + (unsigned long long )nbytes >= (unsigned long long )bnad->reglen) {
    kfree((void const   *)bnad->regdata);
    bnad->regdata = (char *)0;
    bnad->reglen = 0U;
  } else {

  }
  return (rc);
}
}
static ssize_t bnad_debugfs_write_regrd(struct file *file , char const   *buf , size_t nbytes ,
                                        loff_t *ppos ) 
{ 
  struct bnad_debug_info *regrd_debug ;
  struct bnad *bnad ;
  struct bfa_ioc *ioc ;
  int addr ;
  int len ;
  int rc ;
  int i ;
  u32 *regbuf ;
  void *rb ;
  void *reg_addr ;
  unsigned long flags ;
  void *kern_buf ;
  long tmp ;
  bool tmp___0 ;
  void *tmp___1 ;

  {
  regrd_debug = (struct bnad_debug_info *)file->private_data;
  bnad = (struct bnad *)regrd_debug->i_private;
  ioc = & bnad->bna.ioceth.ioc;
  kern_buf = memdup_user((void const   *)buf, nbytes);
  tmp___0 = IS_ERR((void const   *)kern_buf);
  if ((int )tmp___0) {
    tmp = PTR_ERR((void const   *)kern_buf);
    return (tmp);
  } else {

  }
  rc = sscanf((char const   *)kern_buf, "%x:%x", & addr, & len);
  if (rc <= 1) {
    netdev_warn((struct net_device  const  *)bnad->netdev, "failed to read user buffer\n");
    kfree((void const   *)kern_buf);
    return (-22L);
  } else {

  }
  kfree((void const   *)kern_buf);
  kfree((void const   *)bnad->regdata);
  bnad->reglen = 0U;
  tmp___1 = kzalloc((size_t )(len << 2), 208U);
  bnad->regdata = (char *)tmp___1;
  if ((unsigned long )bnad->regdata == (unsigned long )((char *)0)) {
    return (-12L);
  } else {

  }
  bnad->reglen = (u32 )(len << 2);
  rb = ioc->pcidev.pci_bar_kva;
  addr = (int )((((unsigned int )ioc->pcidev.device_id == 20U || (unsigned int )ioc->pcidev.device_id == 33U) || (unsigned int )ioc->pcidev.device_id == 34U ? 262143U : 131071U) & (unsigned int )addr);
  rc = bna_reg_offset_check(ioc, (u32 )addr, (u32 )len);
  if (rc != 0) {
    netdev_warn((struct net_device  const  *)bnad->netdev, "failed reg offset check\n");
    kfree((void const   *)bnad->regdata);
    bnad->regdata = (char *)0;
    bnad->reglen = 0U;
    return (-22L);
  } else {

  }
  reg_addr = rb + (unsigned long )addr;
  regbuf = (u32 *)bnad->regdata;
  ldv_spin_lock();
  i = 0;
  goto ldv_58378;
  ldv_58377: 
  *regbuf = readl((void const volatile   *)reg_addr);
  regbuf = regbuf + 1;
  reg_addr = reg_addr + 4UL;
  i = i + 1;
  ldv_58378: ;
  if (i < len) {
    goto ldv_58377;
  } else {

  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return ((ssize_t )nbytes);
}
}
static ssize_t bnad_debugfs_write_regwr(struct file *file , char const   *buf , size_t nbytes ,
                                        loff_t *ppos ) 
{ 
  struct bnad_debug_info *debug ;
  struct bnad *bnad ;
  struct bfa_ioc *ioc ;
  int addr ;
  int val ;
    klee_make_symbolic(&val, sizeof(int), "val");
  int rc ;
  void *reg_addr ;
  unsigned long flags ;
  void *kern_buf ;
  long tmp ;
  bool tmp___0 ;

  {
  debug = (struct bnad_debug_info *)file->private_data;
  bnad = (struct bnad *)debug->i_private;
  ioc = & bnad->bna.ioceth.ioc;
  kern_buf = memdup_user((void const   *)buf, nbytes);
  tmp___0 = IS_ERR((void const   *)kern_buf);
  if ((int )tmp___0) {
    tmp = PTR_ERR((void const   *)kern_buf);
    return (tmp);
  } else {

  }
  rc = sscanf((char const   *)kern_buf, "%x:%x", & addr, & val);
  if (rc <= 1) {
    netdev_warn((struct net_device  const  *)bnad->netdev, "failed to read user buffer\n");
    kfree((void const   *)kern_buf);
    return (-22L);
  } else {

  }
  kfree((void const   *)kern_buf);
  addr = (int )((((unsigned int )ioc->pcidev.device_id == 20U || (unsigned int )ioc->pcidev.device_id == 33U) || (unsigned int )ioc->pcidev.device_id == 34U ? 262143U : 131071U) & (unsigned int )addr);
  rc = bna_reg_offset_check(ioc, (u32 )addr, 1U);
  if (rc != 0) {
    netdev_warn((struct net_device  const  *)bnad->netdev, "failed reg offset check\n");
    return (-22L);
  } else {

  }
  reg_addr = ioc->pcidev.pci_bar_kva + (unsigned long )addr;
  ldv_spin_lock();
  writel((unsigned int )val, (void volatile   *)reg_addr);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return ((ssize_t )nbytes);
}
}
static int bnad_debugfs_release(struct inode *inode , struct file *file ) 
{ 
  struct bnad_debug_info *debug ;

  {
  debug = (struct bnad_debug_info *)file->private_data;
  if ((unsigned long )debug == (unsigned long )((struct bnad_debug_info *)0)) {
    return (0);
  } else {

  }
  file->private_data = (void *)0;
  kfree((void const   *)debug);
  return (0);
}
}
static int bnad_debugfs_buffer_release(struct inode *inode , struct file *file ) 
{ 
  struct bnad_debug_info *debug ;

  {
  debug = (struct bnad_debug_info *)file->private_data;
  if ((unsigned long )debug == (unsigned long )((struct bnad_debug_info *)0)) {
    return (0);
  } else {

  }
  kfree((void const   *)debug->debug_buffer);
  file->private_data = (void *)0;
  kfree((void const   *)debug);
  debug = (struct bnad_debug_info *)0;
  return (0);
}
}
static struct file_operations  const  bnad_debugfs_op_fwtrc  = 
     {& __this_module, & bnad_debugfs_lseek, & bnad_debugfs_read, 0, 0, 0, 0, 0, 0,
    0, 0, 0, & bnad_debugfs_open_fwtrc, 0, & bnad_debugfs_buffer_release, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static struct file_operations  const  bnad_debugfs_op_fwsave  = 
     {& __this_module, & bnad_debugfs_lseek, & bnad_debugfs_read, 0, 0, 0, 0, 0, 0,
    0, 0, 0, & bnad_debugfs_open_fwsave, 0, & bnad_debugfs_buffer_release, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static struct file_operations  const  bnad_debugfs_op_regrd  = 
     {& __this_module, & bnad_debugfs_lseek, & bnad_debugfs_read_regrd, & bnad_debugfs_write_regrd,
    0, 0, 0, 0, 0, 0, 0, 0, & bnad_debugfs_open_reg, 0, & bnad_debugfs_release, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static struct file_operations  const  bnad_debugfs_op_regwr  = 
     {& __this_module, & bnad_debugfs_lseek, 0, & bnad_debugfs_write_regwr, 0, 0, 0,
    0, 0, 0, 0, 0, & bnad_debugfs_open_reg, 0, & bnad_debugfs_release, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0};
static struct file_operations  const  bnad_debugfs_op_drvinfo  = 
     {& __this_module, & bnad_debugfs_lseek, & bnad_debugfs_read, 0, 0, 0, 0, 0, 0,
    0, 0, 0, & bnad_debugfs_open_drvinfo, 0, & bnad_debugfs_buffer_release, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static struct bnad_debugfs_entry  const  bnad_debugfs_files[5U]  = {      {"fwtrc", 33060U, & bnad_debugfs_op_fwtrc}, 
        {"fwsave", 33060U, & bnad_debugfs_op_fwsave}, 
        {"regrd", 33188U, & bnad_debugfs_op_regrd}, 
        {"regwr", 32896U, & bnad_debugfs_op_regwr}, 
        {"drvinfo", 33060U, & bnad_debugfs_op_drvinfo}};
static struct dentry *bna_debugfs_root  ;
static atomic_t bna_debugfs_port_count  ;
void bnad_debugfs_init(struct bnad *bnad ) 
{ 
  struct bnad_debugfs_entry  const  *file ;
  char name[64U] ;
  int i ;
  char const   *tmp ;

  {
  if ((unsigned long )bna_debugfs_root == (unsigned long )((struct dentry *)0)) {
    bna_debugfs_root = debugfs_create_dir("bna", (struct dentry *)0);
    atomic_set(& bna_debugfs_port_count, 0);
    if ((unsigned long )bna_debugfs_root == (unsigned long )((struct dentry *)0)) {
      netdev_warn((struct net_device  const  *)bnad->netdev, "debugfs root dir creation failed\n");
      return;
    } else {

    }
  } else {

  }
  tmp = pci_name((struct pci_dev  const  *)bnad->pcidev);
  snprintf((char *)(& name), 64UL, "pci_dev:%s", tmp);
  if ((unsigned long )bnad->port_debugfs_root == (unsigned long )((struct dentry *)0)) {
    bnad->port_debugfs_root = debugfs_create_dir((char const   *)(& name), bna_debugfs_root);
    if ((unsigned long )bnad->port_debugfs_root == (unsigned long )((struct dentry *)0)) {
      netdev_warn((struct net_device  const  *)bnad->netdev, "debugfs root dir creation failed\n");
      return;
    } else {

    }
    atomic_inc(& bna_debugfs_port_count);
    i = 0;
    goto ldv_58426;
    ldv_58425: 
    file = (struct bnad_debugfs_entry  const  *)(& bnad_debugfs_files) + (unsigned long )i;
    bnad->bnad_dentry_files[i] = debugfs_create_file(file->name, (int )file->mode,
                                                     bnad->port_debugfs_root, (void *)bnad,
                                                     file->fops);
    if ((unsigned long )bnad->bnad_dentry_files[i] == (unsigned long )((struct dentry *)0)) {
      netdev_warn((struct net_device  const  *)bnad->netdev, "create %s entry failed\n",
                  file->name);
      return;
    } else {

    }
    i = i + 1;
    ldv_58426: ;
    if ((unsigned int )i <= 4U) {
      goto ldv_58425;
    } else {

    }

  } else {

  }
  return;
}
}
void bnad_debugfs_uninit(struct bnad *bnad ) 
{ 
  int i ;
  int tmp ;

  {
  i = 0;
  goto ldv_58435;
  ldv_58434: ;
  if ((unsigned long )bnad->bnad_dentry_files[i] != (unsigned long )((struct dentry *)0)) {
    debugfs_remove(bnad->bnad_dentry_files[i]);
    bnad->bnad_dentry_files[i] = (struct dentry *)0;
  } else {

  }
  i = i + 1;
  ldv_58435: ;
  if ((unsigned int )i <= 4U) {
    goto ldv_58434;
  } else {

  }

  if ((unsigned long )bnad->port_debugfs_root != (unsigned long )((struct dentry *)0)) {
    debugfs_remove(bnad->port_debugfs_root);
    bnad->port_debugfs_root = (struct dentry *)0;
    atomic_dec(& bna_debugfs_port_count);
  } else {

  }
  tmp = atomic_read((atomic_t const   *)(& bna_debugfs_port_count));
  if (tmp == 0) {
    debugfs_remove(bna_debugfs_root);
    bna_debugfs_root = (struct dentry *)0;
  } else {

  }
  return;
}
}
int ldv_retval_5  ;
    klee_make_symbolic(&ldv_retval_5, sizeof(int), "ldv_retval_5");
int ldv_retval_8  ;
    klee_make_symbolic(&ldv_retval_8, sizeof(int), "ldv_retval_8");
int ldv_retval_3  ;
    klee_make_symbolic(&ldv_retval_3, sizeof(int), "ldv_retval_3");
int ldv_retval_2  ;
    klee_make_symbolic(&ldv_retval_2, sizeof(int), "ldv_retval_2");
int ldv_retval_7  ;
    klee_make_symbolic(&ldv_retval_7, sizeof(int), "ldv_retval_7");
void ldv_file_operations_15(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
  tmp = ldv_init_zalloc(1000UL);
  bnad_debugfs_op_regwr_group1 = (struct inode *)tmp;
  tmp___0 = ldv_init_zalloc(504UL);
  bnad_debugfs_op_regwr_group2 = (struct file *)tmp___0;
  return;
}
}
void ldv_file_operations_14(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
  tmp = ldv_init_zalloc(1000UL);
  bnad_debugfs_op_drvinfo_group1 = (struct inode *)tmp;
  tmp___0 = ldv_init_zalloc(504UL);
  bnad_debugfs_op_drvinfo_group2 = (struct file *)tmp___0;
  return;
}
}
void ldv_file_operations_16(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
  tmp = ldv_init_zalloc(1000UL);
  bnad_debugfs_op_regrd_group1 = (struct inode *)tmp;
  tmp___0 = ldv_init_zalloc(504UL);
  bnad_debugfs_op_regrd_group2 = (struct file *)tmp___0;
  return;
}
}
void ldv_file_operations_17(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
  tmp = ldv_init_zalloc(1000UL);
  bnad_debugfs_op_fwsave_group1 = (struct inode *)tmp;
  tmp___0 = ldv_init_zalloc(504UL);
  bnad_debugfs_op_fwsave_group2 = (struct file *)tmp___0;
  return;
}
}
void ldv_file_operations_18(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
  tmp = ldv_init_zalloc(1000UL);
  bnad_debugfs_op_fwtrc_group1 = (struct inode *)tmp;
  tmp___0 = ldv_init_zalloc(504UL);
  bnad_debugfs_op_fwtrc_group2 = (struct file *)tmp___0;
  return;
}
}
void ldv_main_exported_18(void) 
{ 
  loff_t ldvarg19 ;
  char *ldvarg22 ;
  void *tmp ;
  loff_t *ldvarg20 ;
  void *tmp___0 ;
  int ldvarg18 ;
    klee_make_symbolic(&ldvarg18, sizeof(int), "ldvarg18");
  size_t ldvarg21 ;
  int tmp___1 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg22 = (char *)tmp;
  tmp___0 = ldv_init_zalloc(8UL);
  ldvarg20 = (loff_t *)tmp___0;
  ldv_memset((void *)(& ldvarg19), 0, 8UL);
  ldv_memset((void *)(& ldvarg18), 0, 4UL);
  ldv_memset((void *)(& ldvarg21), 0, 8UL);
  tmp___1 = __VERIFIER_nondet_int();
  switch (tmp___1) {
  case 0: ;
  if (ldv_state_variable_18 == 1) {
    ldv_retval_3 = bnad_debugfs_open_fwtrc(bnad_debugfs_op_fwtrc_group1, bnad_debugfs_op_fwtrc_group2);
    if (ldv_retval_3 == 0) {
      ldv_state_variable_18 = 2;
      ref_cnt = ref_cnt + 1;
    } else {

    }
  } else {

  }
  goto ldv_58466;
  case 1: ;
  if (ldv_state_variable_18 == 2) {
    bnad_debugfs_buffer_release(bnad_debugfs_op_fwtrc_group1, bnad_debugfs_op_fwtrc_group2);
    ldv_state_variable_18 = 1;
    ref_cnt = ref_cnt - 1;
  } else {

  }
  goto ldv_58466;
  case 2: ;
  if (ldv_state_variable_18 == 2) {
    bnad_debugfs_read(bnad_debugfs_op_fwtrc_group2, ldvarg22, ldvarg21, ldvarg20);
    ldv_state_variable_18 = 2;
  } else {

  }
  goto ldv_58466;
  case 3: ;
  if (ldv_state_variable_18 == 2) {
    bnad_debugfs_lseek(bnad_debugfs_op_fwtrc_group2, ldvarg19, ldvarg18);
    ldv_state_variable_18 = 2;
  } else {

  }
  goto ldv_58466;
  default: 
  ldv_stop();
  }
  ldv_58466: ;
  return;
}
}
void ldv_main_exported_16(void) 
{ 
  loff_t *ldvarg28 ;
  void *tmp ;
  size_t ldvarg29 ;
  loff_t *ldvarg25 ;
  void *tmp___0 ;
  char *ldvarg30 ;
  void *tmp___1 ;
  int ldvarg23 ;
    klee_make_symbolic(&ldvarg23, sizeof(int), "ldvarg23");
  size_t ldvarg26 ;
  char *ldvarg27 ;
  void *tmp___2 ;
  loff_t ldvarg24 ;
  int tmp___3 ;

  {
  tmp = ldv_init_zalloc(8UL);
  ldvarg28 = (loff_t *)tmp;
  tmp___0 = ldv_init_zalloc(8UL);
  ldvarg25 = (loff_t *)tmp___0;
  tmp___1 = ldv_init_zalloc(1UL);
  ldvarg30 = (char *)tmp___1;
  tmp___2 = ldv_init_zalloc(1UL);
  ldvarg27 = (char *)tmp___2;
  ldv_memset((void *)(& ldvarg29), 0, 8UL);
  ldv_memset((void *)(& ldvarg23), 0, 4UL);
  ldv_memset((void *)(& ldvarg26), 0, 8UL);
  ldv_memset((void *)(& ldvarg24), 0, 8UL);
  tmp___3 = __VERIFIER_nondet_int();
  switch (tmp___3) {
  case 0: ;
  if (ldv_state_variable_16 == 1) {
    ldv_retval_5 = bnad_debugfs_open_reg(bnad_debugfs_op_regrd_group1, bnad_debugfs_op_regrd_group2);
    if (ldv_retval_5 == 0) {
      ldv_state_variable_16 = 2;
      ref_cnt = ref_cnt + 1;
    } else {

    }
  } else {

  }
  goto ldv_58483;
  case 1: ;
  if (ldv_state_variable_16 == 2) {
    bnad_debugfs_release(bnad_debugfs_op_regrd_group1, bnad_debugfs_op_regrd_group2);
    ldv_state_variable_16 = 1;
    ref_cnt = ref_cnt - 1;
  } else {

  }
  goto ldv_58483;
  case 2: ;
  if (ldv_state_variable_16 == 1) {
    bnad_debugfs_write_regrd(bnad_debugfs_op_regrd_group2, (char const   *)ldvarg30,
                             ldvarg29, ldvarg28);
    ldv_state_variable_16 = 1;
  } else {

  }
  if (ldv_state_variable_16 == 2) {
    bnad_debugfs_write_regrd(bnad_debugfs_op_regrd_group2, (char const   *)ldvarg30,
                             ldvarg29, ldvarg28);
    ldv_state_variable_16 = 2;
  } else {

  }
  goto ldv_58483;
  case 3: ;
  if (ldv_state_variable_16 == 2) {
    bnad_debugfs_read_regrd(bnad_debugfs_op_regrd_group2, ldvarg27, ldvarg26, ldvarg25);
    ldv_state_variable_16 = 2;
  } else {

  }
  goto ldv_58483;
  case 4: ;
  if (ldv_state_variable_16 == 2) {
    bnad_debugfs_lseek(bnad_debugfs_op_regrd_group2, ldvarg24, ldvarg23);
    ldv_state_variable_16 = 2;
  } else {

  }
  goto ldv_58483;
  default: 
  ldv_stop();
  }
  ldv_58483: ;
  return;
}
}
void ldv_main_exported_17(void) 
{ 
  loff_t *ldvarg15 ;
  void *tmp ;
  size_t ldvarg16 ;
  int ldvarg13 ;
    klee_make_symbolic(&ldvarg13, sizeof(int), "ldvarg13");
  loff_t ldvarg14 ;
  char *ldvarg17 ;
  void *tmp___0 ;
  int tmp___1 ;

  {
  tmp = ldv_init_zalloc(8UL);
  ldvarg15 = (loff_t *)tmp;
  tmp___0 = ldv_init_zalloc(1UL);
  ldvarg17 = (char *)tmp___0;
  ldv_memset((void *)(& ldvarg16), 0, 8UL);
  ldv_memset((void *)(& ldvarg13), 0, 4UL);
  ldv_memset((void *)(& ldvarg14), 0, 8UL);
  tmp___1 = __VERIFIER_nondet_int();
  switch (tmp___1) {
  case 0: ;
  if (ldv_state_variable_17 == 1) {
    ldv_retval_2 = bnad_debugfs_open_fwsave(bnad_debugfs_op_fwsave_group1, bnad_debugfs_op_fwsave_group2);
    if (ldv_retval_2 == 0) {
      ldv_state_variable_17 = 2;
      ref_cnt = ref_cnt + 1;
    } else {

    }
  } else {

  }
  goto ldv_58498;
  case 1: ;
  if (ldv_state_variable_17 == 2) {
    bnad_debugfs_buffer_release(bnad_debugfs_op_fwsave_group1, bnad_debugfs_op_fwsave_group2);
    ldv_state_variable_17 = 1;
    ref_cnt = ref_cnt - 1;
  } else {

  }
  goto ldv_58498;
  case 2: ;
  if (ldv_state_variable_17 == 2) {
    bnad_debugfs_read(bnad_debugfs_op_fwsave_group2, ldvarg17, ldvarg16, ldvarg15);
    ldv_state_variable_17 = 2;
  } else {

  }
  goto ldv_58498;
  case 3: ;
  if (ldv_state_variable_17 == 2) {
    bnad_debugfs_lseek(bnad_debugfs_op_fwsave_group2, ldvarg14, ldvarg13);
    ldv_state_variable_17 = 2;
  } else {

  }
  goto ldv_58498;
  default: 
  ldv_stop();
  }
  ldv_58498: ;
  return;
}
}
void ldv_main_exported_15(void) 
{ 
  int ldvarg47 ;
    klee_make_symbolic(&ldvarg47, sizeof(int), "ldvarg47");
  size_t ldvarg50 ;
  loff_t *ldvarg49 ;
  void *tmp ;
  char *ldvarg51 ;
  void *tmp___0 ;
  loff_t ldvarg48 ;
  int tmp___1 ;

  {
  tmp = ldv_init_zalloc(8UL);
  ldvarg49 = (loff_t *)tmp;
  tmp___0 = ldv_init_zalloc(1UL);
  ldvarg51 = (char *)tmp___0;
  ldv_memset((void *)(& ldvarg47), 0, 4UL);
  ldv_memset((void *)(& ldvarg50), 0, 8UL);
  ldv_memset((void *)(& ldvarg48), 0, 8UL);
  tmp___1 = __VERIFIER_nondet_int();
  switch (tmp___1) {
  case 0: ;
  if (ldv_state_variable_15 == 1) {
    ldv_retval_8 = bnad_debugfs_open_reg(bnad_debugfs_op_regwr_group1, bnad_debugfs_op_regwr_group2);
    if (ldv_retval_8 == 0) {
      ldv_state_variable_15 = 2;
      ref_cnt = ref_cnt + 1;
    } else {

    }
  } else {

  }
  goto ldv_58512;
  case 1: ;
  if (ldv_state_variable_15 == 2) {
    bnad_debugfs_release(bnad_debugfs_op_regwr_group1, bnad_debugfs_op_regwr_group2);
    ldv_state_variable_15 = 1;
    ref_cnt = ref_cnt - 1;
  } else {

  }
  goto ldv_58512;
  case 2: ;
  if (ldv_state_variable_15 == 1) {
    bnad_debugfs_write_regwr(bnad_debugfs_op_regwr_group2, (char const   *)ldvarg51,
                             ldvarg50, ldvarg49);
    ldv_state_variable_15 = 1;
  } else {

  }
  if (ldv_state_variable_15 == 2) {
    bnad_debugfs_write_regwr(bnad_debugfs_op_regwr_group2, (char const   *)ldvarg51,
                             ldvarg50, ldvarg49);
    ldv_state_variable_15 = 2;
  } else {

  }
  goto ldv_58512;
  case 3: ;
  if (ldv_state_variable_15 == 2) {
    bnad_debugfs_lseek(bnad_debugfs_op_regwr_group2, ldvarg48, ldvarg47);
    ldv_state_variable_15 = 2;
  } else {

  }
  goto ldv_58512;
  default: 
  ldv_stop();
  }
  ldv_58512: ;
  return;
}
}
void ldv_main_exported_14(void) 
{ 
  char *ldvarg46 ;
  void *tmp ;
  loff_t *ldvarg44 ;
  void *tmp___0 ;
  int ldvarg42 ;
    klee_make_symbolic(&ldvarg42, sizeof(int), "ldvarg42");
  loff_t ldvarg43 ;
  size_t ldvarg45 ;
  int tmp___1 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg46 = (char *)tmp;
  tmp___0 = ldv_init_zalloc(8UL);
  ldvarg44 = (loff_t *)tmp___0;
  ldv_memset((void *)(& ldvarg42), 0, 4UL);
  ldv_memset((void *)(& ldvarg43), 0, 8UL);
  ldv_memset((void *)(& ldvarg45), 0, 8UL);
  tmp___1 = __VERIFIER_nondet_int();
  switch (tmp___1) {
  case 0: ;
  if (ldv_state_variable_14 == 1) {
    ldv_retval_7 = bnad_debugfs_open_drvinfo(bnad_debugfs_op_drvinfo_group1, bnad_debugfs_op_drvinfo_group2);
    if (ldv_retval_7 == 0) {
      ldv_state_variable_14 = 2;
      ref_cnt = ref_cnt + 1;
    } else {

    }
  } else {

  }
  goto ldv_58526;
  case 1: ;
  if (ldv_state_variable_14 == 2) {
    bnad_debugfs_buffer_release(bnad_debugfs_op_drvinfo_group1, bnad_debugfs_op_drvinfo_group2);
    ldv_state_variable_14 = 1;
    ref_cnt = ref_cnt - 1;
  } else {

  }
  goto ldv_58526;
  case 2: ;
  if (ldv_state_variable_14 == 2) {
    bnad_debugfs_read(bnad_debugfs_op_drvinfo_group2, ldvarg46, ldvarg45, ldvarg44);
    ldv_state_variable_14 = 2;
  } else {

  }
  goto ldv_58526;
  case 3: ;
  if (ldv_state_variable_14 == 2) {
    bnad_debugfs_lseek(bnad_debugfs_op_drvinfo_group2, ldvarg43, ldvarg42);
    ldv_state_variable_14 = 2;
  } else {

  }
  goto ldv_58526;
  default: 
  ldv_stop();
  }
  ldv_58526: ;
  return;
}
}
__inline static long PTR_ERR(void const   *ptr ) 
{ 
  long tmp ;

  {
  tmp = ldv_ptr_err(ptr);
  return (tmp);
}
}
__inline static bool IS_ERR(void const   *ptr ) 
{ 
  bool tmp ;

  {
  tmp = ldv_is_err(ptr);
  return (tmp);
}
}
bool ldv_queue_work_on_163(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_164(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_165(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_166(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_167(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
int ldv_pskb_expand_head_179(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_181(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_183(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_184(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_185(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_186(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_187(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
int ldv_pskb_expand_head_188(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_189(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
__inline static int list_empty(struct list_head  const  *head ) 
{ 


  {
  return ((unsigned long )((struct list_head  const  *)head->next) == (unsigned long )head);
}
}
bool ldv_queue_work_on_210(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_212(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_211(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_214(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_213(struct workqueue_struct *ldv_func_arg1 ) ;
struct sk_buff *ldv_skb_clone_228(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_236(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_230(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_226(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_234(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_235(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_231(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_232(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_233(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
__inline static void bfa_wc_up(struct bfa_wc *wc ) 
{ 


  {
  wc->wc_count = wc->wc_count + 1;
  return;
}
}
__inline static void bfa_wc_down(struct bfa_wc *wc ) 
{ 


  {
  wc->wc_count = wc->wc_count - 1;
  if (wc->wc_count == 0) {
    (*(wc->wc_resume))(wc->wc_cbarg);
  } else {

  }
  return;
}
}
__inline static void bfa_wc_init(struct bfa_wc *wc , void (*wc_resume)(void * ) ,
                                 void *wc_cbarg ) 
{ 


  {
  wc->wc_resume = wc_resume;
  wc->wc_cbarg = wc_cbarg;
  wc->wc_count = 0;
  bfa_wc_up(wc);
  return;
}
}
__inline static void bfa_wc_wait(struct bfa_wc *wc ) 
{ 


  {
  bfa_wc_down(wc);
  return;
}
}
void bfa_nw_ioc_mbox_isr(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_attach(struct bfa_ioc *ioc , void *bfa , struct bfa_ioc_cbfn *cbfn ) ;
void bfa_nw_ioc_detach(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_pci_init(struct bfa_ioc *ioc , struct bfa_pcidev *pcidev , enum bfi_pcifn_class clscode ) ;
u32 bfa_nw_ioc_meminfo(void) ;
void bfa_nw_ioc_mem_claim(struct bfa_ioc *ioc , u8 *dm_kva , u64 dm_pa ) ;
void bfa_nw_ioc_enable(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_disable(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_error_isr(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_get_mac(struct bfa_ioc *ioc , u8 *mac ) ;
void bfa_nw_ioc_debug_memclaim(struct bfa_ioc *ioc , void *dbg_fwsave ) ;
u32 bfa_nw_flash_meminfo(void) ;
void bfa_nw_flash_attach(struct bfa_flash *flash , struct bfa_ioc *ioc , void *dev ) ;
void bfa_nw_flash_memclaim(struct bfa_flash *flash , u8 *dm_kva , u64 dm_pa ) ;
u32 bfa_nw_cee_meminfo(void) ;
void bfa_nw_cee_mem_claim(struct bfa_cee *cee , u8 *dma_kva , u64 dma_pa ) ;
void bfa_nw_cee_attach(struct bfa_cee *cee , struct bfa_ioc *ioc , void *dev ) ;
u32 bfa_msgq_meminfo(void) ;
void bfa_msgq_memclaim(struct bfa_msgq *msgq , u8 *kva , u64 pa ) ;
void bfa_msgq_attach(struct bfa_msgq *msgq , struct bfa_ioc *ioc ) ;
void bfa_msgq_regisr(struct bfa_msgq *msgq , enum bfi_mclass mc , void (*cbfn)(void * ,
                                                                               struct bfi_msgq_mhdr * ) ,
                     void *cbarg ) ;
void bfa_msgq_cmd_post(struct bfa_msgq *msgq , struct bfa_msgq_cmd_entry *cmd ) ;
struct bna_mac *bna_cam_mod_mac_get(struct list_head *head ) ;
struct bna_mcam_handle *bna_mcam_mod_handle_get(struct bna_mcam_mod *mcam_mod ) ;
void bna_mcam_mod_handle_put(struct bna_mcam_mod *mcam_mod , struct bna_mcam_handle *handle ) ;
void bna_ethport_cb_rx_started(struct bna_ethport *ethport ) ;
void bna_ethport_cb_rx_stopped(struct bna_ethport *ethport ) ;
void bna_bfi_tx_enet_start_rsp(struct bna_tx *tx , struct bfi_msgq_mhdr *msghdr ) ;
void bna_bfi_tx_enet_stop_rsp(struct bna_tx *tx , struct bfi_msgq_mhdr *msghdr ) ;
void bna_bfi_bw_update_aen(struct bna_tx_mod *tx_mod ) ;
void bna_tx_mod_init(struct bna_tx_mod *tx_mod , struct bna *bna , struct bna_res_info *res_info ) ;
void bna_tx_mod_uninit(struct bna_tx_mod *tx_mod ) ;
void bna_tx_mod_start(struct bna_tx_mod *tx_mod , enum bna_tx_type type ) ;
void bna_tx_mod_stop(struct bna_tx_mod *tx_mod , enum bna_tx_type type ) ;
void bna_tx_mod_fail(struct bna_tx_mod *tx_mod ) ;
void bna_bfi_rx_enet_start_rsp(struct bna_rx *rx , struct bfi_msgq_mhdr *msghdr ) ;
void bna_bfi_rx_enet_stop_rsp(struct bna_rx *rx , struct bfi_msgq_mhdr *msghdr ) ;
void bna_bfi_rxf_cfg_rsp(struct bna_rxf *rxf , struct bfi_msgq_mhdr *msghdr ) ;
void bna_bfi_rxf_mcast_add_rsp(struct bna_rxf *rxf , struct bfi_msgq_mhdr *msghdr ) ;
void bna_bfi_rxf_ucast_set_rsp(struct bna_rxf *rxf , struct bfi_msgq_mhdr *msghdr ) ;
void bna_rx_mod_init(struct bna_rx_mod *rx_mod , struct bna *bna , struct bna_res_info *res_info ) ;
void bna_rx_mod_uninit(struct bna_rx_mod *rx_mod ) ;
void bna_rx_mod_start(struct bna_rx_mod *rx_mod , enum bna_rx_type type ) ;
void bna_rx_mod_stop(struct bna_rx_mod *rx_mod , enum bna_rx_type type ) ;
void bna_rx_mod_fail(struct bna_rx_mod *rx_mod ) ;
int bna_enet_mtu_get(struct bna_enet *enet ) ;
void bna_enet_cb_tx_stopped(struct bna_enet *enet ) ;
void bna_enet_cb_rx_stopped(struct bna_enet *enet ) ;
__inline static int ethport_can_be_up(struct bna_ethport *ethport ) 
{ 
  int ready ;
    klee_make_symbolic(&ready, sizeof(int), "ready");

  {
  ready = 0;
  if ((unsigned int )(ethport->bna)->enet.type == 0U) {
    ready = ((int )ethport->flags & 1 && ((unsigned int )ethport->flags & 4U) != 0U) && ((unsigned int )ethport->flags & 2U) != 0U;
  } else {
    ready = ((int )ethport->flags & 1 && ((unsigned int )ethport->flags & 4U) != 0U) && ((unsigned int )ethport->flags & 2U) == 0U;
  }
  return (ready);
}
}
static void bna_bfi_ethport_enable_aen(struct bna_ethport *ethport , struct bfi_msgq_mhdr *msghdr ) 
{ 
  int tmp ;

  {
  ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags | 2U);
  tmp = ethport_can_be_up(ethport);
  if (tmp != 0) {
    (*(ethport->fsm))((void *)ethport, 4);
  } else {

  }
  return;
}
}
static void bna_bfi_ethport_disable_aen(struct bna_ethport *ethport , struct bfi_msgq_mhdr *msghdr ) 
{ 
  int ethport_up ;
    klee_make_symbolic(&ethport_up, sizeof(int), "ethport_up");
  int tmp ;

  {
  tmp = ethport_can_be_up(ethport);
  ethport_up = tmp;
  ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags & 4294967293U);
  if (ethport_up != 0) {
    (*(ethport->fsm))((void *)ethport, 5);
  } else {

  }
  return;
}
}
static void bna_bfi_ethport_admin_rsp(struct bna_ethport *ethport , struct bfi_msgq_mhdr *msghdr ) 
{ 
  struct bfi_enet_enable_req *admin_req ;
  struct bfi_enet_rsp *rsp ;
  struct bfi_msgq_mhdr  const  *__mptr ;

  {
  admin_req = & ethport->bfi_enet_cmd.admin_req;
  __mptr = (struct bfi_msgq_mhdr  const  *)msghdr;
  rsp = (struct bfi_enet_rsp *)__mptr;
  switch ((int )admin_req->enable) {
  case 1: ;
  if ((unsigned int )rsp->error == 0U) {
    (*(ethport->fsm))((void *)ethport, 6);
  } else {
    ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags & 4294967293U);
    (*(ethport->fsm))((void *)ethport, 8);
  }
  goto ldv_49150;
  case 0: 
  (*(ethport->fsm))((void *)ethport, 7);
  ethport->link_status = 0;
  (*(ethport->link_cbfn))((ethport->bna)->bnad, 0);
  goto ldv_49150;
  }
  ldv_49150: ;
  return;
}
}
static void bna_bfi_ethport_lpbk_rsp(struct bna_ethport *ethport , struct bfi_msgq_mhdr *msghdr ) 
{ 
  struct bfi_enet_diag_lb_req *diag_lb_req ;
  struct bfi_enet_rsp *rsp ;
  struct bfi_msgq_mhdr  const  *__mptr ;

  {
  diag_lb_req = & ethport->bfi_enet_cmd.lpbk_req;
  __mptr = (struct bfi_msgq_mhdr  const  *)msghdr;
  rsp = (struct bfi_enet_rsp *)__mptr;
  switch ((int )diag_lb_req->enable) {
  case 1: ;
  if ((unsigned int )rsp->error == 0U) {
    (*(ethport->fsm))((void *)ethport, 6);
  } else {
    ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags & 4294967294U);
    (*(ethport->fsm))((void *)ethport, 8);
  }
  goto ldv_49161;
  case 0: 
  (*(ethport->fsm))((void *)ethport, 7);
  goto ldv_49161;
  }
  ldv_49161: ;
  return;
}
}
static void bna_bfi_pause_set_rsp(struct bna_enet *enet , struct bfi_msgq_mhdr *msghdr ) 
{ 


  {
  (*(enet->fsm))((void *)enet, 6);
  return;
}
}
static void bna_bfi_attr_get_rsp(struct bna_ioceth *ioceth , struct bfi_msgq_mhdr *msghdr ) 
{ 
  struct bfi_enet_attr_rsp *rsp ;
  struct bfi_msgq_mhdr  const  *__mptr ;
  __u32 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;

  {
  __mptr = (struct bfi_msgq_mhdr  const  *)msghdr;
  rsp = (struct bfi_enet_attr_rsp *)__mptr;
  if (! ioceth->attr.fw_query_complete) {
    tmp = __fswab32(rsp->max_cfg);
    ioceth->attr.num_txq = (int )tmp;
    tmp___0 = __fswab32(rsp->max_cfg);
    ioceth->attr.num_rxp = (int )tmp___0;
    tmp___1 = __fswab32(rsp->max_ucmac);
    ioceth->attr.num_ucmac = (int )tmp___1;
    ioceth->attr.num_mcmac = 256;
    tmp___2 = __fswab32(rsp->rit_size);
    ioceth->attr.max_rit_size = (int )tmp___2;
    ioceth->attr.fw_query_complete = 1;
  } else {

  }
  (*(ioceth->fsm))((void *)ioceth, 6);
  return;
}
}
static void bna_bfi_stats_get_rsp(struct bna *bna , struct bfi_msgq_mhdr *msghdr ) 
{ 
  struct bfi_enet_stats_req *stats_req ;
  u64 *stats_src ;
  u64 *stats_dst ;
  u32 tx_enet_mask ;
  __u32 tmp ;
  u32 rx_enet_mask ;
  __u32 tmp___0 ;
  int count ;
  int i ;
  __u64 tmp___1 ;
  __u64 tmp___2 ;
  __u64 tmp___3 ;
  __u64 tmp___4 ;
  __u64 tmp___5 ;
  __u64 tmp___6 ;
  int k ;
    klee_make_symbolic(&k, sizeof(int), "k");
  __u64 tmp___7 ;
  int k___0 ;
    klee_make_symbolic(&k___0, sizeof(int), "k___0");
  __u64 tmp___8 ;

  {
  stats_req = & bna->stats_mod.stats_get;
  tmp = __fswab32(stats_req->tx_enet_mask);
  tx_enet_mask = tmp;
  tmp___0 = __fswab32(stats_req->rx_enet_mask);
  rx_enet_mask = tmp___0;
  count = 45;
  stats_src = (u64 *)(& (bna->stats.hw_stats_kva)->mac_stats);
  stats_dst = (u64 *)(& bna->stats.hw_stats.mac_stats);
  i = 0;
  goto ldv_49186;
  ldv_49185: 
  tmp___1 = __fswab64(*(stats_src + (unsigned long )i));
  *(stats_dst + (unsigned long )i) = tmp___1;
  i = i + 1;
  ldv_49186: ;
  if (i < count) {
    goto ldv_49185;
  } else {

  }
  count = 48;
  stats_src = (u64 *)(& (bna->stats.hw_stats_kva)->bpc_stats);
  stats_dst = (u64 *)(& bna->stats.hw_stats.bpc_stats);
  i = 0;
  goto ldv_49189;
  ldv_49188: 
  tmp___2 = __fswab64(*(stats_src + (unsigned long )i));
  *(stats_dst + (unsigned long )i) = tmp___2;
  i = i + 1;
  ldv_49189: ;
  if (i < count) {
    goto ldv_49188;
  } else {

  }
  count = 13;
  stats_src = (u64 *)(& (bna->stats.hw_stats_kva)->rad_stats);
  stats_dst = (u64 *)(& bna->stats.hw_stats.rad_stats);
  i = 0;
  goto ldv_49192;
  ldv_49191: 
  tmp___3 = __fswab64(*(stats_src + (unsigned long )i));
  *(stats_dst + (unsigned long )i) = tmp___3;
  i = i + 1;
  ldv_49192: ;
  if (i < count) {
    goto ldv_49191;
  } else {

  }
  count = 13;
  stats_src = (u64 *)(& (bna->stats.hw_stats_kva)->rlb_stats);
  stats_dst = (u64 *)(& bna->stats.hw_stats.rlb_stats);
  i = 0;
  goto ldv_49195;
  ldv_49194: 
  tmp___4 = __fswab64(*(stats_src + (unsigned long )i));
  *(stats_dst + (unsigned long )i) = tmp___4;
  i = i + 1;
  ldv_49195: ;
  if (i < count) {
    goto ldv_49194;
  } else {

  }
  count = 9;
  stats_src = (u64 *)(& (bna->stats.hw_stats_kva)->fc_rx_stats);
  stats_dst = (u64 *)(& bna->stats.hw_stats.fc_rx_stats);
  i = 0;
  goto ldv_49198;
  ldv_49197: 
  tmp___5 = __fswab64(*(stats_src + (unsigned long )i));
  *(stats_dst + (unsigned long )i) = tmp___5;
  i = i + 1;
  ldv_49198: ;
  if (i < count) {
    goto ldv_49197;
  } else {

  }
  count = 12;
  stats_src = (u64 *)(& (bna->stats.hw_stats_kva)->fc_tx_stats);
  stats_dst = (u64 *)(& bna->stats.hw_stats.fc_tx_stats);
  i = 0;
  goto ldv_49201;
  ldv_49200: 
  tmp___6 = __fswab64(*(stats_src + (unsigned long )i));
  *(stats_dst + (unsigned long )i) = tmp___6;
  i = i + 1;
  ldv_49201: ;
  if (i < count) {
    goto ldv_49200;
  } else {

  }
  stats_src = (u64 *)(& (bna->stats.hw_stats_kva)->rxf_stats);
  i = 0;
  goto ldv_49208;
  ldv_49207: 
  stats_dst = (u64 *)(& bna->stats.hw_stats.rxf_stats) + (unsigned long )i;
  memset((void *)stats_dst, 0, 80UL);
  if ((int )((unsigned long )rx_enet_mask >> i) & 1) {
    count = 10;
    k = 0;
    goto ldv_49205;
    ldv_49204: 
    tmp___7 = __fswab64(*stats_src);
    *(stats_dst + (unsigned long )k) = tmp___7;
    stats_src = stats_src + 1;
    k = k + 1;
    ldv_49205: ;
    if (k < count) {
      goto ldv_49204;
    } else {

    }

  } else {

  }
  i = i + 1;
  ldv_49208: ;
  if (i <= 31) {
    goto ldv_49207;
  } else {

  }
  i = 0;
  goto ldv_49215;
  ldv_49214: 
  stats_dst = (u64 *)(& bna->stats.hw_stats.txf_stats) + (unsigned long )i;
  memset((void *)stats_dst, 0, 96UL);
  if ((int )((unsigned long )tx_enet_mask >> i) & 1) {
    count = 12;
    k___0 = 0;
    goto ldv_49212;
    ldv_49211: 
    tmp___8 = __fswab64(*stats_src);
    *(stats_dst + (unsigned long )k___0) = tmp___8;
    stats_src = stats_src + 1;
    k___0 = k___0 + 1;
    ldv_49212: ;
    if (k___0 < count) {
      goto ldv_49211;
    } else {

    }

  } else {

  }
  i = i + 1;
  ldv_49215: ;
  if (i <= 31) {
    goto ldv_49214;
  } else {

  }
  bna->stats_mod.stats_get_busy = 0;
  bnad_cb_stats_get(bna->bnad, 0, & bna->stats);
  return;
}
}
static void bna_bfi_ethport_linkup_aen(struct bna_ethport *ethport , struct bfi_msgq_mhdr *msghdr ) 
{ 


  {
  ethport->link_status = 1;
  (*(ethport->link_cbfn))((ethport->bna)->bnad, ethport->link_status);
  return;
}
}
static void bna_bfi_ethport_linkdown_aen(struct bna_ethport *ethport , struct bfi_msgq_mhdr *msghdr ) 
{ 


  {
  ethport->link_status = 0;
  (*(ethport->link_cbfn))((ethport->bna)->bnad, 0);
  return;
}
}
static void bna_err_handler(struct bna *bna , u32 intr_status ) 
{ 
  u32 init_halt ;

  {
  if ((bna->bits.halt_status_bits & intr_status) != 0U) {
    init_halt = readl((void const volatile   *)bna->ioceth.ioc.ioc_regs.ll_halt);
    init_halt = init_halt & 4294967294U;
    writel(init_halt, (void volatile   *)bna->ioceth.ioc.ioc_regs.ll_halt);
    init_halt = readl((void const volatile   *)bna->ioceth.ioc.ioc_regs.ll_halt);
  } else {

  }
  bfa_nw_ioc_error_isr(& bna->ioceth.ioc);
  return;
}
}
void bna_mbox_handler(struct bna *bna , u32 intr_status ) 
{ 


  {
  if ((bna->bits.error_status_bits & intr_status) != 0U) {
    bna_err_handler(bna, intr_status);
    return;
  } else {

  }
  if ((bna->bits.mbox_status_bits & intr_status) != 0U) {
    bfa_nw_ioc_mbox_isr(& bna->ioceth.ioc);
  } else {

  }
  return;
}
}
static void bna_msgq_rsp_handler(void *arg , struct bfi_msgq_mhdr *msghdr ) 
{ 
  struct bna *bna ;
  struct bna_tx *tx ;
  struct bna_rx *rx ;
  struct bna_rx_mod *__rx_mod ;
  struct bna_rx *__rx ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct bna_rx_mod *__rx_mod___0 ;
  struct bna_rx *__rx___0 ;
  struct list_head  const  *__mptr___1 ;
  struct list_head  const  *__mptr___2 ;
  struct bna_rx_mod *__rx_mod___1 ;
  struct bna_rx *__rx___1 ;
  struct list_head  const  *__mptr___3 ;
  struct list_head  const  *__mptr___4 ;
  struct bna_rx_mod *__rx_mod___2 ;
  struct bna_rx *__rx___2 ;
  struct list_head  const  *__mptr___5 ;
  struct list_head  const  *__mptr___6 ;
  struct bna_rx_mod *__rx_mod___3 ;
  struct bna_rx *__rx___3 ;
  struct list_head  const  *__mptr___7 ;
  struct list_head  const  *__mptr___8 ;
  struct bna_tx_mod *__tx_mod ;
  struct bna_tx *__tx ;
  struct list_head  const  *__mptr___9 ;
  struct list_head  const  *__mptr___10 ;
  struct bna_tx_mod *__tx_mod___0 ;
  struct bna_tx *__tx___0 ;
  struct list_head  const  *__mptr___11 ;
  struct list_head  const  *__mptr___12 ;

  {
  bna = (struct bna *)arg;
  switch ((int )msghdr->msg_id) {
  case 129: 
  __rx_mod = & bna->rx_mod;
  rx = (struct bna_rx *)0;
  __mptr = (struct list_head  const  *)__rx_mod->rx_active_q.next;
  __rx = (struct bna_rx *)__mptr;
  goto ldv_49250;
  ldv_49249: ;
  if (__rx->rid == (int )msghdr->enet_id) {
    rx = __rx;
    goto ldv_49248;
  } else {

  }
  __mptr___0 = (struct list_head  const  *)__rx->qe.next;
  __rx = (struct bna_rx *)__mptr___0;
  ldv_49250: ;
  if ((unsigned long )(& __rx->qe) != (unsigned long )(& __rx_mod->rx_active_q)) {
    goto ldv_49249;
  } else {

  }
  ldv_49248: ;
  if ((unsigned long )rx != (unsigned long )((struct bna_rx *)0)) {
    bna_bfi_rx_enet_start_rsp(rx, msghdr);
  } else {

  }
  goto ldv_49251;
  case 130: 
  __rx_mod___0 = & bna->rx_mod;
  rx = (struct bna_rx *)0;
  __mptr___1 = (struct list_head  const  *)__rx_mod___0->rx_active_q.next;
  __rx___0 = (struct bna_rx *)__mptr___1;
  goto ldv_49261;
  ldv_49260: ;
  if (__rx___0->rid == (int )msghdr->enet_id) {
    rx = __rx___0;
    goto ldv_49259;
  } else {

  }
  __mptr___2 = (struct list_head  const  *)__rx___0->qe.next;
  __rx___0 = (struct bna_rx *)__mptr___2;
  ldv_49261: ;
  if ((unsigned long )(& __rx___0->qe) != (unsigned long )(& __rx_mod___0->rx_active_q)) {
    goto ldv_49260;
  } else {

  }
  ldv_49259: ;
  if ((unsigned long )rx != (unsigned long )((struct bna_rx *)0)) {
    bna_bfi_rx_enet_stop_rsp(rx, msghdr);
  } else {

  }
  goto ldv_49251;
  case 131: ;
  case 132: ;
  case 133: ;
  case 134: ;
  case 135: ;
  case 137: ;
  case 138: ;
  case 139: ;
  case 141: ;
  case 142: ;
  case 143: ;
  case 144: 
  __rx_mod___1 = & bna->rx_mod;
  rx = (struct bna_rx *)0;
  __mptr___3 = (struct list_head  const  *)__rx_mod___1->rx_active_q.next;
  __rx___1 = (struct bna_rx *)__mptr___3;
  goto ldv_49282;
  ldv_49281: ;
  if (__rx___1->rid == (int )msghdr->enet_id) {
    rx = __rx___1;
    goto ldv_49280;
  } else {

  }
  __mptr___4 = (struct list_head  const  *)__rx___1->qe.next;
  __rx___1 = (struct bna_rx *)__mptr___4;
  ldv_49282: ;
  if ((unsigned long )(& __rx___1->qe) != (unsigned long )(& __rx_mod___1->rx_active_q)) {
    goto ldv_49281;
  } else {

  }
  ldv_49280: ;
  if ((unsigned long )rx != (unsigned long )((struct bna_rx *)0)) {
    bna_bfi_rxf_cfg_rsp(& rx->rxf, msghdr);
  } else {

  }
  goto ldv_49251;
  case 136: 
  __rx_mod___2 = & bna->rx_mod;
  rx = (struct bna_rx *)0;
  __mptr___5 = (struct list_head  const  *)__rx_mod___2->rx_active_q.next;
  __rx___2 = (struct bna_rx *)__mptr___5;
  goto ldv_49292;
  ldv_49291: ;
  if (__rx___2->rid == (int )msghdr->enet_id) {
    rx = __rx___2;
    goto ldv_49290;
  } else {

  }
  __mptr___6 = (struct list_head  const  *)__rx___2->qe.next;
  __rx___2 = (struct bna_rx *)__mptr___6;
  ldv_49292: ;
  if ((unsigned long )(& __rx___2->qe) != (unsigned long )(& __rx_mod___2->rx_active_q)) {
    goto ldv_49291;
  } else {

  }
  ldv_49290: ;
  if ((unsigned long )rx != (unsigned long )((struct bna_rx *)0)) {
    bna_bfi_rxf_ucast_set_rsp(& rx->rxf, msghdr);
  } else {

  }
  goto ldv_49251;
  case 140: 
  __rx_mod___3 = & bna->rx_mod;
  rx = (struct bna_rx *)0;
  __mptr___7 = (struct list_head  const  *)__rx_mod___3->rx_active_q.next;
  __rx___3 = (struct bna_rx *)__mptr___7;
  goto ldv_49302;
  ldv_49301: ;
  if (__rx___3->rid == (int )msghdr->enet_id) {
    rx = __rx___3;
    goto ldv_49300;
  } else {

  }
  __mptr___8 = (struct list_head  const  *)__rx___3->qe.next;
  __rx___3 = (struct bna_rx *)__mptr___8;
  ldv_49302: ;
  if ((unsigned long )(& __rx___3->qe) != (unsigned long )(& __rx_mod___3->rx_active_q)) {
    goto ldv_49301;
  } else {

  }
  ldv_49300: ;
  if ((unsigned long )rx != (unsigned long )((struct bna_rx *)0)) {
    bna_bfi_rxf_mcast_add_rsp(& rx->rxf, msghdr);
  } else {

  }
  goto ldv_49251;
  case 145: 
  __tx_mod = & bna->tx_mod;
  tx = (struct bna_tx *)0;
  __mptr___9 = (struct list_head  const  *)__tx_mod->tx_active_q.next;
  __tx = (struct bna_tx *)__mptr___9;
  goto ldv_49312;
  ldv_49311: ;
  if (__tx->rid == (int )msghdr->enet_id) {
    tx = __tx;
    goto ldv_49310;
  } else {

  }
  __mptr___10 = (struct list_head  const  *)__tx->qe.next;
  __tx = (struct bna_tx *)__mptr___10;
  ldv_49312: ;
  if ((unsigned long )(& __tx->qe) != (unsigned long )(& __tx_mod->tx_active_q)) {
    goto ldv_49311;
  } else {

  }
  ldv_49310: ;
  if ((unsigned long )tx != (unsigned long )((struct bna_tx *)0)) {
    bna_bfi_tx_enet_start_rsp(tx, msghdr);
  } else {

  }
  goto ldv_49251;
  case 146: 
  __tx_mod___0 = & bna->tx_mod;
  tx = (struct bna_tx *)0;
  __mptr___11 = (struct list_head  const  *)__tx_mod___0->tx_active_q.next;
  __tx___0 = (struct bna_tx *)__mptr___11;
  goto ldv_49322;
  ldv_49321: ;
  if (__tx___0->rid == (int )msghdr->enet_id) {
    tx = __tx___0;
    goto ldv_49320;
  } else {

  }
  __mptr___12 = (struct list_head  const  *)__tx___0->qe.next;
  __tx___0 = (struct bna_tx *)__mptr___12;
  ldv_49322: ;
  if ((unsigned long )(& __tx___0->qe) != (unsigned long )(& __tx_mod___0->tx_active_q)) {
    goto ldv_49321;
  } else {

  }
  ldv_49320: ;
  if ((unsigned long )tx != (unsigned long )((struct bna_tx *)0)) {
    bna_bfi_tx_enet_stop_rsp(tx, msghdr);
  } else {

  }
  goto ldv_49251;
  case 147: 
  bna_bfi_ethport_admin_rsp(& bna->ethport, msghdr);
  goto ldv_49251;
  case 149: 
  bna_bfi_ethport_lpbk_rsp(& bna->ethport, msghdr);
  goto ldv_49251;
  case 148: 
  bna_bfi_pause_set_rsp(& bna->enet, msghdr);
  goto ldv_49251;
  case 150: 
  bna_bfi_attr_get_rsp(& bna->ioceth, msghdr);
  goto ldv_49251;
  case 151: 
  bna_bfi_stats_get_rsp(bna, msghdr);
  goto ldv_49251;
  case 152: ;
  goto ldv_49251;
  case 156: 
  bna_bfi_ethport_linkup_aen(& bna->ethport, msghdr);
  goto ldv_49251;
  case 155: 
  bna_bfi_ethport_linkdown_aen(& bna->ethport, msghdr);
  goto ldv_49251;
  case 157: 
  bna_bfi_ethport_enable_aen(& bna->ethport, msghdr);
  goto ldv_49251;
  case 158: 
  bna_bfi_ethport_disable_aen(& bna->ethport, msghdr);
  goto ldv_49251;
  case 159: 
  bna_bfi_bw_update_aen(& bna->tx_mod);
  goto ldv_49251;
  default: ;
  goto ldv_49251;
  }
  ldv_49251: ;
  return;
}
}
static void bna_bfi_ethport_admin_up(struct bna_ethport *ethport ) 
{ 
  struct bfi_enet_enable_req *admin_up_req ;

  {
  admin_up_req = & ethport->bfi_enet_cmd.admin_req;
  admin_up_req->mh.msg_class = 24U;
  admin_up_req->mh.msg_id = 19U;
  admin_up_req->mh.msg_token = 0U;
  admin_up_req->mh.enet_id = 0U;
  admin_up_req->mh.num_entries = 256U;
  admin_up_req->enable = 1U;
  ethport->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  ethport->msgq_cmd.cbarg = (void *)0;
  ethport->msgq_cmd.msg_size = 12UL;
  ethport->msgq_cmd.msg_hdr = & admin_up_req->mh;
  bfa_msgq_cmd_post(& (ethport->bna)->msgq, & ethport->msgq_cmd);
  return;
}
}
static void bna_bfi_ethport_admin_down(struct bna_ethport *ethport ) 
{ 
  struct bfi_enet_enable_req *admin_down_req ;

  {
  admin_down_req = & ethport->bfi_enet_cmd.admin_req;
  admin_down_req->mh.msg_class = 24U;
  admin_down_req->mh.msg_id = 19U;
  admin_down_req->mh.msg_token = 0U;
  admin_down_req->mh.enet_id = 0U;
  admin_down_req->mh.num_entries = 256U;
  admin_down_req->enable = 0U;
  ethport->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  ethport->msgq_cmd.cbarg = (void *)0;
  ethport->msgq_cmd.msg_size = 12UL;
  ethport->msgq_cmd.msg_hdr = & admin_down_req->mh;
  bfa_msgq_cmd_post(& (ethport->bna)->msgq, & ethport->msgq_cmd);
  return;
}
}
static void bna_bfi_ethport_lpbk_up(struct bna_ethport *ethport ) 
{ 
  struct bfi_enet_diag_lb_req *lpbk_up_req ;

  {
  lpbk_up_req = & ethport->bfi_enet_cmd.lpbk_req;
  lpbk_up_req->mh.msg_class = 24U;
  lpbk_up_req->mh.msg_id = 21U;
  lpbk_up_req->mh.msg_token = 0U;
  lpbk_up_req->mh.enet_id = 0U;
  lpbk_up_req->mh.num_entries = 256U;
  lpbk_up_req->mode = (unsigned int )(ethport->bna)->enet.type != 1U;
  lpbk_up_req->enable = 1U;
  ethport->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  ethport->msgq_cmd.cbarg = (void *)0;
  ethport->msgq_cmd.msg_size = 12UL;
  ethport->msgq_cmd.msg_hdr = & lpbk_up_req->mh;
  bfa_msgq_cmd_post(& (ethport->bna)->msgq, & ethport->msgq_cmd);
  return;
}
}
static void bna_bfi_ethport_lpbk_down(struct bna_ethport *ethport ) 
{ 
  struct bfi_enet_diag_lb_req *lpbk_down_req ;

  {
  lpbk_down_req = & ethport->bfi_enet_cmd.lpbk_req;
  lpbk_down_req->mh.msg_class = 24U;
  lpbk_down_req->mh.msg_id = 21U;
  lpbk_down_req->mh.msg_token = 0U;
  lpbk_down_req->mh.enet_id = 0U;
  lpbk_down_req->mh.num_entries = 256U;
  lpbk_down_req->enable = 0U;
  ethport->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  ethport->msgq_cmd.cbarg = (void *)0;
  ethport->msgq_cmd.msg_size = 12UL;
  ethport->msgq_cmd.msg_hdr = & lpbk_down_req->mh;
  bfa_msgq_cmd_post(& (ethport->bna)->msgq, & ethport->msgq_cmd);
  return;
}
}
static void bna_bfi_ethport_up(struct bna_ethport *ethport ) 
{ 


  {
  if ((unsigned int )(ethport->bna)->enet.type == 0U) {
    bna_bfi_ethport_admin_up(ethport);
  } else {
    bna_bfi_ethport_lpbk_up(ethport);
  }
  return;
}
}
static void bna_bfi_ethport_down(struct bna_ethport *ethport ) 
{ 


  {
  if ((unsigned int )(ethport->bna)->enet.type == 0U) {
    bna_bfi_ethport_admin_down(ethport);
  } else {
    bna_bfi_ethport_lpbk_down(ethport);
  }
  return;
}
}
static void bna_ethport_sm_stopped(struct bna_ethport *ethport , enum bna_ethport_event event ) ;
static void bna_ethport_sm_stopped_entry(struct bna_ethport *ethport ) ;
static void bna_ethport_sm_down(struct bna_ethport *ethport , enum bna_ethport_event event ) ;
static void bna_ethport_sm_down_entry(struct bna_ethport *ethport ) ;
static void bna_ethport_sm_up_resp_wait(struct bna_ethport *ethport , enum bna_ethport_event event ) ;
static void bna_ethport_sm_up_resp_wait_entry(struct bna_ethport *ethport ) ;
static void bna_ethport_sm_down_resp_wait(struct bna_ethport *ethport , enum bna_ethport_event event ) ;
static void bna_ethport_sm_down_resp_wait_entry(struct bna_ethport *ethport ) ;
static void bna_ethport_sm_up(struct bna_ethport *ethport , enum bna_ethport_event event ) ;
static void bna_ethport_sm_up_entry(struct bna_ethport *ethport ) ;
static void bna_ethport_sm_last_resp_wait(struct bna_ethport *ethport , enum bna_ethport_event event ) ;
static void bna_ethport_sm_last_resp_wait_entry(struct bna_ethport *ethport ) ;
static void bna_ethport_sm_stopped_entry(struct bna_ethport *ethport ) 
{ 
  void (*cbfn)(struct bna_enet * ) ;

  {
  if ((unsigned long )ethport->stop_cbfn != (unsigned long )((void (*)(struct bna_enet * ))0)) {
    cbfn = ethport->stop_cbfn;
    ethport->stop_cbfn = (void (*)(struct bna_enet * ))0;
    (*cbfn)(& (ethport->bna)->enet);
  } else {

  }
  return;
}
}
static void bna_ethport_sm_stopped(struct bna_ethport *ethport , enum bna_ethport_event event ) 
{ 
  void (*cbfn)(struct bna_enet * ) ;

  {
  switch ((unsigned int )event) {
  case 1U: 
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_down);
  bna_ethport_sm_down_entry(ethport);
  goto ldv_49397;
  case 2U: ;
  if ((unsigned long )ethport->stop_cbfn != (unsigned long )((void (*)(struct bna_enet * ))0)) {
    cbfn = ethport->stop_cbfn;
    ethport->stop_cbfn = (void (*)(struct bna_enet * ))0;
    (*cbfn)(& (ethport->bna)->enet);
  } else {

  }
  goto ldv_49397;
  case 3U: ;
  goto ldv_49397;
  case 5U: ;
  goto ldv_49397;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         544, (unsigned int )event);
  }
  ldv_49397: ;
  return;
}
}
static void bna_ethport_sm_down_entry(struct bna_ethport *ethport ) 
{ 


  {
  return;
}
}
static void bna_ethport_sm_down(struct bna_ethport *ethport , enum bna_ethport_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  goto ldv_49412;
  case 3U: 
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  goto ldv_49412;
  case 4U: 
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_up_resp_wait);
  bna_ethport_sm_up_resp_wait_entry(ethport);
  bna_bfi_ethport_up(ethport);
  goto ldv_49412;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         572, (unsigned int )event);
  }
  ldv_49412: ;
  return;
}
}
static void bna_ethport_sm_up_resp_wait_entry(struct bna_ethport *ethport ) 
{ 


  {
  return;
}
}
static void bna_ethport_sm_up_resp_wait(struct bna_ethport *ethport , enum bna_ethport_event event ) 
{ 
  void (*cbfn)(struct bnad * , enum bna_cb_status  ) ;
  void (*cbfn___0)(struct bnad * , enum bna_cb_status  ) ;
  void (*cbfn___1)(struct bnad * , enum bna_cb_status  ) ;
  void (*cbfn___2)(struct bnad * , enum bna_cb_status  ) ;

  {
  switch ((unsigned int )event) {
  case 2U: 
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_last_resp_wait);
  bna_ethport_sm_last_resp_wait_entry(ethport);
  goto ldv_49424;
  case 3U: ;
  if ((unsigned long )ethport->adminup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                          enum bna_cb_status  ))0)) {
    cbfn = ethport->adminup_cbfn;
    ethport->adminup_cbfn = (void (*)(struct bnad * , enum bna_cb_status  ))0;
    (*cbfn)((ethport->bna)->bnad, 1);
  } else {

  }
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  goto ldv_49424;
  case 5U: ;
  if ((unsigned long )ethport->adminup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                          enum bna_cb_status  ))0)) {
    cbfn___0 = ethport->adminup_cbfn;
    ethport->adminup_cbfn = (void (*)(struct bnad * , enum bna_cb_status  ))0;
    (*cbfn___0)((ethport->bna)->bnad, 2);
  } else {

  }
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_down_resp_wait);
  bna_ethport_sm_down_resp_wait_entry(ethport);
  goto ldv_49424;
  case 6U: ;
  if ((unsigned long )ethport->adminup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                          enum bna_cb_status  ))0)) {
    cbfn___1 = ethport->adminup_cbfn;
    ethport->adminup_cbfn = (void (*)(struct bnad * , enum bna_cb_status  ))0;
    (*cbfn___1)((ethport->bna)->bnad, 0);
  } else {

  }
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_up);
  bna_ethport_sm_up_entry(ethport);
  goto ldv_49424;
  case 8U: ;
  if ((unsigned long )ethport->adminup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                          enum bna_cb_status  ))0)) {
    cbfn___2 = ethport->adminup_cbfn;
    ethport->adminup_cbfn = (void (*)(struct bnad * , enum bna_cb_status  ))0;
    (*cbfn___2)((ethport->bna)->bnad, 1);
  } else {

  }
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_down);
  bna_ethport_sm_down_entry(ethport);
  goto ldv_49424;
  case 7U: 
  bna_bfi_ethport_up(ethport);
  goto ldv_49424;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         616, (unsigned int )event);
  }
  ldv_49424: ;
  return;
}
}
static void bna_ethport_sm_down_resp_wait_entry(struct bna_ethport *ethport ) 
{ 


  {
  return;
}
}
static void bna_ethport_sm_down_resp_wait(struct bna_ethport *ethport , enum bna_ethport_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_last_resp_wait);
  bna_ethport_sm_last_resp_wait_entry(ethport);
  goto ldv_49451;
  case 3U: 
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  goto ldv_49451;
  case 4U: 
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_up_resp_wait);
  bna_ethport_sm_up_resp_wait_entry(ethport);
  goto ldv_49451;
  case 6U: 
  bna_bfi_ethport_down(ethport);
  goto ldv_49451;
  case 8U: ;
  case 7U: 
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_down);
  bna_ethport_sm_down_entry(ethport);
  goto ldv_49451;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         658, (unsigned int )event);
  }
  ldv_49451: ;
  return;
}
}
static void bna_ethport_sm_up_entry(struct bna_ethport *ethport ) 
{ 


  {
  return;
}
}
static void bna_ethport_sm_up(struct bna_ethport *ethport , enum bna_ethport_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_last_resp_wait);
  bna_ethport_sm_last_resp_wait_entry(ethport);
  bna_bfi_ethport_down(ethport);
  goto ldv_49466;
  case 3U: 
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  goto ldv_49466;
  case 5U: 
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_down_resp_wait);
  bna_ethport_sm_down_resp_wait_entry(ethport);
  bna_bfi_ethport_down(ethport);
  goto ldv_49466;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         687, (unsigned int )event);
  }
  ldv_49466: ;
  return;
}
}
static void bna_ethport_sm_last_resp_wait_entry(struct bna_ethport *ethport ) 
{ 


  {
  return;
}
}
static void bna_ethport_sm_last_resp_wait(struct bna_ethport *ethport , enum bna_ethport_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 3U: 
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  goto ldv_49478;
  case 5U: ;
  goto ldv_49478;
  case 6U: 
  bna_bfi_ethport_down(ethport);
  goto ldv_49478;
  case 8U: ;
  case 7U: 
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  goto ldv_49478;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         724, (unsigned int )event);
  }
  ldv_49478: ;
  return;
}
}
static void bna_ethport_init(struct bna_ethport *ethport , struct bna *bna ) 
{ 


  {
  ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags | 3U);
  ethport->bna = bna;
  ethport->link_status = 0;
  ethport->link_cbfn = & bnad_cb_ethport_link_status;
  ethport->rx_started_count = 0;
  ethport->stop_cbfn = (void (*)(struct bna_enet * ))0;
  ethport->adminup_cbfn = (void (*)(struct bnad * , enum bna_cb_status  ))0;
  ethport->fsm = (void (*)(void * , int  ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  return;
}
}
static void bna_ethport_uninit(struct bna_ethport *ethport ) 
{ 


  {
  ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags & 4294967294U);
  ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags & 4294967293U);
  ethport->bna = (struct bna *)0;
  return;
}
}
static void bna_ethport_start(struct bna_ethport *ethport ) 
{ 


  {
  (*(ethport->fsm))((void *)ethport, 1);
  return;
}
}
static void bna_enet_cb_ethport_stopped(struct bna_enet *enet ) 
{ 


  {
  bfa_wc_down(& enet->chld_stop_wc);
  return;
}
}
static void bna_ethport_stop(struct bna_ethport *ethport ) 
{ 


  {
  ethport->stop_cbfn = & bna_enet_cb_ethport_stopped;
  (*(ethport->fsm))((void *)ethport, 2);
  return;
}
}
static void bna_ethport_fail(struct bna_ethport *ethport ) 
{ 


  {
  ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags | 2U);
  if ((unsigned int )ethport->link_status != 0U) {
    ethport->link_status = 0;
    (*(ethport->link_cbfn))((ethport->bna)->bnad, 0);
  } else {

  }
  (*(ethport->fsm))((void *)ethport, 3);
  return;
}
}
void bna_ethport_cb_rx_started(struct bna_ethport *ethport ) 
{ 
  int tmp ;

  {
  ethport->rx_started_count = ethport->rx_started_count + 1;
  if (ethport->rx_started_count == 1) {
    ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags | 4U);
    tmp = ethport_can_be_up(ethport);
    if (tmp != 0) {
      (*(ethport->fsm))((void *)ethport, 4);
    } else {

    }
  } else {

  }
  return;
}
}
void bna_ethport_cb_rx_stopped(struct bna_ethport *ethport ) 
{ 
  int ethport_up ;
  int tmp ;

  {
  tmp = ethport_can_be_up(ethport);
  ethport_up = tmp;
  ethport->rx_started_count = ethport->rx_started_count - 1;
  if (ethport->rx_started_count == 0) {
    ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags & 4294967291U);
    if (ethport_up != 0) {
      (*(ethport->fsm))((void *)ethport, 5);
    } else {

    }
  } else {

  }
  return;
}
}
static void bna_enet_cb_chld_stopped(void *arg ) ;
static void bna_bfi_pause_set(struct bna_enet *enet ) ;
static void bna_enet_sm_stopped(struct bna_enet *enet , enum bna_enet_event event ) ;
static void bna_enet_sm_stopped_entry(struct bna_enet *enet ) ;
static void bna_enet_sm_pause_init_wait(struct bna_enet *enet , enum bna_enet_event event ) ;
static void bna_enet_sm_pause_init_wait_entry(struct bna_enet *enet ) ;
static void bna_enet_sm_last_resp_wait(struct bna_enet *enet , enum bna_enet_event event ) ;
static void bna_enet_sm_last_resp_wait_entry(struct bna_enet *enet ) ;
static void bna_enet_sm_started(struct bna_enet *enet , enum bna_enet_event event ) ;
static void bna_enet_sm_started_entry(struct bna_enet *enet ) ;
static void bna_enet_sm_cfg_wait(struct bna_enet *enet , enum bna_enet_event event ) ;
static void bna_enet_sm_cfg_wait_entry(struct bna_enet *enet ) ;
static void bna_enet_sm_cfg_stop_wait(struct bna_enet *enet , enum bna_enet_event event ) ;
static void bna_enet_sm_cfg_stop_wait_entry(struct bna_enet *enet ) ;
static void bna_enet_sm_chld_stop_wait(struct bna_enet *enet , enum bna_enet_event event ) ;
static void bna_enet_sm_chld_stop_wait_entry(struct bna_enet *enet ) ;
static void bna_enet_sm_stopped_entry(struct bna_enet *enet ) 
{ 
  void (*cbfn)(struct bnad * ) ;
  void (*cbfn___0)(void * ) ;
  void *cbarg ;

  {
  if ((unsigned long )enet->mtu_cbfn != (unsigned long )((void (*)(struct bnad * ))0)) {
    cbfn = enet->mtu_cbfn;
    enet->mtu_cbfn = (void (*)(struct bnad * ))0;
    (*cbfn)((enet->bna)->bnad);
  } else {

  }
  if ((unsigned long )enet->stop_cbfn != (unsigned long )((void (*)(void * ))0)) {
    cbfn___0 = enet->stop_cbfn;
    cbarg = enet->stop_cbarg;
    enet->stop_cbfn = (void (*)(void * ))0;
    enet->stop_cbarg = (void *)0;
    (*cbfn___0)(cbarg);
  } else {

  }
  return;
}
}
static void bna_enet_sm_stopped(struct bna_enet *enet , enum bna_enet_event event ) 
{ 
  void (*cbfn)(void * ) ;
  void *cbarg ;
  void (*cbfn___0)(struct bnad * ) ;

  {
  switch ((unsigned int )event) {
  case 1U: 
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_pause_init_wait);
  bna_enet_sm_pause_init_wait_entry(enet);
  goto ldv_49562;
  case 2U: ;
  if ((unsigned long )enet->stop_cbfn != (unsigned long )((void (*)(void * ))0)) {
    cbfn = enet->stop_cbfn;
    cbarg = enet->stop_cbarg;
    enet->stop_cbfn = (void (*)(void * ))0;
    enet->stop_cbarg = (void *)0;
    (*cbfn)(cbarg);
  } else {

  }
  goto ldv_49562;
  case 3U: ;
  goto ldv_49562;
  case 4U: ;
  goto ldv_49562;
  case 5U: ;
  if ((unsigned long )enet->mtu_cbfn != (unsigned long )((void (*)(struct bnad * ))0)) {
    cbfn___0 = enet->mtu_cbfn;
    enet->mtu_cbfn = (void (*)(struct bnad * ))0;
    (*cbfn___0)((enet->bna)->bnad);
  } else {

  }
  goto ldv_49562;
  case 7U: ;
  goto ldv_49562;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         954, (unsigned int )event);
  }
  ldv_49562: ;
  return;
}
}
static void bna_enet_sm_pause_init_wait_entry(struct bna_enet *enet ) 
{ 


  {
  bna_bfi_pause_set(enet);
  return;
}
}
static void bna_enet_sm_pause_init_wait(struct bna_enet *enet , enum bna_enet_event event ) 
{ 
  enum bna_tx_type tx_type ;
  enum bna_rx_type rx_type ;

  {
  switch ((unsigned int )event) {
  case 2U: 
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_last_resp_wait);
  bna_enet_sm_last_resp_wait_entry(enet);
  goto ldv_49582;
  case 3U: 
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  goto ldv_49582;
  case 4U: 
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags | 4U);
  goto ldv_49582;
  case 5U: ;
  goto ldv_49582;
  case 6U: ;
  if (((unsigned int )enet->flags & 4U) != 0U) {
    enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
    bna_bfi_pause_set(enet);
  } else {
    enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_started);
    bna_enet_sm_started_entry(enet);
    tx_type = (unsigned int )enet->type != 0U;
    rx_type = (unsigned int )enet->type != 0U;
    bna_ethport_start(& (enet->bna)->ethport);
    bna_tx_mod_start(& (enet->bna)->tx_mod, tx_type);
    bna_rx_mod_start(& (enet->bna)->rx_mod, rx_type);
  }
  goto ldv_49582;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         998, (unsigned int )event);
  }
  ldv_49582: ;
  return;
}
}
static void bna_enet_sm_last_resp_wait_entry(struct bna_enet *enet ) 
{ 


  {
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
  return;
}
}
static void bna_enet_sm_last_resp_wait(struct bna_enet *enet , enum bna_enet_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 6U: 
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  goto ldv_49599;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1019, (unsigned int )event);
  }
  ldv_49599: ;
  return;
}
}
static void bna_enet_sm_started_entry(struct bna_enet *enet ) 
{ 
  void (*cbfn)(struct bnad * ) ;

  {
  if ((unsigned long )enet->mtu_cbfn != (unsigned long )((void (*)(struct bnad * ))0)) {
    cbfn = enet->mtu_cbfn;
    enet->mtu_cbfn = (void (*)(struct bnad * ))0;
    (*cbfn)((enet->bna)->bnad);
  } else {

  }
  return;
}
}
static void bna_enet_sm_started(struct bna_enet *enet , enum bna_enet_event event ) 
{ 
  enum bna_rx_type rx_type ;

  {
  switch ((unsigned int )event) {
  case 2U: 
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_chld_stop_wait);
  bna_enet_sm_chld_stop_wait_entry(enet);
  goto ldv_49611;
  case 3U: 
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  bna_ethport_fail(& (enet->bna)->ethport);
  bna_tx_mod_fail(& (enet->bna)->tx_mod);
  bna_rx_mod_fail(& (enet->bna)->rx_mod);
  goto ldv_49611;
  case 4U: 
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_cfg_wait);
  bna_enet_sm_cfg_wait_entry(enet);
  bna_bfi_pause_set(enet);
  goto ldv_49611;
  case 5U: 
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_cfg_wait);
  bna_enet_sm_cfg_wait_entry(enet);
  rx_type = (unsigned int )enet->type != 0U;
  bfa_wc_init(& enet->chld_stop_wc, & bna_enet_cb_chld_stopped, (void *)enet);
  bfa_wc_up(& enet->chld_stop_wc);
  bna_rx_mod_stop(& (enet->bna)->rx_mod, rx_type);
  bfa_wc_wait(& enet->chld_stop_wc);
  goto ldv_49611;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1058, (unsigned int )event);
  }
  ldv_49611: ;
  return;
}
}
static void bna_enet_sm_cfg_wait_entry(struct bna_enet *enet ) 
{ 


  {
  return;
}
}
static void bna_enet_sm_cfg_wait(struct bna_enet *enet , enum bna_enet_event event ) 
{ 
  enum bna_rx_type rx_type ;
  enum bna_rx_type rx_type___0 ;

  {
  switch ((unsigned int )event) {
  case 2U: 
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967287U);
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_cfg_stop_wait);
  bna_enet_sm_cfg_stop_wait_entry(enet);
  goto ldv_49625;
  case 3U: 
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967287U);
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  bna_ethport_fail(& (enet->bna)->ethport);
  bna_tx_mod_fail(& (enet->bna)->tx_mod);
  bna_rx_mod_fail(& (enet->bna)->rx_mod);
  goto ldv_49625;
  case 4U: 
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags | 4U);
  goto ldv_49625;
  case 5U: 
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags | 8U);
  goto ldv_49625;
  case 7U: 
  rx_type = (unsigned int )enet->type != 0U;
  bna_rx_mod_start(& (enet->bna)->rx_mod, rx_type);
  case 6U: ;
  if (((unsigned int )enet->flags & 4U) != 0U) {
    enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
    bna_bfi_pause_set(enet);
  } else
  if (((unsigned int )enet->flags & 8U) != 0U) {
    enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967287U);
    rx_type___0 = (unsigned int )enet->type != 0U;
    bfa_wc_init(& enet->chld_stop_wc, & bna_enet_cb_chld_stopped, (void *)enet);
    bfa_wc_up(& enet->chld_stop_wc);
    bna_rx_mod_stop(& (enet->bna)->rx_mod, rx_type___0);
    bfa_wc_wait(& enet->chld_stop_wc);
  } else {
    enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_started);
    bna_enet_sm_started_entry(enet);
  }
  goto ldv_49625;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1109, (unsigned int )event);
  }
  ldv_49625: ;
  return;
}
}
static void bna_enet_sm_cfg_stop_wait_entry(struct bna_enet *enet ) 
{ 


  {
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967287U);
  return;
}
}
static void bna_enet_sm_cfg_stop_wait(struct bna_enet *enet , enum bna_enet_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 3U: 
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  bna_ethport_fail(& (enet->bna)->ethport);
  bna_tx_mod_fail(& (enet->bna)->tx_mod);
  bna_rx_mod_fail(& (enet->bna)->rx_mod);
  goto ldv_49642;
  case 6U: ;
  case 7U: 
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_chld_stop_wait);
  bna_enet_sm_chld_stop_wait_entry(enet);
  goto ldv_49642;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1136, (unsigned int )event);
  }
  ldv_49642: ;
  return;
}
}
static void bna_enet_sm_chld_stop_wait_entry(struct bna_enet *enet ) 
{ 
  enum bna_tx_type tx_type ;
  enum bna_rx_type rx_type ;

  {
  tx_type = (unsigned int )enet->type != 0U;
  rx_type = (unsigned int )enet->type != 0U;
  bfa_wc_init(& enet->chld_stop_wc, & bna_enet_cb_chld_stopped, (void *)enet);
  bfa_wc_up(& enet->chld_stop_wc);
  bna_ethport_stop(& (enet->bna)->ethport);
  bfa_wc_up(& enet->chld_stop_wc);
  bna_tx_mod_stop(& (enet->bna)->tx_mod, tx_type);
  bfa_wc_up(& enet->chld_stop_wc);
  bna_rx_mod_stop(& (enet->bna)->rx_mod, rx_type);
  bfa_wc_wait(& enet->chld_stop_wc);
  return;
}
}
static void bna_enet_sm_chld_stop_wait(struct bna_enet *enet , enum bna_enet_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 3U: 
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  bna_ethport_fail(& (enet->bna)->ethport);
  bna_tx_mod_fail(& (enet->bna)->tx_mod);
  bna_rx_mod_fail(& (enet->bna)->rx_mod);
  goto ldv_49656;
  case 7U: 
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  goto ldv_49656;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1161, (unsigned int )event);
  }
  ldv_49656: ;
  return;
}
}
static void bna_bfi_pause_set(struct bna_enet *enet ) 
{ 
  struct bfi_enet_set_pause_req *pause_req ;

  {
  pause_req = & enet->pause_req;
  pause_req->mh.msg_class = 24U;
  pause_req->mh.msg_id = 20U;
  pause_req->mh.msg_token = 0U;
  pause_req->mh.enet_id = 0U;
  pause_req->mh.num_entries = 256U;
  pause_req->tx_pause = (u8 )enet->pause_config.tx_pause;
  pause_req->rx_pause = (u8 )enet->pause_config.rx_pause;
  enet->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  enet->msgq_cmd.cbarg = (void *)0;
  enet->msgq_cmd.msg_size = 12UL;
  enet->msgq_cmd.msg_hdr = & pause_req->mh;
  bfa_msgq_cmd_post(& (enet->bna)->msgq, & enet->msgq_cmd);
  return;
}
}
static void bna_enet_cb_chld_stopped(void *arg ) 
{ 
  struct bna_enet *enet ;

  {
  enet = (struct bna_enet *)arg;
  (*(enet->fsm))((void *)enet, 7);
  return;
}
}
static void bna_enet_init(struct bna_enet *enet , struct bna *bna ) 
{ 


  {
  enet->bna = bna;
  enet->flags = 0;
  enet->mtu = 0;
  enet->type = 0;
  enet->stop_cbfn = (void (*)(void * ))0;
  enet->stop_cbarg = (void *)0;
  enet->mtu_cbfn = (void (*)(struct bnad * ))0;
  enet->fsm = (void (*)(void * , int  ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  return;
}
}
static void bna_enet_uninit(struct bna_enet *enet ) 
{ 


  {
  enet->flags = 0;
  enet->bna = (struct bna *)0;
  return;
}
}
static void bna_enet_start(struct bna_enet *enet ) 
{ 


  {
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags | 1U);
  if (((unsigned int )enet->flags & 2U) != 0U) {
    (*(enet->fsm))((void *)enet, 1);
  } else {

  }
  return;
}
}
static void bna_ioceth_cb_enet_stopped(void *arg ) 
{ 
  struct bna_ioceth *ioceth ;

  {
  ioceth = (struct bna_ioceth *)arg;
  (*(ioceth->fsm))((void *)ioceth, 7);
  return;
}
}
static void bna_enet_stop(struct bna_enet *enet ) 
{ 


  {
  enet->stop_cbfn = & bna_ioceth_cb_enet_stopped;
  enet->stop_cbarg = (void *)(& (enet->bna)->ioceth);
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967294U);
  (*(enet->fsm))((void *)enet, 2);
  return;
}
}
static void bna_enet_fail(struct bna_enet *enet ) 
{ 


  {
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967294U);
  (*(enet->fsm))((void *)enet, 3);
  return;
}
}
void bna_enet_cb_tx_stopped(struct bna_enet *enet ) 
{ 


  {
  bfa_wc_down(& enet->chld_stop_wc);
  return;
}
}
void bna_enet_cb_rx_stopped(struct bna_enet *enet ) 
{ 


  {
  bfa_wc_down(& enet->chld_stop_wc);
  return;
}
}
int bna_enet_mtu_get(struct bna_enet *enet ) 
{ 


  {
  return (enet->mtu);
}
}
void bna_enet_enable(struct bna_enet *enet ) 
{ 


  {
  if ((unsigned long )enet->fsm != (unsigned long )((void (*)(void * , int  ))(& bna_enet_sm_stopped))) {
    return;
  } else {

  }
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags | 2U);
  if ((int )enet->flags & 1) {
    (*(enet->fsm))((void *)enet, 1);
  } else {

  }
  return;
}
}
void bna_enet_disable(struct bna_enet *enet , enum bna_cleanup_type type , void (*cbfn)(void * ) ) 
{ 


  {
  if ((unsigned int )type == 1U) {
    (*cbfn)((void *)(enet->bna)->bnad);
    return;
  } else {

  }
  enet->stop_cbfn = cbfn;
  enet->stop_cbarg = (void *)(enet->bna)->bnad;
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967293U);
  (*(enet->fsm))((void *)enet, 2);
  return;
}
}
void bna_enet_pause_config(struct bna_enet *enet , struct bna_pause_config *pause_config ) 
{ 


  {
  enet->pause_config = *pause_config;
  (*(enet->fsm))((void *)enet, 4);
  return;
}
}
void bna_enet_mtu_set(struct bna_enet *enet , int mtu , void (*cbfn)(struct bnad * ) ) 
{ 


  {
  enet->mtu = mtu;
  enet->mtu_cbfn = cbfn;
  (*(enet->fsm))((void *)enet, 5);
  return;
}
}
void bna_enet_perm_mac_get(struct bna_enet *enet , u8 *mac ) 
{ 


  {
  bfa_nw_ioc_get_mac(& (enet->bna)->ioceth.ioc, mac);
  return;
}
}
static void bna_bfi_attr_get(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_stopped(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_stopped_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_ioc_ready_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_ioc_ready_wait_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_enet_attr_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_enet_attr_wait_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_ready(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_ready_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_last_resp_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_last_resp_wait_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_enet_stop_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_enet_stop_wait_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_ioc_disable_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_ioc_disable_wait_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_failed(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_failed_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_stopped_entry(struct bna_ioceth *ioceth ) 
{ 
  void (*cbfn)(struct bnad * ) ;
  struct bnad *cbarg ;

  {
  if ((unsigned long )ioceth->stop_cbfn != (unsigned long )((void (*)(struct bnad * ))0)) {
    cbfn = ioceth->stop_cbfn;
    cbarg = ioceth->stop_cbarg;
    ioceth->stop_cbfn = (void (*)(struct bnad * ))0;
    ioceth->stop_cbarg = (struct bnad *)0;
    (*cbfn)(cbarg);
  } else {

  }
  return;
}
}
static void bna_ioceth_sm_stopped(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) 
{ 
  u32 intr_status ;
  u32 mask ;
  u32 mask___0 ;

  {
  switch ((unsigned int )event) {
  case 1U: 
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_ioc_ready_wait);
  bna_ioceth_sm_ioc_ready_wait_entry(ioceth);
  bfa_nw_ioc_enable(& ioceth->ioc);
  goto ldv_49772;
  case 2U: 
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_stopped);
  bna_ioceth_sm_stopped_entry(ioceth);
  goto ldv_49772;
  case 3U: 
  intr_status = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_status);
  if (intr_status != 0U) {
    writel(~ (ioceth->bna)->bits.mbox_status_bits & intr_status, (void volatile   *)(ioceth->bna)->regs.fn_int_status);
  } else {

  }
  bnad_cb_mbox_intr_enable((ioceth->bna)->bnad);
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  writel(~ ((ioceth->bna)->bits.mbox_mask_bits | (ioceth->bna)->bits.error_mask_bits) & mask,
         (void volatile   *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  goto ldv_49772;
  case 4U: 
  mask___0 = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  writel(((ioceth->bna)->bits.mbox_mask_bits | mask___0) | (ioceth->bna)->bits.error_mask_bits,
         (void volatile   *)(ioceth->bna)->regs.fn_int_mask);
  mask___0 = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  bnad_cb_mbox_intr_disable((ioceth->bna)->bnad);
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_failed);
  bna_ioceth_sm_failed_entry(ioceth);
  goto ldv_49772;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1419, (unsigned int )event);
  }
  ldv_49772: ;
  return;
}
}
static void bna_ioceth_sm_ioc_ready_wait_entry(struct bna_ioceth *ioceth ) 
{ 


  {
  return;
}
}
static void bna_ioceth_sm_ioc_ready_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) 
{ 
  u32 intr_status ;
  u32 mask ;
  u32 mask___0 ;

  {
  switch ((unsigned int )event) {
  case 2U: 
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_ioc_disable_wait);
  bna_ioceth_sm_ioc_disable_wait_entry(ioceth);
  bfa_nw_ioc_disable(& ioceth->ioc);
  goto ldv_49788;
  case 3U: 
  intr_status = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_status);
  if (intr_status != 0U) {
    writel(~ (ioceth->bna)->bits.mbox_status_bits & intr_status, (void volatile   *)(ioceth->bna)->regs.fn_int_status);
  } else {

  }
  bnad_cb_mbox_intr_enable((ioceth->bna)->bnad);
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  writel(~ ((ioceth->bna)->bits.mbox_mask_bits | (ioceth->bna)->bits.error_mask_bits) & mask,
         (void volatile   *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  goto ldv_49788;
  case 4U: 
  mask___0 = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  writel(((ioceth->bna)->bits.mbox_mask_bits | mask___0) | (ioceth->bna)->bits.error_mask_bits,
         (void volatile   *)(ioceth->bna)->regs.fn_int_mask);
  mask___0 = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  bnad_cb_mbox_intr_disable((ioceth->bna)->bnad);
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_failed);
  bna_ioceth_sm_failed_entry(ioceth);
  goto ldv_49788;
  case 5U: 
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_enet_attr_wait);
  bna_ioceth_sm_enet_attr_wait_entry(ioceth);
  goto ldv_49788;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1456, (unsigned int )event);
  }
  ldv_49788: ;
  return;
}
}
static void bna_ioceth_sm_enet_attr_wait_entry(struct bna_ioceth *ioceth ) 
{ 


  {
  bna_bfi_attr_get(ioceth);
  return;
}
}
static void bna_ioceth_sm_enet_attr_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) 
{ 
  u32 mask ;

  {
  switch ((unsigned int )event) {
  case 2U: 
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_last_resp_wait);
  bna_ioceth_sm_last_resp_wait_entry(ioceth);
  goto ldv_49804;
  case 4U: 
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  writel(((ioceth->bna)->bits.mbox_mask_bits | mask) | (ioceth->bna)->bits.error_mask_bits,
         (void volatile   *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  bnad_cb_mbox_intr_disable((ioceth->bna)->bnad);
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_failed);
  bna_ioceth_sm_failed_entry(ioceth);
  goto ldv_49804;
  case 6U: 
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_ready);
  bna_ioceth_sm_ready_entry(ioceth);
  goto ldv_49804;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1485, (unsigned int )event);
  }
  ldv_49804: ;
  return;
}
}
static void bna_ioceth_sm_ready_entry(struct bna_ioceth *ioceth ) 
{ 


  {
  bna_enet_start(& (ioceth->bna)->enet);
  (ioceth->bna)->stats_mod.ioc_ready = 1;
  bnad_cb_ioceth_ready((ioceth->bna)->bnad);
  return;
}
}
static void bna_ioceth_sm_ready(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) 
{ 
  u32 mask ;

  {
  switch ((unsigned int )event) {
  case 2U: 
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_enet_stop_wait);
  bna_ioceth_sm_enet_stop_wait_entry(ioceth);
  goto ldv_49817;
  case 4U: 
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  writel(((ioceth->bna)->bits.mbox_mask_bits | mask) | (ioceth->bna)->bits.error_mask_bits,
         (void volatile   *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  bnad_cb_mbox_intr_disable((ioceth->bna)->bnad);
  bna_enet_fail(& (ioceth->bna)->enet);
  (ioceth->bna)->stats_mod.ioc_ready = 0;
  (ioceth->bna)->stats_mod.stats_get_busy = 0;
  (ioceth->bna)->stats_mod.stats_clr_busy = 0;
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_failed);
  bna_ioceth_sm_failed_entry(ioceth);
  goto ldv_49817;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1513, (unsigned int )event);
  }
  ldv_49817: ;
  return;
}
}
static void bna_ioceth_sm_last_resp_wait_entry(struct bna_ioceth *ioceth ) 
{ 


  {
  return;
}
}
static void bna_ioceth_sm_last_resp_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) 
{ 
  u32 mask ;

  {
  switch ((unsigned int )event) {
  case 4U: 
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_ioc_disable_wait);
  bna_ioceth_sm_ioc_disable_wait_entry(ioceth);
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  writel(((ioceth->bna)->bits.mbox_mask_bits | mask) | (ioceth->bna)->bits.error_mask_bits,
         (void volatile   *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  bnad_cb_mbox_intr_disable((ioceth->bna)->bnad);
  bfa_nw_ioc_disable(& ioceth->ioc);
  goto ldv_49830;
  case 6U: 
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_ioc_disable_wait);
  bna_ioceth_sm_ioc_disable_wait_entry(ioceth);
  bfa_nw_ioc_disable(& ioceth->ioc);
  goto ldv_49830;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1539, (unsigned int )event);
  }
  ldv_49830: ;
  return;
}
}
static void bna_ioceth_sm_enet_stop_wait_entry(struct bna_ioceth *ioceth ) 
{ 


  {
  (ioceth->bna)->stats_mod.ioc_ready = 0;
  bna_enet_stop(& (ioceth->bna)->enet);
  return;
}
}
static void bna_ioceth_sm_enet_stop_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) 
{ 
  u32 mask ;

  {
  switch ((unsigned int )event) {
  case 4U: 
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_ioc_disable_wait);
  bna_ioceth_sm_ioc_disable_wait_entry(ioceth);
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  writel(((ioceth->bna)->bits.mbox_mask_bits | mask) | (ioceth->bna)->bits.error_mask_bits,
         (void volatile   *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  bnad_cb_mbox_intr_disable((ioceth->bna)->bnad);
  bna_enet_fail(& (ioceth->bna)->enet);
  (ioceth->bna)->stats_mod.ioc_ready = 0;
  (ioceth->bna)->stats_mod.stats_get_busy = 0;
  (ioceth->bna)->stats_mod.stats_clr_busy = 0;
  bfa_nw_ioc_disable(& ioceth->ioc);
  goto ldv_49842;
  case 7U: 
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_ioc_disable_wait);
  bna_ioceth_sm_ioc_disable_wait_entry(ioceth);
  bfa_nw_ioc_disable(& ioceth->ioc);
  goto ldv_49842;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1569, (unsigned int )event);
  }
  ldv_49842: ;
  return;
}
}
static void bna_ioceth_sm_ioc_disable_wait_entry(struct bna_ioceth *ioceth ) 
{ 


  {
  return;
}
}
static void bna_ioceth_sm_ioc_disable_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) 
{ 
  u32 mask ;

  {
  switch ((unsigned int )event) {
  case 8U: 
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  writel(((ioceth->bna)->bits.mbox_mask_bits | mask) | (ioceth->bna)->bits.error_mask_bits,
         (void volatile   *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  bnad_cb_mbox_intr_disable((ioceth->bna)->bnad);
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_stopped);
  bna_ioceth_sm_stopped_entry(ioceth);
  goto ldv_49854;
  case 7U: ;
  goto ldv_49854;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1594, (unsigned int )event);
  }
  ldv_49854: ;
  return;
}
}
static void bna_ioceth_sm_failed_entry(struct bna_ioceth *ioceth ) 
{ 


  {
  bnad_cb_ioceth_failed((ioceth->bna)->bnad);
  return;
}
}
static void bna_ioceth_sm_failed(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) 
{ 
  u32 intr_status ;
  u32 mask ;

  {
  switch ((unsigned int )event) {
  case 2U: 
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_ioc_disable_wait);
  bna_ioceth_sm_ioc_disable_wait_entry(ioceth);
  bfa_nw_ioc_disable(& ioceth->ioc);
  goto ldv_49865;
  case 3U: 
  intr_status = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_status);
  if (intr_status != 0U) {
    writel(~ (ioceth->bna)->bits.mbox_status_bits & intr_status, (void volatile   *)(ioceth->bna)->regs.fn_int_status);
  } else {

  }
  bnad_cb_mbox_intr_enable((ioceth->bna)->bnad);
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  writel(~ ((ioceth->bna)->bits.mbox_mask_bits | (ioceth->bna)->bits.error_mask_bits) & mask,
         (void volatile   *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile   *)(ioceth->bna)->regs.fn_int_mask);
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_ioc_ready_wait);
  bna_ioceth_sm_ioc_ready_wait_entry(ioceth);
  goto ldv_49865;
  case 4U: ;
  goto ldv_49865;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1623, (unsigned int )event);
  }
  ldv_49865: ;
  return;
}
}
static void bna_bfi_attr_get(struct bna_ioceth *ioceth ) 
{ 
  struct bfi_enet_attr_req *attr_req ;

  {
  attr_req = & ioceth->attr_req;
  attr_req->mh.msg_class = 24U;
  attr_req->mh.msg_id = 22U;
  attr_req->mh.msg_token = 0U;
  attr_req->mh.enet_id = 0U;
  attr_req->mh.num_entries = 256U;
  ioceth->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  ioceth->msgq_cmd.cbarg = (void *)0;
  ioceth->msgq_cmd.msg_size = 8UL;
  ioceth->msgq_cmd.msg_hdr = & attr_req->mh;
  bfa_msgq_cmd_post(& (ioceth->bna)->msgq, & ioceth->msgq_cmd);
  return;
}
}
static void bna_cb_ioceth_enable(void *arg , enum bfa_status error ) 
{ 
  struct bna_ioceth *ioceth ;

  {
  ioceth = (struct bna_ioceth *)arg;
  if ((unsigned int )error != 0U) {
    (*(ioceth->fsm))((void *)ioceth, 4);
  } else {
    (*(ioceth->fsm))((void *)ioceth, 5);
  }
  return;
}
}
static void bna_cb_ioceth_disable(void *arg ) 
{ 
  struct bna_ioceth *ioceth ;

  {
  ioceth = (struct bna_ioceth *)arg;
  (*(ioceth->fsm))((void *)ioceth, 8);
  return;
}
}
static void bna_cb_ioceth_hbfail(void *arg ) 
{ 
  struct bna_ioceth *ioceth ;

  {
  ioceth = (struct bna_ioceth *)arg;
  (*(ioceth->fsm))((void *)ioceth, 4);
  return;
}
}
static void bna_cb_ioceth_reset(void *arg ) 
{ 
  struct bna_ioceth *ioceth ;

  {
  ioceth = (struct bna_ioceth *)arg;
  (*(ioceth->fsm))((void *)ioceth, 3);
  return;
}
}
static struct bfa_ioc_cbfn bna_ioceth_cbfn  =    {& bna_cb_ioceth_enable, & bna_cb_ioceth_disable, & bna_cb_ioceth_hbfail, & bna_cb_ioceth_reset};
static void bna_attr_init(struct bna_ioceth *ioceth ) 
{ 


  {
  ioceth->attr.num_txq = 1;
  ioceth->attr.num_rxp = 1;
  ioceth->attr.num_ucmac = 1;
  ioceth->attr.num_mcmac = 256;
  ioceth->attr.max_rit_size = 1;
  ioceth->attr.fw_query_complete = 0;
  return;
}
}
static void bna_ioceth_init(struct bna_ioceth *ioceth , struct bna *bna , struct bna_res_info *res_info ) 
{ 
  u64 dma ;
  u8 *kva ;
  __u32 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;
  u32 tmp___3 ;
  u32 tmp___4 ;
  u32 tmp___5 ;
  u32 tmp___6 ;
  u32 tmp___7 ;
  u32 tmp___8 ;

  {
  ioceth->bna = bna;
  bfa_nw_ioc_attach(& ioceth->ioc, (void *)ioceth, & bna_ioceth_cbfn);
  bfa_nw_ioc_pci_init(& ioceth->ioc, & bna->pcidev, 512);
  tmp = __fswab32(((res_info + 1UL)->res_u.mem_info.mdl)->dma.msb);
  tmp___0 = __fswab32(((res_info + 1UL)->res_u.mem_info.mdl)->dma.lsb);
  dma = ((unsigned long long )tmp << 32) | (unsigned long long )tmp___0;
  kva = (u8 *)((res_info + 1UL)->res_u.mem_info.mdl)->kva;
  bfa_nw_ioc_mem_claim(& ioceth->ioc, kva, dma);
  kva = (u8 *)((res_info + 2UL)->res_u.mem_info.mdl)->kva;
  bfa_nw_ioc_debug_memclaim(& ioceth->ioc, (void *)kva);
  tmp___1 = __fswab32((res_info->res_u.mem_info.mdl)->dma.msb);
  tmp___2 = __fswab32((res_info->res_u.mem_info.mdl)->dma.lsb);
  dma = ((unsigned long long )tmp___1 << 32) | (unsigned long long )tmp___2;
  kva = (u8 *)(res_info->res_u.mem_info.mdl)->kva;
  bfa_nw_cee_attach(& bna->cee, & ioceth->ioc, (void *)bna);
  bfa_nw_cee_mem_claim(& bna->cee, kva, dma);
  tmp___3 = bfa_nw_cee_meminfo();
  kva = kva + (unsigned long )tmp___3;
  tmp___4 = bfa_nw_cee_meminfo();
  dma = (u64 )tmp___4 + dma;
  bfa_nw_flash_attach(& bna->flash, & ioceth->ioc, (void *)bna);
  bfa_nw_flash_memclaim(& bna->flash, kva, dma);
  tmp___5 = bfa_nw_flash_meminfo();
  kva = kva + (unsigned long )tmp___5;
  tmp___6 = bfa_nw_flash_meminfo();
  dma = (u64 )tmp___6 + dma;
  bfa_msgq_attach(& bna->msgq, & ioceth->ioc);
  bfa_msgq_memclaim(& bna->msgq, kva, dma);
  bfa_msgq_regisr(& bna->msgq, 24, & bna_msgq_rsp_handler, (void *)bna);
  tmp___7 = bfa_msgq_meminfo();
  kva = kva + (unsigned long )tmp___7;
  tmp___8 = bfa_msgq_meminfo();
  dma = (u64 )tmp___8 + dma;
  ioceth->stop_cbfn = (void (*)(struct bnad * ))0;
  ioceth->stop_cbarg = (struct bnad *)0;
  bna_attr_init(ioceth);
  ioceth->fsm = (void (*)(void * , int  ))(& bna_ioceth_sm_stopped);
  bna_ioceth_sm_stopped_entry(ioceth);
  return;
}
}
static void bna_ioceth_uninit(struct bna_ioceth *ioceth ) 
{ 


  {
  bfa_nw_ioc_detach(& ioceth->ioc);
  ioceth->bna = (struct bna *)0;
  return;
}
}
void bna_ioceth_enable(struct bna_ioceth *ioceth ) 
{ 


  {
  if ((unsigned long )ioceth->fsm == (unsigned long )((void (*)(void * , int  ))(& bna_ioceth_sm_ready))) {
    bnad_cb_ioceth_ready((ioceth->bna)->bnad);
    return;
  } else {

  }
  if ((unsigned long )ioceth->fsm == (unsigned long )((void (*)(void * , int  ))(& bna_ioceth_sm_stopped))) {
    (*(ioceth->fsm))((void *)ioceth, 1);
  } else {

  }
  return;
}
}
void bna_ioceth_disable(struct bna_ioceth *ioceth , enum bna_cleanup_type type ) 
{ 


  {
  if ((unsigned int )type == 1U) {
    bnad_cb_ioceth_disabled((ioceth->bna)->bnad);
    return;
  } else {

  }
  ioceth->stop_cbfn = & bnad_cb_ioceth_disabled;
  ioceth->stop_cbarg = (ioceth->bna)->bnad;
  (*(ioceth->fsm))((void *)ioceth, 2);
  return;
}
}
static void bna_ucam_mod_init(struct bna_ucam_mod *ucam_mod , struct bna *bna , struct bna_res_info *res_info ) 
{ 
  int i ;

  {
  ucam_mod->ucmac = (struct bna_mac *)((res_info + 5UL)->res_u.mem_info.mdl)->kva;
  INIT_LIST_HEAD(& ucam_mod->free_q);
  i = 0;
  goto ldv_49920;
  ldv_49919: 
  list_add_tail(& (ucam_mod->ucmac + (unsigned long )i)->qe, & ucam_mod->free_q);
  i = i + 1;
  ldv_49920: ;
  if (bna->ioceth.attr.num_ucmac > i) {
    goto ldv_49919;
  } else {

  }
  INIT_LIST_HEAD(& ucam_mod->del_q);
  i = i;
  goto ldv_49923;
  ldv_49922: 
  list_add_tail(& (ucam_mod->ucmac + (unsigned long )i)->qe, & ucam_mod->del_q);
  i = i + 1;
  ldv_49923: ;
  if (bna->ioceth.attr.num_ucmac * 2 > i) {
    goto ldv_49922;
  } else {

  }
  ucam_mod->bna = bna;
  return;
}
}
static void bna_ucam_mod_uninit(struct bna_ucam_mod *ucam_mod ) 
{ 


  {
  ucam_mod->bna = (struct bna *)0;
  return;
}
}
static void bna_mcam_mod_init(struct bna_mcam_mod *mcam_mod , struct bna *bna , struct bna_res_info *res_info ) 
{ 
  int i ;

  {
  mcam_mod->mcmac = (struct bna_mac *)((res_info + 6UL)->res_u.mem_info.mdl)->kva;
  INIT_LIST_HEAD(& mcam_mod->free_q);
  i = 0;
  goto ldv_49935;
  ldv_49934: 
  list_add_tail(& (mcam_mod->mcmac + (unsigned long )i)->qe, & mcam_mod->free_q);
  i = i + 1;
  ldv_49935: ;
  if (bna->ioceth.attr.num_mcmac > i) {
    goto ldv_49934;
  } else {

  }
  mcam_mod->mchandle = (struct bna_mcam_handle *)((res_info + 7UL)->res_u.mem_info.mdl)->kva;
  INIT_LIST_HEAD(& mcam_mod->free_handle_q);
  i = 0;
  goto ldv_49938;
  ldv_49937: 
  list_add_tail(& (mcam_mod->mchandle + (unsigned long )i)->qe, & mcam_mod->free_handle_q);
  i = i + 1;
  ldv_49938: ;
  if (bna->ioceth.attr.num_mcmac > i) {
    goto ldv_49937;
  } else {

  }
  INIT_LIST_HEAD(& mcam_mod->del_q);
  i = i;
  goto ldv_49941;
  ldv_49940: 
  list_add_tail(& (mcam_mod->mcmac + (unsigned long )i)->qe, & mcam_mod->del_q);
  i = i + 1;
  ldv_49941: ;
  if (bna->ioceth.attr.num_mcmac * 2 > i) {
    goto ldv_49940;
  } else {

  }
  mcam_mod->bna = bna;
  return;
}
}
static void bna_mcam_mod_uninit(struct bna_mcam_mod *mcam_mod ) 
{ 


  {
  mcam_mod->bna = (struct bna *)0;
  return;
}
}
static void bna_bfi_stats_get(struct bna *bna ) 
{ 
  struct bfi_enet_stats_req *stats_req ;
  __u32 tmp ;
  __u32 tmp___0 ;

  {
  stats_req = & bna->stats_mod.stats_get;
  bna->stats_mod.stats_get_busy = 1;
  stats_req->mh.msg_class = 24U;
  stats_req->mh.msg_id = 23U;
  stats_req->mh.msg_token = 0U;
  stats_req->mh.enet_id = 0U;
  stats_req->mh.num_entries = 256U;
  stats_req->stats_mask = 7936U;
  tmp = __fswab32(bna->tx_mod.rid_mask);
  stats_req->tx_enet_mask = tmp;
  tmp___0 = __fswab32(bna->rx_mod.rid_mask);
  stats_req->rx_enet_mask = tmp___0;
  stats_req->host_buffer.a32.addr_hi = bna->stats.hw_stats_dma.msb;
  stats_req->host_buffer.a32.addr_lo = bna->stats.hw_stats_dma.lsb;
  bna->stats_mod.stats_get_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  bna->stats_mod.stats_get_cmd.cbarg = (void *)0;
  bna->stats_mod.stats_get_cmd.msg_size = 28UL;
  bna->stats_mod.stats_get_cmd.msg_hdr = & stats_req->mh;
  bfa_msgq_cmd_post(& bna->msgq, & bna->stats_mod.stats_get_cmd);
  return;
}
}
void bna_res_req(struct bna_res_info *res_info ) 
{ 
  u32 tmp ;
  u32 tmp___0 ;
  u32 tmp___1 ;
  u32 tmp___2 ;

  {
  res_info->res_type = 1;
  res_info->res_u.mem_info.mem_type = 2;
  res_info->res_u.mem_info.num = 1U;
  tmp = bfa_nw_cee_meminfo();
  tmp___0 = bfa_nw_flash_meminfo();
  tmp___1 = bfa_msgq_meminfo();
  res_info->res_u.mem_info.len = (((tmp + tmp___0) + tmp___1) + 4095U) & 4294963200U;
  (res_info + 1UL)->res_type = 1;
  (res_info + 1UL)->res_u.mem_info.mem_type = 2;
  (res_info + 1UL)->res_u.mem_info.num = 1U;
  tmp___2 = bfa_nw_ioc_meminfo();
  (res_info + 1UL)->res_u.mem_info.len = (tmp___2 + 4095U) & 4294963200U;
  (res_info + 2UL)->res_type = 1;
  (res_info + 2UL)->res_u.mem_info.mem_type = 1;
  (res_info + 2UL)->res_u.mem_info.num = 1U;
  (res_info + 2UL)->res_u.mem_info.len = 4128U;
  (res_info + 3UL)->res_type = 1;
  (res_info + 3UL)->res_u.mem_info.mem_type = 2;
  (res_info + 3UL)->res_u.mem_info.num = 1U;
  (res_info + 3UL)->res_u.mem_info.len = 8192U;
  return;
}
}
void bna_mod_res_req(struct bna *bna , struct bna_res_info *res_info ) 
{ 
  struct bna_attr *attr ;

  {
  attr = & bna->ioceth.attr;
  res_info->res_type = 1;
  res_info->res_u.mem_info.mem_type = 1;
  res_info->res_u.mem_info.num = 1U;
  res_info->res_u.mem_info.len = (u32 )((unsigned long )attr->num_txq) * 520U;
  (res_info + 1UL)->res_type = 1;
  (res_info + 1UL)->res_u.mem_info.mem_type = 1;
  (res_info + 1UL)->res_u.mem_info.num = 1U;
  (res_info + 1UL)->res_u.mem_info.len = (u32 )((unsigned long )attr->num_txq) * 144U;
  (res_info + 2UL)->res_type = 1;
  (res_info + 2UL)->res_u.mem_info.mem_type = 1;
  (res_info + 2UL)->res_u.mem_info.num = 1U;
  (res_info + 2UL)->res_u.mem_info.len = (u32 )((unsigned long )attr->num_rxp) * 2512U;
  (res_info + 3UL)->res_type = 1;
  (res_info + 3UL)->res_u.mem_info.mem_type = 1;
  (res_info + 3UL)->res_u.mem_info.num = 1U;
  (res_info + 3UL)->res_u.mem_info.len = (u32 )((unsigned long )attr->num_rxp) * 152U;
  (res_info + 4UL)->res_type = 1;
  (res_info + 4UL)->res_u.mem_info.mem_type = 1;
  (res_info + 4UL)->res_u.mem_info.num = 1U;
  (res_info + 4UL)->res_u.mem_info.len = (u32 )((unsigned long )attr->num_rxp) * 240U;
  (res_info + 5UL)->res_type = 1;
  (res_info + 5UL)->res_u.mem_info.mem_type = 1;
  (res_info + 5UL)->res_u.mem_info.num = 1U;
  (res_info + 5UL)->res_u.mem_info.len = (u32 )((unsigned long )attr->num_ucmac) * 64U;
  (res_info + 6UL)->res_type = 1;
  (res_info + 6UL)->res_u.mem_info.mem_type = 1;
  (res_info + 6UL)->res_u.mem_info.num = 1U;
  (res_info + 6UL)->res_u.mem_info.len = (u32 )((unsigned long )attr->num_mcmac) * 64U;
  (res_info + 7UL)->res_type = 1;
  (res_info + 7UL)->res_u.mem_info.mem_type = 1;
  (res_info + 7UL)->res_u.mem_info.num = 1U;
  (res_info + 7UL)->res_u.mem_info.len = (u32 )((unsigned long )attr->num_mcmac) * 24U;
  return;
}
}
void bna_init(struct bna *bna , struct bnad *bnad , struct bfa_pcidev *pcidev , struct bna_res_info *res_info ) 
{ 
  struct bna_reg_offset reg_offset[4U] ;

  {
  bna->bnad = bnad;
  bna->pcidev = *pcidev;
  bna->stats.hw_stats_kva = (struct bfi_enet_stats *)((res_info + 3UL)->res_u.mem_info.mdl)->kva;
  bna->stats.hw_stats_dma.msb = ((res_info + 3UL)->res_u.mem_info.mdl)->dma.msb;
  bna->stats.hw_stats_dma.lsb = ((res_info + 3UL)->res_u.mem_info.mdl)->dma.lsb;
  switch ((int )bna->pcidev.device_id) {
  case 20: 
  reg_offset[0].fn_int_status = 81920U;
  reg_offset[0].fn_int_mask = 81924U;
  reg_offset[1].fn_int_status = 82176U;
  reg_offset[1].fn_int_mask = 82180U;
  reg_offset[2].fn_int_status = 82688U;
  reg_offset[2].fn_int_mask = 82692U;
  reg_offset[3].fn_int_status = 82944U;
  reg_offset[3].fn_int_mask = 82948U;
  bna->regs.fn_int_status = bna->pcidev.pci_bar_kva + (unsigned long )reg_offset[(int )bna->pcidev.pci_func].fn_int_status;
  bna->regs.fn_int_mask = bna->pcidev.pci_bar_kva + (unsigned long )reg_offset[(int )bna->pcidev.pci_func].fn_int_mask;
  bna->bits.mbox_status_bits = 3145728U;
  bna->bits.mbox_mask_bits = 3145728U;
  bna->bits.error_status_bits = 17760256U;
  bna->bits.error_mask_bits = 17760256U;
  bna->bits.halt_status_bits = 16777216U;
  bna->bits.halt_mask_bits = 16777216U;
  goto ldv_49966;
  case 34: 
  bna->regs.fn_int_status = bna->pcidev.pci_bar_kva + 196864UL;
  bna->regs.fn_int_mask = bna->pcidev.pci_bar_kva + 196868UL;
  bna->bits.mbox_status_bits = 196608U;
  bna->bits.mbox_mask_bits = 196608U;
  bna->bits.error_status_bits = 33292288U;
  bna->bits.error_mask_bits = 33292288U;
  bna->bits.halt_status_bits = 2097152U;
  bna->bits.halt_mask_bits = 2097152U;
  goto ldv_49966;
  }
  ldv_49966: 
  bna_ioceth_init(& bna->ioceth, bna, res_info);
  bna_enet_init(& bna->enet, bna);
  bna_ethport_init(& bna->ethport, bna);
  return;
}
}
void bna_mod_init(struct bna *bna , struct bna_res_info *res_info ) 
{ 


  {
  bna_tx_mod_init(& bna->tx_mod, bna, res_info);
  bna_rx_mod_init(& bna->rx_mod, bna, res_info);
  bna_ucam_mod_init(& bna->ucam_mod, bna, res_info);
  bna_mcam_mod_init(& bna->mcam_mod, bna, res_info);
  bna->default_mode_rid = -1;
  bna->promisc_rid = -1;
  bna->mod_flags = (enum bna_mod_flags )((unsigned int )bna->mod_flags | 1U);
  return;
}
}
void bna_uninit(struct bna *bna ) 
{ 


  {
  if ((int )bna->mod_flags & 1) {
    bna_mcam_mod_uninit(& bna->mcam_mod);
    bna_ucam_mod_uninit(& bna->ucam_mod);
    bna_rx_mod_uninit(& bna->rx_mod);
    bna_tx_mod_uninit(& bna->tx_mod);
    bna->mod_flags = (enum bna_mod_flags )((unsigned int )bna->mod_flags & 4294967294U);
  } else {

  }
  bna_ethport_uninit(& bna->ethport);
  bna_enet_uninit(& bna->enet);
  bna_ioceth_uninit(& bna->ioceth);
  bna->bnad = (struct bnad *)0;
  return;
}
}
int bna_num_txq_set(struct bna *bna , int num_txq ) 
{ 


  {
  if ((int )bna->ioceth.attr.fw_query_complete && bna->ioceth.attr.num_txq >= num_txq) {
    bna->ioceth.attr.num_txq = num_txq;
    return (0);
  } else {

  }
  return (1);
}
}
int bna_num_rxp_set(struct bna *bna , int num_rxp ) 
{ 


  {
  if ((int )bna->ioceth.attr.fw_query_complete && bna->ioceth.attr.num_rxp >= num_rxp) {
    bna->ioceth.attr.num_rxp = num_rxp;
    return (0);
  } else {

  }
  return (1);
}
}
struct bna_mac *bna_cam_mod_mac_get(struct list_head *head ) 
{ 
  struct bna_mac *mac ;
  struct list_head  const  *__mptr ;
  int tmp___0 ;

  {
  tmp___0 = list_empty((struct list_head  const  *)head);
  if (tmp___0 == 0) {
    __mptr = (struct list_head  const  *)head->next;
    mac = (struct bna_mac *)__mptr;
  } else {
    mac = (struct bna_mac *)0;
  }
  if ((unsigned long )mac != (unsigned long )((struct bna_mac *)0)) {
    list_del(& mac->qe);
  } else {

  }
  return (mac);
}
}
struct bna_mcam_handle *bna_mcam_mod_handle_get(struct bna_mcam_mod *mcam_mod ) 
{ 
  struct bna_mcam_handle *handle ;
  struct list_head  const  *__mptr ;
  int tmp___0 ;

  {
  tmp___0 = list_empty((struct list_head  const  *)(& mcam_mod->free_handle_q));
  if (tmp___0 == 0) {
    __mptr = (struct list_head  const  *)mcam_mod->free_handle_q.next;
    handle = (struct bna_mcam_handle *)__mptr;
  } else {
    handle = (struct bna_mcam_handle *)0;
  }
  if ((unsigned long )handle != (unsigned long )((struct bna_mcam_handle *)0)) {
    list_del(& handle->qe);
  } else {

  }
  return (handle);
}
}
void bna_mcam_mod_handle_put(struct bna_mcam_mod *mcam_mod , struct bna_mcam_handle *handle ) 
{ 


  {
  list_add_tail(& handle->qe, & mcam_mod->free_handle_q);
  return;
}
}
void bna_hw_stats_get(struct bna *bna ) 
{ 


  {
  if (! bna->stats_mod.ioc_ready) {
    bnad_cb_stats_get(bna->bnad, 1, & bna->stats);
    return;
  } else {

  }
  if ((int )bna->stats_mod.stats_get_busy) {
    bnad_cb_stats_get(bna->bnad, 3, & bna->stats);
    return;
  } else {

  }
  bna_bfi_stats_get(bna);
  return;
}
}
void ldv_main_exported_13(void) 
{ 
  void *ldvarg33 ;
  void *tmp ;
  enum bfa_status ldvarg34 ;
  void *ldvarg31 ;
  void *tmp___0 ;
  void *ldvarg32 ;
  void *tmp___1 ;
  void *ldvarg35 ;
  void *tmp___2 ;
  int tmp___3 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg33 = tmp;
  tmp___0 = ldv_init_zalloc(1UL);
  ldvarg31 = tmp___0;
  tmp___1 = ldv_init_zalloc(1UL);
  ldvarg32 = tmp___1;
  tmp___2 = ldv_init_zalloc(1UL);
  ldvarg35 = tmp___2;
  ldv_memset((void *)(& ldvarg34), 0, 4UL);
  tmp___3 = __VERIFIER_nondet_int();
  switch (tmp___3) {
  case 0: ;
  if (ldv_state_variable_13 == 1) {
    bna_cb_ioceth_disable(ldvarg35);
    ldv_state_variable_13 = 1;
  } else {

  }
  goto ldv_50011;
  case 1: ;
  if (ldv_state_variable_13 == 1) {
    bna_cb_ioceth_enable(ldvarg33, ldvarg34);
    ldv_state_variable_13 = 1;
  } else {

  }
  goto ldv_50011;
  case 2: ;
  if (ldv_state_variable_13 == 1) {
    bna_cb_ioceth_hbfail(ldvarg32);
    ldv_state_variable_13 = 1;
  } else {

  }
  goto ldv_50011;
  case 3: ;
  if (ldv_state_variable_13 == 1) {
    bna_cb_ioceth_reset(ldvarg31);
    ldv_state_variable_13 = 1;
  } else {

  }
  goto ldv_50011;
  default: 
  ldv_stop();
  }
  ldv_50011: ;
  return;
}
}
bool ldv_queue_work_on_210(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_211(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_212(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_213(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_214(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
int ldv_pskb_expand_head_226(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_228(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_230(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_231(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_232(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_233(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_234(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
int ldv_pskb_expand_head_235(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_236(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
__inline static unsigned int fls_long(unsigned long l ) 
{ 
  int tmp___0 ;

  {
  tmp___0 = fls64((__u64 )l);
  return ((unsigned int )tmp___0);
}
}
__inline static unsigned long __roundup_pow_of_two(unsigned long n ) 
{ 
  unsigned int tmp ;

  {
  tmp = fls_long(n - 1UL);
  return (1UL << (int )tmp);
}
}
__inline static void list_add(struct list_head *new , struct list_head *head ) 
{ 


  {
  __list_add(new, head, head->next);
  return;
}
}
extern void __list_del_entry(struct list_head * ) ;
__inline static void list_move_tail(struct list_head *list , struct list_head *head ) 
{ 


  {
  __list_del_entry(list);
  list_add_tail(list, head);
  return;
}
}
bool ldv_queue_work_on_256(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_258(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_257(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_260(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_259(struct workqueue_struct *ldv_func_arg1 ) ;
struct sk_buff *ldv_skb_clone_274(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_282(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_276(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_272(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_280(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_281(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_277(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_278(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_279(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
__inline static bool ether_addr_equal(u8 const   *addr1 , u8 const   *addr2 ) 
{ 
  u32 fold ;

  {
  fold = ((unsigned int )*((u32 const   *)addr1) ^ (unsigned int )*((u32 const   *)addr2)) | (unsigned int )((int )((unsigned short )*((u16 const   *)addr1 + 4U)) ^ (int )((unsigned short )*((u16 const   *)addr2 + 4U)));
  return (fold == 0U);
}
}
void bfa_msgq_rsp_copy(struct bfa_msgq *msgq , u8 *buf , size_t buf_len ) ;
__inline static struct bna_mac *bna_mac_find(struct list_head *q , u8 const   *addr ) 
{ 
  struct bna_mac *mac ;
  struct list_head  const  *__mptr ;
  bool tmp ;
  struct list_head  const  *__mptr___0 ;

  {
  __mptr = (struct list_head  const  *)q->next;
  mac = (struct bna_mac *)__mptr;
  goto ldv_48872;
  ldv_48871: 
  tmp = ether_addr_equal((u8 const   *)(& mac->addr), addr);
  if ((int )tmp) {
    return (mac);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)mac->qe.next;
  mac = (struct bna_mac *)__mptr___0;
  ldv_48872: ;
  if ((unsigned long )(& mac->qe) != (unsigned long )q) {
    goto ldv_48871;
  } else {

  }

  return ((struct bna_mac *)0);
}
}
static void bna_ib_coalescing_timeo_set(struct bna_ib *ib , u8 coalescing_timeo ) 
{ 


  {
  ib->coalescing_timeo = coalescing_timeo;
  ib->door_bell.doorbell_ack = ((unsigned int )ib->coalescing_timeo << 16) | 2147483648U;
  return;
}
}
static int bna_rxf_cfg_apply(struct bna_rxf *rxf ) ;
static void bna_rxf_cfg_reset(struct bna_rxf *rxf ) ;
static int bna_rxf_ucast_cfg_apply(struct bna_rxf *rxf ) ;
static int bna_rxf_promisc_cfg_apply(struct bna_rxf *rxf ) ;
static int bna_rxf_allmulti_cfg_apply(struct bna_rxf *rxf ) ;
static int bna_rxf_vlan_strip_cfg_apply(struct bna_rxf *rxf ) ;
static int bna_rxf_ucast_cfg_reset(struct bna_rxf *rxf , enum bna_cleanup_type cleanup ) ;
static int bna_rxf_promisc_cfg_reset(struct bna_rxf *rxf , enum bna_cleanup_type cleanup ) ;
static int bna_rxf_allmulti_cfg_reset(struct bna_rxf *rxf , enum bna_cleanup_type cleanup ) ;
static void bna_rxf_sm_stopped(struct bna_rxf *rxf , enum bna_rxf_event event ) ;
static void bna_rxf_sm_stopped_entry(struct bna_rxf *rxf ) ;
static void bna_rxf_sm_cfg_wait(struct bna_rxf *rxf , enum bna_rxf_event event ) ;
static void bna_rxf_sm_cfg_wait_entry(struct bna_rxf *rxf ) ;
static void bna_rxf_sm_started(struct bna_rxf *rxf , enum bna_rxf_event event ) ;
static void bna_rxf_sm_started_entry(struct bna_rxf *rxf ) ;
static void bna_rxf_sm_last_resp_wait(struct bna_rxf *rxf , enum bna_rxf_event event ) ;
static void bna_rxf_sm_last_resp_wait_entry(struct bna_rxf *rxf ) ;
static void bna_rxf_sm_stopped_entry(struct bna_rxf *rxf ) 
{ 
  void (*cbfn)(struct bna_rx * ) ;
  struct bna_rx *cbarg ;

  {
  if ((unsigned long )rxf->stop_cbfn != (unsigned long )((void (*)(struct bna_rx * ))0)) {
    cbfn = rxf->stop_cbfn;
    cbarg = rxf->stop_cbarg;
    rxf->stop_cbfn = (void (*)(struct bna_rx * ))0;
    rxf->stop_cbarg = (struct bna_rx *)0;
    (*cbfn)(cbarg);
  } else {

  }
  return;
}
}
static void bna_rxf_sm_stopped(struct bna_rxf *rxf , enum bna_rxf_event event ) 
{ 
  void (*cbfn)(struct bna_rx * ) ;
  struct bna_rx *cbarg ;
  void (*cbfn___0)(struct bnad * , struct bna_rx * ) ;
  struct bnad *cbarg___0 ;

  {
  switch ((unsigned int )event) {
  case 1U: 
  rxf->fsm = (void (*)(void * , int  ))(& bna_rxf_sm_cfg_wait);
  bna_rxf_sm_cfg_wait_entry(rxf);
  goto ldv_49158;
  case 2U: ;
  if ((unsigned long )rxf->stop_cbfn != (unsigned long )((void (*)(struct bna_rx * ))0)) {
    cbfn = rxf->stop_cbfn;
    cbarg = rxf->stop_cbarg;
    rxf->stop_cbfn = (void (*)(struct bna_rx * ))0;
    rxf->stop_cbarg = (struct bna_rx *)0;
    (*cbfn)(cbarg);
  } else {

  }
  goto ldv_49158;
  case 3U: ;
  goto ldv_49158;
  case 4U: ;
  if ((unsigned long )rxf->cam_fltr_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                       struct bna_rx * ))0)) {
    cbfn___0 = rxf->cam_fltr_cbfn;
    cbarg___0 = rxf->cam_fltr_cbarg;
    rxf->cam_fltr_cbfn = (void (*)(struct bnad * , struct bna_rx * ))0;
    rxf->cam_fltr_cbarg = (struct bnad *)0;
    (*cbfn___0)(cbarg___0, rxf->rx);
  } else {

  }
  goto ldv_49158;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         96, (unsigned int )event);
  }
  ldv_49158: ;
  return;
}
}
static void bna_rxf_sm_cfg_wait_entry(struct bna_rxf *rxf ) 
{ 
  int tmp ;

  {
  tmp = bna_rxf_cfg_apply(rxf);
  if (tmp == 0) {
    rxf->fsm = (void (*)(void * , int  ))(& bna_rxf_sm_started);
    bna_rxf_sm_started_entry(rxf);
  } else {

  }
  return;
}
}
static void bna_rxf_sm_cfg_wait(struct bna_rxf *rxf , enum bna_rxf_event event ) 
{ 
  void (*cbfn)(struct bna_rx * ) ;
  struct bna_rx *cbarg ;
  void (*cbfn___0)(struct bnad * , struct bna_rx * ) ;
  struct bnad *cbarg___0 ;
  int tmp ;

  {
  switch ((unsigned int )event) {
  case 2U: 
  rxf->fsm = (void (*)(void * , int  ))(& bna_rxf_sm_last_resp_wait);
  bna_rxf_sm_last_resp_wait_entry(rxf);
  goto ldv_49178;
  case 3U: 
  bna_rxf_cfg_reset(rxf);
  if ((unsigned long )rxf->start_cbfn != (unsigned long )((void (*)(struct bna_rx * ))0)) {
    cbfn = rxf->start_cbfn;
    cbarg = rxf->start_cbarg;
    rxf->start_cbfn = (void (*)(struct bna_rx * ))0;
    rxf->start_cbarg = (struct bna_rx *)0;
    (*cbfn)(cbarg);
  } else {

  }
  if ((unsigned long )rxf->cam_fltr_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                       struct bna_rx * ))0)) {
    cbfn___0 = rxf->cam_fltr_cbfn;
    cbarg___0 = rxf->cam_fltr_cbarg;
    rxf->cam_fltr_cbfn = (void (*)(struct bnad * , struct bna_rx * ))0;
    rxf->cam_fltr_cbarg = (struct bnad *)0;
    (*cbfn___0)(cbarg___0, rxf->rx);
  } else {

  }
  rxf->fsm = (void (*)(void * , int  ))(& bna_rxf_sm_stopped);
  bna_rxf_sm_stopped_entry(rxf);
  goto ldv_49178;
  case 4U: ;
  goto ldv_49178;
  case 7U: 
  tmp = bna_rxf_cfg_apply(rxf);
  if (tmp == 0) {
    rxf->fsm = (void (*)(void * , int  ))(& bna_rxf_sm_started);
    bna_rxf_sm_started_entry(rxf);
  } else {

  }
  goto ldv_49178;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         136, (unsigned int )event);
  }
  ldv_49178: ;
  return;
}
}
static void bna_rxf_sm_started_entry(struct bna_rxf *rxf ) 
{ 
  void (*cbfn)(struct bna_rx * ) ;
  struct bna_rx *cbarg ;
  void (*cbfn___0)(struct bnad * , struct bna_rx * ) ;
  struct bnad *cbarg___0 ;

  {
  if ((unsigned long )rxf->start_cbfn != (unsigned long )((void (*)(struct bna_rx * ))0)) {
    cbfn = rxf->start_cbfn;
    cbarg = rxf->start_cbarg;
    rxf->start_cbfn = (void (*)(struct bna_rx * ))0;
    rxf->start_cbarg = (struct bna_rx *)0;
    (*cbfn)(cbarg);
  } else {

  }
  if ((unsigned long )rxf->cam_fltr_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                       struct bna_rx * ))0)) {
    cbfn___0 = rxf->cam_fltr_cbfn;
    cbarg___0 = rxf->cam_fltr_cbarg;
    rxf->cam_fltr_cbfn = (void (*)(struct bnad * , struct bna_rx * ))0;
    rxf->cam_fltr_cbarg = (struct bnad *)0;
    (*cbfn___0)(cbarg___0, rxf->rx);
  } else {

  }
  return;
}
}
static void bna_rxf_sm_started(struct bna_rxf *rxf , enum bna_rxf_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U: 
  bna_rxf_cfg_reset(rxf);
  rxf->fsm = (void (*)(void * , int  ))(& bna_rxf_sm_stopped);
  bna_rxf_sm_stopped_entry(rxf);
  goto ldv_49206;
  case 4U: 
  rxf->fsm = (void (*)(void * , int  ))(& bna_rxf_sm_cfg_wait);
  bna_rxf_sm_cfg_wait_entry(rxf);
  goto ldv_49206;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         162, (unsigned int )event);
  }
  ldv_49206: ;
  return;
}
}
static void bna_rxf_sm_last_resp_wait_entry(struct bna_rxf *rxf ) 
{ 


  {
  return;
}
}
static void bna_rxf_sm_last_resp_wait(struct bna_rxf *rxf , enum bna_rxf_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 7U: 
  bna_rxf_cfg_reset(rxf);
  rxf->fsm = (void (*)(void * , int  ))(& bna_rxf_sm_stopped);
  bna_rxf_sm_stopped_entry(rxf);
  goto ldv_49218;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         182, (unsigned int )event);
  }
  ldv_49218: ;
  return;
}
}
static void bna_bfi_ucast_req(struct bna_rxf *rxf , struct bna_mac *mac , enum bfi_enet_h2i_msgs req_type ) 
{ 
  struct bfi_enet_ucast_req *req ;

  {
  req = & rxf->bfi_enet_cmd.ucast_req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = (u8 )req_type;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  ether_addr_copy((u8 *)(& req->mac_addr), (u8 const   *)(& mac->addr));
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 16UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_mcast_add_req(struct bna_rxf *rxf , struct bna_mac *mac ) 
{ 
  struct bfi_enet_mcast_add_req *req ;

  {
  req = & rxf->bfi_enet_cmd.mcast_add_req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 12U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  ether_addr_copy((u8 *)(& req->mac_addr), (u8 const   *)(& mac->addr));
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 16UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_mcast_del_req(struct bna_rxf *rxf , u16 handle ) 
{ 
  struct bfi_enet_mcast_del_req *req ;
  __u16 tmp ;

  {
  req = & rxf->bfi_enet_cmd.mcast_del_req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 13U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  tmp = __fswab16((int )handle);
  req->handle = tmp;
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 12UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_mcast_filter_req(struct bna_rxf *rxf , enum bna_status status ) 
{ 
  struct bfi_enet_enable_req *req ;

  {
  req = & rxf->bfi_enet_cmd.req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 14U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  req->enable = (u8 )status;
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 12UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_rx_promisc_req(struct bna_rxf *rxf , enum bna_status status ) 
{ 
  struct bfi_enet_enable_req *req ;

  {
  req = & rxf->bfi_enet_cmd.req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 6U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  req->enable = (u8 )status;
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 12UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_rx_vlan_filter_set(struct bna_rxf *rxf , u8 block_idx ) 
{ 
  struct bfi_enet_rx_vlan_req *req ;
  int i ;
  int j ;
  __u32 tmp ;

  {
  req = & rxf->bfi_enet_cmd.vlan_req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 15U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 512U;
  req->block_idx = block_idx;
  i = 0;
  goto ldv_49254;
  ldv_49253: 
  j = (int )block_idx * 16 + i;
  if ((unsigned int )rxf->vlan_filter_status == 1U) {
    tmp = __fswab32(rxf->vlan_filter_table[j]);
    req->bit_mask[i] = tmp;
  } else {
    req->bit_mask[i] = 4294967295U;
  }
  i = i + 1;
  ldv_49254: ;
  if (i <= 15) {
    goto ldv_49253;
  } else {

  }
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 76UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_vlan_strip_enable(struct bna_rxf *rxf ) 
{ 
  struct bfi_enet_enable_req *req ;

  {
  req = & rxf->bfi_enet_cmd.req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 16U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  req->enable = (u8 )rxf->vlan_strip_status;
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 12UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_rit_cfg(struct bna_rxf *rxf ) 
{ 
  struct bfi_enet_rit_req *req ;
  __u16 tmp ;

  {
  req = & rxf->bfi_enet_cmd.rit_req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 3U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 512U;
  tmp = __fswab16((int )((__u16 )rxf->rit_size));
  req->size = tmp;
  memcpy((void *)(& req->table), (void const   *)rxf->rit, (size_t )rxf->rit_size);
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 76UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_rss_cfg(struct bna_rxf *rxf ) 
{ 
  struct bfi_enet_rss_cfg_req *req ;
  int i ;
  __u32 tmp ;

  {
  req = & rxf->bfi_enet_cmd.rss_req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 4U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  req->cfg.type = (u8 )rxf->rss_cfg.hash_type;
  req->cfg.mask = rxf->rss_cfg.hash_mask;
  i = 0;
  goto ldv_49270;
  ldv_49269: 
  tmp = __fswab32(rxf->rss_cfg.toeplitz_hash_key[i]);
  req->cfg.key[i] = tmp;
  i = i + 1;
  ldv_49270: ;
  if (i <= 9) {
    goto ldv_49269;
  } else {

  }
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 52UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_rss_enable(struct bna_rxf *rxf ) 
{ 
  struct bfi_enet_enable_req *req ;

  {
  req = & rxf->bfi_enet_cmd.req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 5U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  req->enable = (u8 )rxf->rss_status;
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 12UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static struct bna_mac *bna_rxf_mcmac_get(struct bna_rxf *rxf , u8 const   *mac_addr ) 
{ 
  struct bna_mac *mac ;
  struct list_head  const  *__mptr ;
  bool tmp ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;
  bool tmp___0 ;
  struct list_head  const  *__mptr___2 ;

  {
  __mptr = (struct list_head  const  *)rxf->mcast_active_q.next;
  mac = (struct bna_mac *)__mptr;
  goto ldv_49286;
  ldv_49285: 
  tmp = ether_addr_equal((u8 const   *)(& mac->addr), mac_addr);
  if ((int )tmp) {
    return (mac);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)mac->qe.next;
  mac = (struct bna_mac *)__mptr___0;
  ldv_49286: ;
  if ((unsigned long )(& mac->qe) != (unsigned long )(& rxf->mcast_active_q)) {
    goto ldv_49285;
  } else {

  }
  __mptr___1 = (struct list_head  const  *)rxf->mcast_pending_del_q.next;
  mac = (struct bna_mac *)__mptr___1;
  goto ldv_49293;
  ldv_49292: 
  tmp___0 = ether_addr_equal((u8 const   *)(& mac->addr), mac_addr);
  if ((int )tmp___0) {
    return (mac);
  } else {

  }
  __mptr___2 = (struct list_head  const  *)mac->qe.next;
  mac = (struct bna_mac *)__mptr___2;
  ldv_49293: ;
  if ((unsigned long )(& mac->qe) != (unsigned long )(& rxf->mcast_pending_del_q)) {
    goto ldv_49292;
  } else {

  }

  return ((struct bna_mac *)0);
}
}
static struct bna_mcam_handle *bna_rxf_mchandle_get(struct bna_rxf *rxf , int handle ) 
{ 
  struct bna_mcam_handle *mchandle ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  __mptr = (struct list_head  const  *)rxf->mcast_handle_q.next;
  mchandle = (struct bna_mcam_handle *)__mptr;
  goto ldv_49305;
  ldv_49304: ;
  if (mchandle->handle == handle) {
    return (mchandle);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)mchandle->qe.next;
  mchandle = (struct bna_mcam_handle *)__mptr___0;
  ldv_49305: ;
  if ((unsigned long )(& mchandle->qe) != (unsigned long )(& rxf->mcast_handle_q)) {
    goto ldv_49304;
  } else {

  }

  return ((struct bna_mcam_handle *)0);
}
}
static void bna_rxf_mchandle_attach(struct bna_rxf *rxf , u8 *mac_addr , int handle ) 
{ 
  struct bna_mac *mcmac ;
  struct bna_mcam_handle *mchandle ;

  {
  mcmac = bna_rxf_mcmac_get(rxf, (u8 const   *)mac_addr);
  mchandle = bna_rxf_mchandle_get(rxf, handle);
  if ((unsigned long )mchandle == (unsigned long )((struct bna_mcam_handle *)0)) {
    mchandle = bna_mcam_mod_handle_get(& ((rxf->rx)->bna)->mcam_mod);
    mchandle->handle = handle;
    mchandle->refcnt = 0;
    list_add_tail(& mchandle->qe, & rxf->mcast_handle_q);
  } else {

  }
  mchandle->refcnt = mchandle->refcnt + 1;
  mcmac->handle = mchandle;
  return;
}
}
static int bna_rxf_mcast_del(struct bna_rxf *rxf , struct bna_mac *mac , enum bna_cleanup_type cleanup ) 
{ 
  struct bna_mcam_handle *mchandle ;
  int ret ;

  {
  ret = 0;
  mchandle = mac->handle;
  if ((unsigned long )mchandle == (unsigned long )((struct bna_mcam_handle *)0)) {
    return (ret);
  } else {

  }
  mchandle->refcnt = mchandle->refcnt - 1;
  if (mchandle->refcnt == 0) {
    if ((unsigned int )cleanup == 0U) {
      bna_bfi_mcast_del_req(rxf, (int )((u16 )mchandle->handle));
      ret = 1;
    } else {

    }
    list_del(& mchandle->qe);
    bna_mcam_mod_handle_put(& ((rxf->rx)->bna)->mcam_mod, mchandle);
  } else {

  }
  mac->handle = (struct bna_mcam_handle *)0;
  return (ret);
}
}
static int bna_rxf_mcast_cfg_apply(struct bna_rxf *rxf ) 
{ 
  struct bna_mac *mac ;
  int ret ;
  struct list_head  const  *__mptr ;
  int tmp ;
  struct list_head  const  *__mptr___0 ;
  int tmp___0 ;

  {
  mac = (struct bna_mac *)0;
  goto ldv_49329;
  ldv_49328: 
  __mptr = (struct list_head  const  *)rxf->mcast_pending_del_q.next;
  mac = (struct bna_mac *)__mptr;
  ret = bna_rxf_mcast_del(rxf, mac, 0);
  list_move_tail(& mac->qe, & ((rxf->rx)->bna)->mcam_mod.del_q);
  if (ret != 0) {
    return (ret);
  } else {

  }
  ldv_49329: 
  tmp = list_empty((struct list_head  const  *)(& rxf->mcast_pending_del_q));
  if (tmp == 0) {
    goto ldv_49328;
  } else {

  }
  tmp___0 = list_empty((struct list_head  const  *)(& rxf->mcast_pending_add_q));
  if (tmp___0 == 0) {
    __mptr___0 = (struct list_head  const  *)rxf->mcast_pending_add_q.next;
    mac = (struct bna_mac *)__mptr___0;
    list_move_tail(& mac->qe, & rxf->mcast_active_q);
    bna_bfi_mcast_add_req(rxf, mac);
    return (1);
  } else {

  }
  return (0);
}
}
static int bna_rxf_vlan_cfg_apply(struct bna_rxf *rxf ) 
{ 
  u8 vlan_pending_bitmask ;
  int block_idx ;
    klee_make_symbolic(&block_idx, sizeof(int), "block_idx");

  {
  block_idx = 0;
  if ((unsigned int )rxf->vlan_pending_bitmask != 0U) {
    vlan_pending_bitmask = rxf->vlan_pending_bitmask;
    goto ldv_49339;
    ldv_49338: 
    block_idx = block_idx + 1;
    vlan_pending_bitmask = (u8 )((int )vlan_pending_bitmask >> 1);
    ldv_49339: ;
    if (((int )vlan_pending_bitmask & 1) == 0) {
      goto ldv_49338;
    } else {

    }
    rxf->vlan_pending_bitmask = (int )rxf->vlan_pending_bitmask & ~ ((int )((u8 )(1UL << block_idx)));
    bna_bfi_rx_vlan_filter_set(rxf, (int )((u8 )block_idx));
    return (1);
  } else {

  }
  return (0);
}
}
static int bna_rxf_mcast_cfg_reset(struct bna_rxf *rxf , enum bna_cleanup_type cleanup ) 
{ 
  struct bna_mac *mac ;
  int ret ;
  struct list_head  const  *__mptr ;
  int tmp ;
  struct list_head  const  *__mptr___0 ;
  int tmp___0 ;
  int tmp___1 ;

  {
  goto ldv_49350;
  ldv_49349: 
  __mptr = (struct list_head  const  *)rxf->mcast_pending_del_q.next;
  mac = (struct bna_mac *)__mptr;
  ret = bna_rxf_mcast_del(rxf, mac, cleanup);
  list_move_tail(& mac->qe, & ((rxf->rx)->bna)->mcam_mod.del_q);
  if (ret != 0) {
    return (ret);
  } else {

  }
  ldv_49350: 
  tmp = list_empty((struct list_head  const  *)(& rxf->mcast_pending_del_q));
  if (tmp == 0) {
    goto ldv_49349;
  } else {

  }

  goto ldv_49355;
  ldv_49354: 
  __mptr___0 = (struct list_head  const  *)rxf->mcast_active_q.next;
  mac = (struct bna_mac *)__mptr___0;
  list_move_tail(& mac->qe, & rxf->mcast_pending_add_q);
  tmp___0 = bna_rxf_mcast_del(rxf, mac, cleanup);
  if (tmp___0 != 0) {
    return (1);
  } else {

  }
  ldv_49355: 
  tmp___1 = list_empty((struct list_head  const  *)(& rxf->mcast_active_q));
  if (tmp___1 == 0) {
    goto ldv_49354;
  } else {

  }

  return (0);
}
}
static int bna_rxf_rss_cfg_apply(struct bna_rxf *rxf ) 
{ 


  {
  if ((unsigned int )rxf->rss_pending != 0U) {
    if ((int )rxf->rss_pending & 1) {
      rxf->rss_pending = (enum bna_rss_flags )((unsigned int )rxf->rss_pending & 4294967294U);
      bna_bfi_rit_cfg(rxf);
      return (1);
    } else {

    }
    if (((unsigned int )rxf->rss_pending & 2U) != 0U) {
      rxf->rss_pending = (enum bna_rss_flags )((unsigned int )rxf->rss_pending & 4294967293U);
      bna_bfi_rss_cfg(rxf);
      return (1);
    } else {

    }
    if (((unsigned int )rxf->rss_pending & 4U) != 0U) {
      rxf->rss_pending = (enum bna_rss_flags )((unsigned int )rxf->rss_pending & 4294967291U);
      bna_bfi_rss_enable(rxf);
      return (1);
    } else {

    }
  } else {

  }
  return (0);
}
}
static int bna_rxf_cfg_apply(struct bna_rxf *rxf ) 
{ 
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;

  {
  tmp = bna_rxf_ucast_cfg_apply(rxf);
  if (tmp != 0) {
    return (1);
  } else {

  }
  tmp___0 = bna_rxf_mcast_cfg_apply(rxf);
  if (tmp___0 != 0) {
    return (1);
  } else {

  }
  tmp___1 = bna_rxf_promisc_cfg_apply(rxf);
  if (tmp___1 != 0) {
    return (1);
  } else {

  }
  tmp___2 = bna_rxf_allmulti_cfg_apply(rxf);
  if (tmp___2 != 0) {
    return (1);
  } else {

  }
  tmp___3 = bna_rxf_vlan_cfg_apply(rxf);
  if (tmp___3 != 0) {
    return (1);
  } else {

  }
  tmp___4 = bna_rxf_vlan_strip_cfg_apply(rxf);
  if (tmp___4 != 0) {
    return (1);
  } else {

  }
  tmp___5 = bna_rxf_rss_cfg_apply(rxf);
  if (tmp___5 != 0) {
    return (1);
  } else {

  }
  return (0);
}
}
static void bna_rxf_cfg_reset(struct bna_rxf *rxf ) 
{ 


  {
  bna_rxf_ucast_cfg_reset(rxf, 1);
  bna_rxf_mcast_cfg_reset(rxf, 1);
  bna_rxf_promisc_cfg_reset(rxf, 1);
  bna_rxf_allmulti_cfg_reset(rxf, 1);
  rxf->vlan_pending_bitmask = 255U;
  rxf->vlan_strip_pending = 1;
  if ((unsigned int )rxf->rss_status == 1U) {
    rxf->rss_pending = 7;
  } else {

  }
  return;
}
}
static void bna_rit_init(struct bna_rxf *rxf , int rit_size ) 
{ 
  struct bna_rx *rx ;
  struct bna_rxp *rxp ;
  int offset ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  rx = rxf->rx;
  offset = 0;
  rxf->rit_size = rit_size;
  __mptr = (struct list_head  const  *)rx->rxp_q.next;
  rxp = (struct bna_rxp *)__mptr;
  goto ldv_49378;
  ldv_49377: 
  *(rxf->rit + (unsigned long )offset) = (u8 )(rxp->cq.ccb)->id;
  offset = offset + 1;
  __mptr___0 = (struct list_head  const  *)rxp->qe.next;
  rxp = (struct bna_rxp *)__mptr___0;
  ldv_49378: ;
  if ((unsigned long )(& rxp->qe) != (unsigned long )(& rx->rxp_q)) {
    goto ldv_49377;
  } else {

  }

  return;
}
}
void bna_bfi_rxf_cfg_rsp(struct bna_rxf *rxf , struct bfi_msgq_mhdr *msghdr ) 
{ 


  {
  (*(rxf->fsm))((void *)rxf, 7);
  return;
}
}
void bna_bfi_rxf_ucast_set_rsp(struct bna_rxf *rxf , struct bfi_msgq_mhdr *msghdr ) 
{ 
  struct bfi_enet_rsp *rsp ;
  struct bfi_msgq_mhdr  const  *__mptr ;

  {
  __mptr = (struct bfi_msgq_mhdr  const  *)msghdr;
  rsp = (struct bfi_enet_rsp *)__mptr;
  if ((unsigned int )rsp->error != 0U) {
    rxf->ucast_active_set = 0;
  } else {

  }
  (*(rxf->fsm))((void *)rxf, 7);
  return;
}
}
void bna_bfi_rxf_mcast_add_rsp(struct bna_rxf *rxf , struct bfi_msgq_mhdr *msghdr ) 
{ 
  struct bfi_enet_mcast_add_req *req ;
  struct bfi_enet_mcast_add_rsp *rsp ;
  struct bfi_msgq_mhdr  const  *__mptr ;
  __u16 tmp ;

  {
  req = & rxf->bfi_enet_cmd.mcast_add_req;
  __mptr = (struct bfi_msgq_mhdr  const  *)msghdr;
  rsp = (struct bfi_enet_mcast_add_rsp *)__mptr;
  tmp = __fswab16((int )rsp->handle);
  bna_rxf_mchandle_attach(rxf, (u8 *)(& req->mac_addr), (int )tmp);
  (*(rxf->fsm))((void *)rxf, 7);
  return;
}
}
static void bna_rxf_init(struct bna_rxf *rxf , struct bna_rx *rx , struct bna_rx_config *q_config ,
                         struct bna_res_info *res_info ) 
{ 


  {
  rxf->rx = rx;
  INIT_LIST_HEAD(& rxf->ucast_pending_add_q);
  INIT_LIST_HEAD(& rxf->ucast_pending_del_q);
  rxf->ucast_pending_set = 0;
  rxf->ucast_active_set = 0;
  INIT_LIST_HEAD(& rxf->ucast_active_q);
  rxf->ucast_pending_mac = (struct bna_mac *)0;
  INIT_LIST_HEAD(& rxf->mcast_pending_add_q);
  INIT_LIST_HEAD(& rxf->mcast_pending_del_q);
  INIT_LIST_HEAD(& rxf->mcast_active_q);
  INIT_LIST_HEAD(& rxf->mcast_handle_q);
  rxf->rit = (u8 *)((res_info + 14UL)->res_u.mem_info.mdl)->kva;
  bna_rit_init(rxf, q_config->num_paths);
  rxf->rss_status = q_config->rss_status;
  if ((unsigned int )rxf->rss_status == 1U) {
    rxf->rss_cfg = q_config->rss_config;
    rxf->rss_pending = (enum bna_rss_flags )((unsigned int )rxf->rss_pending | 2U);
    rxf->rss_pending = (enum bna_rss_flags )((unsigned int )rxf->rss_pending | 1U);
    rxf->rss_pending = (enum bna_rss_flags )((unsigned int )rxf->rss_pending | 4U);
  } else {

  }
  rxf->vlan_filter_status = 0;
  memset((void *)(& rxf->vlan_filter_table), 0, 512UL);
  rxf->vlan_filter_table[0] = rxf->vlan_filter_table[0] | 1U;
  rxf->vlan_pending_bitmask = 255U;
  rxf->vlan_strip_status = q_config->vlan_strip_status;
  rxf->fsm = (void (*)(void * , int  ))(& bna_rxf_sm_stopped);
  bna_rxf_sm_stopped_entry(rxf);
  return;
}
}
static void bna_rxf_uninit(struct bna_rxf *rxf ) 
{ 
  struct bna_mac *mac ;
  struct list_head  const  *__mptr ;
  int tmp ;
  struct list_head  const  *__mptr___0 ;
  int tmp___0 ;

  {
  rxf->ucast_pending_set = 0;
  rxf->ucast_active_set = 0;
  goto ldv_49412;
  ldv_49411: 
  __mptr = (struct list_head  const  *)rxf->ucast_pending_add_q.next;
  mac = (struct bna_mac *)__mptr;
  list_move_tail(& mac->qe, & ((rxf->rx)->bna)->ucam_mod.free_q);
  ldv_49412: 
  tmp = list_empty((struct list_head  const  *)(& rxf->ucast_pending_add_q));
  if (tmp == 0) {
    goto ldv_49411;
  } else {

  }

  if ((unsigned long )rxf->ucast_pending_mac != (unsigned long )((struct bna_mac *)0)) {
    list_add_tail(& (rxf->ucast_pending_mac)->qe, & ((rxf->rx)->bna)->ucam_mod.free_q);
    rxf->ucast_pending_mac = (struct bna_mac *)0;
  } else {

  }
  goto ldv_49417;
  ldv_49416: 
  __mptr___0 = (struct list_head  const  *)rxf->mcast_pending_add_q.next;
  mac = (struct bna_mac *)__mptr___0;
  list_move_tail(& mac->qe, & ((rxf->rx)->bna)->mcam_mod.free_q);
  ldv_49417: 
  tmp___0 = list_empty((struct list_head  const  *)(& rxf->mcast_pending_add_q));
  if (tmp___0 == 0) {
    goto ldv_49416;
  } else {

  }
  rxf->rxmode_pending = 0;
  rxf->rxmode_pending_bitmask = 0;
  if (((rxf->rx)->bna)->promisc_rid == (rxf->rx)->rid) {
    ((rxf->rx)->bna)->promisc_rid = -1;
  } else {

  }
  if (((rxf->rx)->bna)->default_mode_rid == (rxf->rx)->rid) {
    ((rxf->rx)->bna)->default_mode_rid = -1;
  } else {

  }
  rxf->rss_pending = 0;
  rxf->vlan_strip_pending = 0;
  rxf->rx = (struct bna_rx *)0;
  return;
}
}
static void bna_rx_cb_rxf_started(struct bna_rx *rx ) 
{ 


  {
  (*(rx->fsm))((void *)rx, 6);
  return;
}
}
static void bna_rxf_start(struct bna_rxf *rxf ) 
{ 


  {
  rxf->start_cbfn = & bna_rx_cb_rxf_started;
  rxf->start_cbarg = rxf->rx;
  (*(rxf->fsm))((void *)rxf, 1);
  return;
}
}
static void bna_rx_cb_rxf_stopped(struct bna_rx *rx ) 
{ 


  {
  (*(rx->fsm))((void *)rx, 7);
  return;
}
}
static void bna_rxf_stop(struct bna_rxf *rxf ) 
{ 


  {
  rxf->stop_cbfn = & bna_rx_cb_rxf_stopped;
  rxf->stop_cbarg = rxf->rx;
  (*(rxf->fsm))((void *)rxf, 2);
  return;
}
}
static void bna_rxf_fail(struct bna_rxf *rxf ) 
{ 


  {
  (*(rxf->fsm))((void *)rxf, 3);
  return;
}
}
enum bna_cb_status bna_rx_ucast_set(struct bna_rx *rx , u8 const   *ucmac ) 
{ 
  struct bna_rxf *rxf ;

  {
  rxf = & rx->rxf;
  if ((unsigned long )rxf->ucast_pending_mac == (unsigned long )((struct bna_mac *)0)) {
    rxf->ucast_pending_mac = bna_cam_mod_mac_get(& ((rxf->rx)->bna)->ucam_mod.free_q);
    if ((unsigned long )rxf->ucast_pending_mac == (unsigned long )((struct bna_mac *)0)) {
      return (6);
    } else {

    }
  } else {

  }
  ether_addr_copy((u8 *)(& (rxf->ucast_pending_mac)->addr), ucmac);
  rxf->ucast_pending_set = 1;
  rxf->cam_fltr_cbfn = (void (*)(struct bnad * , struct bna_rx * ))0;
  rxf->cam_fltr_cbarg = (rx->bna)->bnad;
  (*(rxf->fsm))((void *)rxf, 4);
  return (0);
}
}
enum bna_cb_status bna_rx_mcast_add(struct bna_rx *rx , u8 const   *addr , void (*cbfn)(struct bnad * ,
                                                                                        struct bna_rx * ) ) 
{ 
  struct bna_rxf *rxf ;
  struct bna_mac *mac ;
  struct bna_mac *tmp ;
  struct bna_mac *tmp___0 ;

  {
  rxf = & rx->rxf;
  tmp = bna_mac_find(& rxf->mcast_active_q, addr);
  if ((unsigned long )tmp != (unsigned long )((struct bna_mac *)0)) {
    goto _L;
  } else {
    tmp___0 = bna_mac_find(& rxf->mcast_pending_add_q, addr);
    if ((unsigned long )tmp___0 != (unsigned long )((struct bna_mac *)0)) {
      _L: /* CIL Label */ 
      if ((unsigned long )cbfn != (unsigned long )((void (*)(struct bnad * , struct bna_rx * ))0)) {
        (*cbfn)((rx->bna)->bnad, rx);
      } else {

      }
      return (0);
    } else {

    }
  }
  mac = bna_cam_mod_mac_get(& ((rxf->rx)->bna)->mcam_mod.free_q);
  if ((unsigned long )mac == (unsigned long )((struct bna_mac *)0)) {
    return (5);
  } else {

  }
  ether_addr_copy((u8 *)(& mac->addr), addr);
  list_add_tail(& mac->qe, & rxf->mcast_pending_add_q);
  rxf->cam_fltr_cbfn = cbfn;
  rxf->cam_fltr_cbarg = (rx->bna)->bnad;
  (*(rxf->fsm))((void *)rxf, 4);
  return (0);
}
}
enum bna_cb_status bna_rx_ucast_listset(struct bna_rx *rx , int count , u8 const   *uclist ) 
{ 
  struct bna_ucam_mod *ucam_mod ;
  struct bna_rxf *rxf ;
  struct list_head list_head ;
  u8 const   *mcaddr ;
  struct bna_mac *mac ;
  struct bna_mac *del_mac ;
  int i ;
  struct list_head  const  *__mptr ;
  int tmp ;
  struct list_head  const  *__mptr___0 ;
  int tmp___0 ;
  struct list_head  const  *__mptr___1 ;
  int tmp___1 ;
  struct list_head  const  *__mptr___2 ;
  int tmp___2 ;

  {
  ucam_mod = & (rx->bna)->ucam_mod;
  rxf = & rx->rxf;
  goto ldv_49463;
  ldv_49462: 
  __mptr = (struct list_head  const  *)rxf->ucast_pending_add_q.next;
  mac = (struct bna_mac *)__mptr;
  list_move_tail(& mac->qe, & ucam_mod->free_q);
  ldv_49463: 
  tmp = list_empty((struct list_head  const  *)(& rxf->ucast_pending_add_q));
  if (tmp == 0) {
    goto ldv_49462;
  } else {

  }

  goto ldv_49468;
  ldv_49467: 
  __mptr___0 = (struct list_head  const  *)rxf->ucast_active_q.next;
  mac = (struct bna_mac *)__mptr___0;
  del_mac = bna_cam_mod_mac_get(& ucam_mod->del_q);
  ether_addr_copy((u8 *)(& del_mac->addr), (u8 const   *)(& mac->addr));
  del_mac->handle = mac->handle;
  list_add_tail(& del_mac->qe, & rxf->ucast_pending_del_q);
  list_move_tail(& mac->qe, & ucam_mod->free_q);
  ldv_49468: 
  tmp___0 = list_empty((struct list_head  const  *)(& rxf->ucast_active_q));
  if (tmp___0 == 0) {
    goto ldv_49467;
  } else {

  }
  INIT_LIST_HEAD(& list_head);
  i = 0;
  mcaddr = uclist;
  goto ldv_49472;
  ldv_49471: 
  mac = bna_cam_mod_mac_get(& ucam_mod->free_q);
  if ((unsigned long )mac == (unsigned long )((struct bna_mac *)0)) {
    goto err_return;
  } else {

  }
  ether_addr_copy((u8 *)(& mac->addr), mcaddr);
  list_add_tail(& mac->qe, & list_head);
  mcaddr = mcaddr + 6UL;
  i = i + 1;
  ldv_49472: ;
  if (i < count) {
    goto ldv_49471;
  } else {

  }

  goto ldv_49477;
  ldv_49476: 
  __mptr___1 = (struct list_head  const  *)list_head.next;
  mac = (struct bna_mac *)__mptr___1;
  list_move_tail(& mac->qe, & rxf->ucast_pending_add_q);
  ldv_49477: 
  tmp___1 = list_empty((struct list_head  const  *)(& list_head));
  if (tmp___1 == 0) {
    goto ldv_49476;
  } else {

  }
  (*(rxf->fsm))((void *)rxf, 4);
  return (0);
  err_return: ;
  goto ldv_49482;
  ldv_49481: 
  __mptr___2 = (struct list_head  const  *)list_head.next;
  mac = (struct bna_mac *)__mptr___2;
  list_move_tail(& mac->qe, & ucam_mod->free_q);
  ldv_49482: 
  tmp___2 = list_empty((struct list_head  const  *)(& list_head));
  if (tmp___2 == 0) {
    goto ldv_49481;
  } else {

  }

  return (6);
}
}
enum bna_cb_status bna_rx_mcast_listset(struct bna_rx *rx , int count , u8 const   *mclist ) 
{ 
  struct bna_mcam_mod *mcam_mod ;
  struct bna_rxf *rxf ;
  struct list_head list_head ;
  u8 const   *mcaddr ;
  struct bna_mac *mac ;
  struct bna_mac *del_mac ;
  int i ;
  struct list_head  const  *__mptr ;
  int tmp ;
  struct list_head  const  *__mptr___0 ;
  int tmp___0 ;
  struct list_head  const  *__mptr___1 ;
  int tmp___1 ;
  struct list_head  const  *__mptr___2 ;
  int tmp___2 ;

  {
  mcam_mod = & (rx->bna)->mcam_mod;
  rxf = & rx->rxf;
  goto ldv_49499;
  ldv_49498: 
  __mptr = (struct list_head  const  *)rxf->mcast_pending_add_q.next;
  mac = (struct bna_mac *)__mptr;
  list_move_tail(& mac->qe, & mcam_mod->free_q);
  ldv_49499: 
  tmp = list_empty((struct list_head  const  *)(& rxf->mcast_pending_add_q));
  if (tmp == 0) {
    goto ldv_49498;
  } else {

  }

  goto ldv_49504;
  ldv_49503: 
  __mptr___0 = (struct list_head  const  *)rxf->mcast_active_q.next;
  mac = (struct bna_mac *)__mptr___0;
  del_mac = bna_cam_mod_mac_get(& mcam_mod->del_q);
  ether_addr_copy((u8 *)(& del_mac->addr), (u8 const   *)(& mac->addr));
  del_mac->handle = mac->handle;
  list_add_tail(& del_mac->qe, & rxf->mcast_pending_del_q);
  mac->handle = (struct bna_mcam_handle *)0;
  list_move_tail(& mac->qe, & mcam_mod->free_q);
  ldv_49504: 
  tmp___0 = list_empty((struct list_head  const  *)(& rxf->mcast_active_q));
  if (tmp___0 == 0) {
    goto ldv_49503;
  } else {

  }
  INIT_LIST_HEAD(& list_head);
  i = 0;
  mcaddr = mclist;
  goto ldv_49508;
  ldv_49507: 
  mac = bna_cam_mod_mac_get(& mcam_mod->free_q);
  if ((unsigned long )mac == (unsigned long )((struct bna_mac *)0)) {
    goto err_return;
  } else {

  }
  ether_addr_copy((u8 *)(& mac->addr), mcaddr);
  list_add_tail(& mac->qe, & list_head);
  mcaddr = mcaddr + 6UL;
  i = i + 1;
  ldv_49508: ;
  if (i < count) {
    goto ldv_49507;
  } else {

  }

  goto ldv_49513;
  ldv_49512: 
  __mptr___1 = (struct list_head  const  *)list_head.next;
  mac = (struct bna_mac *)__mptr___1;
  list_move_tail(& mac->qe, & rxf->mcast_pending_add_q);
  ldv_49513: 
  tmp___1 = list_empty((struct list_head  const  *)(& list_head));
  if (tmp___1 == 0) {
    goto ldv_49512;
  } else {

  }
  (*(rxf->fsm))((void *)rxf, 4);
  return (0);
  err_return: ;
  goto ldv_49518;
  ldv_49517: 
  __mptr___2 = (struct list_head  const  *)list_head.next;
  mac = (struct bna_mac *)__mptr___2;
  list_move_tail(& mac->qe, & mcam_mod->free_q);
  ldv_49518: 
  tmp___2 = list_empty((struct list_head  const  *)(& list_head));
  if (tmp___2 == 0) {
    goto ldv_49517;
  } else {

  }

  return (5);
}
}
void bna_rx_mcast_delall(struct bna_rx *rx ) 
{ 
  struct bna_rxf *rxf ;
  struct bna_mac *mac ;
  struct bna_mac *del_mac ;
  int need_hw_config ;
    klee_make_symbolic(&need_hw_config, sizeof(int), "need_hw_config");
  struct list_head  const  *__mptr ;
  int tmp ;
  struct list_head  const  *__mptr___0 ;
  int tmp___0 ;

  {
  rxf = & rx->rxf;
  need_hw_config = 0;
  goto ldv_49530;
  ldv_49529: 
  __mptr = (struct list_head  const  *)rxf->mcast_pending_add_q.next;
  mac = (struct bna_mac *)__mptr;
  list_move_tail(& mac->qe, & ((rxf->rx)->bna)->mcam_mod.free_q);
  ldv_49530: 
  tmp = list_empty((struct list_head  const  *)(& rxf->mcast_pending_add_q));
  if (tmp == 0) {
    goto ldv_49529;
  } else {

  }

  goto ldv_49535;
  ldv_49534: 
  __mptr___0 = (struct list_head  const  *)rxf->mcast_active_q.next;
  mac = (struct bna_mac *)__mptr___0;
  list_del(& mac->qe);
  del_mac = bna_cam_mod_mac_get(& ((rxf->rx)->bna)->mcam_mod.del_q);
  memcpy((void *)del_mac, (void const   *)mac, 32UL);
  list_add_tail(& del_mac->qe, & rxf->mcast_pending_del_q);
  mac->handle = (struct bna_mcam_handle *)0;
  list_add_tail(& mac->qe, & ((rxf->rx)->bna)->mcam_mod.free_q);
  need_hw_config = 1;
  ldv_49535: 
  tmp___0 = list_empty((struct list_head  const  *)(& rxf->mcast_active_q));
  if (tmp___0 == 0) {
    goto ldv_49534;
  } else {

  }

  if (need_hw_config != 0) {
    (*(rxf->fsm))((void *)rxf, 4);
  } else {

  }
  return;
}
}
void bna_rx_vlan_add(struct bna_rx *rx , int vlan_id ) 
{ 
  struct bna_rxf *rxf ;
  int index ;
  int bit ;
    klee_make_symbolic(&bit, sizeof(int), "bit");
  int group_id ;
    klee_make_symbolic(&group_id, sizeof(int), "group_id");

  {
  rxf = & rx->rxf;
  index = vlan_id >> 5;
  bit = (int )(1UL << (vlan_id & 31));
  group_id = vlan_id >> 9;
  rxf->vlan_filter_table[index] = rxf->vlan_filter_table[index] | (u32 )bit;
  if ((unsigned int )rxf->vlan_filter_status == 1U) {
    rxf->vlan_pending_bitmask = (int )rxf->vlan_pending_bitmask | (int )((u8 )(1UL << group_id));
    (*(rxf->fsm))((void *)rxf, 4);
  } else {

  }
  return;
}
}
void bna_rx_vlan_del(struct bna_rx *rx , int vlan_id ) 
{ 
  struct bna_rxf *rxf ;
  int index ;
  int bit ;
  int group_id ;

  {
  rxf = & rx->rxf;
  index = vlan_id >> 5;
  bit = (int )(1UL << (vlan_id & 31));
  group_id = vlan_id >> 9;
  rxf->vlan_filter_table[index] = rxf->vlan_filter_table[index] & (u32 )(~ bit);
  if ((unsigned int )rxf->vlan_filter_status == 1U) {
    rxf->vlan_pending_bitmask = (int )rxf->vlan_pending_bitmask | (int )((u8 )(1UL << group_id));
    (*(rxf->fsm))((void *)rxf, 4);
  } else {

  }
  return;
}
}
static int bna_rxf_ucast_cfg_apply(struct bna_rxf *rxf ) 
{ 
  struct bna_mac *mac ;
  struct list_head  const  *__mptr ;
  int tmp ;
  struct list_head  const  *__mptr___0 ;
  int tmp___0 ;

  {
  mac = (struct bna_mac *)0;
  tmp = list_empty((struct list_head  const  *)(& rxf->ucast_pending_del_q));
  if (tmp == 0) {
    __mptr = (struct list_head  const  *)rxf->ucast_pending_del_q.next;
    mac = (struct bna_mac *)__mptr;
    bna_bfi_ucast_req(rxf, mac, 11);
    list_move_tail(& mac->qe, & ((rxf->rx)->bna)->ucam_mod.del_q);
    return (1);
  } else {

  }
  if (rxf->ucast_pending_set != 0) {
    rxf->ucast_pending_set = 0;
    ether_addr_copy((u8 *)(& rxf->ucast_active_mac.addr), (u8 const   *)(& (rxf->ucast_pending_mac)->addr));
    rxf->ucast_active_set = 1;
    bna_bfi_ucast_req(rxf, & rxf->ucast_active_mac, 8);
    return (1);
  } else {

  }
  tmp___0 = list_empty((struct list_head  const  *)(& rxf->ucast_pending_add_q));
  if (tmp___0 == 0) {
    __mptr___0 = (struct list_head  const  *)rxf->ucast_pending_add_q.next;
    mac = (struct bna_mac *)__mptr___0;
    list_add_tail(& mac->qe, & rxf->ucast_active_q);
    bna_bfi_ucast_req(rxf, mac, 10);
    return (1);
  } else {

  }
  return (0);
}
}
static int bna_rxf_ucast_cfg_reset(struct bna_rxf *rxf , enum bna_cleanup_type cleanup ) 
{ 
  struct bna_mac *mac ;
  struct list_head  const  *__mptr ;
  int tmp ;
  struct list_head  const  *__mptr___0 ;
  int tmp___0 ;

  {
  goto ldv_49569;
  ldv_49568: 
  __mptr = (struct list_head  const  *)rxf->ucast_pending_del_q.next;
  mac = (struct bna_mac *)__mptr;
  if ((unsigned int )cleanup == 1U) {
    list_move_tail(& mac->qe, & ((rxf->rx)->bna)->ucam_mod.del_q);
  } else {
    bna_bfi_ucast_req(rxf, mac, 11);
    list_move_tail(& mac->qe, & ((rxf->rx)->bna)->ucam_mod.del_q);
    return (1);
  }
  ldv_49569: 
  tmp = list_empty((struct list_head  const  *)(& rxf->ucast_pending_del_q));
  if (tmp == 0) {
    goto ldv_49568;
  } else {

  }

  goto ldv_49574;
  ldv_49573: 
  __mptr___0 = (struct list_head  const  *)rxf->ucast_active_q.next;
  mac = (struct bna_mac *)__mptr___0;
  list_move_tail(& mac->qe, & rxf->ucast_pending_add_q);
  if ((unsigned int )cleanup == 0U) {
    bna_bfi_ucast_req(rxf, mac, 11);
    return (1);
  } else {

  }
  ldv_49574: 
  tmp___0 = list_empty((struct list_head  const  *)(& rxf->ucast_active_q));
  if (tmp___0 == 0) {
    goto ldv_49573;
  } else {

  }

  if (rxf->ucast_active_set != 0) {
    rxf->ucast_pending_set = 1;
    rxf->ucast_active_set = 0;
    if ((unsigned int )cleanup == 0U) {
      bna_bfi_ucast_req(rxf, & rxf->ucast_active_mac, 9);
      return (1);
    } else {

    }
  } else {

  }
  return (0);
}
}
static int bna_rxf_promisc_cfg_apply(struct bna_rxf *rxf ) 
{ 
  struct bna *bna ;

  {
  bna = (rxf->rx)->bna;
  if ((int )rxf->rxmode_pending_bitmask & 1 && (int )rxf->rxmode_pending & 1) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967294U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967294U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active | 1U);
    bna_bfi_rx_promisc_req(rxf, 1);
    return (1);
  } else
  if ((int )rxf->rxmode_pending_bitmask & 1 && ((unsigned int )rxf->rxmode_pending & 1U) == 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967294U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967294U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active & 4294967294U);
    bna->promisc_rid = -1;
    bna_bfi_rx_promisc_req(rxf, 0);
    return (1);
  } else {

  }
  return (0);
}
}
static int bna_rxf_promisc_cfg_reset(struct bna_rxf *rxf , enum bna_cleanup_type cleanup ) 
{ 
  struct bna *bna ;

  {
  bna = (rxf->rx)->bna;
  if ((int )rxf->rxmode_pending_bitmask & 1 && ((unsigned int )rxf->rxmode_pending & 1U) == 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967294U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967294U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active & 4294967294U);
    bna->promisc_rid = -1;
    if ((unsigned int )cleanup == 0U) {
      bna_bfi_rx_promisc_req(rxf, 0);
      return (1);
    } else {

    }
  } else {

  }
  if ((int )rxf->rxmode_active & 1) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask | 1U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending | 1U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active & 4294967294U);
    if ((unsigned int )cleanup == 0U) {
      bna_bfi_rx_promisc_req(rxf, 0);
      return (1);
    } else {

    }
  } else {

  }
  return (0);
}
}
static int bna_rxf_allmulti_cfg_apply(struct bna_rxf *rxf ) 
{ 


  {
  if (((unsigned int )rxf->rxmode_pending_bitmask & 4U) != 0U && ((unsigned int )rxf->rxmode_pending & 4U) != 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967291U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967291U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active | 4U);
    bna_bfi_mcast_filter_req(rxf, 0);
    return (1);
  } else
  if (((unsigned int )rxf->rxmode_pending_bitmask & 4U) != 0U && ((unsigned int )rxf->rxmode_pending & 4U) == 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967291U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967291U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active & 4294967291U);
    bna_bfi_mcast_filter_req(rxf, 1);
    return (1);
  } else {

  }
  return (0);
}
}
static int bna_rxf_allmulti_cfg_reset(struct bna_rxf *rxf , enum bna_cleanup_type cleanup ) 
{ 


  {
  if (((unsigned int )rxf->rxmode_pending_bitmask & 4U) != 0U && ((unsigned int )rxf->rxmode_pending & 4U) == 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967291U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967291U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active & 4294967291U);
    if ((unsigned int )cleanup == 0U) {
      bna_bfi_mcast_filter_req(rxf, 1);
      return (1);
    } else {

    }
  } else {

  }
  if (((unsigned int )rxf->rxmode_active & 4U) != 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask | 4U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending | 4U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active & 4294967291U);
    if ((unsigned int )cleanup == 0U) {
      bna_bfi_mcast_filter_req(rxf, 1);
      return (1);
    } else {

    }
  } else {

  }
  return (0);
}
}
static int bna_rxf_promisc_enable(struct bna_rxf *rxf ) 
{ 
  struct bna *bna ;
  int ret ;

  {
  bna = (rxf->rx)->bna;
  ret = 0;
  if (((int )rxf->rxmode_pending_bitmask & 1 && (int )rxf->rxmode_pending & 1) || (int )rxf->rxmode_active & 1) {

  } else
  if ((int )rxf->rxmode_pending_bitmask & 1 && ((unsigned int )rxf->rxmode_pending & 1U) == 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967294U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967294U);
  } else {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask | 1U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending | 1U);
    bna->promisc_rid = (rxf->rx)->rid;
    ret = 1;
  }
  return (ret);
}
}
static int bna_rxf_promisc_disable(struct bna_rxf *rxf ) 
{ 
  struct bna *bna ;
  int ret ;

  {
  bna = (rxf->rx)->bna;
  ret = 0;
  if (((int )rxf->rxmode_pending_bitmask & 1 && ((unsigned int )rxf->rxmode_pending & 1U) == 0U) || ((unsigned int )rxf->rxmode_active & 1U) == 0U) {

  } else
  if ((int )rxf->rxmode_pending_bitmask & 1 && (int )rxf->rxmode_pending & 1) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967294U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967294U);
    bna->promisc_rid = -1;
  } else
  if ((int )rxf->rxmode_active & 1) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask | 1U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967294U);
    ret = 1;
  } else {

  }
  return (ret);
}
}
static int bna_rxf_allmulti_enable(struct bna_rxf *rxf ) 
{ 
  int ret ;

  {
  ret = 0;
  if ((((unsigned int )rxf->rxmode_pending_bitmask & 4U) != 0U && ((unsigned int )rxf->rxmode_pending & 4U) != 0U) || ((unsigned int )rxf->rxmode_active & 4U) != 0U) {

  } else
  if (((unsigned int )rxf->rxmode_pending_bitmask & 4U) != 0U && ((unsigned int )rxf->rxmode_pending & 4U) == 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967291U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967291U);
  } else {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask | 4U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending | 4U);
    ret = 1;
  }
  return (ret);
}
}
static int bna_rxf_allmulti_disable(struct bna_rxf *rxf ) 
{ 
  int ret ;

  {
  ret = 0;
  if ((((unsigned int )rxf->rxmode_pending_bitmask & 4U) != 0U && ((unsigned int )rxf->rxmode_pending & 4U) == 0U) || ((unsigned int )rxf->rxmode_active & 4U) == 0U) {

  } else
  if (((unsigned int )rxf->rxmode_pending_bitmask & 4U) != 0U && ((unsigned int )rxf->rxmode_pending & 4U) != 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967291U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967291U);
  } else
  if (((unsigned int )rxf->rxmode_active & 4U) != 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask | 4U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967291U);
    ret = 1;
  } else {

  }
  return (ret);
}
}
static int bna_rxf_vlan_strip_cfg_apply(struct bna_rxf *rxf ) 
{ 


  {
  if ((int )rxf->vlan_strip_pending) {
    rxf->vlan_strip_pending = 0;
    bna_bfi_vlan_strip_enable(rxf);
    return (1);
  } else {

  }
  return (0);
}
}
static void bna_bfi_rx_enet_start(struct bna_rx *rx ) ;
static void bna_rx_enet_stop(struct bna_rx *rx ) ;
static void bna_rx_mod_cb_rx_stopped(void *arg , struct bna_rx *rx ) ;
static void bna_rx_sm_stopped(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_stopped_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_start_wait(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_start_wait_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_start_stop_wait(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_start_stop_wait_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_rxf_start_wait(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_rxf_start_wait_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_started(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_started_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_rxf_stop_wait(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_rxf_stop_wait_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_stop_wait(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_stop_wait_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_cleanup_wait(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_cleanup_wait_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_failed(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_failed_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_quiesce_wait(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_quiesce_wait_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_stopped_entry(struct bna_rx *rx ) 
{ 
  void (*cbfn)(void * , struct bna_rx * ) ;
  void *cbarg ;

  {
  if ((unsigned long )rx->stop_cbfn != (unsigned long )((void (*)(void * , struct bna_rx * ))0)) {
    cbfn = rx->stop_cbfn;
    cbarg = rx->stop_cbarg;
    rx->stop_cbfn = (void (*)(void * , struct bna_rx * ))0;
    rx->stop_cbarg = (void *)0;
    (*cbfn)(cbarg, rx);
  } else {

  }
  return;
}
}
static void bna_rx_sm_stopped(struct bna_rx *rx , enum bna_rx_event event ) 
{ 
  void (*cbfn)(void * , struct bna_rx * ) ;
  void *cbarg ;

  {
  switch ((unsigned int )event) {
  case 1U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_start_wait);
  bna_rx_sm_start_wait_entry(rx);
  goto ldv_49682;
  case 2U: ;
  if ((unsigned long )rx->stop_cbfn != (unsigned long )((void (*)(void * , struct bna_rx * ))0)) {
    cbfn = rx->stop_cbfn;
    cbarg = rx->stop_cbarg;
    rx->stop_cbfn = (void (*)(void * , struct bna_rx * ))0;
    rx->stop_cbarg = (void *)0;
    (*cbfn)(cbarg, rx);
  } else {

  }
  goto ldv_49682;
  case 3U: ;
  goto ldv_49682;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1356, (unsigned int )event);
  goto ldv_49682;
  }
  ldv_49682: ;
  return;
}
}
static void bna_rx_sm_start_wait_entry(struct bna_rx *rx ) 
{ 


  {
  bna_bfi_rx_enet_start(rx);
  return;
}
}
static void bna_rx_sm_stop_wait_entry(struct bna_rx *rx ) 
{ 


  {
  return;
}
}
static void bna_rx_sm_stop_wait(struct bna_rx *rx , enum bna_rx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 5U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_cleanup_wait);
  bna_rx_sm_cleanup_wait_entry(rx);
  (*(rx->rx_cleanup_cbfn))((rx->bna)->bnad, rx);
  goto ldv_49702;
  case 4U: 
  bna_rx_enet_stop(rx);
  goto ldv_49702;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1386, (unsigned int )event);
  goto ldv_49702;
  }
  ldv_49702: ;
  return;
}
}
static void bna_rx_sm_start_wait(struct bna_rx *rx , enum bna_rx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_start_stop_wait);
  bna_rx_sm_start_stop_wait_entry(rx);
  goto ldv_49710;
  case 3U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_stopped);
  bna_rx_sm_stopped_entry(rx);
  goto ldv_49710;
  case 4U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_rxf_start_wait);
  bna_rx_sm_rxf_start_wait_entry(rx);
  goto ldv_49710;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1408, (unsigned int )event);
  goto ldv_49710;
  }
  ldv_49710: ;
  return;
}
}
static void bna_rx_sm_rxf_start_wait_entry(struct bna_rx *rx ) 
{ 


  {
  (*(rx->rx_post_cbfn))((rx->bna)->bnad, rx);
  bna_rxf_start(& rx->rxf);
  return;
}
}
static void bna_rx_sm_rxf_stop_wait_entry(struct bna_rx *rx ) 
{ 


  {
  return;
}
}
static void bna_rx_sm_rxf_stop_wait(struct bna_rx *rx , enum bna_rx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 3U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_cleanup_wait);
  bna_rx_sm_cleanup_wait_entry(rx);
  bna_rxf_fail(& rx->rxf);
  if ((unsigned long )rx->rx_stall_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                      struct bna_rx * ))0)) {
    (*(rx->rx_stall_cbfn))((rx->bna)->bnad, rx);
  } else {

  }
  (*(rx->rx_cleanup_cbfn))((rx->bna)->bnad, rx);
  goto ldv_49725;
  case 6U: 
  bna_rxf_stop(& rx->rxf);
  goto ldv_49725;
  case 7U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_stop_wait);
  bna_rx_sm_stop_wait_entry(rx);
  if ((unsigned long )rx->rx_stall_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                      struct bna_rx * ))0)) {
    (*(rx->rx_stall_cbfn))((rx->bna)->bnad, rx);
  } else {

  }
  bna_rx_enet_stop(rx);
  goto ldv_49725;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1446, (unsigned int )event);
  goto ldv_49725;
  }
  ldv_49725: ;
  return;
}
}
static void bna_rx_sm_start_stop_wait_entry(struct bna_rx *rx ) 
{ 


  {
  return;
}
}
static void bna_rx_sm_start_stop_wait(struct bna_rx *rx , enum bna_rx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 5U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_stopped);
  bna_rx_sm_stopped_entry(rx);
  goto ldv_49738;
  case 4U: 
  bna_rx_enet_stop(rx);
  goto ldv_49738;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1471, (unsigned int )event);
  }
  ldv_49738: ;
  return;
}
}
static void bna_rx_sm_started_entry(struct bna_rx *rx ) 
{ 
  struct bna_rxp *rxp ;
  int is_regular ;
    klee_make_symbolic(&is_regular, sizeof(int), "is_regular");
  struct list_head  const  *__mptr ;
  u32 intx_mask ;
  struct bna_ib *ib ;
  struct list_head  const  *__mptr___0 ;

  {
  is_regular = (unsigned int )rx->type == 0U;
  __mptr = (struct list_head  const  *)rx->rxp_q.next;
  rxp = (struct bna_rxp *)__mptr;
  goto ldv_49753;
  ldv_49752: 
  ib = & rxp->cq.ib;
  if ((unsigned int )ib->intr_type == 1U) {
    intx_mask = readl((void const volatile   *)(rx->bna)->regs.fn_int_mask);
    writel(4294967295U, (void volatile   *)(rx->bna)->regs.fn_int_mask);
    intx_mask = (u32 )(~ ib->intr_vector) & intx_mask;
    writel(intx_mask, (void volatile   *)(rx->bna)->regs.fn_int_mask);
  } else {

  }
  ib->door_bell.doorbell_ack = (unsigned int )((int )ib->coalescing_timeo << 16) | 2147483648U;
  if (is_regular != 0) {
    writel(ib->door_bell.doorbell_ack, (void volatile   *)ib->door_bell.doorbell_addr);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)rxp->qe.next;
  rxp = (struct bna_rxp *)__mptr___0;
  ldv_49753: ;
  if ((unsigned long )(& rxp->qe) != (unsigned long )(& rx->rxp_q)) {
    goto ldv_49752;
  } else {

  }
  bna_ethport_cb_rx_started(& (rx->bna)->ethport);
  return;
}
}
static void bna_rx_sm_started(struct bna_rx *rx , enum bna_rx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_rxf_stop_wait);
  bna_rx_sm_rxf_stop_wait_entry(rx);
  bna_ethport_cb_rx_stopped(& (rx->bna)->ethport);
  bna_rxf_stop(& rx->rxf);
  goto ldv_49760;
  case 3U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_failed);
  bna_rx_sm_failed_entry(rx);
  bna_ethport_cb_rx_stopped(& (rx->bna)->ethport);
  bna_rxf_fail(& rx->rxf);
  if ((unsigned long )rx->rx_stall_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                      struct bna_rx * ))0)) {
    (*(rx->rx_stall_cbfn))((rx->bna)->bnad, rx);
  } else {

  }
  (*(rx->rx_cleanup_cbfn))((rx->bna)->bnad, rx);
  goto ldv_49760;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1507, (unsigned int )event);
  goto ldv_49760;
  }
  ldv_49760: ;
  return;
}
}
static void bna_rx_sm_rxf_start_wait(struct bna_rx *rx , enum bna_rx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_rxf_stop_wait);
  bna_rx_sm_rxf_stop_wait_entry(rx);
  goto ldv_49768;
  case 3U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_failed);
  bna_rx_sm_failed_entry(rx);
  bna_rxf_fail(& rx->rxf);
  if ((unsigned long )rx->rx_stall_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                      struct bna_rx * ))0)) {
    (*(rx->rx_stall_cbfn))((rx->bna)->bnad, rx);
  } else {

  }
  (*(rx->rx_cleanup_cbfn))((rx->bna)->bnad, rx);
  goto ldv_49768;
  case 6U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_started);
  bna_rx_sm_started_entry(rx);
  goto ldv_49768;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1532, (unsigned int )event);
  goto ldv_49768;
  }
  ldv_49768: ;
  return;
}
}
static void bna_rx_sm_cleanup_wait_entry(struct bna_rx *rx ) 
{ 


  {
  return;
}
}
static void bna_rx_sm_cleanup_wait(struct bna_rx *rx , enum bna_rx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 7U: ;
  goto ldv_49781;
  case 8U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_stopped);
  bna_rx_sm_stopped_entry(rx);
  goto ldv_49781;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1556, (unsigned int )event);
  goto ldv_49781;
  }
  ldv_49781: ;
  return;
}
}
static void bna_rx_sm_failed_entry(struct bna_rx *rx ) 
{ 


  {
  return;
}
}
static void bna_rx_sm_failed(struct bna_rx *rx , enum bna_rx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 1U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_quiesce_wait);
  bna_rx_sm_quiesce_wait_entry(rx);
  goto ldv_49792;
  case 2U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_cleanup_wait);
  bna_rx_sm_cleanup_wait_entry(rx);
  goto ldv_49792;
  case 3U: ;
  case 6U: ;
  case 7U: ;
  goto ldv_49792;
  case 8U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_stopped);
  bna_rx_sm_stopped_entry(rx);
  goto ldv_49792;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1589, (unsigned int )event);
  goto ldv_49792;
  }
  ldv_49792: ;
  return;
}
}
static void bna_rx_sm_quiesce_wait_entry(struct bna_rx *rx ) 
{ 


  {
  return;
}
}
static void bna_rx_sm_quiesce_wait(struct bna_rx *rx , enum bna_rx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_cleanup_wait);
  bna_rx_sm_cleanup_wait_entry(rx);
  goto ldv_49807;
  case 3U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_failed);
  bna_rx_sm_failed_entry(rx);
  goto ldv_49807;
  case 8U: 
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_start_wait);
  bna_rx_sm_start_wait_entry(rx);
  goto ldv_49807;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1615, (unsigned int )event);
  goto ldv_49807;
  }
  ldv_49807: ;
  return;
}
}
static void bna_bfi_rx_enet_start(struct bna_rx *rx ) 
{ 
  struct bfi_enet_rx_cfg_req *cfg_req ;
  struct bna_rxp *rxp ;
  struct bna_rxq *q0 ;
  struct bna_rxq *q1 ;
  int i ;
  int tmp ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct bna_dma_addr cur_q_addr ;
  __u16 tmp___0 ;
  __u16 tmp___1 ;
  __u16 tmp___2 ;
  struct bna_dma_addr cur_q_addr___0 ;
  __u16 tmp___3 ;
  __u16 tmp___4 ;
  __u16 tmp___5 ;
  long tmp___6 ;
  struct bna_dma_addr cur_q_addr___1 ;
  __u16 tmp___7 ;
  __u16 tmp___8 ;
  __u16 tmp___9 ;
  __u32 tmp___10 ;
  __u32 tmp___11 ;
  long tmp___12 ;

  {
  cfg_req = & rx->bfi_enet_cmd.cfg_req;
  rxp = (struct bna_rxp *)0;
  q0 = (struct bna_rxq *)0;
  q1 = (struct bna_rxq *)0;
  cfg_req->mh.msg_class = 24U;
  cfg_req->mh.msg_id = 1U;
  cfg_req->mh.msg_token = 0U;
  cfg_req->mh.enet_id = (u8 )rx->rid;
  cfg_req->mh.num_entries = 5376U;
  tmp = bna_enet_mtu_get(& (rx->bna)->enet);
  cfg_req->rx_cfg.frame_size = (u16 )tmp;
  cfg_req->num_queue_sets = (u8 )rx->num_paths;
  i = 0;
  goto ldv_49837;
  ldv_49836: ;
  if ((unsigned long )rxp != (unsigned long )((struct bna_rxp *)0)) {
    __mptr = (struct list_head  const  *)rxp->qe.next;
    rxp = (struct bna_rxp *)__mptr;
  } else {
    __mptr___0 = (struct list_head  const  *)rx->rxp_q.next;
    rxp = (struct bna_rxp *)__mptr___0;
  }
  switch ((unsigned int )rxp->type) {
  case 1U: 
  q0 = rxp->rxq.single.only;
  q1 = (struct bna_rxq *)0;
  goto ldv_49824;
  case 2U: 
  q0 = rxp->rxq.slr.large;
  q1 = rxp->rxq.slr.small;
  goto ldv_49824;
  case 3U: 
  q0 = rxp->rxq.hds.data;
  q1 = rxp->rxq.hds.hdr;
  goto ldv_49824;
  }
  ldv_49824: ;
  switch ((unsigned int )rxp->type) {
  case 2U: ;
  case 3U: 
  cur_q_addr = *((struct bna_dma_addr *)q1->qpt.kv_qpt_ptr);
  cfg_req->q_cfg[i].qs.q.pg_tbl.a32.addr_lo = q1->qpt.hw_qpt_ptr.lsb;
  cfg_req->q_cfg[i].qs.q.pg_tbl.a32.addr_hi = q1->qpt.hw_qpt_ptr.msb;
  cfg_req->q_cfg[i].qs.q.first_entry.a32.addr_lo = cur_q_addr.lsb;
  cfg_req->q_cfg[i].qs.q.first_entry.a32.addr_hi = cur_q_addr.msb;
  tmp___0 = __fswab16((int )((unsigned short )q1->qpt.page_count));
  cfg_req->q_cfg[i].qs.q.pages = tmp___0;
  tmp___1 = __fswab16((int )((unsigned short )q1->qpt.page_size));
  cfg_req->q_cfg[i].qs.q.page_sz = tmp___1;
  tmp___2 = __fswab16((int )((unsigned short )q1->buffer_size));
  cfg_req->q_cfg[i].qs.rx_buffer_size = tmp___2;
  case 1U: 
  cur_q_addr___0 = *((struct bna_dma_addr *)q0->qpt.kv_qpt_ptr);
  cfg_req->q_cfg[i].ql.q.pg_tbl.a32.addr_lo = q0->qpt.hw_qpt_ptr.lsb;
  cfg_req->q_cfg[i].ql.q.pg_tbl.a32.addr_hi = q0->qpt.hw_qpt_ptr.msb;
  cfg_req->q_cfg[i].ql.q.first_entry.a32.addr_lo = cur_q_addr___0.lsb;
  cfg_req->q_cfg[i].ql.q.first_entry.a32.addr_hi = cur_q_addr___0.msb;
  tmp___3 = __fswab16((int )((unsigned short )q0->qpt.page_count));
  cfg_req->q_cfg[i].ql.q.pages = tmp___3;
  tmp___4 = __fswab16((int )((unsigned short )q0->qpt.page_size));
  cfg_req->q_cfg[i].ql.q.page_sz = tmp___4;
  if ((unsigned int )q0->multi_buffer != 0U) {
    cfg_req->rx_cfg.multi_buffer = 1U;
  } else {
    q0->buffer_size = bna_enet_mtu_get(& (rx->bna)->enet);
  }
  tmp___5 = __fswab16((int )((unsigned short )q0->buffer_size));
  cfg_req->q_cfg[i].ql.rx_buffer_size = tmp___5;
  goto ldv_49832;
  default: 
  tmp___6 = ldv__builtin_expect(1L, 0L);
  if (tmp___6 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c"),
                         "i" (1669), "i" (12UL));
    ldv_49834: ;
    goto ldv_49834;
  } else {

  }
  }
  ldv_49832: 
  cur_q_addr___1 = *((struct bna_dma_addr *)rxp->cq.qpt.kv_qpt_ptr);
  cfg_req->q_cfg[i].cq.q.pg_tbl.a32.addr_lo = rxp->cq.qpt.hw_qpt_ptr.lsb;
  cfg_req->q_cfg[i].cq.q.pg_tbl.a32.addr_hi = rxp->cq.qpt.hw_qpt_ptr.msb;
  cfg_req->q_cfg[i].cq.q.first_entry.a32.addr_lo = cur_q_addr___1.lsb;
  cfg_req->q_cfg[i].cq.q.first_entry.a32.addr_hi = cur_q_addr___1.msb;
  tmp___7 = __fswab16((int )((unsigned short )rxp->cq.qpt.page_count));
  cfg_req->q_cfg[i].cq.q.pages = tmp___7;
  tmp___8 = __fswab16((int )((unsigned short )rxp->cq.qpt.page_size));
  cfg_req->q_cfg[i].cq.q.page_sz = tmp___8;
  cfg_req->q_cfg[i].ib.index_addr.a32.addr_lo = rxp->cq.ib.ib_seg_host_addr.lsb;
  cfg_req->q_cfg[i].ib.index_addr.a32.addr_hi = rxp->cq.ib.ib_seg_host_addr.msb;
  tmp___9 = __fswab16((int )((unsigned short )rxp->cq.ib.intr_vector));
  cfg_req->q_cfg[i].ib.intr.msix_index = tmp___9;
  i = i + 1;
  ldv_49837: ;
  if (rx->num_paths > i) {
    goto ldv_49836;
  } else {

  }
  cfg_req->ib_cfg.int_pkt_dma = 0U;
  cfg_req->ib_cfg.int_enabled = 1U;
  cfg_req->ib_cfg.int_pkt_enabled = 0U;
  cfg_req->ib_cfg.continuous_coalescing = 0U;
  cfg_req->ib_cfg.msix = (unsigned int )rxp->cq.ib.intr_type == 2U;
  tmp___10 = __fswab32((unsigned int )rxp->cq.ib.coalescing_timeo);
  cfg_req->ib_cfg.coalescing_timeout = tmp___10;
  tmp___11 = __fswab32((unsigned int )rxp->cq.ib.interpkt_timeo);
  cfg_req->ib_cfg.inter_pkt_timeout = tmp___11;
  cfg_req->ib_cfg.inter_pkt_count = (unsigned char )rxp->cq.ib.interpkt_count;
  switch ((unsigned int )rxp->type) {
  case 2U: 
  cfg_req->rx_cfg.rxq_type = 2U;
  goto ldv_49840;
  case 3U: 
  cfg_req->rx_cfg.rxq_type = 3U;
  cfg_req->rx_cfg.hds.type = (u8 )rx->hds_cfg.hdr_type;
  cfg_req->rx_cfg.hds.force_offset = (u8 )rx->hds_cfg.forced_offset;
  cfg_req->rx_cfg.hds.max_header_size = (u8 )rx->hds_cfg.forced_offset;
  goto ldv_49840;
  case 1U: 
  cfg_req->rx_cfg.rxq_type = 1U;
  goto ldv_49840;
  default: 
  tmp___12 = ldv__builtin_expect(1L, 0L);
  if (tmp___12 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c"),
                         "i" (1713), "i" (12UL));
    ldv_49844: ;
    goto ldv_49844;
  } else {

  }
  }
  ldv_49840: 
  cfg_req->rx_cfg.strip_vlan = (u8 )rx->rxf.vlan_strip_status;
  rx->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  rx->msgq_cmd.cbarg = (void *)0;
  rx->msgq_cmd.msg_size = 1324UL;
  rx->msgq_cmd.msg_hdr = & cfg_req->mh;
  bfa_msgq_cmd_post(& (rx->bna)->msgq, & rx->msgq_cmd);
  return;
}
}
static void bna_bfi_rx_enet_stop(struct bna_rx *rx ) 
{ 
  struct bfi_enet_req *req ;

  {
  req = & rx->bfi_enet_cmd.req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 2U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )rx->rid;
  req->mh.num_entries = 256U;
  rx->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  rx->msgq_cmd.cbarg = (void *)0;
  rx->msgq_cmd.msg_size = 8UL;
  rx->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& (rx->bna)->msgq, & rx->msgq_cmd);
  return;
}
}
static void bna_rx_enet_stop(struct bna_rx *rx ) 
{ 
  struct bna_rxp *rxp ;
  struct list_head  const  *__mptr ;
  u32 intx_mask ;
  struct bna_ib *ib ;
  struct list_head  const  *__mptr___0 ;

  {
  __mptr = (struct list_head  const  *)rx->rxp_q.next;
  rxp = (struct bna_rxp *)__mptr;
  goto ldv_49860;
  ldv_49859: 
  ib = & rxp->cq.ib;
  writel(1073741824U, (void volatile   *)ib->door_bell.doorbell_addr);
  if ((unsigned int )ib->intr_type == 1U) {
    intx_mask = readl((void const volatile   *)(rx->bna)->regs.fn_int_mask);
    writel(4294967295U, (void volatile   *)(rx->bna)->regs.fn_int_mask);
    intx_mask = (u32 )ib->intr_vector | intx_mask;
    writel(intx_mask, (void volatile   *)(rx->bna)->regs.fn_int_mask);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)rxp->qe.next;
  rxp = (struct bna_rxp *)__mptr___0;
  ldv_49860: ;
  if ((unsigned long )(& rxp->qe) != (unsigned long )(& rx->rxp_q)) {
    goto ldv_49859;
  } else {

  }
  bna_bfi_rx_enet_stop(rx);
  return;
}
}
static int bna_rx_res_check(struct bna_rx_mod *rx_mod , struct bna_rx_config *rx_cfg ) 
{ 


  {
  if ((rx_mod->rx_free_count == 0 || rx_mod->rxp_free_count == 0) || rx_mod->rxq_free_count == 0) {
    return (0);
  } else {

  }
  if ((unsigned int )rx_cfg->rxp_type == 1U) {
    if (rx_mod->rxp_free_count < rx_cfg->num_paths || rx_mod->rxq_free_count < rx_cfg->num_paths) {
      return (0);
    } else {

    }
  } else
  if (rx_mod->rxp_free_count < rx_cfg->num_paths || rx_mod->rxq_free_count < rx_cfg->num_paths * 2) {
    return (0);
  } else {

  }
  return (1);
}
}
static struct bna_rxq *bna_rxq_get(struct bna_rx_mod *rx_mod ) 
{ 
  struct bna_rxq *rxq ;
  struct list_head  const  *__mptr ;

  {
  rxq = (struct bna_rxq *)0;
  __mptr = (struct list_head  const  *)rx_mod->rxq_free_q.next;
  rxq = (struct bna_rxq *)__mptr;
  list_del(& rxq->qe);
  rx_mod->rxq_free_count = rx_mod->rxq_free_count - 1;
  return (rxq);
}
}
static void bna_rxq_put(struct bna_rx_mod *rx_mod , struct bna_rxq *rxq ) 
{ 


  {
  list_add_tail(& rxq->qe, & rx_mod->rxq_free_q);
  rx_mod->rxq_free_count = rx_mod->rxq_free_count + 1;
  return;
}
}
static struct bna_rxp *bna_rxp_get(struct bna_rx_mod *rx_mod ) 
{ 
  struct bna_rxp *rxp ;
  struct list_head  const  *__mptr ;

  {
  rxp = (struct bna_rxp *)0;
  __mptr = (struct list_head  const  *)rx_mod->rxp_free_q.next;
  rxp = (struct bna_rxp *)__mptr;
  list_del(& rxp->qe);
  rx_mod->rxp_free_count = rx_mod->rxp_free_count - 1;
  return (rxp);
}
}
static void bna_rxp_put(struct bna_rx_mod *rx_mod , struct bna_rxp *rxp ) 
{ 


  {
  list_add_tail(& rxp->qe, & rx_mod->rxp_free_q);
  rx_mod->rxp_free_count = rx_mod->rxp_free_count + 1;
  return;
}
}
static struct bna_rx *bna_rx_get(struct bna_rx_mod *rx_mod , enum bna_rx_type type ) 
{ 
  struct bna_rx *rx ;
  int tmp ;
  long tmp___0 ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  rx = (struct bna_rx *)0;
  tmp = list_empty((struct list_head  const  *)(& rx_mod->rx_free_q));
  tmp___0 = ldv__builtin_expect(tmp != 0, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c"),
                         "i" (1812), "i" (12UL));
    ldv_49891: ;
    goto ldv_49891;
  } else {

  }
  if ((unsigned int )type == 0U) {
    __mptr = (struct list_head  const  *)rx_mod->rx_free_q.next;
    rx = (struct bna_rx *)__mptr;
  } else {
    __mptr___0 = (struct list_head  const  *)rx_mod->rx_free_q.prev;
    rx = (struct bna_rx *)__mptr___0;
  }
  rx_mod->rx_free_count = rx_mod->rx_free_count - 1;
  list_move_tail(& rx->qe, & rx_mod->rx_active_q);
  rx->type = type;
  return (rx);
}
}
static void bna_rx_put(struct bna_rx_mod *rx_mod , struct bna_rx *rx ) 
{ 
  struct list_head *qe ;

  {
  qe = rx_mod->rx_free_q.prev;
  goto ldv_49903;
  ldv_49902: ;
  if (((struct bna_rx *)qe)->rid < rx->rid) {
    goto ldv_49901;
  } else {

  }
  qe = qe->prev;
  ldv_49903: ;
  if ((unsigned long )(& rx_mod->rx_free_q) != (unsigned long )qe) {
    goto ldv_49902;
  } else {

  }
  ldv_49901: 
  list_add(& rx->qe, qe);
  rx_mod->rx_free_count = rx_mod->rx_free_count + 1;
  return;
}
}
static void bna_rxp_add_rxqs(struct bna_rxp *rxp , struct bna_rxq *q0 , struct bna_rxq *q1 ) 
{ 


  {
  switch ((unsigned int )rxp->type) {
  case 1U: 
  rxp->rxq.single.only = q0;
  rxp->rxq.single.reserved = (struct bna_rxq *)0;
  goto ldv_49910;
  case 2U: 
  rxp->rxq.slr.large = q0;
  rxp->rxq.slr.small = q1;
  goto ldv_49910;
  case 3U: 
  rxp->rxq.hds.data = q0;
  rxp->rxq.hds.hdr = q1;
  goto ldv_49910;
  default: ;
  goto ldv_49910;
  }
  ldv_49910: ;
  return;
}
}
static void bna_rxq_qpt_setup(struct bna_rxq *rxq , struct bna_rxp *rxp , u32 page_count___0 ,
                              u32 page_size , struct bna_mem_descr *qpt_mem , struct bna_mem_descr *swqpt_mem ,
                              struct bna_mem_descr *page_mem ) 
{ 
  u8 *kva ;
  u64 dma ;
  struct bna_dma_addr bna_dma ;
  int i ;
  __u32 tmp ;
  __u32 tmp___0 ;
  u64 tmp_addr ;
  __u64 tmp___1 ;

  {
  rxq->qpt.hw_qpt_ptr.lsb = qpt_mem->dma.lsb;
  rxq->qpt.hw_qpt_ptr.msb = qpt_mem->dma.msb;
  rxq->qpt.kv_qpt_ptr = qpt_mem->kva;
  rxq->qpt.page_count = page_count___0;
  rxq->qpt.page_size = page_size;
  (rxq->rcb)->sw_qpt = (void **)swqpt_mem->kva;
  (rxq->rcb)->sw_q = page_mem->kva;
  kva = (u8 *)page_mem->kva;
  tmp = __fswab32(page_mem->dma.msb);
  tmp___0 = __fswab32(page_mem->dma.lsb);
  dma = ((unsigned long long )tmp << 32) | (unsigned long long )tmp___0;
  i = 0;
  goto ldv_49929;
  ldv_49928: 
  *((rxq->rcb)->sw_qpt + (unsigned long )i) = (void *)kva;
  kva = kva + 4096UL;
  tmp___1 = __fswab64(dma);
  tmp_addr = tmp___1;
  bna_dma.msb = ((struct bna_dma_addr *)(& tmp_addr))->msb;
  bna_dma.lsb = ((struct bna_dma_addr *)(& tmp_addr))->lsb;
  ((struct bna_dma_addr *)rxq->qpt.kv_qpt_ptr + (unsigned long )i)->lsb = bna_dma.lsb;
  ((struct bna_dma_addr *)rxq->qpt.kv_qpt_ptr + (unsigned long )i)->msb = bna_dma.msb;
  dma = dma + 4096ULL;
  i = i + 1;
  ldv_49929: ;
  if ((u32 )i < rxq->qpt.page_count) {
    goto ldv_49928;
  } else {

  }

  return;
}
}
static void bna_rxp_cqpt_setup(struct bna_rxp *rxp , u32 page_count___0 , u32 page_size ,
                               struct bna_mem_descr *qpt_mem , struct bna_mem_descr *swqpt_mem ,
                               struct bna_mem_descr *page_mem ) 
{ 
  u8 *kva ;
  u64 dma ;
  struct bna_dma_addr bna_dma ;
  int i ;
  __u32 tmp ;
  __u32 tmp___0 ;
  u64 tmp_addr ;
  __u64 tmp___1 ;

  {
  rxp->cq.qpt.hw_qpt_ptr.lsb = qpt_mem->dma.lsb;
  rxp->cq.qpt.hw_qpt_ptr.msb = qpt_mem->dma.msb;
  rxp->cq.qpt.kv_qpt_ptr = qpt_mem->kva;
  rxp->cq.qpt.page_count = page_count___0;
  rxp->cq.qpt.page_size = page_size;
  (rxp->cq.ccb)->sw_qpt = (void **)swqpt_mem->kva;
  (rxp->cq.ccb)->sw_q = page_mem->kva;
  kva = (u8 *)page_mem->kva;
  tmp = __fswab32(page_mem->dma.msb);
  tmp___0 = __fswab32(page_mem->dma.lsb);
  dma = ((unsigned long long )tmp << 32) | (unsigned long long )tmp___0;
  i = 0;
  goto ldv_49945;
  ldv_49944: 
  *((rxp->cq.ccb)->sw_qpt + (unsigned long )i) = (void *)kva;
  kva = kva + 4096UL;
  tmp___1 = __fswab64(dma);
  tmp_addr = tmp___1;
  bna_dma.msb = ((struct bna_dma_addr *)(& tmp_addr))->msb;
  bna_dma.lsb = ((struct bna_dma_addr *)(& tmp_addr))->lsb;
  ((struct bna_dma_addr *)rxp->cq.qpt.kv_qpt_ptr + (unsigned long )i)->lsb = bna_dma.lsb;
  ((struct bna_dma_addr *)rxp->cq.qpt.kv_qpt_ptr + (unsigned long )i)->msb = bna_dma.msb;
  dma = dma + 4096ULL;
  i = i + 1;
  ldv_49945: ;
  if ((u32 )i < rxp->cq.qpt.page_count) {
    goto ldv_49944;
  } else {

  }

  return;
}
}
static void bna_rx_mod_cb_rx_stopped(void *arg , struct bna_rx *rx ) 
{ 
  struct bna_rx_mod *rx_mod ;

  {
  rx_mod = (struct bna_rx_mod *)arg;
  bfa_wc_down(& rx_mod->rx_stop_wc);
  return;
}
}
static void bna_rx_mod_cb_rx_stopped_all(void *arg ) 
{ 
  struct bna_rx_mod *rx_mod ;

  {
  rx_mod = (struct bna_rx_mod *)arg;
  if ((unsigned long )rx_mod->stop_cbfn != (unsigned long )((void (*)(struct bna_enet * ))0)) {
    (*(rx_mod->stop_cbfn))(& (rx_mod->bna)->enet);
  } else {

  }
  rx_mod->stop_cbfn = (void (*)(struct bna_enet * ))0;
  return;
}
}
static void bna_rx_start(struct bna_rx *rx ) 
{ 


  {
  rx->rx_flags = (enum bna_rx_flags )((unsigned int )rx->rx_flags | 1U);
  if (((unsigned int )rx->rx_flags & 2U) != 0U) {
    (*(rx->fsm))((void *)rx, 1);
  } else {

  }
  return;
}
}
static void bna_rx_stop(struct bna_rx *rx ) 
{ 


  {
  rx->rx_flags = (enum bna_rx_flags )((unsigned int )rx->rx_flags & 4294967294U);
  if ((unsigned long )rx->fsm == (unsigned long )((void (*)(void * , int  ))(& bna_rx_sm_stopped))) {
    bna_rx_mod_cb_rx_stopped((void *)(& (rx->bna)->rx_mod), rx);
  } else {
    rx->stop_cbfn = & bna_rx_mod_cb_rx_stopped;
    rx->stop_cbarg = (void *)(& (rx->bna)->rx_mod);
    (*(rx->fsm))((void *)rx, 2);
  }
  return;
}
}
static void bna_rx_fail(struct bna_rx *rx ) 
{ 


  {
  rx->rx_flags = (enum bna_rx_flags )((unsigned int )rx->rx_flags & 4294967294U);
  (*(rx->fsm))((void *)rx, 3);
  return;
}
}
void bna_rx_mod_start(struct bna_rx_mod *rx_mod , enum bna_rx_type type ) 
{ 
  struct bna_rx *rx ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  rx_mod->flags = (enum bna_rx_mod_flags )((unsigned int )rx_mod->flags | 1U);
  if ((unsigned int )type == 1U) {
    rx_mod->flags = (enum bna_rx_mod_flags )((unsigned int )rx_mod->flags | 2U);
  } else {

  }
  __mptr = (struct list_head  const  *)rx_mod->rx_active_q.next;
  rx = (struct bna_rx *)__mptr;
  goto ldv_49975;
  ldv_49974: ;
  if ((unsigned int )rx->type == (unsigned int )type) {
    bna_rx_start(rx);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)rx->qe.next;
  rx = (struct bna_rx *)__mptr___0;
  ldv_49975: ;
  if ((unsigned long )(& rx->qe) != (unsigned long )(& rx_mod->rx_active_q)) {
    goto ldv_49974;
  } else {

  }

  return;
}
}
void bna_rx_mod_stop(struct bna_rx_mod *rx_mod , enum bna_rx_type type ) 
{ 
  struct bna_rx *rx ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  rx_mod->flags = (enum bna_rx_mod_flags )((unsigned int )rx_mod->flags & 4294967294U);
  rx_mod->flags = (enum bna_rx_mod_flags )((unsigned int )rx_mod->flags & 4294967293U);
  rx_mod->stop_cbfn = & bna_enet_cb_rx_stopped;
  bfa_wc_init(& rx_mod->rx_stop_wc, & bna_rx_mod_cb_rx_stopped_all, (void *)rx_mod);
  __mptr = (struct list_head  const  *)rx_mod->rx_active_q.next;
  rx = (struct bna_rx *)__mptr;
  goto ldv_49987;
  ldv_49986: ;
  if ((unsigned int )rx->type == (unsigned int )type) {
    bfa_wc_up(& rx_mod->rx_stop_wc);
    bna_rx_stop(rx);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)rx->qe.next;
  rx = (struct bna_rx *)__mptr___0;
  ldv_49987: ;
  if ((unsigned long )(& rx->qe) != (unsigned long )(& rx_mod->rx_active_q)) {
    goto ldv_49986;
  } else {

  }
  bfa_wc_wait(& rx_mod->rx_stop_wc);
  return;
}
}
void bna_rx_mod_fail(struct bna_rx_mod *rx_mod ) 
{ 
  struct bna_rx *rx ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  rx_mod->flags = (enum bna_rx_mod_flags )((unsigned int )rx_mod->flags & 4294967294U);
  rx_mod->flags = (enum bna_rx_mod_flags )((unsigned int )rx_mod->flags & 4294967293U);
  __mptr = (struct list_head  const  *)rx_mod->rx_active_q.next;
  rx = (struct bna_rx *)__mptr;
  goto ldv_49998;
  ldv_49997: 
  bna_rx_fail(rx);
  __mptr___0 = (struct list_head  const  *)rx->qe.next;
  rx = (struct bna_rx *)__mptr___0;
  ldv_49998: ;
  if ((unsigned long )(& rx->qe) != (unsigned long )(& rx_mod->rx_active_q)) {
    goto ldv_49997;
  } else {

  }

  return;
}
}
void bna_rx_mod_init(struct bna_rx_mod *rx_mod , struct bna *bna , struct bna_res_info *res_info ) 
{ 
  int index ;
  struct bna_rx *rx_ptr ;
  struct bna_rxp *rxp_ptr ;
  struct bna_rxq *rxq_ptr ;

  {
  rx_mod->bna = bna;
  rx_mod->flags = 0;
  rx_mod->rx = (struct bna_rx *)((res_info + 2UL)->res_u.mem_info.mdl)->kva;
  rx_mod->rxp = (struct bna_rxp *)((res_info + 3UL)->res_u.mem_info.mdl)->kva;
  rx_mod->rxq = (struct bna_rxq *)((res_info + 4UL)->res_u.mem_info.mdl)->kva;
  INIT_LIST_HEAD(& rx_mod->rx_free_q);
  rx_mod->rx_free_count = 0;
  INIT_LIST_HEAD(& rx_mod->rxq_free_q);
  rx_mod->rxq_free_count = 0;
  INIT_LIST_HEAD(& rx_mod->rxp_free_q);
  rx_mod->rxp_free_count = 0;
  INIT_LIST_HEAD(& rx_mod->rx_active_q);
  index = 0;
  goto ldv_50010;
  ldv_50009: 
  rx_ptr = rx_mod->rx + (unsigned long )index;
  INIT_LIST_HEAD(& rx_ptr->rxp_q);
  rx_ptr->bna = (struct bna *)0;
  rx_ptr->rid = index;
  rx_ptr->stop_cbfn = (void (*)(void * , struct bna_rx * ))0;
  rx_ptr->stop_cbarg = (void *)0;
  list_add_tail(& rx_ptr->qe, & rx_mod->rx_free_q);
  rx_mod->rx_free_count = rx_mod->rx_free_count + 1;
  index = index + 1;
  ldv_50010: ;
  if (bna->ioceth.attr.num_rxp > index) {
    goto ldv_50009;
  } else {

  }
  index = 0;
  goto ldv_50013;
  ldv_50012: 
  rxp_ptr = rx_mod->rxp + (unsigned long )index;
  list_add_tail(& rxp_ptr->qe, & rx_mod->rxp_free_q);
  rx_mod->rxp_free_count = rx_mod->rxp_free_count + 1;
  index = index + 1;
  ldv_50013: ;
  if (bna->ioceth.attr.num_rxp > index) {
    goto ldv_50012;
  } else {

  }
  index = 0;
  goto ldv_50016;
  ldv_50015: 
  rxq_ptr = rx_mod->rxq + (unsigned long )index;
  list_add_tail(& rxq_ptr->qe, & rx_mod->rxq_free_q);
  rx_mod->rxq_free_count = rx_mod->rxq_free_count + 1;
  index = index + 1;
  ldv_50016: ;
  if (bna->ioceth.attr.num_rxp * 2 > index) {
    goto ldv_50015;
  } else {

  }

  return;
}
}
void bna_rx_mod_uninit(struct bna_rx_mod *rx_mod ) 
{ 


  {
  rx_mod->bna = (struct bna *)0;
  return;
}
}
void bna_bfi_rx_enet_start_rsp(struct bna_rx *rx , struct bfi_msgq_mhdr *msghdr ) 
{ 
  struct bfi_enet_rx_cfg_rsp *cfg_rsp ;
  struct bna_rxp *rxp ;
  struct bna_rxq *q0 ;
  struct bna_rxq *q1 ;
  int i ;
  struct list_head  const  *__mptr ;
  __u32 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  u32 tmp___2 ;
  u32 tmp___3 ;
  struct list_head  const  *__mptr___0 ;

  {
  cfg_rsp = & rx->bfi_enet_cmd.cfg_rsp;
  rxp = (struct bna_rxp *)0;
  q0 = (struct bna_rxq *)0;
  q1 = (struct bna_rxq *)0;
  bfa_msgq_rsp_copy(& (rx->bna)->msgq, (u8 *)cfg_rsp, 268UL);
  rx->hw_id = (int )cfg_rsp->hw_id;
  i = 0;
  __mptr = (struct list_head  const  *)rx->rxp_q.next;
  rxp = (struct bna_rxp *)__mptr;
  goto ldv_50039;
  ldv_50038: ;
  switch ((unsigned int )rxp->type) {
  case 1U: 
  q0 = rxp->rxq.single.only;
  q1 = (struct bna_rxq *)0;
  goto ldv_50035;
  case 2U: 
  q0 = rxp->rxq.slr.large;
  q1 = rxp->rxq.slr.small;
  goto ldv_50035;
  case 3U: 
  q0 = rxp->rxq.hds.data;
  q1 = rxp->rxq.hds.hdr;
  goto ldv_50035;
  }
  ldv_50035: 
  tmp = __fswab32(cfg_rsp->q_handles[i].i_dbell);
  ((rxp->cq.ccb)->i_dbell)->doorbell_addr = (rx->bna)->pcidev.pci_bar_kva + (unsigned long )tmp;
  rxp->hw_id = (int )cfg_rsp->q_handles[i].hw_cqid;
  tmp___0 = __fswab32(cfg_rsp->q_handles[i].ql_dbell);
  (q0->rcb)->q_dbell = (rx->bna)->pcidev.pci_bar_kva + (unsigned long )tmp___0;
  q0->hw_id = (int )cfg_rsp->q_handles[i].hw_lqid;
  if ((unsigned long )q1 != (unsigned long )((struct bna_rxq *)0)) {
    tmp___1 = __fswab32(cfg_rsp->q_handles[i].qs_dbell);
    (q1->rcb)->q_dbell = (rx->bna)->pcidev.pci_bar_kva + (unsigned long )tmp___1;
    q1->hw_id = (int )cfg_rsp->q_handles[i].hw_sqid;
  } else {

  }
  *((rxp->cq.ccb)->hw_producer_index) = 0U;
  (rxp->cq.ccb)->producer_index = 0U;
  tmp___2 = 0U;
  (q0->rcb)->consumer_index = tmp___2;
  (q0->rcb)->producer_index = tmp___2;
  if ((unsigned long )q1 != (unsigned long )((struct bna_rxq *)0)) {
    tmp___3 = 0U;
    (q1->rcb)->consumer_index = tmp___3;
    (q1->rcb)->producer_index = tmp___3;
  } else {

  }
  i = i + 1;
  __mptr___0 = (struct list_head  const  *)rxp->qe.next;
  rxp = (struct bna_rxp *)__mptr___0;
  ldv_50039: ;
  if (rx->num_paths > i) {
    goto ldv_50038;
  } else {

  }
  (*(rx->fsm))((void *)rx, 4);
  return;
}
}
void bna_bfi_rx_enet_stop_rsp(struct bna_rx *rx , struct bfi_msgq_mhdr *msghdr ) 
{ 


  {
  (*(rx->fsm))((void *)rx, 5);
  return;
}
}
void bna_rx_res_req(struct bna_rx_config *q_cfg , struct bna_res_info *res_info ) 
{ 
  u32 cq_size ;
  u32 hq_size ;
  u32 dq_size ;
  u32 cpage_count ;
  u32 hpage_count ;
  u32 dpage_count ;
  struct bna_mem_info *mem_info ;
  u32 cq_depth ;
  u32 hq_depth ;
  u32 dq_depth ;
  unsigned long tmp ;
  unsigned long tmp___0 ;
  unsigned long tmp___1 ;

  {
  dq_depth = q_cfg->q0_depth;
  hq_depth = (unsigned int )q_cfg->rxp_type != 1U ? q_cfg->q1_depth : 0U;
  tmp = __roundup_pow_of_two((unsigned long )(dq_depth + hq_depth));
  cq_depth = (u32 )tmp;
  cq_size = cq_depth * 16U;
  cq_size = (cq_size + 4095U) & 4294963200U;
  cpage_count = (cq_size >> 12) + (u32 )((((unsigned long )cq_size & 4095UL) + 4095UL) >> 12);
  tmp___0 = __roundup_pow_of_two((unsigned long )dq_depth);
  dq_depth = (u32 )tmp___0;
  dq_size = dq_depth * 8U;
  dq_size = (dq_size + 4095U) & 4294963200U;
  dpage_count = (dq_size >> 12) + (u32 )((((unsigned long )dq_size & 4095UL) + 4095UL) >> 12);
  if ((unsigned int )q_cfg->rxp_type != 1U) {
    tmp___1 = __roundup_pow_of_two((unsigned long )hq_depth);
    hq_depth = (u32 )tmp___1;
    hq_size = hq_depth * 8U;
    hq_size = (hq_size + 4095U) & 4294963200U;
    hpage_count = (hq_size >> 12) + (u32 )((((unsigned long )hq_size & 4095UL) + 4095UL) >> 12);
  } else {
    hpage_count = 0U;
  }
  res_info->res_type = 1;
  mem_info = & res_info->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = 144U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 1UL)->res_type = 1;
  mem_info = & (res_info + 1UL)->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = 96U;
  mem_info->num = (u32 )((unsigned int )q_cfg->rxp_type == 1U ? q_cfg->num_paths : q_cfg->num_paths * 2);
  (res_info + 4UL)->res_type = 1;
  mem_info = & (res_info + 4UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = cpage_count * 8U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 5UL)->res_type = 1;
  mem_info = & (res_info + 5UL)->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = cpage_count * 8U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 6UL)->res_type = 1;
  mem_info = & (res_info + 6UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = cpage_count * 4096U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 8UL)->res_type = 1;
  mem_info = & (res_info + 8UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = dpage_count * 8U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 10UL)->res_type = 1;
  mem_info = & (res_info + 10UL)->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = dpage_count * 8U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 11UL)->res_type = 1;
  mem_info = & (res_info + 11UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = dpage_count * 4096U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 7UL)->res_type = 1;
  mem_info = & (res_info + 7UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = hpage_count * 8U;
  mem_info->num = hpage_count != 0U ? (u32 )q_cfg->num_paths : 0U;
  (res_info + 9UL)->res_type = 1;
  mem_info = & (res_info + 9UL)->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = hpage_count * 8U;
  mem_info->num = hpage_count != 0U ? (u32 )q_cfg->num_paths : 0U;
  (res_info + 12UL)->res_type = 1;
  mem_info = & (res_info + 12UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = hpage_count * 4096U;
  mem_info->num = hpage_count != 0U ? (u32 )q_cfg->num_paths : 0U;
  (res_info + 13UL)->res_type = 1;
  mem_info = & (res_info + 13UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = 4U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 14UL)->res_type = 1;
  mem_info = & (res_info + 14UL)->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = 64U;
  mem_info->num = 1U;
  (res_info + 15UL)->res_type = 2;
  (res_info + 15UL)->res_u.intr_info.intr_type = 2;
  (res_info + 15UL)->res_u.intr_info.num = q_cfg->num_paths;
  return;
}
}
struct bna_rx *bna_rx_create(struct bna *bna , struct bnad *bnad , struct bna_rx_config *rx_cfg ,
                             struct bna_rx_event_cbfn  const  *rx_cbfn , struct bna_res_info *res_info ,
                             void *priv ) 
{ 
  struct bna_rx_mod *rx_mod ;
  struct bna_rx *rx ;
  struct bna_rxp *rxp ;
  struct bna_rxq *q0 ;
  struct bna_rxq *q1 ;
  struct bna_intr_info *intr_info ;
  struct bna_mem_descr *hqunmap_mem ;
  struct bna_mem_descr *dqunmap_mem ;
  struct bna_mem_descr *ccb_mem ;
  struct bna_mem_descr *rcb_mem ;
  struct bna_mem_descr *cqpt_mem ;
  struct bna_mem_descr *cswqpt_mem ;
  struct bna_mem_descr *cpage_mem ;
  struct bna_mem_descr *hqpt_mem ;
  struct bna_mem_descr *dqpt_mem ;
  struct bna_mem_descr *hsqpt_mem ;
  struct bna_mem_descr *dsqpt_mem ;
  struct bna_mem_descr *hpage_mem ;
  struct bna_mem_descr *dpage_mem ;
  u32 dpage_count ;
  u32 hpage_count ;
  u32 hq_idx ;
  u32 dq_idx ;
  u32 rcb_idx ;
  u32 cq_depth ;
  u32 i ;
  u32 page_count___0 ;
  int tmp ;
  u64 tmp___0 ;
  u64 tmp___1 ;
  u64 tmp___2 ;
  u64 tmp___3 ;
  unsigned long tmp___4 ;

  {
  rx_mod = & bna->rx_mod;
  tmp = bna_rx_res_check(rx_mod, rx_cfg);
  if (tmp == 0) {
    return ((struct bna_rx *)0);
  } else {

  }
  intr_info = & (res_info + 15UL)->res_u.intr_info;
  ccb_mem = res_info->res_u.mem_info.mdl;
  rcb_mem = (res_info + 1UL)->res_u.mem_info.mdl;
  dqunmap_mem = (res_info + 3UL)->res_u.mem_info.mdl;
  hqunmap_mem = (res_info + 2UL)->res_u.mem_info.mdl;
  cqpt_mem = (res_info + 4UL)->res_u.mem_info.mdl;
  cswqpt_mem = (res_info + 5UL)->res_u.mem_info.mdl;
  cpage_mem = (res_info + 6UL)->res_u.mem_info.mdl;
  hqpt_mem = (res_info + 7UL)->res_u.mem_info.mdl;
  dqpt_mem = (res_info + 8UL)->res_u.mem_info.mdl;
  hsqpt_mem = (res_info + 9UL)->res_u.mem_info.mdl;
  dsqpt_mem = (res_info + 10UL)->res_u.mem_info.mdl;
  hpage_mem = (res_info + 12UL)->res_u.mem_info.mdl;
  dpage_mem = (res_info + 11UL)->res_u.mem_info.mdl;
  page_count___0 = (res_info + 6UL)->res_u.mem_info.len / 4096U;
  dpage_count = (res_info + 11UL)->res_u.mem_info.len / 4096U;
  hpage_count = (res_info + 12UL)->res_u.mem_info.len / 4096U;
  rx = bna_rx_get(rx_mod, rx_cfg->rx_type);
  rx->bna = bna;
  rx->rx_flags = 0;
  INIT_LIST_HEAD(& rx->rxp_q);
  rx->stop_cbfn = (void (*)(void * , struct bna_rx * ))0;
  rx->stop_cbarg = (void *)0;
  rx->priv = priv;
  rx->rcb_setup_cbfn = rx_cbfn->rcb_setup_cbfn;
  rx->rcb_destroy_cbfn = rx_cbfn->rcb_destroy_cbfn;
  rx->ccb_setup_cbfn = rx_cbfn->ccb_setup_cbfn;
  rx->ccb_destroy_cbfn = rx_cbfn->ccb_destroy_cbfn;
  rx->rx_stall_cbfn = rx_cbfn->rx_stall_cbfn;
  rx->rx_cleanup_cbfn = rx_cbfn->rx_cleanup_cbfn;
  rx->rx_post_cbfn = rx_cbfn->rx_post_cbfn;
  if ((int )(rx->bna)->rx_mod.flags & 1) {
    switch ((unsigned int )rx->type) {
    case 0U: ;
    if (((unsigned int )(rx->bna)->rx_mod.flags & 2U) == 0U) {
      rx->rx_flags = (enum bna_rx_flags )((unsigned int )rx->rx_flags | 1U);
    } else {

    }
    goto ldv_50095;
    case 1U: ;
    if (((unsigned int )(rx->bna)->rx_mod.flags & 2U) != 0U) {
      rx->rx_flags = (enum bna_rx_flags )((unsigned int )rx->rx_flags | 1U);
    } else {

    }
    goto ldv_50095;
    }
    ldv_50095: ;
  } else {

  }
  rx->num_paths = rx_cfg->num_paths;
  i = 0U;
  hq_idx = 0U;
  dq_idx = 0U;
  rcb_idx = 0U;
  goto ldv_50098;
  ldv_50097: 
  rxp = bna_rxp_get(rx_mod);
  list_add_tail(& rxp->qe, & rx->rxp_q);
  rxp->type = rx_cfg->rxp_type;
  rxp->rx = rx;
  rxp->cq.rx = rx;
  q0 = bna_rxq_get(rx_mod);
  if ((unsigned int )rx_cfg->rxp_type == 1U) {
    q1 = (struct bna_rxq *)0;
  } else {
    q1 = bna_rxq_get(rx_mod);
  }
  if (intr_info->num == 1) {
    rxp->vector = (intr_info->idl)->vector;
  } else {
    rxp->vector = (intr_info->idl + (unsigned long )i)->vector;
  }
  rxp->cq.ib.ib_seg_host_addr.lsb = ((res_info + 13UL)->res_u.mem_info.mdl + (unsigned long )i)->dma.lsb;
  rxp->cq.ib.ib_seg_host_addr.msb = ((res_info + 13UL)->res_u.mem_info.mdl + (unsigned long )i)->dma.msb;
  rxp->cq.ib.ib_seg_host_addr_kva = ((res_info + 13UL)->res_u.mem_info.mdl + (unsigned long )i)->kva;
  rxp->cq.ib.intr_type = intr_info->intr_type;
  if ((unsigned int )intr_info->intr_type == 2U) {
    rxp->cq.ib.intr_vector = rxp->vector;
  } else {
    rxp->cq.ib.intr_vector = (int )(1UL << rxp->vector);
  }
  rxp->cq.ib.coalescing_timeo = (u8 )rx_cfg->coalescing_timeo;
  rxp->cq.ib.interpkt_count = 6;
  rxp->cq.ib.interpkt_timeo = 3;
  bna_rxp_add_rxqs(rxp, q0, q1);
  q0->rx = rx;
  q0->rxp = rxp;
  q0->rcb = (struct bna_rcb *)(rcb_mem + (unsigned long )rcb_idx)->kva;
  (q0->rcb)->unmap_q = (dqunmap_mem + (unsigned long )dq_idx)->kva;
  rcb_idx = rcb_idx + 1U;
  dq_idx = dq_idx + 1U;
  (q0->rcb)->q_depth = rx_cfg->q0_depth;
  q0->q_depth = (int )rx_cfg->q0_depth;
  q0->multi_buffer = rx_cfg->q0_multi_buf;
  q0->buffer_size = (int )rx_cfg->q0_buf_size;
  q0->num_vecs = rx_cfg->q0_num_vecs;
  (q0->rcb)->rxq = q0;
  (q0->rcb)->bnad = bna->bnad;
  (q0->rcb)->id = 0;
  tmp___0 = 0ULL;
  q0->rx_bytes = tmp___0;
  q0->rx_packets = tmp___0;
  tmp___1 = 0ULL;
  q0->rxbuf_alloc_failed = tmp___1;
  q0->rx_packets_with_error = tmp___1;
  bna_rxq_qpt_setup(q0, rxp, dpage_count, 4096U, dqpt_mem + (unsigned long )i, dsqpt_mem + (unsigned long )i,
                    dpage_mem + (unsigned long )i);
  if ((unsigned long )rx->rcb_setup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                       struct bna_rcb * ))0)) {
    (*(rx->rcb_setup_cbfn))(bnad, q0->rcb);
  } else {

  }
  if ((unsigned long )q1 != (unsigned long )((struct bna_rxq *)0)) {
    q1->rx = rx;
    q1->rxp = rxp;
    q1->rcb = (struct bna_rcb *)(rcb_mem + (unsigned long )rcb_idx)->kva;
    (q1->rcb)->unmap_q = (hqunmap_mem + (unsigned long )hq_idx)->kva;
    rcb_idx = rcb_idx + 1U;
    hq_idx = hq_idx + 1U;
    (q1->rcb)->q_depth = rx_cfg->q1_depth;
    q1->q_depth = (int )rx_cfg->q1_depth;
    q1->multi_buffer = 0;
    q1->num_vecs = 1U;
    (q1->rcb)->rxq = q1;
    (q1->rcb)->bnad = bna->bnad;
    (q1->rcb)->id = 1;
    q1->buffer_size = (unsigned int )rx_cfg->rxp_type == 3U ? rx_cfg->hds_config.forced_offset : (int )rx_cfg->q1_buf_size;
    tmp___2 = 0ULL;
    q1->rx_bytes = tmp___2;
    q1->rx_packets = tmp___2;
    tmp___3 = 0ULL;
    q1->rxbuf_alloc_failed = tmp___3;
    q1->rx_packets_with_error = tmp___3;
    bna_rxq_qpt_setup(q1, rxp, hpage_count, 4096U, hqpt_mem + (unsigned long )i, hsqpt_mem + (unsigned long )i,
                      hpage_mem + (unsigned long )i);
    if ((unsigned long )rx->rcb_setup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                         struct bna_rcb * ))0)) {
      (*(rx->rcb_setup_cbfn))(bnad, q1->rcb);
    } else {

    }
  } else {

  }
  rxp->cq.ccb = (struct bna_ccb *)(ccb_mem + (unsigned long )i)->kva;
  cq_depth = rx_cfg->q0_depth + ((unsigned int )rx_cfg->rxp_type != 1U ? rx_cfg->q1_depth : 0U);
  tmp___4 = __roundup_pow_of_two((unsigned long )cq_depth);
  cq_depth = (u32 )tmp___4;
  (rxp->cq.ccb)->q_depth = cq_depth;
  (rxp->cq.ccb)->cq = & rxp->cq;
  (rxp->cq.ccb)->rcb[0] = q0->rcb;
  (q0->rcb)->ccb = rxp->cq.ccb;
  if ((unsigned long )q1 != (unsigned long )((struct bna_rxq *)0)) {
    (rxp->cq.ccb)->rcb[1] = q1->rcb;
    (q1->rcb)->ccb = rxp->cq.ccb;
  } else {

  }
  (rxp->cq.ccb)->hw_producer_index = (u32 volatile   *)rxp->cq.ib.ib_seg_host_addr_kva;
  (rxp->cq.ccb)->i_dbell = & rxp->cq.ib.door_bell;
  (rxp->cq.ccb)->intr_type = rxp->cq.ib.intr_type;
  (rxp->cq.ccb)->intr_vector = rxp->cq.ib.intr_vector;
  (rxp->cq.ccb)->rx_coalescing_timeo = rxp->cq.ib.coalescing_timeo;
  (rxp->cq.ccb)->pkt_rate.small_pkt_cnt = 0U;
  (rxp->cq.ccb)->pkt_rate.large_pkt_cnt = 0U;
  (rxp->cq.ccb)->bnad = bna->bnad;
  (rxp->cq.ccb)->id = (int )i;
  bna_rxp_cqpt_setup(rxp, page_count___0, 4096U, cqpt_mem + (unsigned long )i, cswqpt_mem + (unsigned long )i,
                     cpage_mem + (unsigned long )i);
  if ((unsigned long )rx->ccb_setup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                       struct bna_ccb * ))0)) {
    (*(rx->ccb_setup_cbfn))(bnad, rxp->cq.ccb);
  } else {

  }
  i = i + 1U;
  ldv_50098: ;
  if ((u32 )rx->num_paths > i) {
    goto ldv_50097;
  } else {

  }
  rx->hds_cfg = rx_cfg->hds_config;
  bna_rxf_init(& rx->rxf, rx, rx_cfg, res_info);
  rx->fsm = (void (*)(void * , int  ))(& bna_rx_sm_stopped);
  bna_rx_sm_stopped_entry(rx);
  rx_mod->rid_mask = rx_mod->rid_mask | (u32 )(1UL << rx->rid);
  return (rx);
}
}
void bna_rx_destroy(struct bna_rx *rx ) 
{ 
  struct bna_rx_mod *rx_mod ;
  struct bna_rxq *q0 ;
  struct bna_rxq *q1 ;
  struct bna_rxp *rxp ;
  struct list_head *qe ;
  struct list_head  const  *__mptr ;
  int tmp ;

  {
  rx_mod = & (rx->bna)->rx_mod;
  q0 = (struct bna_rxq *)0;
  q1 = (struct bna_rxq *)0;
  bna_rxf_uninit(& rx->rxf);
  goto ldv_50115;
  ldv_50114: 
  __mptr = (struct list_head  const  *)rx->rxp_q.next;
  rxp = (struct bna_rxp *)__mptr;
  list_del(& rxp->qe);
  switch ((unsigned int )rxp->type) {
  case 1U: 
  q0 = rxp->rxq.single.only;
  q1 = (struct bna_rxq *)0;
  goto ldv_50111;
  case 2U: 
  q0 = rxp->rxq.slr.large;
  q1 = rxp->rxq.slr.small;
  goto ldv_50111;
  case 3U: 
  q0 = rxp->rxq.hds.data;
  q1 = rxp->rxq.hds.hdr;
  goto ldv_50111;
  }
  ldv_50111: ;
  if ((unsigned long )rx->rcb_destroy_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                         struct bna_rcb * ))0)) {
    (*(rx->rcb_destroy_cbfn))((rx->bna)->bnad, q0->rcb);
  } else {

  }
  q0->rcb = (struct bna_rcb *)0;
  q0->rxp = (struct bna_rxp *)0;
  q0->rx = (struct bna_rx *)0;
  bna_rxq_put(rx_mod, q0);
  if ((unsigned long )q1 != (unsigned long )((struct bna_rxq *)0)) {
    if ((unsigned long )rx->rcb_destroy_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                           struct bna_rcb * ))0)) {
      (*(rx->rcb_destroy_cbfn))((rx->bna)->bnad, q1->rcb);
    } else {

    }
    q1->rcb = (struct bna_rcb *)0;
    q1->rxp = (struct bna_rxp *)0;
    q1->rx = (struct bna_rx *)0;
    bna_rxq_put(rx_mod, q1);
  } else {

  }
  rxp->rxq.slr.large = (struct bna_rxq *)0;
  rxp->rxq.slr.small = (struct bna_rxq *)0;
  if ((unsigned long )rx->ccb_destroy_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                         struct bna_ccb * ))0)) {
    (*(rx->ccb_destroy_cbfn))((rx->bna)->bnad, rxp->cq.ccb);
  } else {

  }
  rxp->cq.ccb = (struct bna_ccb *)0;
  rxp->rx = (struct bna_rx *)0;
  bna_rxp_put(rx_mod, rxp);
  ldv_50115: 
  tmp = list_empty((struct list_head  const  *)(& rx->rxp_q));
  if (tmp == 0) {
    goto ldv_50114;
  } else {

  }
  qe = rx_mod->rx_active_q.next;
  goto ldv_50119;
  ldv_50118: ;
  if ((unsigned long )(& rx->qe) == (unsigned long )qe) {
    list_del(& rx->qe);
    goto ldv_50117;
  } else {

  }
  qe = qe->next;
  ldv_50119: ;
  if ((unsigned long )(& rx_mod->rx_active_q) != (unsigned long )qe) {
    goto ldv_50118;
  } else {

  }
  ldv_50117: 
  rx_mod->rid_mask = rx_mod->rid_mask & ~ ((u32 )(1UL << rx->rid));
  rx->bna = (struct bna *)0;
  rx->priv = (void *)0;
  bna_rx_put(rx_mod, rx);
  return;
}
}
void bna_rx_enable(struct bna_rx *rx ) 
{ 


  {
  if ((unsigned long )rx->fsm != (unsigned long )((void (*)(void * , int  ))(& bna_rx_sm_stopped))) {
    return;
  } else {

  }
  rx->rx_flags = (enum bna_rx_flags )((unsigned int )rx->rx_flags | 2U);
  if ((int )rx->rx_flags & 1) {
    (*(rx->fsm))((void *)rx, 1);
  } else {

  }
  return;
}
}
void bna_rx_disable(struct bna_rx *rx , enum bna_cleanup_type type , void (*cbfn)(void * ,
                                                                                  struct bna_rx * ) ) 
{ 


  {
  if ((unsigned int )type == 1U) {
    (*cbfn)((void *)(rx->bna)->bnad, rx);
  } else {
    rx->stop_cbfn = cbfn;
    rx->stop_cbarg = (void *)(rx->bna)->bnad;
    rx->rx_flags = (enum bna_rx_flags )((unsigned int )rx->rx_flags & 4294967293U);
    (*(rx->fsm))((void *)rx, 2);
  }
  return;
}
}
void bna_rx_cleanup_complete(struct bna_rx *rx ) 
{ 


  {
  (*(rx->fsm))((void *)rx, 8);
  return;
}
}
void bna_rx_vlan_strip_enable(struct bna_rx *rx ) 
{ 
  struct bna_rxf *rxf ;

  {
  rxf = & rx->rxf;
  if ((unsigned int )rxf->vlan_strip_status == 0U) {
    rxf->vlan_strip_status = 1;
    rxf->vlan_strip_pending = 1;
    (*(rxf->fsm))((void *)rxf, 4);
  } else {

  }
  return;
}
}
void bna_rx_vlan_strip_disable(struct bna_rx *rx ) 
{ 
  struct bna_rxf *rxf ;

  {
  rxf = & rx->rxf;
  if ((unsigned int )rxf->vlan_strip_status != 0U) {
    rxf->vlan_strip_status = 0;
    rxf->vlan_strip_pending = 1;
    (*(rxf->fsm))((void *)rxf, 4);
  } else {

  }
  return;
}
}
enum bna_cb_status bna_rx_mode_set(struct bna_rx *rx , enum bna_rxmode new_mode ,
                                   enum bna_rxmode bitmask ) 
{ 
  struct bna_rxf *rxf ;
  int need_hw_config ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
  rxf = & rx->rxf;
  need_hw_config = 0;
  if ((int )bitmask & 1 && (int )new_mode & 1) {
    if ((rx->bna)->promisc_rid != -1 && (rx->bna)->promisc_rid != (rxf->rx)->rid) {
      goto err_return;
    } else {

    }
    if ((rx->bna)->default_mode_rid != -1) {
      goto err_return;
    } else {

    }
    if (((unsigned int )bitmask & 2U) != 0U && ((unsigned int )new_mode & 2U) != 0U) {
      goto err_return;
    } else {

    }
  } else {

  }
  if (((unsigned int )bitmask & 2U) != 0U && ((unsigned int )new_mode & 2U) != 0U) {
    if ((rx->bna)->default_mode_rid != -1 && (rx->bna)->default_mode_rid != (rxf->rx)->rid) {
      goto err_return;
    } else {

    }
    if ((rx->bna)->promisc_rid != -1) {
      goto err_return;
    } else {

    }
  } else {

  }
  if ((int )bitmask & 1 && (int )new_mode & 1) {
    tmp = bna_rxf_promisc_enable(rxf);
    if (tmp != 0) {
      need_hw_config = 1;
    } else {

    }
  } else
  if ((int )bitmask & 1 && ((unsigned int )new_mode & 1U) == 0U) {
    tmp___0 = bna_rxf_promisc_disable(rxf);
    if (tmp___0 != 0) {
      need_hw_config = 1;
    } else {

    }
  } else {

  }
  if (((unsigned int )bitmask & 4U) != 0U && ((unsigned int )new_mode & 4U) != 0U) {
    tmp___1 = bna_rxf_allmulti_enable(rxf);
    if (tmp___1 != 0) {
      need_hw_config = 1;
    } else {

    }
  } else
  if (((unsigned int )bitmask & 4U) != 0U && ((unsigned int )new_mode & 4U) == 0U) {
    tmp___2 = bna_rxf_allmulti_disable(rxf);
    if (tmp___2 != 0) {
      need_hw_config = 1;
    } else {

    }
  } else {

  }
  if (need_hw_config != 0) {
    rxf->cam_fltr_cbfn = (void (*)(struct bnad * , struct bna_rx * ))0;
    rxf->cam_fltr_cbarg = (rx->bna)->bnad;
    (*(rxf->fsm))((void *)rxf, 4);
  } else {

  }
  return (0);
  err_return: ;
  return (1);
}
}
void bna_rx_vlanfilter_enable(struct bna_rx *rx ) 
{ 
  struct bna_rxf *rxf ;

  {
  rxf = & rx->rxf;
  if ((unsigned int )rxf->vlan_filter_status == 0U) {
    rxf->vlan_filter_status = 1;
    rxf->vlan_pending_bitmask = 255U;
    (*(rxf->fsm))((void *)rxf, 4);
  } else {

  }
  return;
}
}
void bna_rx_coalescing_timeo_set(struct bna_rx *rx , int coalescing_timeo ) 
{ 
  struct bna_rxp *rxp ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  __mptr = (struct list_head  const  *)rx->rxp_q.next;
  rxp = (struct bna_rxp *)__mptr;
  goto ldv_50163;
  ldv_50162: 
  (rxp->cq.ccb)->rx_coalescing_timeo = (u8 )coalescing_timeo;
  bna_ib_coalescing_timeo_set(& rxp->cq.ib, (int )((u8 )coalescing_timeo));
  __mptr___0 = (struct list_head  const  *)rxp->qe.next;
  rxp = (struct bna_rxp *)__mptr___0;
  ldv_50163: ;
  if ((unsigned long )(& rxp->qe) != (unsigned long )(& rx->rxp_q)) {
    goto ldv_50162;
  } else {

  }

  return;
}
}
void bna_rx_dim_reconfig(struct bna *bna , u32 const   (*vector)[2] ) 
{ 
  int i ;
  int j ;

  {
  i = 0;
  goto ldv_50175;
  ldv_50174: 
  j = 0;
  goto ldv_50172;
  ldv_50171: 
  bna->rx_mod.dim_vector[i][j] = (*(vector + (unsigned long )i))[j];
  j = j + 1;
  ldv_50172: ;
  if (j <= 1) {
    goto ldv_50171;
  } else {

  }
  i = i + 1;
  ldv_50175: ;
  if (i <= 7) {
    goto ldv_50174;
  } else {

  }

  return;
}
}
void bna_rx_dim_update(struct bna_ccb *ccb ) 
{ 
  struct bna *bna ;
  u32 load ;
  u32 bias ;
  u32 pkt_rt ;
  u32 small_rt ;
  u32 large_rt ;
  u8 coalescing_timeo ;

  {
  bna = ((ccb->cq)->rx)->bna;
  if (ccb->pkt_rate.small_pkt_cnt == 0U && ccb->pkt_rate.large_pkt_cnt == 0U) {
    return;
  } else {

  }
  small_rt = ccb->pkt_rate.small_pkt_cnt;
  large_rt = ccb->pkt_rate.large_pkt_cnt;
  pkt_rt = small_rt + large_rt;
  if (pkt_rt <= 9999U) {
    load = 7U;
  } else
  if (pkt_rt <= 19999U) {
    load = 6U;
  } else
  if (pkt_rt <= 29999U) {
    load = 5U;
  } else
  if (pkt_rt <= 39999U) {
    load = 4U;
  } else
  if (pkt_rt <= 49999U) {
    load = 3U;
  } else
  if (pkt_rt <= 59999U) {
    load = 2U;
  } else
  if (pkt_rt <= 79999U) {
    load = 1U;
  } else {
    load = 0U;
  }
  if (large_rt << 1 < small_rt) {
    bias = 0U;
  } else {
    bias = 1U;
  }
  ccb->pkt_rate.small_pkt_cnt = 0U;
  ccb->pkt_rate.large_pkt_cnt = 0U;
  coalescing_timeo = (u8 )bna->rx_mod.dim_vector[load][bias];
  ccb->rx_coalescing_timeo = coalescing_timeo;
  bna_ib_coalescing_timeo_set(& (ccb->cq)->ib, (int )coalescing_timeo);
  return;
}
}
u32 const   bna_napi_dim_vector[8U][2U]  = 
  { {        12U,        12U}, 
   {        6U,        10U}, 
   {        5U,        10U}, 
   {        4U,        8U}, 
   {        3U,        6U}, 
   {        3U,        6U}, 
   {        2U,        4U}, 
   {        1U,        2U}};
static void bna_tx_mod_cb_tx_stopped(void *arg , struct bna_tx *tx ) ;
static void bna_bfi_tx_enet_start(struct bna_tx *tx ) ;
static void bna_tx_enet_stop(struct bna_tx *tx ) ;
static void bna_tx_sm_stopped(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_stopped_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_start_wait(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_start_wait_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_started(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_started_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_stop_wait(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_stop_wait_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_cleanup_wait(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_cleanup_wait_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_prio_stop_wait(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_prio_stop_wait_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_prio_cleanup_wait(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_prio_cleanup_wait_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_failed(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_failed_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_quiesce_wait(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_quiesce_wait_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_stopped_entry(struct bna_tx *tx ) 
{ 
  void (*cbfn)(void * , struct bna_tx * ) ;
  void *cbarg ;

  {
  if ((unsigned long )tx->stop_cbfn != (unsigned long )((void (*)(void * , struct bna_tx * ))0)) {
    cbfn = tx->stop_cbfn;
    cbarg = tx->stop_cbarg;
    tx->stop_cbfn = (void (*)(void * , struct bna_tx * ))0;
    tx->stop_cbarg = (void *)0;
    (*cbfn)(cbarg, tx);
  } else {

  }
  return;
}
}
static void bna_tx_sm_stopped(struct bna_tx *tx , enum bna_tx_event event ) 
{ 
  void (*cbfn)(void * , struct bna_tx * ) ;
  void *cbarg ;

  {
  switch ((unsigned int )event) {
  case 1U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_start_wait);
  bna_tx_sm_start_wait_entry(tx);
  goto ldv_50260;
  case 2U: ;
  if ((unsigned long )tx->stop_cbfn != (unsigned long )((void (*)(void * , struct bna_tx * ))0)) {
    cbfn = tx->stop_cbfn;
    cbarg = tx->stop_cbarg;
    tx->stop_cbfn = (void (*)(void * , struct bna_tx * ))0;
    tx->stop_cbarg = (void *)0;
    (*cbfn)(cbarg, tx);
  } else {

  }
  goto ldv_50260;
  case 3U: ;
  goto ldv_50260;
  case 8U: ;
  goto ldv_50260;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         2832, (unsigned int )event);
  }
  ldv_50260: ;
  return;
}
}
static void bna_tx_sm_start_wait_entry(struct bna_tx *tx ) 
{ 


  {
  bna_bfi_tx_enet_start(tx);
  return;
}
}
static void bna_tx_sm_start_wait(struct bna_tx *tx , enum bna_tx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags & 4294967287U);
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_stop_wait);
  bna_tx_sm_stop_wait_entry(tx);
  goto ldv_50277;
  case 3U: 
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags & 4294967287U);
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_stopped);
  bna_tx_sm_stopped_entry(tx);
  goto ldv_50277;
  case 4U: ;
  if (((unsigned int )tx->flags & 8U) != 0U) {
    tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags & 4294967287U);
    tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_prio_stop_wait);
    bna_tx_sm_prio_stop_wait_entry(tx);
  } else {
    tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_started);
    bna_tx_sm_started_entry(tx);
  }
  goto ldv_50277;
  case 8U: 
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags | 8U);
  goto ldv_50277;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         2869, (unsigned int )event);
  }
  ldv_50277: ;
  return;
}
}
static void bna_tx_sm_started_entry(struct bna_tx *tx ) 
{ 
  struct bna_txq *txq ;
  int is_regular ;
  struct list_head  const  *__mptr ;
  u32 intx_mask ;
  struct bna_ib *ib ;
  struct list_head  const  *__mptr___0 ;

  {
  is_regular = (unsigned int )tx->type == 0U;
  __mptr = (struct list_head  const  *)tx->txq_q.next;
  txq = (struct bna_txq *)__mptr;
  goto ldv_50294;
  ldv_50293: 
  (txq->tcb)->priority = txq->priority;
  ib = & txq->ib;
  if ((unsigned int )ib->intr_type == 1U) {
    intx_mask = readl((void const volatile   *)(tx->bna)->regs.fn_int_mask);
    writel(4294967295U, (void volatile   *)(tx->bna)->regs.fn_int_mask);
    intx_mask = (u32 )(~ ib->intr_vector) & intx_mask;
    writel(intx_mask, (void volatile   *)(tx->bna)->regs.fn_int_mask);
  } else {

  }
  ib->door_bell.doorbell_ack = (unsigned int )((int )ib->coalescing_timeo << 16) | 2147483648U;
  if (is_regular != 0) {
    writel(ib->door_bell.doorbell_ack, (void volatile   *)ib->door_bell.doorbell_addr);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)txq->qe.next;
  txq = (struct bna_txq *)__mptr___0;
  ldv_50294: ;
  if ((unsigned long )(& txq->qe) != (unsigned long )(& tx->txq_q)) {
    goto ldv_50293;
  } else {

  }
  (*(tx->tx_resume_cbfn))((tx->bna)->bnad, tx);
  return;
}
}
static void bna_tx_sm_started(struct bna_tx *tx , enum bna_tx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_stop_wait);
  bna_tx_sm_stop_wait_entry(tx);
  (*(tx->tx_stall_cbfn))((tx->bna)->bnad, tx);
  bna_tx_enet_stop(tx);
  goto ldv_50301;
  case 3U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_failed);
  bna_tx_sm_failed_entry(tx);
  (*(tx->tx_stall_cbfn))((tx->bna)->bnad, tx);
  (*(tx->tx_cleanup_cbfn))((tx->bna)->bnad, tx);
  goto ldv_50301;
  case 8U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_prio_stop_wait);
  bna_tx_sm_prio_stop_wait_entry(tx);
  goto ldv_50301;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         2908, (unsigned int )event);
  }
  ldv_50301: ;
  return;
}
}
static void bna_tx_sm_stop_wait_entry(struct bna_tx *tx ) 
{ 


  {
  return;
}
}
static void bna_tx_sm_stop_wait(struct bna_tx *tx , enum bna_tx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 5U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_cleanup_wait);
  bna_tx_sm_cleanup_wait_entry(tx);
  (*(tx->tx_cleanup_cbfn))((tx->bna)->bnad, tx);
  goto ldv_50314;
  case 4U: 
  bna_tx_enet_stop(tx);
  goto ldv_50314;
  case 8U: ;
  goto ldv_50314;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         2940, (unsigned int )event);
  }
  ldv_50314: ;
  return;
}
}
static void bna_tx_sm_cleanup_wait_entry(struct bna_tx *tx ) 
{ 


  {
  return;
}
}
static void bna_tx_sm_cleanup_wait(struct bna_tx *tx , enum bna_tx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 8U: ;
  goto ldv_50327;
  case 7U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_stopped);
  bna_tx_sm_stopped_entry(tx);
  goto ldv_50327;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         2963, (unsigned int )event);
  }
  ldv_50327: ;
  return;
}
}
static void bna_tx_sm_prio_stop_wait_entry(struct bna_tx *tx ) 
{ 


  {
  (*(tx->tx_stall_cbfn))((tx->bna)->bnad, tx);
  bna_tx_enet_stop(tx);
  return;
}
}
static void bna_tx_sm_prio_stop_wait(struct bna_tx *tx , enum bna_tx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_stop_wait);
  bna_tx_sm_stop_wait_entry(tx);
  goto ldv_50338;
  case 3U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_failed);
  bna_tx_sm_failed_entry(tx);
  (*(tx->tx_cleanup_cbfn))((tx->bna)->bnad, tx);
  goto ldv_50338;
  case 5U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_prio_cleanup_wait);
  bna_tx_sm_prio_cleanup_wait_entry(tx);
  goto ldv_50338;
  case 8U: ;
  goto ldv_50338;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         2996, (unsigned int )event);
  }
  ldv_50338: ;
  return;
}
}
static void bna_tx_sm_prio_cleanup_wait_entry(struct bna_tx *tx ) 
{ 


  {
  (*(tx->tx_cleanup_cbfn))((tx->bna)->bnad, tx);
  return;
}
}
static void bna_tx_sm_prio_cleanup_wait(struct bna_tx *tx , enum bna_tx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_cleanup_wait);
  bna_tx_sm_cleanup_wait_entry(tx);
  goto ldv_50351;
  case 3U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_failed);
  bna_tx_sm_failed_entry(tx);
  goto ldv_50351;
  case 8U: ;
  goto ldv_50351;
  case 7U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_start_wait);
  bna_tx_sm_start_wait_entry(tx);
  goto ldv_50351;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         3027, (unsigned int )event);
  }
  ldv_50351: ;
  return;
}
}
static void bna_tx_sm_failed_entry(struct bna_tx *tx ) 
{ 


  {
  return;
}
}
static void bna_tx_sm_failed(struct bna_tx *tx , enum bna_tx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 1U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_quiesce_wait);
  bna_tx_sm_quiesce_wait_entry(tx);
  goto ldv_50364;
  case 2U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_cleanup_wait);
  bna_tx_sm_cleanup_wait_entry(tx);
  goto ldv_50364;
  case 3U: ;
  goto ldv_50364;
  case 7U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_stopped);
  bna_tx_sm_stopped_entry(tx);
  goto ldv_50364;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         3057, (unsigned int )event);
  }
  ldv_50364: ;
  return;
}
}
static void bna_tx_sm_quiesce_wait_entry(struct bna_tx *tx ) 
{ 


  {
  return;
}
}
static void bna_tx_sm_quiesce_wait(struct bna_tx *tx , enum bna_tx_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_cleanup_wait);
  bna_tx_sm_cleanup_wait_entry(tx);
  goto ldv_50377;
  case 3U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_failed);
  bna_tx_sm_failed_entry(tx);
  goto ldv_50377;
  case 7U: 
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_start_wait);
  bna_tx_sm_start_wait_entry(tx);
  goto ldv_50377;
  case 8U: ;
  goto ldv_50377;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         3087, (unsigned int )event);
  }
  ldv_50377: ;
  return;
}
}
static void bna_bfi_tx_enet_start(struct bna_tx *tx ) 
{ 
  struct bfi_enet_tx_cfg_req *cfg_req ;
  struct bna_txq *txq ;
  int i ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct bna_dma_addr cur_q_addr ;
  __u16 tmp ;
  __u16 tmp___0 ;
  __u16 tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;
  __u16 tmp___4 ;

  {
  cfg_req = & tx->bfi_enet_cmd.cfg_req;
  txq = (struct bna_txq *)0;
  cfg_req->mh.msg_class = 24U;
  cfg_req->mh.msg_id = 17U;
  cfg_req->mh.msg_token = 0U;
  cfg_req->mh.enet_id = (u8 )tx->rid;
  cfg_req->mh.num_entries = 1536U;
  cfg_req->num_queues = (u8 )tx->num_txq;
  i = 0;
  goto ldv_50394;
  ldv_50393: ;
  if ((unsigned long )txq != (unsigned long )((struct bna_txq *)0)) {
    __mptr = (struct list_head  const  *)txq->qe.next;
    txq = (struct bna_txq *)__mptr;
  } else {
    __mptr___0 = (struct list_head  const  *)tx->txq_q.next;
    txq = (struct bna_txq *)__mptr___0;
  }
  cur_q_addr = *((struct bna_dma_addr *)txq->qpt.kv_qpt_ptr);
  cfg_req->q_cfg[i].q.q.pg_tbl.a32.addr_lo = txq->qpt.hw_qpt_ptr.lsb;
  cfg_req->q_cfg[i].q.q.pg_tbl.a32.addr_hi = txq->qpt.hw_qpt_ptr.msb;
  cfg_req->q_cfg[i].q.q.first_entry.a32.addr_lo = cur_q_addr.lsb;
  cfg_req->q_cfg[i].q.q.first_entry.a32.addr_hi = cur_q_addr.msb;
  tmp = __fswab16((int )((unsigned short )txq->qpt.page_count));
  cfg_req->q_cfg[i].q.q.pages = tmp;
  tmp___0 = __fswab16((int )((unsigned short )txq->qpt.page_size));
  cfg_req->q_cfg[i].q.q.page_sz = tmp___0;
  cfg_req->q_cfg[i].q.priority = txq->priority;
  cfg_req->q_cfg[i].ib.index_addr.a32.addr_lo = txq->ib.ib_seg_host_addr.lsb;
  cfg_req->q_cfg[i].ib.index_addr.a32.addr_hi = txq->ib.ib_seg_host_addr.msb;
  tmp___1 = __fswab16((int )((unsigned short )txq->ib.intr_vector));
  cfg_req->q_cfg[i].ib.intr.msix_index = tmp___1;
  i = i + 1;
  ldv_50394: ;
  if (tx->num_txq > i) {
    goto ldv_50393;
  } else {

  }
  cfg_req->ib_cfg.int_pkt_dma = 1U;
  cfg_req->ib_cfg.int_enabled = 1U;
  cfg_req->ib_cfg.int_pkt_enabled = 0U;
  cfg_req->ib_cfg.continuous_coalescing = 1U;
  cfg_req->ib_cfg.msix = (unsigned int )txq->ib.intr_type == 2U;
  tmp___2 = __fswab32((unsigned int )txq->ib.coalescing_timeo);
  cfg_req->ib_cfg.coalescing_timeout = tmp___2;
  tmp___3 = __fswab32((unsigned int )txq->ib.interpkt_timeo);
  cfg_req->ib_cfg.inter_pkt_timeout = tmp___3;
  cfg_req->ib_cfg.inter_pkt_count = (unsigned char )txq->ib.interpkt_count;
  cfg_req->tx_cfg.vlan_mode = 2U;
  tmp___4 = __fswab16((int )tx->txf_vlan_id);
  cfg_req->tx_cfg.vlan_id = tmp___4;
  cfg_req->tx_cfg.admit_tagged_frame = 1U;
  cfg_req->tx_cfg.apply_vlan_filter = 0U;
  tx->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  tx->msgq_cmd.cbarg = (void *)0;
  tx->msgq_cmd.msg_size = 328UL;
  tx->msgq_cmd.msg_hdr = & cfg_req->mh;
  bfa_msgq_cmd_post(& (tx->bna)->msgq, & tx->msgq_cmd);
  return;
}
}
static void bna_bfi_tx_enet_stop(struct bna_tx *tx ) 
{ 
  struct bfi_enet_req *req ;

  {
  req = & tx->bfi_enet_cmd.req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 18U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )tx->rid;
  req->mh.num_entries = 256U;
  tx->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status  ))0;
  tx->msgq_cmd.cbarg = (void *)0;
  tx->msgq_cmd.msg_size = 8UL;
  tx->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& (tx->bna)->msgq, & tx->msgq_cmd);
  return;
}
}
static void bna_tx_enet_stop(struct bna_tx *tx ) 
{ 
  struct bna_txq *txq ;
  struct list_head  const  *__mptr ;
  u32 intx_mask ;
  struct bna_ib *ib ;
  struct list_head  const  *__mptr___0 ;

  {
  __mptr = (struct list_head  const  *)tx->txq_q.next;
  txq = (struct bna_txq *)__mptr;
  goto ldv_50411;
  ldv_50410: 
  ib = & txq->ib;
  writel(1073741824U, (void volatile   *)ib->door_bell.doorbell_addr);
  if ((unsigned int )ib->intr_type == 1U) {
    intx_mask = readl((void const volatile   *)(tx->bna)->regs.fn_int_mask);
    writel(4294967295U, (void volatile   *)(tx->bna)->regs.fn_int_mask);
    intx_mask = (u32 )ib->intr_vector | intx_mask;
    writel(intx_mask, (void volatile   *)(tx->bna)->regs.fn_int_mask);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)txq->qe.next;
  txq = (struct bna_txq *)__mptr___0;
  ldv_50411: ;
  if ((unsigned long )(& txq->qe) != (unsigned long )(& tx->txq_q)) {
    goto ldv_50410;
  } else {

  }
  bna_bfi_tx_enet_stop(tx);
  return;
}
}
static void bna_txq_qpt_setup(struct bna_txq *txq , int page_count___0 , int page_size ,
                              struct bna_mem_descr *qpt_mem , struct bna_mem_descr *swqpt_mem ,
                              struct bna_mem_descr *page_mem ) 
{ 
  u8 *kva ;
  u64 dma ;
  struct bna_dma_addr bna_dma ;
  int i ;
  __u32 tmp ;
  __u32 tmp___0 ;
  u64 tmp_addr ;
  __u64 tmp___1 ;

  {
  txq->qpt.hw_qpt_ptr.lsb = qpt_mem->dma.lsb;
  txq->qpt.hw_qpt_ptr.msb = qpt_mem->dma.msb;
  txq->qpt.kv_qpt_ptr = qpt_mem->kva;
  txq->qpt.page_count = (u32 )page_count___0;
  txq->qpt.page_size = (u32 )page_size;
  (txq->tcb)->sw_qpt = (void **)swqpt_mem->kva;
  (txq->tcb)->sw_q = page_mem->kva;
  kva = (u8 *)page_mem->kva;
  tmp = __fswab32(page_mem->dma.msb);
  tmp___0 = __fswab32(page_mem->dma.lsb);
  dma = ((unsigned long long )tmp << 32) | (unsigned long long )tmp___0;
  i = 0;
  goto ldv_50427;
  ldv_50426: 
  *((txq->tcb)->sw_qpt + (unsigned long )i) = (void *)kva;
  kva = kva + 4096UL;
  tmp___1 = __fswab64(dma);
  tmp_addr = tmp___1;
  bna_dma.msb = ((struct bna_dma_addr *)(& tmp_addr))->msb;
  bna_dma.lsb = ((struct bna_dma_addr *)(& tmp_addr))->lsb;
  ((struct bna_dma_addr *)txq->qpt.kv_qpt_ptr + (unsigned long )i)->lsb = bna_dma.lsb;
  ((struct bna_dma_addr *)txq->qpt.kv_qpt_ptr + (unsigned long )i)->msb = bna_dma.msb;
  dma = dma + 4096ULL;
  i = i + 1;
  ldv_50427: ;
  if (i < page_count___0) {
    goto ldv_50426;
  } else {

  }

  return;
}
}
static struct bna_tx *bna_tx_get(struct bna_tx_mod *tx_mod , enum bna_tx_type type ) 
{ 
  struct bna_tx *tx ;
  int tmp ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  tx = (struct bna_tx *)0;
  tmp = list_empty((struct list_head  const  *)(& tx_mod->tx_free_q));
  if (tmp != 0) {
    return ((struct bna_tx *)0);
  } else {

  }
  if ((unsigned int )type == 0U) {
    __mptr = (struct list_head  const  *)tx_mod->tx_free_q.next;
    tx = (struct bna_tx *)__mptr;
  } else {
    __mptr___0 = (struct list_head  const  *)tx_mod->tx_free_q.prev;
    tx = (struct bna_tx *)__mptr___0;
  }
  list_del(& tx->qe);
  tx->type = type;
  return (tx);
}
}
static void bna_tx_free(struct bna_tx *tx ) 
{ 
  struct bna_tx_mod *tx_mod ;
  struct bna_txq *txq ;
  struct list_head *qe ;
  struct list_head  const  *__mptr ;
  int tmp ;

  {
  tx_mod = & (tx->bna)->tx_mod;
  goto ldv_50447;
  ldv_50446: 
  __mptr = (struct list_head  const  *)tx->txq_q.next;
  txq = (struct bna_txq *)__mptr;
  txq->tcb = (struct bna_tcb *)0;
  txq->tx = (struct bna_tx *)0;
  list_move_tail(& txq->qe, & tx_mod->txq_free_q);
  ldv_50447: 
  tmp = list_empty((struct list_head  const  *)(& tx->txq_q));
  if (tmp == 0) {
    goto ldv_50446;
  } else {

  }
  qe = tx_mod->tx_active_q.next;
  goto ldv_50451;
  ldv_50450: ;
  if ((unsigned long )(& tx->qe) == (unsigned long )qe) {
    list_del(& tx->qe);
    goto ldv_50449;
  } else {

  }
  qe = qe->next;
  ldv_50451: ;
  if ((unsigned long )(& tx_mod->tx_active_q) != (unsigned long )qe) {
    goto ldv_50450;
  } else {

  }
  ldv_50449: 
  tx->bna = (struct bna *)0;
  tx->priv = (void *)0;
  qe = tx_mod->tx_free_q.prev;
  goto ldv_50454;
  ldv_50453: ;
  if (((struct bna_tx *)qe)->rid < tx->rid) {
    goto ldv_50452;
  } else {

  }
  qe = qe->prev;
  ldv_50454: ;
  if ((unsigned long )(& tx_mod->tx_free_q) != (unsigned long )qe) {
    goto ldv_50453;
  } else {

  }
  ldv_50452: 
  list_add(& tx->qe, qe);
  return;
}
}
static void bna_tx_start(struct bna_tx *tx ) 
{ 


  {
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags | 1U);
  if (((unsigned int )tx->flags & 2U) != 0U) {
    (*(tx->fsm))((void *)tx, 1);
  } else {

  }
  return;
}
}
static void bna_tx_stop(struct bna_tx *tx ) 
{ 


  {
  tx->stop_cbfn = & bna_tx_mod_cb_tx_stopped;
  tx->stop_cbarg = (void *)(& (tx->bna)->tx_mod);
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags & 4294967294U);
  (*(tx->fsm))((void *)tx, 2);
  return;
}
}
static void bna_tx_fail(struct bna_tx *tx ) 
{ 


  {
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags & 4294967294U);
  (*(tx->fsm))((void *)tx, 3);
  return;
}
}
void bna_bfi_tx_enet_start_rsp(struct bna_tx *tx , struct bfi_msgq_mhdr *msghdr ) 
{ 
  struct bfi_enet_tx_cfg_rsp *cfg_rsp ;
  struct bna_txq *txq ;
  int i ;
  struct list_head  const  *__mptr ;
  __u32 tmp ;
  __u32 tmp___0 ;
  u32 tmp___1 ;
  struct list_head  const  *__mptr___0 ;

  {
  cfg_rsp = & tx->bfi_enet_cmd.cfg_rsp;
  txq = (struct bna_txq *)0;
  bfa_msgq_rsp_copy(& (tx->bna)->msgq, (u8 *)cfg_rsp, 108UL);
  tx->hw_id = (int )cfg_rsp->hw_id;
  i = 0;
  __mptr = (struct list_head  const  *)tx->txq_q.next;
  txq = (struct bna_txq *)__mptr;
  goto ldv_50476;
  ldv_50475: 
  tmp = __fswab32(cfg_rsp->q_handles[i].i_dbell);
  ((txq->tcb)->i_dbell)->doorbell_addr = (tx->bna)->pcidev.pci_bar_kva + (unsigned long )tmp;
  tmp___0 = __fswab32(cfg_rsp->q_handles[i].q_dbell);
  (txq->tcb)->q_dbell = (tx->bna)->pcidev.pci_bar_kva + (unsigned long )tmp___0;
  txq->hw_id = (int )cfg_rsp->q_handles[i].hw_qid;
  *((txq->tcb)->hw_consumer_index) = 0U;
  tmp___1 = 0U;
  (txq->tcb)->consumer_index = tmp___1;
  (txq->tcb)->producer_index = tmp___1;
  i = i + 1;
  __mptr___0 = (struct list_head  const  *)txq->qe.next;
  txq = (struct bna_txq *)__mptr___0;
  ldv_50476: ;
  if (tx->num_txq > i) {
    goto ldv_50475;
  } else {

  }
  (*(tx->fsm))((void *)tx, 4);
  return;
}
}
void bna_bfi_tx_enet_stop_rsp(struct bna_tx *tx , struct bfi_msgq_mhdr *msghdr ) 
{ 


  {
  (*(tx->fsm))((void *)tx, 5);
  return;
}
}
void bna_bfi_bw_update_aen(struct bna_tx_mod *tx_mod ) 
{ 
  struct bna_tx *tx ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  __mptr = (struct list_head  const  *)tx_mod->tx_active_q.next;
  tx = (struct bna_tx *)__mptr;
  goto ldv_50491;
  ldv_50490: 
  (*(tx->fsm))((void *)tx, 8);
  __mptr___0 = (struct list_head  const  *)tx->qe.next;
  tx = (struct bna_tx *)__mptr___0;
  ldv_50491: ;
  if ((unsigned long )(& tx->qe) != (unsigned long )(& tx_mod->tx_active_q)) {
    goto ldv_50490;
  } else {

  }

  return;
}
}
void bna_tx_res_req(int num_txq , int txq_depth , struct bna_res_info *res_info ) 
{ 
  u32 q_size ;
  u32 page_count___0 ;
  struct bna_mem_info *mem_info ;

  {
  res_info->res_type = 1;
  mem_info = & res_info->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = 136U;
  mem_info->num = (u32 )num_txq;
  q_size = (u32 )(txq_depth * 64);
  q_size = (q_size + 4095U) & 4294963200U;
  page_count___0 = q_size >> 12;
  (res_info + 2UL)->res_type = 1;
  mem_info = & (res_info + 2UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = page_count___0 * 8U;
  mem_info->num = (u32 )num_txq;
  (res_info + 3UL)->res_type = 1;
  mem_info = & (res_info + 3UL)->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = page_count___0 * 8U;
  mem_info->num = (u32 )num_txq;
  (res_info + 4UL)->res_type = 1;
  mem_info = & (res_info + 4UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = page_count___0 * 4096U;
  mem_info->num = (u32 )num_txq;
  (res_info + 5UL)->res_type = 1;
  mem_info = & (res_info + 5UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = 4U;
  mem_info->num = (u32 )num_txq;
  (res_info + 6UL)->res_type = 2;
  (res_info + 6UL)->res_u.intr_info.intr_type = 2;
  (res_info + 6UL)->res_u.intr_info.num = num_txq;
  return;
}
}
struct bna_tx *bna_tx_create(struct bna *bna , struct bnad *bnad , struct bna_tx_config *tx_cfg ,
                             struct bna_tx_event_cbfn  const  *tx_cbfn , struct bna_res_info *res_info ,
                             void *priv ) 
{ 
  struct bna_intr_info *intr_info ;
  struct bna_tx_mod *tx_mod ;
  struct bna_tx *tx ;
  struct bna_txq *txq ;
  int page_count___0 ;
    klee_make_symbolic(&page_count___0, sizeof(int), "page_count___0");
  int i ;
  int tmp ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;

  {
  tx_mod = & bna->tx_mod;
  intr_info = & (res_info + 6UL)->res_u.intr_info;
  page_count___0 = (int )((res_info + 4UL)->res_u.mem_info.len / 4096U);
  if (intr_info->num != 1 && intr_info->num != tx_cfg->num_txq) {
    return ((struct bna_tx *)0);
  } else {

  }
  tx = bna_tx_get(tx_mod, tx_cfg->tx_type);
  if ((unsigned long )tx == (unsigned long )((struct bna_tx *)0)) {
    return ((struct bna_tx *)0);
  } else {

  }
  tx->bna = bna;
  tx->priv = priv;
  INIT_LIST_HEAD(& tx->txq_q);
  i = 0;
  goto ldv_50519;
  ldv_50518: 
  tmp = list_empty((struct list_head  const  *)(& tx_mod->txq_free_q));
  if (tmp != 0) {
    goto err_return;
  } else {

  }
  __mptr = (struct list_head  const  *)tx_mod->txq_free_q.next;
  txq = (struct bna_txq *)__mptr;
  list_move_tail(& txq->qe, & tx->txq_q);
  txq->tx = tx;
  i = i + 1;
  ldv_50519: ;
  if (tx_cfg->num_txq > i) {
    goto ldv_50518;
  } else {

  }
  tx->tcb_setup_cbfn = tx_cbfn->tcb_setup_cbfn;
  tx->tcb_destroy_cbfn = tx_cbfn->tcb_destroy_cbfn;
  tx->tx_stall_cbfn = tx_cbfn->tx_stall_cbfn;
  tx->tx_resume_cbfn = tx_cbfn->tx_resume_cbfn;
  tx->tx_cleanup_cbfn = tx_cbfn->tx_cleanup_cbfn;
  list_add_tail(& tx->qe, & tx_mod->tx_active_q);
  tx->num_txq = tx_cfg->num_txq;
  tx->flags = 0;
  if ((int )(tx->bna)->tx_mod.flags & 1) {
    switch ((unsigned int )tx->type) {
    case 0U: ;
    if (((unsigned int )(tx->bna)->tx_mod.flags & 2U) == 0U) {
      tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags | 1U);
    } else {

    }
    goto ldv_50522;
    case 1U: ;
    if (((unsigned int )(tx->bna)->tx_mod.flags & 2U) != 0U) {
      tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags | 1U);
    } else {

    }
    goto ldv_50522;
    }
    ldv_50522: ;
  } else {

  }
  i = 0;
  __mptr___0 = (struct list_head  const  *)tx->txq_q.next;
  txq = (struct bna_txq *)__mptr___0;
  goto ldv_50529;
  ldv_50528: 
  txq->tcb = (struct bna_tcb *)(res_info->res_u.mem_info.mdl + (unsigned long )i)->kva;
  txq->tx_packets = 0ULL;
  txq->tx_bytes = 0ULL;
  txq->ib.ib_seg_host_addr.lsb = ((res_info + 5UL)->res_u.mem_info.mdl + (unsigned long )i)->dma.lsb;
  txq->ib.ib_seg_host_addr.msb = ((res_info + 5UL)->res_u.mem_info.mdl + (unsigned long )i)->dma.msb;
  txq->ib.ib_seg_host_addr_kva = ((res_info + 5UL)->res_u.mem_info.mdl + (unsigned long )i)->kva;
  txq->ib.intr_type = intr_info->intr_type;
  txq->ib.intr_vector = intr_info->num == 1 ? (intr_info->idl)->vector : (intr_info->idl + (unsigned long )i)->vector;
  if ((unsigned int )intr_info->intr_type == 1U) {
    txq->ib.intr_vector = (int )(1UL << txq->ib.intr_vector);
  } else {

  }
  txq->ib.coalescing_timeo = (u8 )tx_cfg->coalescing_timeo;
  txq->ib.interpkt_timeo = 15;
  txq->ib.interpkt_count = 12;
  (txq->tcb)->q_depth = (u32 )tx_cfg->txq_depth;
  (txq->tcb)->unmap_q = ((res_info + 1UL)->res_u.mem_info.mdl + (unsigned long )i)->kva;
  (txq->tcb)->hw_consumer_index = (u32 volatile   *)txq->ib.ib_seg_host_addr_kva;
  (txq->tcb)->i_dbell = & txq->ib.door_bell;
  (txq->tcb)->intr_type = txq->ib.intr_type;
  (txq->tcb)->intr_vector = txq->ib.intr_vector;
  (txq->tcb)->txq = txq;
  (txq->tcb)->bnad = bnad;
  (txq->tcb)->id = i;
  bna_txq_qpt_setup(txq, page_count___0, 4096, (res_info + 2UL)->res_u.mem_info.mdl + (unsigned long )i,
                    (res_info + 3UL)->res_u.mem_info.mdl + (unsigned long )i, (res_info + 4UL)->res_u.mem_info.mdl + (unsigned long )i);
  if ((unsigned long )tx->tcb_setup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                       struct bna_tcb * ))0)) {
    (*(tx->tcb_setup_cbfn))(bna->bnad, txq->tcb);
  } else {

  }
  if (tx_cfg->num_txq == 8) {
    txq->priority = (u8 )(txq->tcb)->id;
  } else {
    txq->priority = (u8 )tx_mod->default_prio;
  }
  i = i + 1;
  __mptr___1 = (struct list_head  const  *)txq->qe.next;
  txq = (struct bna_txq *)__mptr___1;
  ldv_50529: ;
  if ((unsigned long )(& txq->qe) != (unsigned long )(& tx->txq_q)) {
    goto ldv_50528;
  } else {

  }
  tx->txf_vlan_id = 0U;
  tx->fsm = (void (*)(void * , int  ))(& bna_tx_sm_stopped);
  bna_tx_sm_stopped_entry(tx);
  tx_mod->rid_mask = tx_mod->rid_mask | (u32 )(1UL << tx->rid);
  return (tx);
  err_return: 
  bna_tx_free(tx);
  return ((struct bna_tx *)0);
}
}
void bna_tx_destroy(struct bna_tx *tx ) 
{ 
  struct bna_txq *txq ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  __mptr = (struct list_head  const  *)tx->txq_q.next;
  txq = (struct bna_txq *)__mptr;
  goto ldv_50540;
  ldv_50539: ;
  if ((unsigned long )tx->tcb_destroy_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                         struct bna_tcb * ))0)) {
    (*(tx->tcb_destroy_cbfn))((tx->bna)->bnad, txq->tcb);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)txq->qe.next;
  txq = (struct bna_txq *)__mptr___0;
  ldv_50540: ;
  if ((unsigned long )(& txq->qe) != (unsigned long )(& tx->txq_q)) {
    goto ldv_50539;
  } else {

  }
  (tx->bna)->tx_mod.rid_mask = (tx->bna)->tx_mod.rid_mask & ~ ((u32 )(1UL << tx->rid));
  bna_tx_free(tx);
  return;
}
}
void bna_tx_enable(struct bna_tx *tx ) 
{ 


  {
  if ((unsigned long )tx->fsm != (unsigned long )((void (*)(void * , int  ))(& bna_tx_sm_stopped))) {
    return;
  } else {

  }
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags | 2U);
  if ((int )tx->flags & 1) {
    (*(tx->fsm))((void *)tx, 1);
  } else {

  }
  return;
}
}
void bna_tx_disable(struct bna_tx *tx , enum bna_cleanup_type type , void (*cbfn)(void * ,
                                                                                  struct bna_tx * ) ) 
{ 


  {
  if ((unsigned int )type == 1U) {
    (*cbfn)((void *)(tx->bna)->bnad, tx);
    return;
  } else {

  }
  tx->stop_cbfn = cbfn;
  tx->stop_cbarg = (void *)(tx->bna)->bnad;
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags & 4294967293U);
  (*(tx->fsm))((void *)tx, 2);
  return;
}
}
void bna_tx_cleanup_complete(struct bna_tx *tx ) 
{ 


  {
  (*(tx->fsm))((void *)tx, 7);
  return;
}
}
static void bna_tx_mod_cb_tx_stopped(void *arg , struct bna_tx *tx ) 
{ 
  struct bna_tx_mod *tx_mod ;

  {
  tx_mod = (struct bna_tx_mod *)arg;
  bfa_wc_down(& tx_mod->tx_stop_wc);
  return;
}
}
static void bna_tx_mod_cb_tx_stopped_all(void *arg ) 
{ 
  struct bna_tx_mod *tx_mod ;

  {
  tx_mod = (struct bna_tx_mod *)arg;
  if ((unsigned long )tx_mod->stop_cbfn != (unsigned long )((void (*)(struct bna_enet * ))0)) {
    (*(tx_mod->stop_cbfn))(& (tx_mod->bna)->enet);
  } else {

  }
  tx_mod->stop_cbfn = (void (*)(struct bna_enet * ))0;
  return;
}
}
void bna_tx_mod_init(struct bna_tx_mod *tx_mod , struct bna *bna , struct bna_res_info *res_info ) 
{ 
  int i ;

  {
  tx_mod->bna = bna;
  tx_mod->flags = 0;
  tx_mod->tx = (struct bna_tx *)(res_info->res_u.mem_info.mdl)->kva;
  tx_mod->txq = (struct bna_txq *)((res_info + 1UL)->res_u.mem_info.mdl)->kva;
  INIT_LIST_HEAD(& tx_mod->tx_free_q);
  INIT_LIST_HEAD(& tx_mod->tx_active_q);
  INIT_LIST_HEAD(& tx_mod->txq_free_q);
  i = 0;
  goto ldv_50571;
  ldv_50570: 
  (tx_mod->tx + (unsigned long )i)->rid = i;
  list_add_tail(& (tx_mod->tx + (unsigned long )i)->qe, & tx_mod->tx_free_q);
  list_add_tail(& (tx_mod->txq + (unsigned long )i)->qe, & tx_mod->txq_free_q);
  i = i + 1;
  ldv_50571: ;
  if (bna->ioceth.attr.num_txq > i) {
    goto ldv_50570;
  } else {

  }
  tx_mod->prio_map = 255U;
  tx_mod->default_prio = 0;
  tx_mod->iscsi_over_cee = 0;
  tx_mod->iscsi_prio = -1;
  return;
}
}
void bna_tx_mod_uninit(struct bna_tx_mod *tx_mod ) 
{ 


  {
  tx_mod->bna = (struct bna *)0;
  return;
}
}
void bna_tx_mod_start(struct bna_tx_mod *tx_mod , enum bna_tx_type type ) 
{ 
  struct bna_tx *tx ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  tx_mod->flags = (enum bna_tx_mod_flags )((unsigned int )tx_mod->flags | 1U);
  if ((unsigned int )type == 1U) {
    tx_mod->flags = (enum bna_tx_mod_flags )((unsigned int )tx_mod->flags | 2U);
  } else {

  }
  __mptr = (struct list_head  const  *)tx_mod->tx_active_q.next;
  tx = (struct bna_tx *)__mptr;
  goto ldv_50586;
  ldv_50585: ;
  if ((unsigned int )tx->type == (unsigned int )type) {
    bna_tx_start(tx);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)tx->qe.next;
  tx = (struct bna_tx *)__mptr___0;
  ldv_50586: ;
  if ((unsigned long )(& tx->qe) != (unsigned long )(& tx_mod->tx_active_q)) {
    goto ldv_50585;
  } else {

  }

  return;
}
}
void bna_tx_mod_stop(struct bna_tx_mod *tx_mod , enum bna_tx_type type ) 
{ 
  struct bna_tx *tx ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  tx_mod->flags = (enum bna_tx_mod_flags )((unsigned int )tx_mod->flags & 4294967294U);
  tx_mod->flags = (enum bna_tx_mod_flags )((unsigned int )tx_mod->flags & 4294967293U);
  tx_mod->stop_cbfn = & bna_enet_cb_tx_stopped;
  bfa_wc_init(& tx_mod->tx_stop_wc, & bna_tx_mod_cb_tx_stopped_all, (void *)tx_mod);
  __mptr = (struct list_head  const  *)tx_mod->tx_active_q.next;
  tx = (struct bna_tx *)__mptr;
  goto ldv_50598;
  ldv_50597: ;
  if ((unsigned int )tx->type == (unsigned int )type) {
    bfa_wc_up(& tx_mod->tx_stop_wc);
    bna_tx_stop(tx);
  } else {

  }
  __mptr___0 = (struct list_head  const  *)tx->qe.next;
  tx = (struct bna_tx *)__mptr___0;
  ldv_50598: ;
  if ((unsigned long )(& tx->qe) != (unsigned long )(& tx_mod->tx_active_q)) {
    goto ldv_50597;
  } else {

  }
  bfa_wc_wait(& tx_mod->tx_stop_wc);
  return;
}
}
void bna_tx_mod_fail(struct bna_tx_mod *tx_mod ) 
{ 
  struct bna_tx *tx ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  tx_mod->flags = (enum bna_tx_mod_flags )((unsigned int )tx_mod->flags & 4294967294U);
  tx_mod->flags = (enum bna_tx_mod_flags )((unsigned int )tx_mod->flags & 4294967293U);
  __mptr = (struct list_head  const  *)tx_mod->tx_active_q.next;
  tx = (struct bna_tx *)__mptr;
  goto ldv_50609;
  ldv_50608: 
  bna_tx_fail(tx);
  __mptr___0 = (struct list_head  const  *)tx->qe.next;
  tx = (struct bna_tx *)__mptr___0;
  ldv_50609: ;
  if ((unsigned long )(& tx->qe) != (unsigned long )(& tx_mod->tx_active_q)) {
    goto ldv_50608;
  } else {

  }

  return;
}
}
void bna_tx_coalescing_timeo_set(struct bna_tx *tx , int coalescing_timeo ) 
{ 
  struct bna_txq *txq ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  __mptr = (struct list_head  const  *)tx->txq_q.next;
  txq = (struct bna_txq *)__mptr;
  goto ldv_50621;
  ldv_50620: 
  bna_ib_coalescing_timeo_set(& txq->ib, (int )((u8 )coalescing_timeo));
  __mptr___0 = (struct list_head  const  *)txq->qe.next;
  txq = (struct bna_txq *)__mptr___0;
  ldv_50621: ;
  if ((unsigned long )(& txq->qe) != (unsigned long )(& tx->txq_q)) {
    goto ldv_50620;
  } else {

  }

  return;
}
}
bool ldv_queue_work_on_256(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_257(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_258(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_259(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_260(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
int ldv_pskb_expand_head_272(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_274(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_276(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_277(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_278(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_279(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_280(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
int ldv_pskb_expand_head_281(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_282(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
bool ldv_queue_work_on_302(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_304(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_303(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_306(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_305(struct workqueue_struct *ldv_func_arg1 ) ;
struct sk_buff *ldv_skb_clone_320(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_328(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_322(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_318(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_326(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_327(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_323(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_324(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_325(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
__inline static void __bfa_dma_be_addr_set(union bfi_addr_u *dma_addr , u64 pa ) 
{ 
  __u32 tmp ;
  __u32 tmp___0 ;

  {
  tmp = __fswab32((__u32 )pa);
  dma_addr->a32.addr_lo = tmp;
  tmp___0 = __fswab32((unsigned int )(pa >> 32ULL));
  dma_addr->a32.addr_hi = tmp___0;
  return;
}
}
bool bfa_nw_ioc_mbox_queue(struct bfa_ioc *ioc , struct bfa_mbox_cmd *cmd , void (*cbfn)(void * ) ,
                           void *cbarg ) ;
void bfa_nw_ioc_mbox_regisr(struct bfa_ioc *ioc , enum bfi_mclass mc , void (*cbfn)(void * ,
                                                                                    struct bfi_mbmsg * ) ,
                            void *cbarg ) ;
bool bfa_nw_ioc_is_disabled(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_notify_register(struct bfa_ioc *ioc , struct bfa_ioc_notify *notify ) ;
static void bfa_msgq_cmdq_dbell(struct bfa_msgq_cmdq *cmdq ) ;
static void bfa_msgq_cmdq_copy_rsp(struct bfa_msgq_cmdq *cmdq ) ;
static void cmdq_sm_stopped(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event ) ;
static void cmdq_sm_stopped_entry(struct bfa_msgq_cmdq *cmdq ) ;
static void cmdq_sm_init_wait(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event ) ;
static void cmdq_sm_init_wait_entry(struct bfa_msgq_cmdq *cmdq ) ;
static void cmdq_sm_ready(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event ) ;
static void cmdq_sm_ready_entry(struct bfa_msgq_cmdq *cmdq ) ;
static void cmdq_sm_dbell_wait(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event ) ;
static void cmdq_sm_dbell_wait_entry(struct bfa_msgq_cmdq *cmdq ) ;
static void cmdq_sm_stopped_entry(struct bfa_msgq_cmdq *cmdq ) 
{ 
  struct bfa_msgq_cmd_entry *cmdq_ent ;
  struct list_head  const  *__mptr ;
  void (*cbfn)(void * , enum bfa_status  ) ;
  void *cbarg ;
  int tmp ;

  {
  cmdq->producer_index = 0U;
  cmdq->consumer_index = 0U;
  cmdq->flags = 0;
  cmdq->token = 0U;
  cmdq->offset = 0;
  cmdq->bytes_to_copy = 0;
  goto ldv_47569;
  ldv_47568: 
  __mptr = (struct list_head  const  *)cmdq->pending_q.next;
  cmdq_ent = (struct bfa_msgq_cmd_entry *)__mptr;
  list_del(& cmdq_ent->qe);
  cbfn = cmdq_ent->cbfn;
  cbarg = cmdq_ent->cbarg;
  cmdq_ent->cbfn = (void (*)(void * , enum bfa_status  ))0;
  cmdq_ent->cbarg = (void *)0;
  if ((unsigned long )cbfn != (unsigned long )((void (*)(void * , enum bfa_status  ))0)) {
    (*cbfn)(cbarg, 1);
  } else {

  }
  ldv_47569: 
  tmp = list_empty((struct list_head  const  *)(& cmdq->pending_q));
  if (tmp == 0) {
    goto ldv_47568;
  } else {

  }

  return;
}
}
static void cmdq_sm_stopped(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 1U: 
  cmdq->fsm = (void (*)(void * , int  ))(& cmdq_sm_init_wait);
  cmdq_sm_init_wait_entry(cmdq);
  goto ldv_47576;
  case 2U: ;
  case 3U: ;
  goto ldv_47576;
  case 4U: 
  cmdq->flags = (enum bfa_msgq_cmdq_flags )((unsigned int )cmdq->flags | 1U);
  goto ldv_47576;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         94, (unsigned int )event);
  }
  ldv_47576: ;
  return;
}
}
static void cmdq_sm_init_wait_entry(struct bfa_msgq_cmdq *cmdq ) 
{ 


  {
  bfa_wc_down(& (cmdq->msgq)->init_wc);
  return;
}
}
static void cmdq_sm_init_wait(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U: 
  cmdq->fsm = (void (*)(void * , int  ))(& cmdq_sm_stopped);
  cmdq_sm_stopped_entry(cmdq);
  goto ldv_47590;
  case 4U: 
  cmdq->flags = (enum bfa_msgq_cmdq_flags )((unsigned int )cmdq->flags | 1U);
  goto ldv_47590;
  case 5U: ;
  if ((int )cmdq->flags & 1) {
    cmdq->flags = (enum bfa_msgq_cmdq_flags )((unsigned int )cmdq->flags & 4294967294U);
    cmdq->fsm = (void (*)(void * , int  ))(& cmdq_sm_dbell_wait);
    cmdq_sm_dbell_wait_entry(cmdq);
  } else {
    cmdq->fsm = (void (*)(void * , int  ))(& cmdq_sm_ready);
    cmdq_sm_ready_entry(cmdq);
  }
  goto ldv_47590;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         126, (unsigned int )event);
  }
  ldv_47590: ;
  return;
}
}
static void cmdq_sm_ready_entry(struct bfa_msgq_cmdq *cmdq ) 
{ 


  {
  return;
}
}
static void cmdq_sm_ready(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U: 
  cmdq->fsm = (void (*)(void * , int  ))(& cmdq_sm_stopped);
  cmdq_sm_stopped_entry(cmdq);
  goto ldv_47603;
  case 4U: 
  cmdq->fsm = (void (*)(void * , int  ))(& cmdq_sm_dbell_wait);
  cmdq_sm_dbell_wait_entry(cmdq);
  goto ldv_47603;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         149, (unsigned int )event);
  }
  ldv_47603: ;
  return;
}
}
static void cmdq_sm_dbell_wait_entry(struct bfa_msgq_cmdq *cmdq ) 
{ 


  {
  bfa_msgq_cmdq_dbell(cmdq);
  return;
}
}
static void cmdq_sm_dbell_wait(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U: 
  cmdq->fsm = (void (*)(void * , int  ))(& cmdq_sm_stopped);
  cmdq_sm_stopped_entry(cmdq);
  goto ldv_47615;
  case 4U: 
  cmdq->flags = (enum bfa_msgq_cmdq_flags )((unsigned int )cmdq->flags | 1U);
  goto ldv_47615;
  case 6U: ;
  if ((int )cmdq->flags & 1) {
    cmdq->flags = (enum bfa_msgq_cmdq_flags )((unsigned int )cmdq->flags & 4294967294U);
    cmdq->fsm = (void (*)(void * , int  ))(& cmdq_sm_dbell_wait);
    cmdq_sm_dbell_wait_entry(cmdq);
  } else {
    cmdq->fsm = (void (*)(void * , int  ))(& cmdq_sm_ready);
    cmdq_sm_ready_entry(cmdq);
  }
  goto ldv_47615;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         181, (unsigned int )event);
  }
  ldv_47615: ;
  return;
}
}
static void bfa_msgq_cmdq_dbell_ready(void *arg ) 
{ 
  struct bfa_msgq_cmdq *cmdq ;

  {
  cmdq = (struct bfa_msgq_cmdq *)arg;
  (*(cmdq->fsm))((void *)cmdq, 6);
  return;
}
}
static void bfa_msgq_cmdq_dbell(struct bfa_msgq_cmdq *cmdq ) 
{ 
  struct bfi_msgq_h2i_db *dbell ;
  __u16 tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  dbell = (struct bfi_msgq_h2i_db *)(& cmdq->dbell_mb.msg);
  memset((void *)dbell, 0, 6UL);
  dbell->mh.msg_class = 23U;
  dbell->mh.msg_id = 2U;
  dbell->mh.mtag.h2i.fn_lpu = 0U;
  dbell->mh.mtag.i2htok = 0U;
  tmp = __fswab16((int )cmdq->producer_index);
  dbell->idx.cmdq_pi = tmp;
  tmp___0 = bfa_nw_ioc_mbox_queue((cmdq->msgq)->ioc, & cmdq->dbell_mb, & bfa_msgq_cmdq_dbell_ready,
                                  (void *)cmdq);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    bfa_msgq_cmdq_dbell_ready((void *)cmdq);
  } else {

  }
  return;
}
}
static void __cmd_copy(struct bfa_msgq_cmdq *cmdq , struct bfa_msgq_cmd_entry *cmd ) 
{ 
  size_t len ;
  int num_entries ;
    klee_make_symbolic(&num_entries, sizeof(int), "num_entries");
  size_t to_copy ;
  u8 *src ;
  u8 *dst ;

  {
  len = cmd->msg_size;
  num_entries = 0;
  src = (u8 *)cmd->msg_hdr;
  dst = (u8 *)cmdq->addr.kva;
  dst = dst + (unsigned long )((int )cmdq->producer_index * 64);
  goto ldv_47637;
  ldv_47636: 
  to_copy = 64UL < len ? 64UL : len;
  memcpy((void *)dst, (void const   *)src, to_copy);
  len = len - to_copy;
  src = src + 64UL;
  cmdq->producer_index = (u16 )((int )((short )((unsigned int )cmdq->producer_index + 1U)) & (int )((short )((unsigned int )cmdq->depth + 65535U)));
  dst = (u8 *)cmdq->addr.kva;
  dst = dst + (unsigned long )((int )cmdq->producer_index * 64);
  num_entries = num_entries + 1;
  ldv_47637: ;
  if (len != 0UL) {
    goto ldv_47636;
  } else {

  }

  return;
}
}
static void bfa_msgq_cmdq_ci_update(struct bfa_msgq_cmdq *cmdq , struct bfi_mbmsg *mb ) 
{ 
  struct bfi_msgq_i2h_db *dbell ;
  struct bfa_msgq_cmd_entry *cmd ;
  int posted ;
    klee_make_symbolic(&posted, sizeof(int), "posted");
  __u16 tmp ;
  struct list_head  const  *__mptr ;
  void (*cbfn)(void * , enum bfa_status  ) ;
  void *cbarg ;
  __u16 tmp___0 ;
  int tmp___1 ;

  {
  dbell = (struct bfi_msgq_i2h_db *)mb;
  posted = 0;
  tmp = __fswab16((int )dbell->idx.cmdq_ci);
  cmdq->consumer_index = tmp;
  goto ldv_47652;
  ldv_47651: 
  __mptr = (struct list_head  const  *)cmdq->pending_q.next;
  cmd = (struct bfa_msgq_cmd_entry *)__mptr;
  tmp___0 = __fswab16((int )(cmd->msg_hdr)->num_entries);
  if ((int )tmp___0 <= ((((int )cmdq->consumer_index - (int )cmdq->producer_index) + -1) & ((int )cmdq->depth + -1))) {
    list_del(& cmd->qe);
    __cmd_copy(cmdq, cmd);
    posted = 1;
    cbfn = cmd->cbfn;
    cbarg = cmd->cbarg;
    cmd->cbfn = (void (*)(void * , enum bfa_status  ))0;
    cmd->cbarg = (void *)0;
    if ((unsigned long )cbfn != (unsigned long )((void (*)(void * , enum bfa_status  ))0)) {
      (*cbfn)(cbarg, 0);
    } else {

    }
  } else {
    goto ldv_47650;
  }
  ldv_47652: 
  tmp___1 = list_empty((struct list_head  const  *)(& cmdq->pending_q));
  if (tmp___1 == 0) {
    goto ldv_47651;
  } else {

  }
  ldv_47650: ;
  if (posted != 0) {
    (*(cmdq->fsm))((void *)cmdq, 4);
  } else {

  }
  return;
}
}
static void bfa_msgq_cmdq_copy_next(void *arg ) 
{ 
  struct bfa_msgq_cmdq *cmdq ;

  {
  cmdq = (struct bfa_msgq_cmdq *)arg;
  if (cmdq->bytes_to_copy != 0) {
    bfa_msgq_cmdq_copy_rsp(cmdq);
  } else {

  }
  return;
}
}
static void bfa_msgq_cmdq_copy_req(struct bfa_msgq_cmdq *cmdq , struct bfi_mbmsg *mb ) 
{ 
  struct bfi_msgq_i2h_cmdq_copy_req *req ;
  __u16 tmp ;
  __u16 tmp___0 ;

  {
  req = (struct bfi_msgq_i2h_cmdq_copy_req *)mb;
  cmdq->token = 0U;
  tmp = __fswab16((int )req->offset);
  cmdq->offset = (int )tmp;
  tmp___0 = __fswab16((int )req->len);
  cmdq->bytes_to_copy = (int )tmp___0;
  bfa_msgq_cmdq_copy_rsp(cmdq);
  return;
}
}
static void bfa_msgq_cmdq_copy_rsp(struct bfa_msgq_cmdq *cmdq ) 
{ 
  struct bfi_msgq_h2i_cmdq_copy_rsp *rsp ;
  int copied ;
    klee_make_symbolic(&copied, sizeof(int), "copied");
  u8 *addr ;
  __u16 tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  rsp = (struct bfi_msgq_h2i_cmdq_copy_rsp *)(& cmdq->copy_mb.msg);
  addr = (u8 *)cmdq->addr.kva;
  memset((void *)rsp, 0, 32UL);
  rsp->mh.msg_class = 23U;
  rsp->mh.msg_id = 4U;
  rsp->mh.mtag.h2i.fn_lpu = 0U;
  tmp = __fswab16((int )cmdq->token);
  rsp->mh.mtag.i2htok = tmp;
  copied = 28 < cmdq->bytes_to_copy ? 28 : cmdq->bytes_to_copy;
  addr = addr + (unsigned long )cmdq->offset;
  memcpy((void *)(& rsp->data), (void const   *)addr, (size_t )copied);
  cmdq->token = (u16 )((int )cmdq->token + 1);
  cmdq->offset = cmdq->offset + copied;
  cmdq->bytes_to_copy = cmdq->bytes_to_copy - copied;
  tmp___0 = bfa_nw_ioc_mbox_queue((cmdq->msgq)->ioc, & cmdq->copy_mb, & bfa_msgq_cmdq_copy_next,
                                  (void *)cmdq);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    bfa_msgq_cmdq_copy_next((void *)cmdq);
  } else {

  }
  return;
}
}
static void bfa_msgq_cmdq_attach(struct bfa_msgq_cmdq *cmdq , struct bfa_msgq *msgq ) 
{ 


  {
  cmdq->depth = 128U;
  INIT_LIST_HEAD(& cmdq->pending_q);
  cmdq->msgq = msgq;
  cmdq->fsm = (void (*)(void * , int  ))(& cmdq_sm_stopped);
  cmdq_sm_stopped_entry(cmdq);
  return;
}
}
static void bfa_msgq_rspq_dbell(struct bfa_msgq_rspq *rspq ) ;
static void rspq_sm_stopped(struct bfa_msgq_rspq *rspq , enum rspq_event event ) ;
static void rspq_sm_stopped_entry(struct bfa_msgq_rspq *rspq ) ;
static void rspq_sm_init_wait(struct bfa_msgq_rspq *rspq , enum rspq_event event ) ;
static void rspq_sm_init_wait_entry(struct bfa_msgq_rspq *rspq ) ;
static void rspq_sm_ready(struct bfa_msgq_rspq *rspq , enum rspq_event event ) ;
static void rspq_sm_ready_entry(struct bfa_msgq_rspq *rspq ) ;
static void rspq_sm_dbell_wait(struct bfa_msgq_rspq *rspq , enum rspq_event event ) ;
static void rspq_sm_dbell_wait_entry(struct bfa_msgq_rspq *rspq ) ;
static void rspq_sm_stopped_entry(struct bfa_msgq_rspq *rspq ) 
{ 


  {
  rspq->producer_index = 0U;
  rspq->consumer_index = 0U;
  rspq->flags = 0;
  return;
}
}
static void rspq_sm_stopped(struct bfa_msgq_rspq *rspq , enum rspq_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 1U: 
  rspq->fsm = (void (*)(void * , int  ))(& rspq_sm_init_wait);
  rspq_sm_init_wait_entry(rspq);
  goto ldv_47709;
  case 2U: ;
  case 3U: ;
  goto ldv_47709;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         359, (unsigned int )event);
  }
  ldv_47709: ;
  return;
}
}
static void rspq_sm_init_wait_entry(struct bfa_msgq_rspq *rspq ) 
{ 


  {
  bfa_wc_down(& (rspq->msgq)->init_wc);
  return;
}
}
static void rspq_sm_init_wait(struct bfa_msgq_rspq *rspq , enum rspq_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 2U: 
  rspq->fsm = (void (*)(void * , int  ))(& rspq_sm_stopped);
  rspq_sm_stopped_entry(rspq);
  goto ldv_47722;
  case 5U: 
  rspq->fsm = (void (*)(void * , int  ))(& rspq_sm_ready);
  rspq_sm_ready_entry(rspq);
  goto ldv_47722;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         383, (unsigned int )event);
  }
  ldv_47722: ;
  return;
}
}
static void rspq_sm_ready_entry(struct bfa_msgq_rspq *rspq ) 
{ 


  {
  return;
}
}
static void rspq_sm_ready(struct bfa_msgq_rspq *rspq , enum rspq_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U: 
  rspq->fsm = (void (*)(void * , int  ))(& rspq_sm_stopped);
  rspq_sm_stopped_entry(rspq);
  goto ldv_47734;
  case 4U: 
  rspq->fsm = (void (*)(void * , int  ))(& rspq_sm_dbell_wait);
  rspq_sm_dbell_wait_entry(rspq);
  goto ldv_47734;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         406, (unsigned int )event);
  }
  ldv_47734: ;
  return;
}
}
static void rspq_sm_dbell_wait_entry(struct bfa_msgq_rspq *rspq ) 
{ 
  bool tmp ;
  int tmp___0 ;

  {
  tmp = bfa_nw_ioc_is_disabled((rspq->msgq)->ioc);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    bfa_msgq_rspq_dbell(rspq);
  } else {

  }
  return;
}
}
static void rspq_sm_dbell_wait(struct bfa_msgq_rspq *rspq , enum rspq_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U: 
  rspq->fsm = (void (*)(void * , int  ))(& rspq_sm_stopped);
  rspq_sm_stopped_entry(rspq);
  goto ldv_47746;
  case 4U: 
  rspq->flags = (enum bfa_msgq_rspq_flags )((unsigned int )rspq->flags | 1U);
  goto ldv_47746;
  case 6U: ;
  if ((int )rspq->flags & 1) {
    rspq->flags = (enum bfa_msgq_rspq_flags )((unsigned int )rspq->flags & 4294967294U);
    rspq->fsm = (void (*)(void * , int  ))(& rspq_sm_dbell_wait);
    rspq_sm_dbell_wait_entry(rspq);
  } else {
    rspq->fsm = (void (*)(void * , int  ))(& rspq_sm_ready);
    rspq_sm_ready_entry(rspq);
  }
  goto ldv_47746;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         439, (unsigned int )event);
  }
  ldv_47746: ;
  return;
}
}
static void bfa_msgq_rspq_dbell_ready(void *arg ) 
{ 
  struct bfa_msgq_rspq *rspq ;

  {
  rspq = (struct bfa_msgq_rspq *)arg;
  (*(rspq->fsm))((void *)rspq, 6);
  return;
}
}
static void bfa_msgq_rspq_dbell(struct bfa_msgq_rspq *rspq ) 
{ 
  struct bfi_msgq_h2i_db *dbell ;
  __u16 tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  dbell = (struct bfi_msgq_h2i_db *)(& rspq->dbell_mb.msg);
  memset((void *)dbell, 0, 6UL);
  dbell->mh.msg_class = 23U;
  dbell->mh.msg_id = 3U;
  dbell->mh.mtag.h2i.fn_lpu = 0U;
  dbell->mh.mtag.i2htok = 0U;
  tmp = __fswab16((int )rspq->consumer_index);
  dbell->idx.rspq_ci = tmp;
  tmp___0 = bfa_nw_ioc_mbox_queue((rspq->msgq)->ioc, & rspq->dbell_mb, & bfa_msgq_rspq_dbell_ready,
                                  (void *)rspq);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    bfa_msgq_rspq_dbell_ready((void *)rspq);
  } else {

  }
  return;
}
}
static void bfa_msgq_rspq_pi_update(struct bfa_msgq_rspq *rspq , struct bfi_mbmsg *mb ) 
{ 
  struct bfi_msgq_i2h_db *dbell ;
  struct bfi_msgq_mhdr *msghdr ;
  int num_entries ;
  int mc ;
    klee_make_symbolic(&mc, sizeof(int), "mc");
  u8 *rspq_qe ;
  __u16 tmp ;
  __u16 tmp___0 ;

  {
  dbell = (struct bfi_msgq_i2h_db *)mb;
  tmp = __fswab16((int )dbell->idx.rspq_pi);
  rspq->producer_index = tmp;
  goto ldv_47769;
  ldv_47768: 
  rspq_qe = (u8 *)rspq->addr.kva;
  rspq_qe = rspq_qe + (unsigned long )((int )rspq->consumer_index * 64);
  msghdr = (struct bfi_msgq_mhdr *)rspq_qe;
  mc = (int )msghdr->msg_class;
  tmp___0 = __fswab16((int )msghdr->num_entries);
  num_entries = (int )tmp___0;
  if (mc > 33 || (unsigned long )rspq->rsphdlr[mc].cbfn == (unsigned long )((void (*)(void * ,
                                                                                      struct bfi_msgq_mhdr * ))0)) {
    goto ldv_47767;
  } else {

  }
  (*(rspq->rsphdlr[mc].cbfn))(rspq->rsphdlr[mc].cbarg, msghdr);
  rspq->consumer_index = (u16 )((int )((short )((int )rspq->consumer_index + (int )((unsigned short )num_entries))) & (int )((short )((unsigned int )rspq->depth + 65535U)));
  ldv_47769: ;
  if ((int )rspq->consumer_index != (int )rspq->producer_index) {
    goto ldv_47768;
  } else {

  }
  ldv_47767: 
  (*(rspq->fsm))((void *)rspq, 4);
  return;
}
}
static void bfa_msgq_rspq_attach(struct bfa_msgq_rspq *rspq , struct bfa_msgq *msgq ) 
{ 


  {
  rspq->depth = 128U;
  rspq->msgq = msgq;
  rspq->fsm = (void (*)(void * , int  ))(& rspq_sm_stopped);
  rspq_sm_stopped_entry(rspq);
  return;
}
}
static void bfa_msgq_init_rsp(struct bfa_msgq *msgq , struct bfi_mbmsg *mb ) 
{ 


  {
  (*(msgq->cmdq.fsm))((void *)(& msgq->cmdq), 5);
  (*(msgq->rspq.fsm))((void *)(& msgq->rspq), 5);
  return;
}
}
static void bfa_msgq_init(void *arg ) 
{ 
  struct bfa_msgq *msgq ;
  struct bfi_msgq_cfg_req *msgq_cfg ;
  __u16 tmp ;
  __u16 tmp___0 ;

  {
  msgq = (struct bfa_msgq *)arg;
  msgq_cfg = (struct bfi_msgq_cfg_req *)(& msgq->init_mb.msg);
  memset((void *)msgq_cfg, 0, 28UL);
  msgq_cfg->mh.msg_class = 23U;
  msgq_cfg->mh.msg_id = 1U;
  msgq_cfg->mh.mtag.h2i.fn_lpu = 0U;
  msgq_cfg->mh.mtag.i2htok = 0U;
  __bfa_dma_be_addr_set(& msgq_cfg->cmdq.addr, msgq->cmdq.addr.pa);
  tmp = __fswab16((int )msgq->cmdq.depth);
  msgq_cfg->cmdq.q_depth = tmp;
  __bfa_dma_be_addr_set(& msgq_cfg->rspq.addr, msgq->rspq.addr.pa);
  tmp___0 = __fswab16((int )msgq->rspq.depth);
  msgq_cfg->rspq.q_depth = tmp___0;
  bfa_nw_ioc_mbox_queue(msgq->ioc, & msgq->init_mb, (void (*)(void * ))0, (void *)0);
  return;
}
}
static void bfa_msgq_isr(void *cbarg , struct bfi_mbmsg *msg ) 
{ 
  struct bfa_msgq *msgq ;
  long tmp ;

  {
  msgq = (struct bfa_msgq *)cbarg;
  switch ((int )msg->mh.msg_id) {
  case 129: 
  bfa_msgq_init_rsp(msgq, msg);
  goto ldv_47789;
  case 130: 
  bfa_msgq_rspq_pi_update(& msgq->rspq, msg);
  goto ldv_47789;
  case 131: 
  bfa_msgq_cmdq_ci_update(& msgq->cmdq, msg);
  goto ldv_47789;
  case 132: 
  bfa_msgq_cmdq_copy_req(& msgq->cmdq, msg);
  goto ldv_47789;
  default: 
  tmp = ldv__builtin_expect(1L, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c"),
                         "i" (556), "i" (12UL));
    ldv_47794: ;
    goto ldv_47794;
  } else {

  }
  }
  ldv_47789: ;
  return;
}
}
static void bfa_msgq_notify(void *cbarg , enum bfa_ioc_event event ) 
{ 
  struct bfa_msgq *msgq ;

  {
  msgq = (struct bfa_msgq *)cbarg;
  switch ((unsigned int )event) {
  case 1U: 
  bfa_wc_init(& msgq->init_wc, & bfa_msgq_init, (void *)msgq);
  bfa_wc_up(& msgq->init_wc);
  (*(msgq->cmdq.fsm))((void *)(& msgq->cmdq), 1);
  bfa_wc_up(& msgq->init_wc);
  (*(msgq->rspq.fsm))((void *)(& msgq->rspq), 1);
  bfa_wc_wait(& msgq->init_wc);
  goto ldv_47801;
  case 2U: 
  (*(msgq->cmdq.fsm))((void *)(& msgq->cmdq), 2);
  (*(msgq->rspq.fsm))((void *)(& msgq->rspq), 2);
  goto ldv_47801;
  case 3U: 
  (*(msgq->cmdq.fsm))((void *)(& msgq->cmdq), 3);
  (*(msgq->rspq.fsm))((void *)(& msgq->rspq), 3);
  goto ldv_47801;
  default: ;
  goto ldv_47801;
  }
  ldv_47801: ;
  return;
}
}
u32 bfa_msgq_meminfo(void) 
{ 
  int __y ;
    klee_make_symbolic(&__y, sizeof(int), "__y");
  int __y___0 ;
    klee_make_symbolic(&__y___0, sizeof(int), "__y___0");

  {
  __y = 256;
  __y___0 = 256;
  return ((u32 )(((__y + 8191) / __y) * __y + ((__y___0 + 8191) / __y___0) * __y___0));
}
}
void bfa_msgq_memclaim(struct bfa_msgq *msgq , u8 *kva , u64 pa ) 
{ 
  int __y ;
  int __y___0 ;

  {
  msgq->cmdq.addr.kva = (void *)kva;
  msgq->cmdq.addr.pa = pa;
  __y = 256;
  kva = kva + (unsigned long )(((__y + 8191) / __y) * __y);
  __y___0 = 256;
  pa = (u64 )(((__y___0 + 8191) / __y___0) * __y___0) + pa;
  msgq->rspq.addr.kva = (void *)kva;
  msgq->rspq.addr.pa = pa;
  return;
}
}
void bfa_msgq_attach(struct bfa_msgq *msgq , struct bfa_ioc *ioc ) 
{ 


  {
  msgq->ioc = ioc;
  bfa_msgq_cmdq_attach(& msgq->cmdq, msgq);
  bfa_msgq_rspq_attach(& msgq->rspq, msgq);
  bfa_nw_ioc_mbox_regisr(msgq->ioc, 23, & bfa_msgq_isr, (void *)msgq);
  msgq->ioc_notify.cbfn = & bfa_msgq_notify;
  msgq->ioc_notify.cbarg = (void *)msgq;
  bfa_nw_ioc_notify_register(msgq->ioc, & msgq->ioc_notify);
  return;
}
}
void bfa_msgq_regisr(struct bfa_msgq *msgq , enum bfi_mclass mc , void (*cbfn)(void * ,
                                                                               struct bfi_msgq_mhdr * ) ,
                     void *cbarg ) 
{ 


  {
  msgq->rspq.rsphdlr[(unsigned int )mc].cbfn = cbfn;
  msgq->rspq.rsphdlr[(unsigned int )mc].cbarg = cbarg;
  return;
}
}
void bfa_msgq_cmd_post(struct bfa_msgq *msgq , struct bfa_msgq_cmd_entry *cmd ) 
{ 
  void (*cbfn)(void * , enum bfa_status  ) ;
  void *cbarg ;
  __u16 tmp ;

  {
  tmp = __fswab16((int )(cmd->msg_hdr)->num_entries);
  if ((int )tmp <= ((((int )msgq->cmdq.consumer_index - (int )msgq->cmdq.producer_index) + -1) & ((int )msgq->cmdq.depth + -1))) {
    __cmd_copy(& msgq->cmdq, cmd);
    cbfn = cmd->cbfn;
    cbarg = cmd->cbarg;
    cmd->cbfn = (void (*)(void * , enum bfa_status  ))0;
    cmd->cbarg = (void *)0;
    if ((unsigned long )cbfn != (unsigned long )((void (*)(void * , enum bfa_status  ))0)) {
      (*cbfn)(cbarg, 0);
    } else {

    }
    (*(msgq->cmdq.fsm))((void *)(& msgq->cmdq), 4);
  } else {
    list_add_tail(& cmd->qe, & msgq->cmdq.pending_q);
  }
  return;
}
}
void bfa_msgq_rsp_copy(struct bfa_msgq *msgq , u8 *buf , size_t buf_len ) 
{ 
  struct bfa_msgq_rspq *rspq ;
  size_t len ;
  size_t to_copy ;
  int ci ;
    klee_make_symbolic(&ci, sizeof(int), "ci");
  u8 *src ;
  u8 *dst ;

  {
  rspq = & msgq->rspq;
  len = buf_len;
  ci = (int )rspq->consumer_index;
  src = (u8 *)rspq->addr.kva;
  src = src + (unsigned long )(ci * 64);
  dst = buf;
  goto ldv_47849;
  ldv_47848: 
  to_copy = 64UL < len ? 64UL : len;
  memcpy((void *)dst, (void const   *)src, to_copy);
  len = len - to_copy;
  dst = dst + 64UL;
  ci = (ci + 1) & ((int )rspq->depth + -1);
  src = (u8 *)rspq->addr.kva;
  src = src + (unsigned long )(ci * 64);
  ldv_47849: ;
  if (len != 0UL) {
    goto ldv_47848;
  } else {

  }

  return;
}
}
bool ldv_queue_work_on_302(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_303(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_304(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_305(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_306(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
int ldv_pskb_expand_head_318(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_320(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_322(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_323(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_324(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_325(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_326(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
int ldv_pskb_expand_head_327(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_328(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
extern void do_gettimeofday(struct timeval * ) ;
extern int del_timer(struct timer_list * ) ;
int ldv_del_timer_376(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_377(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_378(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_381(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_382(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_384(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_386(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_387(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_388(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_390(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_391(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_393(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_396(struct timer_list *ldv_func_arg1 ) ;
int ldv_mod_timer_375(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_379(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_380(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_383(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_385(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_389(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_392(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_394(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_395(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_397(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
bool ldv_queue_work_on_348(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_350(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_349(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_352(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_351(struct workqueue_struct *ldv_func_arg1 ) ;
extern void __const_udelay(unsigned long  ) ;
struct sk_buff *ldv_skb_clone_366(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_374(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_368(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_364(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_372(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_373(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_369(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_370(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_371(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
__inline static int bfa_sm_to_state(struct bfa_sm_table  const  *smt , void (*sm)(void * ,
                                                                                  int  ) ) 
{ 
  int i ;

  {
  i = 0;
  goto ldv_46557;
  ldv_46556: 
  i = i + 1;
  ldv_46557: ;
  if ((unsigned long )(smt + (unsigned long )i)->sm != (unsigned long )((void (*)(void * ,
                                                                                  int  ))0) && (unsigned long )((void (*)(void * ,
                                                                                                                          int  ))(smt + (unsigned long )i)->sm) != (unsigned long )sm) {
    goto ldv_46556;
  } else {

  }

  return ((int )(smt + (unsigned long )i)->state);
}
}
__inline static void __bfa_alen_set(struct bfi_alen *alen , u32 len , u64 pa ) 
{ 
  __u32 tmp ;

  {
  tmp = __fswab32(len);
  alen->al_len = tmp;
  __bfa_dma_be_addr_set(& alen->al_addr, pa);
  return;
}
}
void bfa_nw_ioc_set_ct_hwif(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_set_ct2_hwif(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_ct2_poweron(struct bfa_ioc *ioc ) ;
bool bfa_nw_ioc_is_operational(struct bfa_ioc *ioc ) ;
bool bfa_nw_ioc_sem_get(void *sem_reg ) ;
void bfa_nw_ioc_sem_release(void *sem_reg ) ;
void bfa_nw_ioc_hw_sem_release(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_fwver_get(struct bfa_ioc *ioc , struct bfi_ioc_image_hdr *fwhdr ) ;
bool bfa_nw_ioc_fwver_cmp(struct bfa_ioc *ioc , struct bfi_ioc_image_hdr *fwhdr ) ;
u32 *bfa_cb_image_get_chunk(enum bfi_asic_gen asic_gen , u32 off ) ;
u32 bfa_cb_image_get_size(enum bfi_asic_gen asic_gen ) ;
static bool bfa_nw_auto_recover  =    1;
static void bfa_ioc_hw_sem_init(struct bfa_ioc *ioc ) ;
static void bfa_ioc_hw_sem_get(struct bfa_ioc *ioc ) ;
static void bfa_ioc_hw_sem_get_cancel(struct bfa_ioc *ioc ) ;
static void bfa_ioc_hwinit(struct bfa_ioc *ioc , bool force ) ;
static void bfa_ioc_poll_fwinit(struct bfa_ioc *ioc ) ;
static void bfa_ioc_send_enable(struct bfa_ioc *ioc ) ;
static void bfa_ioc_send_disable(struct bfa_ioc *ioc ) ;
static void bfa_ioc_send_getattr(struct bfa_ioc *ioc ) ;
static void bfa_ioc_hb_monitor(struct bfa_ioc *ioc ) ;
static void bfa_ioc_hb_stop(struct bfa_ioc *ioc ) ;
static void bfa_ioc_reset(struct bfa_ioc *ioc , bool force ) ;
static void bfa_ioc_mbox_poll(struct bfa_ioc *ioc ) ;
static void bfa_ioc_mbox_flush(struct bfa_ioc *ioc ) ;
static void bfa_ioc_recover(struct bfa_ioc *ioc ) ;
static void bfa_ioc_event_notify(struct bfa_ioc *ioc , enum bfa_ioc_event event ) ;
static void bfa_ioc_disable_comp(struct bfa_ioc *ioc ) ;
static void bfa_ioc_lpu_stop(struct bfa_ioc *ioc ) ;
static void bfa_nw_ioc_debug_save_ftrc(struct bfa_ioc *ioc ) ;
static void bfa_ioc_fail_notify(struct bfa_ioc *ioc ) ;
static void bfa_ioc_pf_enabled(struct bfa_ioc *ioc ) ;
static void bfa_ioc_pf_disabled(struct bfa_ioc *ioc ) ;
static void bfa_ioc_pf_failed(struct bfa_ioc *ioc ) ;
static void bfa_ioc_pf_hwfailed(struct bfa_ioc *ioc ) ;
static void bfa_ioc_pf_fwmismatch(struct bfa_ioc *ioc ) ;
static enum bfa_status bfa_ioc_boot(struct bfa_ioc *ioc , enum bfi_fwboot_type boot_type ,
                                    u32 boot_env ) ;
static u32 bfa_ioc_smem_pgnum(struct bfa_ioc *ioc , u32 fmaddr ) ;
static void bfa_ioc_get_adapter_serial_num(struct bfa_ioc *ioc , char *serial_num ) ;
static void bfa_ioc_get_adapter_fw_ver(struct bfa_ioc *ioc , char *fw_ver ) ;
static void bfa_ioc_get_pci_chip_rev(struct bfa_ioc *ioc , char *chip_rev ) ;
static void bfa_ioc_get_adapter_optrom_ver(struct bfa_ioc *ioc , char *optrom_ver ) ;
static void bfa_ioc_get_adapter_manufacturer(struct bfa_ioc *ioc , char *manufacturer ) ;
static void bfa_ioc_get_adapter_model(struct bfa_ioc *ioc , char *model ) ;
static u64 bfa_ioc_get_pwwn(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_uninit(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_uninit_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_reset(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_reset_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_enabling(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_enabling_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_getattr(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_getattr_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_op(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_op_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_fail_retry(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_fail_retry_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_fail(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_fail_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_disabling(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_disabling_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_disabled(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_disabled_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_hwfail(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_hwfail_entry(struct bfa_ioc *ioc ) ;
static struct bfa_sm_table ioc_sm_table[10U]  = 
  {      {(void (*)(void * , int  ))(& bfa_ioc_sm_uninit), 1, 0}, 
        {(void (*)(void * , int  ))(& bfa_ioc_sm_reset), 2, 0}, 
        {(void (*)(void * , int  ))(& bfa_ioc_sm_enabling), 12, 0}, 
        {(void (*)(void * , int  ))(& bfa_ioc_sm_getattr), 5, 0}, 
        {(void (*)(void * , int  ))(& bfa_ioc_sm_op), 6, 0}, 
        {(void (*)(void * , int  ))(& bfa_ioc_sm_fail_retry), 7, 0}, 
        {(void (*)(void * , int  ))(& bfa_ioc_sm_fail), 8, 0}, 
        {(void (*)(void * , int  ))(& bfa_ioc_sm_disabling), 9, 0}, 
        {(void (*)(void * , int  ))(& bfa_ioc_sm_disabled), 10, 0}, 
        {(void (*)(void * , int  ))(& bfa_ioc_sm_hwfail), 13, 0}};
static void bfa_iocpf_enable(struct bfa_ioc *ioc ) ;
static void bfa_iocpf_disable(struct bfa_ioc *ioc ) ;
static void bfa_iocpf_fail(struct bfa_ioc *ioc ) ;
static void bfa_iocpf_initfail(struct bfa_ioc *ioc ) ;
static void bfa_iocpf_getattrfail(struct bfa_ioc *ioc ) ;
static void bfa_iocpf_stop(struct bfa_ioc *ioc ) ;
static void bfa_iocpf_sm_reset(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_reset_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_fwcheck(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_fwcheck_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_mismatch(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_mismatch_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_semwait(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_semwait_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_hwinit(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_hwinit_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_enabling(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_enabling_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_ready(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_ready_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_initfail_sync(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_initfail_sync_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_initfail(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_initfail_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_fail_sync(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_fail_sync_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_fail(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_fail_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_disabling(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_disabling_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_disabling_sync(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_disabling_sync_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_disabled(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_disabled_entry(struct bfa_iocpf *iocpf ) ;
static struct bfa_sm_table iocpf_sm_table[14U]  = 
  {      {(void (*)(void * , int  ))(& bfa_iocpf_sm_reset), 1, 0}, 
        {(void (*)(void * , int  ))(& bfa_iocpf_sm_fwcheck), 9, 0}, 
        {(void (*)(void * , int  ))(& bfa_iocpf_sm_mismatch), 9, 0}, 
        {(void (*)(void * , int  ))(& bfa_iocpf_sm_semwait), 2, 0}, 
        {(void (*)(void * , int  ))(& bfa_iocpf_sm_hwinit), 3, 0}, 
        {(void (*)(void * , int  ))(& bfa_iocpf_sm_enabling), 3, 0}, 
        {(void (*)(void * , int  ))(& bfa_iocpf_sm_ready), 4, 0}, 
        {(void (*)(void * , int  ))(& bfa_iocpf_sm_initfail_sync), 5, 0}, 
        {(void (*)(void * , int  ))(& bfa_iocpf_sm_initfail), 5, 0}, 
        {(void (*)(void * , int  ))(& bfa_iocpf_sm_fail_sync), 6, 0}, 
        {(void (*)(void * , int  ))(& bfa_iocpf_sm_fail), 6, 0}, 
        {(void (*)(void * , int  ))(& bfa_iocpf_sm_disabling), 7, 0}, 
        {(void (*)(void * , int  ))(& bfa_iocpf_sm_disabling_sync), 7, 0}, 
        {(void (*)(void * , int  ))(& bfa_iocpf_sm_disabled), 8, 0}};
static void bfa_ioc_sm_uninit_entry(struct bfa_ioc *ioc ) 
{ 


  {
  return;
}
}
static void bfa_ioc_sm_uninit(struct bfa_ioc *ioc , enum ioc_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 1U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_reset);
  bfa_ioc_sm_reset_entry(ioc);
  goto ldv_47838;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         229, (unsigned int )event);
  }
  ldv_47838: ;
  return;
}
}
static void bfa_ioc_sm_reset_entry(struct bfa_ioc *ioc ) 
{ 


  {
  ioc->iocpf.fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(& ioc->iocpf);
  return;
}
}
static void bfa_ioc_sm_reset(struct bfa_ioc *ioc , enum ioc_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_enabling);
  bfa_ioc_sm_enabling_entry(ioc);
  goto ldv_47848;
  case 3U: 
  bfa_ioc_disable_comp(ioc);
  goto ldv_47848;
  case 4U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_uninit);
  bfa_ioc_sm_uninit_entry(ioc);
  goto ldv_47848;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         258, (unsigned int )event);
  }
  ldv_47848: ;
  return;
}
}
static void bfa_ioc_sm_enabling_entry(struct bfa_ioc *ioc ) 
{ 


  {
  bfa_iocpf_enable(ioc);
  return;
}
}
static void bfa_ioc_sm_enabling(struct bfa_ioc *ioc , enum ioc_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 5U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_getattr);
  bfa_ioc_sm_getattr_entry(ioc);
  goto ldv_47860;
  case 8U: ;
  case 10U: 
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_fail);
  bfa_ioc_sm_fail_entry(ioc);
  if ((unsigned int )event != 8U) {
    bfa_iocpf_initfail(ioc);
  } else {

  }
  goto ldv_47860;
  case 12U: 
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_hwfail);
  bfa_ioc_sm_hwfail_entry(ioc);
  goto ldv_47860;
  case 3U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_disabling);
  bfa_ioc_sm_disabling_entry(ioc);
  goto ldv_47860;
  case 4U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_uninit);
  bfa_ioc_sm_uninit_entry(ioc);
  bfa_iocpf_stop(ioc);
  goto ldv_47860;
  case 2U: ;
  goto ldv_47860;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         306, (unsigned int )event);
  }
  ldv_47860: ;
  return;
}
}
static void bfa_ioc_sm_getattr_entry(struct bfa_ioc *ioc ) 
{ 
  unsigned long tmp ;

  {
  tmp = msecs_to_jiffies(3000U);
  ldv_mod_timer_375(& ioc->ioc_timer, tmp + (unsigned long )jiffies);
  bfa_ioc_send_getattr(ioc);
  return;
}
}
static void bfa_ioc_sm_getattr(struct bfa_ioc *ioc , enum ioc_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 6U: 
  ldv_del_timer_376(& ioc->ioc_timer);
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_op);
  bfa_ioc_sm_op_entry(ioc);
  goto ldv_47876;
  case 8U: ;
  case 10U: 
  ldv_del_timer_377(& ioc->ioc_timer);
  case 11U: 
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_fail);
  bfa_ioc_sm_fail_entry(ioc);
  if ((unsigned int )event != 8U) {
    bfa_iocpf_getattrfail(ioc);
  } else {

  }
  goto ldv_47876;
  case 3U: 
  ldv_del_timer_378(& ioc->ioc_timer);
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_disabling);
  bfa_ioc_sm_disabling_entry(ioc);
  goto ldv_47876;
  case 2U: ;
  goto ldv_47876;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         349, (unsigned int )event);
  }
  ldv_47876: ;
  return;
}
}
static void bfa_ioc_sm_op_entry(struct bfa_ioc *ioc ) 
{ 


  {
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 0);
  bfa_ioc_event_notify(ioc, 1);
  bfa_ioc_hb_monitor(ioc);
  return;
}
}
static void bfa_ioc_sm_op(struct bfa_ioc *ioc , enum ioc_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: ;
  goto ldv_47891;
  case 3U: 
  bfa_ioc_hb_stop(ioc);
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_disabling);
  bfa_ioc_sm_disabling_entry(ioc);
  goto ldv_47891;
  case 8U: ;
  case 10U: 
  bfa_ioc_hb_stop(ioc);
  case 9U: ;
  if ((int )ioc->iocpf.auto_recover) {
    ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_fail_retry);
    bfa_ioc_sm_fail_retry_entry(ioc);
  } else {
    ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_fail);
    bfa_ioc_sm_fail_entry(ioc);
  }
  bfa_ioc_fail_notify(ioc);
  if ((unsigned int )event != 8U) {
    bfa_iocpf_fail(ioc);
  } else {

  }
  goto ldv_47891;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         390, (unsigned int )event);
  }
  ldv_47891: ;
  return;
}
}
static void bfa_ioc_sm_disabling_entry(struct bfa_ioc *ioc ) 
{ 


  {
  bfa_iocpf_disable(ioc);
  return;
}
}
static void bfa_ioc_sm_disabling(struct bfa_ioc *ioc , enum ioc_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 7U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_disabled);
  bfa_ioc_sm_disabled_entry(ioc);
  goto ldv_47905;
  case 10U: 
  bfa_iocpf_fail(ioc);
  goto ldv_47905;
  case 12U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_hwfail);
  bfa_ioc_sm_hwfail_entry(ioc);
  bfa_ioc_disable_comp(ioc);
  goto ldv_47905;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         424, (unsigned int )event);
  }
  ldv_47905: ;
  return;
}
}
static void bfa_ioc_sm_disabled_entry(struct bfa_ioc *ioc ) 
{ 


  {
  bfa_ioc_disable_comp(ioc);
  return;
}
}
static void bfa_ioc_sm_disabled(struct bfa_ioc *ioc , enum ioc_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_enabling);
  bfa_ioc_sm_enabling_entry(ioc);
  goto ldv_47917;
  case 3U: 
  (*((ioc->cbfn)->disable_cbfn))((void *)ioc->bfa);
  goto ldv_47917;
  case 4U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_uninit);
  bfa_ioc_sm_uninit_entry(ioc);
  bfa_iocpf_stop(ioc);
  goto ldv_47917;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         453, (unsigned int )event);
  }
  ldv_47917: ;
  return;
}
}
static void bfa_ioc_sm_fail_retry_entry(struct bfa_ioc *ioc ) 
{ 


  {
  return;
}
}
static void bfa_ioc_sm_fail_retry(struct bfa_ioc *ioc , enum ioc_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 5U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_getattr);
  bfa_ioc_sm_getattr_entry(ioc);
  goto ldv_47929;
  case 8U: ;
  case 10U: 
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_fail);
  bfa_ioc_sm_fail_entry(ioc);
  if ((unsigned int )event != 8U) {
    bfa_iocpf_initfail(ioc);
  } else {

  }
  goto ldv_47929;
  case 12U: 
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_hwfail);
  bfa_ioc_sm_hwfail_entry(ioc);
  goto ldv_47929;
  case 2U: ;
  goto ldv_47929;
  case 3U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_disabling);
  bfa_ioc_sm_disabling_entry(ioc);
  goto ldv_47929;
  case 4U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_uninit);
  bfa_ioc_sm_uninit_entry(ioc);
  bfa_iocpf_stop(ioc);
  goto ldv_47929;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         500, (unsigned int )event);
  }
  ldv_47929: ;
  return;
}
}
static void bfa_ioc_sm_fail_entry(struct bfa_ioc *ioc ) 
{ 


  {
  return;
}
}
static void bfa_ioc_sm_fail(struct bfa_ioc *ioc , enum ioc_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  goto ldv_47945;
  case 3U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_disabling);
  bfa_ioc_sm_disabling_entry(ioc);
  goto ldv_47945;
  case 4U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_uninit);
  bfa_ioc_sm_uninit_entry(ioc);
  bfa_iocpf_stop(ioc);
  goto ldv_47945;
  case 10U: ;
  goto ldv_47945;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         532, (unsigned int )event);
  }
  ldv_47945: ;
  return;
}
}
static void bfa_ioc_sm_hwfail_entry(struct bfa_ioc *ioc ) 
{ 


  {
  return;
}
}
static void bfa_ioc_sm_hwfail(struct bfa_ioc *ioc , enum ioc_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  goto ldv_47958;
  case 3U: 
  (*((ioc->cbfn)->disable_cbfn))((void *)ioc->bfa);
  goto ldv_47958;
  case 4U: 
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_uninit);
  bfa_ioc_sm_uninit_entry(ioc);
  goto ldv_47958;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         560, (unsigned int )event);
  }
  ldv_47958: ;
  return;
}
}
static void bfa_iocpf_sm_reset_entry(struct bfa_iocpf *iocpf ) 
{ 


  {
  iocpf->fw_mismatch_notified = 0;
  iocpf->auto_recover = bfa_nw_auto_recover;
  return;
}
}
static void bfa_iocpf_sm_reset(struct bfa_iocpf *iocpf , enum iocpf_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 1U: 
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_fwcheck);
  bfa_iocpf_sm_fwcheck_entry(iocpf);
  goto ldv_47970;
  case 3U: ;
  goto ldv_47970;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         587, (unsigned int )event);
  }
  ldv_47970: ;
  return;
}
}
static void bfa_iocpf_sm_fwcheck_entry(struct bfa_iocpf *iocpf ) 
{ 


  {
  bfa_ioc_hw_sem_init(iocpf->ioc);
  bfa_ioc_hw_sem_get(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_fwcheck(struct bfa_iocpf *iocpf , enum iocpf_event event ) 
{ 
  struct bfa_ioc *ioc ;
  unsigned long tmp ;
  bool tmp___0 ;
  bool tmp___1 ;

  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 10U: 
  tmp___1 = (*((ioc->ioc_hwif)->ioc_firmware_lock))(ioc);
  if ((int )tmp___1) {
    tmp___0 = (*((ioc->ioc_hwif)->ioc_sync_start))(ioc);
    if ((int )tmp___0) {
      (*((ioc->ioc_hwif)->ioc_sync_join))(ioc);
      iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_hwinit);
      bfa_iocpf_sm_hwinit_entry(iocpf);
    } else {
      (*((ioc->ioc_hwif)->ioc_firmware_unlock))(ioc);
      bfa_nw_ioc_hw_sem_release(ioc);
      tmp = msecs_to_jiffies(500U);
      ldv_mod_timer_379(& ioc->sem_timer, tmp + (unsigned long )jiffies);
    }
  } else {
    bfa_nw_ioc_hw_sem_release(ioc);
    iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_mismatch);
    bfa_iocpf_sm_mismatch_entry(iocpf);
  }
  goto ldv_47982;
  case 12U: 
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_fail);
  bfa_iocpf_sm_fail_entry(iocpf);
  bfa_ioc_pf_hwfailed(ioc);
  goto ldv_47982;
  case 2U: 
  bfa_ioc_hw_sem_get_cancel(ioc);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(iocpf);
  bfa_ioc_pf_disabled(ioc);
  goto ldv_47982;
  case 3U: 
  bfa_ioc_hw_sem_get_cancel(ioc);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(iocpf);
  goto ldv_47982;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         640, (unsigned int )event);
  }
  ldv_47982: ;
  return;
}
}
static void bfa_iocpf_sm_mismatch_entry(struct bfa_iocpf *iocpf ) 
{ 
  unsigned long tmp ;

  {
  if (! iocpf->fw_mismatch_notified) {
    bfa_ioc_pf_fwmismatch(iocpf->ioc);
  } else {

  }
  iocpf->fw_mismatch_notified = 1;
  tmp = msecs_to_jiffies(3000U);
  ldv_mod_timer_380(& (iocpf->ioc)->iocpf_timer, tmp + (unsigned long )jiffies);
  return;
}
}
static void bfa_iocpf_sm_mismatch(struct bfa_iocpf *iocpf , enum iocpf_event event ) 
{ 
  struct bfa_ioc *ioc ;

  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 11U: 
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_fwcheck);
  bfa_iocpf_sm_fwcheck_entry(iocpf);
  goto ldv_47996;
  case 2U: 
  ldv_del_timer_381(& ioc->iocpf_timer);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(iocpf);
  bfa_ioc_pf_disabled(ioc);
  goto ldv_47996;
  case 3U: 
  ldv_del_timer_382(& ioc->iocpf_timer);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(iocpf);
  goto ldv_47996;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         680, (unsigned int )event);
  }
  ldv_47996: ;
  return;
}
}
static void bfa_iocpf_sm_semwait_entry(struct bfa_iocpf *iocpf ) 
{ 


  {
  bfa_ioc_hw_sem_get(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_semwait(struct bfa_iocpf *iocpf , enum iocpf_event event ) 
{ 
  struct bfa_ioc *ioc ;
  unsigned long tmp ;
  bool tmp___0 ;

  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 10U: 
  tmp___0 = (*((ioc->ioc_hwif)->ioc_sync_complete))(ioc);
  if ((int )tmp___0) {
    (*((ioc->ioc_hwif)->ioc_sync_join))(ioc);
    iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_hwinit);
    bfa_iocpf_sm_hwinit_entry(iocpf);
  } else {
    bfa_nw_ioc_hw_sem_release(ioc);
    tmp = msecs_to_jiffies(500U);
    ldv_mod_timer_383(& ioc->sem_timer, tmp + (unsigned long )jiffies);
  }
  goto ldv_48009;
  case 12U: 
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_fail);
  bfa_iocpf_sm_fail_entry(iocpf);
  bfa_ioc_pf_hwfailed(ioc);
  goto ldv_48009;
  case 2U: 
  bfa_ioc_hw_sem_get_cancel(ioc);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_disabling_sync);
  bfa_iocpf_sm_disabling_sync_entry(iocpf);
  goto ldv_48009;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         720, (unsigned int )event);
  }
  ldv_48009: ;
  return;
}
}
static void bfa_iocpf_sm_hwinit_entry(struct bfa_iocpf *iocpf ) 
{ 


  {
  iocpf->poll_time = 0U;
  bfa_ioc_reset(iocpf->ioc, 0);
  return;
}
}
static void bfa_iocpf_sm_hwinit(struct bfa_iocpf *iocpf , enum iocpf_event event ) 
{ 
  struct bfa_ioc *ioc ;

  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 4U: 
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_enabling);
  bfa_iocpf_sm_enabling_entry(iocpf);
  goto ldv_48022;
  case 11U: 
  bfa_nw_ioc_hw_sem_release(ioc);
  bfa_ioc_pf_failed(ioc);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_initfail_sync);
  bfa_iocpf_sm_initfail_sync_entry(iocpf);
  goto ldv_48022;
  case 2U: 
  ldv_del_timer_384(& ioc->iocpf_timer);
  (*((ioc->ioc_hwif)->ioc_sync_leave))(ioc);
  bfa_nw_ioc_hw_sem_release(ioc);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_disabled);
  bfa_iocpf_sm_disabled_entry(iocpf);
  goto ldv_48022;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         758, (unsigned int )event);
  }
  ldv_48022: ;
  return;
}
}
static void bfa_iocpf_sm_enabling_entry(struct bfa_iocpf *iocpf ) 
{ 
  unsigned long tmp ;

  {
  tmp = msecs_to_jiffies(3000U);
  ldv_mod_timer_385(& (iocpf->ioc)->iocpf_timer, tmp + (unsigned long )jiffies);
  (*(((iocpf->ioc)->cbfn)->reset_cbfn))((void *)(iocpf->ioc)->bfa);
  bfa_ioc_send_enable(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_enabling(struct bfa_iocpf *iocpf , enum iocpf_event event ) 
{ 
  struct bfa_ioc *ioc ;

  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 5U: 
  ldv_del_timer_386(& ioc->iocpf_timer);
  bfa_nw_ioc_hw_sem_release(ioc);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_ready);
  bfa_iocpf_sm_ready_entry(iocpf);
  goto ldv_48035;
  case 8U: 
  ldv_del_timer_387(& ioc->iocpf_timer);
  case 11U: 
  bfa_nw_ioc_hw_sem_release(ioc);
  if ((unsigned int )event == 11U) {
    bfa_ioc_pf_failed(ioc);
  } else {

  }
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_initfail_sync);
  bfa_iocpf_sm_initfail_sync_entry(iocpf);
  goto ldv_48035;
  case 2U: 
  ldv_del_timer_388(& ioc->iocpf_timer);
  bfa_nw_ioc_hw_sem_release(ioc);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_disabling);
  bfa_iocpf_sm_disabling_entry(iocpf);
  goto ldv_48035;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         808, (unsigned int )event);
  }
  ldv_48035: ;
  return;
}
}
static void bfa_iocpf_sm_ready_entry(struct bfa_iocpf *iocpf ) 
{ 


  {
  bfa_ioc_pf_enabled(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_ready(struct bfa_iocpf *iocpf , enum iocpf_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_disabling);
  bfa_iocpf_sm_disabling_entry(iocpf);
  goto ldv_48048;
  case 9U: 
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_initfail_sync);
  bfa_iocpf_sm_initfail_sync_entry(iocpf);
  goto ldv_48048;
  case 7U: 
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_fail_sync);
  bfa_iocpf_sm_fail_sync_entry(iocpf);
  goto ldv_48048;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         835, (unsigned int )event);
  }
  ldv_48048: ;
  return;
}
}
static void bfa_iocpf_sm_disabling_entry(struct bfa_iocpf *iocpf ) 
{ 
  unsigned long tmp ;

  {
  tmp = msecs_to_jiffies(3000U);
  ldv_mod_timer_389(& (iocpf->ioc)->iocpf_timer, tmp + (unsigned long )jiffies);
  bfa_ioc_send_disable(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_disabling(struct bfa_iocpf *iocpf , enum iocpf_event event ) 
{ 
  struct bfa_ioc *ioc ;

  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 6U: 
  ldv_del_timer_390(& ioc->iocpf_timer);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_disabling_sync);
  bfa_iocpf_sm_disabling_sync_entry(iocpf);
  goto ldv_48061;
  case 7U: 
  ldv_del_timer_391(& ioc->iocpf_timer);
  case 11U: 
  (*((ioc->ioc_hwif)->ioc_set_fwstate))(ioc, 8);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_disabling_sync);
  bfa_iocpf_sm_disabling_sync_entry(iocpf);
  goto ldv_48061;
  case 5U: ;
  goto ldv_48061;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         874, (unsigned int )event);
  }
  ldv_48061: ;
  return;
}
}
static void bfa_iocpf_sm_disabling_sync_entry(struct bfa_iocpf *iocpf ) 
{ 


  {
  bfa_ioc_hw_sem_get(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_disabling_sync(struct bfa_iocpf *iocpf , enum iocpf_event event ) 
{ 
  struct bfa_ioc *ioc ;

  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 10U: 
  (*((ioc->ioc_hwif)->ioc_sync_leave))(ioc);
  bfa_nw_ioc_hw_sem_release(ioc);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_disabled);
  bfa_iocpf_sm_disabled_entry(iocpf);
  goto ldv_48075;
  case 12U: 
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_fail);
  bfa_iocpf_sm_fail_entry(iocpf);
  bfa_ioc_pf_hwfailed(ioc);
  goto ldv_48075;
  case 7U: ;
  goto ldv_48075;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         906, (unsigned int )event);
  }
  ldv_48075: ;
  return;
}
}
static void bfa_iocpf_sm_disabled_entry(struct bfa_iocpf *iocpf ) 
{ 


  {
  bfa_ioc_mbox_flush(iocpf->ioc);
  bfa_ioc_pf_disabled(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_disabled(struct bfa_iocpf *iocpf , enum iocpf_event event ) 
{ 
  struct bfa_ioc *ioc ;

  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 1U: 
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_semwait);
  bfa_iocpf_sm_semwait_entry(iocpf);
  goto ldv_48088;
  case 3U: 
  (*((ioc->ioc_hwif)->ioc_firmware_unlock))(ioc);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(iocpf);
  goto ldv_48088;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         934, (unsigned int )event);
  }
  ldv_48088: ;
  return;
}
}
static void bfa_iocpf_sm_initfail_sync_entry(struct bfa_iocpf *iocpf ) 
{ 


  {
  bfa_nw_ioc_debug_save_ftrc(iocpf->ioc);
  bfa_ioc_hw_sem_get(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_initfail_sync(struct bfa_iocpf *iocpf , enum iocpf_event event ) 
{ 
  struct bfa_ioc *ioc ;

  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 10U: 
  (*((ioc->ioc_hwif)->ioc_notify_fail))(ioc);
  (*((ioc->ioc_hwif)->ioc_sync_leave))(ioc);
  (*((ioc->ioc_hwif)->ioc_set_fwstate))(ioc, 8);
  bfa_nw_ioc_hw_sem_release(ioc);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_initfail);
  bfa_iocpf_sm_initfail_entry(iocpf);
  goto ldv_48100;
  case 12U: 
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_fail);
  bfa_iocpf_sm_fail_entry(iocpf);
  bfa_ioc_pf_hwfailed(ioc);
  goto ldv_48100;
  case 2U: 
  bfa_ioc_hw_sem_get_cancel(ioc);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_disabling_sync);
  bfa_iocpf_sm_disabling_sync_entry(iocpf);
  goto ldv_48100;
  case 3U: 
  bfa_ioc_hw_sem_get_cancel(ioc);
  (*((ioc->ioc_hwif)->ioc_firmware_unlock))(ioc);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(iocpf);
  goto ldv_48100;
  case 7U: ;
  goto ldv_48100;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         980, (unsigned int )event);
  }
  ldv_48100: ;
  return;
}
}
static void bfa_iocpf_sm_initfail_entry(struct bfa_iocpf *iocpf ) 
{ 


  {
  return;
}
}
static void bfa_iocpf_sm_initfail(struct bfa_iocpf *iocpf , enum iocpf_event event ) 
{ 
  struct bfa_ioc *ioc ;

  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 2U: 
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_disabled);
  bfa_iocpf_sm_disabled_entry(iocpf);
  goto ldv_48115;
  case 3U: 
  (*((ioc->ioc_hwif)->ioc_firmware_unlock))(ioc);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(iocpf);
  goto ldv_48115;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         1006, (unsigned int )event);
  }
  ldv_48115: ;
  return;
}
}
static void bfa_iocpf_sm_fail_sync_entry(struct bfa_iocpf *iocpf ) 
{ 


  {
  bfa_ioc_lpu_stop(iocpf->ioc);
  bfa_ioc_mbox_flush(iocpf->ioc);
  bfa_ioc_hw_sem_get(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_fail_sync(struct bfa_iocpf *iocpf , enum iocpf_event event ) 
{ 
  struct bfa_ioc *ioc ;
  bool tmp ;

  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 10U: 
  (*((ioc->ioc_hwif)->ioc_sync_ack))(ioc);
  (*((ioc->ioc_hwif)->ioc_notify_fail))(ioc);
  if (! iocpf->auto_recover) {
    (*((ioc->ioc_hwif)->ioc_sync_leave))(ioc);
    (*((ioc->ioc_hwif)->ioc_set_fwstate))(ioc, 8);
    bfa_nw_ioc_hw_sem_release(ioc);
    iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_fail);
    bfa_iocpf_sm_fail_entry(iocpf);
  } else {
    tmp = (*((ioc->ioc_hwif)->ioc_sync_complete))(ioc);
    if ((int )tmp) {
      iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_hwinit);
      bfa_iocpf_sm_hwinit_entry(iocpf);
    } else {
      bfa_nw_ioc_hw_sem_release(ioc);
      iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_semwait);
      bfa_iocpf_sm_semwait_entry(iocpf);
    }
  }
  goto ldv_48127;
  case 12U: 
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_fail);
  bfa_iocpf_sm_fail_entry(iocpf);
  bfa_ioc_pf_hwfailed(ioc);
  goto ldv_48127;
  case 2U: 
  bfa_ioc_hw_sem_get_cancel(ioc);
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_disabling_sync);
  bfa_iocpf_sm_disabling_sync_entry(iocpf);
  goto ldv_48127;
  case 7U: ;
  goto ldv_48127;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         1064, (unsigned int )event);
  }
  ldv_48127: ;
  return;
}
}
static void bfa_iocpf_sm_fail_entry(struct bfa_iocpf *iocpf ) 
{ 


  {
  return;
}
}
static void bfa_iocpf_sm_fail(struct bfa_iocpf *iocpf , enum iocpf_event event ) 
{ 


  {
  switch ((unsigned int )event) {
  case 2U: 
  iocpf->fsm = (void (*)(void * , int  ))(& bfa_iocpf_sm_disabled);
  bfa_iocpf_sm_disabled_entry(iocpf);
  goto ldv_48140;
  default: 
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         1083, (unsigned int )event);
  }
  ldv_48140: ;
  return;
}
}
static void bfa_ioc_event_notify(struct bfa_ioc *ioc , enum bfa_ioc_event event ) 
{ 
  struct bfa_ioc_notify *notify ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;

  {
  __mptr = (struct list_head  const  *)ioc->notify_q.next;
  notify = (struct bfa_ioc_notify *)__mptr;
  goto ldv_48152;
  ldv_48151: 
  (*(notify->cbfn))(notify->cbarg, event);
  __mptr___0 = (struct list_head  const  *)notify->qe.next;
  notify = (struct bfa_ioc_notify *)__mptr___0;
  ldv_48152: ;
  if ((unsigned long )(& notify->qe) != (unsigned long )(& ioc->notify_q)) {
    goto ldv_48151;
  } else {

  }

  return;
}
}
static void bfa_ioc_disable_comp(struct bfa_ioc *ioc ) 
{ 


  {
  (*((ioc->cbfn)->disable_cbfn))((void *)ioc->bfa);
  bfa_ioc_event_notify(ioc, 2);
  return;
}
}
bool bfa_nw_ioc_sem_get(void *sem_reg ) 
{ 
  u32 r32 ;
  int cnt ;
    klee_make_symbolic(&cnt, sizeof(int), "cnt");

  {
  cnt = 0;
  r32 = readl((void const volatile   *)sem_reg);
  goto ldv_48163;
  ldv_48162: 
  cnt = cnt + 1;
  __const_udelay(8590UL);
  r32 = readl((void const volatile   *)sem_reg);
  ldv_48163: ;
  if ((int )r32 & 1 && cnt <= 2999) {
    goto ldv_48162;
  } else {

  }

  if ((r32 & 1U) == 0U) {
    return (1);
  } else {

  }
  return (0);
}
}
void bfa_nw_ioc_sem_release(void *sem_reg ) 
{ 


  {
  readl((void const volatile   *)sem_reg);
  writel(1U, (void volatile   *)sem_reg);
  return;
}
}
static void bfa_ioc_fwver_clear(struct bfa_ioc *ioc ) 
{ 
  u32 pgnum ;
  u32 pgoff ;
  u32 loff ;
  int i ;

  {
  loff = 0U;
  pgnum = ioc->ioc_regs.smem_pg0 + (loff >> 15);
  pgoff = loff & 32767U;
  writel(pgnum, (void volatile   *)ioc->ioc_regs.host_page_num_fn);
  i = 0;
  goto ldv_48176;
  ldv_48175: 
  writel(0U, (void volatile   *)ioc->ioc_regs.smem_page_start + (unsigned long )loff);
  loff = loff + 4U;
  i = i + 1;
  ldv_48176: ;
  if ((unsigned int )i <= 11U) {
    goto ldv_48175;
  } else {

  }

  return;
}
}
static void bfa_ioc_hw_sem_init(struct bfa_ioc *ioc ) 
{ 
  struct bfi_ioc_image_hdr fwhdr ;
  u32 fwstate ;
  u32 r32 ;
  enum bfi_ioc_state tmp ;
  __u32 tmp___0 ;

  {
  r32 = readl((void const volatile   *)ioc->ioc_regs.ioc_init_sem_reg);
  goto ldv_48185;
  ldv_48184: 
  __const_udelay(85900UL);
  r32 = readl((void const volatile   *)ioc->ioc_regs.ioc_init_sem_reg);
  ldv_48185: ;
  if ((int )r32 & 1) {
    goto ldv_48184;
  } else {

  }
  tmp = (*((ioc->ioc_hwif)->ioc_get_fwstate))(ioc);
  fwstate = (u32 )tmp;
  if (fwstate == 0U) {
    writel(1U, (void volatile   *)ioc->ioc_regs.ioc_init_sem_reg);
    return;
  } else {

  }
  bfa_nw_ioc_fwver_get(ioc, & fwhdr);
  tmp___0 = __fswab32(fwhdr.exec);
  if (tmp___0 == 0U) {
    writel(1U, (void volatile   *)ioc->ioc_regs.ioc_init_sem_reg);
    return;
  } else {

  }
  bfa_ioc_fwver_clear(ioc);
  (*((ioc->ioc_hwif)->ioc_set_fwstate))(ioc, 0);
  (*((ioc->ioc_hwif)->ioc_set_alt_fwstate))(ioc, 0);
  readl((void const volatile   *)ioc->ioc_regs.ioc_sem_reg);
  writel(1U, (void volatile   *)ioc->ioc_regs.ioc_sem_reg);
  writel(1U, (void volatile   *)ioc->ioc_regs.ioc_init_sem_reg);
  return;
}
}
static void bfa_ioc_hw_sem_get(struct bfa_ioc *ioc ) 
{ 
  u32 r32 ;
  unsigned long tmp ;

  {
  r32 = readl((void const volatile   *)ioc->ioc_regs.ioc_sem_reg);
  if (r32 == 4294967295U) {
    (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 12);
    return;
  } else {

  }
  if ((r32 & 1U) == 0U) {
    (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 10);
    return;
  } else {

  }
  tmp = msecs_to_jiffies(500U);
  ldv_mod_timer_392(& ioc->sem_timer, tmp + (unsigned long )jiffies);
  return;
}
}
void bfa_nw_ioc_hw_sem_release(struct bfa_ioc *ioc ) 
{ 


  {
  writel(1U, (void volatile   *)ioc->ioc_regs.ioc_sem_reg);
  return;
}
}
static void bfa_ioc_hw_sem_get_cancel(struct bfa_ioc *ioc ) 
{ 


  {
  ldv_del_timer_393(& ioc->sem_timer);
  return;
}
}
static void bfa_ioc_lmem_init(struct bfa_ioc *ioc ) 
{ 
  u32 pss_ctl ;
  int i ;
  long tmp ;

  {
  pss_ctl = readl((void const volatile   *)ioc->ioc_regs.pss_ctl_reg);
  pss_ctl = pss_ctl & 4294966783U;
  pss_ctl = pss_ctl | 256U;
  pss_ctl = pss_ctl | 196608U;
  writel(pss_ctl, (void volatile   *)ioc->ioc_regs.pss_ctl_reg);
  i = 0;
  ldv_48202: 
  pss_ctl = readl((void const volatile   *)ioc->ioc_regs.pss_ctl_reg);
  i = i + 1;
  if ((pss_ctl & 4096U) == 0U && i <= 9999) {
    goto ldv_48202;
  } else {

  }
  tmp = ldv__builtin_expect((pss_ctl & 4096U) == 0U, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c"),
                         "i" (1258), "i" (12UL));
    ldv_48204: ;
    goto ldv_48204;
  } else {

  }
  pss_ctl = pss_ctl & 4294962943U;
  writel(pss_ctl, (void volatile   *)ioc->ioc_regs.pss_ctl_reg);
  return;
}
}
static void bfa_ioc_lpu_start(struct bfa_ioc *ioc ) 
{ 
  u32 pss_ctl ;

  {
  pss_ctl = readl((void const volatile   *)ioc->ioc_regs.pss_ctl_reg);
  pss_ctl = pss_ctl & 4294967294U;
  writel(pss_ctl, (void volatile   *)ioc->ioc_regs.pss_ctl_reg);
  return;
}
}
static void bfa_ioc_lpu_stop(struct bfa_ioc *ioc ) 
{ 
  u32 pss_ctl ;

  {
  pss_ctl = readl((void const volatile   *)ioc->ioc_regs.pss_ctl_reg);
  pss_ctl = pss_ctl | 3U;
  writel(pss_ctl, (void volatile   *)ioc->ioc_regs.pss_ctl_reg);
  return;
}
}
void bfa_nw_ioc_fwver_get(struct bfa_ioc *ioc , struct bfi_ioc_image_hdr *fwhdr ) 
{ 
  u32 pgnum ;
  u32 loff ;
  int i ;
  u32 *fwsig ;
  unsigned int tmp ;
  __u32 tmp___0 ;

  {
  loff = 0U;
  fwsig = (u32 *)fwhdr;
  pgnum = bfa_ioc_smem_pgnum(ioc, loff);
  writel(pgnum, (void volatile   *)ioc->ioc_regs.host_page_num_fn);
  i = 0;
  goto ldv_48222;
  ldv_48221: 
  tmp = readl((void const volatile   *)ioc->ioc_regs.smem_page_start + (unsigned long )loff);
  tmp___0 = __fswab32(tmp);
  *(fwsig + (unsigned long )i) = tmp___0;
  loff = loff + 4U;
  i = i + 1;
  ldv_48222: ;
  if ((unsigned int )i <= 11U) {
    goto ldv_48221;
  } else {

  }

  return;
}
}
static bool bfa_ioc_fwver_md5_check(struct bfi_ioc_image_hdr *fwhdr_1 , struct bfi_ioc_image_hdr *fwhdr_2 ) 
{ 
  int i ;

  {
  i = 0;
  goto ldv_48230;
  ldv_48229: ;
  if (fwhdr_1->md5sum[i] != fwhdr_2->md5sum[i]) {
    return (0);
  } else {

  }
  i = i + 1;
  ldv_48230: ;
  if (i <= 3) {
    goto ldv_48229;
  } else {

  }

  return (1);
}
}
static bool bfa_ioc_fw_ver_compatible(struct bfi_ioc_image_hdr *drv_fwhdr , struct bfi_ioc_image_hdr *fwhdr_to_cmp ) 
{ 
  bool tmp ;

  {
  if (drv_fwhdr->signature != fwhdr_to_cmp->signature) {
    return (0);
  } else {

  }
  if ((int )drv_fwhdr->fwver.major != (int )fwhdr_to_cmp->fwver.major) {
    return (0);
  } else {

  }
  if ((int )drv_fwhdr->fwver.minor != (int )fwhdr_to_cmp->fwver.minor) {
    return (0);
  } else {

  }
  if ((int )drv_fwhdr->fwver.maint != (int )fwhdr_to_cmp->fwver.maint) {
    return (0);
  } else {

  }
  if (((int )drv_fwhdr->fwver.patch == (int )fwhdr_to_cmp->fwver.patch && (int )drv_fwhdr->fwver.phase == (int )fwhdr_to_cmp->fwver.phase) && (int )drv_fwhdr->fwver.build == (int )fwhdr_to_cmp->fwver.build) {
    tmp = bfa_ioc_fwver_md5_check(drv_fwhdr, fwhdr_to_cmp);
    return (tmp);
  } else {

  }
  return (1);
}
}
static bool bfa_ioc_flash_fwver_valid(struct bfi_ioc_image_hdr *flash_fwhdr ) 
{ 


  {
  if ((unsigned int )flash_fwhdr->fwver.major == 0U || (unsigned int )flash_fwhdr->fwver.major == 255U) {
    return (0);
  } else {

  }
  return (1);
}
}
static bool fwhdr_is_ga(struct bfi_ioc_image_hdr *fwhdr ) 
{ 


  {
  if ((unsigned int )fwhdr->fwver.phase == 0U && (unsigned int )fwhdr->fwver.build == 0U) {
    return (0);
  } else {

  }
  return (1);
}
}
static enum bfi_ioc_img_ver_cmp bfa_ioc_fw_ver_patch_cmp(struct bfi_ioc_image_hdr *base_fwhdr ,
                                                         struct bfi_ioc_image_hdr *fwhdr_to_cmp ) 
{ 
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  bool tmp___2 ;
  bool tmp___3 ;

  {
  tmp = bfa_ioc_fw_ver_compatible(base_fwhdr, fwhdr_to_cmp);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (0);
  } else {

  }
  if ((int )fwhdr_to_cmp->fwver.patch > (int )base_fwhdr->fwver.patch) {
    return (3);
  } else
  if ((int )fwhdr_to_cmp->fwver.patch < (int )base_fwhdr->fwver.patch) {
    return (1);
  } else {

  }
  tmp___3 = fwhdr_is_ga(base_fwhdr);
  if ((int )tmp___3) {
    tmp___1 = fwhdr_is_ga(fwhdr_to_cmp);
    if ((int )tmp___1) {
      return (2);
    } else {
      return (1);
    }
  } else {
    tmp___2 = fwhdr_is_ga(fwhdr_to_cmp);
    if ((int )tmp___2) {
      return (3);
    } else {

    }
  }
  if ((int )fwhdr_to_cmp->fwver.phase > (int )base_fwhdr->fwver.phase) {
    return (3);
  } else
  if ((int )fwhdr_to_cmp->fwver.phase < (int )base_fwhdr->fwver.phase) {
    return (1);
  } else {

  }
  if ((int )fwhdr_to_cmp->fwver.build > (int )base_fwhdr->fwver.build) {
    return (3);
  } else
  if ((int )fwhdr_to_cmp->fwver.build < (int )base_fwhdr->fwver.build) {
    return (1);
  } else {

  }
  return (2);
}
}
static void bfa_flash_set_cmd(void *pci_bar , u8 wr_cnt , u8 rd_cnt , u8 ad_cnt ,
                              u8 op ) 
{ 
  union bfa_flash_cmd_reg cmd ;

  {
  cmd.i = 0U;
  cmd.r.act = 1U;
  cmd.r.write_cnt = (unsigned short )wr_cnt;
  cmd.r.read_cnt = (unsigned short )rd_cnt;
  cmd.r.addr_cnt = ad_cnt;
  cmd.r.cmd = op;
  writel(cmd.i, (void volatile   *)pci_bar + 118784U);
  return;
}
}
static void bfa_flash_set_addr(void *pci_bar , u32 address ) 
{ 
  union bfa_flash_addr_reg addr ;

  {
  addr.r.addr = address & 16777215U;
  addr.r.dummy = 0U;
  writel(addr.i, (void volatile   *)pci_bar + 118788U);
  return;
}
}
static int bfa_flash_cmd_act_check(void *pci_bar ) 
{ 
  union bfa_flash_cmd_reg cmd ;

  {
  cmd.i = readl((void const volatile   *)pci_bar + 118784U);
  if ((unsigned int )*((unsigned char *)(& cmd) + 3UL) != 0U) {
    return (-5);
  } else {

  }
  return (0);
}
}
static u32 bfa_flash_fifo_flush(void *pci_bar ) 
{ 
  u32 i ;
  u32 t ;
  union bfa_flash_dev_status_reg dev_status ;

  {
  dev_status.i = readl((void const volatile   *)pci_bar + 118804U);
  if ((unsigned int )*((unsigned short *)(& dev_status) + 0UL) == 0U) {
    return (0U);
  } else {

  }
  i = 0U;
  goto ldv_48313;
  ldv_48312: 
  t = readl((void const volatile   *)pci_bar + 118800U);
  i = i + 1U;
  ldv_48313: ;
  if ((u32 )dev_status.r.fifo_cnt > i) {
    goto ldv_48312;
  } else {

  }
  i = 0U;
  goto ldv_48317;
  ldv_48316: 
  dev_status.i = readl((void const volatile   *)pci_bar + 118804U);
  if ((unsigned int )*((unsigned short *)(& dev_status) + 0UL) == 0U) {
    goto ldv_48315;
  } else {

  }
  i = i + 1U;
  ldv_48317: ;
  if (i <= 9999U) {
    goto ldv_48316;
  } else {

  }
  ldv_48315: ;
  if ((unsigned int )*((unsigned short *)(& dev_status) + 0UL) != 0U) {
    return (4294967290U);
  } else {

  }
  return (0U);
}
}
static u32 bfa_flash_status_read(void *pci_bar ) 
{ 
  union bfa_flash_dev_status_reg dev_status ;
  u32 status ;
  u32 ret_status ;
  int i ;
  int tmp ;

  {
  status = bfa_flash_fifo_flush(pci_bar);
  bfa_flash_set_cmd(pci_bar, 0, 4, 0, 5);
  i = 0;
  goto ldv_48327;
  ldv_48326: 
  tmp = bfa_flash_cmd_act_check(pci_bar);
  status = (u32 )tmp;
  if (status == 0U) {
    goto ldv_48325;
  } else {

  }
  i = i + 1;
  ldv_48327: ;
  if (i <= 9999) {
    goto ldv_48326;
  } else {

  }
  ldv_48325: ;
  if (status != 0U) {
    return (status);
  } else {

  }
  dev_status.i = readl((void const volatile   *)pci_bar + 118804U);
  if ((unsigned int )*((unsigned short *)(& dev_status) + 0UL) == 0U) {
    return (4294967292U);
  } else {

  }
  ret_status = readl((void const volatile   *)pci_bar + 118800U);
  ret_status = ret_status >> 24;
  status = bfa_flash_fifo_flush(pci_bar);
  return (ret_status);
}
}
static u32 bfa_flash_read_start(void *pci_bar , u32 offset , u32 len , char *buf ) 
{ 
  u32 status ;

  {
  if ((len == 0U || len > 128U) || (len & 3U) != 0U) {
    return (4294967287U);
  } else {

  }
  status = bfa_flash_status_read(pci_bar);
  if (status == 4294967292U) {
    status = bfa_flash_status_read(pci_bar);
  } else {

  }
  if ((int )status & 1) {
    return (4294967289U);
  } else {

  }
  bfa_flash_set_addr(pci_bar, offset);
  bfa_flash_set_cmd(pci_bar, 0, (int )((unsigned char )len), 4, 11);
  return (0U);
}
}
static u32 bfa_flash_read_check(void *pci_bar ) 
{ 
  int tmp ;

  {
  tmp = bfa_flash_cmd_act_check(pci_bar);
  if (tmp != 0) {
    return (1U);
  } else {

  }
  return (0U);
}
}
static void bfa_flash_read_end(void *pci_bar , u32 len , char *buf ) 
{ 
  u32 i ;
  u32 w ;
  unsigned int tmp ;
  __u32 tmp___0 ;

  {
  i = 0U;
  goto ldv_48346;
  ldv_48345: 
  tmp = readl((void const volatile   *)pci_bar + 118800U);
  w = tmp;
  tmp___0 = __fswab32(w);
  *((u32 *)buf + (unsigned long )i) = tmp___0;
  i = i + 4U;
  ldv_48346: ;
  if (i < len) {
    goto ldv_48345;
  } else {

  }
  bfa_flash_fifo_flush(pci_bar);
  return;
}
}
static int bfa_raw_sem_get(void *bar ) 
{ 
  int locked ;
    klee_make_symbolic(&locked, sizeof(int), "locked");
  unsigned int tmp ;

  {
  tmp = readl((void const volatile   *)bar + 100384U);
  locked = (int )tmp;
  return (locked == 0);
}
}
static enum bfa_status bfa_flash_sem_get(void *bar ) 
{ 
  u32 n ;
  unsigned long __ms ;
    klee_make_symbolic(&__ms, sizeof(long), "__ms");
  unsigned long tmp ;
  int tmp___0 ;

  {
  n = 500U;
  goto ldv_48361;
  ldv_48360: 
  n = n - 1U;
  if (n == 0U) {
    return (9);
  } else {

  }
  __ms = 10UL;
  goto ldv_48358;
  ldv_48357: 
  __const_udelay(4295000UL);
  ldv_48358: 
  tmp = __ms;
  __ms = __ms - 1UL;
  if (tmp != 0UL) {
    goto ldv_48357;
  } else {

  }

  ldv_48361: 
  tmp___0 = bfa_raw_sem_get(bar);
  if (tmp___0 == 0) {
    goto ldv_48360;
  } else {

  }

  return (0);
}
}
static void bfa_flash_sem_put(void *bar ) 
{ 


  {
  writel(0U, (void volatile   *)bar + 100384U);
  return;
}
}
static enum bfa_status bfa_flash_raw_read(void *pci_bar , u32 offset , char *buf ,
                                          u32 len ) 
{ 
  u32 n ;
  u32 status ;
  u32 off ;
  u32 l ;
  u32 s ;
  u32 residue ;
  u32 fifo_sz ;
  enum bfa_status tmp ;
  u32 tmp___0 ;

  {
  residue = len;
  off = 0U;
  fifo_sz = 128U;
  tmp = bfa_flash_sem_get(pci_bar);
  status = (u32 )tmp;
  if (status != 0U) {
    return ((enum bfa_status )status);
  } else {

  }
  goto ldv_48383;
  ldv_48382: 
  s = offset + off;
  n = s / fifo_sz;
  l = (n + 1U) * fifo_sz - s;
  if (l > residue) {
    l = residue;
  } else {

  }
  status = bfa_flash_read_start(pci_bar, offset + off, l, buf + (unsigned long )off);
  n = 1000000U;
  goto ldv_48380;
  ldv_48379: 
  n = n - 1U;
  if (n == 0U) {
    bfa_flash_sem_put(pci_bar);
    return (1);
  } else {

  }
  ldv_48380: 
  tmp___0 = bfa_flash_read_check(pci_bar);
  if (tmp___0 != 0U) {
    goto ldv_48379;
  } else {

  }
  bfa_flash_read_end(pci_bar, l, buf + (unsigned long )off);
  residue = residue - l;
  off = off + l;
  ldv_48383: ;
  if (residue != 0U) {
    goto ldv_48382;
  } else {

  }
  bfa_flash_sem_put(pci_bar);
  return (0);
}
}
static enum bfa_status bfa_nw_ioc_flash_img_get_chnk(struct bfa_ioc *ioc , u32 off ,
                                                     u32 *fwimg ) 
{ 
  enum bfa_status tmp ;

  {
  tmp = bfa_flash_raw_read(ioc->pcidev.pci_bar_kva, (u32 )((unsigned long )off + 262144UL) * 4U,
                           (char *)fwimg, 256U);
  return (tmp);
}
}
static enum bfi_ioc_img_ver_cmp bfa_ioc_flash_fwver_cmp(struct bfa_ioc *ioc , struct bfi_ioc_image_hdr *base_fwhdr ) 
{ 
  struct bfi_ioc_image_hdr *flash_fwhdr ;
  enum bfa_status status ;
  u32 fwimg[64U] ;
  enum bfi_ioc_img_ver_cmp tmp ;
  bool tmp___0 ;

  {
  status = bfa_nw_ioc_flash_img_get_chnk(ioc, 0U, (u32 *)(& fwimg));
  if ((unsigned int )status != 0U) {
    return (0);
  } else {

  }
  flash_fwhdr = (struct bfi_ioc_image_hdr *)(& fwimg);
  tmp___0 = bfa_ioc_flash_fwver_valid(flash_fwhdr);
  if ((int )tmp___0) {
    tmp = bfa_ioc_fw_ver_patch_cmp(base_fwhdr, flash_fwhdr);
    return (tmp);
  } else {
    return (0);
  }
}
}
bool bfa_nw_ioc_fwver_cmp(struct bfa_ioc *ioc , struct bfi_ioc_image_hdr *fwhdr ) 
{ 
  struct bfi_ioc_image_hdr *drv_fwhdr ;
  enum bfi_ioc_img_ver_cmp smem_flash_cmp ;
  enum bfi_ioc_img_ver_cmp drv_smem_cmp ;
  u32 *tmp ;

  {
  tmp = bfa_cb_image_get_chunk(ioc->asic_gen, 0U);
  drv_fwhdr = (struct bfi_ioc_image_hdr *)tmp;
  drv_smem_cmp = bfa_ioc_fw_ver_patch_cmp(drv_fwhdr, fwhdr);
  if ((unsigned int )drv_smem_cmp == 0U || (unsigned int )drv_smem_cmp == 1U) {
    return (0);
  } else {

  }
  smem_flash_cmp = bfa_ioc_flash_fwver_cmp(ioc, fwhdr);
  if ((unsigned int )smem_flash_cmp == 3U) {
    return (0);
  } else
  if ((unsigned int )smem_flash_cmp == 2U) {
    return (1);
  } else {
    return ((unsigned int )drv_smem_cmp == 2U);
  }
}
}
static bool bfa_ioc_fwver_valid(struct bfa_ioc *ioc , u32 boot_env ) 
{ 
  struct bfi_ioc_image_hdr fwhdr ;
  __u32 tmp ;
  bool tmp___0 ;

  {
  bfa_nw_ioc_fwver_get(ioc, & fwhdr);
  tmp = __fswab32(fwhdr.bootenv);
  if (tmp != boot_env) {
    return (0);
  } else {

  }
  tmp___0 = bfa_nw_ioc_fwver_cmp(ioc, & fwhdr);
  return (tmp___0);
}
}
static void bfa_ioc_msgflush(struct bfa_ioc *ioc ) 
{ 
  u32 r32 ;

  {
  r32 = readl((void const volatile   *)ioc->ioc_regs.lpu_mbox_cmd);
  if (r32 != 0U) {
    writel(1U, (void volatile   *)ioc->ioc_regs.lpu_mbox_cmd);
  } else {

  }
  return;
}
}
static void bfa_ioc_hwinit(struct bfa_ioc *ioc , bool force ) 
{ 
  enum bfi_ioc_state ioc_fwstate ;
  bool fwvalid ;
  u32 boot_env ;
  bool tmp ;
  int tmp___0 ;
  enum bfa_status tmp___1 ;
  enum bfa_status tmp___2 ;

  {
  ioc_fwstate = (*((ioc->ioc_hwif)->ioc_get_fwstate))(ioc);
  if ((int )force) {
    ioc_fwstate = 0;
  } else {

  }
  boot_env = 0U;
  if ((unsigned int )ioc_fwstate != 0U) {
    tmp = bfa_ioc_fwver_valid(ioc, boot_env);
    if ((int )tmp != 0) {
      tmp___0 = 1;
    } else {
      tmp___0 = 0;
    }
  } else {
    tmp___0 = 0;
  }
  fwvalid = tmp___0;
  if (! fwvalid) {
    tmp___1 = bfa_ioc_boot(ioc, 0, boot_env);
    if ((unsigned int )tmp___1 == 0U) {
      bfa_ioc_poll_fwinit(ioc);
    } else {

    }
    return;
  } else {

  }
  if ((unsigned int )ioc_fwstate == 1U) {
    bfa_ioc_poll_fwinit(ioc);
    return;
  } else {

  }
  if ((unsigned int )ioc_fwstate == 6U || (unsigned int )ioc_fwstate == 4U) {
    bfa_ioc_msgflush(ioc);
    (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 4);
    return;
  } else {

  }
  tmp___2 = bfa_ioc_boot(ioc, 0, boot_env);
  if ((unsigned int )tmp___2 == 0U) {
    bfa_ioc_poll_fwinit(ioc);
  } else {

  }
  return;
}
}
void bfa_nw_ioc_timeout(struct bfa_ioc *ioc ) 
{ 


  {
  (*(ioc->fsm))((void *)ioc, 11);
  return;
}
}
static void bfa_ioc_mbox_send(struct bfa_ioc *ioc , void *ioc_msg , int len ) 
{ 
  u32 *msgp ;
  u32 i ;
  long tmp ;

  {
  msgp = (u32 *)ioc_msg;
  tmp = ldv__builtin_expect(len > 32, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c"),
                         "i" (1909), "i" (12UL));
    ldv_48430: ;
    goto ldv_48430;
  } else {

  }
  i = 0U;
  goto ldv_48432;
  ldv_48431: 
  writel(*(msgp + (unsigned long )i), (void volatile   *)(ioc->ioc_regs.hfn_mbox + (unsigned long )i * 4UL));
  i = i + 1U;
  ldv_48432: ;
  if ((unsigned long )i < (unsigned long )len / 4UL) {
    goto ldv_48431;
  } else {

  }

  goto ldv_48435;
  ldv_48434: 
  writel(0U, (void volatile   *)(ioc->ioc_regs.hfn_mbox + (unsigned long )i * 4UL));
  i = i + 1U;
  ldv_48435: ;
  if (i <= 7U) {
    goto ldv_48434;
  } else {

  }
  writel(1U, (void volatile   *)ioc->ioc_regs.hfn_mbox_cmd);
  readl((void const volatile   *)ioc->ioc_regs.hfn_mbox_cmd);
  return;
}
}
static void bfa_ioc_send_enable(struct bfa_ioc *ioc ) 
{ 
  struct bfi_ioc_ctrl_req enable_req ;
  struct timeval tv ;
  __u16 tmp ;
  __u32 tmp___0 ;

  {
  enable_req.mh.msg_class = 1U;
  enable_req.mh.msg_id = 1U;
  enable_req.mh.mtag.h2i.fn_lpu = ioc->port_id;
  tmp = __fswab16((int )((__u16 )ioc->clscode));
  enable_req.clscode = tmp;
  do_gettimeofday(& tv);
  tmp___0 = __fswab32((unsigned int )tv.tv_sec);
  enable_req.tv_sec = tmp___0;
  bfa_ioc_mbox_send(ioc, (void *)(& enable_req), 12);
  return;
}
}
static void bfa_ioc_send_disable(struct bfa_ioc *ioc ) 
{ 
  struct bfi_ioc_ctrl_req disable_req ;

  {
  disable_req.mh.msg_class = 1U;
  disable_req.mh.msg_id = 2U;
  disable_req.mh.mtag.h2i.fn_lpu = ioc->port_id;
  bfa_ioc_mbox_send(ioc, (void *)(& disable_req), 12);
  return;
}
}
static void bfa_ioc_send_getattr(struct bfa_ioc *ioc ) 
{ 
  struct bfi_ioc_getattr_req attr_req ;

  {
  attr_req.mh.msg_class = 1U;
  attr_req.mh.msg_id = 3U;
  attr_req.mh.mtag.h2i.fn_lpu = ioc->port_id;
  __bfa_dma_be_addr_set(& attr_req.attr_addr, ioc->attr_dma.pa);
  bfa_ioc_mbox_send(ioc, (void *)(& attr_req), 12);
  return;
}
}
void bfa_nw_ioc_hb_check(struct bfa_ioc *ioc ) 
{ 
  u32 hb_count ;
  unsigned long tmp ;

  {
  hb_count = readl((void const volatile   *)ioc->ioc_regs.heartbeat);
  if (ioc->hb_count == hb_count) {
    bfa_ioc_recover(ioc);
    return;
  } else {
    ioc->hb_count = hb_count;
  }
  bfa_ioc_mbox_poll(ioc);
  tmp = msecs_to_jiffies(500U);
  ldv_mod_timer_394(& ioc->hb_timer, tmp + (unsigned long )jiffies);
  return;
}
}
static void bfa_ioc_hb_monitor(struct bfa_ioc *ioc ) 
{ 
  unsigned long tmp ;

  {
  ioc->hb_count = readl((void const volatile   *)ioc->ioc_regs.heartbeat);
  tmp = msecs_to_jiffies(500U);
  ldv_mod_timer_395(& ioc->hb_timer, tmp + (unsigned long )jiffies);
  return;
}
}
static void bfa_ioc_hb_stop(struct bfa_ioc *ioc ) 
{ 


  {
  ldv_del_timer_396(& ioc->hb_timer);
  return;
}
}
static enum bfa_status bfa_ioc_download_fw(struct bfa_ioc *ioc , u32 boot_type , u32 boot_env ) 
{ 
  u32 *fwimg ;
  u32 pgnum ;
  u32 loff ;
  u32 chunkno ;
  u32 i ;
  u32 asicmode ;
  u32 fwimg_size ;
  u32 fwimg_buf[64U] ;
  enum bfa_status status ;
  __u32 tmp ;
  u32 tmp___0 ;

  {
  loff = 0U;
  chunkno = 0U;
  if (boot_env == 0U && boot_type == 1U) {
    fwimg_size = 262144U;
    status = bfa_nw_ioc_flash_img_get_chnk(ioc, chunkno * 64U, (u32 *)(& fwimg_buf));
    if ((unsigned int )status != 0U) {
      return (status);
    } else {

    }
    fwimg = (u32 *)(& fwimg_buf);
  } else {
    fwimg_size = bfa_cb_image_get_size(ioc->asic_gen);
    fwimg = bfa_cb_image_get_chunk(ioc->asic_gen, chunkno * 64U);
  }
  pgnum = bfa_ioc_smem_pgnum(ioc, loff);
  writel(pgnum, (void volatile   *)ioc->ioc_regs.host_page_num_fn);
  i = 0U;
  goto ldv_48475;
  ldv_48474: ;
  if (i / 64U != chunkno) {
    chunkno = i / 64U;
    if (boot_env == 0U && boot_type == 1U) {
      status = bfa_nw_ioc_flash_img_get_chnk(ioc, chunkno * 64U, (u32 *)(& fwimg_buf));
      if ((unsigned int )status != 0U) {
        return (status);
      } else {

      }
      fwimg = (u32 *)(& fwimg_buf);
    } else {
      fwimg = bfa_cb_image_get_chunk(ioc->asic_gen, chunkno * 64U);
    }
  } else {

  }
  tmp = __fswab32(*(fwimg + ((unsigned long )i & 63UL)));
  writel(tmp, (void volatile   *)ioc->ioc_regs.smem_page_start + (unsigned long )loff);
  loff = loff + 4U;
  loff = loff & 32767U;
  if (loff == 0U) {
    pgnum = pgnum + 1U;
    writel(pgnum, (void volatile   *)ioc->ioc_regs.host_page_num_fn);
  } else {

  }
  i = i + 1U;
  ldv_48475: ;
  if (i < fwimg_size) {
    goto ldv_48474;
  } else {

  }
  tmp___0 = bfa_ioc_smem_pgnum(ioc, 0U);
  writel(tmp___0, (void volatile   *)ioc->ioc_regs.host_page_num_fn);
  if (boot_env == 0U && boot_type == 1U) {
    boot_type = 0U;
  } else {

  }
  asicmode = ((((unsigned int )ioc->asic_gen << 24) | ((unsigned int )ioc->asic_mode << 16)) | ((unsigned int )ioc->port0_mode << 8)) | (unsigned int )ioc->port1_mode;
  writel(asicmode, (void volatile   *)ioc->ioc_regs.smem_page_start + 4U);
  writel(boot_type, (void volatile   *)ioc->ioc_regs.smem_page_start + 8U);
  writel(boot_env, (void volatile   *)ioc->ioc_regs.smem_page_start + 12U);
  return (0);
}
}
static void bfa_ioc_reset(struct bfa_ioc *ioc , bool force ) 
{ 


  {
  bfa_ioc_hwinit(ioc, (int )force);
  return;
}
}
static void bfa_ioc_enable_reply(struct bfa_ioc *ioc , enum bfa_mode port_mode , u8 cap_bm ) 
{ 
  struct bfa_iocpf *iocpf ;
  u8 tmp ;

  {
  iocpf = & ioc->iocpf;
  tmp = (u8 )port_mode;
  ioc->port_mode_cfg = tmp;
  ioc->port_mode = (enum bfa_mode )tmp;
  ioc->ad_cap_bm = cap_bm;
  (*(iocpf->fsm))((void *)iocpf, 5);
  return;
}
}
static void bfa_ioc_getattr_reply(struct bfa_ioc *ioc ) 
{ 
  struct bfi_ioc_attr *attr ;
  __u32 tmp ;
  __u32 tmp___0 ;
  __u16 tmp___1 ;

  {
  attr = ioc->attr;
  tmp = __fswab32(attr->adapter_prop);
  attr->adapter_prop = tmp;
  tmp___0 = __fswab32(attr->card_type);
  attr->card_type = tmp___0;
  tmp___1 = __fswab16((int )attr->maxfrsize);
  attr->maxfrsize = tmp___1;
  (*(ioc->fsm))((void *)ioc, 6);
  return;
}
}
static void bfa_ioc_mbox_attach(struct bfa_ioc *ioc ) 
{ 
  struct bfa_ioc_mbox_mod *mod ;
  int mc ;

  {
  mod = & ioc->mbox_mod;
  INIT_LIST_HEAD(& mod->cmd_q);
  mc = 0;
  goto ldv_48497;
  ldv_48496: 
  mod->mbhdlr[mc].cbfn = (void (*)(void * , struct bfi_mbmsg * ))0;
  mod->mbhdlr[mc].cbarg = (void *)ioc->bfa;
  mc = mc + 1;
  ldv_48497: ;
  if (mc <= 33) {
    goto ldv_48496;
  } else {

  }

  return;
}
}
static void bfa_ioc_mbox_poll(struct bfa_ioc *ioc ) 
{ 
  struct bfa_ioc_mbox_mod *mod ;
  struct bfa_mbox_cmd *cmd ;
  void (*cbfn)(void * ) ;
  void *cbarg ;
  u32 stat ;
  int tmp ;
  struct list_head  const  *__mptr ;

  {
  mod = & ioc->mbox_mod;
  tmp = list_empty((struct list_head  const  *)(& mod->cmd_q));
  if (tmp != 0) {
    return;
  } else {

  }
  stat = readl((void const volatile   *)ioc->ioc_regs.hfn_mbox_cmd);
  if (stat != 0U) {
    return;
  } else {

  }
  __mptr = (struct list_head  const  *)mod->cmd_q.next;
  cmd = (struct bfa_mbox_cmd *)__mptr;
  list_del(& cmd->qe);
  bfa_ioc_mbox_send(ioc, (void *)(& cmd->msg), 32);
  if ((unsigned long )cmd->cbfn != (unsigned long )((void (*)(void * ))0)) {
    cbfn = cmd->cbfn;
    cbarg = cmd->cbarg;
    cmd->cbfn = (void (*)(void * ))0;
    (*cbfn)(cbarg);
  } else {

  }
  return;
}
}
static void bfa_ioc_mbox_flush(struct bfa_ioc *ioc ) 
{ 
  struct bfa_ioc_mbox_mod *mod ;
  struct bfa_mbox_cmd *cmd ;
  struct list_head  const  *__mptr ;
  int tmp ;

  {
  mod = & ioc->mbox_mod;
  goto ldv_48517;
  ldv_48516: 
  __mptr = (struct list_head  const  *)mod->cmd_q.next;
  cmd = (struct bfa_mbox_cmd *)__mptr;
  list_del(& cmd->qe);
  ldv_48517: 
  tmp = list_empty((struct list_head  const  *)(& mod->cmd_q));
  if (tmp == 0) {
    goto ldv_48516;
  } else {

  }

  return;
}
}
static int bfa_nw_ioc_smem_read(struct bfa_ioc *ioc , void *tbuf , u32 soff , u32 sz ) 
{ 
  u32 pgnum ;
  u32 loff ;
  u32 r32 ;
  int i ;
  int len ;
  u32 *buf ;
  bool tmp ;
  int tmp___0 ;
  unsigned int tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;

  {
  buf = (u32 *)tbuf;
  pgnum = ioc->ioc_regs.smem_pg0 + (soff >> 15);
  loff = soff & 32767U;
  tmp = bfa_nw_ioc_sem_get(ioc->ioc_regs.ioc_init_sem_reg);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (1);
  } else {

  }
  writel(pgnum, (void volatile   *)ioc->ioc_regs.host_page_num_fn);
  len = (int )(sz / 4U);
  i = 0;
  goto ldv_48532;
  ldv_48531: 
  tmp___1 = readl((void const volatile   *)ioc->ioc_regs.smem_page_start + (unsigned long )loff);
  tmp___2 = __fswab32(tmp___1);
  r32 = tmp___2;
  tmp___3 = __fswab32(r32);
  *(buf + (unsigned long )i) = tmp___3;
  loff = loff + 4U;
  loff = loff & 32767U;
  if (loff == 0U) {
    pgnum = pgnum + 1U;
    writel(pgnum, (void volatile   *)ioc->ioc_regs.host_page_num_fn);
  } else {

  }
  i = i + 1;
  ldv_48532: ;
  if (i < len) {
    goto ldv_48531;
  } else {

  }
  writel(ioc->ioc_regs.smem_pg0, (void volatile   *)ioc->ioc_regs.host_page_num_fn);
  readl((void const volatile   *)ioc->ioc_regs.ioc_init_sem_reg);
  writel(1U, (void volatile   *)ioc->ioc_regs.ioc_init_sem_reg);
  return (0);
}
}
int bfa_nw_ioc_debug_fwtrc(struct bfa_ioc *ioc , void *trcdata , int *trclen ) 
{ 
  u32 loff ;
  int tlen ;
    klee_make_symbolic(&tlen, sizeof(int), "tlen");
  int status ;
    klee_make_symbolic(&status, sizeof(int), "status");

  {
  loff = (u32 )((int )ioc->port_id * 4128 + 19200);
  status = 0;
  tlen = *trclen;
  if (tlen > 4128) {
    tlen = 4128;
  } else {

  }
  status = bfa_nw_ioc_smem_read(ioc, trcdata, loff, (u32 )tlen);
  *trclen = tlen;
  return (status);
}
}
static void bfa_nw_ioc_debug_save_ftrc(struct bfa_ioc *ioc ) 
{ 
  int tlen ;

  {
  if ((int )ioc->dbg_fwsave_once) {
    ioc->dbg_fwsave_once = 0;
    if (ioc->dbg_fwsave_len != 0) {
      tlen = ioc->dbg_fwsave_len;
      bfa_nw_ioc_debug_fwtrc(ioc, ioc->dbg_fwsave, & tlen);
    } else {

    }
  } else {

  }
  return;
}
}
int bfa_nw_ioc_debug_fwsave(struct bfa_ioc *ioc , void *trcdata , int *trclen ) 
{ 
  int tlen ;

  {
  if (ioc->dbg_fwsave_len == 0) {
    return (78);
  } else {

  }
  tlen = *trclen;
  if (ioc->dbg_fwsave_len < tlen) {
    tlen = ioc->dbg_fwsave_len;
  } else {

  }
  memmove(trcdata, (void const   *)ioc->dbg_fwsave, (size_t )tlen);
  *trclen = tlen;
  return (0);
}
}
static void bfa_ioc_fail_notify(struct bfa_ioc *ioc ) 
{ 


  {
  (*((ioc->cbfn)->hbfail_cbfn))((void *)ioc->bfa);
  bfa_ioc_event_notify(ioc, 3);
  bfa_nw_ioc_debug_save_ftrc(ioc);
  return;
}
}
static void bfa_ioc_pf_enabled(struct bfa_ioc *ioc ) 
{ 


  {
  (*(ioc->fsm))((void *)ioc, 5);
  return;
}
}
static void bfa_ioc_pf_disabled(struct bfa_ioc *ioc ) 
{ 


  {
  (*(ioc->fsm))((void *)ioc, 7);
  return;
}
}
static void bfa_ioc_pf_failed(struct bfa_ioc *ioc ) 
{ 


  {
  (*(ioc->fsm))((void *)ioc, 8);
  return;
}
}
static void bfa_ioc_pf_hwfailed(struct bfa_ioc *ioc ) 
{ 


  {
  (*(ioc->fsm))((void *)ioc, 12);
  return;
}
}
static void bfa_ioc_pf_fwmismatch(struct bfa_ioc *ioc ) 
{ 


  {
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  return;
}
}
static enum bfa_status bfa_ioc_pll_init(struct bfa_ioc *ioc ) 
{ 


  {
  bfa_nw_ioc_sem_get(ioc->ioc_regs.ioc_init_sem_reg);
  (*((ioc->ioc_hwif)->ioc_pll_init))(ioc->pcidev.pci_bar_kva, ioc->asic_mode);
  ioc->pllinit = 1;
  bfa_ioc_lmem_init(ioc);
  bfa_nw_ioc_sem_release(ioc->ioc_regs.ioc_init_sem_reg);
  return (0);
}
}
static enum bfa_status bfa_ioc_boot(struct bfa_ioc *ioc , enum bfi_fwboot_type boot_type ,
                                    u32 boot_env ) 
{ 
  struct bfi_ioc_image_hdr *drv_fwhdr ;
  enum bfa_status status ;
  enum bfa_status tmp ;
  u32 *tmp___0 ;
  enum bfi_ioc_img_ver_cmp tmp___1 ;

  {
  ioc->stats.ioc_boots = ioc->stats.ioc_boots + 1U;
  tmp = bfa_ioc_pll_init(ioc);
  if ((unsigned int )tmp != 0U) {
    return (1);
  } else {

  }
  if (boot_env == 0U && (unsigned int )boot_type == 0U) {
    tmp___0 = bfa_cb_image_get_chunk(ioc->asic_gen, 0U);
    drv_fwhdr = (struct bfi_ioc_image_hdr *)tmp___0;
    tmp___1 = bfa_ioc_flash_fwver_cmp(ioc, drv_fwhdr);
    if ((unsigned int )tmp___1 == 3U) {
      boot_type = 1;
    } else {

    }
  } else {

  }
  if ((unsigned int )boot_type == 2U) {
    (*((ioc->ioc_hwif)->ioc_set_fwstate))(ioc, 9);
    (*((ioc->ioc_hwif)->ioc_set_alt_fwstate))(ioc, 9);
  } else {
    (*((ioc->ioc_hwif)->ioc_set_fwstate))(ioc, 1);
    (*((ioc->ioc_hwif)->ioc_set_alt_fwstate))(ioc, 1);
  }
  bfa_ioc_msgflush(ioc);
  status = bfa_ioc_download_fw(ioc, (u32 )boot_type, boot_env);
  if ((unsigned int )status == 0U) {
    bfa_ioc_lpu_start(ioc);
  } else {
    (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 11);
  }
  return (status);
}
}
void bfa_nw_ioc_auto_recover(bool auto_recover ) 
{ 


  {
  bfa_nw_auto_recover = auto_recover;
  return;
}
}
static bool bfa_ioc_msgget(struct bfa_ioc *ioc , void *mbmsg ) 
{ 
  u32 *msgp ;
  u32 r32 ;
  int i ;
  __u32 tmp ;

  {
  msgp = (u32 *)mbmsg;
  r32 = readl((void const volatile   *)ioc->ioc_regs.lpu_mbox_cmd);
  if ((r32 & 1U) == 0U) {
    return (0);
  } else {

  }
  i = 0;
  goto ldv_48591;
  ldv_48590: 
  r32 = readl((void const volatile   *)(ioc->ioc_regs.lpu_mbox + (unsigned long )i * 4UL));
  tmp = __fswab32(r32);
  *(msgp + (unsigned long )i) = tmp;
  i = i + 1;
  ldv_48591: ;
  if ((unsigned int )i <= 7U) {
    goto ldv_48590;
  } else {

  }
  writel(1U, (void volatile   *)ioc->ioc_regs.lpu_mbox_cmd);
  readl((void const volatile   *)ioc->ioc_regs.lpu_mbox_cmd);
  return (1);
}
}
static void bfa_ioc_isr(struct bfa_ioc *ioc , struct bfi_mbmsg *m ) 
{ 
  union bfi_ioc_i2h_msg_u *msg ;
  struct bfa_iocpf *iocpf ;
  long tmp ;

  {
  iocpf = & ioc->iocpf;
  msg = (union bfi_ioc_i2h_msg_u *)m;
  ioc->stats.ioc_isrs = ioc->stats.ioc_isrs + 1U;
  switch ((int )msg->mh.msg_id) {
  case 132: ;
  goto ldv_48600;
  case 129: 
  bfa_ioc_enable_reply(ioc, (enum bfa_mode )msg->fw_event.port_mode, (int )msg->fw_event.cap_bm);
  goto ldv_48600;
  case 130: 
  (*(iocpf->fsm))((void *)iocpf, 6);
  goto ldv_48600;
  case 131: 
  bfa_ioc_getattr_reply(ioc);
  goto ldv_48600;
  default: 
  tmp = ldv__builtin_expect(1L, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c"),
                         "i" (2471), "i" (12UL));
    ldv_48605: ;
    goto ldv_48605;
  } else {

  }
  }
  ldv_48600: ;
  return;
}
}
void bfa_nw_ioc_attach(struct bfa_ioc *ioc , void *bfa , struct bfa_ioc_cbfn *cbfn ) 
{ 


  {
  ioc->bfa = (struct bfa *)bfa;
  ioc->cbfn = cbfn;
  ioc->fcmode = 0;
  ioc->pllinit = 0;
  ioc->dbg_fwsave_once = 1;
  ioc->iocpf.ioc = ioc;
  bfa_ioc_mbox_attach(ioc);
  INIT_LIST_HEAD(& ioc->notify_q);
  ioc->fsm = (void (*)(void * , int  ))(& bfa_ioc_sm_uninit);
  bfa_ioc_sm_uninit_entry(ioc);
  (*(ioc->fsm))((void *)ioc, 1);
  return;
}
}
void bfa_nw_ioc_detach(struct bfa_ioc *ioc ) 
{ 


  {
  (*(ioc->fsm))((void *)ioc, 4);
  INIT_LIST_HEAD(& ioc->notify_q);
  return;
}
}
void bfa_nw_ioc_pci_init(struct bfa_ioc *ioc , struct bfa_pcidev *pcidev , enum bfi_pcifn_class clscode ) 
{ 
  enum bfi_port_mode tmp ;
  enum bfi_port_mode tmp___0 ;
  enum bfi_port_mode tmp___1 ;
  long tmp___2 ;
  int __ret_warn_on ;
  long tmp___3 ;

  {
  ioc->clscode = clscode;
  ioc->pcidev = *pcidev;
  tmp = 1;
  ioc->port1_mode = tmp;
  ioc->port0_mode = tmp;
  ioc->asic_mode = 1;
  switch ((int )pcidev->device_id) {
  case 20: 
  ioc->asic_gen = 2;
  tmp___0 = 2;
  ioc->port1_mode = tmp___0;
  ioc->port0_mode = tmp___0;
  ioc->asic_mode = 3;
  ioc->port_mode_cfg = 2U;
  ioc->port_mode = 2;
  ioc->ad_cap_bm = 2U;
  goto ldv_48620;
  case 34: 
  ioc->asic_gen = 3;
  if ((unsigned int )clscode == 3076U && (unsigned int )pcidev->ssid == 36U) {
    ioc->asic_mode = 2;
    ioc->fcmode = 1;
    ioc->port_mode_cfg = 1U;
    ioc->port_mode = 1;
    ioc->ad_cap_bm = 1U;
  } else {
    tmp___1 = 2;
    ioc->port1_mode = tmp___1;
    ioc->port0_mode = tmp___1;
    ioc->asic_mode = 3;
    if ((unsigned int )pcidev->ssid == 34U) {
      ioc->port_mode_cfg = 2U;
      ioc->port_mode = 2;
      ioc->ad_cap_bm = 2U;
    } else {
      ioc->port_mode_cfg = 3U;
      ioc->port_mode = 3;
      ioc->ad_cap_bm = 4U;
    }
  }
  goto ldv_48620;
  default: 
  tmp___2 = ldv__builtin_expect(1L, 0L);
  if (tmp___2 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c"),
                         "i" (2559), "i" (12UL));
    ldv_48623: ;
    goto ldv_48623;
  } else {

  }
  }
  ldv_48620: ;
  if ((unsigned int )ioc->asic_gen == 2U) {
    bfa_nw_ioc_set_ct_hwif(ioc);
  } else {
    __ret_warn_on = (unsigned int )ioc->asic_gen != 3U;
    tmp___3 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___3 != 0L) {
      warn_slowpath_null("/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
                         2568);
    } else {

    }
    ldv__builtin_expect(__ret_warn_on != 0, 0L);
    bfa_nw_ioc_set_ct2_hwif(ioc);
    bfa_nw_ioc_ct2_poweron(ioc);
  }
  (*((ioc->ioc_hwif)->ioc_map_port))(ioc);
  (*((ioc->ioc_hwif)->ioc_reg_init))(ioc);
  return;
}
}
void bfa_nw_ioc_mem_claim(struct bfa_ioc *ioc , u8 *dm_kva , u64 dm_pa ) 
{ 


  {
  ioc->attr_dma.kva = (void *)dm_kva;
  ioc->attr_dma.pa = dm_pa;
  ioc->attr = (struct bfi_ioc_attr *)dm_kva;
  return;
}
}
u32 bfa_nw_ioc_meminfo(void) 
{ 
  int __y ;

  {
  __y = 256;
  return ((u32 )((((unsigned long )(__y + -1) + 732UL) / (unsigned long )__y) * (unsigned long )__y));
}
}
void bfa_nw_ioc_enable(struct bfa_ioc *ioc ) 
{ 


  {
  ioc->stats.ioc_enables = ioc->stats.ioc_enables + 1U;
  ioc->dbg_fwsave_once = 1;
  (*(ioc->fsm))((void *)ioc, 2);
  return;
}
}
void bfa_nw_ioc_disable(struct bfa_ioc *ioc ) 
{ 


  {
  ioc->stats.ioc_disables = ioc->stats.ioc_disables + 1U;
  (*(ioc->fsm))((void *)ioc, 3);
  return;
}
}
void bfa_nw_ioc_debug_memclaim(struct bfa_ioc *ioc , void *dbg_fwsave ) 
{ 


  {
  ioc->dbg_fwsave = dbg_fwsave;
  ioc->dbg_fwsave_len = (int )ioc->iocpf.auto_recover ? 4128 : 0;
  return;
}
}
static u32 bfa_ioc_smem_pgnum(struct bfa_ioc *ioc , u32 fmaddr ) 
{ 


  {
  return (ioc->ioc_regs.smem_pg0 + (fmaddr >> 15));
}
}
void bfa_nw_ioc_mbox_regisr(struct bfa_ioc *ioc , enum bfi_mclass mc , void (*cbfn)(void * ,
                                                                                    struct bfi_mbmsg * ) ,
                            void *cbarg ) 
{ 
  struct bfa_ioc_mbox_mod *mod ;

  {
  mod = & ioc->mbox_mod;
  mod->mbhdlr[(unsigned int )mc].cbfn = cbfn;
  mod->mbhdlr[(unsigned int )mc].cbarg = cbarg;
  return;
}
}
bool bfa_nw_ioc_mbox_queue(struct bfa_ioc *ioc , struct bfa_mbox_cmd *cmd , void (*cbfn)(void * ) ,
                           void *cbarg ) 
{ 
  struct bfa_ioc_mbox_mod *mod ;
  u32 stat ;
  int tmp ;

  {
  mod = & ioc->mbox_mod;
  cmd->cbfn = cbfn;
  cmd->cbarg = cbarg;
  tmp = list_empty((struct list_head  const  *)(& mod->cmd_q));
  if (tmp == 0) {
    list_add_tail(& cmd->qe, & mod->cmd_q);
    return (1);
  } else {

  }
  stat = readl((void const volatile   *)ioc->ioc_regs.hfn_mbox_cmd);
  if (stat != 0U) {
    list_add_tail(& cmd->qe, & mod->cmd_q);
    return (1);
  } else {

  }
  bfa_ioc_mbox_send(ioc, (void *)(& cmd->msg), 32);
  return (0);
}
}
void bfa_nw_ioc_mbox_isr(struct bfa_ioc *ioc ) 
{ 
  struct bfa_ioc_mbox_mod *mod ;
  struct bfi_mbmsg m ;
  int mc ;
  bool tmp ;

  {
  mod = & ioc->mbox_mod;
  tmp = bfa_ioc_msgget(ioc, (void *)(& m));
  if ((int )tmp) {
    mc = (int )m.mh.msg_class;
    if (mc == 1) {
      bfa_ioc_isr(ioc, & m);
      return;
    } else {

    }
    if (mc > 33 || (unsigned long )mod->mbhdlr[mc].cbfn == (unsigned long )((void (*)(void * ,
                                                                                      struct bfi_mbmsg * ))0)) {
      return;
    } else {

    }
    (*(mod->mbhdlr[mc].cbfn))(mod->mbhdlr[mc].cbarg, & m);
  } else {

  }
  if ((unsigned long )(ioc->ioc_hwif)->ioc_lpu_read_stat != (unsigned long )((bool (*/* const  */)(struct bfa_ioc * ))0)) {
    (*((ioc->ioc_hwif)->ioc_lpu_read_stat))(ioc);
  } else {

  }
  bfa_ioc_mbox_poll(ioc);
  return;
}
}
void bfa_nw_ioc_error_isr(struct bfa_ioc *ioc ) 
{ 


  {
  ioc->stats.ioc_hbfails = ioc->stats.ioc_hbfails + 1U;
  ioc->stats.hb_count = ioc->hb_count;
  (*(ioc->fsm))((void *)ioc, 10);
  return;
}
}
bool bfa_nw_ioc_is_disabled(struct bfa_ioc *ioc ) 
{ 


  {
  return ((bool )((unsigned long )ioc->fsm == (unsigned long )((void (*)(void * ,
                                                                         int  ))(& bfa_ioc_sm_disabling)) || (unsigned long )ioc->fsm == (unsigned long )((void (*)(void * ,
                                                                                                                                                                    int  ))(& bfa_ioc_sm_disabled))));
}
}
bool bfa_nw_ioc_is_operational(struct bfa_ioc *ioc ) 
{ 


  {
  return ((unsigned long )ioc->fsm == (unsigned long )((void (*)(void * , int  ))(& bfa_ioc_sm_op)));
}
}
void bfa_nw_ioc_notify_register(struct bfa_ioc *ioc , struct bfa_ioc_notify *notify ) 
{ 


  {
  list_add_tail(& notify->qe, & ioc->notify_q);
  return;
}
}
static void bfa_ioc_get_adapter_attr(struct bfa_ioc *ioc , struct bfa_adapter_attr *ad_attr ) 
{ 
  struct bfi_ioc_attr *ioc_attr ;

  {
  ioc_attr = ioc->attr;
  bfa_ioc_get_adapter_serial_num(ioc, (char *)(& ad_attr->serial_num));
  bfa_ioc_get_adapter_fw_ver(ioc, (char *)(& ad_attr->fw_ver));
  bfa_ioc_get_adapter_optrom_ver(ioc, (char *)(& ad_attr->optrom_ver));
  bfa_ioc_get_adapter_manufacturer(ioc, (char *)(& ad_attr->manufacturer));
  memcpy((void *)(& ad_attr->vpd), (void const   *)(& ioc_attr->vpd), 520UL);
  ad_attr->nports = (u8 )(((ioc->attr)->adapter_prop & 65280U) >> 8);
  ad_attr->max_speed = (u8 )(ioc->attr)->adapter_prop;
  bfa_ioc_get_adapter_model(ioc, (char *)(& ad_attr->model));
  bfa_ioc_get_adapter_model(ioc, (char *)(& ad_attr->model_descr));
  ad_attr->card_type = ioc_attr->card_type;
  ad_attr->is_mezz = (u8 )(((((ioc_attr->card_type == 804U || ioc_attr->card_type == 1007U) || ioc_attr->card_type == 807U) || ioc_attr->card_type == 902U) || ioc_attr->card_type == 1741U) || ioc_attr->card_type == 1867U);
  if ((ioc_attr->adapter_prop & 7340032U) != 0U) {
    ad_attr->prototype = 1U;
  } else {
    ad_attr->prototype = 0U;
  }
  ad_attr->pwwn = bfa_ioc_get_pwwn(ioc);
  bfa_nw_ioc_get_mac(ioc, (u8 *)(& ad_attr->mac));
  ad_attr->pcie_gen = ioc_attr->pcie_gen;
  ad_attr->pcie_lanes = ioc_attr->pcie_lanes;
  ad_attr->pcie_lanes_orig = ioc_attr->pcie_lanes_orig;
  ad_attr->asic_rev = ioc_attr->asic_rev;
  bfa_ioc_get_pci_chip_rev(ioc, (char *)(& ad_attr->hw_ver));
  return;
}
}
static enum bfa_ioc_type bfa_ioc_get_type(struct bfa_ioc *ioc ) 
{ 
  long tmp ;

  {
  if ((unsigned int )ioc->clscode == 512U) {
    return (3);
  } else {

  }
  tmp = ldv__builtin_expect((unsigned int )ioc->clscode != 3076U, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c"),
                         "i" (2798), "i" (12UL));
    ldv_48692: ;
    goto ldv_48692;
  } else {

  }
  return ((unsigned int )(ioc->attr)->port_mode == 1U ? 1 : 2);
}
}
static void bfa_ioc_get_adapter_serial_num(struct bfa_ioc *ioc , char *serial_num ) 
{ 


  {
  memcpy((void *)serial_num, (void const   *)(& (ioc->attr)->brcd_serialnum), 12UL);
  return;
}
}
static void bfa_ioc_get_adapter_fw_ver(struct bfa_ioc *ioc , char *fw_ver ) 
{ 


  {
  memcpy((void *)fw_ver, (void const   *)(& (ioc->attr)->fw_version), 64UL);
  return;
}
}
static void bfa_ioc_get_pci_chip_rev(struct bfa_ioc *ioc , char *chip_rev ) 
{ 
  long tmp ;

  {
  tmp = ldv__builtin_expect((unsigned long )chip_rev == (unsigned long )((char *)0),
                         0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c"),
                         "i" (2821), "i" (12UL));
    ldv_48705: ;
    goto ldv_48705;
  } else {

  }
  memset((void *)chip_rev, 0, 8UL);
  *chip_rev = 82;
  *(chip_rev + 1UL) = 101;
  *(chip_rev + 2UL) = 118;
  *(chip_rev + 3UL) = 45;
  *(chip_rev + 4UL) = (ioc->attr)->asic_rev;
  *(chip_rev + 5UL) = 0;
  return;
}
}
static void bfa_ioc_get_adapter_optrom_ver(struct bfa_ioc *ioc , char *optrom_ver ) 
{ 


  {
  memcpy((void *)optrom_ver, (void const   *)(& (ioc->attr)->optrom_version), 64UL);
  return;
}
}
static void bfa_ioc_get_adapter_manufacturer(struct bfa_ioc *ioc , char *manufacturer ) 
{ 


  {
  memcpy((void *)manufacturer, (void const   *)"QLogic", 8UL);
  return;
}
}
static void bfa_ioc_get_adapter_model(struct bfa_ioc *ioc , char *model ) 
{ 
  struct bfi_ioc_attr *ioc_attr ;
  long tmp ;

  {
  tmp = ldv__builtin_expect((unsigned long )model == (unsigned long )((char *)0), 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c"),
                         "i" (2851), "i" (12UL));
    ldv_48719: ;
    goto ldv_48719;
  } else {

  }
  memset((void *)model, 0, 16UL);
  ioc_attr = ioc->attr;
  snprintf(model, 16UL, "%s-%u", (char *)"QLogic", ioc_attr->card_type);
  return;
}
}
static enum bfa_ioc_state bfa_ioc_get_state(struct bfa_ioc *ioc ) 
{ 
  enum bfa_iocpf_state iocpf_st ;
  enum bfa_ioc_state ioc_st ;
  int tmp ;
  int tmp___0 ;

  {
  tmp = bfa_sm_to_state((struct bfa_sm_table  const  *)(& ioc_sm_table), ioc->fsm);
  ioc_st = (enum bfa_ioc_state )tmp;
  if (((unsigned int )ioc_st == 12U || (unsigned int )ioc_st == 8U) || (unsigned int )ioc_st == 7U) {
    tmp___0 = bfa_sm_to_state((struct bfa_sm_table  const  *)(& iocpf_sm_table), ioc->iocpf.fsm);
    iocpf_st = (enum bfa_iocpf_state )tmp___0;
    switch ((unsigned int )iocpf_st) {
    case 2U: 
    ioc_st = 3;
    goto ldv_48726;
    case 3U: 
    ioc_st = 4;
    goto ldv_48726;
    case 9U: 
    ioc_st = 11;
    goto ldv_48726;
    case 6U: 
    ioc_st = 8;
    goto ldv_48726;
    case 5U: 
    ioc_st = 7;
    goto ldv_48726;
    default: ;
    goto ldv_48726;
    }
    ldv_48726: ;
  } else {

  }
  return (ioc_st);
}
}
void bfa_nw_ioc_get_attr(struct bfa_ioc *ioc , struct bfa_ioc_attr *ioc_attr ) 
{ 


  {
  memset((void *)ioc_attr, 0, 1600UL);
  ioc_attr->state = bfa_ioc_get_state(ioc);
  ioc_attr->port_id = ioc->port_id;
  ioc_attr->port_mode = (u8 )ioc->port_mode;
  ioc_attr->port_mode_cfg = ioc->port_mode_cfg;
  ioc_attr->cap_bm = ioc->ad_cap_bm;
  ioc_attr->ioc_type = bfa_ioc_get_type(ioc);
  bfa_ioc_get_adapter_attr(ioc, & ioc_attr->adapter_attr);
  ioc_attr->pci_attr.device_id = ioc->pcidev.device_id;
  ioc_attr->pci_attr.pcifn = (u32 )ioc->pcidev.pci_func;
  ioc_attr->def_fn = (int )ioc->pcidev.pci_func == (int )ioc->port_id;
  bfa_ioc_get_pci_chip_rev(ioc, (char *)(& ioc_attr->pci_attr.chip_rev));
  return;
}
}
static u64 bfa_ioc_get_pwwn(struct bfa_ioc *ioc ) 
{ 


  {
  return ((ioc->attr)->pwwn);
}
}
void bfa_nw_ioc_get_mac(struct bfa_ioc *ioc , u8 *mac ) 
{ 


  {
  ether_addr_copy(mac, (u8 const   *)(& (ioc->attr)->mac));
  return;
}
}
static void bfa_ioc_recover(struct bfa_ioc *ioc ) 
{ 


  {
  printk("\nHeart Beat of IOC has failed\n");
  ioc->stats.ioc_hbfails = ioc->stats.ioc_hbfails + 1U;
  ioc->stats.hb_count = ioc->hb_count;
  (*(ioc->fsm))((void *)ioc, 9);
  return;
}
}
static void bfa_iocpf_enable(struct bfa_ioc *ioc ) 
{ 


  {
  (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 1);
  return;
}
}
static void bfa_iocpf_disable(struct bfa_ioc *ioc ) 
{ 


  {
  (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 2);
  return;
}
}
static void bfa_iocpf_fail(struct bfa_ioc *ioc ) 
{ 


  {
  (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 7);
  return;
}
}
static void bfa_iocpf_initfail(struct bfa_ioc *ioc ) 
{ 


  {
  (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 8);
  return;
}
}
static void bfa_iocpf_getattrfail(struct bfa_ioc *ioc ) 
{ 


  {
  (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 9);
  return;
}
}
static void bfa_iocpf_stop(struct bfa_ioc *ioc ) 
{ 


  {
  (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 3);
  return;
}
}
void bfa_nw_iocpf_timeout(struct bfa_ioc *ioc ) 
{ 
  enum bfa_iocpf_state iocpf_st ;
  int tmp ;

  {
  tmp = bfa_sm_to_state((struct bfa_sm_table  const  *)(& iocpf_sm_table), ioc->iocpf.fsm);
  iocpf_st = (enum bfa_iocpf_state )tmp;
  if ((unsigned int )iocpf_st == 3U) {
    bfa_ioc_poll_fwinit(ioc);
  } else {
    (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 11);
  }
  return;
}
}
void bfa_nw_iocpf_sem_timeout(struct bfa_ioc *ioc ) 
{ 


  {
  bfa_ioc_hw_sem_get(ioc);
  return;
}
}
static void bfa_ioc_poll_fwinit(struct bfa_ioc *ioc ) 
{ 
  u32 fwstate ;
  enum bfi_ioc_state tmp ;
  unsigned long tmp___0 ;

  {
  tmp = (*((ioc->ioc_hwif)->ioc_get_fwstate))(ioc);
  fwstate = tmp;
  if (fwstate == 6U) {
    (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 4);
    return;
  } else {

  }
  if (ioc->iocpf.poll_time > 2999U) {
    (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 11);
  } else {
    ioc->iocpf.poll_time = ioc->iocpf.poll_time + 200U;
    tmp___0 = msecs_to_jiffies(200U);
    ldv_mod_timer_397(& ioc->iocpf_timer, tmp___0 + (unsigned long )jiffies);
  }
  return;
}
}
static void bfa_flash_cb(struct bfa_flash *flash ) 
{ 


  {
  flash->op_busy = 0U;
  if ((unsigned long )flash->cbfn != (unsigned long )((void (*)(void * , enum bfa_status  ))0)) {
    (*(flash->cbfn))(flash->cbarg, flash->status);
  } else {

  }
  return;
}
}
static void bfa_flash_notify(void *cbarg , enum bfa_ioc_event event ) 
{ 
  struct bfa_flash *flash ;

  {
  flash = (struct bfa_flash *)cbarg;
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U: ;
  if (flash->op_busy != 0U) {
    flash->status = 56;
    (*(flash->cbfn))(flash->cbarg, flash->status);
    flash->op_busy = 0U;
  } else {

  }
  goto ldv_48785;
  default: ;
  goto ldv_48785;
  }
  ldv_48785: ;
  return;
}
}
static void bfa_flash_write_send(struct bfa_flash *flash ) 
{ 
  struct bfi_flash_write_req *msg ;
  u32 len ;
  __u32 tmp ;
  __u32 tmp___0 ;
  int __y___0 ;
  int __y___1 ;
    klee_make_symbolic(&__y___1, sizeof(int), "__y___1");
  __u32 tmp___1 ;

  {
  msg = (struct bfi_flash_write_req *)(& flash->mb.msg);
  tmp = __fswab32(flash->type);
  msg->type = tmp;
  msg->instance = flash->instance;
  tmp___0 = __fswab32(flash->addr_off + flash->offset);
  msg->offset = tmp___0;
  __y___1 = 2048;
  if ((unsigned long )flash->residue < (((unsigned long )(__y___1 + -1) + 65792UL) / (unsigned long )__y___1) * (unsigned long )__y___1) {
    len = flash->residue;
  } else {
    __y___0 = 2048;
    len = (u32 )((((unsigned long )(__y___0 + -1) + 65792UL) / (unsigned long )__y___0) * (unsigned long )__y___0);
  }
  tmp___1 = __fswab32(len);
  msg->length = tmp___1;
  msg->last = flash->residue == len;
  msg->mh.msg_class = 3U;
  msg->mh.msg_id = 3U;
  msg->mh.mtag.h2i.fn_lpu = (flash->ioc)->port_id;
  __bfa_alen_set(& msg->alen, len, flash->dbuf_pa);
  memcpy((void *)flash->dbuf_kva, (void const   *)flash->ubuf + (unsigned long )flash->offset,
           (size_t )len);
  bfa_nw_ioc_mbox_queue(flash->ioc, & flash->mb, (void (*)(void * ))0, (void *)0);
  flash->residue = flash->residue - len;
  flash->offset = flash->offset + len;
  return;
}
}
static void bfa_flash_read_send(void *cbarg ) 
{ 
  struct bfa_flash *flash ;
  struct bfi_flash_read_req *msg ;
  u32 len ;
  __u32 tmp ;
  __u32 tmp___0 ;
  int __y___0 ;
  int __y___1 ;
  __u32 tmp___1 ;

  {
  flash = (struct bfa_flash *)cbarg;
  msg = (struct bfi_flash_read_req *)(& flash->mb.msg);
  tmp = __fswab32(flash->type);
  msg->type = tmp;
  msg->instance = flash->instance;
  tmp___0 = __fswab32(flash->addr_off + flash->offset);
  msg->offset = tmp___0;
  __y___1 = 2048;
  if ((unsigned long )flash->residue < (((unsigned long )(__y___1 + -1) + 65792UL) / (unsigned long )__y___1) * (unsigned long )__y___1) {
    len = flash->residue;
  } else {
    __y___0 = 2048;
    len = (u32 )((((unsigned long )(__y___0 + -1) + 65792UL) / (unsigned long )__y___0) * (unsigned long )__y___0);
  }
  tmp___1 = __fswab32(len);
  msg->length = tmp___1;
  msg->mh.msg_class = 3U;
  msg->mh.msg_id = 4U;
  msg->mh.mtag.h2i.fn_lpu = (flash->ioc)->port_id;
  __bfa_alen_set(& msg->alen, len, flash->dbuf_pa);
  bfa_nw_ioc_mbox_queue(flash->ioc, & flash->mb, (void (*)(void * ))0, (void *)0);
  return;
}
}
static void bfa_flash_intr(void *flasharg , struct bfi_mbmsg *msg ) 
{ 
  struct bfa_flash *flash ;
  u32 status ;
  union __anonunion_m_341 m ;
  __u32 tmp ;
  u32 i ;
  struct bfa_flash_attr *attr ;
  struct bfa_flash_attr *f ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;
  __u32 tmp___4 ;
  __u32 tmp___5 ;
  __u32 tmp___6 ;
  __u32 tmp___7 ;
  __u32 tmp___8 ;
  __u32 tmp___9 ;
  u32 len ;
  __u32 tmp___10 ;
  int __ret_warn_on ;
  long tmp___11 ;

  {
  flash = (struct bfa_flash *)flasharg;
  m.msg = msg;
  if (flash->op_busy == 0U && (unsigned int )msg->mh.msg_id != 255U) {
    return;
  } else {

  }
  switch ((int )msg->mh.msg_id) {
  case 129: 
  tmp = __fswab32((m.query)->status);
  status = tmp;
  if (status == 0U) {
    attr = (struct bfa_flash_attr *)flash->ubuf;
    f = (struct bfa_flash_attr *)flash->dbuf_kva;
    tmp___0 = __fswab32(f->status);
    attr->status = tmp___0;
    tmp___1 = __fswab32(f->npart);
    attr->npart = tmp___1;
    i = 0U;
    goto ldv_48823;
    ldv_48822: 
    tmp___2 = __fswab32(f->part[i].part_type);
    attr->part[i].part_type = tmp___2;
    tmp___3 = __fswab32(f->part[i].part_instance);
    attr->part[i].part_instance = tmp___3;
    tmp___4 = __fswab32(f->part[i].part_off);
    attr->part[i].part_off = tmp___4;
    tmp___5 = __fswab32(f->part[i].part_size);
    attr->part[i].part_size = tmp___5;
    tmp___6 = __fswab32(f->part[i].part_len);
    attr->part[i].part_len = tmp___6;
    tmp___7 = __fswab32(f->part[i].part_status);
    attr->part[i].part_status = tmp___7;
    i = i + 1U;
    ldv_48823: ;
    if (attr->npart > i) {
      goto ldv_48822;
    } else {

    }

  } else {

  }
  flash->status = (enum bfa_status )status;
  bfa_flash_cb(flash);
  goto ldv_48825;
  case 131: 
  tmp___8 = __fswab32((m.write)->status);
  status = tmp___8;
  if (status != 0U || flash->residue == 0U) {
    flash->status = (enum bfa_status )status;
    bfa_flash_cb(flash);
  } else {
    bfa_flash_write_send(flash);
  }
  goto ldv_48825;
  case 132: 
  tmp___9 = __fswab32((m.read)->status);
  status = tmp___9;
  if (status != 0U) {
    flash->status = (enum bfa_status )status;
    bfa_flash_cb(flash);
  } else {
    tmp___10 = __fswab32((m.read)->length);
    len = tmp___10;
    memcpy((void *)flash->ubuf + (unsigned long )flash->offset, (void const   *)flash->dbuf_kva,
             (size_t )len);
    flash->residue = flash->residue - len;
    flash->offset = flash->offset + len;
    if (flash->residue == 0U) {
      flash->status = (enum bfa_status )status;
      bfa_flash_cb(flash);
    } else {
      bfa_flash_read_send((void *)flash);
    }
  }
  goto ldv_48825;
  case 133: ;
  case 255: ;
  goto ldv_48825;
  default: 
  __ret_warn_on = 1;
  tmp___11 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___11 != 0L) {
    warn_slowpath_null("/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
                       3199);
  } else {

  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  }
  ldv_48825: ;
  return;
}
}
u32 bfa_nw_flash_meminfo(void) 
{ 
  int __y ;
  int __y___0 ;

  {
  __y = 256;
  __y___0 = 2048;
  return ((u32 )((((((unsigned long )(__y___0 + -1) + 65792UL) / (unsigned long )__y___0) * (unsigned long )__y___0 + (unsigned long )(__y + -1)) / (unsigned long )__y) * (unsigned long )__y));
}
}
void bfa_nw_flash_attach(struct bfa_flash *flash , struct bfa_ioc *ioc , void *dev ) 
{ 


  {
  flash->ioc = ioc;
  flash->cbfn = (void (*)(void * , enum bfa_status  ))0;
  flash->cbarg = (void *)0;
  flash->op_busy = 0U;
  bfa_nw_ioc_mbox_regisr(flash->ioc, 3, & bfa_flash_intr, (void *)flash);
  flash->ioc_notify.cbfn = & bfa_flash_notify;
  flash->ioc_notify.cbarg = (void *)flash;
  list_add_tail(& flash->ioc_notify.qe, & (flash->ioc)->notify_q);
  return;
}
}
void bfa_nw_flash_memclaim(struct bfa_flash *flash , u8 *dm_kva , u64 dm_pa ) 
{ 
  int __y ;
  int __y___0 ;
  int __y___1 ;
  int __y___2 ;
    klee_make_symbolic(&__y___2, sizeof(int), "__y___2");
  int __y___3 ;
    klee_make_symbolic(&__y___3, sizeof(int), "__y___3");

  {
  flash->dbuf_kva = dm_kva;
  flash->dbuf_pa = dm_pa;
  __y = 2048;
  memset((void *)flash->dbuf_kva, 0, (((unsigned long )(__y + -1) + 65792UL) / (unsigned long )__y) * (unsigned long )__y);
  __y___0 = 256;
  __y___1 = 2048;
  dm_kva = dm_kva + (((((unsigned long )(__y___1 + -1) + 65792UL) / (unsigned long )__y___1) * (unsigned long )__y___1 + (unsigned long )(__y___0 + -1)) / (unsigned long )__y___0) * (unsigned long )__y___0;
  __y___2 = 256;
  __y___3 = 2048;
  dm_pa = (unsigned long long )((((((unsigned long )(__y___3 + -1) + 65792UL) / (unsigned long )__y___3) * (unsigned long )__y___3 + (unsigned long )(__y___2 + -1)) / (unsigned long )__y___2) * (unsigned long )__y___2) + dm_pa;
  return;
}
}
enum bfa_status bfa_nw_flash_get_attr(struct bfa_flash *flash , struct bfa_flash_attr *attr ,
                                      void (*cbfn)(void * , enum bfa_status  ) , void *cbarg ) 
{ 
  struct bfi_flash_query_req *msg ;
  bool tmp ;
  int tmp___0 ;

  {
  msg = (struct bfi_flash_query_req *)(& flash->mb.msg);
  tmp = bfa_nw_ioc_is_operational(flash->ioc);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (61);
  } else {

  }
  if (flash->op_busy != 0U) {
    return (13);
  } else {

  }
  flash->op_busy = 1U;
  flash->cbfn = cbfn;
  flash->cbarg = cbarg;
  flash->ubuf = (u8 *)attr;
  msg->mh.msg_class = 3U;
  msg->mh.msg_id = 1U;
  msg->mh.mtag.h2i.fn_lpu = (flash->ioc)->port_id;
  __bfa_alen_set(& msg->alen, 1032U, flash->dbuf_pa);
  bfa_nw_ioc_mbox_queue(flash->ioc, & flash->mb, (void (*)(void * ))0, (void *)0);
  return (0);
}
}
enum bfa_status bfa_nw_flash_update_part(struct bfa_flash *flash , u32 type , u8 instance ,
                                         void *buf , u32 len , u32 offset , void (*cbfn)(void * ,
                                                                                         enum bfa_status  ) ,
                                         void *cbarg ) 
{ 
  bool tmp ;
  int tmp___0 ;

  {
  tmp = bfa_nw_ioc_is_operational(flash->ioc);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (61);
  } else {

  }
  if (len == 0U || (len & 3U) != 0U) {
    return (17);
  } else {

  }
  if (type == 7U) {
    return (2);
  } else {

  }
  if (flash->op_busy != 0U) {
    return (13);
  } else {

  }
  flash->op_busy = 1U;
  flash->cbfn = cbfn;
  flash->cbarg = cbarg;
  flash->type = type;
  flash->instance = instance;
  flash->residue = len;
  flash->offset = 0U;
  flash->addr_off = offset;
  flash->ubuf = (u8 *)buf;
  bfa_flash_write_send(flash);
  return (0);
}
}
enum bfa_status bfa_nw_flash_read_part(struct bfa_flash *flash , u32 type , u8 instance ,
                                       void *buf , u32 len , u32 offset , void (*cbfn)(void * ,
                                                                                       enum bfa_status  ) ,
                                       void *cbarg ) 
{ 
  bool tmp ;
  int tmp___0 ;

  {
  tmp = bfa_nw_ioc_is_operational(flash->ioc);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (61);
  } else {

  }
  if (len == 0U || (len & 3U) != 0U) {
    return (17);
  } else {

  }
  if (flash->op_busy != 0U) {
    return (13);
  } else {

  }
  flash->op_busy = 1U;
  flash->cbfn = cbfn;
  flash->cbarg = cbarg;
  flash->type = type;
  flash->instance = instance;
  flash->residue = len;
  flash->offset = 0U;
  flash->addr_off = offset;
  flash->ubuf = (u8 *)buf;
  bfa_flash_read_send((void *)flash);
  return (0);
}
}
bool ldv_queue_work_on_348(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_349(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_350(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_351(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_352(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
int ldv_pskb_expand_head_364(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_366(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_368(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_369(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_370(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_371(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_372(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
int ldv_pskb_expand_head_373(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_374(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
int ldv_mod_timer_375(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___6 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_376(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___7 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_377(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___8 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_378(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___9 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_379(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___10 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_380(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___11 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_381(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___12 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_382(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___13 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_383(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___14 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_384(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___15 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_385(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___16 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_386(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___17 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_387(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___18 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_388(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___19 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_389(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___20 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_390(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___21 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_391(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___22 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_392(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___23 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_393(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___24 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_394(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___25 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_395(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___26 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_396(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___27 ldv_func_res ;
  int tmp ;

  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_397(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___28 ldv_func_res ;
  int tmp ;

  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
bool ldv_queue_work_on_440(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_442(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_441(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_444(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_443(struct workqueue_struct *ldv_func_arg1 ) ;
struct sk_buff *ldv_skb_clone_458(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_466(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_460(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_456(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_464(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_465(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_461(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_462(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_463(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
static bool bfa_ioc_ct_firmware_lock(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_firmware_unlock(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_reg_init(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct2_reg_init(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_map_port(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct2_map_port(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_isr_mode_set(struct bfa_ioc *ioc , bool msix ) ;
static void bfa_ioc_ct_notify_fail(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_ownership_reset(struct bfa_ioc *ioc ) ;
static bool bfa_ioc_ct_sync_start(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_sync_join(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_sync_leave(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_sync_ack(struct bfa_ioc *ioc ) ;
static bool bfa_ioc_ct_sync_complete(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_set_cur_ioc_fwstate(struct bfa_ioc *ioc , enum bfi_ioc_state fwstate ) ;
static enum bfi_ioc_state bfa_ioc_ct_get_cur_ioc_fwstate(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_set_alt_ioc_fwstate(struct bfa_ioc *ioc , enum bfi_ioc_state fwstate ) ;
static enum bfi_ioc_state bfa_ioc_ct_get_alt_ioc_fwstate(struct bfa_ioc *ioc ) ;
static enum bfa_status bfa_ioc_ct_pll_init(void *rb , enum bfi_asic_mode asic_mode ) ;
static enum bfa_status bfa_ioc_ct2_pll_init(void *rb , enum bfi_asic_mode asic_mode ) ;
static bool bfa_ioc_ct2_lpu_read_stat(struct bfa_ioc *ioc ) ;
static struct bfa_ioc_hwif  const  nw_hwif_ct  = 
     {& bfa_ioc_ct_pll_init, & bfa_ioc_ct_firmware_lock, & bfa_ioc_ct_firmware_unlock,
    & bfa_ioc_ct_reg_init, & bfa_ioc_ct_map_port, & bfa_ioc_ct_isr_mode_set, & bfa_ioc_ct_notify_fail,
    & bfa_ioc_ct_ownership_reset, & bfa_ioc_ct_sync_start, & bfa_ioc_ct_sync_join,
    & bfa_ioc_ct_sync_leave, & bfa_ioc_ct_sync_ack, & bfa_ioc_ct_sync_complete, 0,
    & bfa_ioc_ct_set_cur_ioc_fwstate, & bfa_ioc_ct_get_cur_ioc_fwstate, & bfa_ioc_ct_set_alt_ioc_fwstate,
    & bfa_ioc_ct_get_alt_ioc_fwstate};
static struct bfa_ioc_hwif  const  nw_hwif_ct2  = 
     {& bfa_ioc_ct2_pll_init, & bfa_ioc_ct_firmware_lock, & bfa_ioc_ct_firmware_unlock,
    & bfa_ioc_ct2_reg_init, & bfa_ioc_ct2_map_port, (void (*)(struct bfa_ioc * , bool  ))0,
    & bfa_ioc_ct_notify_fail, & bfa_ioc_ct_ownership_reset, & bfa_ioc_ct_sync_start,
    & bfa_ioc_ct_sync_join, & bfa_ioc_ct_sync_leave, & bfa_ioc_ct_sync_ack, & bfa_ioc_ct_sync_complete,
    & bfa_ioc_ct2_lpu_read_stat, & bfa_ioc_ct_set_cur_ioc_fwstate, & bfa_ioc_ct_get_cur_ioc_fwstate,
    & bfa_ioc_ct_set_alt_ioc_fwstate, & bfa_ioc_ct_get_alt_ioc_fwstate};
void bfa_nw_ioc_set_ct_hwif(struct bfa_ioc *ioc ) 
{ 


  {
  ioc->ioc_hwif = & nw_hwif_ct;
  return;
}
}
void bfa_nw_ioc_set_ct2_hwif(struct bfa_ioc *ioc ) 
{ 


  {
  ioc->ioc_hwif = & nw_hwif_ct2;
  return;
}
}
static bool bfa_ioc_ct_firmware_lock(struct bfa_ioc *ioc ) 
{ 
  enum bfi_ioc_state ioc_fwstate ;
  u32 usecnt ;
  struct bfi_ioc_image_hdr fwhdr ;
  u32 tmp ;
  unsigned int tmp___0 ;
  long tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;

  {
  tmp = bfa_cb_image_get_size(ioc->asic_gen);
  if (tmp <= 16383U) {
    return (1);
  } else {

  }
  bfa_nw_ioc_sem_get(ioc->ioc_regs.ioc_usage_sem_reg);
  usecnt = readl((void const volatile   *)ioc->ioc_regs.ioc_usage_reg);
  if (usecnt == 0U) {
    writel(1U, (void volatile   *)ioc->ioc_regs.ioc_usage_reg);
    bfa_nw_ioc_sem_release(ioc->ioc_regs.ioc_usage_sem_reg);
    writel(0U, (void volatile   *)ioc->ioc_regs.ioc_fail_sync);
    return (1);
  } else {

  }
  tmp___0 = readl((void const volatile   *)ioc->ioc_regs.ioc_fwstate);
  ioc_fwstate = (enum bfi_ioc_state )tmp___0;
  tmp___1 = ldv__builtin_expect((unsigned int )ioc_fwstate == 0U, 0L);
  if (tmp___1 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc_ct.c"),
                         "i" (150), "i" (12UL));
    ldv_47530: ;
    goto ldv_47530;
  } else {

  }
  bfa_nw_ioc_fwver_get(ioc, & fwhdr);
  tmp___2 = bfa_nw_ioc_fwver_cmp(ioc, & fwhdr);
  if (tmp___2) {
    tmp___3 = 0;
  } else {
    tmp___3 = 1;
  }
  if (tmp___3) {
    bfa_nw_ioc_sem_release(ioc->ioc_regs.ioc_usage_sem_reg);
    return (0);
  } else {

  }
  usecnt = usecnt + 1U;
  writel(usecnt, (void volatile   *)ioc->ioc_regs.ioc_usage_reg);
  bfa_nw_ioc_sem_release(ioc->ioc_regs.ioc_usage_sem_reg);
  return (1);
}
}
static void bfa_ioc_ct_firmware_unlock(struct bfa_ioc *ioc ) 
{ 
  u32 usecnt ;
  u32 tmp ;
  long tmp___0 ;

  {
  tmp = bfa_cb_image_get_size(ioc->asic_gen);
  if (tmp <= 16383U) {
    return;
  } else {

  }
  bfa_nw_ioc_sem_get(ioc->ioc_regs.ioc_usage_sem_reg);
  usecnt = readl((void const volatile   *)ioc->ioc_regs.ioc_usage_reg);
  tmp___0 = ldv__builtin_expect(usecnt == 0U, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc_ct.c"),
                         "i" (187), "i" (12UL));
    ldv_47535: ;
    goto ldv_47535;
  } else {

  }
  usecnt = usecnt - 1U;
  writel(usecnt, (void volatile   *)ioc->ioc_regs.ioc_usage_reg);
  bfa_nw_ioc_sem_release(ioc->ioc_regs.ioc_usage_sem_reg);
  return;
}
}
static void bfa_ioc_ct_notify_fail(struct bfa_ioc *ioc ) 
{ 


  {
  writel(1U, (void volatile   *)ioc->ioc_regs.ll_halt);
  writel(1U, (void volatile   *)ioc->ioc_regs.alt_ll_halt);
  readl((void const volatile   *)ioc->ioc_regs.ll_halt);
  readl((void const volatile   *)ioc->ioc_regs.alt_ll_halt);
  return;
}
}
static struct __anonstruct_ct_fnreg_337  const  ct_fnreg[4U]  = {      {102912U, 103040U, 81928U}, 
        {103008U, 103136U, 82184U}, 
        {103424U, 103552U, 82696U}, 
        {103520U, 103648U, 82952U}};
static struct __anonstruct_ct_p0reg_338  const  ct_p0reg[4U]  = {      {102400U, 102408U}, 
        {102416U, 102424U}, 
        {102736U, 102744U}, 
        {102752U, 102760U}};
static struct __anonstruct_ct_p1reg_339  const  ct_p1reg[4U]  = {      {102404U, 102412U}, 
        {102420U, 102428U}, 
        {102740U, 102748U}, 
        {102756U, 102764U}};
static struct __anonstruct_ct2_reg_340  const  ct2_reg[2U]  = {      {196608U, 196672U, 196888U, 196736U, 196744U, 196752U}, 
        {196640U, 196704U, 196888U, 196740U, 196748U, 196756U}};
static void bfa_ioc_ct_reg_init(struct bfa_ioc *ioc ) 
{ 
  void *rb ;
  int pcifn ;
    klee_make_symbolic(&pcifn, sizeof(int), "pcifn");

  {
  pcifn = (int )ioc->pcidev.pci_func;
  rb = ioc->pcidev.pci_bar_kva;
  ioc->ioc_regs.hfn_mbox = rb + (unsigned long )ct_fnreg[pcifn].hfn_mbox;
  ioc->ioc_regs.lpu_mbox = rb + (unsigned long )ct_fnreg[pcifn].lpu_mbox;
  ioc->ioc_regs.host_page_num_fn = rb + (unsigned long )ct_fnreg[pcifn].hfn_pgn;
  if ((unsigned int )ioc->port_id == 0U) {
    ioc->ioc_regs.heartbeat = rb + 82496UL;
    ioc->ioc_regs.ioc_fwstate = rb + 82500UL;
    ioc->ioc_regs.alt_ioc_fwstate = rb + 82508UL;
    ioc->ioc_regs.hfn_mbox_cmd = rb + (unsigned long )ct_p0reg[pcifn].hfn;
    ioc->ioc_regs.lpu_mbox_cmd = rb + (unsigned long )ct_p0reg[pcifn].lpu;
    ioc->ioc_regs.ll_halt = rb + 102828UL;
    ioc->ioc_regs.alt_ll_halt = rb + 102844UL;
  } else {
    ioc->ioc_regs.heartbeat = rb + 82504UL;
    ioc->ioc_regs.ioc_fwstate = rb + 82508UL;
    ioc->ioc_regs.alt_ioc_fwstate = rb + 82500UL;
    ioc->ioc_regs.hfn_mbox_cmd = rb + (unsigned long )ct_p1reg[pcifn].hfn;
    ioc->ioc_regs.lpu_mbox_cmd = rb + (unsigned long )ct_p1reg[pcifn].lpu;
    ioc->ioc_regs.ll_halt = rb + 102844UL;
    ioc->ioc_regs.alt_ll_halt = rb + 102828UL;
  }
  ioc->ioc_regs.pss_ctl_reg = rb + 100352UL;
  ioc->ioc_regs.pss_err_status_reg = rb + 100368UL;
  ioc->ioc_regs.app_pll_fast_ctl_reg = rb + 82436UL;
  ioc->ioc_regs.app_pll_slow_ctl_reg = rb + 82440UL;
  ioc->ioc_regs.ioc_sem_reg = rb + 82480UL;
  ioc->ioc_regs.ioc_usage_sem_reg = rb + 82484UL;
  ioc->ioc_regs.ioc_init_sem_reg = rb + 82488UL;
  ioc->ioc_regs.ioc_usage_reg = rb + 83488UL;
  ioc->ioc_regs.ioc_fail_sync = rb + 83492UL;
  ioc->ioc_regs.smem_page_start = rb + 32768UL;
  ioc->ioc_regs.smem_pg0 = 384U;
  ioc->ioc_regs.err_set = rb + 100376UL;
  return;
}
}
static void bfa_ioc_ct2_reg_init(struct bfa_ioc *ioc ) 
{ 
  void *rb ;
  int port ;

  {
  port = (int )ioc->port_id;
  rb = ioc->pcidev.pci_bar_kva;
  ioc->ioc_regs.hfn_mbox = rb + (unsigned long )ct2_reg[port].hfn_mbox;
  ioc->ioc_regs.lpu_mbox = rb + (unsigned long )ct2_reg[port].lpu_mbox;
  ioc->ioc_regs.host_page_num_fn = rb + (unsigned long )ct2_reg[port].hfn_pgn;
  ioc->ioc_regs.hfn_mbox_cmd = rb + (unsigned long )ct2_reg[port].hfn;
  ioc->ioc_regs.lpu_mbox_cmd = rb + (unsigned long )ct2_reg[port].lpu;
  ioc->ioc_regs.lpu_read_stat = rb + (unsigned long )ct2_reg[port].lpu_read;
  if (port == 0) {
    ioc->ioc_regs.heartbeat = rb + 84144UL;
    ioc->ioc_regs.ioc_fwstate = rb + 84148UL;
    ioc->ioc_regs.alt_ioc_fwstate = rb + 84156UL;
    ioc->ioc_regs.ll_halt = rb + 102828UL;
    ioc->ioc_regs.alt_ll_halt = rb + 102844UL;
  } else {
    ioc->ioc_regs.heartbeat = rb + 84152UL;
    ioc->ioc_regs.ioc_fwstate = rb + 84156UL;
    ioc->ioc_regs.alt_ioc_fwstate = rb + 84148UL;
    ioc->ioc_regs.ll_halt = rb + 102844UL;
    ioc->ioc_regs.alt_ll_halt = rb + 102828UL;
  }
  ioc->ioc_regs.pss_ctl_reg = rb + 100352UL;
  ioc->ioc_regs.pss_err_status_reg = rb + 100368UL;
  ioc->ioc_regs.app_pll_fast_ctl_reg = rb + 83976UL;
  ioc->ioc_regs.app_pll_slow_ctl_reg = rb + 83980UL;
  ioc->ioc_regs.ioc_sem_reg = rb + 84208UL;
  ioc->ioc_regs.ioc_usage_sem_reg = rb + 84212UL;
  ioc->ioc_regs.ioc_init_sem_reg = rb + 84216UL;
  ioc->ioc_regs.ioc_usage_reg = rb + 84160UL;
  ioc->ioc_regs.ioc_fail_sync = rb + 84164UL;
  ioc->ioc_regs.smem_page_start = rb + 32768UL;
  ioc->ioc_regs.smem_pg0 = 384U;
  ioc->ioc_regs.err_set = rb + 100376UL;
  return;
}
}
static void bfa_ioc_ct_map_port(struct bfa_ioc *ioc ) 
{ 
  void *rb ;
  u32 r32 ;

  {
  rb = ioc->pcidev.pci_bar_kva;
  r32 = readl((void const volatile   *)rb + 83460U);
  r32 = r32 >> (int )ioc->pcidev.pci_func * 8;
  ioc->port_id = (u8 )((r32 & 48U) >> 4);
  return;
}
}
static void bfa_ioc_ct2_map_port(struct bfa_ioc *ioc ) 
{ 
  void *rb ;
  u32 r32 ;

  {
  rb = ioc->pcidev.pci_bar_kva;
  r32 = readl((void const volatile   *)rb + 196872U);
  ioc->port_id = (u8 )((r32 & 393216U) >> 17);
  return;
}
}
static void bfa_ioc_ct_isr_mode_set(struct bfa_ioc *ioc , bool msix ) 
{ 
  void *rb ;
  u32 r32 ;
  u32 mode ;

  {
  rb = ioc->pcidev.pci_bar_kva;
  r32 = readl((void const volatile   *)rb + 83460U);
  mode = (r32 >> (int )ioc->pcidev.pci_func * 8) & 7U;
  if ((! msix && mode != 0U) || ((int )msix && mode == 0U)) {
    return;
  } else {

  }
  if ((int )msix) {
    mode = 0U;
  } else {
    mode = 1U;
  }
  r32 = (u32 )(~ (7 << (int )ioc->pcidev.pci_func * 8)) & r32;
  r32 = (mode << (int )ioc->pcidev.pci_func * 8) | r32;
  writel(r32, (void volatile   *)rb + 83460U);
  return;
}
}
static bool bfa_ioc_ct2_lpu_read_stat(struct bfa_ioc *ioc ) 
{ 
  u32 r32 ;

  {
  r32 = readl((void const volatile   *)ioc->ioc_regs.lpu_read_stat);
  if (r32 != 0U) {
    writel(1U, (void volatile   *)ioc->ioc_regs.lpu_read_stat);
    return (1);
  } else {

  }
  return (0);
}
}
void bfa_nw_ioc_ct2_poweron(struct bfa_ioc *ioc ) 
{ 
  void *rb ;
  u32 r32 ;

  {
  rb = ioc->pcidev.pci_bar_kva;
  r32 = readl((void const volatile   *)rb + 196924U);
  if ((r32 & 4192256U) != 0U) {
    writel(r32 & 2047U, (void volatile   *)rb + 196920U);
    return;
  } else {

  }
  writel((unsigned int )((int )ioc->pcidev.pci_func * 64 | 129024), (void volatile   *)rb + 196924U);
  writel((unsigned int )((int )ioc->pcidev.pci_func * 64), (void volatile   *)rb + 196920U);
  return;
}
}
static void bfa_ioc_ct_ownership_reset(struct bfa_ioc *ioc ) 
{ 


  {
  bfa_nw_ioc_sem_get(ioc->ioc_regs.ioc_usage_sem_reg);
  writel(0U, (void volatile   *)ioc->ioc_regs.ioc_usage_reg);
  bfa_nw_ioc_sem_release(ioc->ioc_regs.ioc_usage_sem_reg);
  readl((void const volatile   *)ioc->ioc_regs.ioc_sem_reg);
  bfa_nw_ioc_hw_sem_release(ioc);
  return;
}
}
static bool bfa_ioc_ct_sync_start(struct bfa_ioc *ioc ) 
{ 
  u32 r32 ;
  unsigned int tmp ;
  u32 sync_reqd ;
  bool tmp___0 ;

  {
  tmp = readl((void const volatile   *)ioc->ioc_regs.ioc_fail_sync);
  r32 = tmp;
  sync_reqd = r32 >> 16;
  if ((int )((unsigned long )sync_reqd >> (int )ioc->pcidev.pci_func) & 1) {
    writel(0U, (void volatile   *)ioc->ioc_regs.ioc_fail_sync);
    writel(1U, (void volatile   *)ioc->ioc_regs.ioc_usage_reg);
    writel(0U, (void volatile   *)ioc->ioc_regs.ioc_fwstate);
    writel(0U, (void volatile   *)ioc->ioc_regs.alt_ioc_fwstate);
    return (1);
  } else {

  }
  tmp___0 = bfa_ioc_ct_sync_complete(ioc);
  return (tmp___0);
}
}
static void bfa_ioc_ct_sync_join(struct bfa_ioc *ioc ) 
{ 
  u32 r32 ;
  unsigned int tmp ;
  u32 sync_pos ;

  {
  tmp = readl((void const volatile   *)ioc->ioc_regs.ioc_fail_sync);
  r32 = tmp;
  sync_pos = (u32 )(1UL << (int )ioc->pcidev.pci_func) << 16U;
  writel(r32 | sync_pos, (void volatile   *)ioc->ioc_regs.ioc_fail_sync);
  return;
}
}
static void bfa_ioc_ct_sync_leave(struct bfa_ioc *ioc ) 
{ 
  u32 r32 ;
  unsigned int tmp ;
  u32 sync_msk ;

  {
  tmp = readl((void const volatile   *)ioc->ioc_regs.ioc_fail_sync);
  r32 = tmp;
  sync_msk = ((u32 )(1UL << (int )ioc->pcidev.pci_func) << 16U) | (u32 )(1UL << (int )ioc->pcidev.pci_func);
  writel(~ sync_msk & r32, (void volatile   *)ioc->ioc_regs.ioc_fail_sync);
  return;
}
}
static void bfa_ioc_ct_sync_ack(struct bfa_ioc *ioc ) 
{ 
  u32 r32 ;
  unsigned int tmp ;

  {
  tmp = readl((void const volatile   *)ioc->ioc_regs.ioc_fail_sync);
  r32 = tmp;
  writel((unsigned int )(1UL << (int )ioc->pcidev.pci_func) | r32, (void volatile   *)ioc->ioc_regs.ioc_fail_sync);
  return;
}
}
static bool bfa_ioc_ct_sync_complete(struct bfa_ioc *ioc ) 
{ 
  u32 r32 ;
  unsigned int tmp ;
  u32 sync_reqd ;
  u32 sync_ackd ;
  u32 tmp_ackd ;

  {
  tmp = readl((void const volatile   *)ioc->ioc_regs.ioc_fail_sync);
  r32 = tmp;
  sync_reqd = r32 >> 16;
  sync_ackd = r32 & 65535U;
  if (sync_ackd == 0U) {
    return (1);
  } else {

  }
  tmp_ackd = sync_ackd;
  if ((int )((unsigned long )sync_reqd >> (int )ioc->pcidev.pci_func) & 1 && (((unsigned long )sync_ackd >> (int )ioc->pcidev.pci_func) & 1UL) == 0UL) {
    sync_ackd = (u32 )(1UL << (int )ioc->pcidev.pci_func) | sync_ackd;
  } else {

  }
  if (sync_reqd == sync_ackd) {
    writel(r32 & 4294901760U, (void volatile   *)ioc->ioc_regs.ioc_fail_sync);
    writel(8U, (void volatile   *)ioc->ioc_regs.ioc_fwstate);
    writel(8U, (void volatile   *)ioc->ioc_regs.alt_ioc_fwstate);
    return (1);
  } else {

  }
  if (tmp_ackd != sync_ackd) {
    writel(r32 | sync_ackd, (void volatile   *)ioc->ioc_regs.ioc_fail_sync);
  } else {

  }
  return (0);
}
}
static void bfa_ioc_ct_set_cur_ioc_fwstate(struct bfa_ioc *ioc , enum bfi_ioc_state fwstate ) 
{ 


  {
  writel((unsigned int )fwstate, (void volatile   *)ioc->ioc_regs.ioc_fwstate);
  return;
}
}
static enum bfi_ioc_state bfa_ioc_ct_get_cur_ioc_fwstate(struct bfa_ioc *ioc ) 
{ 
  unsigned int tmp ;

  {
  tmp = readl((void const volatile   *)ioc->ioc_regs.ioc_fwstate);
  return ((enum bfi_ioc_state )tmp);
}
}
static void bfa_ioc_ct_set_alt_ioc_fwstate(struct bfa_ioc *ioc , enum bfi_ioc_state fwstate ) 
{ 


  {
  writel((unsigned int )fwstate, (void volatile   *)ioc->ioc_regs.alt_ioc_fwstate);
  return;
}
}
static enum bfi_ioc_state bfa_ioc_ct_get_alt_ioc_fwstate(struct bfa_ioc *ioc ) 
{ 
  unsigned int tmp ;

  {
  tmp = readl((void const volatile   *)ioc->ioc_regs.alt_ioc_fwstate);
  return ((enum bfi_ioc_state )tmp);
}
}
static enum bfa_status bfa_ioc_ct_pll_init(void *rb , enum bfi_asic_mode asic_mode ) 
{ 
  u32 pll_sclk ;
  u32 pll_fclk ;
  u32 r32 ;
  bool fcmode ;

  {
  fcmode = (unsigned int )asic_mode == 1U;
  pll_sclk = 29466U;
  pll_fclk = 29466U;
  if ((int )fcmode) {
    writel(0U, (void volatile   *)rb + 83468U);
    writel(13U, (void volatile   *)rb + 82568U);
  } else {
    writel(1U, (void volatile   *)rb + 83468U);
    writel(2U, (void volatile   *)rb + 82568U);
  }
  writel(0U, (void volatile   *)rb + 82500U);
  writel(0U, (void volatile   *)rb + 82508U);
  writel(4294967295U, (void volatile   *)rb + 81924U);
  writel(4294967295U, (void volatile   *)rb + 82180U);
  writel(4294967295U, (void volatile   *)rb + 81920U);
  writel(4294967295U, (void volatile   *)rb + 82176U);
  writel(4294967295U, (void volatile   *)rb + 81924U);
  writel(4294967295U, (void volatile   *)rb + 82180U);
  writel(pll_sclk | 65536U, (void volatile   *)rb + 82440U);
  writel(pll_fclk | 65536U, (void volatile   *)rb + 82436U);
  writel(pll_sclk | 65537U, (void volatile   *)rb + 82440U);
  writel(pll_fclk | 65537U, (void volatile   *)rb + 82436U);
  readl((void const volatile   *)rb + 81924U);
  __const_udelay(8590000UL);
  writel(4294967295U, (void volatile   *)rb + 81920U);
  writel(4294967295U, (void volatile   *)rb + 82176U);
  writel(pll_sclk | 1U, (void volatile   *)rb + 82440U);
  writel(pll_fclk | 1U, (void volatile   *)rb + 82436U);
  if (! fcmode) {
    writel(1U, (void volatile   *)rb + 145436U);
    writel(1U, (void volatile   *)rb + 146460U);
  } else {

  }
  r32 = readl((void const volatile   *)rb + 100352U);
  r32 = r32 & 4294966783U;
  writel(r32, (void volatile   *)rb + 100352U);
  __const_udelay(4295000UL);
  if (! fcmode) {
    writel(0U, (void volatile   *)rb + 145436U);
    writel(0U, (void volatile   *)rb + 146460U);
  } else {

  }
  writel(4U, (void volatile   *)rb + 82464U);
  __const_udelay(4295000UL);
  r32 = readl((void const volatile   *)rb + 82468U);
  writel(0U, (void volatile   *)rb + 82464U);
  return (0);
}
}
static void bfa_ioc_ct2_sclk_init(void *rb ) 
{ 
  u32 r32 ;

  {
  r32 = readl((void const volatile   *)rb + 83980U);
  r32 = r32 & 4294967292U;
  r32 = r32 | 65548U;
  writel(r32, (void volatile   *)rb + 83980U);
  r32 = readl((void const volatile   *)rb + 83980U);
  r32 = r32 & 2684354559U;
  writel(r32, (void volatile   *)rb + 83980U);
  r32 = readl((void const volatile   *)rb + 84132U);
  writel(r32 | 16384U, (void volatile   *)rb + 84132U);
  r32 = readl((void const volatile   *)rb + 83972U);
  writel(r32 | 16U, (void volatile   *)rb + 83972U);
  r32 = readl((void const volatile   *)rb + 83980U);
  r32 = r32 & 3758096384U;
  writel(r32 | 274821915U, (void volatile   *)rb + 83980U);
  __const_udelay(4295000UL);
  return;
}
}
static void bfa_ioc_ct2_lclk_init(void *rb ) 
{ 
  u32 r32 ;

  {
  r32 = readl((void const volatile   *)rb + 83976U);
  r32 = r32 & 4294967292U;
  r32 = r32 | 65548U;
  writel(r32, (void volatile   *)rb + 83976U);
  r32 = readl((void const volatile   *)rb + 84132U);
  writel(r32, (void volatile   *)rb + 84132U);
  r32 = readl((void const volatile   *)rb + 83976U);
  writel(r32, (void volatile   *)rb + 83976U);
  r32 = readl((void const volatile   *)rb + 83976U);
  r32 = r32 & 3221225472U;
  r32 = r32 | 549548827U;
  writel(r32, (void volatile   *)rb + 83976U);
  __const_udelay(4295000UL);
  return;
}
}
static void bfa_ioc_ct2_mem_init(void *rb ) 
{ 
  u32 r32 ;

  {
  r32 = readl((void const volatile   *)rb + 100352U);
  r32 = r32 & 4294966783U;
  writel(r32, (void volatile   *)rb + 100352U);
  __const_udelay(4295000UL);
  writel(4U, (void volatile   *)rb + 83996U);
  __const_udelay(4295000UL);
  writel(0U, (void volatile   *)rb + 83996U);
  return;
}
}
static void bfa_ioc_ct2_mac_reset(void *rb ) 
{ 
  u32 volatile   r32 ;
  unsigned int tmp ;
  unsigned int tmp___0 ;

  {
  bfa_ioc_ct2_sclk_init(rb);
  bfa_ioc_ct2_lclk_init(rb);
  tmp = readl((void const volatile   *)rb + 83980U);
  r32 = tmp;
  writel((unsigned int )r32 & 4294901759U, (void volatile   *)rb + 83980U);
  tmp___0 = readl((void const volatile   *)rb + 83976U);
  r32 = tmp___0;
  writel((unsigned int )r32 & 4294901759U, (void volatile   *)rb + 83976U);
  writel(24U, (void volatile   *)rb + 159952U);
  writel(24U, (void volatile   *)rb + 159956U);
  return;
}
}
static bool bfa_ioc_ct2_nfc_halted(void *rb ) 
{ 
  u32 volatile   r32 ;
  unsigned int tmp ;

  {
  tmp = readl((void const volatile   *)rb + 160804U);
  r32 = tmp;
  if (((unsigned int )r32 & 4096U) != 0U) {
    return (1);
  } else {

  }
  return (0);
}
}
static void bfa_ioc_ct2_nfc_resume(void *rb ) 
{ 
  u32 volatile   r32 ;
  int i ;
  unsigned int tmp ;
  long tmp___0 ;

  {
  writel(2U, (void volatile   *)rb + 160800U);
  i = 0;
  goto ldv_47673;
  ldv_47672: 
  tmp = readl((void const volatile   *)rb + 160804U);
  r32 = tmp;
  if (((unsigned int )r32 & 4096U) == 0U) {
    return;
  } else {

  }
  __const_udelay(4295000UL);
  i = i + 1;
  ldv_47673: ;
  if (i <= 999) {
    goto ldv_47672;
  } else {

  }
  tmp___0 = ldv__builtin_expect(1L, 0L);
  if (tmp___0 != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc_ct.c"),
                         "i" (850), "i" (12UL));
    ldv_47675: ;
    goto ldv_47675;
  } else {

  }
  return;
}
}
static enum bfa_status bfa_ioc_ct2_pll_init(void *rb , enum bfi_asic_mode asic_mode ) 
{ 
  u32 volatile   wgn ;
  u32 volatile   r32 ;
  u32 nfc_ver ;
  u32 i ;
  unsigned int tmp ;
  bool tmp___0 ;
  unsigned int tmp___1 ;
  long tmp___2 ;
  unsigned int tmp___3 ;
  long tmp___4 ;
  unsigned int tmp___5 ;
  long tmp___6 ;
  unsigned int tmp___7 ;
  unsigned int tmp___8 ;
  unsigned int tmp___9 ;
  unsigned int tmp___10 ;
  unsigned int tmp___11 ;
  unsigned int tmp___12 ;
  unsigned int tmp___13 ;
  unsigned int tmp___14 ;

  {
  tmp = readl((void const volatile   *)rb + 84368U);
  wgn = tmp;
  nfc_ver = readl((void const volatile   *)rb + 161372U);
  if ((unsigned int )wgn == 3072U && nfc_ver > 322U) {
    tmp___0 = bfa_ioc_ct2_nfc_halted(rb);
    if ((int )tmp___0) {
      bfa_ioc_ct2_nfc_resume(rb);
    } else {

    }
    writel(65536U, (void volatile   *)rb + 159880U);
    i = 0U;
    goto ldv_47686;
    ldv_47685: 
    tmp___1 = readl((void const volatile   *)rb + 83976U);
    r32 = tmp___1;
    if (((unsigned int )r32 & 65536U) != 0U) {
      goto ldv_47684;
    } else {

    }
    i = i + 1U;
    ldv_47686: ;
    if (i <= 999999U) {
      goto ldv_47685;
    } else {

    }
    ldv_47684: 
    tmp___2 = ldv__builtin_expect(((unsigned int )r32 & 65536U) == 0U, 0L);
    if (tmp___2 != 0L) {
      __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc_ct.c"),
                           "i" (875), "i" (12UL));
      ldv_47687: ;
      goto ldv_47687;
    } else {

    }
    i = 0U;
    goto ldv_47690;
    ldv_47689: 
    tmp___3 = readl((void const volatile   *)rb + 83976U);
    r32 = tmp___3;
    if (((unsigned int )r32 & 65536U) == 0U) {
      goto ldv_47688;
    } else {

    }
    i = i + 1U;
    ldv_47690: ;
    if (i <= 999999U) {
      goto ldv_47689;
    } else {

    }
    ldv_47688: 
    tmp___4 = ldv__builtin_expect(((unsigned int )r32 & 65536U) != 0U, 0L);
    if (tmp___4 != 0L) {
      __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc_ct.c"),
                           "i" (882), "i" (12UL));
      ldv_47691: ;
      goto ldv_47691;
    } else {

    }
    __const_udelay(4295000UL);
    tmp___5 = readl((void const volatile   *)rb + 159872U);
    r32 = tmp___5;
    tmp___6 = ldv__builtin_expect(((unsigned int )r32 & 65536U) != 0U, 0L);
    if (tmp___6 != 0L) {
      __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc_ct.c"),
                           "i" (886), "i" (12UL));
      ldv_47692: ;
      goto ldv_47692;
    } else {

    }
  } else {
    writel(2U, (void volatile   *)rb + 160804U);
    i = 0U;
    goto ldv_47695;
    ldv_47694: 
    tmp___7 = readl((void const volatile   *)rb + 160804U);
    r32 = tmp___7;
    if (((unsigned int )r32 & 4096U) != 0U) {
      goto ldv_47693;
    } else {

    }
    __const_udelay(4295000UL);
    i = i + 1U;
    ldv_47695: ;
    if (i <= 999U) {
      goto ldv_47694;
    } else {

    }
    ldv_47693: 
    bfa_ioc_ct2_mac_reset(rb);
    bfa_ioc_ct2_sclk_init(rb);
    bfa_ioc_ct2_lclk_init(rb);
    tmp___8 = readl((void const volatile   *)rb + 83980U);
    r32 = tmp___8;
    writel((unsigned int )r32 & 4294901759U, (void volatile   *)rb + 83980U);
    tmp___9 = readl((void const volatile   *)rb + 83976U);
    r32 = tmp___9;
    writel((unsigned int )r32 & 4294901759U, (void volatile   *)rb + 83976U);
  }
  if ((unsigned int )wgn == 1536U) {
    tmp___10 = readl((void const volatile   *)rb + 100544U);
    r32 = tmp___10;
    writel((unsigned int )r32 & 4294967294U, (void volatile   *)rb + 100544U);
    tmp___11 = readl((void const volatile   *)rb + 100552U);
    r32 = tmp___11;
    writel((unsigned int )r32 | 1U, (void volatile   *)rb + 100552U);
  } else {

  }
  writel(1U, (void volatile   *)rb + 196760U);
  writel(1U, (void volatile   *)rb + 196764U);
  tmp___12 = readl((void const volatile   *)rb + 83476U);
  r32 = tmp___12;
  if ((int )r32 & 1) {
    tmp___13 = readl((void const volatile   *)rb + 196744U);
    r32 = tmp___13;
    if ((unsigned int )r32 == 1U) {
      writel(1U, (void volatile   *)rb + 196744U);
      readl((void const volatile   *)rb + 196744U);
    } else {

    }
    tmp___14 = readl((void const volatile   *)rb + 196748U);
    r32 = tmp___14;
    if ((unsigned int )r32 == 1U) {
      writel(1U, (void volatile   *)rb + 196748U);
      readl((void const volatile   *)rb + 196748U);
    } else {

    }
  } else {

  }
  bfa_ioc_ct2_mem_init(rb);
  writel(0U, (void volatile   *)rb + 84148U);
  writel(0U, (void volatile   *)rb + 84156U);
  return (0);
}
}
extern int ldv_release_11(void) ;
extern int ldv_probe_11(void) ;
void ldv_initialize_bfa_ioc_hwif_11(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(1512UL);
  nw_hwif_ct2_group0 = (struct bfa_ioc *)tmp;
  return;
}
}
void ldv_initialize_bfa_ioc_hwif_12(void) 
{ 
  void *tmp ;

  {
  tmp = ldv_init_zalloc(1512UL);
  nw_hwif_ct_group0 = (struct bfa_ioc *)tmp;
  return;
}
}
void ldv_main_exported_11(void) 
{ 
  enum bfi_asic_mode ldvarg2 ;
  enum bfi_ioc_state ldvarg0 ;
  enum bfi_ioc_state ldvarg3 ;
  void *ldvarg1 ;
  void *tmp ;
  int tmp___0 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg1 = tmp;
  ldv_memset((void *)(& ldvarg2), 0, 4UL);
  ldv_memset((void *)(& ldvarg0), 0, 4UL);
  ldv_memset((void *)(& ldvarg3), 0, 4UL);
  tmp___0 = __VERIFIER_nondet_int();
  switch (tmp___0) {
  case 0: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_ownership_reset(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_ownership_reset(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 1: ;
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct2_lpu_read_stat(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 2: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_sync_join(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_sync_join(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 3: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_notify_fail(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_notify_fail(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 4: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_firmware_lock(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_firmware_lock(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 5: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_get_cur_ioc_fwstate(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_get_cur_ioc_fwstate(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 6: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_firmware_unlock(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_firmware_unlock(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 7: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_set_cur_ioc_fwstate(nw_hwif_ct2_group0, ldvarg3);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_set_cur_ioc_fwstate(nw_hwif_ct2_group0, ldvarg3);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 8: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_sync_complete(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_sync_complete(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 9: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_sync_ack(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_sync_ack(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 10: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_sync_start(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_sync_start(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 11: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct2_pll_init(ldvarg1, ldvarg2);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct2_pll_init(ldvarg1, ldvarg2);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 12: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_set_alt_ioc_fwstate(nw_hwif_ct2_group0, ldvarg0);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_set_alt_ioc_fwstate(nw_hwif_ct2_group0, ldvarg0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 13: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct2_reg_init(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct2_reg_init(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 14: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_sync_leave(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_sync_leave(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 15: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct2_map_port(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct2_map_port(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 16: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_get_alt_ioc_fwstate(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {

  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_get_alt_ioc_fwstate(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {

  }
  goto ldv_47714;
  case 17: ;
  if (ldv_state_variable_11 == 2) {
    ldv_release_11();
    ldv_state_variable_11 = 1;
    ref_cnt = ref_cnt - 1;
  } else {

  }
  goto ldv_47714;
  case 18: ;
  if (ldv_state_variable_11 == 1) {
    ldv_probe_11();
    ldv_state_variable_11 = 2;
    ref_cnt = ref_cnt + 1;
  } else {

  }
  goto ldv_47714;
  default: 
  ldv_stop();
  }
  ldv_47714: ;
  return;
}
}
void ldv_main_exported_12(void) 
{ 
  enum bfi_asic_mode ldvarg38 ;
  bool ldvarg40 ;
  enum bfi_ioc_state ldvarg36 ;
  void *ldvarg37 ;
  void *tmp ;
  enum bfi_ioc_state ldvarg39 ;
  int tmp___0 ;

  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg37 = tmp;
  ldv_memset((void *)(& ldvarg38), 0, 4UL);
  ldv_memset((void *)(& ldvarg40), 0, 1UL);
  ldv_memset((void *)(& ldvarg36), 0, 4UL);
  ldv_memset((void *)(& ldvarg39), 0, 4UL);
  tmp___0 = __VERIFIER_nondet_int();
  switch (tmp___0) {
  case 0: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_ownership_reset(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 1: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_isr_mode_set(nw_hwif_ct_group0, (int )ldvarg40);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 2: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_sync_join(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 3: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_notify_fail(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 4: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_firmware_lock(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 5: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_get_cur_ioc_fwstate(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 6: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_firmware_unlock(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 7: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_set_cur_ioc_fwstate(nw_hwif_ct_group0, ldvarg39);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 8: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_sync_complete(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 9: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_sync_ack(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 10: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_sync_start(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 11: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_pll_init(ldvarg37, ldvarg38);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 12: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_set_alt_ioc_fwstate(nw_hwif_ct_group0, ldvarg36);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 13: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_reg_init(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 14: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_sync_leave(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 15: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_map_port(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  case 16: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_get_alt_ioc_fwstate(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {

  }
  goto ldv_47743;
  default: 
  ldv_stop();
  }
  ldv_47743: ;
  return;
}
}
bool ldv_queue_work_on_440(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_441(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_442(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_443(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_444(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
int ldv_pskb_expand_head_456(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_458(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_460(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_461(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_462(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_463(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_464(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
int ldv_pskb_expand_head_465(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_466(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
bool ldv_queue_work_on_486(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_488(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_487(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_490(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_489(struct workqueue_struct *ldv_func_arg1 ) ;
struct sk_buff *ldv_skb_clone_504(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_512(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_506(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_502(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_510(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_511(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_507(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_508(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_509(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
static void bfa_cee_format_lldp_cfg(struct bfa_cee_lldp_cfg *lldp_cfg ) ;
static void bfa_cee_format_cee_cfg(void *buffer ) ;
static void bfa_cee_format_cee_cfg(void *buffer ) 
{ 
  struct bfa_cee_attr *cee_cfg ;

  {
  cee_cfg = (struct bfa_cee_attr *)buffer;
  bfa_cee_format_lldp_cfg(& cee_cfg->lldp_remote);
  return;
}
}
static void bfa_cee_stats_swap(struct bfa_cee_stats *stats ) 
{ 
  u32 *buffer ;
  int i ;
  __u32 tmp ;

  {
  buffer = (u32 *)stats;
  i = 0;
  goto ldv_47731;
  ldv_47730: 
  tmp = __fswab32(*(buffer + (unsigned long )i));
  *(buffer + (unsigned long )i) = tmp;
  i = i + 1;
  ldv_47731: ;
  if ((unsigned int )i <= 17U) {
    goto ldv_47730;
  } else {

  }

  return;
}
}
static void bfa_cee_format_lldp_cfg(struct bfa_cee_lldp_cfg *lldp_cfg ) 
{ 
  __u16 tmp ;
  __u16 tmp___0 ;

  {
  tmp = __fswab16((int )lldp_cfg->time_to_live);
  lldp_cfg->time_to_live = tmp;
  tmp___0 = __fswab16((int )lldp_cfg->enabled_system_cap);
  lldp_cfg->enabled_system_cap = tmp___0;
  return;
}
}
static u32 bfa_cee_attr_meminfo(void) 
{ 
  int __y ;

  {
  __y = 256;
  return ((u32 )((((unsigned long )(__y + -1) + 832UL) / (unsigned long )__y) * (unsigned long )__y));
}
}
static u32 bfa_cee_stats_meminfo(void) 
{ 
  int __y ;

  {
  __y = 256;
  return ((u32 )((((unsigned long )(__y + -1) + 72UL) / (unsigned long )__y) * (unsigned long )__y));
}
}
static void bfa_cee_get_attr_isr(struct bfa_cee *cee , enum bfa_status status ) 
{ 


  {
  cee->get_attr_status = status;
  if ((unsigned int )status == 0U) {
    memcpy((void *)cee->attr, (void const   *)cee->attr_dma.kva, 832UL);
    bfa_cee_format_cee_cfg((void *)cee->attr);
  } else {

  }
  cee->get_attr_pending = 0;
  if ((unsigned long )cee->cbfn.get_attr_cbfn != (unsigned long )((void (*)(void * ,
                                                                            enum bfa_status  ))0)) {
    (*(cee->cbfn.get_attr_cbfn))(cee->cbfn.get_attr_cbarg, status);
  } else {

  }
  return;
}
}
static void bfa_cee_get_stats_isr(struct bfa_cee *cee , enum bfa_status status ) 
{ 


  {
  cee->get_stats_status = status;
  if ((unsigned int )status == 0U) {
    memcpy((void *)cee->stats, (void const   *)cee->stats_dma.kva, 72UL);
    bfa_cee_stats_swap(cee->stats);
  } else {

  }
  cee->get_stats_pending = 0;
  if ((unsigned long )cee->cbfn.get_stats_cbfn != (unsigned long )((void (*)(void * ,
                                                                             enum bfa_status  ))0)) {
    (*(cee->cbfn.get_stats_cbfn))(cee->cbfn.get_stats_cbarg, status);
  } else {

  }
  return;
}
}
static void bfa_cee_reset_stats_isr(struct bfa_cee *cee , enum bfa_status status ) 
{ 


  {
  cee->reset_stats_status = status;
  cee->reset_stats_pending = 0;
  if ((unsigned long )cee->cbfn.reset_stats_cbfn != (unsigned long )((void (*)(void * ,
                                                                               enum bfa_status  ))0)) {
    (*(cee->cbfn.reset_stats_cbfn))(cee->cbfn.reset_stats_cbarg, status);
  } else {

  }
  return;
}
}
u32 bfa_nw_cee_meminfo(void) 
{ 
  u32 tmp ;
  u32 tmp___0 ;

  {
  tmp = bfa_cee_attr_meminfo();
  tmp___0 = bfa_cee_stats_meminfo();
  return (tmp + tmp___0);
}
}
void bfa_nw_cee_mem_claim(struct bfa_cee *cee , u8 *dma_kva , u64 dma_pa ) 
{ 
  u32 tmp ;
  u32 tmp___0 ;
  u32 tmp___1 ;

  {
  cee->attr_dma.kva = (void *)dma_kva;
  cee->attr_dma.pa = dma_pa;
  tmp = bfa_cee_attr_meminfo();
  cee->stats_dma.kva = (void *)dma_kva + (unsigned long )tmp;
  tmp___0 = bfa_cee_attr_meminfo();
  cee->stats_dma.pa = (u64 )tmp___0 + dma_pa;
  cee->attr = (struct bfa_cee_attr *)dma_kva;
  tmp___1 = bfa_cee_attr_meminfo();
  cee->stats = (struct bfa_cee_stats *)dma_kva + (unsigned long )tmp___1;
  return;
}
}
enum bfa_status bfa_nw_cee_get_attr(struct bfa_cee *cee , struct bfa_cee_attr *attr ,
                                    void (*cbfn)(void * , enum bfa_status  ) , void *cbarg ) 
{ 
  struct bfi_cee_get_req *cmd ;
  long tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
  tmp = ldv__builtin_expect((long )((unsigned long )cee == (unsigned long )((struct bfa_cee *)0) || (unsigned long )cee->ioc == (unsigned long )((struct bfa_ioc *)0)),
                         0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_cee.c"),
                         "i" (171), "i" (12UL));
    ldv_47773: ;
    goto ldv_47773;
  } else {

  }
  tmp___0 = bfa_nw_ioc_is_operational(cee->ioc);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    return (56);
  } else {

  }
  if ((int )cee->get_attr_pending) {
    return (13);
  } else {

  }
  cee->get_attr_pending = 1;
  cmd = (struct bfi_cee_get_req *)(& cee->get_cfg_mb.msg);
  cee->attr = attr;
  cee->cbfn.get_attr_cbfn = cbfn;
  cee->cbfn.get_attr_cbarg = cbarg;
  cmd->mh.msg_class = 4U;
  cmd->mh.msg_id = 1U;
  cmd->mh.mtag.h2i.fn_lpu = (cee->ioc)->port_id;
  __bfa_dma_be_addr_set(& cmd->dma_addr, cee->attr_dma.pa);
  bfa_nw_ioc_mbox_queue(cee->ioc, & cee->get_cfg_mb, (void (*)(void * ))0, (void *)0);
  return (0);
}
}
static void bfa_cee_isr(void *cbarg , struct bfi_mbmsg *m ) 
{ 
  union bfi_cee_i2h_msg_u *msg ;
  struct bfi_cee_get_rsp *get_rsp ;
  struct bfa_cee *cee ;
  long tmp ;

  {
  cee = (struct bfa_cee *)cbarg;
  msg = (union bfi_cee_i2h_msg_u *)m;
  get_rsp = (struct bfi_cee_get_rsp *)m;
  switch ((int )msg->mh.msg_id) {
  case 129: 
  bfa_cee_get_attr_isr(cee, (enum bfa_status )get_rsp->cmd_status);
  goto ldv_47782;
  case 131: 
  bfa_cee_get_stats_isr(cee, (enum bfa_status )get_rsp->cmd_status);
  goto ldv_47782;
  case 130: 
  bfa_cee_reset_stats_isr(cee, (enum bfa_status )get_rsp->cmd_status);
  goto ldv_47782;
  default: 
  tmp = ldv__builtin_expect(1L, 0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_cee.c"),
                         "i" (214), "i" (12UL));
    ldv_47786: ;
    goto ldv_47786;
  } else {

  }
  }
  ldv_47782: ;
  return;
}
}
static void bfa_cee_notify(void *arg , enum bfa_ioc_event event ) 
{ 
  struct bfa_cee *cee ;

  {
  cee = (struct bfa_cee *)arg;
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U: ;
  if ((int )cee->get_attr_pending) {
    cee->get_attr_status = 1;
    cee->get_attr_pending = 0;
    if ((unsigned long )cee->cbfn.get_attr_cbfn != (unsigned long )((void (*)(void * ,
                                                                              enum bfa_status  ))0)) {
      (*(cee->cbfn.get_attr_cbfn))(cee->cbfn.get_attr_cbarg, 1);
    } else {

    }
  } else {

  }
  if ((int )cee->get_stats_pending) {
    cee->get_stats_status = 1;
    cee->get_stats_pending = 0;
    if ((unsigned long )cee->cbfn.get_stats_cbfn != (unsigned long )((void (*)(void * ,
                                                                               enum bfa_status  ))0)) {
      (*(cee->cbfn.get_stats_cbfn))(cee->cbfn.get_stats_cbarg, 1);
    } else {

    }
  } else {

  }
  if ((int )cee->reset_stats_pending) {
    cee->reset_stats_status = 1;
    cee->reset_stats_pending = 0;
    if ((unsigned long )cee->cbfn.reset_stats_cbfn != (unsigned long )((void (*)(void * ,
                                                                                 enum bfa_status  ))0)) {
      (*(cee->cbfn.reset_stats_cbfn))(cee->cbfn.reset_stats_cbarg, 1);
    } else {

    }
  } else {

  }
  goto ldv_47794;
  default: ;
  goto ldv_47794;
  }
  ldv_47794: ;
  return;
}
}
void bfa_nw_cee_attach(struct bfa_cee *cee , struct bfa_ioc *ioc , void *dev ) 
{ 
  long tmp ;

  {
  tmp = ldv__builtin_expect((unsigned long )cee == (unsigned long )((struct bfa_cee *)0),
                         0L);
  if (tmp != 0L) {
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_cee.c"),
                         "i" (280), "i" (12UL));
    ldv_47801: ;
    goto ldv_47801;
  } else {

  }
  cee->dev = dev;
  cee->ioc = ioc;
  bfa_nw_ioc_mbox_regisr(cee->ioc, 4, & bfa_cee_isr, (void *)cee);
  cee->ioc_notify.cbfn = & bfa_cee_notify;
  cee->ioc_notify.cbarg = (void *)cee;
  bfa_nw_ioc_notify_register(cee->ioc, & cee->ioc_notify);
  return;
}
}
bool ldv_queue_work_on_486(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_487(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_488(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_489(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_490(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
int ldv_pskb_expand_head_502(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_504(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_506(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_507(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_508(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_509(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_510(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
int ldv_pskb_expand_head_511(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_512(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
bool ldv_queue_work_on_532(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_534(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_533(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_536(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_535(struct workqueue_struct *ldv_func_arg1 ) ;
extern void dev_alert(struct device  const  * , char const   *  , ...) ;
struct sk_buff *ldv_skb_clone_550(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_558(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_552(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_548(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_556(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_557(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_553(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_554(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_555(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct firmware  const  *bfi_fw  ;
static u32 *bfi_image_ct_cna  ;
static u32 *bfi_image_ct2_cna  ;
static u32 bfi_image_ct_cna_size  ;
static u32 bfi_image_ct2_cna_size  ;
static u32 *cna_read_firmware(struct pci_dev *pdev , u32 **bfi_image , u32 *bfi_image_size ,
                              char *fw_name ) 
{ 
  struct firmware  const  *fw ;
  u32 n ;
  int tmp ;

  {
  tmp = request_firmware(& fw, (char const   *)fw_name, & pdev->dev);
  if (tmp != 0) {
    dev_alert((struct device  const  *)(& pdev->dev), "can\'t load firmware %s\n",
              fw_name);
    goto error;
  } else {

  }
  *bfi_image = (u32 *)fw->data;
  *bfi_image_size = (u32 )((unsigned long )fw->size / 4UL);
  bfi_fw = fw;
  n = 0U;
  goto ldv_58171;
  ldv_58170: 
  n = n + 1U;
  ldv_58171: ;
  if (*bfi_image_size > n) {
    goto ldv_58170;
  } else {

  }

  return (*bfi_image);
  error: ;
  return ((u32 *)0U);
}
}
u32 *cna_get_firmware_buf(struct pci_dev *pdev ) 
{ 


  {
  if ((unsigned int )pdev->device == 34U) {
    if (bfi_image_ct2_cna_size == 0U) {
      cna_read_firmware(pdev, & bfi_image_ct2_cna, & bfi_image_ct2_cna_size, (char *)"ct2fw-3.2.5.1.bin");
    } else {

    }
    return (bfi_image_ct2_cna);
  } else
  if ((unsigned int )pdev->device == 20U || (unsigned int )pdev->device == 33U) {
    if (bfi_image_ct_cna_size == 0U) {
      cna_read_firmware(pdev, & bfi_image_ct_cna, & bfi_image_ct_cna_size, (char *)"ctfw-3.2.5.1.bin");
    } else {

    }
    return (bfi_image_ct_cna);
  } else {

  }
  return ((u32 *)0U);
}
}
u32 *bfa_cb_image_get_chunk(enum bfi_asic_gen asic_gen , u32 off ) 
{ 


  {
  switch ((unsigned int )asic_gen) {
  case 2U: ;
  return (bfi_image_ct_cna + (unsigned long )off);
  case 3U: ;
  return (bfi_image_ct2_cna + (unsigned long )off);
  default: ;
  return ((u32 *)0U);
  }
}
}
u32 bfa_cb_image_get_size(enum bfi_asic_gen asic_gen ) 
{ 


  {
  switch ((unsigned int )asic_gen) {
  case 2U: ;
  return (bfi_image_ct_cna_size);
  case 3U: ;
  return (bfi_image_ct2_cna_size);
  default: ;
  return (0U);
  }
}
}
bool ldv_queue_work_on_532(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_533(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_534(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_535(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_536(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;

  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
int ldv_pskb_expand_head_548(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_550(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_552(struct sk_buff  const  *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_553(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_554(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_555(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_556(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
int ldv_pskb_expand_head_557(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) 
{ 

  {
  ldv_check_alloc_flags(flags);
  return __VERIFIER_nondet_int();
}
}
struct sk_buff *ldv_skb_clone_558(struct sk_buff *ldv_func_arg1 , gfp_t flags ) 
{ 
  void *tmp ;

  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_malloc(sizeof(struct sk_buff));
  return ((struct sk_buff *)tmp);
}
}
bool ldv_is_err(void const   *ptr ) 
{ 


  {
  return ((unsigned long )ptr > 2012UL);
}
}
void *ldv_err_ptr(long error ) 
{ 


  {
  return ((void *)(2012L - error));
}
}
long ldv_ptr_err(void const   *ptr ) 
{ 


  {
  return ((long )(2012UL - (unsigned long )ptr));
}
}
bool ldv_is_err_or_null(void const   *ptr ) 
{ 
  bool tmp ;
  int tmp___0 ;

  {
  if ((unsigned long )ptr == (unsigned long )((void const   *)0)) {
    tmp___0 = 1;
  } else {
    tmp = ldv_is_err(ptr);
    if ((int )tmp) {
      tmp___0 = 1;
    } else {
      tmp___0 = 0;
    }
  }
  return ((bool )tmp___0);
}
}
int ldv_spin  =    0;
void ldv_check_alloc_flags(gfp_t flags ) 
{ 


  {
  if (ldv_spin != 0 && (flags & 16U) != 0U) {
    ldv_error();
  } else {

  }
  return;
}
}
extern struct page *ldv_some_page(void) ;
struct page *ldv_check_alloc_flags_and_return_some_page(gfp_t flags ) 
{ 
  struct page *tmp ;

  {
  if (ldv_spin != 0 && (flags & 16U) != 0U) {
    ldv_error();
  } else {

  }
  tmp = ldv_some_page();
  return (tmp);
}
}
void ldv_check_alloc_nonatomic(void) 
{ 


  {
  if (ldv_spin != 0) {
    ldv_error();
  } else {

  }
  return;
}
}
void ldv_spin_lock(void) 
{ 


  {
  ldv_spin = 1;
  return;
}
}
void ldv_spin_unlock(void) 
{ 


  {
  ldv_spin = 0;
  return;
}
}
int ldv_spin_trylock(void) 
{ 
  int is_lock ;
    klee_make_symbolic(&is_lock, sizeof(int), "is_lock");

  {
  is_lock = ldv_undef_int();
  if (is_lock != 0) {
    return (0);
  } else {
    ldv_spin = 1;
    return (1);
  }
}
}
#include "model/linux-4.2-rc1.tar.xz-43_2a-drivers--net--ethernet--brocade--bna--bna.ko-entry_point_true-unreach-call.cil.out.env.c"
#include <klee/klee.h>
#include "model/common.env.c"
